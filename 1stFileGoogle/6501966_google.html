<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6501966 - Speech recognition system for electronic switches in a non-wireline ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Speech recognition system for electronic switches in a non-wireline communications network"><meta name="DC.contributor" content="Bernard F. Bareis" scheme="inventor"><meta name="DC.contributor" content="Peter J. Foster" scheme="inventor"><meta name="DC.contributor" content="Thomas B. Schalk" scheme="inventor"><meta name="DC.contributor" content="Koninklijke Philips Electronics N.V." scheme="assignee"><meta name="DC.date" content="2000-11-27" scheme="dateSubmitted"><meta name="DC.description" content="An advanced telecommunications system is provided for the recognizing of spoken commands over a cellular telephone, satellite telephone, or personal communications network. In the cellular application, for example, a Speech Recognition System interconnects either internally with or as an external peripheral to a cellular telecommunications switch. The Speech Recognition System includes an administrative subsystem, a call processing subsystem, a speaker-dependent recognition subsystem, a speaker-independent recognition subsystem, and a data storage subsystem. The Speech Recognition System also allows for increased efficiency in the cellular telephone network by integrating with the switch or switches as a shared resource. The administrative subsystem of the Speech Recognition System is used to keep statistical logs of pertinent call information. Pre-recorded instructional messages are stored in the memory of the call processing subsystem for instructing a user on his or her progress in using the system. The speaker-independent recognition subsystem allows the user to interact with the system employing non-user specific functions. User specific functions are controlled with the speaker-dependent recognition subsystem. User specific attributes collected by the recognition subsystems are stored in the data storage subsystem."><meta name="DC.date" content="2002-12-31" scheme="issued"><meta name="DC.relation" content="US:3673331" scheme="references"><meta name="DC.relation" content="US:3928724" scheme="references"><meta name="DC.relation" content="US:4385359" scheme="references"><meta name="DC.relation" content="US:4587670" scheme="references"><meta name="DC.relation" content="US:4827500" scheme="references"><meta name="DC.relation" content="US:4922538" scheme="references"><meta name="DC.relation" content="US:4949374" scheme="references"><meta name="DC.relation" content="US:4961212" scheme="references"><meta name="DC.relation" content="US:5054053" scheme="references"><meta name="DC.relation" content="US:5148471" scheme="references"><meta name="DC.relation" content="US:5182765" scheme="references"><meta name="DC.relation" content="US:5195090" scheme="references"><meta name="DC.relation" content="US:5199062" scheme="references"><meta name="DC.relation" content="US:5222121" scheme="references"><meta name="DC.relation" content="US:5283833" scheme="references"><meta name="DC.relation" content="US:5289530" scheme="references"><meta name="DC.relation" content="US:5297183" scheme="references"><meta name="DC.relation" content="US:5301223" scheme="references"><meta name="DC.relation" content="US:5335313" scheme="references"><meta name="DC.relation" content="US:5365574" scheme="references"><meta name="DC.relation" content="US:5371901" scheme="references"><meta name="DC.relation" content="US:5390278" scheme="references"><meta name="DC.relation" content="US:5659597" scheme="references"><meta name="DC.relation" content="US:6157848" scheme="references"><meta name="citation_reference" content="&quot;A Multi-DSP Implementation of a Broad-Band Adaptive Beamformer for Use in a Hands-Free Mobile Radio Telephone&quot;, by Claesson et al, IEEE Transactions on Vehicular Technology, vol. 40, No. 1, Feb. 1991, pp. 194-202."><meta name="citation_reference" content="&quot;A New Speaker-Independent Voice Recognition Scheme for Voice Dialling&quot;, by Takizawa et al, IEEE 1987 p. 547-551."><meta name="citation_reference" content="&quot;A PABX That Listens and Talks&quot;, Speech Technology, Jan./Feb. 1984, pp. 75-79."><meta name="citation_reference" content="&quot;A speaker independent voice dialing system for Italian in the cellular phone application&quot;, by Babini et al, CSELT Technical Reports, vol. XVIII, No. 3, Jun. 1990, pp. 201-205."><meta name="citation_reference" content="&quot;AT&amp;T&#39;s Conversant I Voice System&quot;, by John P. Moosemiller, Speech Technologoy, Mar./Apr. 1986, pp. 88-93."><meta name="citation_reference" content="&quot;Automating Services with Speech Recognition over the Public Switched Telephone Network: Human Factors Considerations&quot;, by Karis et al, IEEE Journal on Selected Areas in Communications, vol. 9, No. 4, May 1991, pp. 574-585."><meta name="citation_reference" content="&quot;Cellular Packet Communications&quot;, by Goodman, IEEE Transactions on Communications, vol. 38, No. 8, Aug. 1990, pp. 1272-1280."><meta name="citation_reference" content="&quot;Development of the Speaker-Dependent Voice Activated Dialing Equipment&quot;, by Sato, pp. 548-554."><meta name="citation_reference" content="&quot;Dialing a Phone by Voice&quot;, by Pawate et al, Machine Design, Jan. 19, 1991, pp. 95-98."><meta name="citation_reference" content="&quot;Dialing by Voice&quot;, IEEE Spectrum, Aug. 1986, p. 22."><meta name="citation_reference" content="&quot;Environment Adaptation for Speech Recognition in Noise&quot;, by Blanchet et al, Signal Processing VI: Theories and Applications, 1992, pp. 391-394."><meta name="citation_reference" content="&quot;Eyes Free Dialing for Cellular Telephones&quot;, by Bendelac et al, IEEE 1991, pp. 120-125."><meta name="citation_reference" content="&quot;Eyes Free Dialing for Cellular Telephones&quot;, by Bendelac et al, pp. 234-237."><meta name="citation_reference" content="&quot;Freedom Doesn&#39;t Come Easy&quot;, by Shandle, Electronics, Mar. 1991, pp. 45-48."><meta name="citation_reference" content="&quot;Hands-Free Voice Communication in an Automobile with a Microphone Array&quot;, by Oh et al, IEEE 1992, pp. I-281-I-I-284."><meta name="citation_reference" content="&quot;HMM Modeling for Speaker Independent Voice Dialing in Car Environment&quot;, by Fissore et al, IEEE 1992, pp. I-249-I-252."><meta name="citation_reference" content="&quot;Interactive Voice Technology Applications&quot;, by Fischell et al, AT&amp;T Technical Journal, Sep./Oct. 1990, pp. 61-76."><meta name="citation_reference" content="&quot;Is thought dialing next?&quot;, Telephone Engineer &amp; Management, Apr. 1, 1991, p. 58, ISSN: 0040-263X."><meta name="citation_reference" content="&quot;Isolated Word Recognition in the Mobile-Radio System: Experiments and Results&quot;, by Fissore, Signal Processing V: Theories and Applications, 1990, pp. 1207-1210."><meta name="citation_reference" content="&quot;Learned Codebook Excited Linear Predictive (LCELP) Speech Codec for Digital Cellular System&quot;, by Unno et al, NEC Res. &amp; Develop., vol. 32, No. 4, Oct. 1991, pp. 549-556."><meta name="citation_reference" content="&quot;Network Protocols for the Cellular Packet Switch&quot;, by Meier-Hellstern et al, EEE Transactions on Communications, vol. 42, No. 2/3/4, Feb./Mar./Apr. 1994, pp. 1235-1243."><meta name="citation_reference" content="&quot;Packet Switching in Digital Cellular Systems&quot;, by Felix, Motorola Inc, pp. 414-418."><meta name="citation_reference" content="&quot;Putting Speech Recognition to Work in the Telephone Network&quot;, by Lennig, Computer, Aug. 1990, pp. 35-41."><meta name="citation_reference" content="&quot;Speech Recognition Services&quot; Projects to consder for voice input work at USWEST, from 1988 Presentation to USWEST."><meta name="citation_reference" content="&quot;SPS51-A universal interface for hands-free telephony, speech recognition and speech storage in the car telephone&quot;, by Ruhl et al, Philips Telecommunication Review, vol. 48, No. 4, Dec. 1990, pp. 1-10."><meta name="citation_reference" content="&quot;The 5ESS Switching System&quot;, by Martersteck et al, AT&amp;T Technical Journal, vol. 64, No. 6, Jul., Aug. 1985, pp. 1305-1313."><meta name="citation_reference" content="&quot;The 5ESS Switching System: Architectural Overview&quot;, by D.L. Carney et al, AT&amp;T Technical Journal, vol. 64, No. 6, Jul.-Aug. 1985, pp. 1339-1355."><meta name="citation_reference" content="&quot;The 5ESS Switching Systems: Applications Planning&quot;, by W.R. Byre et al, AT&amp;T Technical Journal, Jul.-Aug. 1985, pp. 1315-1336."><meta name="citation_reference" content="&quot;The 5ESS(R) Wireless Mobile Switching Center&quot;, by Gauldin et al, AT&amp;T Technical Journal, Jul./Aug. 1993, pp. 38-47."><meta name="citation_reference" content="&quot;Trends in Cellular and Cordless Communications&quot;, by Goodman, IEEE Communications Magazine, Jun. 1991, pp. 31-40."><meta name="citation_reference" content="&quot;Voice Control of Mobile Telephones&quot;, by Helms, Speech Tech 1986, pp. 126-130."><meta name="citation_reference" content="&quot;Voice Recognition in Cellular Mobile Telephones&quot;, by Thomas B. Schalk, Speech Technology, Sep./Oct. 1986, pp. 24-28."><meta name="citation_reference" content="&quot;Wireless Network Directions&quot; by Ross, IEEE Communications Magazine, Feb. 1991, pp. 40-42."><meta name="citation_reference" content="“SPS51—A universal interface for hands-free telephony, speech recognition and speech storage in the car telephone”, by Ruhl et al, Philips Telecommunication Review, vol. 48, No. 4, Dec. 1990, pp. 1-10."><meta name="citation_reference" content="“The 5ESS® Wireless Mobile Switching Center”, by Gauldin et al, AT&amp;T Technical Journal, Jul./Aug. 1993, pp. 38-47."><meta name="citation_reference" content="Abstract of Acceptance of voice system hinges on &quot;true&quot; recognition: Voice Ware offers speech recognition board, by Waurzyniak, Computer Software News vol., v4, Issue No. 10, Mar. 10, 1986."><meta name="citation_reference" content="Hands-free telephony, speech recognition and speech coding techniques implemented in the SPS51, by Armbruster et al, Philips Telecommunication Review, vol. 49, No. 1, Mar. 1991, pp. 19-27."><meta name="citation_reference" content="Voice Dial Operating Guide, Voice Command System for Cellular Telephones, By-Word Technologies, Inc. 1989, pp. 1-18."><meta name="citation_patent_number" content="US:6501966"><meta name="citation_patent_application_number" content="US:09/722,810"><link rel="canonical" href="http://www.google.com/patents/US6501966"/><meta property="og:url" content="http://www.google.com/patents/US6501966"/><meta name="title" content="Patent US6501966 - Speech recognition system for electronic switches in a non-wireline communications network"/><meta name="description" content="An advanced telecommunications system is provided for the recognizing of spoken commands over a cellular telephone, satellite telephone, or personal communications network. In the cellular application, for example, a Speech Recognition System interconnects either internally with or as an external peripheral to a cellular telecommunications switch. The Speech Recognition System includes an administrative subsystem, a call processing subsystem, a speaker-dependent recognition subsystem, a speaker-independent recognition subsystem, and a data storage subsystem. The Speech Recognition System also allows for increased efficiency in the cellular telephone network by integrating with the switch or switches as a shared resource. The administrative subsystem of the Speech Recognition System is used to keep statistical logs of pertinent call information. Pre-recorded instructional messages are stored in the memory of the call processing subsystem for instructing a user on his or her progress in using the system. The speaker-independent recognition subsystem allows the user to interact with the system employing non-user specific functions. User specific functions are controlled with the speaker-dependent recognition subsystem. User specific attributes collected by the recognition subsystems are stored in the data storage subsystem."/><meta property="og:title" content="Patent US6501966 - Speech recognition system for electronic switches in a non-wireline communications network"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("sqDtU_HGDKitsAT-1IGIBQ"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("USA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("sqDtU_HGDKitsAT-1IGIBQ"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("USA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6501966?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6501966"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=LbxdBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6501966&amp;usg=AFQjCNEqBRc5mxNrA7HBabFHYMQJVDebLA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6501966.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6501966.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6501966" style="display:none"><span itemprop="description">An advanced telecommunications system is provided for the recognizing of spoken commands over a cellular telephone, satellite telephone, or personal communications network. In the cellular application, for example, a Speech Recognition System interconnects either internally with or as an external peripheral...</span><span itemprop="url">http://www.google.com/patents/US6501966?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6501966 - Speech recognition system for electronic switches in a non-wireline communications network</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6501966 - Speech recognition system for electronic switches in a non-wireline communications network" title="Patent US6501966 - Speech recognition system for electronic switches in a non-wireline communications network"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6501966 B1</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/722,810</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Dec 31, 2002</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Nov 27, 2000</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Apr 13, 1992</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2118135A1">CA2118135A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2118135C">CA2118135C</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE69329850D1">DE69329850D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE69329850T2">DE69329850T2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0636294A1">EP0636294A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0636294A4">EP0636294A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0636294B1">EP0636294B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5297183">US5297183</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5659597">US5659597</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6157848">US6157848</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7551944">US7551944</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8019387">US8019387</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20030087675">US20030087675</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20090074157">US20090074157</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO1993021721A1">WO1993021721A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09722810, </span><span class="patent-bibdata-value">722810, </span><span class="patent-bibdata-value">US 6501966 B1, </span><span class="patent-bibdata-value">US 6501966B1, </span><span class="patent-bibdata-value">US-B1-6501966, </span><span class="patent-bibdata-value">US6501966 B1, </span><span class="patent-bibdata-value">US6501966B1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Bernard+F.+Bareis%22">Bernard F. Bareis</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Peter+J.+Foster%22">Peter J. Foster</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Thomas+B.+Schalk%22">Thomas B. Schalk</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Koninklijke+Philips+Electronics+N.V.%22">Koninklijke Philips Electronics N.V.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6501966.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6501966.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6501966.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (24),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (38),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (20),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (26),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (9)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6501966&usg=AFQjCNFswv5jY-O01cwReDEffF85HnCB1g">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6501966&usg=AFQjCNE8QYagyMrYJXKk1FFlXiG1X2_rKQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6501966B1%26KC%3DB1%26FT%3DD&usg=AFQjCNEyNzvIT3KODdUJ5T_VmGrLjNrFkA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55025523" lang="EN" load-source="patent-office">Speech recognition system for electronic switches in a non-wireline communications network</invention-title></span><br><span class="patent-number">US 6501966 B1</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50429225" lang="EN" load-source="patent-office"> <div class="abstract">An advanced telecommunications system is provided for the recognizing of spoken commands over a cellular telephone, satellite telephone, or personal communications network. In the cellular application, for example, a Speech Recognition System interconnects either internally with or as an external peripheral to a cellular telecommunications switch. The Speech Recognition System includes an administrative subsystem, a call processing subsystem, a speaker-dependent recognition subsystem, a speaker-independent recognition subsystem, and a data storage subsystem. The Speech Recognition System also allows for increased efficiency in the cellular telephone network by integrating with the switch or switches as a shared resource. The administrative subsystem of the Speech Recognition System is used to keep statistical logs of pertinent call information. Pre-recorded instructional messages are stored in the memory of the call processing subsystem for instructing a user on his or her progress in using the system. The speaker-independent recognition subsystem allows the user to interact with the system employing non-user specific functions. User specific functions are controlled with the speaker-dependent recognition subsystem. User specific attributes collected by the recognition subsystems are stored in the data storage subsystem.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(13)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6501966B1/US06501966-20021231-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6501966B1/US06501966-20021231-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(30)</span></span></div><div class="patent-text"><div mxw-id="PCLM8413044" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is: </claim-statement> <div class="claim"> <div num="1" id="US-6501966-B1-CLM-00001" class="claim">
      <div class="claim-text">1. A speech recognition method for a mobile telecommunication system which includes a voice recognizer capable of recognizing commands and characters received from a mobile telecommunication user, the method comprising the steps of:</div>
      <div class="claim-text">receiving a command from the mobile telecommunication user; </div>
      <div class="claim-text">determining whether the command is a first or second command type; </div>
      <div class="claim-text">if the command is the first command type, collecting digits representing a telephone number to be dialed received from the mobile telecommunication user; and </div>
      <div class="claim-text">if the command is the second command type, determining whether a previously stored telephone number is associated with a keyword received from the mobile telecommunication user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6501966-B1-CLM-00002" class="claim">
      <div class="claim-text">2. The method according to <claim-ref idref="US-6501966-B1-CLM-00001">claim 1</claim-ref>, wherein the keyword is a name.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6501966-B1-CLM-00003" class="claim">
      <div class="claim-text">3. The method according to <claim-ref idref="US-6501966-B1-CLM-00001">claim 1</claim-ref>, wherein the keyword is a location or relationship modifier.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6501966-B1-CLM-00004" class="claim">
      <div class="claim-text">4. The method according to <claim-ref idref="US-6501966-B1-CLM-00003">claim 3</claim-ref> wherein the location modifier is home, work or office.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6501966-B1-CLM-00005" class="claim">
      <div class="claim-text">5. The method according to <claim-ref idref="US-6501966-B1-CLM-00001">claim 1</claim-ref>, further comprising the steps of verifying the command and initiating a telecommunication call with the mobile telecommunication system.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6501966-B1-CLM-00006" class="claim">
      <div class="claim-text">6. The method according to <claim-ref idref="US-6501966-B1-CLM-00001">claim 1</claim-ref>, further comprising the step of prompting the mobile telecommunication user to enter information needed for the first or the second command type.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" id="US-6501966-B1-CLM-00007" class="claim">
      <div class="claim-text">7. The method according to <claim-ref idref="US-6501966-B1-CLM-00001">claim 1</claim-ref>, further comprising the step of verifying the mobile telecommunication user's identity.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" id="US-6501966-B1-CLM-00008" class="claim">
      <div class="claim-text">8. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00007">claim 7</claim-ref> wherein the speech recognition apparatus is connected to the mobile telecommunication switch as an external peripheral.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" id="US-6501966-B1-CLM-00009" class="claim">
      <div class="claim-text">9. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00007">claim 7</claim-ref> wherein the memory is connected to the controller through a data network.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" id="US-6501966-B1-CLM-00010" class="claim">
      <div class="claim-text">10. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00007">claim 7</claim-ref> wherein the speech recognition apparatus is a shared resource that can be accessed by more than one mobile telecommunication switch.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" id="US-6501966-B1-CLM-00011" class="claim">
      <div class="claim-text">11. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00007">claim 7</claim-ref> wherein the speech recognition apparatus is connected to a non-mobile telecommunication switch and the interface communicates with the mobile telecommunication switch through the non-mobile telecommunication switch.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" id="US-6501966-B1-CLM-00012" class="claim">
      <div class="claim-text">12. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00007">claim 7</claim-ref> wherein the voice recognizer is also capable of recognizing commands and characters received through the interface from a non-mobile telecommunication user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" id="US-6501966-B1-CLM-00013" class="claim">
      <div class="claim-text">13. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00007">claim 7</claim-ref> wherein the mobile telecommunication system interfaces with a communication network.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" id="US-6501966-B1-CLM-00014" class="claim">
      <div class="claim-text">14. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00013">claim 13</claim-ref> wherein the communication network is a circuit switched network.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" id="US-6501966-B1-CLM-00015" class="claim">
      <div class="claim-text">15. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00013">claim 13</claim-ref> wherein the communication network is a packet switched network.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" id="US-6501966-B1-CLM-00016" class="claim">
      <div class="claim-text">16. The method according to <claim-ref idref="US-6501966-B1-CLM-00001">claim 1</claim-ref> wherein the keyword is associated with a type of data requested by the mobile telecommunication user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" id="US-6501966-B1-CLM-00017" class="claim">
      <div class="claim-text">17. The method according to <claim-ref idref="US-6501966-B1-CLM-00016">claim 16</claim-ref> wherein the keyword includes time and information.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" id="US-6501966-B1-CLM-00018" class="claim">
      <div class="claim-text">18. The method according to <claim-ref idref="US-6501966-B1-CLM-00016">claim 16</claim-ref> further comprising the step of having the mobile telecommunication user subscribe to a service that includes a predetermined list of keywords.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" id="US-6501966-B1-CLM-00019" class="claim">
      <div class="claim-text">19. The method according to <claim-ref idref="US-6501966-B1-CLM-00001">claim 1</claim-ref> further comprising the step of having the mobile telecommunication system establish a path connection between the mobile telecommunication user and the voice recognizer.</div>
    </div>
    </div> <div class="claim"> <div num="20" id="US-6501966-B1-CLM-00020" class="claim">
      <div class="claim-text">20. A speech recognition apparatus for a mobile telecommunication system, the apparatus comprising:</div>
      <div class="claim-text">a memory; </div>
      <div class="claim-text">an interface with a mobile telecommunication switch; </div>
      <div class="claim-text">a voice recognizer capable of recognizing commands and characters received through the interface from a mobile telecommunication user; and </div>
      <div class="claim-text">a controller, coupled to the memory and the voice recognizer, arranged to determine whether a speech input from the user is a call command, if the command is a first call command type, collect digits representing a telephone number to be dialed spoken by the user, if the command is a second call command type, determine whether a previously stored telephone number is associated with a reference code received from the mobile telecommunication user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" id="US-6501966-B1-CLM-00021" class="claim">
      <div class="claim-text">21. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00020">claim 20</claim-ref>, wherein the reference code is a name.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" id="US-6501966-B1-CLM-00022" class="claim">
      <div class="claim-text">22. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00020">claim 20</claim-ref>, wherein the reference code is a location or relationship modifier.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" id="US-6501966-B1-CLM-00023" class="claim">
      <div class="claim-text">23. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00020">claim 20</claim-ref> further comprising means for verifying the mobile telecommunication user's identity.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" id="US-6501966-B1-CLM-00024" class="claim">
      <div class="claim-text">24. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00020">claim 20</claim-ref> wherein the interface communicates with the mobile telecommunication switch using at least one trunk.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" id="US-6501966-B1-CLM-00025" class="claim">
      <div class="claim-text">25. The apparatus according to <claim-ref idref="US-6501966-B1-CLM-00024">claim 24</claim-ref> wherein the at least one trunk is a digital trunk.</div>
    </div>
    </div> <div class="claim"> <div num="26" id="US-6501966-B1-CLM-00026" class="claim">
      <div class="claim-text">26. A voice activated dialing system for a wireless communication user, the system comprising:</div>
      <div class="claim-text">at least one wireless telecommunication switch; </div>
      <div class="claim-text">an interface with the at least one wireless telecommunication switch; </div>
      <div class="claim-text">a voice recognizer capable of recognizing commands and characters received through the interface from the wireless communication user; and </div>
      <div class="claim-text">a controller, coupled to the voice recognizer, arranged to determine whether a speech input from the wireless communication user is a call command, if the command is a first call command type, collect digits representing a telephone number to be dialed spoken by the user, if the command is a second call command type, determine whether a previously stored telephone number is associated with a reference code received from the wireless communication user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" id="US-6501966-B1-CLM-00027" class="claim">
      <div class="claim-text">27. The system according to <claim-ref idref="US-6501966-B1-CLM-00026">claim 26</claim-ref>, wherein the reference code is a name.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" id="US-6501966-B1-CLM-00028" class="claim">
      <div class="claim-text">28. The system according to <claim-ref idref="US-6501966-B1-CLM-00026">claim 26</claim-ref> wherein the interface communicates with the at least one wireless telecommunication switch using at least one trunk.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" id="US-6501966-B1-CLM-00029" class="claim">
      <div class="claim-text">29. The system according to <claim-ref idref="US-6501966-B1-CLM-00026">claim 26</claim-ref> wherein the voice recognizer and the controller form a speech recognition node that is communicatively coupleable to the at least one wireless telecommunication switch as an external peripheral.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" id="US-6501966-B1-CLM-00030" class="claim">
      <div class="claim-text">30. The system according to <claim-ref idref="US-6501966-B1-CLM-00026">claim 26</claim-ref> wherein the voice recognizer and the controller form a speech recognition node that acts like a shared resource that can be accessed by more than one telecommunication switch.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES53689420" lang="EN" load-source="patent-office" class="description">
    <heading>CROSS REFERENCE TO RELATED APPLICATION</heading> <p>This application is a continuation of application Ser. No. 08/914,440, filed Aug. 19, 1997, now U.S. Pat. No. 6,157,848, which is a continuation of application Se. No. 08/216,009 filed Mar. 22, 1994 now U.S. Pat. No. 5,659,597, which is a continuation of application Ser. No. 07,867,873, filed Apr. 13, 1992, now U.S. Pat. No. 5,297,183.</p>
    <heading>TECHNICAL FIELD</heading> <p>This invention is related to telecommunications systems, and more particularly to an electronic digital signal processor-controlled telecommunications system for the recognition of spoken commands and for the directing of telephone calls based on spoken commands.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>It is well-known that many of the safety hazards of cellular telephone use could be alleviated by utilizing automatic speech recognition. While telephone-based speech recognition systems are known, cellular voice dialing over a mobile telephone exchange (“MTX”) presents significant challenges for two basic reasons. First, the recognition technology must accommodate a tremendous range of both remotely-mounted and hand-held microphone types. Second, the signal may be band-limited and degraded in transmission to the MTX where the recognition system will be located. Voice-controlled dialers of the prior art, such as taught in U.S. Pat. No. 4,853,953 to Fujisaki, have not been successfully implemented in the cellular environment.</p>
    <p>There is therefore a need for voice recognition systems for use in the cellular, satelite and and personal communications network environments that overcome these and other problems of the prior art and that facilitate the use of voice-dialing and other safety and convenience features.</p>
    <heading>BRIEF SUMMARY OF THE INVENTION</heading> <p>It is therefore an object of the present invention to describe an implementation of a speech recognition system in a cellular or personal communications network environment.</p>
    <p>It is a further object of the invention to describe a speech recognition system for use at a mobile telephone exchange (MTX) of a cellular or personal communications network. The placement of the speech recognition system at the MTX significantly reduces cost and increases reliability by enabling the switch vendor to install and maintain the system in conjunction with the cellular switch.</p>
    <p>It is another object of the invention to describe a cellular voice dialing system for use in or in conjunction with an MTX of a cellular network.</p>
    <p>It is still another object of the invention to use voice recognition techniques to secure access to a cellular or personal communications network.</p>
    <p>Another object of the invention is to provide for combined use of speaker-dependent and speaker-independent voice recognition and speaker verification techniques in an MTX of a cellular or personal communications telephone network.</p>
    <p>These and other objects of the invention are provided in an advanced system for the recognizing of spoken commands over the cellular telephone or any personal communications (i.e., any non-wireline) network. In the cellular application, for example, a Speech Recognition System interconnects either internally with or as an external peripheral to a cellular telecommunications MTX switch. The Speech Recognition System includes an administrative subsystem, a call processing subsystem, a speaker-dependent recognition subsystem, a speaker-independent recognition subsystem, and a data storage subsystem. The Speech Recognition System also allows for increased efficiency in the cellular telephone network by integrating with the switch or switches as a shared resource. The administrative subsystem of the Speech Recognition System is used to keep statistical logs of pertinent call information. Pre-recorded instructional messages are stored in the memory of the call processing subsystem for instructing a user on his or her progress in using the system. The speaker-independent recognition subsystem allows the user to interact with the system employing non-user specific functions. User specific functions are controlled with the speaker-dependent recognition subsystem. User specific attributes collected by the recognition subsystems are stored in the data storage subsystem.</p>
    <p>The foregoing has outlined some of the more pertinent objects of the present invention. These objects should be construed to be merely illustrative of some of the more prominent features and applications of the invention. Many other beneficial results can be attained by applying the disclosed invention in a different manner or modifying the invention as will be described. Accordingly, other objects and a fuller understanding of the invention may be had by referring to the following Detailed Description of the preferred embodiment.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>For a more complete understanding of the present invention and the advantages thereof, reference should be made to the following Detailed Description taken in connection with the accompanying drawings in which:</p>
    <p>FIG. 1 is a block diagram of a cellular telephone network incorporating an external switch-based Speech Recognition System according to the present invention;</p>
    <p>FIG. 2 is a block diagram of a cellular telephone network incorporating an internal switch-based Speech Recognition System;</p>
    <p>FIG. 3 is an upper level block diagram of the Speech Recognition System and data storage subsystem of FIG. 1;</p>
    <p>FIG. 4 is a detailed component diagram of the speech recognizer board of the Speech Recognition System of FIGS. 2 and 3;</p>
    <p>FIG. 5 is a flowchart showing a Control routine used in the Speech Recognition System;</p>
    <p>FIG. 6 is a flowchart of the Dial routine of the invention used by the subscriber to voice dial a telephone number that has been previously-stored by the subscriber;</p>
    <p>FIG. 7 is a flowchart of the Call routine used by the subscriber to voice dial a speaker-independent telephone number;</p>
    <p>FIG. 8 is a flowchart of the Directory Dialing routine used by the subscriber to recall a previously-stored number using a speaker-dependent directory name;</p>
    <p>FIG. 9 is a flowchart of a Store routine used to store subscriber-specific destination number information;</p>
    <p>FIG. 10 is a flowchart of a Memory routine used to store speed-dial numbers associated with specific memory locations; and</p>
    <p>FIG. 11 is a flowchart of a Directory Storage routine used to store speaker-dependent directory names and associated telephone numbers for use by the subscriber to speed-dial destination numbers based on the associated directory names.</p>
    <p>Similar reference characters refer to similar parts or steps throughout the several drawings.</p>
    <heading>DETAILED DESCRIPTION</heading> <p>FIG. 1 is a block diagram of a cellular telephone network incorporating an external switch-based Speech Recognition System according to the present invention. Although the following description is specifically related to use of the Speech Recognition System at or in conjunction with an MTX of a cellular network, it should be appreciated that the System also interconnects either internally with or as an external peripheral to a personal communications network. Indeed, the principles of the invention are applicable to any cellular-like network application, i.e., where a non-wireline communications network is employed for mobile, satelite, portable or personal communications. The Speech Recognition System can also be used as a shared resource through integration with a plurality of such non-wireline communications networks.</p>
    <p>Referring now to FIG. 1, an exemplary telephone network is a cellular network <b>10</b> having a mobile telephone exchange (MTX) switch <b>12</b> connected to a transceiver and an antenna <b>14</b>. The transceiver is located in each cell of the cellular network and communicates with the MTX to effect transmission and reception of signals to and from the mobile telephone located in vehicle <b>15</b>. The transceiver is typically connected to the MTX via a leased or dedicated network line <b>11</b>. The MTX <b>12</b> is typically connected to the land-based destinations via telephone network <b>16</b>.</p>
    <p>A cellular mobile telecommunications system connects mobile telecommunications customers, each having a mobile unit, to land-based customers served by a telephone network. Incoming and outgoing calls are routed through a mobile telecommunications switching office connected to a group of cell sites that communicate with mobile units. The mobile telecommunications switching office includes a mobile telephone switching exchange (MTX) for routing the calls between the mobile units and the telephone network. In a typically mobile cellular communications system, there are usually many cells per MTX and several MTX's per system. As used herein, “mobile telecommunications system” refers to cellular, satelite and personal communications network environments.</p>
    <p>Each cellular telephone is uniquely identified by two numbers: a serial number (“ESN”) encoded in the phone by its manufacturer, and a mobile identification number (“MIN” ), which is the cellular telephone number programmed in by the cellular service provider. The service provider operates the MTX <b>12</b> and keeps a database of all MIN's (and their associated ESN's). Each time a call is placed by the cellular telephone, the service provider verifies whether the MIN and the associated ESN are authorized. If the MIN and ESN of a cellular phone are not recognized (and the area code or NPA of the MIN indicates that the phone number is outside of the provider's service area), the provider normally allows the call to proceed at least one time. If billing authorization cannot later be verified, however, the MIN and serial number are then placed on an exception list. Subsequent attempts to use the MIN will then be rejected.</p>
    <p>According to one embodiment of the invention as shown in FIG. 1, a Speech Recognition System <b>20</b> is connected as an external peripheral to the MTX through a set of preferably digital trunk lines. Set <b>22</b> is used for incoming signals and set <b>24</b> is used for outgoing signals. Other types of signaling, such as CEPT E<b>1</b> or analog, may also be used besides T<b>1</b>. The Speech Recognition System <b>20</b> is connected to a dedicated data storage subsystem <b>26</b> through a data network <b>28</b>. The data storage subsystem is used to store recognition data derived from the subscribers to the voice dialing service as will be described. The Speech Recognition System <b>20</b> may be integrated with one or more switches (whether or not cellular) for use as a shared resource via incoming and outgoing trunk sets <b>30</b> and <b>32</b>.</p>
    <p>Referring now to FIG. 2, a block diagram shows the cellular telephone network <b>10</b>′ with the Speech Recognition System <b>20</b> interconnected internally to the MTX. This is the preferred embodiment of the invention. The hierarchical architecture of the cellular switch includes the central processing unit <b>33</b>, memory <b>34</b>, data storage disk <b>35</b>, cellular interface <b>36</b>, central office trunk interface <b>37</b> and a backplane or switching matrix <b>38</b>.</p>
    <p>The Speech Recognition System <b>20</b> includes a number of functional subsystems: an administrative subsystem <b>21</b>, a call processing subsystem <b>23</b>, a speaker-dependent recognition subsystem <b>25</b>, a speaker-independent recognition subsystem <b>27</b>, and the data storage subsystem <b>29</b> (which corresponds to the storage system <b>26</b> of FIG. <b>1</b>). The administrative subsystem <b>21</b> of the Speech Recognition System is used to keep statistical logs of pertinent call information. Pre-recorded instructional messages are stored in the memory of the call processing subsystem <b>23</b> for instructing a user on his or her progress in using the system. The speaker-independent recognition subsystem <b>27</b> allows the user to interact with the system employing non-user specific functions. User specific functions are controlled with the speaker-dependent recognition subsystem <b>25</b>. User specific attributes collected by the recognition subsystems are stored in the data storage subsystem <b>29</b>.</p>
    <p>FIG. 3 is an upper level block diagram of the Speech Recognition System of FIG. <b>1</b>. The hierarchical architecture of the System <b>20</b> comprises a control central processing unit <b>40</b>, a speech recognizer board <b>41</b>, a video drive circuit board <b>42</b>, a disk drive controller board <b>43</b> with associated hard disk drive, telephone interface circuit boards <b>44</b>, and a local area network (“LAN”) interface board <b>45</b>. A local area network <b>46</b> connects these components of the System to the data storage subsystem <b>29</b>, which comprises a LAN interface board <b>47</b>, a CPU control board <b>48</b> and a mass storage hard drive device <b>49</b>. As also seen in FIG. 3, a pulse code modulation (“PCM”) highway connects the telephone interface boards <b>44</b> to the speech recognition board <b>41</b>. The MTX is also connected to the System <b>20</b> through the interface boards <b>44</b>.</p>
    <p>The CPU <b>40</b> and associated control programs function as the system administrative subsystem <b>21</b> of FIG. <b>2</b>. The recognizer board <b>41</b> acts as the recognition call processing subsystem <b>23</b> and the recognition subsystems <b>25</b> and <b>27</b>. Command and control functions are communicated to the recognizer board <b>41</b> from the system administrative processor <b>40</b> to the recognition call processing subsystem through a system bus. Responses received by the administrative processor from the recognition subsystem indicate primary and secondary recognition responses, error codes and command acknowledgements.</p>
    <p>Referring now to FIG. 4, a more detailed schematic diagram is shown of the recognizer board <b>41</b> of FIG. <b>3</b> and modules <b>25</b> and <b>27</b> of FIG. <b>2</b>. The recognizer includes a control digital signal processor (“DSP”) <b>50</b> having an associated memory <b>51</b> for supporting control programs and data. The control DSP <b>50</b> in this embodiment of the invention controls a plurality of speech recognition digital signal processors <b>52</b> <i>a </i>. . . <b>52</b> <i>d </i>via a control bus <b>53</b>. The control DSP <b>50</b> also connects to an interface processor <b>54</b> via a host port interface <b>55</b>. Interface processor <b>54</b> has its own processor memory <b>56</b>. A buffer <b>57</b> interconnects the interface processor to a system bus interface circuit <b>58</b> that interconnects the recognizer board to the system bus.</p>
    <p>The PCM highway of FIG. 3 or backplane of FIG. 2 is connected to a PCM highway interface circuit <b>59</b> that supplies speech sample information to the control DSP <b>50</b> and memory <b>51</b> via address and data bases <b>60</b> and <b>61</b>. Each of the speech recognition DSP's <b>52</b> <i>a </i>. . . <b>52</b> <i>d </i>has an associated memory <b>62</b> <i>a </i>. . . <b>62</b> <i>d </i>and storage buffer <b>63</b> <i>a </i>. . . <b>63</b> <i>d</i>. Buffered address and data buses <b>64</b> and <b>65</b> interconnect to the address and data buses <b>60</b> and <b>61</b> through the buffers <b>66</b>.</p>
    <p>The interface processor <b>64</b> converts batch system commands or command blocks received through the system bus interface <b>58</b> into singular commands for the control DSP <b>50</b>. Similarly, singular responses from the control DSP <b>50</b> are buffered by the interface processor <b>54</b> and are sent to the administrative processor (of FIGS. 2 and 3) in code blocks to increase overall system efficiency.</p>
    <p>All telephone channel signaling and PCM highway sample transfer is handled by the control DSP <b>50</b> through the PCM highway interface <b>59</b>. The control DSP <b>50</b> is also used to send samples and commands to the four speech recognition DSP's <b>52</b> <i>a </i>. . . <b>52</b> <i>d</i>. Additionally, the DSP's <b>52</b> can function to stop outgoing messages based on detection of certain incoming speech energy.</p>
    <p>The system data flow is such that recognition commands and responses are sent to and from the administrative processor and the speech recognition DSP's <b>52</b> through the control DSP <b>50</b>, the interface processor <b>54</b>, and the system bus interface <b>58</b>. Speech samples are received by the speech recognition DSP's <b>52</b> through the PCM highway interface <b>59</b> and the control DSP <b>50</b>.</p>
    <p>The present invention facilitates the implementation of voice-dialing in a cellular telephone or other personal communications network environment. When a user “subscribes” to the service (e.g., with the MTX service provider), it is desirable that certain speech data be collected from the subscriber for security purposes. Thus, upon subscription, the user normally will be asked to provide his or her native language (e.g., English, Spanish, French, etc.), a personal identification number, and personal information related specifically to the subscriber such as a social security number or date of birth. This latter information may be used in an automated query process as will be described to prevent fraudulent use of the cellular or personal telephone network. Once the user information is activated in the system, the user may place or receive telephone calls. Initially, the user will be required to enter speed-dial numbers and their associated directory names.</p>
    <p>Referring now to FIG. 5, a functional flowchart is provided describing the basic control functions of the Speech Recognition System according to the present-invention. The routine begins at step <b>102</b> when the user dials digits from the cellular telephone. At step <b>104</b>, a test is performed to determine if a Speech Recognition System access code has been dialed. If not, the cellular switch processes the call based on the number dialed at step <b>106</b> and the routine ends. If the result of the test at step <b>104</b> is positive, the routine continues at step <b>108</b> during which the switch makes an audio path connection between the user and the Speech Recognition System. At step <b>110</b>, the switch sends the user's mobile identification number (“MIN”) to the Speech Recognition System. As noted above, the MIN is a unique number associated with a given cellular telephone that is available to the switch each time a telephone call is placed.</p>
    <p>According to the invention, each user who subscribes to the service will have prerecorded a list of destination numbers. At step <b>110</b>, these speed-dial numbers, along with speaker-dependent templates and user language type data, are retrieved from the data storage subsystem. As noted above, the data storage subsystem stores such data at predetermined locations that are preferably accessed by the MIN. The routine then continues at step <b>112</b> with the Speech Recognition System prompting the user that it is “Ready For Command” or the like. The command is made in the language as determined by the user language type data retrieved at step <b>110</b>. At step <b>114</b>, the Speech Recognition Systems engages the speaker-independent recognition subsystem to obtain the user response. Depending on the response, one of several different subroutines follow.</p>
    <p>If the user states and the system recognizes a “Dial” command, control is passed to the Dial Routine of FIG. <b>6</b>. In particular, a test is made at step <b>116</b> to determine if the Dial command is recognized. If so, control is transferred to the routine of FIG. <b>6</b>. If the response to the test at step <b>116</b> is negative, a test is made at step <b>118</b> to determine if a “Call” command has been spoken and recognized. If the system recognizes a “Call” Command, control is passed to the Call Routine of FIG. <b>7</b>. If the response to the test at step <b>118</b> is negative, a test is made at step <b>120</b> to determine if a “Directory” command has been spoken and recognized. If the system recognizes a “Directory” Command, control is passed to the Directory Dialing Routine of FIG. <b>8</b>.</p>
    <p>If the result of the test at step <b>120</b> is negative, a test is made at step <b>122</b> to determine if the user has spoken a “Quit” command. If so, the routine terminates. If the result of the test at step <b>122</b> is negative, the Speech Recognition System responds with a error message in step <b>124</b>. A test is then performed at step <b>126</b> to determine if a predetermined maximum error count has been reached. If not, control is transferred back to step <b>114</b>. If the predetermined maximum error count has been reached, the call and the MIN is transferred to an operator at step <b>128</b> and the routine ends.</p>
    <p>Referring now to FIG. 6, the Dial Routine is described in detail. At step <b>130</b>, the Speech Recognition System prompts the user with a message, such as “Phone Number Please,” and applies the speaker-independent recognizer to collect the digits. A test is performed at step <b>132</b> to determine whether a digit has been collected. If not, a test is made at step <b>134</b> to determine if a predetermined timeout has elapsed. A negative response to the timeout step returns control back to step <b>132</b>. If the outcome of the test at step <b>134</b> is positive, the routine performs a test at step <b>136</b> to determine if at least the first digit of the phone number to be called has been entered. If so, another test is performed at step <b>138</b> to determine if a maximum error count has been reached. If the outcome of the test at step <b>138</b> is negative, the Speech Recognition System prompts the user to “please enter next digit” at step <b>140</b> and control returns to step <b>132</b>.</p>
    <p>If, however, the outcome of the test at step <b>136</b> is negative, the routine tests to determine whether a maximum error count has been reached at step <b>142</b>. If not, control returns to step <b>130</b> to request the user to enter the phone number. If the outcome of the test at either step <b>138</b> or <b>142</b> is positive, the call (with the MIN) is transferred to an operator at step <b>144</b> and the routine ends.</p>
    <p>If the outcome of the test at step <b>132</b> is positive, the recognizer preferably responds with a short beep or other audible indication at step <b>146</b>. A test is then made at step <b>148</b> to determine if the digit collected is the last digit expected in the string. If not, the digit is saved in a string buffer at step <b>149</b> and the routine returns to step <b>132</b> to collect another digit. If, however, the outcome of step <b>148</b> is positive, all digits have been collected and the speaker-independent recognition subsystem is engaged at step <b>150</b>.</p>
    <p>At step <b>152</b>, the subsystem attempts to verify the called number. If the verification command is not recognized, the Speech Recognition System responds at step <b>154</b> with a message such as “Error, Please repeat,” and control returns back to step <b>152</b>. If the outcome of the test at step <b>152</b> is positive, the telephone number is repeated to the user at step <b>156</b> and the speaker-independent recognition subsystem is engaged.</p>
    <p>A test is then made at step <b>158</b> to determine whether the user (by spoken command) desires to “Store” the number. If yes, the control is transferred to the Store routine of FIG. <b>9</b>. If the outcome of the test at step <b>158</b> is negative, a test <b>162</b> is made to determine whether the user has spoken (and the recognizer has recognized) a “Send” command. If not, the Speech Recognition System again plays an error message at step <b>164</b> and control is returned to step <b>158</b>. A positive response to the “Send” test made at step <b>162</b> transfers the MIN and the string dialed to the switch for outdialing. Such transfer occurs at step <b>166</b>. At step <b>168</b>, the switch dials the telephone number and connects the user to the dialed number.</p>
    <p>The Call routine is shown in detail in FIG. <b>7</b>. The routine begins at step <b>170</b> during which the Speech Recognition System responds to the user's “Call” command with a message “Calling.” At step <b>172</b>, the speaker independent recognition subsystem is engaged to obtain the user's response. A test is then made at step <b>174</b> to determine if the user speaks a “Memory” command, indicating that the number to be called is to be stored and made available for speed-dialing once a preferably two digit memory location number is subsequently received. If the outcome of the test at step <b>174</b> is positive, the Speech Recognition System queries the user “Which memory” and engages the recognition subsystem at step <b>176</b>. At step <b>178</b>, a test is made to determine if a two digit memory location has been identified by the user. If a two digit memory location has not been identified, a timeout test is performed at step <b>180</b>. If timeout occurs, the Speech Recognition System prompts the user to “Please enter next digit” at step <b>182</b> and control is returned to step <b>178</b>. A negative outcome of the timeout test also returns control back to step <b>178</b>.</p>
    <p>A positive outcome of the test at step <b>178</b> indicates that the two digit memory code has been received. The routine then recalls the previously-stored telephone number associated with the memory code at step <b>184</b>. The Speech Recognition System then notifies issues a “Calling” message to the user at step <b>186</b>.</p>
    <p>A user may also retrieve the stored telephone number by speaking one of the speaker-independent key words. Thus, if the outcome of the test at step <b>174</b> is negative, the routine continues at step <b>187</b> with the user speaking a valid key word associated with one or more previously-stored telephone numbers. Without limitation, such key words include HOME, OFFICE, TIME, SECRETARY, FRIEND, WORK and INFORMATION. A test is then made at step <b>188</b> to determine if the work spoken is a valid key word. If not, the system responds with an error message at step <b>190</b> and asks the user to speak the word again at step <b>187</b>. A positive outcome to the test at step <b>188</b> transfers control to step <b>186</b>.</p>
    <p>At step <b>192</b>, the speaker-independent subsystem is again engaged to obtain a user command. A test is made at step <b>194</b> to determine whether the user desires to “Verify” the number retrieved. If a “Verify” command is spoken and recognized, the stored number associated with the key word is repeated to the user and the recognizer is engaged at step <b>196</b>. A test is then made at step <b>198</b> to determine whether the user desires to “Clear” the number retrieved and start again. If so, the Speech Recognition System responds with a “Ready” message at step <b>200</b> and control returns to step <b>187</b>.</p>
    <p>If, however, the outcome of the test at either step <b>194</b> or step <b>198</b> is negative, a test is made at step <b>202</b> to determine if a “Send” command has been spoken and recognized. If not, the system responds with an error message at step <b>204</b> and returns to step <b>192</b>. If the user speaks the “Send” message, the Speech Recognition System responds at step <b>206</b> with a “Dialing” message. At step <b>208</b>, the System transfers the MIN and the telephone number to be dialed to the switch for outdialing. The switch dials the telephone number and connects the user to the dialed number at step <b>210</b>.</p>
    <p>Referring now to FIG. 8, a flowchart is shown of the Directory Dialing routine. This routine is called when the user desires to recall and dial some previously-stored telephone numbers using a previously-stored speaker-dependent name. In response to the “Directory” command from the user, the routine plays a message at step <b>212</b> to request the name in the directory. Step <b>212</b> also engages the speaker-dependent recognition subsystem. A test is then made at step <b>214</b> to determine if the name has been collected from the speaker. If no response is obtained, a timeout test is performed at step <b>216</b>. Failure of the speaker to respond before the end of the timeout causes the issuance of an error message at step <b>218</b> and the routine returns to step <b>214</b>. If the timeout occurs without the speaker's response, control is transferred back to step <b>212</b>.</p>
    <p>A positive outcome of the test at step <b>214</b> means that the directory name spoken by the user has been recognized. The routine then continues at step <b>220</b> and recalls from the data storage subsystem a number associated with such name. At step <b>222</b>, the stored number is played to the user and the Speech Recognition System issues a “Correct” prompt. A test is then made at step <b>224</b> to determine if the number is correct. If not, control is returned back to step <b>212</b>. If the outcome of the test at step <b>224</b> is positive, then the Speech Recognition System responds with a “Dialing” message at step <b>226</b>. At step <b>228</b>, the System transfers the MIN and the telephone number to be dialed to the switch for outdialing. The switch dials the telephone number and connects the user to the dialed number at step <b>230</b>.</p>
    <p>Referring now to the Store routine FIG. 9, a flowchart is shown of a routine used by the subscriber to store telephone numbers for the two digit memory codes, keywords, and directory names to be later dialed. The routine begins in response to receipt of a speaker-independent “Store” command spoken by the user to update the speed-dial list whenever necessary. At step <b>232</b>, the routine responds to the command with a “Storing” message and engages the speaker-independent recognition subsystem. A test is then made at step <b>234</b> to determine whether the user desires to store two digit memory codes. If so, control is transferred to the Memory routine of FIG. <b>10</b>. If the outcome of the test at step <b>234</b> is negative, a test is made at step <b>236</b> to determine whether the user desires to store a Directory name or a number associated with a Directory name. If so, control is transferred to the Directory Storage routine of FIG. <b>11</b>. If the outcome of the test at step <b>236</b> is negative, then the system will expect to receive a key word for association with the number to be stored at step <b>238</b>. A test is thus made at step <b>240</b> to determine whether the subscriber has spoken a valid key word. If not, the system responds with an error message at step <b>242</b> and control is returned to step <b>234</b>. If the outcome of the test at step <b>240</b> is positive, the Speech Recognition System makes an inquiry “Storing (key word), correct” and engages the speaker-independent recognition subsystem at step <b>244</b>. A test is then made at step <b>246</b> to determine if the user selection is correct. If not, the Speech Recognition System issues a “Location, please” prompt at step <b>248</b> and returns to step <b>240</b>. A positive outcome of the test at step <b>246</b> causes the system to issue a “Storing” prompt while a number associated with the keyword is stored in the data storage subsystem in step <b>249</b>. Control is then returned to step <b>112</b> in FIG. <b>5</b>.</p>
    <p>The Memory routine is shown in FIG. <b>10</b>. The routine begins at step <b>250</b> by inquiring “Which memory” and engages the speaker-independent recognition subsystem. At step <b>252</b>, a test is made to determine if a two digit memory location number has been collected from the user. A timeout test is then performed at step <b>254</b>. If timeout occurs, the Speech Recognition System prompts the user to “Please enter next digit” at step <b>256</b> and control is returned to step <b>252</b>. A negative outcome of the timeout test also returns control back to step <b>252</b>.</p>
    <p>A positive outcome of the test at step <b>252</b> indicates that the two digit memory code has been collected from the subscriber. At step <b>258</b>, the Speech Recognition System responds with a message “Storing memory (2 digits), correct” and engages the speaker-independent recognition subsystem. A test is then made at step <b>260</b> to confirm that the subscriber is storing the telephone number in the appropriate location. If not, the Speech Recognition System issues a “Location, please” prompt at step <b>262</b> and returns to step <b>252</b>. A positive outcome of the test at step <b>260</b> then causes the routine to test at step <b>264</b> whether the memory is already filled up with stored codes. If not, the system issues a “Storing” message and stores the number in the data storage subsystem at step <b>265</b>. If, however, the response to the test at step <b>264</b> is affirmative, the Speech Recognition System issues a “Memory full, erase?” message and engages the speaker-independent recognition subsystem at step <b>266</b>. A test is then performed at step <b>268</b> to determine whether the speaker wishes to erase a memory location. If not, control returns to step <b>112</b> in FIG. <b>5</b>.</p>
    <p>If the subscriber desires to erase a given memory location code, the system issues a “Confirm erase” message at step <b>270</b> and engages the speaker-independent recognizer. An erase test is then performed again at step <b>272</b> to confirm that the subscriber wishes to erase the specified memory location. A negative outcome of the test at step <b>272</b> returns control to step <b>112</b> in FIG. 5. A positive outcome of the erase test at step <b>272</b> causes the system to issue an acknowledgment at step <b>274</b>. Control then returns to step <b>112</b> in FIG. <b>5</b>.</p>
    <p>Referring now to FIG. 11, a flowchart is shown of the Directory Storage routine. The routine begins at step <b>276</b> in response to a positive response to the Directory inquiry performed in step <b>236</b> in FIG. 9 (i.e., receipt of the Directory command). Step <b>276</b> issues a prompt to the subscriber to determine if a “Number in Memory” has been previously associated with a Directory name. A test is then performed at step <b>278</b> to determine if the Number in memory has been previously stored. If not, the Speech Recognition System responds by issuing an “Enroll” message and engages the speaker-independent recognition subsystem at step <b>280</b>. A test is then made at step <b>282</b> to determine whether the subscriber wishes to enroll. If not, the routine terminates and returns to step <b>112</b> in FIG. <b>5</b>.</p>
    <p>If the outcome of the test at step <b>278</b> is affirmative, the Speech Recognition System issues a message “Re-enroll” and engages the speaker-independent recognition subsystem at step <b>284</b>. A test is then made at step <b>286</b> to determine whether the subscriber wishes to re-enroll the directory name. If yes, or if the outcome of the test at step <b>282</b> is positive, the routine continues at step <b>288</b> and issues a “Name Please” message and engages the speaker-dependent recognition subsystem. The user then speaks the name a predetermined number (e.g., three (3) times) at step <b>290</b> to program the speaker-dependent subsystem. The new directory name and the associated telephone number are then stored in the data storage subsystem in step <b>292</b>. Control is then returned to step <b>112</b> in FIG. <b>5</b>.</p>
    <p>If the outcome of the test at step <b>286</b> is negative, the Speech Recognition System issues a message “Erase” and engages the speaker-independent recognition subsystem at step <b>296</b>. A test is then made at step <b>298</b> to determine whether the subscriber wishes to erase the directory number. If so, the associated number is erased at step <b>300</b>. Control is then returned to step <b>112</b> in FIG. <b>5</b>.</p>
    <p>It should be appreciated that the specific names of the commands are merely exemplary and should not be taken by way of limitation. Other suitable command names are of course suitable.</p>
    <p>As noted above, each cellular telephone is uniquely identified with its MIN and ESN. In the prior art, the service provider operates the MTX <b>12</b> and keeps a database of all MIN's (and their associated ESN's). Each time a call is placed by the cellular telephone, the service provider verifies whether the MIN and the associated ESN are authorized. If the MIN and ESN of a cellular phone are not recognized in the switch database, the provider normally allows the call to proceed at least one time. If billing authorization cannot later be verified, however, the MIN and serial number are then placed on an exception list. Subsequent attempts to use the MIN will then be rejected.</p>
    <p>Such fraudulent use of the cellular network is ameliorated by the present invention. According to another feature of the invention, the Speech Recognition System also includes a positive identification function that enables the system under certain circumstances to test whether the user associated with a received MIN (whether in or out of the service area) is an authorized subscriber to the service. For example, after a call is voice-dialed and the Send command is spoken, the system might prompt the caller to answer one or more personal questions. Thus, the caller might be requested to speak the social security and/or account number of the subscriber (purportedly associated with the MIN and ESN). Alternatively, the caller can be prompted to enter such identifying information manually through the telephone keypad. Of course, the nature and scope of the personal information requested by the system depends entirely on the system operator and the degree of security sought by the subscriber and operator.</p>
    <p>Such a system could also be used to prevent a local call being placed from a stolen vehicle, for example, i.e., even if the MIN was recognized in the service provider's database. It could also be used to limit access to the voice-dialing function from the subscriber's phone to certain persons. Thus the subscriber may limit his or her children or others from using the phone without the subscriber's knowledge. If the user cannot provide proper answers to such questions, the system rejects the SEND command and the call is terminated. Correct entry of the requested information enables the caller to continue his or her access to the service.</p>
    <p>Alternatively the identification function may be implemented in conjunction with a speaker verification function in which the user's identity must first be verified with some spoken predetermined personal identification code. If the verification function is not “convinced” that the person is who he or she claims to be, the identification function is then executed to ask the follow-up questions. One such system is described in copending application Ser. No. 07/523,486, filed May 15, 1990, to Hunt et al, titled “Simultaneous Speaker-Independent Voice Recognition And Verification Over A Telephone Network,” assigned to the assignee of the present invention.</p>
    <p>The present invention has numerous advantages over the prior art. The system combines the use of both speaker-dependent and speaker-independent speech recognition in an mobile or portable telephone communications network environment. Multiple language prompts are spoken from and available simultaneously on multiple ports from a single automated telecommunications-based system. The language selected is based on the language spoken by the user. The system advantageously stores user specific speaker-dependent and speaker-independent speech information with particular user-based addresses.</p>
    <p>The invention successfully implements speech recognition in the cellular telephone or personal communications network. Non-wireline networks provide a special challenge to both the recognition algorithm developers as well as the applications developers. The recognition algorithm in conjunction with the system application is insensitive to the radio fading, speech clipping, and speech compression conditions that occur in a non-wireline network. In addition, the recognition algorithm accommodates conditions found in the standard switched network. The invention provides a means of accurately recognizing speech that has limited distortion due to clipping or fading and provides a means of reprompting the user for input when the speech has become too distorted for accurate recognition.</p>
    <p>Previously, only the best examples of spoken words have been used as tokens for developing speech vocabularies. By collecting speech that has been compressed or that although distorted by radio fading or clipping is still intelligible and by adding this collected speech to the speech training database, the vocabulary based on such data becomes more robust and less sensitive to these conditions. Adding the distorted but intelligible data to the training database of excellent example words allows for a more diverse statistical representation of each vocabulary word. Words that might have been previously rejected, because part of the word was clipped can now be recognized if enough intelligible information is available. If the statistical representation of the word indicates that not enough information is available for accurate recognition, the recognition system will reject the word and reprompt the user for input.</p>
    <p>The invention also enables real-time vocabulary uploading. Previously, speech recognition vocabularies were stored in memory and were not updated or totally changed during the operation of an application. The present invention solves the problem of allowing speech recognition vocabularies to be loaded into a recognition system while an application is in operation. This capability allows for less high speed memory to be used in a system, because an entire set of vocabularies is not required to be resident in memory at one time. This capability also allows for efficient memory management when multiple languages are used, because only the language required by the system user need be resident in memory at any one time. Previously, all possible languages required by users would have been stored in memory simultaneously.</p>
    <p>Both continuous and discrete recognition techniques are used in the Speech Recognition System of the present invention.</p>
    <p>It should be appreciated by those skilled in the art that the specific embodiments disclosed above may be readily utilized as a basis for modifying or designing other structures for carrying out the same purposes of the present invention. It should also be realized by those skilled in the art that such equivalent constructions do not depart from the spirit and scope of the invention as set forth in the appended claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3673331">US3673331</a></td><td class="patent-data-table-td patent-date-value">Jan 19, 1970</td><td class="patent-data-table-td patent-date-value">Jun 27, 1972</td><td class="patent-data-table-td ">Texas Instruments Inc</td><td class="patent-data-table-td ">Identity verification by voice signals in the frequency domain</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3928724">US3928724</a></td><td class="patent-data-table-td patent-date-value">Oct 10, 1974</td><td class="patent-data-table-td patent-date-value">Dec 23, 1975</td><td class="patent-data-table-td ">Andersen Byram Kouma Murphy Lo</td><td class="patent-data-table-td ">Voice-actuated telephone directory-assistance system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4385359">US4385359</a></td><td class="patent-data-table-td patent-date-value">Mar 11, 1981</td><td class="patent-data-table-td patent-date-value">May 24, 1983</td><td class="patent-data-table-td ">Nippon Electric Co., Ltd.</td><td class="patent-data-table-td ">Multiple-channel voice input/output system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4587670">US4587670</a></td><td class="patent-data-table-td patent-date-value">Oct 15, 1982</td><td class="patent-data-table-td patent-date-value">May 6, 1986</td><td class="patent-data-table-td ">At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Hidden Markov model speech recognition arrangement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4827500">US4827500</a></td><td class="patent-data-table-td patent-date-value">Jan 30, 1987</td><td class="patent-data-table-td patent-date-value">May 2, 1989</td><td class="patent-data-table-td ">American Telephone And Telegraph Company, At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Automatic speech recognition to select among call destinations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4922538">US4922538</a></td><td class="patent-data-table-td patent-date-value">Feb 5, 1988</td><td class="patent-data-table-td patent-date-value">May 1, 1990</td><td class="patent-data-table-td ">British Telecommunications Public Limited Company</td><td class="patent-data-table-td ">Multi-user speech recognition system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4949374">US4949374</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 28, 1989</td><td class="patent-data-table-td patent-date-value">Aug 14, 1990</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Speech recognition system with an accurate recognition function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4961212">US4961212</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 3, 1989</td><td class="patent-data-table-td patent-date-value">Oct 2, 1990</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Voice recognition system used in telephone apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5054053">US5054053</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 14, 1989</td><td class="patent-data-table-td patent-date-value">Oct 1, 1991</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Speech recognition system for telephony</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5148471">US5148471</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 20, 1989</td><td class="patent-data-table-td patent-date-value">Sep 15, 1992</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Communications device with voice recognition and movable element control interface</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5182765">US5182765</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 24, 1992</td><td class="patent-data-table-td patent-date-value">Jan 26, 1993</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Speech recognition system with an accurate recognition function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5195090">US5195090</a></td><td class="patent-data-table-td patent-date-value">Jul 9, 1991</td><td class="patent-data-table-td patent-date-value">Mar 16, 1993</td><td class="patent-data-table-td ">At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Wireless access telephone-to-telephone network interface architecture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5199062">US5199062</a></td><td class="patent-data-table-td patent-date-value">Nov 8, 1991</td><td class="patent-data-table-td patent-date-value">Mar 30, 1993</td><td class="patent-data-table-td ">Phone Base Systems Inc.</td><td class="patent-data-table-td ">Telephone communications system including a digital telephone switch, a voice response unit and a stored program sequence for controlling both the switch and the voice response unit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5222121">US5222121</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 19, 1990</td><td class="patent-data-table-td patent-date-value">Jun 22, 1993</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Voice recognition dialing unit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5283833">US5283833</a></td><td class="patent-data-table-td patent-date-value">Sep 19, 1991</td><td class="patent-data-table-td patent-date-value">Feb 1, 1994</td><td class="patent-data-table-td ">At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Method and apparatus for speech processing using morphology and rhyming</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5289530">US5289530</a></td><td class="patent-data-table-td patent-date-value">Jul 23, 1991</td><td class="patent-data-table-td patent-date-value">Feb 22, 1994</td><td class="patent-data-table-td ">Morris Reese</td><td class="patent-data-table-td ">Method and apparatus for vocally communicating to a caller at a remote telephone station synthesized speech of stored special service information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5297183">US5297183</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 13, 1992</td><td class="patent-data-table-td patent-date-value">Mar 22, 1994</td><td class="patent-data-table-td ">Vcs Industries, Inc.</td><td class="patent-data-table-td ">Speech recognition system for electronic switches in a cellular telephone or personal communication network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5301223">US5301223</a></td><td class="patent-data-table-td patent-date-value">Aug 25, 1992</td><td class="patent-data-table-td patent-date-value">Apr 5, 1994</td><td class="patent-data-table-td ">Cellular Technical Services Company, Inc.</td><td class="patent-data-table-td ">Cellular telephone system with remote programming, voice responsive registration and real time billing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5335313">US5335313</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 3, 1991</td><td class="patent-data-table-td patent-date-value">Aug 2, 1994</td><td class="patent-data-table-td ">Douglas Terry L</td><td class="patent-data-table-td ">Voice-actuated, speaker-dependent control system for hospital bed</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5365574">US5365574</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 25, 1992</td><td class="patent-data-table-td patent-date-value">Nov 15, 1994</td><td class="patent-data-table-td ">Vcs Industries, Inc.</td><td class="patent-data-table-td ">Telephone network voice recognition and verification using selectively-adjustable signal thresholds</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5371901">US5371901</a></td><td class="patent-data-table-td patent-date-value">Mar 4, 1994</td><td class="patent-data-table-td patent-date-value">Dec 6, 1994</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Remote voice control system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5390278">US5390278</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 8, 1991</td><td class="patent-data-table-td patent-date-value">Feb 14, 1995</td><td class="patent-data-table-td ">Bell Canada</td><td class="patent-data-table-td ">Phoneme based speech recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5659597">US5659597</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 22, 1994</td><td class="patent-data-table-td patent-date-value">Aug 19, 1997</td><td class="patent-data-table-td ">Voice Control Systems, Inc.</td><td class="patent-data-table-td ">Speech recognition system for electronic switches in a non-wireline communications network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6157848">US6157848</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 19, 1997</td><td class="patent-data-table-td patent-date-value">Dec 5, 2000</td><td class="patent-data-table-td ">Philips Electronics North America Corporation</td><td class="patent-data-table-td ">Speech recognition system for electronic switches in a non-wireline communications network</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="A+Multi-DSP+Implementation+of+a+Broad-Band+Adaptive+Beamformer+for+Use+in+a+Hands-Free+Mobile+Radio+Telephone"'>A Multi-DSP Implementation of a Broad-Band Adaptive Beamformer for Use in a Hands-Free Mobile Radio Telephone</a>", by Claesson et al, IEEE Transactions on Vehicular Technology, vol. 40, No. 1, Feb. 1991, pp. 194-202.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="A+New+Speaker-Independent+Voice+Recognition+Scheme+for+Voice+Dialling"'>A New Speaker-Independent Voice Recognition Scheme for Voice Dialling</a>", by Takizawa et al, IEEE 1987 p. 547-551.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="A+PABX+That+Listens+and+Talks"'>A PABX That Listens and Talks</a>", Speech Technology, Jan./Feb. 1984, pp. 75-79.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="A+speaker+independent+voice+dialing+system+for+Italian+in+the+cellular+phone+application"'>A speaker independent voice dialing system for Italian in the cellular phone application</a>", by Babini et al, CSELT Technical Reports, vol. XVIII, No. 3, Jun. 1990, pp. 201-205.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="AT%26amp%3BT%27s+Conversant+I+Voice+System"'>AT&amp;T's Conversant I Voice System</a>", by John P. Moosemiller, Speech Technologoy, Mar./Apr. 1986, pp. 88-93.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Automating+Services+with+Speech+Recognition+over+the+Public+Switched+Telephone+Network%3A+Human+Factors+Considerations"'>Automating Services with Speech Recognition over the Public Switched Telephone Network: Human Factors Considerations</a>", by Karis et al, IEEE Journal on Selected Areas in Communications, vol. 9, No. 4, May 1991, pp. 574-585.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Cellular+Packet+Communications"'>Cellular Packet Communications</a>", by Goodman, IEEE Transactions on Communications, vol. 38, No. 8, Aug. 1990, pp. 1272-1280.</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Development+of+the+Speaker-Dependent+Voice+Activated+Dialing+Equipment"'>Development of the Speaker-Dependent Voice Activated Dialing Equipment</a>", by Sato, pp. 548-554.</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Dialing+a+Phone+by+Voice"'>Dialing a Phone by Voice</a>", by Pawate et al, Machine Design, Jan. 19, 1991, pp. 95-98.</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Dialing+by+Voice"'>Dialing by Voice</a>", IEEE Spectrum, Aug. 1986, p. 22.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Environment+Adaptation+for+Speech+Recognition+in+Noise"'>Environment Adaptation for Speech Recognition in Noise</a>", by Blanchet et al, Signal Processing VI: Theories and Applications, 1992, pp. 391-394.</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Eyes+Free+Dialing+for+Cellular+Telephones"'>Eyes Free Dialing for Cellular Telephones</a>", by Bendelac et al, IEEE 1991, pp. 120-125.</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Eyes+Free+Dialing+for+Cellular+Telephones"'>Eyes Free Dialing for Cellular Telephones</a>", by Bendelac et al, pp. 234-237.</td></tr><tr><td class="patent-data-table-td ">14</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Freedom+Doesn%27t+Come+Easy"'>Freedom Doesn't Come Easy</a>", by Shandle, Electronics, Mar. 1991, pp. 45-48.</td></tr><tr><td class="patent-data-table-td ">15</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Hands-Free+Voice+Communication+in+an+Automobile+with+a+Microphone+Array"'>Hands-Free Voice Communication in an Automobile with a Microphone Array</a>", by Oh et al, IEEE 1992, pp. I-281-I-I-284.</td></tr><tr><td class="patent-data-table-td ">16</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="HMM+Modeling+for+Speaker+Independent+Voice+Dialing+in+Car+Environment"'>HMM Modeling for Speaker Independent Voice Dialing in Car Environment</a>", by Fissore et al, IEEE 1992, pp. I-249-I-252.</td></tr><tr><td class="patent-data-table-td ">17</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Interactive+Voice+Technology+Applications"'>Interactive Voice Technology Applications</a>", by Fischell et al, AT&amp;T Technical Journal, Sep./Oct. 1990, pp. 61-76.</td></tr><tr><td class="patent-data-table-td ">18</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Is+thought+dialing+next%3F"'>Is thought dialing next?</a>", Telephone Engineer &amp; Management, Apr. 1, 1991, p. 58, ISSN: 0040-263X.</td></tr><tr><td class="patent-data-table-td ">19</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Isolated+Word+Recognition+in+the+Mobile-Radio+System%3A+Experiments+and+Results"'>Isolated Word Recognition in the Mobile-Radio System: Experiments and Results</a>", by Fissore, Signal Processing V: Theories and Applications, 1990, pp. 1207-1210.</td></tr><tr><td class="patent-data-table-td ">20</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Learned+Codebook+Excited+Linear+Predictive+%28LCELP%29+Speech+Codec+for+Digital+Cellular+System"'>Learned Codebook Excited Linear Predictive (LCELP) Speech Codec for Digital Cellular System</a>", by Unno et al, NEC Res. &amp; Develop., vol. 32, No. 4, Oct. 1991, pp. 549-556.</td></tr><tr><td class="patent-data-table-td ">21</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Network+Protocols+for+the+Cellular+Packet+Switch"'>Network Protocols for the Cellular Packet Switch</a>", by Meier-Hellstern et al, EEE Transactions on Communications, vol. 42, No. 2/3/4, Feb./Mar./Apr. 1994, pp. 1235-1243.</td></tr><tr><td class="patent-data-table-td ">22</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Packet+Switching+in+Digital+Cellular+Systems"'>Packet Switching in Digital Cellular Systems</a>", by Felix, Motorola Inc, pp. 414-418.</td></tr><tr><td class="patent-data-table-td ">23</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Putting+Speech+Recognition+to+Work+in+the+Telephone+Network"'>Putting Speech Recognition to Work in the Telephone Network</a>", by Lennig, Computer, Aug. 1990, pp. 35-41.</td></tr><tr><td class="patent-data-table-td ">24</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Speech+Recognition+Services"'>Speech Recognition Services</a>" Projects to consder for voice input work at USWEST, from 1988 Presentation to USWEST.</td></tr><tr><td class="patent-data-table-td ">25</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="SPS51-A+universal+interface+for+hands-free+telephony%2C+speech+recognition+and+speech+storage+in+the+car+telephone"'>SPS51-A universal interface for hands-free telephony, speech recognition and speech storage in the car telephone</a>", by Ruhl et al, Philips Telecommunication Review, vol. 48, No. 4, Dec. 1990, pp. 1-10.</td></tr><tr><td class="patent-data-table-td ">26</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="The+5ESS+Switching+System"'>The 5ESS Switching System</a>", by Martersteck et al, AT&amp;T Technical Journal, vol. 64, No. 6, Jul., Aug. 1985, pp. 1305-1313.</td></tr><tr><td class="patent-data-table-td ">27</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="The+5ESS+Switching+System%3A+Architectural+Overview"'>The 5ESS Switching System: Architectural Overview</a>", by D.L. Carney et al, AT&amp;T Technical Journal, vol. 64, No. 6, Jul.-Aug. 1985, pp. 1339-1355.</td></tr><tr><td class="patent-data-table-td ">28</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="The+5ESS+Switching+Systems%3A+Applications+Planning"'>The 5ESS Switching Systems: Applications Planning</a>", by W.R. Byre et al, AT&amp;T Technical Journal, Jul.-Aug. 1985, pp. 1315-1336.</td></tr><tr><td class="patent-data-table-td ">29</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="The+5ESS%28R%29+Wireless+Mobile+Switching+Center"'>The 5ESS(R) Wireless Mobile Switching Center</a>", by Gauldin et al, AT&amp;T Technical Journal, Jul./Aug. 1993, pp. 38-47.</td></tr><tr><td class="patent-data-table-td ">30</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Trends+in+Cellular+and+Cordless+Communications"'>Trends in Cellular and Cordless Communications</a>", by Goodman, IEEE Communications Magazine, Jun. 1991, pp. 31-40.</td></tr><tr><td class="patent-data-table-td ">31</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Voice+Control+of+Mobile+Telephones"'>Voice Control of Mobile Telephones</a>", by Helms, Speech Tech 1986, pp. 126-130.</td></tr><tr><td class="patent-data-table-td ">32</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Voice+Recognition+in+Cellular+Mobile+Telephones"'>Voice Recognition in Cellular Mobile Telephones</a>", by Thomas B. Schalk, Speech Technology, Sep./Oct. 1986, pp. 24-28.</td></tr><tr><td class="patent-data-table-td ">33</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Wireless+Network+Directions"'>Wireless Network Directions</a>" by Ross, IEEE Communications Magazine, Feb. 1991, pp. 40-42.</td></tr><tr><td class="patent-data-table-td ">34</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="SPS51%E2%80%94A+universal+interface+for+hands-free+telephony%2C+speech+recognition+and+speech+storage+in+the+car+telephone"'>SPS51—A universal interface for hands-free telephony, speech recognition and speech storage in the car telephone</a>", by Ruhl et al, Philips Telecommunication Review, vol. 48, No. 4, Dec. 1990, pp. 1-10.</td></tr><tr><td class="patent-data-table-td ">35</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="The+5ESS%C2%AE+Wireless+Mobile+Switching+Center"'>The 5ESS® Wireless Mobile Switching Center</a>", by Gauldin et al, AT&amp;T Technical Journal, Jul./Aug. 1993, pp. 38-47.</td></tr><tr><td class="patent-data-table-td ">36</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Abstract of Acceptance of voice system hinges on "<a href='http://scholar.google.com/scholar?q="true"'>true</a>" recognition: Voice Ware offers speech recognition board, by Waurzyniak, Computer Software News vol., v4, Issue No. 10, Mar. 10, 1986.</td></tr><tr><td class="patent-data-table-td ">37</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Hands-free telephony, speech recognition and speech coding techniques implemented in the SPS51, by Armbruster et al, Philips Telecommunication Review, vol. 49, No. 1, Mar. 1991, pp. 19-27.</td></tr><tr><td class="patent-data-table-td ">38</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Voice Dial Operating Guide, Voice Command System for Cellular Telephones, By-Word Technologies, Inc. 1989, pp. 1-18.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6898568">US6898568</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 13, 2001</td><td class="patent-data-table-td patent-date-value">May 24, 2005</td><td class="patent-data-table-td ">Innomedia Pte Ltd</td><td class="patent-data-table-td ">Speaker verification utilizing compressed audio formants</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7076431">US7076431</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 9, 2004</td><td class="patent-data-table-td patent-date-value">Jul 11, 2006</td><td class="patent-data-table-td ">Parus Holdings, Inc.</td><td class="patent-data-table-td ">Robust voice browser system and voice activated device controller</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7113572">US7113572</a></td><td class="patent-data-table-td patent-date-value">Oct 3, 2001</td><td class="patent-data-table-td patent-date-value">Sep 26, 2006</td><td class="patent-data-table-td ">Cingular Wireless Ii, Llc</td><td class="patent-data-table-td ">System and method for recognition of and automatic connection using spoken address information received in voice mails and live telephone conversations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7203651">US7203651</a></td><td class="patent-data-table-td patent-date-value">Dec 7, 2001</td><td class="patent-data-table-td patent-date-value">Apr 10, 2007</td><td class="patent-data-table-td ">Art-Advanced Recognition Technologies, Ltd.</td><td class="patent-data-table-td ">Voice control system with multiple voice recognition engines</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7548610">US7548610</a></td><td class="patent-data-table-td patent-date-value">Feb 14, 2003</td><td class="patent-data-table-td patent-date-value">Jun 16, 2009</td><td class="patent-data-table-td ">Alaven, Inc.</td><td class="patent-data-table-td ">Voice-activated geographically based telephone routing system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7551944">US7551944</a></td><td class="patent-data-table-td patent-date-value">Dec 3, 2002</td><td class="patent-data-table-td patent-date-value">Jun 23, 2009</td><td class="patent-data-table-td ">Nuance Communications, Inc.</td><td class="patent-data-table-td ">Speech recognition system for electronic switches in a non-wireline communications network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7610016">US7610016</a></td><td class="patent-data-table-td patent-date-value">Feb 4, 2005</td><td class="patent-data-table-td patent-date-value">Oct 27, 2009</td><td class="patent-data-table-td ">At&amp;T Mobility Ii Llc</td><td class="patent-data-table-td ">System and method for providing an adapter module</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7735021">US7735021</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 21, 2001</td><td class="patent-data-table-td patent-date-value">Jun 8, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Shortcut system for use in a mobile electronic device and method thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8161116">US8161116</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 24, 2004</td><td class="patent-data-table-td patent-date-value">Apr 17, 2012</td><td class="patent-data-table-td ">Kirusa, Inc.</td><td class="patent-data-table-td ">Method and system for communicating a data file over a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8166297">US8166297</a></td><td class="patent-data-table-td patent-date-value">Jul 2, 2008</td><td class="patent-data-table-td patent-date-value">Apr 24, 2012</td><td class="patent-data-table-td ">Veritrix, Inc.</td><td class="patent-data-table-td ">Systems and methods for controlling access to encrypted data stored on a mobile device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8185646">US8185646</a></td><td class="patent-data-table-td patent-date-value">Oct 29, 2009</td><td class="patent-data-table-td patent-date-value">May 22, 2012</td><td class="patent-data-table-td ">Veritrix, Inc.</td><td class="patent-data-table-td ">User authentication for social networks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8285654">US8285654</a></td><td class="patent-data-table-td patent-date-value">Jun 21, 2007</td><td class="patent-data-table-td patent-date-value">Oct 9, 2012</td><td class="patent-data-table-td ">Nathan Bajrach</td><td class="patent-data-table-td ">Method and system of providing a personalized performance</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8347370">US8347370</a></td><td class="patent-data-table-td patent-date-value">Aug 18, 2011</td><td class="patent-data-table-td patent-date-value">Jan 1, 2013</td><td class="patent-data-table-td ">Veritrix, Inc.</td><td class="patent-data-table-td ">Multi-channel multi-factor authentication</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8468358">US8468358</a></td><td class="patent-data-table-td patent-date-value">Nov 9, 2010</td><td class="patent-data-table-td patent-date-value">Jun 18, 2013</td><td class="patent-data-table-td ">Veritrix, Inc.</td><td class="patent-data-table-td ">Methods for identifying the guarantor of an application</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8474014">US8474014</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 2011</td><td class="patent-data-table-td patent-date-value">Jun 25, 2013</td><td class="patent-data-table-td ">Veritrix, Inc.</td><td class="patent-data-table-td ">Methods for the secure use of one-time passwords</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8516562">US8516562</a></td><td class="patent-data-table-td patent-date-value">Aug 18, 2011</td><td class="patent-data-table-td patent-date-value">Aug 20, 2013</td><td class="patent-data-table-td ">Veritrix, Inc.</td><td class="patent-data-table-td ">Multi-channel multi-factor authentication</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8536976">US8536976</a></td><td class="patent-data-table-td patent-date-value">Jun 11, 2008</td><td class="patent-data-table-td patent-date-value">Sep 17, 2013</td><td class="patent-data-table-td ">Veritrix, Inc.</td><td class="patent-data-table-td ">Single-channel multi-factor authentication</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8555066">US8555066</a></td><td class="patent-data-table-td patent-date-value">Mar 6, 2012</td><td class="patent-data-table-td patent-date-value">Oct 8, 2013</td><td class="patent-data-table-td ">Veritrix, Inc.</td><td class="patent-data-table-td ">Systems and methods for controlling access to encrypted data stored on a mobile device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20050020250">US20050020250</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 24, 2004</td><td class="patent-data-table-td patent-date-value">Jan 27, 2005</td><td class="patent-data-table-td ">Navin Chaddha</td><td class="patent-data-table-td ">Method and system for communicating a data file over a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2006025774A1?cl=en">WO2006025774A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 26, 2005</td><td class="patent-data-table-td patent-date-value">Mar 9, 2006</td><td class="patent-data-table-td ">Klas Greger Eriksson</td><td class="patent-data-table-td ">Mobile telephone system related arrangement</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc455/defs455.htm&usg=AFQjCNFL3EGhrZhenbDalCuSOJ_Q_FR4Vw#C455S563000">455/563</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc455/defs455.htm&usg=AFQjCNFL3EGhrZhenbDalCuSOJ_Q_FR4Vw#C455S414100">455/414.1</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc379/defs379.htm&usg=AFQjCNEr2i5HiMlkBIt1vZADj0MjdHVCTw#C379S088010">379/88.01</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc379/defs379.htm&usg=AFQjCNEr2i5HiMlkBIt1vZADj0MjdHVCTw#C379S088030">379/88.03</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04W0004000000">H04W4/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04W0004180000">H04W4/18</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04M0003493000">H04M3/493</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04W0088180000">H04W88/18</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04M0003420000">H04M3/42</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04B0007185000">H04B7/185</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04M0011100000">H04M11/10</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M3/4936">H04M3/4936</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M2201/40">H04M2201/40</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M2201/405">H04M2201/405</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M11/10">H04M11/10</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M3/42204">H04M3/42204</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04B7/18567">H04B7/18567</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W4/00">H04W4/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W4/18">H04W4/18</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=LbxdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W88/18">H04W88/18</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04W4/18</span>, <span class="nested-value">H04W4/00</span>, <span class="nested-value">H04M3/493S</span>, <span class="nested-value">H04M3/42H</span>, <span class="nested-value">H04M11/10</span>, <span class="nested-value">H04B7/185M16</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jul 1, 2010</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 1, 2010</td><td class="patent-data-table-td ">SULP</td><td class="patent-data-table-td ">Surcharge for late payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">7</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 24, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">USB AG. STAMFORD BRANCH, CONNECTICUT</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:NUANCE COMMUNICATIONS, INC.;REEL/FRAME:018160/0909</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060331</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:NUANCE COMMUNICATIONS, INC.;REEL/FRAME:018160/0909</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">USB AG. STAMFORD BRANCH,CONNECTICUT</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:NUANCE COMMUNICATIONS, INC.;US-ASSIGNMENT DATABASE UPDATED:20100216;REEL/FRAME:18160/909</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:NUANCE COMMUNICATIONS, INC.;REEL/FRAME:18160/909</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 18, 2006</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060424</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 7, 2006</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 7, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">USB AG, STAMFORD BRANCH, CONNECTICUT</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:NUANCE COMMUNICATIONS, INC.;REEL/FRAME:017435/0199</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060331</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">USB AG, STAMFORD BRANCH,CONNECTICUT</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:NUANCE COMMUNICATIONS, INC.;US-ASSIGNMENT DATABASE UPDATED:20100216;REEL/FRAME:17435/199</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:NUANCE COMMUNICATIONS, INC.;US-ASSIGNMENT DATABASE UPDATED:20100309;REEL/FRAME:17435/199</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 20, 2005</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">NUANCE COMMUNICATIONS, INC., MASSACHUSETTS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">MERGER AND CHANGE OF NAME TO NUANCE COMMUNICATIONS, INC.;ASSIGNOR:SCANSOFT, INC.;REEL/FRAME:016914/0975</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20051017</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 14, 2003</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SCANSOFT, INC., MASSACHUSETTS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:KONINKLIJKE PHILIPS ELECTRONICS N.V.;REEL/FRAME:013835/0252</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20030131</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SCANSOFT, INC. 9 CENTENNIAL DRIVEPEABODY, MASSACHU</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 12, 2002</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">KONINKLIJKE PHILIPS ELECTRONICS N.V., NETHERLANDS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:PHILIPS ELECTRONICS NORTH AMERICA CORPORATION;REEL/FRAME:013471/0526</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20021104</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">KONINKLIJKE PHILIPS ELECTRONICS N.V. GROENEWOUDSEW</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:PHILIPS ELECTRONICS NORTH AMERICA CORPORATION /AR;REEL/FRAME:013471/0526</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U3yYW4GUYv2WBjarjpeDSGn3FY0rA\u0026id=LbxdBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0BWVOdbDW0ZO727WrOcN4bCTL1zQ\u0026id=LbxdBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U04D2pOR_m_f8tz6C7LfXmJNYxzTQ","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Speech_recognition_system_for_electronic.pdf?id=LbxdBAABERAJ\u0026output=pdf\u0026sig=ACfU3U3xuk_puv8QqxJws-O-SH0fk5RfKw"},"sample_url":"http://www.google.com/patents/reader?id=LbxdBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>