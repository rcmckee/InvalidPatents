<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5995903 - Method and system for assisting navigation using rendered terrain imagery - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method and system for assisting navigation using rendered terrain imagery"><meta name="DC.contributor" content="Eric L. Smith" scheme="inventor"><meta name="DC.contributor" content="Kurt Zimmerman" scheme="inventor"><meta name="DC.contributor" content="Smith; Eric L." scheme="assignee"><meta name="DC.contributor" content="Zimmerman; Kurt" scheme="assignee"><meta name="DC.date" content="1996-11-12" scheme="dateSubmitted"><meta name="DC.description" content="A digital computer system for displaying a computer generated terrain representing a 3-dimensional depiction of the real world terrain surrounding a vehicle in real-time while the vehicle is in motion. This 3-D (3-Dimensional) image is rendered in real time while the vehicle is in motion and uses Global Positioning System (GPS) or differential GPS (dGPS) data available from a GPS unit and translates that data into virtual space within an Image Generation Processing block of the digital computer system. The digital computer system generates a virtual world 3-D image representing the eye-point position of the vehicle and directional vector into a terrain database. Using the latitude, longitude, and altitude supplied from the GPS unit as the eye point position into a virtual world using a terrain database, the Image Generation Processing block has a render engine capable of rendering a depiction of the terrain outside of the vehicle, as would be seen in high visibility conditions, regardless of weather, lighting and atmospheric conditions."><meta name="DC.date" content="1999-11-30" scheme="issued"><meta name="DC.relation" content="US:4224669" scheme="references"><meta name="DC.relation" content="US:4682160" scheme="references"><meta name="DC.relation" content="US:4812991" scheme="references"><meta name="DC.relation" content="US:5148179" scheme="references"><meta name="DC.relation" content="US:5450345" scheme="references"><meta name="DC.relation" content="US:5475594" scheme="references"><meta name="DC.relation" content="US:5488563" scheme="references"><meta name="DC.relation" content="US:5566073" scheme="references"><meta name="DC.relation" content="US:5721679" scheme="references"><meta name="DC.relation" content="US:5751576" scheme="references"><meta name="DC.relation" content="US:5839080" scheme="references"><meta name="citation_patent_number" content="US:5995903"><meta name="citation_patent_application_number" content="US:08/745,827"><link rel="canonical" href="http://www.google.com/patents/US5995903"/><meta property="og:url" content="http://www.google.com/patents/US5995903"/><meta name="title" content="Patent US5995903 - Method and system for assisting navigation using rendered terrain imagery"/><meta name="description" content="A digital computer system for displaying a computer generated terrain representing a 3-dimensional depiction of the real world terrain surrounding a vehicle in real-time while the vehicle is in motion. This 3-D (3-Dimensional) image is rendered in real time while the vehicle is in motion and uses Global Positioning System (GPS) or differential GPS (dGPS) data available from a GPS unit and translates that data into virtual space within an Image Generation Processing block of the digital computer system. The digital computer system generates a virtual world 3-D image representing the eye-point position of the vehicle and directional vector into a terrain database. Using the latitude, longitude, and altitude supplied from the GPS unit as the eye point position into a virtual world using a terrain database, the Image Generation Processing block has a render engine capable of rendering a depiction of the terrain outside of the vehicle, as would be seen in high visibility conditions, regardless of weather, lighting and atmospheric conditions."/><meta property="og:title" content="Patent US5995903 - Method and system for assisting navigation using rendered terrain imagery"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("bUjsU-myPNLzgwSmnYCgCA"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("BRA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("bUjsU-myPNLzgwSmnYCgCA"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("BRA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5995903?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5995903"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=jzxNBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5995903&amp;usg=AFQjCNF3GLXMg6mjClQ5bxmoB5emNEr0KQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5995903.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5995903.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5995903" style="display:none"><span itemprop="description">A digital computer system for displaying a computer generated terrain representing a 3-dimensional depiction of the real world terrain surrounding a vehicle in real-time while the vehicle is in motion. This 3-D (3-Dimensional) image is rendered in real time while the vehicle is in motion and uses Global...</span><span itemprop="url">http://www.google.com/patents/US5995903?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5995903 - Method and system for assisting navigation using rendered terrain imagery</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5995903 - Method and system for assisting navigation using rendered terrain imagery" title="Patent US5995903 - Method and system for assisting navigation using rendered terrain imagery"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5995903 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/745,827</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Nov 30, 1999</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Nov 12, 1996</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Nov 12, 1996</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08745827, </span><span class="patent-bibdata-value">745827, </span><span class="patent-bibdata-value">US 5995903 A, </span><span class="patent-bibdata-value">US 5995903A, </span><span class="patent-bibdata-value">US-A-5995903, </span><span class="patent-bibdata-value">US5995903 A, </span><span class="patent-bibdata-value">US5995903A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Eric+L.+Smith%22">Eric L. Smith</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Kurt+Zimmerman%22">Kurt Zimmerman</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Smith%3B+Eric+L.%22">Smith; Eric L.</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Zimmerman%3B+Kurt%22">Zimmerman; Kurt</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5995903.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5995903.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5995903.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (11),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (55),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (15),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (11)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5995903&usg=AFQjCNHoIET-O868UMdP7iQ4d3HoKww_cg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5995903&usg=AFQjCNGCI1dvFT9SZPI8t3ms0Q6HK1trgw">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5995903A%26KC%3DA%26FT%3DD&usg=AFQjCNHlGZGkX96u8ydIK-dtmWxcK12xVA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54521223" lang="EN" load-source="patent-office">Method and system for assisting navigation using rendered terrain imagery</invention-title></span><br><span class="patent-number">US 5995903 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37999623" lang="EN" load-source="patent-office"> <div class="abstract">A digital computer system for displaying a computer generated terrain representing a 3-dimensional depiction of the real world terrain surrounding a vehicle in real-time while the vehicle is in motion. This 3-D (3-Dimensional) image is rendered in real time while the vehicle is in motion and uses Global Positioning System (GPS) or differential GPS (dGPS) data available from a GPS unit and translates that data into virtual space within an Image Generation Processing block of the digital computer system. The digital computer system generates a virtual world 3-D image representing the eye-point position of the vehicle and directional vector into a terrain database. Using the latitude, longitude, and altitude supplied from the GPS unit as the eye point position into a virtual world using a terrain database, the Image Generation Processing block has a render engine capable of rendering a depiction of the terrain outside of the vehicle, as would be seen in high visibility conditions, regardless of weather, lighting and atmospheric conditions.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(3)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5995903-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5995903-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5995903-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5995903-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5995903-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5995903-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(20)</span></span></div><div class="patent-text"><div mxw-id="PCLM59534124" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A digital computer system that correlates positional input data for generating a 3-D virtual image, representational of a localized terrain over which a vehicle is traveling, comprising:<div class="claim-text">a positional information unit which receives the positional input data provided by a satellite-based positioning system;</div> <div class="claim-text">a terrain database unit, containing data of the localized terrain over which the vehicle is traveling; and</div> <div class="claim-text">a location calculation unit which receives the positional input data from the positional information unit and generates a most recent spatial location of the vehicle in the localized terrain over which the vehicle is traveling;</div> <div class="claim-text">an image generation processing unit having a render engine which receives data from the positional information unit and the terrain database unit and which generates the 3-D virtual image representational of the terrain over which the vehicle is traveling, wherein the image generation processing unit generates the 3-D virtual image by referencing the most recent spatial location of the vehicle in the localized terrain over which the vehicle is traveling in order to compute a heading, a pitch, and a directional vector of a current position of the vehicle, wherein the most recent spatial location of the vehicle is generated by the location calculation unit.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The system of claim 1, wherein the heading and the pitch of the current position of the vehicle are computed through the use of a lookup table.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The system of claim 1, wherein the system further comprises:<div class="claim-text">a radar information unit that provides radar data to the image generation processing unit, wherein the image generation processing unit incorporates the radar data from the radar information unit with data from the terrain database unit and the positional information unit to generate the 3-D virtual image representative of the terrain over which the vehicle is traveling.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The system of claim 3, wherein the radar information unit is a weather radar system and the radar data is representative of weather conditions.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The system of claim 3, wherein the radar information unit is a traffic collision avoidance system (TCAS) and the radar data is representative of vehicular traffic.</div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6. A digital computer system that correlates positional input data for generating a 3-D virtual image, representational of a localized terrain over which a vehicle is traveling, comprising:<div class="claim-text">a positional information unit which receives the positional input data provided by a satellite-based positioning system;</div> <div class="claim-text">a terrain database unit, containing data of the localized terrain over which the vehicle is traveling; and</div> <div class="claim-text">an image generation processing unit having a render engine which receives data from the positional information unit and the terrain database unit and which generates the 3-D virtual image representational of the terrain over which the vehicle is traveling, wherein the image generation processing unit generates the 3-D virtual image by referencing a most recent spatial location of the vehicle in the localized terrain over which the vehicle is traveling in order to compute a heading and a pitch of a current position of the vehicle, wherein the most recent spatial location of the vehicle is generated by a location calculation unit which receives the positional input data from the positional information unit.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The system of claim 6, wherein the heading and the pitch of the current position of the vehicle are computed through the use of a lookup table.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The system of claim 6, wherein the system further comprises:<div class="claim-text">a radar information unit that provides radar data to the image generation processing unit, wherein the image generation processing unit incorporates the radar data from the radar information unit with data from the terrain database unit and the positional information unit to generate the 3-D virtual image representative of the terrain over which the vehicle is traveling.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The system of claim 8, wherein the radar information unit is a weather radar system and the radar data is representative of weather conditions.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The system of claim 8, wherein the radar information unit is a traffic collision avoidance system (TCAS) and the radar data is representative of vehicular traffic.</div>
    </div>
    </div> <div class="claim"> <div num="11" class="claim">
      <div class="claim-text">11. method for generating a 3-D virtual image representational of a localized terrain over which a vehicle is traveling, comprising the steps of:<div class="claim-text">receiving positional input data provided by a satellite-based positioning system which provides latitude data, longitude data, altitude data, and time data to define a spatial location representative of an eye point position seen by an operator of the vehicle in the terrain over which the vehicle is traveling;</div> <div class="claim-text">deriving an initial positional reading of the vehicle at time T1 from a sampled GPS data, wherein the initial positional reading at time T1 is represented as A =(X<sub>1</sub>, Y<sub>1</sub>, Z<sub>1</sub>, T<sub>1</sub>) where X<sub>1</sub> is representative of latitude at time T<sub>1</sub>, Y<sub>1</sub> is representative of longitude at time T<sub>1</sub>, and Z<sub>1</sub> is representative of altitude at time T<sub>1;</sub> </div> <div class="claim-text">deriving a subsequent positional reading of the vehicle at time T2 from the sampled GPS data, wherein the subsequent positional reading at time T2 is represented as B=(X<sub>2</sub>, Y<sub>2</sub>, Z<sub>2</sub>, T<sub>2</sub>) where X<sub>2</sub> is representative of latitude at time T2, Y<sub>2</sub> is representative of longitude at time T2, and Z<sub>2</sub> is representative of altitude at time T<sub>2</sub> ;</div> <div class="claim-text">calculating a directional vector of the vehicle defined as the vector AB;</div> <div class="claim-text">calculating the velocity of the vehicle according to the equation: ##EQU4## generating a computer image representative of the eye point position seen by the operator of the vehicle and the directional vector of the vehicle, wherein the computer image is generated by a render engine of an image generation processing unit; and</div> <div class="claim-text">overlaying the computer image representing the eye point position and the directional vector of the vehicle onto a simulated image of the terrain over which the vehicle is traveling to generate a 3-D virtual image.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The method of claim 11, comprising the further step of:<div class="claim-text">displaying the 3-D virtual image.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The method of claim 11, wherein the sampled global positioning satellite (GPS) data is differential global positioning satellite data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The method of claim 11, wherein the step of overlaying the computer image representing the eye point position and the directional vector of the vehicle onto the simulated image to generate the 3-D virtual image is accomplished by an image generation processing block of a digital computer system.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. The method of claim 11, wherein the step of receiving positional input data is accomplished by periodically sampling global positioning satellite (GPS) data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The method of claim 15, wherein the GPS data is preferably sampled as often as possible.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The method of claim 16, wherein the GPS data is sampled at least every 1/2 second.</div>
    </div>
    </div> <div class="claim"> <div num="18" class="claim">
      <div class="claim-text">18. A digital computer system that correlates differential positional input data for generating a 3-D virtual image, representational of a localized terrain over which a vehicle is traveling, comprising:<div class="claim-text">a positional information unit which receives the differential positional input data provided by a satellite-based positioning system, wherein the differential positional input data is a differential GPS data provided from a Global Positioning Satellite (GPS) unit;</div> <div class="claim-text">a terrain database unit, containing data of the localized terrain over which the vehicle is traveling;</div> <div class="claim-text">an image generation processing unit having a render engine which receives differential data from the positional information unit and the terrain database unit and which generates the 3-D virtual image representational of the terrain over which the vehicle is traveling; and</div> <div class="claim-text">a radar information unit that provides radar data to the image generation processing unit, wherein the image generation processing unit incorporates the radar data from the radar information unit with data from the terrain database unit and the positional information unit to generate the 3-D virtual image representative of the terrain over which the vehicle is traveling.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The system of claim 18, wherein the radar information unit is a weather radar system and the radar data is representative of weather conditions.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The system of claim 18, wherein the radar information unit is a traffic collision avoidance system (TCAS) and the radar data is representative of vehicular traffic.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67378560" lang="EN" load-source="patent-office" class="description">
    <heading>FIELD OF THE INVENTION</heading> <p>The present invention relates generally to information display systems and more specifically to a digital system for generating a 3-Dimensional (3-D) representation of real-world terrain which closely approximates the view seen when actually looking at the real-world terrain.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>In the navigation of a vehicle over a prescribed route contour maps are commonly used to provide an indication of the terrain over which the vehicle is traveling. The information afforded by contour maps, assorted vehicle instrumentation, and visual observation enables the operator to navigate the vehicle as it travels along its prescribed route. Thus, a pilot navigating an aircraft, for instance, uses contour maps, instrumentation readings and visual observation in order to determine altitude and other course parameters have traditionally defined a navigational instrument used primarily to aid in the navigation of the vehicle along a pre-defined path.</p>
    <p>U.S. Pat. No. 4,682,160 issued to Beckwith Jr. et al. on Jul. 21, 1987, describes a system which generates a real time perspective view of the terrain lying along an aircraft's flight path for the benefit of the pilot of an aircraft employing the system. The system of the Beckwith, Jr. et al. patent accesses terrain data stored as digital information in a digital map generator and then converts the digital data into the perspective representation of the terrain which may be viewed on an appropriate input/output device, such as a cockpit CRT (cathode ray tube) instrument panel. The real time perspective representation provided to the pilot of the aircraft approximates the view the pilot would have if actually looking out a window of the aircraft during high visibility conditions.</p>
    <p>The Beckwith et al. patent defines a hardware device that accesses terrain data which is converted into a perspective representation of the terrain which is displayed on a display device, such as a CRT instrument panel, for the pilot to see. The contour representation of the terrain on the display device represents a perspective as if the pilot were actually viewing the terrain himself during high visibility conditions. The Beckwith et al. patent offers the advantage of allowing a pilot to fly during inclement weather conditions with the aid of a display which provides terrain information of the type that would be available to the pilot's naked eye during high visibility weather conditions.</p>
    <p>The hardware implementation of the Beckwith et al. patent produces a wire-frame model of the terrain over which the aircraft is flying. The Beckwith et al. patent requires a great number of contour paths in order to generate a wire-frame model of the terrain is a limitation. Additionally, the hardware approach of the Beckwith et al. patent does not provide as flexible a solution as could be achieved with a software approach.</p>
    <p>U.S. Pat. No. 5,488,563 issued to Chazelle et al. on Jan. 30, 1996 defines a device that correlates the terrain data with the flight path of an aircraft to define an anti-collision mechanism and warning system. Memory of the device stores terrain information of a very large area of the earth. As a function of the position of the aircraft, the appropriate local map is temporarily transferred into a fast access memory of the device and an altitude envelope of the aircraft is developed given local terrain information, velocity and acceleration vectors for the zone in which the aircraft is flying. The device further has anti-collision processing capabilities such that an alarm indicates if the flight path of the aircraft violates a predetermined relation between a protection field and the altitude envelope. The Chazelle et al. patent uses either an inertial navigational unit or a radio navigational instrument to generate a synthetic image representative of a flight path trajectory that will avoid collision with the terrain over which the airplane is flying. The synthetic image representative of a flight path trajectory is not a 3-D image of the terrain over which the airplane is flying.</p>
    <p>The flight management technology of the Chazelle et al. patent studies terrain curves in order to calculate an exit path for the airplane. The positional information required in order to calculate the exit path necessarily includes flight information parameters that must be supplied by the flight management system of the aircraft. This is clearly shown by Informations in flight block 2 of FIG. 2 of the Chazelle et al. patent. Such flight parameters would include information with regard to the inertial unit 20, radio navigational instrument 21, and Radio-altimeter 22 all shown in FIG. 3. The inertial unit 20 provides information on the velocity and acceleration of the aircraft from which the angle of incidence, yaw, slope, pitch, heading, and bank may be determined. The angular values are used in the vicinity of the acceptable flight deck of the aircraft.</p>
    <p>There is currently an unmet need in the art to be able to provide a navigator of a vehicle with terrain information over which the vehicle is traveling regardless of weather and visibility conditions in a manner that is not dependent upon trip information such as velocity and acceleration of the vehicle and in a manner that is more flexible than the hardware solution to be found in the prior art. There is a need in the art for the terrain information to be a 3-D, non-wire frame image different from the synthetic image representative of an exit path generated by the invention of the Chazelle et al. patent. Additionally, there is an unmet need in the art to provide such terrain information to navigators of a variety of vehicle types including, but not limited to, aircraft.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>It is an object of the invention to be able to provide a navigator of a vehicle with terrain information over which the vehicle is traveling regardless of weather and visibility conditions in a manner that is not dependent upon trip information such as velocity and acceleration of the vehicle and in a manner that is more flexible than the hardware solution to be found in the prior art.</p>
    <p>It is further an object of the invention to provide such terrain information to navigators of a variety of vehicle types, including but not limited to aircraft.</p>
    <p>Therefore, in accordance with the present invention, a digital computer system for displaying a computer generated terrain representing a 3-dimensional depiction of the real world terrain surrounding a vehicle in real-time while the vehicle is in motion. This 3-D (3-Dimensional) image is rendered in real time while the vehicle is in motion and uses Global Positioning System (GPS) or differential GPS (dGPS) data available from a GPS unit and translates that data into virtual space within an Image Generation Processing block of the digital computer system. The digital computer system generates a virtual world 3-D image representing the eye-point position of the vehicle and directional vector into a terrain database. Using the latitude, longitude, and altitude supplied from the GPS unit as the eye point position into a virtual world using a terrain database, the device can render a depiction of the terrain outside of the vehicle, as would be seen in high visibility conditions, regardless of weather, lighting and atmospheric conditions.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>The novel features believed characteristic of the invention are set forth in the claims. The invention itself, however, as well as a preferred mode of use, and further objects and advantages thereof, will best be understood by reference to the following detailed description of an illustrative embodiment when read in conjunction with the accompanying drawing(s), wherein:</p>
    <p>FIG. 1 is a block diagram of the digital computer system, according to the present invention;</p>
    <p>FIG. 2 is an illustration of the controlled and restricted zones for a particular space through which the vehicle is traveling;</p>
    <p>FIG. 3 illustrates the lighting angle condition used by the present invention,</p>
    <p>FIG. 4A illustrates the vertical field of view, according to the present invention.</p>
    <p>FIG. 4B illustrates the horizontal field of view, according to the present invention.</p>
    <p>FIG. 5 illustrates the "safe-distance" bubble parameter that causes the audible and/or visual indicator to enunciate, according to the present invention; and</p>
    <p>FIG. 6 illustrates the polygons set for 3 position points which define the 3-D virtual image, according to an embodiment of the present invention.</p>
    <heading>DESCRIPTION OF THE INVENTION</heading> <p>The present invention is a digital computer system that correlates positional input data, such as Global Positioning Satellite (GPS) or differental GPS (dGPS) data, into virtual space within a computer system to generate the eye-point position of the vehicle into a simulated "real-world" image. A virtual reality image, which may be shaded or textured if so desired, is generated at a real-time rate which depicts the real-world terrain in front of the vehicle following the directional vector of travel in front of the vehicle. The computer-generated image is a view of 3-D space representing what would be viewed by the operator of the vehicle during ideal weather conditions and may be a filled polygonal image or a fractal image. The image generated by the digital computer system is viewed on an instrument panel of a vehicle which has access to the system. Thus the computer-generated image allows the operator to view the terrain in the vehicle's directional vector of travel in spite of restricted visibility conditions such as might be caused by smoke, ice, snow, rain, blizzards, nighttime.</p>
    <p>The digital computer system of the present invention encompasses a software system that operates on a digital computer system. The digital computer system has three major components required to generate the real-time 3-D image: a database of terrain information, a 3-D render engine, and a display device for displaying the 3-D image rendered by the 3-D render engine. Reference to block diagram of the digital computer system 10 of FIG. 1 illustrates the informational flow between the three major components of the digital computer system 10 of the present invention: Terrain Database block 18, the render engine represented by Image Generation Processing block 24, and Display block 26 through which the operator may view the rendered image generated by Image Generation Processing block 24. The Display block 26 represents a Display device which displays for the operator the real world terrain surrounding the vehicle. The computer generated scene is a view of the 3-D space representing what would be viewed of the real world if viewed by the operator of the vehicle during ideal weather and lighting conditions.</p>
    <p>Position Information block 14 of the digital computer system 10 contains GPS (Global Positioning Satellite) data or dGPS (differential Global Positioning Satellite) data received from GPS unit 12, hereinafter referred to as GPS data. The GPS system allows civilians access to twenty-four satellites in orbit around the earth. The GPS system takes directional information from each of three or four of the twenty-four satellites, using a 3-D triangulation measurement, in order to compute a position. It is important to note that the FM (Federal Aviation Administration), on Dec. 7, 1995, approved the use of differential GPS for instrument approaches to otherwise restricted airports. This is expected to greatly expand the number of IFR rated airports in the United States in the future.</p>
    <p>GPS unit 12 is representative of a variety of GPS systems which use standard interface protocols, such as the National Marine Equipment Association 0183 or Trimble Standard Interface Protocol. The digital computer system 10 translates the GPS or dGPS data into virtual space within the Image Generation Processing block 24 of digital computer system 10. Image Generation Processing block 24 may be any image processing technology, including image processing technology commercially available.</p>
    <p>In addition to the GPS data, Image Generation Processing block 24 is provided with information from the Terrain Acquisition block 20 in order to generate a computer image of the terrain over which the vehicle is traveling that may be viewed at Display block 26. Given the GPS data and terrain data, Image Generation Processing block 24 uses a render engine to generate the 3-D image. A render engine may be defined as code that will generate an image based upon terrain database information and eyepoint position. The computer image produced by Image Generation Processing block 24 and viewed at Display block 26 represents the eye-point position and directional vector of the vehicle in the simulated "real-world" image of the vehicle into the terrain database. The Display device represented by Display lock 26 may be any number of appropriate devices known in the art. For instance, the Display device may employ a CPU (central processing unit) with an embedded operating system (O/S) and code; naturally, such a Display device with embedded code must have enough RAM (random access memory) in order to execute the code. The Display device may be a storage device such as a CD ROM (compact disk read only memory) which stores data for the terrain database over which the vehicle is traveling for that given trip. The 3-D image itself may be displayed upon any display device such as an active matrix LCD (liquid crystal display) screen that is located on the instrument panel of the vehicle.</p>
    <p>As previously discussed, the positional information of Position Information block 14 of the vehicle is acquired from a GPS system, represented by GPS Unit 12, and is used to determine the eye point position in a database of real-world terrain data. The GPS system takes directional information from each of three or four satellites to compute a position, using the 3-D triangulation method. GPS data or dGPS data provides information concerning Latitude Degrees &amp; Minutes, Longitude Degrees &amp; Minutes, Altitude in meters above the average/mean sea level, and Time to digital computer system 10; Velocity information may or may not be available on all GPS systems. The Latitude, Longitude, Altitude, and Time values may be used to define a position in 3-Dimensional space which is mapped to a corresponding location in a virtual reality world which will exactly mimic the real-world which actually exists outside the vehicle.</p>
    <p>Information related to the Latitude, Longitude, Altitude, Time and Velocity of the vehicle, allows a 4-point spatial location, represented by (X, Y, Z, T), to be derived by Location Calculations block 16 given the GPS data, where X is representative of Latitude in degrees and minutes, Y is representative of Longitude in degrees and minutes, Z is representative of Altitude in meters, and T is representative of time. Typically, T is representative of time at a resolution of 0.5 second. The 4-point spatial location is useful in determining a number of useful parameters related to the trip of the vehicle. These parameters to be determined using the 4-point spatial relationship include the position of the vehicle in relation to the real-world database coordinates using either longitude/latitude or Universal Transverse Mercator units; the directional vector of travel using the last set of coordinates including heading and pitch; and the velocity, v=d/t, at which the vehicle is traveling.</p>
    <p>The GPS data must be sampled periodically at short enough intervals to render a reliable image of the vehicle in the terrain it is transversing. Thus, Position Information block 14 of the digital computer system 10 samples GPS positional data at least every 1/2 second if possible or even faster if possible; if 1/2 second output from the GPS system is unavailable, the digital computer system 10 retrieves GPS data as rapidly as it is available. The faster the sampling, the more realistic the real-time image produced by Image Generation Processing block 24 will be. It will be understood by one of ordinary skill in the art, therefore, that sampling may occur so frequently as to be characterized as "continuous sampling" where positional input data is continuously received by Position Information block 14. The Image Generation Processing block 24 of digital computer system 10 then draws a smooth "animation" of the movement of the vehicle based upon the last known position and the speed of the vehicle.</p>
    <p>Using the latitude, longitude, altitude, and direction of travel as the eye point position for a terrain database, the digital computer system can render a depiction of the terrain along the directional vector of the vehicle by referencing the last positional reading in order to compute the heading and pitch of the current position of the vehicle. It should be noted that location A is the next to last positional reading at time T1 while location B is the last positional reading of the vehicle at time T2. By appropriately manipulating the latitude, longitude, and altitude readings of two subsequent readings at time T1 and time T2, it is possible to generate a directional vector and to calculate the velocity of the vehicle.</p>
    <p>Computing the heading and pitch of the current position of the vehicle is accomplished though simple geometry through the use of a lookup table, an example of which is included here for completeness:</p>
    <p>For locations, A=(X<sub>1</sub>, Y<sub>1</sub>, Z<sub>1</sub>, T<sub>1</sub>) and B=(X<sub>2</sub>, Y<sub>2</sub>, Z<sub>2</sub>, T<sub>2</sub>)</p>
    <p>Heading: sin() lookup of: ##EQU1## Pitch: sin()look up of: ##EQU2## Pitch is correlated against 90 increments for relative attitude correctness.</p>
    <p>The vector AB defines the directional vector, and the velocity of the vehicle is obtained by: ##EQU3## It should be noted that differential GPS (dGPS) data provides more accurate positional information than does GPS data. DGPS data is the result of coupling GPS data with correctional information to reduce the error inherent in the GPS system. A radio signal from a ground-based system is used to "correct" the error found in GPS data. While conventional GPS data has an accuracy of approximately 100 meters, dGPS has a much greater accuracy of approximately 1 to 10 meters. Either GPS data or dGPS data may be used in the present invention.</p>
    <p>The digital computer system 10 correlates the eyepoint position a operator of the vehicle would have with a terrain database location provided by a GPS system in order to generate the virtual image of the real-world terrain following the directional vector of travel in front of the vehicle. This correlation can be accomplished different ways. Pure longitude/latitude data may be used or longitude/latitude data may be converted to Universal Transverse Mercator units or any similar positional locus units.</p>
    <p>The terrain database 18 derived from a GPS system as previously mentioned is preferably based on the highest possible resolution terrain data available from sources such as the United States Geological Society, the Department of Defense, and/or the Defense Mapping Agency. The data of terrain database 18 is typically provided at 30 meter spacing and is used by Image Generation Processing block 24 to generate the 3-D image seen on Display block 26. The terrain data included in terrain database 18 is a subset of the data contained in Positional Information block 14 which is received from GPS Unit block 12. Nonetheless, the number of data points represented by terrain database 18 is quite staggering. Assuming that terrain database 18 is a sectional chart having a size of 600 NM (nautical miles)400 NM with a resolution of 30 meter spacing, a total of 914,628,720 data points are represented! Obviously this represents too many data points to fit onto a single CD and additionally would require quite a bit of access time upon power-up of the digital computer system.</p>
    <p>The terrain data contained within Terrain Database 18 is used to pre-generate terrain database 18 of the real-world terrain of the applicable travel plan and is put onto a storage device, such as a CD-ROM, that is made available to the digital computer system 10 upon power-up. Upon power-up of the digital computer system 10, the system 10 reads the GPS position, including directional vector information, and generates a 3-D scene depicting the forward view of the vehicle in the terrain.</p>
    <p>Terrain Database 18, in addition to containing GPS terrain information, might also contain sectional chart information about objects such as wires, frequencies, restricted airspace, control zones, landmarks such as towers etc. This sectional chart information is integrated into the terrain database such that can be displayed to the operator upon request. The sectional chart information is used to add transparent/translucent cylinders or objects of "color" around controlled zones and/or restricted zones for the sectional area through which the vehicle is currently traveling. Referring to FIG. 2, an illustration of the controlled and restricted zones for a particular terrain, such as airspace, through which the vehicle operator is traveling is shown.</p>
    <p>In addition to the sectional chart information and terrain information provided by terrain Database 18, the digital computer system 10 may be provided with additional information at Other Inputs block 22. Thus the digital computer system 10 can also acquire radar input from either an on-board weather radar system or from an on-board TCAS (Traffic Collision Avoidance System) thereby having the ability to incorporate weather conditions or information concerning the location of other vehicles in the region into the generated 3-D image. Such additional information provided by Other Inputs block 22 is incorporated with the terrain database and sectional chart information by Image Generation Processing block 24. As can be seen in FIG. 2, the information concerning sectional chart information, terrain information, and other parameters is extremely valuable to air traffic control management.</p>
    <p>The positional information derived by Location Calculations block 16 from data received from Position Information block 14 is used in conjunction with the terrain database by Image Generation Processing block 24 to create the 3-D image.</p>
    <p>The 3-D image produced by Image Generation Processing block 24 and shown at Display block 26 is a depiction of the terrain in front of the vehicle with the light source at 12:00 "high-noon" and at infinity. This default lighting condition permits the Display block 26 to always display a scene relative to "ideal" conditions, regardless of the actual conditions which might exist outside the vehicle. The lighting angle condition used by the present invention is illustrated in FIG. 3.</p>
    <p>The field of view (FOV) contained in the 3-D image generated by Image Generation Processing block 24 is selectable within given parameters. The rendered FOV is selectable from 60 to 145, horizontal HFOV (HFOV) and vertical FOV (VFOV). The FOV is selected with care since too large a FOV value may cause the scene to appear "fish-eyed" and therefore of little use; too small a FOV value may limit the amount of data displayed making the rendered image unusable. Selectable FOV allows the 3-D image to be put on different sized screens for viewing by the operator. Examples of a 90 HFOV and a 90 VFOV are illustrated in FIGS. 4A and 4B.</p>
    <p>It should be noted that the distant terrain shown in the 3-D image generated by Image Generation Processing block 24 is generated as a function of the speed of the vehicle. Typically, the distant terrain represents the terrain a given number of seconds from the vehicle's present position along the vehicle's directional vector of travel. The distance parameter of the 3-D image is calculated in real-time so as to allow the digital software system 10 to be used with all types of vehicles, including both air and ground vehicles.</p>
    <p>The 3-D image generated by Image Generation Processing block 24 is a representation of the terrain that may be based upon polygonal or fractal image technology. A fractal repesentation is based upon discrete points and thus generally has a higher resolution image than a filled 3-D polygonal image. For a polygonal filled 3-D image, a fairly simple calculation on each polygon in the rendered scene can result in a distance coefficient from the vehicle to the intersection of the plane of the polygon. The render engine of Image Generation Processing block 24, as previously discussed, is code that will generate the 3-D image based upon both terrain data and eyepoint position. In the case of a polygonal filled 3-D image, the render engine is able to translate the polygon list into the 3-D image.</p>
    <p>From the rate of travel of the vehicle, it can then be determined if the polygon lies within another configurable parameter, the "safe-distance" bubble of the vehicle. The "safe-distance" bubble parameter is set by the operator of the vehicle and allows the digital computer system 10 to be easily used in conjunction with vehicles of different sizes, such as with a smaller, slower vehicles or faster, larger vehicles. After the size of the "safe-distance" bubble parameter has been set by the operator, should a polygon within the 3-D image come within the "safe-distance" bubble of the vehicle, an audible and/or visual indicator such as an alarm will inform the operator. The bubble intersection caused by a polygon invading the safe area established by the "safe-distance" bubble parameter that causes the audible and/or visual indicator to enunciate is shown in FIG. 5.</p>
    <p>In the 3-D image presented to the operator of the vehicle, the polygons of that image have color, texture and other indicators which indicate what type of surface is being represented. For instance, Dark Blue may be representative of water, Green-Land representative of Sky-Blue, Gray representative of Buildings or other protruding land masses, and White representative of surfaces above the "tree-line". Since the database shall be generated prior to "run-time" and shall be stored on a storage device, such as a CD-ROM or other storage device, the color, texture, and other indicators conveyed by the polygon is pre-determined and used by the 3-Dimensional render engine provided by Image Generation Processing 24 at run-time. Coloring the polygons allows for a "baseline" color before any shading has occurred. Subsequent shading provides motion queuing to the operator of the vehicle as the vehicle traverses through the database.</p>
    <p>The polygons of the 3-D image are defined by taking 3 position points from the terrain database 18 in order to generate a flat surface for the render engine represented by Image Generation Processing 24 at that point in the 3-D image. By using multiples of these triplets of terrain data, an fairly accurate rendition of the surface can be developed by the Image Generation Processing 24. The definition of the polygons of the 3-D image by 3 position points is illustrated by FIG. 6.</p>
    <p>The digital computer system 10 can optionally display a "cross-hair" in the center to of the display which depicts the projected flight path of the vehicle. Should this cross-hair intersect with a rendered polygon inside the safety bubble, a visual and/or audible alert will either flash or sound requiring the operator to acknowledge this intersection. The device allows the operator to select either a cockpit view or a trailing view, which depicts a view of the vehicle in the 3-D scene as seen from behind the vehicle. Obviously, the 3-D image produced by Display block 26 should be within easy viewing distance of the operator in the vehicle.</p>
    <p>The operator of the vehicle uses the digital computer system of the present invention when nighttime or other restricted visibility conditions precipitate the need for the operator to be able to "see" the terrain over which the vehicle is traveling in spite of the restricted visibility conditions. The present invention is not intended to be used as the sole navigational device in inclement weather or lighting conditions, but rather serves as a supplemental device to assist conventional IFR navigational devices. The operator of the vehicle is to use the present invention when questions of location, or outside conditions warrant the use of the device to "see" into otherwise blind conditions. Because operation of the digital computer system is independent all other navigational instruments, save for the GPS system on-board the vehicle, the digital computer system is capable as serving as a secondary back-up device for all other navigational instruments on-board the vehicle.</p>
    <p>While the invention has been particularly shown and described with reference to a preferred embodiment, it will be understood by those skilled in the art that various changes in form and detail may be made therein without departing from the spirit and scope of the invention.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4224669">US4224669</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 22, 1977</td><td class="patent-data-table-td patent-date-value">Sep 23, 1980</td><td class="patent-data-table-td ">The Boeing Company</td><td class="patent-data-table-td ">Minimum safe altitude monitoring, indication and warning system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4682160">US4682160</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 25, 1983</td><td class="patent-data-table-td patent-date-value">Jul 21, 1987</td><td class="patent-data-table-td ">Harris Corporation</td><td class="patent-data-table-td ">Real time perspective display employing digital map generator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4812991">US4812991</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 1, 1986</td><td class="patent-data-table-td patent-date-value">Mar 14, 1989</td><td class="patent-data-table-td ">Magnavox Govt. And Industrial Electronics Company</td><td class="patent-data-table-td ">Method for precision dynamic differential positioning</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5148179">US5148179</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 27, 1991</td><td class="patent-data-table-td patent-date-value">Sep 15, 1992</td><td class="patent-data-table-td ">Trimble Navigation</td><td class="patent-data-table-td ">Differential position determination using satellites</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5450345">US5450345</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 15, 1992</td><td class="patent-data-table-td patent-date-value">Sep 12, 1995</td><td class="patent-data-table-td ">Honeywell Inc.</td><td class="patent-data-table-td ">Terrain referenced navigation-Schuler cycle error reduction method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5475594">US5475594</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 23, 1993</td><td class="patent-data-table-td patent-date-value">Dec 12, 1995</td><td class="patent-data-table-td ">Sextant Avionique</td><td class="patent-data-table-td ">Method and device for assisting the piloting of an aircraft from a voluminous set of memory-stored documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5488563">US5488563</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 2, 1993</td><td class="patent-data-table-td patent-date-value">Jan 30, 1996</td><td class="patent-data-table-td ">Dassault Electronique</td><td class="patent-data-table-td ">Method and device for preventing collisions with the ground for an aircraft</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5566073">US5566073</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 9, 1995</td><td class="patent-data-table-td patent-date-value">Oct 15, 1996</td><td class="patent-data-table-td ">Margolin; Jed</td><td class="patent-data-table-td ">Pilot aid using a synthetic environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5721679">US5721679</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 18, 1995</td><td class="patent-data-table-td patent-date-value">Feb 24, 1998</td><td class="patent-data-table-td ">Ag-Chem Equipment Co., Inc.</td><td class="patent-data-table-td ">Heads-up display apparatus for computer-controlled agricultural product application equipment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5751576">US5751576</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 18, 1995</td><td class="patent-data-table-td patent-date-value">May 12, 1998</td><td class="patent-data-table-td ">Ag-Chem Equipment Co., Inc.</td><td class="patent-data-table-td ">Animated map display method for computer-controlled agricultural product application equipment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5839080">US5839080</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 31, 1995</td><td class="patent-data-table-td patent-date-value">Nov 17, 1998</td><td class="patent-data-table-td ">Alliedsignal, Inc.</td><td class="patent-data-table-td ">Terrain awareness system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6173239">US6173239</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 30, 1998</td><td class="patent-data-table-td patent-date-value">Jan 9, 2001</td><td class="patent-data-table-td ">Geo Vector Corporation</td><td class="patent-data-table-td ">Apparatus and methods for presentation of information relating to objects being addressed</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6256559">US6256559</a></td><td class="patent-data-table-td patent-date-value">Mar 13, 2000</td><td class="patent-data-table-td patent-date-value">Jul 3, 2001</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Air Force</td><td class="patent-data-table-td ">Passive altimeter employing GPS signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6429814">US6429814</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 19, 2001</td><td class="patent-data-table-td patent-date-value">Aug 6, 2002</td><td class="patent-data-table-td ">Global Locate, Inc.</td><td class="patent-data-table-td ">Method and apparatus for enhancing a global positioning system with terrain model</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6456941">US6456941</a></td><td class="patent-data-table-td patent-date-value">Nov 14, 2001</td><td class="patent-data-table-td patent-date-value">Sep 24, 2002</td><td class="patent-data-table-td ">William Gutierrez</td><td class="patent-data-table-td ">System and method for aircraft and watercraft control and collision prevention</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6496760">US6496760</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 21, 2000</td><td class="patent-data-table-td patent-date-value">Dec 17, 2002</td><td class="patent-data-table-td ">Honeywell International Inc.</td><td class="patent-data-table-td ">Flight information display with plane of flight view</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6539288">US6539288</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 23, 2001</td><td class="patent-data-table-td patent-date-value">Mar 25, 2003</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Vehicle rendering device for generating image for drive assistance</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6558164">US6558164</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 4, 2001</td><td class="patent-data-table-td patent-date-value">May 6, 2003</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">Method and system for simulating travel</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6567087">US6567087</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 27, 2000</td><td class="patent-data-table-td patent-date-value">May 20, 2003</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Army</td><td class="patent-data-table-td ">Method to create a high resolution database</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6590530">US6590530</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 7, 2002</td><td class="patent-data-table-td patent-date-value">Jul 8, 2003</td><td class="patent-data-table-td ">Global Locate, Inc.</td><td class="patent-data-table-td ">Method and apparatus for enhancing a global positioning system with a terrain model</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6597380">US6597380</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 10, 1999</td><td class="patent-data-table-td patent-date-value">Jul 22, 2003</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">In-space viewpoint control device for use in information visualization system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6643580">US6643580</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 15, 1999</td><td class="patent-data-table-td patent-date-value">Nov 4, 2003</td><td class="patent-data-table-td ">Universal Avionics Systems Corporation</td><td class="patent-data-table-td ">Flight plan intent alert system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6653947">US6653947</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 20, 2002</td><td class="patent-data-table-td patent-date-value">Nov 25, 2003</td><td class="patent-data-table-td ">Honeywell International Inc.</td><td class="patent-data-table-td ">Apparatus for the display of weather and terrain information on a single display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6735557">US6735557</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 15, 1999</td><td class="patent-data-table-td patent-date-value">May 11, 2004</td><td class="patent-data-table-td ">Aechelon Technology</td><td class="patent-data-table-td ">LUT-based system for simulating sensor-assisted perception of terrain</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6798343">US6798343</a></td><td class="patent-data-table-td patent-date-value">Sep 15, 2003</td><td class="patent-data-table-td patent-date-value">Sep 28, 2004</td><td class="patent-data-table-td ">Carba Fire Technologies, Inc.</td><td class="patent-data-table-td ">Mobile emergency response platform</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6885939">US6885939</a></td><td class="patent-data-table-td patent-date-value">Dec 31, 2002</td><td class="patent-data-table-td patent-date-value">Apr 26, 2005</td><td class="patent-data-table-td ">Robert Bosch Gmbh</td><td class="patent-data-table-td ">System and method for advanced 3D visualization for mobile navigation units</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6947842">US6947842</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 6, 2003</td><td class="patent-data-table-td patent-date-value">Sep 20, 2005</td><td class="patent-data-table-td ">User-Centric Enterprises, Inc.</td><td class="patent-data-table-td ">Normalized and animated inundation maps</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6999602">US6999602</a></td><td class="patent-data-table-td patent-date-value">Jun 28, 2001</td><td class="patent-data-table-td patent-date-value">Feb 14, 2006</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Image generation for assistance of drivers of vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7107081">US7107081</a></td><td class="patent-data-table-td patent-date-value">Jul 29, 2002</td><td class="patent-data-table-td patent-date-value">Sep 12, 2006</td><td class="patent-data-table-td ">Iwao Fujisaki</td><td class="patent-data-table-td ">Communication device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7107146">US7107146</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 17, 2004</td><td class="patent-data-table-td patent-date-value">Sep 12, 2006</td><td class="patent-data-table-td ">Honeywell International Inc.</td><td class="patent-data-table-td ">Methods and systems for generating a terrain elevation map in a cartesian format</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7251788">US7251788</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 21, 2000</td><td class="patent-data-table-td patent-date-value">Jul 31, 2007</td><td class="patent-data-table-td ">Nokia Corporation</td><td class="patent-data-table-td ">Simulated speed-of-light delay for recreational benefit applications</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7304651">US7304651</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 22, 2001</td><td class="patent-data-table-td patent-date-value">Dec 4, 2007</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Rendering device for generating a display image for drive assistance</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7375678">US7375678</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 29, 2005</td><td class="patent-data-table-td patent-date-value">May 20, 2008</td><td class="patent-data-table-td ">Honeywell International, Inc.</td><td class="patent-data-table-td ">Displaying obstacles in perspective view</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7532879">US7532879</a></td><td class="patent-data-table-td patent-date-value">Aug 20, 2005</td><td class="patent-data-table-td patent-date-value">May 12, 2009</td><td class="patent-data-table-td ">Iwao Fujisaki</td><td class="patent-data-table-td ">Communication device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7739032">US7739032</a></td><td class="patent-data-table-td patent-date-value">Mar 21, 2006</td><td class="patent-data-table-td patent-date-value">Jun 15, 2010</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Method and apparatus for generating and using a regional-terrain model</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7853297">US7853297</a></td><td class="patent-data-table-td patent-date-value">Apr 26, 2008</td><td class="patent-data-table-td patent-date-value">Dec 14, 2010</td><td class="patent-data-table-td ">Iwao Fujisaki</td><td class="patent-data-table-td ">Communication device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7907963">US7907963</a></td><td class="patent-data-table-td patent-date-value">Apr 27, 2008</td><td class="patent-data-table-td patent-date-value">Mar 15, 2011</td><td class="patent-data-table-td ">Iwao Fujisaki</td><td class="patent-data-table-td ">Method to display three-dimensional map on communication device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7917289">US7917289</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Mar 29, 2011</td><td class="patent-data-table-td ">Honeywell International Inc.</td><td class="patent-data-table-td ">Perspective view primary flight display system and method with range lines</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7957853">US7957853</a></td><td class="patent-data-table-td patent-date-value">Jun 13, 2006</td><td class="patent-data-table-td patent-date-value">Jun 7, 2011</td><td class="patent-data-table-td ">The Mitre Corporation</td><td class="patent-data-table-td ">Flight restriction zone detection and avoidance</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8035547">US8035547</a></td><td class="patent-data-table-td patent-date-value">Mar 17, 2008</td><td class="patent-data-table-td patent-date-value">Oct 11, 2011</td><td class="patent-data-table-td ">Garmin Switzerland Gmbh</td><td class="patent-data-table-td ">System and method of assisted aerial navigation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8185647">US8185647</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 18, 2009</td><td class="patent-data-table-td patent-date-value">May 22, 2012</td><td class="patent-data-table-td ">Dearborn Group, Inc.</td><td class="patent-data-table-td ">Protocol adapter for transferring diagnostic signals between in-vehicle networks and a computer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8190308">US8190308</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 25, 2006</td><td class="patent-data-table-td patent-date-value">May 29, 2012</td><td class="patent-data-table-td ">Airbus Operations Sas</td><td class="patent-data-table-td ">Method and device for detecting a risk of collision of an aircraft with the surrounding terrain</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8203503">US8203503</a></td><td class="patent-data-table-td patent-date-value">Sep 8, 2005</td><td class="patent-data-table-td patent-date-value">Jun 19, 2012</td><td class="patent-data-table-td ">Aechelon Technology, Inc.</td><td class="patent-data-table-td ">Sensor and display-independent quantitative per-pixel stimulation system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8301368">US8301368</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 31, 2011</td><td class="patent-data-table-td patent-date-value">Oct 30, 2012</td><td class="patent-data-table-td ">Angela Masson</td><td class="patent-data-table-td ">Electronic kit bag</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8379087">US8379087</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 16, 2007</td><td class="patent-data-table-td patent-date-value">Feb 19, 2013</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Navy</td><td class="patent-data-table-td ">Attitude estimation using ground imagery</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8457882">US8457882</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 19, 2011</td><td class="patent-data-table-td patent-date-value">Jun 4, 2013</td><td class="patent-data-table-td ">Honeywell International Inc.</td><td class="patent-data-table-td ">Systems and methods for navigation in a GPS-denied environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8483889">US8483889</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 29, 2010</td><td class="patent-data-table-td patent-date-value">Jul 9, 2013</td><td class="patent-data-table-td ">Honeywell International Inc.</td><td class="patent-data-table-td ">Systems and methods for selectively altering a ground proximity message</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8489252">US8489252</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 22, 2011</td><td class="patent-data-table-td patent-date-value">Jul 16, 2013</td><td class="patent-data-table-td ">Denso Corporation</td><td class="patent-data-table-td ">Apparatus for controlling speed of mobile object</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8698655">US8698655</a></td><td class="patent-data-table-td patent-date-value">Oct 3, 2011</td><td class="patent-data-table-td patent-date-value">Apr 15, 2014</td><td class="patent-data-table-td ">Garmin International, Inc.</td><td class="patent-data-table-td ">System and method of assisted aerial navigation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8781802">US8781802</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 17, 2007</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Saab Ab</td><td class="patent-data-table-td ">Simulation device and simulation method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080189092">US20080189092</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 17, 2007</td><td class="patent-data-table-td patent-date-value">Aug 7, 2008</td><td class="patent-data-table-td ">Saab Ab</td><td class="patent-data-table-td ">Simulation device and simulation method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080215197">US20080215197</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 25, 2006</td><td class="patent-data-table-td patent-date-value">Sep 4, 2008</td><td class="patent-data-table-td ">Airbus France</td><td class="patent-data-table-td ">Method and Device for Detecting a Risk of Collison of an Aircraft with the Surrounding Terrain</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100198509">US20100198509</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 4, 2008</td><td class="patent-data-table-td patent-date-value">Aug 5, 2010</td><td class="patent-data-table-td ">Qualcomm Incorporated</td><td class="patent-data-table-td ">3d maps rendering device and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100286851">US20100286851</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 29, 2010</td><td class="patent-data-table-td patent-date-value">Nov 11, 2010</td><td class="patent-data-table-td ">Honeywell International Inc.</td><td class="patent-data-table-td ">Systems and methods for selectively altering a ground proximity message</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120046803">US20120046803</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 22, 2011</td><td class="patent-data-table-td patent-date-value">Feb 23, 2012</td><td class="patent-data-table-td ">Denso Corporation</td><td class="patent-data-table-td ">Apparatus for controlling speed of mobile object</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120271546">US20120271546</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 19, 2011</td><td class="patent-data-table-td patent-date-value">Oct 25, 2012</td><td class="patent-data-table-td ">Honeywell International Inc.</td><td class="patent-data-table-td ">Systems and methods for navigation in a gps-denied environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN100386223C?cl=en">CN100386223C</a></td><td class="patent-data-table-td patent-date-value">May 24, 2001</td><td class="patent-data-table-td patent-date-value">May 7, 2008</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Drawing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/DE102004017755A1?cl=en">DE102004017755A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 10, 2004</td><td class="patent-data-table-td patent-date-value">Oct 27, 2005</td><td class="patent-data-table-td ">Mller, Lisa</td><td class="patent-data-table-td ">Satellite navigation method for a handheld terminal, in which geographical position data is output to a terminal display such that the terminal itself is shown moving in a virtual representation of the actual environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1158803A2?cl=en">EP1158803A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 21, 2001</td><td class="patent-data-table-td patent-date-value">Nov 28, 2001</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Rendering device for generating a display image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1158804A2?cl=en">EP1158804A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 21, 2001</td><td class="patent-data-table-td patent-date-value">Nov 28, 2001</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Rendering device for generating a display image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1168248A2?cl=en">EP1168248A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 28, 2001</td><td class="patent-data-table-td patent-date-value">Jan 2, 2002</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Rendering device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2390627A1?cl=en">EP2390627A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 28, 2010</td><td class="patent-data-table-td patent-date-value">Nov 30, 2011</td><td class="patent-data-table-td ">BAE Systems PLC</td><td class="patent-data-table-td ">Simulating a terrain view from an airborne point of view</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2003005305A1?cl=en">WO2003005305A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 3, 2002</td><td class="patent-data-table-td patent-date-value">Jan 16, 2003</td><td class="patent-data-table-td ">Goodrich Avionics Systems Inc</td><td class="patent-data-table-td ">System and method for synthetic vision terrain display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2007050196A2?cl=en">WO2007050196A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 7, 2006</td><td class="patent-data-table-td patent-date-value">May 3, 2007</td><td class="patent-data-table-td ">Aechelon Tecnolony Inc</td><td class="patent-data-table-td ">Sensor and display-independent quantitative per-pixel stimulation system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2010097071A1?cl=en">WO2010097071A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 18, 2010</td><td class="patent-data-table-td patent-date-value">Sep 2, 2010</td><td class="patent-data-table-td ">Navigon Ag</td><td class="patent-data-table-td ">Method, system and computer program product for the three-dimensional representation of buildings on a graphical display device of a navigation apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2011148199A1?cl=en">WO2011148199A1</a></td><td class="patent-data-table-td patent-date-value">May 27, 2011</td><td class="patent-data-table-td patent-date-value">Dec 1, 2011</td><td class="patent-data-table-td ">Bae Systems Plc</td><td class="patent-data-table-td ">Simulating a terrain view from an airborne point of view</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc701/defs701.htm&usg=AFQjCNFn25anNrI7_vY4MNK7_80zsoxwdA#C701S470000">701/470</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc340/defs340.htm&usg=AFQjCNGk_NCDWkt8oMijCQ2jvfqday0GbA#C340S995260">340/995.26</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc342/defs342.htm&usg=AFQjCNHmJcOXqM2sgcclreqTZjYK9v88aQ#C342S357520">342/357.52</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc701/defs701.htm&usg=AFQjCNFn25anNrI7_vY4MNK7_80zsoxwdA#C701S454000">701/454</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc701/defs701.htm&usg=AFQjCNFn25anNrI7_vY4MNK7_80zsoxwdA#C701S468000">701/468</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc701/defs701.htm&usg=AFQjCNFn25anNrI7_vY4MNK7_80zsoxwdA#C701S514000">701/514</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0017050000">G06T17/05</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01C0021000000">G01C21/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09B0009360000">G09B9/36</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G09B9/36">G09B9/36</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T17/05">G06T17/05</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jzxNBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G01C21/00">G01C21/00</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06T17/05</span>, <span class="nested-value">G09B9/36</span>, <span class="nested-value">G01C21/00</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Apr 4, 2014</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY INTEREST;ASSIGNOR:TARANIS IP LLC;REEL/FRAME:032610/0560</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">FORTRESS CREDIT CO LLC, NEW YORK</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20140404</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 18, 2012</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIM 18 IS DETERMINED TO BE PATENTABLE AS AMENDED.CLAIMS 19 AND 20, DEPENDENT ON AN AMENDED CLAIM,ARE DETERMINED TO BE PATENTABLE.NEW CLAIMS 21-26 ARE ADDED AND DETERMINED TO BE PATENTABLE.CLAIMS 1-17 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 2, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110609</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 31, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 26, 2010</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">TARANIS IP LLC, TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:TARANIS LLC;REEL/FRAME:024879/0955</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100825</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 10, 2010</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">TARANIS LLC, TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SMITH, ERIC;ZIMMERMAN, KURT;REEL/FRAME:024812/0644</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100106</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100808</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:VISUAL NAVIGATION INC.;REEL/FRAME:024812/0650</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 18, 2007</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 12, 2007</td><td class="patent-data-table-td ">SULP</td><td class="patent-data-table-td ">Surcharge for late payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">7</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 12, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 22, 2003</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 12, 1996</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">VISUAL NAVIGATION, INC., TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:SMITH, ERIC L.;REEL/FRAME:008444/0084</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19961102</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0NY72UxF96j5ulflBVA716FrWgqw\u0026id=jzxNBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3K3pQx5OZji0YQcgBHM1I0iOYcHw\u0026id=jzxNBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2jTaTDlkfHRA_6sC96ebYfcH1f4g","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_and_system_for_assisting_navigati.pdf?id=jzxNBAABERAJ\u0026output=pdf\u0026sig=ACfU3U0gpzEr3wVa1gQIXcpltUVZ1WmRgg"},"sample_url":"http://www.google.com/patents/reader?id=jzxNBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>