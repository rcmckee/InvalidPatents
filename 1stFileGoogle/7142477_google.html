<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7142477 - Memory interface system and method for reducing cycle time of sequential ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Memory interface system and method for reducing cycle time of sequential read and write accesses using separate address and data buses"><meta name="DC.contributor" content="Thinh Tran" scheme="inventor"><meta name="DC.contributor" content="Joseph Tzou" scheme="inventor"><meta name="DC.contributor" content="Suresh Parameswaran" scheme="inventor"><meta name="DC.contributor" content="Cypress Semiconductor Corp." scheme="assignee"><meta name="DC.date" content="2004-6-18" scheme="dateSubmitted"><meta name="DC.description" content="A memory interface system and method are provided for transferring data between a memory controller and an array of storage elements. The storage elements are preferably SRAM elements, and the memory interface is preferably one having separate address bus paths and separate data bus paths. One address bus path is reserved for receiving read addresses and the other address bus path is reserved for receiving write addresses. One of the data bus paths is reserved for receiving read data from the array, and the other data bus path is reserved for receiving data written to the array. While bifurcating the address and data bus paths within the interface is transparent to the memory controller, the separate paths afford addressing phases of a read and write address operation to be partially overlapped, as well as the data transfer phases. This will essentially reduce the cycle time between a read and write memory access, and proves useful when maximizing the data throughput across the data bus when implementing double data rate (QDR) mechanisms."><meta name="DC.date" content="2006-11-28" scheme="issued"><meta name="DC.relation" content="US:20020023200:A1" scheme="references"><meta name="DC.relation" content="US:20020054532:A1" scheme="references"><meta name="DC.relation" content="US:6026050" scheme="references"><meta name="citation_reference" content="&quot;General DDR SDRAM Functionality,&quot; (C) 2001 Micron Technology, Inc., pp. 1-11."><meta name="citation_patent_number" content="US:7142477"><meta name="citation_patent_application_number" content="US:10/871,825"><link rel="canonical" href="http://www.google.com/patents/US7142477"/><meta property="og:url" content="http://www.google.com/patents/US7142477"/><meta name="title" content="Patent US7142477 - Memory interface system and method for reducing cycle time of sequential read and write accesses using separate address and data buses"/><meta name="description" content="A memory interface system and method are provided for transferring data between a memory controller and an array of storage elements. The storage elements are preferably SRAM elements, and the memory interface is preferably one having separate address bus paths and separate data bus paths. One address bus path is reserved for receiving read addresses and the other address bus path is reserved for receiving write addresses. One of the data bus paths is reserved for receiving read data from the array, and the other data bus path is reserved for receiving data written to the array. While bifurcating the address and data bus paths within the interface is transparent to the memory controller, the separate paths afford addressing phases of a read and write address operation to be partially overlapped, as well as the data transfer phases. This will essentially reduce the cycle time between a read and write memory access, and proves useful when maximizing the data throughput across the data bus when implementing double data rate (QDR) mechanisms."/><meta property="og:title" content="Patent US7142477 - Memory interface system and method for reducing cycle time of sequential read and write accesses using separate address and data buses"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("dlTsU_7TOYS7sQSM0YCgDw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CZE"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("dlTsU_7TOYS7sQSM0YCgDw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CZE"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7142477?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7142477"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=gCd4BAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7142477&amp;usg=AFQjCNEXLXzFYtdHyiVTzbz3YXwrrHoFOA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7142477.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7142477.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7142477" style="display:none"><span itemprop="description">A memory interface system and method are provided for transferring data between a memory controller and an array of storage elements. The storage elements are preferably SRAM elements, and the memory interface is preferably one having separate address bus paths and separate data bus paths. One address...</span><span itemprop="url">http://www.google.com/patents/US7142477?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7142477 - Memory interface system and method for reducing cycle time of sequential read and write accesses using separate address and data buses</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7142477 - Memory interface system and method for reducing cycle time of sequential read and write accesses using separate address and data buses" title="Patent US7142477 - Memory interface system and method for reducing cycle time of sequential read and write accesses using separate address and data buses"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7142477 B1</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 10/871,825</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Nov 28, 2006</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jun 18, 2004</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jun 18, 2004</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">10871825, </span><span class="patent-bibdata-value">871825, </span><span class="patent-bibdata-value">US 7142477 B1, </span><span class="patent-bibdata-value">US 7142477B1, </span><span class="patent-bibdata-value">US-B1-7142477, </span><span class="patent-bibdata-value">US7142477 B1, </span><span class="patent-bibdata-value">US7142477B1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Thinh+Tran%22">Thinh Tran</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Joseph+Tzou%22">Joseph Tzou</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Suresh+Parameswaran%22">Suresh Parameswaran</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Cypress+Semiconductor+Corp.%22">Cypress Semiconductor Corp.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7142477.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7142477.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7142477.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (3),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (1),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (9),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (10),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7142477&usg=AFQjCNF-B5reuDCI6zAnejINlcd405tMlA">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7142477&usg=AFQjCNFTvm9HU9UxC5LgKmNDat8kHe0n7A">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7142477B1%26KC%3DB1%26FT%3DD&usg=AFQjCNHc0Pcy8BR3pajKJVcMzNvEQyBbUA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55669092" lang="EN" load-source="patent-office">Memory interface system and method for reducing cycle time of sequential read and write accesses using separate address and data buses</invention-title></span><br><span class="patent-number">US 7142477 B1</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA51073728" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">A memory interface system and method are provided for transferring data between a memory controller and an array of storage elements. The storage elements are preferably SRAM elements, and the memory interface is preferably one having separate address bus paths and separate data bus paths. One address bus path is reserved for receiving read addresses and the other address bus path is reserved for receiving write addresses. One of the data bus paths is reserved for receiving read data from the array, and the other data bus path is reserved for receiving data written to the array. While bifurcating the address and data bus paths within the interface is transparent to the memory controller, the separate paths afford addressing phases of a read and write address operation to be partially overlapped, as well as the data transfer phases. This will essentially reduce the cycle time between a read and write memory access, and proves useful when maximizing the data throughput across the data bus when implementing double data rate (QDR) mechanisms.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(7)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7142477B1/US07142477-20061128-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7142477B1/US07142477-20061128-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7142477B1/US07142477-20061128-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7142477B1/US07142477-20061128-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7142477B1/US07142477-20061128-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7142477B1/US07142477-20061128-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7142477B1/US07142477-20061128-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7142477B1/US07142477-20061128-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7142477B1/US07142477-20061128-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7142477B1/US07142477-20061128-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7142477B1/US07142477-20061128-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7142477B1/US07142477-20061128-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7142477B1/US07142477-20061128-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7142477B1/US07142477-20061128-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(15)</span></span></div><div class="patent-text"><div mxw-id="PCLM9122370" lang="EN" load-source="patent-office" class="claims">
  <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
    <div class="claim-text">1. A memory interface system for addressing an array of storage elements, comprising:
<div class="claim-text">a first latch coupled to receive a read address and a write address;</div>
<div class="claim-text">a first path and a second path coupled to an output of the latch for receiving respective said read address and said write address;</div>
<div class="claim-text">a storage device coupled to the second path; and</div>
<div class="claim-text">a multiplexer having a first input coupled to the first path and a second input coupled to the second path for sending the read address into the array before sending the write address stored by the storage device into the array.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
    <div class="claim-text">2. The system as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first and second paths receive respective said read address and said write address during successive portions of a clock cycle.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
    <div class="claim-text">3. The system as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the array of storage elements are coupled to a plurality of word line driver inputs.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
    <div class="claim-text">4. The system as recited in <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the multiplexer comprises a plurality of output conductors directly coupled to the plurality of word line driver inputs for receiving the read address before receiving the write address.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
    <div class="claim-text">5. The system as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first and second paths each comprises a pre-decoder and a buffer, and wherein the write address is sent through the pre-decoder and the buffer upon the second path from the storage device and held within a second latch whose output is directly coupled to the second input upon the first input receiving the read address.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
    <div class="claim-text">6. The system as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first input and the second input are coupled to receive the write address before a read enable signal is received upon a select pin of the multiplexer.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
    <div class="claim-text">7. The system as recited in <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the storage device comprises a set of registers.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00008" num="00008" class="claim">
    <div class="claim-text">8. A method for accessing an array of storage elements, comprising:
<div class="claim-text">storing upon an input to a multiplexer a write address sent over a write address path;</div>
<div class="claim-text">sending upon another input to the multiplexer a read address sent over a read address path in parallel with the write address path;</div>
<div class="claim-text">sensing read data from the array of storage elements sent across a read data path read data accessed by the read address; and</div>
<div class="claim-text">while sensing read data, sending write data across a write data path to be written to the array at the write address.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
    <div class="claim-text">9. The method as recited in <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said storing comprises holding the write address held within a set of registers.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
    <div class="claim-text">10. The method as recited in <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising forwarding the read address from the multiplexer before forwarding the write address.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
    <div class="claim-text">11. The method as recited in <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising forwarding the read address from the multiplexer while storing upon an input to the multiplexer the write address.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
    <div class="claim-text">12. The method as recited in <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said sensing comprises storing the sensed read data in an output buffer while sending the write data across the write data path.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
    <div class="claim-text">13. The method as recited in <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising storing the write data into a set of registers coupled to the write data path while storing the sensed read data in an output buffer coupled to the read data path.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
    <div class="claim-text">14. The method as recited in <claim-ref idref="CLM-00008">claim 8</claim-ref>, further comprising selecting complementary bit lines for sending the write data from the write data path while outputting the read data from the read data path.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
    <div class="claim-text">15. The method as recited in <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said sensing read data comprises sensing a voltage difference between complementary pairs of bit line values stored in the array, and wherein said sending write data comprises driving complementary pairs of bit line values onto the array.</div>
  </div>
</div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES16144914" lang="EN" load-source="patent-office" class="description">
<heading>BACKGROUND OF THE INVENTION</heading> <p num="p-0002">1. Field of the Invention</p>
  <p num="p-0003">This invention relates to semiconductor memory and, more particularly, to a memory interface that transparently separates the read and write address and data buses to achieve a faster sequential read and write cycle time.</p>
  <p num="p-0004">2. Description of the Related Art</p>
  <p num="p-0005">The following descriptions and examples are not admitted to be prior art or conventional by virtue of their inclusion within this section.</p>
  <p num="p-0006">Most computing systems consist of four functional blocks: a microprocessor (or CPU), memory, input/output (I/O) interface, and an I/O device. The CPU is interconnected to the memory and the I/O interface via an address bus and a data bus. The address bus provides a path in which the CPU can select certain storage locations in which data is stored. The data bus provides a path over which data is transferred between the CPU, memory, and the I/O interface. Most microprocessors handle bits in 16, 32, or 64 bit groups. Thus, the address bus and data bus are normally 16, 32, or 64 bits wide.</p>
  <p num="p-0007">The mechanism by which a CPU or I/O interface accesses memory depends on the type of memory being accessed. There are numerous types of memories available in the marketplace. For example, data can be stored in magnetic memory, such as a hard disk drive, or stored in memory elements upon an integrated circuit, sometimes referred to as “semiconductor memory.” Semiconductor memory is typically arranged closer to the CPU or execution unit than a hard disk drive and, therefore, can be accessed much faster than magnetic memory.</p>
  <p num="p-0008">Common to semiconductor memory is an array of storage elements. Depending on the type of semiconductor memory, each storage element can have a significantly different architecture and function. For example, a storage element can be volatile or non-volatile. Types of volatile memory include memory that must be periodically refreshed (DRAMs) or memory that will lose its programmed state if power is removed (SRAMs).</p>
  <p num="p-0009">The differences between SRAMs and DRAMs are fairly significant. Each storage element of SRAM includes latch and pass transistors. Conversely, each cell of DRAM involves simply one transistor and a capacitive storage element. While DRAMs are significantly denser than SRAMs, DRAMs require additional support circuitry to coordinate the accesses of each element, along with the need to periodically refresh that element.</p>
  <p num="p-0010">SRAMs typically implement complementary bit lines and bit line signals and enjoy the benefits of faster access times than DRAMs. SRAMs are oftentimes used as the primary cache of the CPU, whereas DRAMs are generally used as the main semiconductor memory. SRAM has a faster access time than DRAM since performance of a read operation simply involves asserting an address, asserting a chip select line, and a read/write enable signal. The requested data will then appear sometime thereafter upon the data lines.</p>
  <p num="p-0011">As used herein, the term “access time” for a read operation, for example, is the time between when an address is placed on the address bus and the addressed data appears on the data bus. Access time often gauges the speed of the memory, which is the time from assertion of a valid address to valid data (read operation), or to completion of the write into the array (write operation).</p>
  <p num="p-0012">Even with fast access time associated with SRAM, one memory access cannot be rapidly followed by another memory access. The time from one memory access to the next is often referred to as the “cycle time.” For SRAM, cycle time is generally equal to the access time. Therefore, in an SRAM, a write operation must wait until the read operation has completed before the write operation can begin. This is due primarily to the address bus and data bus needing to be free of the previous operation before new addresses and data are presented on those respective buses. The problem of having a cycle time constraint on conventional SRAM is made more profound with the advent of newer double data rate (DDR) SRAM.</p>
  <p num="p-0013">DDR memory allows data to be captured at a rate of twice the frequency of the clock signal sent along the control bus. This is accomplished by utilizing a 2n prefetch architecture, where the internal data bus of the DDR memory is twice the “n” width of the external data bus to allow data capture of twice per system clock cycle. A special form of DDR, when implementing both read and write accesses during the same cycle is referred to as quad data rate (QDR) SRAM. Under QDR transfer mechanisms, the internal data bus allows external data to be captured at four times per system clock cycle. Details of the difference between single data rate (SDR) and DDR, and the ramifications for QDR memories can be found in “General DDR SDRAM Functionality,” Micron Technology, 2001 (herein incorporated by reference).</p>
  <p num="p-0014">While both SDR and QDR memory devices generally include the same array of storage elements, the input/output memory interface is considerably different. For example, QDR utilizes a differential pair of system clock signals to formulate the triggering rising and falling clock edges, and data strobe signals are needed to drive the data signal to and from the QDR-accessed memory banks. The differential system clock signals and the data strobe signals can allow accesses to occur and data to be strobed every one-half cycle of the system clock. Data throughput can, therefore, be substantially increased at a 2× factor.</p>
  <p num="p-0015">While it would be beneficial to implement QDR SRAM with faster access time than DRAM, it would also be beneficial to reduce the cycle time between accesses. A desired solution should be one that can implement QDR SRAM accesses, but with subsequent accesses occurring partially concurrent with the previous accesses in order to reduce the cycle time, and therefore take full advantage of a high-speed system clock implemented in a QDR methodology.</p>
  <heading>SUMMARY OF THE INVENTION</heading> <p num="p-0016">The problems outlined above are solved by an improved semiconductor memory and, more specifically, a QDR SRAM that can output data in multiples of each every clock cycle of the system clock. The system clock, synchronous with the data strobe, is sent with the control bus between the functional elements of the CPU, memory, and I/O interface. By transferring data to and from the memory each one-half clock cycle of the system clock, data throughput across the data bus is substantially increased. To take full advantage of this increased throughput, however, cycle times of a read operation, followed by a write operation (i.e., read access followed by a write access) is reduced. The reduced cycle time is preferably achieved using separate address and data buses internal to a memory interface of the SRAM. While the memory and data buses are bifurcated within the memory interface, the data and address buses are not bifurcated outside of the memory interface and, specifically, are not bifurcated between the interface-fitted memory and a CPU or I/O interface. Therefore, outside of the memory interface, neither the address bus nor the data bus appear as bifurcated and, in fact, are not bifurcated. Only internal to the interface, and transparent to a user and system designer, is the address bus and data bus bifurcated.</p>
  <p num="p-0017">Bifurcation of the address and data buses are achieved by forming two paths in the interface. A first path of the address bus can receive a read address, and a second path can receive a write address. The write address can be stored in one or more registers along the second path. While the read address can be multiplexed into the array first, the write address is nonetheless prefetched and stored at or near the input of the multiplexer in readiness for the subsequent write operation. The output of the multiplexer is connected directly into the array and, therefore, all prefetching involved with decoding and making the address available has previously taken place, so that the write address can be immediately presented to the array once the data is read from the array during the previous read operation. Separating the read and write address paths into a bifurcated address bus allows faster addressing and, specifically, overlapping a portion of the write address with the read address to lower the cycle time.</p>
  <p num="p-0018">In addition to the bifurcation of the address bus, the data bus is also bifurcated internal to the memory interface. As data is being read from the array using sense amplifiers, the data can be stored in buffers within a read data path, while write data is sent to the array across a write data path. The data to be written to the array can occur across the write data path partially and contemporaneous with data being read from the array across the read data path. Similar to the read address and write address paths, the read data and write data paths allow concurrent movement of data and partial overlap of the read and write operations to lower the memory cycle time. The data paths are separated because the address paths are separated and, therefore, partially concurrent read/write addressing follows hand-in-hand with partially concurrent read and write data.</p>
  <p num="p-0019">According to one embodiment, a memory interface system is provided. The memory interface includes a first latch coupled to receive a read address and write address. The first path and the second path are coupled to an output of the latch for receiving the read address and the write address along those respective paths. A storage device, such as a register, is coupled to the second path. A multiplexer having a first input and a second input is coupled to the respective first and second paths for sending the read address into the array before sending the write address. The array is preferably an SRAM device, and preferably the first and second paths each comprise a predecoder and a buffer. The write address is sent through the predecoder and the buffer upon the second path from the storage device, and held within a second latch whose output is directly coupled to the second input upon the first input of the multiplexer receiving the read address. The first input and the second input of the multiplexer are preferably coupled to receive the write address before a read enable signal is received upon a select pin of the multiplexer.</p>
  <p num="p-0020">In addition to the memory interface system for addressing an array of storage elements, the memory interface system also includes a system for sending read data from and write data to the array of storage elements. The system which sends read data from and write data to the array includes a first data path and a second data path. The first path includes a sense amplifier and a buffer. The sense amplifier is coupled to sense read data from the array and the buffer is coupled to the sense amplifier for storing the read data. The second path includes a storage device and a write driver. The storage device is coupled to store write data sent to the array contemporaneous with the sense amplifier coupled to sense read data. The write driver is further coupled to drive the stored write data contemporaneous with the output buffer storing the read data.</p>
  <p num="p-0021">According to yet another embodiment, a method is provided for accessing (i.e., addressing, reading, and writing data) an array of storage elements. The method includes storing upon an input to a multiplexer a write address sent over a write address path. Upon another input of the multiplexer, a read address is sent over a read address path in parallel with the write address path. Then, read data is sensed from the array of storage elements sent across a read data path. While sensing the read data, write data is sent across a write data path to be written to the array at the write address.</p>
<description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0022">Other objects and advantages of the invention will become apparent upon reading the following detailed description and upon reference to the accompanying drawings in which:</p>
    <p num="p-0023"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram of an execution engine, memory controller, memory, and memory interface that receives address, control, data and clock signals from the memory controller and bifurcates the address and data buses internal to the interface into separate read and write address and data paths into and from the memory for faster cycle time from one memory access to the next;</p>
    <p num="p-0024"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a block diagram of the memory interface, according to one embodiment, coupled to a memory array;</p>
    <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a timing diagram of signals at various nodes of the memory interface of <figref idrefs="DRAWINGS">FIG. 2</figref>;</p>
    <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a block diagram of the memory interface, according to a preferred embodiment, coupled to a memory array;</p>
    <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a timing diagram of signals at various nodes of the memory interface of <figref idrefs="DRAWINGS">FIG. 4</figref>; and</p>
    <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a state diagram of sequential states shown in the timing diagram of <figref idrefs="DRAWINGS">FIG. 5</figref>.</p>
  </description-of-drawings> <p num="p-0029">While the invention is susceptible to various modifications and alternative forms, specific embodiments hereof are shown by way of example in the drawings and will herein be described in detail. It should be understood, however, that the drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed, but on the contrary, are intended to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the present invention as defined by the appended claims.</p>
  <heading>DETAILED DESCRIPTION OF PREFERRED EMBODIMENTS</heading> <p num="p-0030">Turning now to the drawings, <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates various functional blocks of a computing system <b>10</b>. System <b>10</b> includes a microprocessor or CPU <b>12</b>. CPU <b>12</b> is oftentimes referred to as an execution engine or processor. Most CPUs are known to incorporate two operational units: an integer unit and a floating-point unit. These units communicate data via a data cache and are controlled by a single instruction stream supplied by an instruction cache. The data cache and instruction cache can be connected to memory <b>14</b> if desired by a memory controller <b>16</b>. The instruction cache can supply multiple instructions per fetch if, for example, CPU <b>12</b> is a superscalar processor. The actual number of instructions fetched can vary. As the instructions are dispatched from the instruction cache, a decoder will decode those instructions and place them into a prefetch unit, and finally into the execution engine. Any out-of-order conditions can be resolved by a reorder buffer, which places those instructions back into a register file and, thereafter, into the prefetch unit for re-execution. The general implementations of superscalar architecture RISC and CISC instruction sets, as well as integer and floating-point units, prefetch unit, and reorder buffers are generally known to those skilled in microprocessor architecture.</p>
  <p num="p-0031">Communication between CPU <b>12</b>, I/O interface <b>18</b>, and memory controller <b>16</b> occur across a local bus or, possibly, a mezzanine or peripheral bus such as a PCI bus associated with I/O interface <b>18</b>. The bus architecture generally involves a control bus, a data bus, and an address bus of varying widths. The functional units are typically synchronized to a master clock, oftentimes referred to as a system clock sent along the control bus. The memory controller can either by synchronized to the system clock on the control bus or synchronized to its own controller clock. Synchronizing the controller clock and the system clock at the same frequency will cause synchronous accesses to the memory and, to take advantage of the synchronous accesses, synchronous memory systems are employed. Popular synchronous memory includes SDRAM and, specifically, SRAM.</p>
  <p num="p-0032">Memory controller <b>16</b> is shown connected to a memory interface <b>20</b> hereof. Memory controller <b>16</b> sends the conventional control, address, data, and system clock signals into memory interface <b>20</b> and, therefore, it is transparent to the user what memory interface <b>20</b> does to those signals by bifurcating the control and address signals as will be described herein below. The clock signal (CLK) can be used to form a data strobe, and can be formed into a complementary pair of clock signals from which a QDR operation can ensue. If so, if the system clock (CLK) transitions at, for example, 150 MHz, then the data transfer rate across the data bus might be 300 MHz if memory <b>14</b> is synchronous to CLK. Details of memory interface <b>20</b> operation and architecture are described in two embodiments, beginning with <figref idrefs="DRAWINGS">FIGS. 2 and 3</figref>, followed by <figref idrefs="DRAWINGS">FIGS. 4 and 5</figref>. The preferred embodiment is shown in <figref idrefs="DRAWINGS">FIGS. 4 and 5</figref>, however.</p>
  <p num="p-0033">Turning now to <figref idrefs="DRAWINGS">FIGS. 2 and 3</figref> in conjunction, <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates a memory interface <b>20</b> connected to memory <b>14</b>. Memory interface <b>20</b> includes a buffer <b>22</b> connected to receive addresses sent across the address bus. Buffer <b>22</b> is essentially a circuit that does not alter the logic values of the address bits going through it, yet provides isolation of those values at the output of buffer <b>22</b>. If the address bus constitutes 16 bit values, for example, then buffer <b>22</b> will retain those values and place the same logic values received upon its output to latch <b>24</b>.</p>
  <p num="p-0034">Latch <b>24</b> involves either one omnibus latch or a plurality of latches coupled to receive the buffered address bits which are sampled, for example, on the rising edges of the system clock. If QDR is employed, then the address bus is sampled on both the rising and falling edges of the system clock. Latch <b>24</b> is preferably a gated latch and, more specifically, involves a transparent mode of operation. When enabled, the outputs from latch <b>24</b> will follow the inputs, and the output will hold the last value placed into the input when disabled. The inputs are gated by the clock signal (CLK). For example, beginning at the rising edge of the clock signal, the read address bit values on the address bus are sampled and passed onto latch <b>24</b> output, and during after the falling edge of the clock signal, those outputs are held in conformance with the transparent mode. However, beginning with the falling edge of the clock signal, write addresses are sampled and thereafter held after the rising edge of the clock signal.</p>
  <p num="p-0035">Output from latch <b>24</b> is thereby channeled based on the phase of the clocking signal to either a read address path or a write address path. Within the write address path is a storage device <b>26</b>. Preferably, the storage device includes one or more registers that sample and hold write address bit values on the rising edges of an internal clock, referred to as IN_WR_CLK. More than one register may be needed depending on the depth of the write pipeline. In the example of <figref idrefs="DRAWINGS">FIG. 2</figref>, two registers <b>27</b> <i>a </i>and <b>27</b> <i>b </i>are provided.</p>
  <p num="p-0036">The bit values sent over the read and write address paths are held on the input of multiplexer <b>28</b> or within storage device <b>26</b> (subsequently held at the input of multiplexer <b>28</b>). The impedance to multiplexer <b>28</b> prevents substantial loss of voltage values so that whatever set of address bits are placed on those inputs, the values will remain for at least one cycle of the clocking signal.</p>
  <p num="p-0037">A read enable (RD_EN) and a write enable (WR_EN) signal synchronized to the rising and falling edges of the clocking signal determine whether the read address bit values or the write address bit values are forwarded to a predecoder <b>30</b>, buffer <b>32</b>, and finally to the word-line drivers <b>34</b> of memory array <b>14</b>. Thus, connected to the select input of multiplexer <b>28</b> is the read enable and write enable signal. Decoder <b>30</b> essentially functions to convert, for example, a binary coded decimal (BCD) input of 2n states to an n decimal value. The n values then feed directly to each word line of driver <b>34</b> after those values have been appropriately buffered and voltaged by buffer <b>32</b>.</p>
  <p num="p-0038">Whatever read or write address is placed into the word-line drivers <b>34</b>, is also placed into a column select circuit <b>36</b>. Although not shown for brevity and clarity in the drawing, the column select circuitry <b>36</b> responds to the incoming address, similar to driver <b>34</b>, by selecting a particular pair of bit lines (bl and blb). The pair of bit lines are oftentimes referred to as complementary bit lines, with bl representing the true voltage value and blb representing the inverted voltage value. In this fashion, the address signals can address the particular storage element within array <b>14</b>. Column select circuit <b>36</b> is shown placed within a data path by which incoming date (during a write operation) or outgoing data (during a read operation) traverse.</p>
  <p num="p-0039">Outgoing data can be sensed by sense amplifier <b>38</b>. Sense amplifier <b>38</b> essentially compares the differential voltage values on the complementary bit lines or data lines (dl and dlb). The sensed voltage difference can then be output on the complementary data input/output lines (dio and diob) onto input/output buffer <b>40</b>. If, instead of a read operation, a write operation forces data to be written to array <b>14</b> that is originally sent into buffer <b>40</b>, and then driven onto the column select circuit <b>36</b> via a write driver circuit <b>42</b>. The operation of the read/write addressing and read/write data paths of interface <b>20</b> in <figref idrefs="DRAWINGS">FIG. 2</figref> is further illustrated in <figref idrefs="DRAWINGS">FIG. 3</figref>.</p>
  <p num="p-0040"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a timing diagram of read and write operations and, specifically, shows a read operation followed by a write operation, both of which occur during a single clock cycle of the system clock. When the system clock transitions to a logic high voltage value, a read address (RD_ADDR) will appear at the time <b>46</b>. Synchronized to the rising and falling edges of the clock is a read enable and write enable signal. The read enable and write enable signals can be formed using, for example, a one-shot circuit having an a-stable state maintained by the specification of the one-shot. Thus, at time <b>48</b>, the read address on the input of the multiplexer <b>28</b> (<figref idrefs="DRAWINGS">FIG. 2</figref>) will be sent into the predecoder <b>30</b>, buffer <b>32</b> (<figref idrefs="DRAWINGS">FIG. 2</figref>), and then at time <b>50</b>, a read access will occur by the word-line drivers driving the appropriate word lines onto memory array <b>14</b> (<figref idrefs="DRAWINGS">FIG. 2</figref>). The data addressed by the read address will then emanate from array <b>14</b> and be sensed by the sense amplifier <b>38</b>, and thereafter placed on the input/output buffer <b>40</b> (<figref idrefs="DRAWINGS">FIG. 2</figref>). This will cause the sense amplifier to release the complementary data lines at time <b>52</b>. Once the complementary data lines are released, then a write operation can occur, beginning with a write address pre-existing upon the storage device <b>26</b>.</p>
  <p num="p-0041">Comparing <figref idrefs="DRAWINGS">FIGS. 2 and 3</figref>, the write address would normally occur upon a falling edge of the system clock, however, since the register is essentially buffer or delay the write address, the write address does not appear until sometime thereafter. Thus, even though the write address exists at the input of multiplexer <b>28</b>, it is not until the write enable signal is activated during the falling edge of the clock signal that the write address will be sent into the predecoder <b>30</b> and buffer <b>32</b>, as shown by reference numeral <b>54</b>. Thereafter, reference numeral <b>56</b> indicates data being driven onto the corresponding bit lines via the write driver <b>42</b> and column select circuit <b>36</b>. Thereafter, the properly activated word line drivers <b>34</b> will allow a write access into the array <b>14</b>, as noted by reference numeral <b>58</b>.</p>
  <p num="p-0042"> <figref idrefs="DRAWINGS">FIGS. 2 and 3</figref> illustrate bifurcation of the read and write address paths, as well as bifurcation of the read and write data paths. However, the time delay through predecoder <b>30</b> and buffer <b>32</b>, prohibits effective overlap of certain operations within the write cycle with those of the read cycle. Thus, the write access cannot begin until the read access has completed. To do otherwise would involve contention within the shared address line through predecoder <b>30</b>, buffer <b>32</b>, and I/O buffer <b>40</b>. Thus, the cycle time from the read access operation to the write access operation is somewhat long since various portions of those operations cannot be overlapped. Therefore, a more preferred interface circuit with shorter cycle time is desired. The preferred interface circuit and timing diagram are illustrated in <figref idrefs="DRAWINGS">FIGS. 4 and 5</figref>.</p>
  <p num="p-0043">Referring to <figref idrefs="DRAWINGS">FIGS. 4 and 5</figref> in conjunction, an alternative and preferred embodiment for a memory interface <b>60</b> is illustrated having address buffer <b>62</b>, latch <b>64</b>, storage device <b>66</b>, with one or more registers <b>67</b> <i>a/b</i>, similar to items <b>22</b>–<b>27</b> <i>b </i>(<figref idrefs="DRAWINGS">FIG. 2</figref>). However, instead of placing multiplexer <b>68</b> in the read and write address paths prior to the predecoder (as in <figref idrefs="DRAWINGS">FIG. 2</figref>), multiplexer <b>68</b> is placed post the predecoder and buffer circuits. Also, a predecoder <b>70</b> <i>a/b </i>and buffer <b>72</b> <i>a/b </i>are provided on each of the bifurcated paths. Items <b>62</b>–<b>72</b> operate identical to items <b>22</b>–<b>32</b> of <figref idrefs="DRAWINGS">FIG. 2</figref>. In addition, a second latch <b>73</b> is provided in the embodiment of <figref idrefs="DRAWINGS">FIG. 4</figref>.</p>
  <p num="p-0044">Latch <b>73</b> is also a transparent latch, similar to latch <b>64</b> in <figref idrefs="DRAWINGS">FIG. 2</figref>. However, instead of being clocked by the system clock, latch <b>73</b> is clocked by another internally generated clock (IN_WR_CLK<b>2</b>), similar to IN_WR_CLK (<figref idrefs="DRAWINGS">FIG. 3</figref>) or IN_WR_CLK<b>1</b> (<figref idrefs="DRAWINGS">FIG. 4</figref>). IN_WR_CLK<b>2</b> is generated from a one-shot that is synchronized and delayed relative to a rising or falling edge of the system clock. The second internal clock (i.e., IN_WR_CLK<b>2</b>) is preferably advanced in time relative to the first internal clock (i.e., IN_WR_CLK<b>1</b>), so that the first internal clock will present the write addresses in sequence to the predecoder <b>70</b> <i>b </i>and, thereafter, the second internal clock will latch those sequential write addresses onto multiplexer <b>68</b>. In this fashion, the write address pipeline is not disturbed.</p>
  <p num="p-0045">In addition to the more elongated read and write address paths, a more elongated read and write data paths are provided. Similar to column select circuit <b>36</b>, sense amplifier <b>38</b>, and write driver <b>42</b> of circuit <b>20</b>, circuit <b>60</b> illustrates identical function and structure for column select circuit <b>76</b>, sense amplifier <b>78</b>, and write driver <b>82</b>. However, instead of the input/output buffer <b>40</b> being bidirectional, a substitute output-only buffer <b>80</b> is provided in the read data path. In the separate write data path in which write driver <b>82</b> is provided, registers and another buffer <b>84</b> are provided. In this fashion, read data can be stored in the output buffer <b>80</b>, while write data is written into the column select circuit <b>76</b> via the write data bus, on which write driver <b>82</b> and registers <b>84</b> are coupled. This allows the read data to traverse the read data path while the write data traverses the write data path at the same time as the read data.</p>
  <p num="p-0046">Circuit <b>60</b> allows the read address information to be stored and placed closer to the memory array <b>14</b> in readiness for a write enable signal than circuit <b>20</b>. This ensures that the write address information is placed through the time-delayed buffer <b>72</b> <i>b </i>as the read address traverses the read address path. Therefore, portions of the read and write address operations can overlap one another. Moreover, circuit <b>60</b> allows the read data to be output and stored along the read data path at the same time as write data is initiated onto the column select circuit. Again, circuit <b>60</b> allows overlap of data read and write operations. <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates in more detail that overlap functionality and the advantages thereof.</p>
  <p num="p-0047"> <figref idrefs="DRAWINGS">FIG. 5</figref> is best illustrated in reference to the state diagram of <figref idrefs="DRAWINGS">FIG. 6</figref>. State diagram <b>90</b> includes certain states A–G corresponding to the states of <figref idrefs="DRAWINGS">FIG. 5</figref>. Referring to <figref idrefs="DRAWINGS">FIGS. 5 and 6</figref> in conjunction, during a previous write operation in which the clocking signal is at a logic low voltage value, and the second internal clock transitions high, whatever was present within latch <b>73</b> is selected as a write address placed into the memory array. This represents a previous write access occurring at state A (see reference <b>92</b> in <figref idrefs="DRAWINGS">FIG. 6</figref>). Whatever data values that are driven from the write driver <b>82</b> will then be placed into the memory array <b>14</b> during the previous write access. Those data values are thereafter cleared, as well as the column select circuitry <b>76</b> and the register driver values on buffer <b>84</b>.</p>
  <p num="p-0048">At state B (see reference <b>94</b> in <figref idrefs="DRAWINGS">FIG. 6</figref>), the first internal clock signal is transitioned to a logic high voltage value causing the current write address to be stored within storage device <b>66</b>. The stored write address values will then be placed as a write address at state C onto the predecoder <b>70</b> <i>b</i>, buffer <b>72</b> <i>b</i>, and the input of latch <b>73</b>. Thus, the write operation indicates the current write address is sent to the predecoder and buffer, beginning at state B/C. Even before the write address is placed upon latch <b>73</b>, a read address can be initiated by the rising edge of the system clock at state D (see reference <b>96</b> in <figref idrefs="DRAWINGS">FIG. 6</figref>). Thus, an overlap <b>98</b> occurs between the read and write addressing operations due to the separate read and write address bus paths.</p>
  <p num="p-0049">Once state D has begun, then whatever is sent along the read address path is forwarded to the word-line driver <b>34</b> to begin the read access of memory array <b>14</b>. Data read from array <b>14</b> will be sensed by sense amplifier <b>78</b> and placed on output buffer <b>80</b> as the complementary data lines (dl/dlb) are released from their voltage values. This will allow the next step in the write operation to occur by driving the write driver <b>82</b> within the separate write data bus path from the read data bus path on which output buffer <b>80</b> exists. This overlap <b>100</b> is made possible due to the separate read and write data bus paths. The read access and release of the complementary data lines, sense amplifier, and maintaining the read data in the output buffer, while driving the write driver <b>82</b> are shown by states <b>102</b> and <b>104</b> (<figref idrefs="DRAWINGS">FIG. 6</figref>). Noticeably, state <b>104</b> indicates overlap <b>100</b> in the separate read and write data paths.</p>
  <p num="p-0050">Next, at state E, it is recognized that the read operation has completed and essentially the write address exists at the input of multiplexer <b>68</b>, while the write data exists at the input of the column select circuit <b>76</b>. Thus, when state E occurs by asserting the second internal clock at the input of multiplexer <b>68</b>, knowing that write enable has been previously asserted at the beginning of the write cycle, the write address will be sent to the memory array to initiate a write access for the current write address. Thus, the write enable signal occurs previous to the second internal clock transitioning, to allow immediate write access once that second internal clock transitions to a high logic value. State E is shown as reference <b>106</b> in <figref idrefs="DRAWINGS">FIG. 6</figref> and is equivalent to state A, with the then-existing write access occurring to the array, with the column select circuit reset, along with the write drivers and registers/buffers <b>82</b> and <b>84</b>.</p>
  <p num="p-0051">Thereafter, at state F, the next write address is clocked into storage device <b>66</b> to initiate the write address at the output of storage device <b>66</b>. States F and G are similar to states B and C, which sends the next write address to the latch and holds within the latch to await the second internal clock transition, as shown by state <b>108</b> (<figref idrefs="DRAWINGS">FIG. 6</figref>). Thus, states <b>106</b> and <b>108</b> are equivalent to states <b>92</b> and <b>94</b>, but for a subsequent write cycle occurring. Overlap <b>110</b> is made possible due to the second latch <b>73</b> holding the write address that has been pre-decoded and buffered at the input of multiplexer <b>68</b>.</p>
  <p num="p-0052">Numerous variations and modifications will become apparent to those skilled in the art once the above disclosure is fully appreciated. It is intended that the following claims are to be interpreted to embrace all such variations and modifications. In addition, the foregoing description is illustrative of only exemplary embodiments. The disclosure is not to be interpreted as reflecting an intention that the claimed invention requires more features than are expressly recited in each claim. The specification and drawings are to be regarded in an illustrative rather than a restrictive sense.</p>
</div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6026050">US6026050</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 10, 1999</td><td class="patent-data-table-td patent-date-value">Feb 15, 2000</td><td class="patent-data-table-td ">Micron Technology, Inc.</td><td class="patent-data-table-td ">Method and apparatus for adaptively adjusting the timing of a clock signal used to latch digital signals, and memory device using same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020023200">US20020023200</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 9, 2001</td><td class="patent-data-table-td patent-date-value">Feb 21, 2002</td><td class="patent-data-table-td ">Ryan Kevin J.</td><td class="patent-data-table-td ">Method and apparatus for synchronous data transfers in a memory device with selectable data or address paths</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020054532">US20020054532</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 7, 2002</td><td class="patent-data-table-td patent-date-value">May 9, 2002</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Semiconductor memory device having function of supplying stable power supply voltage</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="General+DDR+SDRAM+Functionality%2C"'>General DDR SDRAM Functionality,</a>" (C) 2001 Micron Technology, Inc., pp. 1-11.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8149643">US8149643</a></td><td class="patent-data-table-td patent-date-value">Oct 23, 2008</td><td class="patent-data-table-td patent-date-value">Apr 3, 2012</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Memory device and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8219778">US8219778</a></td><td class="patent-data-table-td patent-date-value">Feb 27, 2008</td><td class="patent-data-table-td patent-date-value">Jul 10, 2012</td><td class="patent-data-table-td ">Microchip Technology Incorporated</td><td class="patent-data-table-td ">Virtual memory interface</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8358557">US8358557</a></td><td class="patent-data-table-td patent-date-value">Sep 26, 2011</td><td class="patent-data-table-td patent-date-value">Jan 22, 2013</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Memory device and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8645617">US8645617</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 15, 2009</td><td class="patent-data-table-td patent-date-value">Feb 4, 2014</td><td class="patent-data-table-td ">Rambus Inc.</td><td class="patent-data-table-td ">Memory device for concurrent and pipelined memory operations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8705310">US8705310</a></td><td class="patent-data-table-td patent-date-value">Dec 26, 2012</td><td class="patent-data-table-td patent-date-value">Apr 22, 2014</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Access methods and circuits for memory devices having multiple banks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110208905">US20110208905</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 15, 2009</td><td class="patent-data-table-td patent-date-value">Aug 25, 2011</td><td class="patent-data-table-td ">Rambus Inc.</td><td class="patent-data-table-td ">Non-Volatile Memory Device For Concurrent And Pipelined Memory Operations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120008378">US20120008378</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 8, 2011</td><td class="patent-data-table-td patent-date-value">Jan 12, 2012</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Memory devices and methods having multiple address accesses in same cycle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20140006730">US20140006730</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 29, 2012</td><td class="patent-data-table-td patent-date-value">Jan 2, 2014</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Memory controller devices, systems and methods for high reliability memory devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2009108590A1?cl=en">WO2009108590A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 23, 2009</td><td class="patent-data-table-td patent-date-value">Sep 3, 2009</td><td class="patent-data-table-td ">Zerog Wireless, Inc.</td><td class="patent-data-table-td ">Virtual memory interface</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc365/defs365.htm&usg=AFQjCNEzHaQGuetTtzY59oDtginiG6P-0A#C365S230020">365/230.02</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc365/defs365.htm&usg=AFQjCNEzHaQGuetTtzY59oDtginiG6P-0A#C365S230010">365/230.01</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc365/defs365.htm&usg=AFQjCNEzHaQGuetTtzY59oDtginiG6P-0A#C365S230080">365/230.08</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G11C0008000000">G11C8/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11C8/18">G11C8/18</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11C11/417">G11C11/417</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=gCd4BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11C7/1066">G11C7/1066</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G11C7/10R7</span>, <span class="nested-value">G11C8/18</span>, <span class="nested-value">G11C11/417</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">May 23, 2014</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 12, 2012</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 8-15 IS CONFIRMED. CLAIM 1 IS DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 2-4 AND 7, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. NEW CLAIMS 16-79 ARE ADDED AND DETERMINED TO BE PATENTABLE. CLAIMS 5 AND 6 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 30, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110718</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 18, 2010</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 18, 2004</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CYPRESS SEMICONDUCTOR CORP., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:TRAN, THINH;TZOU, JOSEPH;PARAMESWARAN, SURESH;REEL/FRAME:015497/0689</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20040615</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0Tbb3e_9p8sTCRZEXRZfLIUnaYjg\u0026id=gCd4BAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U1q2T0KJ-AZIkzZ1cTR1qpcQ_oTKg\u0026id=gCd4BAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1AWw3GAMv9KB-VYgEWg4w6D6A1rA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Memory_interface_system_and_method_for_r.pdf?id=gCd4BAABERAJ\u0026output=pdf\u0026sig=ACfU3U08xT1zKejbv6o4GokCDbd0nRzsYw"},"sample_url":"http://www.google.com/patents/reader?id=gCd4BAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>