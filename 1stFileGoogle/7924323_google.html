<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7924323 - Method and apparatus for automatically capturing and managing images - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method and apparatus for automatically capturing and managing images"><meta name="DC.contributor" content="Jay S. Walker" scheme="inventor"><meta name="DC.contributor" content="James A. Jorasch" scheme="inventor"><meta name="DC.contributor" content="Russell P. Sammon" scheme="inventor"><meta name="DC.contributor" content="Walker Digital, Llc" scheme="assignee"><meta name="DC.date" content="2004-12-23" scheme="dateSubmitted"><meta name="DC.description" content="According to one embodiment of the invention, a camera determines whether to acquire an image (e.g., automatically), determines whether to store the acquired image, and determines how to store the acquired image."><meta name="DC.date" content="2011-4-12" scheme="issued"><meta name="DC.relation" content="JP:2000209483" scheme="references"><meta name="DC.relation" content="JP:H11136557" scheme="references"><meta name="DC.relation" content="US:20020054224:A1" scheme="references"><meta name="DC.relation" content="US:20020149689:A1" scheme="references"><meta name="DC.relation" content="US:20030193610:A1" scheme="references"><meta name="DC.relation" content="US:20040056966:A1" scheme="references"><meta name="DC.relation" content="US:20040075756:A1" scheme="references"><meta name="DC.relation" content="US:5266985" scheme="references"><meta name="DC.relation" content="US:5831670" scheme="references"><meta name="DC.relation" content="US:6094215" scheme="references"><meta name="DC.relation" content="US:6301440" scheme="references"><meta name="DC.relation" content="US:6757693" scheme="references"><meta name="DC.relation" content="US:6765612" scheme="references"><meta name="DC.relation" content="US:6847388" scheme="references"><meta name="DC.relation" content="US:6914625" scheme="references"><meta name="DC.relation" content="US:6977680" scheme="references"><meta name="DC.relation" content="US:7286168" scheme="references"><meta name="DC.relation" content="US:7362359" scheme="references"><meta name="DC.relation" content="US:7508444" scheme="references"><meta name="DC.relation" content="US:7701490" scheme="references"><meta name="citation_reference" content="Office Action for Application No. EP 04815525.3, dated Nov. 17, 2009; 4 pp."><meta name="citation_reference" content="Office Action for Australian Application No. 2004311841 mailed Aug. 7, 2007, 1 pg."><meta name="citation_reference" content="Office Action for Canadian Application No. 2,544,135 mailed Nov. 26, 2010, 3 pp."><meta name="citation_reference" content="Office Action for Canadian Application No. 2,554,135 mailed Dec. 30, 2008, 3 pp."><meta name="citation_reference" content="Office Action for European Application No. 04815525.3 mailed Nov. 23, 2007, 5 pp."><meta name="citation_reference" content="Office Action for Japanese Application No. 2006-547417 mailed Sep. 12, 2008, 2 pp."><meta name="citation_reference" content="PCT International Search Report for PCT/US2004/043460 mailed Feb. 16, 2006, 4 pp."><meta name="citation_reference" content="PCT Written Opinion for PCT/US 2004/043460 mailed Jul. 6, 2006, 3 pp."><meta name="citation_reference" content="ProPhoto Home Wireless Image Transmitter, http://www.prophotohome.com/forum/pro-photo-wiki-select-articles/73285-wireless-image-transmitter.html, download date Nov. 2, 2010, 4 pp."><meta name="citation_reference" content="Shutterfly Online Photo Sharing http://www.shutterfly.com/refdesk/get-sub-tran.jsp, download date Nov. 2, 2010, 3 pp."><meta name="citation_reference" content="Shutterfly Online Photo Sharing http://www.shutterfly.com/refdesk/get—sub—tran.jsp, download date Nov. 2, 2010, 3 pp."><meta name="citation_reference" content="Supplementary European Search Report, Aug. 14, 2007, 2 pp."><meta name="citation_reference" content="WiPics From ProPHOTO WIKI, http://www.prophotowiki.com/w/index.php/WiPics, download date Nov. 1, 2010, 3 pp."><meta name="citation_patent_number" content="US:7924323"><meta name="citation_patent_application_number" content="US:11/719,108"><link rel="canonical" href="http://www.google.com/patents/US7924323"/><meta property="og:url" content="http://www.google.com/patents/US7924323"/><meta name="title" content="Patent US7924323 - Method and apparatus for automatically capturing and managing images"/><meta name="description" content="According to one embodiment of the invention, a camera determines whether to acquire an image (e.g., automatically), determines whether to store the acquired image, and determines how to store the acquired image."/><meta property="og:title" content="Patent US7924323 - Method and apparatus for automatically capturing and managing images"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("pkzsU-KZCsKlyASxsYG4Bg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CAN"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("pkzsU-KZCsKlyASxsYG4Bg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CAN"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7924323?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7924323"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=xT7UBgABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7924323&amp;usg=AFQjCNF5UP_Eny1sVNPVRr0YscqeIzAuWQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7924323.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7924323.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20080192129"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US7924323"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7924323" style="display:none"><span itemprop="description">According to one embodiment of the invention, a camera determines whether to acquire an image (e.g., automatically), determines whether to store the acquired image, and determines how to store the acquired image....</span><span itemprop="url">http://www.google.com/patents/US7924323?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7924323 - Method and apparatus for automatically capturing and managing images</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7924323 - Method and apparatus for automatically capturing and managing images" title="Patent US7924323 - Method and apparatus for automatically capturing and managing images"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7924323 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 11/719,108</td></tr><tr><td class="patent-bibdata-heading">PCT number</td><td class="single-patent-bibdata">PCT/US2004/043460</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Apr 12, 2011</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Dec 23, 2004</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Dec 24, 2003</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2554135A1">CA2554135A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2554135C">CA2554135C</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1704710A2">EP1704710A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1704710A4">EP1704710A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8466987">US8466987</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20080192129">US20080192129</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20110128414">US20110128414</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120242844">US20120242844</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2005065283A2">WO2005065283A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2005065283A3">WO2005065283A3</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">11719108, </span><span class="patent-bibdata-value">719108, </span><span class="patent-bibdata-value">PCT/2004/43460, </span><span class="patent-bibdata-value">PCT/US/2004/043460, </span><span class="patent-bibdata-value">PCT/US/2004/43460, </span><span class="patent-bibdata-value">PCT/US/4/043460, </span><span class="patent-bibdata-value">PCT/US/4/43460, </span><span class="patent-bibdata-value">PCT/US2004/043460, </span><span class="patent-bibdata-value">PCT/US2004/43460, </span><span class="patent-bibdata-value">PCT/US2004043460, </span><span class="patent-bibdata-value">PCT/US200443460, </span><span class="patent-bibdata-value">PCT/US4/043460, </span><span class="patent-bibdata-value">PCT/US4/43460, </span><span class="patent-bibdata-value">PCT/US4043460, </span><span class="patent-bibdata-value">PCT/US443460, </span><span class="patent-bibdata-value">US 7924323 B2, </span><span class="patent-bibdata-value">US 7924323B2, </span><span class="patent-bibdata-value">US-B2-7924323, </span><span class="patent-bibdata-value">US7924323 B2, </span><span class="patent-bibdata-value">US7924323B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jay+S.+Walker%22">Jay S. Walker</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22James+A.+Jorasch%22">James A. Jorasch</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Russell+P.+Sammon%22">Russell P. Sammon</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Walker+Digital,+Llc%22">Walker Digital, Llc</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7924323.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7924323.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7924323.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (20),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (13),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (18),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (28),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7924323&usg=AFQjCNE8vDex4iGOoChM5ZHlNURqXHFpVg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7924323&usg=AFQjCNEJRy1-ymd--vpmnigZ8n70d2mP8Q">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7924323B2%26KC%3DB2%26FT%3DD&usg=AFQjCNHEyMkqXZV1abskFYswFadUJxwc3g">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT102151679" lang="EN" load-source="patent-office">Method and apparatus for automatically capturing and managing images</invention-title></span><br><span class="patent-number">US 7924323 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA83977219" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">According to one embodiment of the invention, a camera determines whether to acquire an image (e.g., automatically), determines whether to store the acquired image, and determines how to store the acquired image.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(17)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00014.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00014.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00015.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00015.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7924323B2/US07924323-20110412-D00016.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7924323B2/US07924323-20110412-D00016.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(29)</span></span></div><div class="patent-text"><div mxw-id="PCLM35428051" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A method, comprising:
<div class="claim-text">receiving, at a memory of a digital camera comprising a first device and from a user of the digital camera, one or more indications comprising (i) an indication of one or more conditions which, if satisfied, cause a transmission of an acquired image from the memory of the digital camera; and (ii) an indication of a second device to which the acquired image is to be transmitted upon the one or more conditions being satisfied;</div>
<div class="claim-text">acquiring, at the memory of the digital camera after receiving the one or more indications, an image;</div>
<div class="claim-text">storing the one or more indications;</div>
<div class="claim-text">monitoring the one or more conditions to determine whether the one or more conditions have been satisfied; and</div>
<div class="claim-text">transmitting, upon determining that the one or more conditions have been satisfied, the acquired image to the second device.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, in which transmitting the image to a second device further comprises compressing the acquired image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising deleting the acquired image from the memory.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising storing meta-data associated with the acquired image, wherein the meta-data comprises at least one of position data, orientation data, altitude data, camera settings data, lens setting data, sound annotations, date and time data, cropping data, or scale data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising storing meta-data associated with the acquired image, wherein the meta-data comprises at least one of scene data, illumination data, subject motion data, image content data, or image categorization data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising at least one of modifying the image, cropping the image, rotating the image, filtering the image, adding a meta tag to the image, or displaying the image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising selecting at least one of a sports mode, a portrait mode, a sunny mode, or a sunset mode.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising selecting at least one of a fluorescent light mode, a power save mode, a silent mode, or a macro mode.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising at least one of deleting or compressing the acquired image based on at least one of an amount of memory available, an amount of memory that is used, or a comparison between an amount of memory available and a threshold value.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein none of the at least one or more conditions cause a transmission of the acquired image based on a content of the acquired image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the transmission of the acquired image is based on bandwidth available for the transmission.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the monitoring and transmitting is performed for each image acquired by the digital camera.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the indication of the one or more conditions and the indication of the second device comprise distinct indications.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. A non-transitory computer readable storage medium storing instructions configured to direct a processor to:
<div class="claim-text">recognize, at a memory of a digital camera comprising a first device and from a user of the digital camera, one or more indications comprising (i) an indication of one or more conditions which, if satisfied, cause a transmission of an acquired image from the memory of the digital camera; and (ii) an indication of a second device to which the acquired image is to be transmitted upon the one or more conditions being satisfied;</div>
<div class="claim-text">acquire, after recognizing the one or more indications, an image at the memory of the digital camera;</div>
<div class="claim-text">store the one or more indications;</div>
<div class="claim-text">monitor the one or more conditions to determine whether the one or more conditions have been satisfied; and</div>
<div class="claim-text">transmit, upon determining that the one or more conditions have been satisfied, the acquired image to the second device.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor to transmit the image to a second device comprise instructions configured to direct the processor to compress the acquired image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor further comprise instructions configured to direct the processor to delete the acquired image from the memory.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor further comprise instructions configured to direct the processor to store meta-data associated with the acquired image, wherein the meta-data comprises at least one of position data, orientation data, altitude data, camera settings data, lens setting data, sound annotations, date and time data, cropping data, or scale data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor further comprise instructions configured to direct the processor to store meta-data associated with the acquired image, wherein the meta-data comprises at least one of scene data, illumination data, subject motion data, image content data, or image categorization data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text">19. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor further comprise instructions configured to direct the processor to at least one of modify the image, crop the image, rotate the image, filter the image, add a meta tag to the image, or display the image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text">20. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor further comprise instructions configured to direct the processor to select at least one of a sports mode, a portrait mode, a sunny mode, or a sunset mode.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
      <div class="claim-text">21. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor further comprise instructions configured to direct the processor to select at least one of a fluorescent light mode, a power save mode, a silent mode, or a macro mode.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
      <div class="claim-text">22. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor to store the acquired image comprise instructions configured to direct the processor to compress the image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
      <div class="claim-text">23. The computer readable medium of <claim-ref idref="CLM-00022">claim 22</claim-ref>, in which the instructions configured to direct the processor to compress the acquired image comprise instructions configured to direct the processor to store at least one of a compression condition or a compression parameter associated with the acquired image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00024" num="00024" class="claim">
      <div class="claim-text">24. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor further comprise instructions configured to direct the processor to delete or compress the acquired image based on at least one of a categorical rating of the acquired image, an indication from the user, a preference of the user, a state of the camera, or a capture condition.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00025" num="00025" class="claim">
      <div class="claim-text">25. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor further comprise instructions configured to direct the processor to delete or compress the acquired image based on at least one of a an amount of memory available, an amount of memory that is used, or a comparison between an amount of memory available and a threshold value.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00026" num="00026" class="claim">
      <div class="claim-text">26. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein none of the at least one or more conditions cause a transmission of the acquired image based on a content of the acquired image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00027" num="00027" class="claim">
      <div class="claim-text">27. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the transmission of the acquired image is based on bandwidth available for the transmission.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00028" num="00028" class="claim">
      <div class="claim-text">28. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the instructions configured to direct the processor are configured to direct the processor to perform the monitoring and transmitting for each image acquired by the digital camera.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00029" num="00029" class="claim">
      <div class="claim-text">29. The computer readable medium of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the indication of the one or more conditions and the indication of the second device comprise distinct indications.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES41237948" lang="EN" load-source="patent-office" class="description">
    <p num="p-0002">The present Application claims the benefit of (i) International Patent Application No. PCT/US2004/043460, filed Dec. 23, 2004 entitled, METHOD AND APPARATUS FOR AUTOMATICALLY CAPTURING AND MANAGING IMAGES; and (ii) U.S. Provisional Application No. 60/532,645 filed Dec. 24, 2003 entitled, METHOD AND APPARATUS FOR AUTOMATICALLY CAPTURING AND MANAGING IMAGES.</p>
    <p num="p-0003">The content of each of the above applications is incorporated herein by reference.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE FIGURES</heading> <p num="p-0004"> <figref idrefs="DRAWINGS">FIG. 1</figref> shows a block diagram of a system that is consistent with at least one embodiment of the present invention.</p>
      <p num="p-0005"> <figref idrefs="DRAWINGS">FIG. 2</figref> shows a block diagram of a system that is consistent with at least one embodiment of the present invention.</p>
      <p num="p-0006"> <figref idrefs="DRAWINGS">FIG. 3</figref> shows a block diagram of a system that is consistent with at least one embodiment of the present invention.</p>
      <p num="p-0007"> <figref idrefs="DRAWINGS">FIG. 4</figref> shows a block diagram of a computing device that is consistent with at least one embodiment of the present invention.</p>
      <p num="p-0008"> <figref idrefs="DRAWINGS">FIG. 5</figref> shows a block diagram of a camera that is consistent with at least one embodiment of the present invention.</p>
      <p num="p-0009"> <figref idrefs="DRAWINGS">FIG. 6A</figref> shows a block diagram of an imaging device that is consistent with at least one embodiment of the present invention.</p>
      <p num="p-0010"> <figref idrefs="DRAWINGS">FIG. 6B</figref> shows a block diagram of an imaging device that is consistent with at least one embodiment of the present invention.</p>
      <p num="p-0011"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a table illustrating an exemplary data structure of an acquire condition database consistent with at least one embodiment of the present invention.</p>
      <p num="p-0012"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a table illustrating an exemplary data structure of an acquired image log consistent with at least one embodiment of the present invention.</p>
      <p num="p-0013"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a table illustrating an exemplary data structure of an image rating database consistent with at least one embodiment of the present invention.</p>
      <p num="p-0014"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a table illustrating an exemplary data structure of a captured image database consistent with at least one embodiment of the present invention.</p>
      <p num="p-0015"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a table illustrating an exemplary data structure of a compression condition database consistent with at least one embodiment of the present invention.</p>
      <p num="p-0016"> <figref idrefs="DRAWINGS">FIG. 12</figref> is a table illustrating an exemplary data structure of a compression tracking database consistent with at least one embodiment of the present invention.</p>
      <p num="p-0017"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a flowchart illustrating a process consistent with at least one embodiment of the present invention.</p>
      <p num="p-0018"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a flowchart illustrating a process for acquiring an image automatically that is consistent with at least one embodiment of the present invention.</p>
      <p num="p-0019"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a flowchart illustrating a process consistent with at least one embodiment of the present invention.</p>
      <p num="p-0020"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a flowchart illustrating a process consistent with at least one embodiment of the present invention.</p>
    </description-of-drawings> <heading>DETAILED DESCRIPTION</heading> <p num="p-0021">Applicants have recognized that, in accordance with some embodiments of the present invention, some types of users of cameras (and other types of imaging devices) may find it appealing to have a camera that is able to capture one or more images automatically.</p>
    <p num="p-0022">Applicants have further recognized that, in accordance with some embodiments of the present invention, some types of users may find it appealing to have an imaging device that automatically manages stored images (e.g., automatically-captured images) and/or automatically manages memory associated with an imaging device. Some types of users may find it appealing, for example, to have a camera that automatically frees up memory of the camera (e.g., for capturing images).</p>
    <p num="p-0023">Applicants have further recognized that, in accordance with one or more embodiments of the present invention, some types of users may find it appealing to be provided methods and apparatus for automatically capturing and managing images such that users may be able to capture higher quality images easily and reliably while minimizing or otherwise managing the danger of running out of memory on their cameras.</p>
    <p num="p-0024">According to one embodiment of the present invention, a method and apparatus are provided for capturing images automatically (e.g., without any direct indication from a user). In one example, whenever a user raises or aims an imaging device (e.g., a camera) to take a picture, the imaging device may automatically capture a plurality of images (e.g., with different respective exposure settings, focus settings, etc). Such images may be captured, for example, as an auto-bracketed set when a user presses the shutter button of a camera, or they may be captured completely independently of images that are captured by the user pressing the shutter button. Automatically capturing different images of a scene (that may or may not be changing) may provide the benefit that the user ends up with at least one high quality image for any scene.</p>
    <p num="p-0025">According to one embodiment of the present invention, a camera or other type of imaging device includes or otherwise has access to an image analysis program that rates images (e.g., based on their exposure quality, desirability to a user, or other factors). For example, a camera consistent with some embodiments of the present invention may use a color histogram to determine whether an image is overexposed, is underexposed, is in focus, or has too much contrast. A rating that is indicative of the image's quality may be assigned to the image, for example, based on the results of the image analysis. For instance, high quality images may receive higher ratings (e.g., 8 or 9 out of 10), while lower quality images may receive lower ratings (e.g., 2 or 3 out of 10).</p>
    <p num="p-0026">According to various embodiments of the present invention, an imaging device (e.g., a digital camera) is provided that is operable to perform a variety of different processes based on a quality of one or more images, and additionally may be able to determine (e.g., in accordance with a stored program, or based one or more stored rules) which of a plurality of available actions to perform. Such a determination may be based on a variety of factors, such as, without limitation, an amount of free memory, a quality of an image, and/or a rate at which new images are being captured.</p>
    <p num="p-0027">According to one or more embodiments of the present invention, a method and apparatus are provided operable to automatically capture a plurality of images (e.g., via a digital camera or other imaging device) and is further operable to determine whether to stop automatically capturing images. According to one embodiment, a camera is operable to automatically capture a plurality of images of a scene (e.g., a family building a sandcastle on a beach). After a number of images have been taken (e.g., halfway through a predetermined set), the camera may evaluate the images already captured by rating them. If one or more of the images already captured are determined to be of sufficient quality (e.g., by meeting a predetermined rating or other measure of quality), then the camera may determine that it should stop capturing images. Otherwise (e.g., if the camera determines that the captured images are of insufficient quality), the camera may proceed to capture one or more additional images of the scene. In this way, the camera may ensure that at least one image of desirable quality is captured.</p>
    <p num="p-0028">According to at least one embodiment of the present invention, a method and apparatus are provided by which an imaging device (e.g., a digital camera) may manage memory and/or stored images (e.g., automatically-captured images) automatically. It will be readily understood that although a memory available to an imaging device for storing images may have a large capacity, the capacity may be limited.</p>
    <p num="p-0029">According to one embodiment of the present invention, a method and apparatus are provided for automatically compressing or deleting one or more images, including images acquired automatically (e.g., by a digital camera).</p>
    <p num="p-0030">According to one embodiment of the present invention, a method and apparatus are provided for acquiring an image, determining a quality of the image, and determining a resolution at which to store the image based on the quality.</p>
    <p num="p-0031">According to another embodiment of the present invention, a method and apparatus are provided for acquiring an image automatically, storing the image in a memory (e.g., an image buffer), and evaluating the quality of the image. Evaluating may comprise determining if an image is of a predetermined quality (e.g., “high” quality, or the image has an associated rating greater than a threshold value). In some embodiments, an image of a first predetermined quality may be stored (e.g., in a flash memory card) in a first resolution and an image of a second determined quality may be stored in a second resolution, compressed, or deleted.</p>
    <p num="p-0032">According to one embodiment of the present invention, a method and apparatus are provided for determining if an amount of memory available for storing images is less than a predetermined threshold and determining whether one or more images should be compressed and/or one or more images should be deleted. In one example, if a camera begins to run low on memory (e.g., 90% of the camera's secondary memory is occupied), then the camera may determine that one or more automatically captured images should be compressed or deleted to free up some memory space.</p>
    <p num="p-0033">According to one embodiment of the present invention, a method and apparatus are provided for determining which of a plurality of stored images to compress, and, optionally, determining how much to compress a particular image or images. For example, a camera may determine to compress the ten stored images of the lowest quality (e.g., lowest quality ratings) and may also determine how much to compress these images (e.g., lower quality images may be compressed more or deleted).</p>
    <p num="p-0034">According to one embodiment of the present invention, a method and apparatus is provided for capturing images automatically and automatically managing images (e.g., automatically-captured images) stored on an imaging device (e.g., a digital camera).</p>
    <p num="p-0035">Numerous embodiments are described in this application, and are presented for illustrative purposes only. The described embodiments are not intended to be limiting in any sense. The invention is widely applicable to numerous embodiments, as is readily apparent from the disclosure herein. Those skilled in the art will recognize that the present invention may be practiced with modification and alteration without departing from the teachings disclosed herein. Although particular features of the present invention may be described with reference to one or more particular embodiments or figures, it should be understood that such features are not limited to usage in the one or more particular embodiments or figures with reference to which they are described.</p>
    <p num="p-0036">The terms “an embodiment,” “embodiment,” “embodiments,” “the embodiment,” “the embodiments,” “one or more embodiments,” “some embodiments,” and “one embodiment” mean “one or more (but not all) embodiments of the present invention(s),” unless expressly specified otherwise.</p>
    <p num="p-0037">The terms “including,” “comprising” and variations thereof mean “including but not limited to,” unless expressly specified otherwise. A listing of items does not imply that any or all of the items are mutually exclusive, unless expressly specified otherwise. The terms “a,” “an” and “the” mean “one or more,” unless expressly specified otherwise.</p>
    <p num="p-0038">The term “plurality” means “two or more,” unless expressly specified otherwise.</p>
    <p num="p-0039">Devices that are in communication with each other need not be in continuous communication with each other, unless expressly specified otherwise. In addition, devices that are in communication with each other may communicate directly or indirectly through one or more intermediaries.</p>
    <p num="p-0040">A description of an embodiment with several components in communication with each other does not imply that all such components are required. On the contrary a variety of optional components are described to illustrate the wide variety of possible embodiments of the present invention.</p>
    <p num="p-0041">Further, although process steps, method steps, algorithms or the like may be described (in the disclosure and/or in the claims) in a sequential order, such processes, methods and algorithms may be configured to work in alternate orders. In other words, any sequence or order of steps that may be described does not necessarily indicate a requirement that the steps be performed in that order. The steps of processes described herein may be performed in any order practical. Further, some steps may be performed simultaneously.</p>
    <p num="p-0042">It will be readily apparent that the various methods and algorithms described herein may be implemented by, e.g., appropriately programmed general purpose computers and computing devices. Further, programs that implement such methods and algorithms may be stored and transmitted using a variety of known media.</p>
    <p num="p-0043">When a single device or article is described herein, it will be readily apparent that more than one device/article (whether or not they cooperate) may be used in place of a single device/article. Similarly, where more than one device or article is described herein (whether or not they cooperate), it will be readily apparent that a single device/article may be used in place of the more than one device or article.</p>
    <p num="p-0044">The functionality and/or the features of a device may be alternatively embodied by one or more other devices which are not explicitly described as having such functionality/features. Thus, other embodiments of the present invention need not include the device itself.</p>
    <p num="p-0045">The term “computer-readable medium” as used herein refers to any medium that participates in providing instructions that may be read by a computer, a processor or a like device. Such a medium may take many forms, including but not limited to, non-volatile media, volatile media, and transmission media. Non-volatile media include, for example, optical or magnetic disks and other persistent memory. Volatile media include dynamic random access memory (DRAM), which typically constitutes the main memory. Transmission media include coaxial cables, copper wire and fiber optics, including wires that comprise a system bus coupled to a processor. Transmission media may include or convey acoustic waves, light waves and electromagnetic emissions, such as those generated during radio frequency (RF) and infrared (IR) data communications. Common forms of computer-readable media include, for example, a floppy disk, a flexible disk, hard disk, magnetic tape, any other magnetic medium, a CD-ROM, DVD, any other optical medium, punch cards, paper tape, any other physical medium with patterns of holes, a RAM, a PROM, an EPROM, a FLASH-EEPROM, any other memory chip or cartridge, a carrier wave as described hereinafter, or any other medium from which a computer can read. Various forms of computer readable-media may be involved in carrying a sequence of instructions to a processor.</p>
    <p num="p-0046">Various embodiments of the present invention are described herein with reference to the accompanying drawings. The leftmost digit(s) of a reference numeral typically identifies the figure in which the reference numeral first appears.</p>
    <p num="p-0047">Embodiments of the present invention will first be introduced by means of block diagrams of exemplary systems and devices that may be utilized by an entity practicing one or more embodiments of the present invention. Exemplary data structures illustrating tables that may be used when practicing various embodiments of the present invention will then be described, along with corresponding flowcharts that illustrate exemplary processes with reference to the exemplary devices, systems, and tables.</p>
    <p num="p-0048">As will be understood by those skilled in the art, the drawings and accompanying descriptions presented herein indicate some exemplary arrangements for stored representations of information. A number of other arrangements may be employed besides the tables shown. Similarly, the illustrated entries represent exemplary information, but those skilled in the art will understand that the number and content of the entries can be different from those illustrated herein.</p>
    <p num="p-0049">Terms</p>
    <p num="p-0050">Throughout the description that follows and unless otherwise specified, the following terms may include and/or encompass the example meanings provided in this section. These terms and illustrative example meanings are provided to clarify the language selected to describe embodiments of the invention both in the specification and in the appended claims.</p>
    <p num="p-0051">an imaging device—a device, such as a camera, that is used to capture an image. In one example, an imaging device is a digital camera that captures images and stores them digitally.</p>
    <p num="p-0052">user—one or more people who operate an imaging device.</p>
    <p num="p-0053">image—a two-dimensional representation of light reflected or emitted by a scene. For example, an image may comprise, without limitation, a photo, photograph, picture, and/or shot.</p>
    <p num="p-0054">capturing an image—the process of recording an image. In one example, a camera may capture an image when a user presses the camera's shutter button. Capturing an image may comprise, for example, taking a picture, photographing, and/or taking a photograph. In another example, capturing an image may comprise one or more of: acquiring an image and storing an image.</p>
    <p num="p-0055">acquiring an image—In one example, using an image sensor (e.g., of a camera) to determine an image. An acquired image may be stored temporarily in memory (e.g., in an image buffer or RAM) for further processing (e.g., determining one or more ratings, determining whether to store the image).</p>
    <p num="p-0056">storing an image—In one example, storing a representation of an image in removable or non-volatile memory.</p>
    <p num="p-0057">compressing an image—reducing an amount of memory used to store an image. Compressing an image may include, for example, reducing a size of a file (or other type of memory allocation) used to store an image, or deleting a file that stores an image.</p>
    <p num="p-0058">compression setting—a parameter that affects how much an image an image is compressed. In one example, a compression program (e.g., a JPEG image compression program) compresses an image based on a compression setting. For instance, a compression setting of “60%” may compress an image more than a compression setting of “80%.”</p>
    <p num="p-0059">capturing an image manually—In one example, a user capturing an image by operating a control of an imaging device. In one example, a user may press the shutter button on a camera to capture an image or otherwise indicate or provide a signal that the camera should capture the image.</p>
    <p num="p-0060">capturing an image automatically—In one example, capturing an image absent or without receiving a request for the image from a user. In another example, a camera may capture an image automatically without a user pressing a shutter button on the camera. In another example, a camera may capture an image automatically without a user initiating a timer.</p>
    <p num="p-0061">acquire condition—a condition that, if satisfied, may cause at least one image to be acquired by an imaging device. An acquire condition may be associated with one or more criteria, events, circumstances, and/or triggers.</p>
    <p num="p-0062">compression condition—a condition that, if satisfied, may cause at least one image to be compressed or deleted by an imaging device. A compression condition may be associated with one or more criteria, events, circumstances, and/or triggers.</p>
    <p num="p-0063">selection condition—a condition that may be used to select one or more images to be compressed or deleted by the camera. A selection condition may be associated with one or more criteria, events, circumstances, and/or triggers.</p>
    <p num="p-0064">rating—information that indicates a quality of an image. In one example, a rating may include a measurement of the quality of an image. In another example, a well-exposed, interesting image may be associated with a higher rating than an under-exposed, boring image.</p>
    <p num="p-0065">meta-data or meta-tag—supplementary information associated with an image. Some examples of meta-data that may be associated with an image include: a time, a date, a location, one or more subjects of an image, one or more settings of an imaging device (e.g., when the image was captured), and an audio clip.</p>
    <p num="p-0066">meta-tagging—associating meta-data or other supplementary information with an image.</p>
    <p num="p-0067">auto-bracketed, auto-bracketing—relating to the capturing or acquiring of a plurality of images of a scene, with at least one setting on the camera being adjusted among the plurality of images. For example, the camera might auto-bracket for exposure by capturing four images of a scene, each image being captured with a different aperture setting (e.g., f/2.8, f/3.5, f/5, and f/8). As will be readily understood, an imaging device may auto-bracket for one or more other types of settings including without limitation, shutter speed, ISO, focus, zoom, white balance, color saturation, flash brightness, or any other setting that may affect an image captured by the camera.</p>
    <p num="p-0068">primary memory—primary memory will typically refer herein to volatile memory or memory that is used by the camera's processor in performing calculations. RAM and memory buffers are examples of primary memory.</p>
    <p num="p-0069">secondary memory—secondary memory will typically refer herein to memory that is non-volatile, that may be used for storing information over a longer period of time than primary memory, and/or memory that is removable from a camera or other imaging device. A flash memory card is one example of secondary memory.</p>
    <p num="p-0070">Systems and Devices</p>
    <p num="p-0071">Referring now to <figref idrefs="DRAWINGS">FIG. 1</figref>, a block diagram of a system <b>100</b> according to at least one embodiment of the present invention includes an imaging device <b>110</b> in communication (e.g., via a communications network or system bus) with a computing device <b>120</b>. Various exemplary means by which devices may communicate are discussed below with respect to <figref idrefs="DRAWINGS">FIG. 3</figref>. Although only one imaging device <b>110</b> and one computing device <b>120</b> are depicted in <figref idrefs="DRAWINGS">FIG. 1</figref>, it will be understood that any number and type of imaging devices <b>110</b> may communicate with any number of computing devices <b>120</b>.</p>
    <p num="p-0072">Various types of imaging devices <b>110</b> and computing devices <b>120</b> are discussed herein. The imaging device <b>110</b> preferably comprises at least one device or component for acquiring and/or recording an image, such as, without limitation, an image sensor, a camera, or a handheld device having an integrated camera. It will be understood, therefore, that a lens and an image sensor, for example, may each be referred to individually as an imaging device, or, alternatively, two or more such components may be referred to collectively as an imaging device (e.g., as embodied in a camera or PDA). Further, it will be understood, as discussed further below with respect to <figref idrefs="DRAWINGS">FIG. 2</figref>, that a device embodying any such components (e.g., a camera) may itself be referred to as an imaging device.</p>
    <p num="p-0073">The imaging device <b>110</b> may further comprise one or more types of computing devices, such as those based on the Intel Pentium® processor, adapted to communicate with the computing device <b>120</b>. For example, as will be readily apparent to those skilled in the art, many types of cameras include an imaging device (e.g., an image sensor for capturing images) and a computing device (e.g., a processor for executing camera functions).</p>
    <p num="p-0074">For example, referring now to <figref idrefs="DRAWINGS">FIG. 2</figref>, a block diagram of a system <b>200</b> according to at least one embodiment of the present invention includes a camera <b>210</b> in communication (e.g., via a communications network) with a storage device <b>240</b> (e.g., a server, an external hard drive). The camera <b>210</b> comprises an imaging device <b>220</b> (e.g., an image sensor and/or lens) and a computing device <b>230</b> (e.g., a camera processor) that is in communication (e.g., via a communication port of the computing device <b>230</b>) with the storage device <b>240</b> (e.g., a Web server). In some embodiments, the computing device <b>230</b> may include or may be in communication with a storage device or memory other than storage device <b>240</b>. For example, the camera <b>210</b> may comprise a flash memory card, and/or the computing device <b>230</b> may comprise RAM or ROM. It will be understood that a device such as the camera <b>210</b>, comprising both an imaging device and a computing device, may itself be referred to, alternatively, as an imaging device or a computing device.</p>
    <p num="p-0075">Referring again to <figref idrefs="DRAWINGS">FIG. 1</figref>, a computer or computing device <b>120</b> may comprise one or more processors adapted to communicate with the imaging device <b>110</b> (or one or more computing devices of the imaging device <b>110</b>). As discussed herein, a computer or computing device <b>120</b> preferably also comprises a memory (e.g., for storing a program executable by the processor, for storing images) and may optionally comprise a communication port (e.g., for communication with an imaging device <b>110</b> and/or other devices). Some examples of a computer or computing device <b>120</b> include, without limitation: a camera processor, a camera, a server, a PDA, a personal computer, a computer server, personal computer, portable hard drive, digital picture frame, or other electronic device. Thus, a computing device <b>120</b> may but need not include any devices for capturing images. Some exemplary components of a computing device are discussed in further detail below.</p>
    <p num="p-0076">In some exemplary embodiments of the present invention, as discussed herein, imaging device <b>110</b> comprises a camera (e.g., a camera <b>330</b> of <figref idrefs="DRAWINGS">FIG. 3</figref>) and the computing device <b>120</b> comprises a server or other device configured to store information. In another example consistent with at least one embodiment of the present invention, the system <b>100</b> depicts components of a camera or other device capable of recording images. For instance, the imaging device <b>110</b> may comprise an image sensor or lens in communication via a camera system bus with a computing device <b>120</b> such as a camera computer or integrated communication device (e.g., a mobile phone).</p>
    <p num="p-0077">An imaging device <b>110</b> or camera <b>210</b> may communicate with one or more other devices (e.g., computing device <b>120</b>, storage device <b>240</b>) in accordance with one or more systems and methods of the invention. Examples of devices that an imaging device may communicate with include, without limitation:</p>
    <p num="p-0078">a personal digital assistant (PDA)</p>
    <p num="p-0079">a cellular telephone</p>
    <p num="p-0080">a digital wallet (e.g., the iPod™ by Apple, the MindStor™ from Minds@Work, Nixvue's Digital Album™)</p>
    <p num="p-0081">a portable stereo (e.g., an MP3 (or other file format) music player, a Sony Discman™)</p>
    <p num="p-0082">a notebook computer</p>
    <p num="p-0083">a tablet computer</p>
    <p num="p-0084">a digital picture frame (e.g., Iomega's FotoShow™, NORDview's Portable Digital Photo Album™)</p>
    <p num="p-0085">a GPS device (e.g., such as those manufactured by Garmin)</p>
    <p num="p-0086">a personal computer</p>
    <p num="p-0087">According to various embodiments of the present invention, an imaging device <b>110</b> may transfer one or more images to a second device (e.g., computing device <b>120</b>). Some examples are provided with reference to <figref idrefs="DRAWINGS">FIGS. 1-3</figref>. In one example, a camera <b>210</b> may include a wireless communication port that allows the camera to transmit images to a second electronic device (e.g., storage device <b>240</b>). The second electronic device may then store copies of the images. After transferring the images to this second electronic device, the imaging device <b>110</b> may optionally delete or compress the images because they are now stored on the second electronic device.</p>
    <p num="p-0088">According to another exemplary embodiment, the camera <b>210</b> may include or be connected to a cellular telephone with wireless communication capabilities (e.g., a cellular telephone on a 2.5 G or 3 G wireless network). Using the cellular telephone, the camera <b>210</b> may transmit one or more images to a server, which may store the images.</p>
    <p num="p-0089">In another example, an imaging device <b>110</b> may communicate with a portable hard drive such as an Apple iPod™. To free up memory on the imaging device <b>110</b>, the imaging device <b>110</b> may transfer images to the portable hard drive.</p>
    <p num="p-0090">In another example, the imaging device <b>110</b> may have a wireless Internet connection (e.g., using the 802.11 wireless protocol) and use this connection to transmit images to a personal computer that is connected to the Internet. Note that by transferring an image from a camera to a second electronic device, the camera may effectively expand its available memory. That is, some or all of the memory on the second electronic device may be available to the camera for storing images.</p>
    <p num="p-0091">Referring now to <figref idrefs="DRAWINGS">FIG. 3</figref>, a block diagram of a system <b>300</b> according to at least one embodiment of the present invention includes one or more storage devices <b>310</b> (e.g., a personal computer, a Web server, a hard drive) in communication, via a communications network <b>320</b>, with one or more cameras <b>330</b> (e.g., digital camera, video camera, wireless phone with integrated digital camera). Each of the storage devices <b>310</b> and cameras <b>330</b> may comprise one or more computing devices, such as those based on the Intel Pentium® processor, that are adapted to communicate with any number and type of devices (e.g., other cameras and/or storage devices) via the communications network <b>320</b>. Although only two cameras <b>330</b> and two storage devices <b>310</b> are depicted in <figref idrefs="DRAWINGS">FIG. 3</figref>, it will be understood that any number and type of cameras <b>330</b> may communicate with any number of storage devices <b>310</b> and/or other cameras <b>330</b> (and vice versa).</p>
    <p num="p-0092">According to one or more embodiments of the present invention, a camera <b>330</b> may communicate with a storage device <b>310</b> in order to transmit one or more images to the storage device <b>310</b> (e.g., for storage).</p>
    <p num="p-0093">A storage device <b>310</b> may be embodied in a variety of different forms, including, without limitation, a server, a mainframe computer (e.g., an SGI Origin™ server), a personal computer (e.g., a Dell Dimension™ computer), and a portable computer (e.g., an Apple iBook™ laptop, a Palm m515™ PDA, a Kyocera 7135™ cell phone).</p>
    <p num="p-0094">Communication by and among any of the imaging devices, computing devices, and storage devices described herein (including the cameras <b>330</b> and the storage devices <b>310</b>) may be direct or may be indirect, and may occur via a wired or wireless medium. Some, but not all, possible communication networks that may comprise network <b>320</b> (or may otherwise be part of system <b>300</b> and/or other exemplary systems described herein) include: a local area network (LAN), a wide area network (WAN), the Internet, a telephone line, a cable line, a radio channel, an optical communications line, and a satellite communications link. In yet other embodiments, the devices of the system <b>300</b> may communicate with one another over RF, cable TV, satellite links and the like. Some possible communications protocols that may be part of system <b>300</b> include, without limitation: Ethernet (or IEEE 802.3), SAP, ATP, Bluetooth™, IEEE 802.11, CDMA, TDMA, ultra-wideband, universal serial bus (USB), and TCP/IP. Optionally, communication may be encrypted to ensure privacy and to prevent fraud in any of a variety of ways well known in the art.</p>
    <p num="p-0095">Of course, in lieu of or in addition to the exemplary communications means described herein, any appropriate communications means or combination of communications means may be employed in the system <b>300</b> and in other exemplary systems described herein. For example, communication may take place over the Internet through a Web site maintained by a remote server, or over an on-line data network including commercial on-line service providers, bulletin board systems and the like. In another example, using the wireless capabilities of his mobile phone, a user may upload an image captured using the integrated digital camera to his personal computer, or to a personal database of images on a Web server maintained by his telecommunications company. In another example, while a user is still away from home on vacation, the user's personal computer may receive, via a cable modem, a series of vacation snapshots taken by the user.</p>
    <p num="p-0096">According to one or more embodiments of the present invention, a storage device <b>310</b> may comprise a server including an external or internal module associated with one or more of the cameras <b>330</b> and capable of communicating with one or more of the cameras <b>330</b> and of directing the one or more cameras <b>330</b> to perform one or more functions. For example, a server may be configured to execute a program for controlling one or more functions of a camera <b>330</b> remotely. Similarly, a camera <b>330</b> may comprise a module associated with one or more storage devices <b>310</b> that is capable of directing one or more storage devices <b>310</b> to perform one or more functions. For example, a camera <b>330</b> may be configured to direct a server to execute a facial recognition program on a captured image and to return an indication of the best matches to the camera <b>330</b> via the communication network <b>320</b>.</p>
    <p num="p-0097">A camera <b>330</b> may be operable to access one or more databases (e.g., of storage device <b>310</b>). A camera <b>330</b> may also be operable to access a database (e.g., an image database) via the network <b>320</b> to determine what meta-information (e.g., information descriptive of an image) to associate with one or more images. For example, as discussed further herein, a database of images and/or image templates may be stored for a user on a storage device <b>310</b> (e.g., a server). Various functions of a camera <b>330</b> and/or the storage device <b>310</b> may be performed based on images stored in a personalized database. For instance, an image recognition program running on the server <b>310</b> (or on the camera <b>330</b>) may use the user's personalized database of images for reference in identifying people, objects, and/or scenes in an image captured by the user. If, in accordance with one embodiment, the user has identified the content of some of the images in the database himself (e.g., by associating a meta-tag with an image), a match determined by the image recognition software with reference to the customized database is likely to be acceptable to the user (e.g., the user is likely to agree to a suggestion to associate a meta-tag from a stored reference image with the new image also).</p>
    <p num="p-0098">Information exchanged by the exemplary devices depicted in <figref idrefs="DRAWINGS">FIG. 3</figref> may include, without limitation, images and indications of changes in settings or operation of a camera <b>330</b> (e.g., an indication that a user or the camera <b>330</b> has altered an exposure setting). Other exemplary types of information that may be determined by the camera <b>330</b> and/or the storage device <b>310</b> and communicated to one or more other devices are described herein. A server, for example, may monitor operations of a camera <b>330</b> (and/or activity of a user) via the network <b>320</b>. For instance, a server may identify a subject a user is recording images of and, optionally, use that information to direct the camera <b>330</b> to ask if the user would like to e-mail or otherwise transmit a copy of the captured image to the subject.</p>
    <p num="p-0099">With respect to the various exemplary systems, devices, and methods discussed herein, those skilled in the art will understand that devices in communication with each other need not be continually transmitting to each other. On the contrary, such devices need only transmit to each other as necessary, and may actually refrain from exchanging data most of the time. For example, a device in communication with another device via the Internet may not transmit data to the other device for weeks at a time.</p>
    <p num="p-0100">According to some embodiments, various processes may be performed by the camera <b>330</b> in conjunction with the storage device <b>310</b>. For example, some steps of a described process may be performed by the camera <b>330</b>, while other steps are performed by the storage device <b>310</b>. As discussed herein, data useful in providing some of the described functionality may be stored on one of or both of the camera <b>330</b> and storage device <b>310</b> (and/or other devices).</p>
    <p num="p-0101">In some embodiments, as discussed herein, the storage devices <b>310</b> may not be necessary and/or may not be preferred. For example, some embodiments of the present invention may be practiced using a camera <b>330</b> alone, as described herein. In such embodiments, one or more functions described as being performed by a storage device <b>310</b> (e.g., a server) may be performed by the camera <b>330</b>, and some or all of the data described as being stored on a storage device <b>310</b> may be stored on the camera <b>330</b> or on another device in communication with the camera <b>330</b> (e.g., another camera, a PDA).</p>
    <p num="p-0102">Similarly, in some embodiments the cameras <b>330</b> may not be necessary and/or may not be preferred. Accordingly, one or more functions described herein as being performed by the camera <b>330</b> may be performed by a server or other type of appropriately configured storage device, and some or all of the described as being stored on the camera <b>330</b> may be stored on the storage device <b>310</b> or on another device in communication with the storage device <b>310</b> (e.g., a PDA, a personal computer).</p>
    <p num="p-0103">Several examples of types of cameras, storage devices, servers, and other devices are discussed herein, and other types consistent with various embodiments of the present invention will be readily understood by those of skill in the art in light of the present disclosure.</p>
    <p num="p-0104">Referring now to <figref idrefs="DRAWINGS">FIG. 4</figref>, illustrated therein is a block diagram of an embodiment <b>400</b> of computing device <b>330</b> (<figref idrefs="DRAWINGS">FIG. 3</figref>). The computing device <b>400</b> may be implemented as a system controller, a dedicated hardware circuit, an appropriately programmed general-purpose computer, or any other equivalent electronic, mechanical or electromechanical device. The computing device <b>400</b> may comprise, for example, a server computer operable to communicate with one or more client devices, such as an imaging device <b>220</b>. The computing device <b>400</b> may be operative to manage the system <b>100</b>, the system <b>200</b>, the system <b>300</b>, and/or the camera <b>210</b> and to execute various methods of the present invention.</p>
    <p num="p-0105">In operation, the computing device <b>400</b> may function under the control of a user, remote operator, image storage service provider, or other entity that may also control use of an imaging device <b>110</b>, camera <b>210</b>, imaging device <b>220</b> and/or storage device <b>240</b>. For example, the computing device <b>400</b> may be a Web server maintained by an Internet services provider, or may be a computer embodied in a camera <b>310</b> or camera <b>330</b>. In some embodiments, the computing device <b>400</b> and an imaging device <b>110</b> may be different devices. In some embodiments, the computing device <b>400</b> and the imaging device <b>110</b> may be the same device. In some embodiments, the computing device <b>400</b> may comprise more than one computer operating together.</p>
    <p num="p-0106">The computing device <b>400</b> comprises a processor <b>405</b>, such as one or more Intel Pentium® processors. The processor <b>405</b> is in communication with a memory <b>410</b> and with a communication port <b>495</b> (e.g., for communicating with one or more other devices).</p>
    <p num="p-0107">The memory <b>410</b> (as well as any of the various types of storage devices described herein) may comprise an appropriate combination of magnetic, optical and/or semiconductor memory, and may include, for example, Random Access Memory (RAM), Read-Only Memory (ROM), a compact disc and/or a hard disk. The processor <b>405</b> and the memory <b>410</b> may each be, for example: (i) located entirely within a single computer or other device; or (ii) connected to each other by a remote communication medium, such as a serial port cable, telephone line or radio frequency transceiver. In one embodiment, the computing device <b>400</b> may comprise one or more devices that are connected to a remote server computer for maintaining databases.</p>
    <p num="p-0108">In the example depicted in <figref idrefs="DRAWINGS">FIG. 4</figref>, the memory <b>410</b> stores a program <b>415</b> for controlling the processor <b>405</b>. The processor <b>405</b> performs instructions of the program <b>415</b>, and thereby operates in accordance with the present invention, and particularly in accordance with the methods described in detail herein. The program <b>415</b> may be stored in a compressed, uncompiled and/or encrypted format. The program <b>415</b> furthermore includes program elements that may be necessary, such as an operating system, a database management system and “device drivers” for allowing the processor <b>405</b> to interface with computer peripheral devices. Appropriate program elements are known to those skilled in the art, and need not be described in detail herein.</p>
    <p num="p-0109">Various forms of computer-readable media may be involved in carrying one or more sequences of one or more instructions to processor <b>405</b> (or any other processor of a device described herein) for execution. For example, the instructions may initially be borne on a magnetic disk of a remote computer. The remote computer can load the instructions into its dynamic memory and send the instructions over a telephone line using a modem. A modem local to a computing device <b>400</b> can receive the data on the telephone line and use an infrared transmitter to convert the data to an infrared signal. An infrared detector can receive the data carried in the infrared signal and place the data on a system bus for processor <b>405</b>. The system bus carries the data to main memory, from which processor <b>405</b> retrieves and executes the instructions. The instructions received by main memory may optionally be stored in memory <b>410</b> either before or after execution by processor <b>405</b>. In addition, instructions may be received via communication port <b>495</b> as electrical, electromagnetic or optical signals, which are exemplary forms of carrier waves that carry data streams representing various types of information. Thus, the computing device <b>400</b> may obtain instructions in the form of a carrier wave.</p>
    <p num="p-0110">According to one embodiment of the present invention, the instructions of the program <b>415</b> may be read into a main memory from another computer-readable medium, such from a ROM to RAM. Execution of sequences of the instructions in program <b>415</b> causes processor <b>405</b> to perform the process steps described herein. In alternate embodiments, hard-wired circuitry may be used in place of, or in combination with, software instructions for implementation of the processes of the present invention. Thus, embodiments of the present invention are not limited to any specific combination of hardware and software.</p>
    <p num="p-0111">The memory <b>410</b> also preferably stores a plurality of databases, including an acquire condition database <b>420</b>, an acquired image log <b>425</b>, an image rating database <b>430</b>, an image database <b>435</b>, a compression condition database <b>440</b>, and a compression tracking database <b>445</b>. Examples of each of these databases are described in detail below and example structures are depicted with sample entries in the accompanying figures.</p>
    <p num="p-0112">As will be understood by those skilled in the art, the schematic illustrations and accompanying descriptions of the sample databases presented herein are exemplary arrangements for stored representations of information. Any number of other arrangements may be employed besides those suggested by the tables shown. For example, even though a particular number of separate databases are illustrated, the invention could be practiced effectively using any number of functionally equivalent databases. Similarly, the illustrated entries of the databases represent exemplary information only; those skilled in the art will understand that the number and content of the entries can be different from those illustrated herein. Further, despite the depiction of the databases as tables, an object-based model could be used to store and manipulate the data types of the present invention and, likewise, object methods or behaviors can be used to implement the processes of the present invention.</p>
    <p num="p-0113">Note that, although these databases are described with respect to <figref idrefs="DRAWINGS">FIG. 4</figref> as being stored in one computing device, in other embodiments of the present invention some or all of these databases may be partially or wholly stored in another device, such as one or more imaging devices <b>110</b>, one or more of the cameras <b>330</b>, one or more of the storage devices <b>240</b> or <b>310</b>, another device, or any combination thereof. Further, some or all of the data described as being stored in the databases may be partially or wholly stored (in addition to or in lieu of being stored in the memory <b>410</b> of the computing device <b>400</b>) in a memory of one or more other devices.</p>
    <p num="p-0114">Referring now to <figref idrefs="DRAWINGS">FIG. 5</figref>, illustrated therein is a block diagram of an embodiment <b>530</b> of a camera in communication with a server <b>550</b> (e.g., via a communications network). The camera <b>530</b> may be implemented as a system controller, a dedicated hardware circuit, an appropriately configured computer, or any other equivalent electronic, mechanical or electro-mechanical device. The camera <b>530</b> may comprise, for example, any of various types of cameras well known in the art, including, without limitation, a still camera, a digital camera, an underwater camera, and a video camera. A still camera, for example, typically includes functionality to capture images that may be displayed individually. A single lens reflex (SLR) camera is one example of a still camera. A video camera typically includes functionality to capture movies or video (i.e., one or more sequences of images typically displayed in succession). A still image, movie file or video file may or may not include or be associated with recorded audio. It will be understood by those skilled in the art that some types of cameras, such as the Powershot A40™ by Canon U.S.A., Inc., may include functionality to capture movies and functionality to capture still images.</p>
    <p num="p-0115">The camera <b>530</b> may comprise any or all of the cameras <b>330</b> of system <b>300</b> (<figref idrefs="DRAWINGS">FIG. 3</figref>) or the imaging device <b>110</b> (<figref idrefs="DRAWINGS">FIG. 1</figref>). In some embodiments, a user device such as a PDA or cell phone may be used in place of, or in addition to, some or all of the camera <b>530</b> components depicted in <figref idrefs="DRAWINGS">FIG. 5</figref>. Further, a camera <b>530</b> may comprise a computing device or other device operable to communicate with another computing device (e.g., a computing device <b>120</b>).</p>
    <p num="p-0116">The camera <b>530</b> comprises a processor <b>505</b>, such as one or more Intel Pentium™ processors. The processor <b>505</b> is in communication with a memory <b>510</b> and a communication port <b>520</b> (e.g., for communicating with one or more other devices).</p>
    <p num="p-0117">The memory <b>510</b> (as well as other types of memory and storage devices described herein) may comprise an appropriate combination of magnetic, optical and/or semiconductor memory, and may include, for example, Random Access Memory (RAM), Read-Only Memory (ROM), a programmable read only memory (PROM), a compact disc and/or a hard disk. The memory <b>510</b> may comprise or include any type of computer-readable medium. The processor <b>505</b> and the memory <b>510</b> may each be, for example: (i) located entirely within a single computer or other device; or (ii) connected to each other by a remote communication medium, such as a serial port cable, telephone line or radio frequency transceiver. In one embodiment, the camera <b>530</b> may comprise one or more devices that are connected to a remote server computer for maintaining databases.</p>
    <p num="p-0118">According to some embodiments, memory <b>510</b> of camera <b>530</b> may comprise an image buffer (e.g., a high-speed buffer for transferring images from an image sensor) and/or a flash memory (e.g., a high-capacity, removable flash memory card for storing images). An example of a camera with an image buffer is depicted in <figref idrefs="DRAWINGS">FIG. 6B</figref>.</p>
    <p num="p-0119">A wide variety of different types of memory and storage devices are possible and are known to those skilled in the art. For example, memory may be volatile or non-volatile; may be electronic, capacitive, inductive, or magnetic in nature; and may be accessed sequentially or randomly.</p>
    <p num="p-0120">Memory may be volatile and/or non-volatile. As will be readily understood, most RAM is volatile (DRAM=Dynamic Random Access Memory), meaning that it is erased whenever the device is turned off. In contrast, EEPROMs (Electrically Erasable Programmable Read-Only Memory) like flash memory cards are non-volatile; images stored in a flash memory card will continue to be stored even after a device is turned off.</p>
    <p num="p-0121">Memory may or may not be designed to be removable (e.g., by a user) from a device (e.g., camera <b>530</b>, computing device <b>400</b>). Many types of cameras, for example, may use one or more forms of removable memory, such as chips, cards, and/or discs, to store and/or to transfer images and other data. For instance, it is typically possible for a user to remove a flash memory card from a camera that accepts such memory (e.g., for transferring images to a personal computer), but it is typically difficult for a user to remove a camera's RAM or ROM (e.g., storing a program for various camera functions).</p>
    <p num="p-0122">Some examples of removable non-volatile memory include, without limitation: a flash memory card, a hard drive, and a compact disc. A flash memory card is a variation of an EEPROM (Electrically Erasable Programmable Read-Only Memory). Some examples flash memory cards include CompactFlash™ cards, SmartMedia™ cards, Sony Memory Sticks™, MultiMediaCards™ (MMC) memory cards, and Secure Digital™ (SD) memory cards. Some examples of hard drives include IBM Microdrives™, which are small, lightweight hard drives. Some Microdrives™ may store up to 1 GB of information. Some examples of compact discs include CD-R (e.g., writeable) and CD-RW (e.g., rewriteable) recordable compact discs and DataPlay™ optical media. In another example, Sony's MVC-CD400 stores captured images on 8 cm CD-R/RW compact discs, making it easy for a user to transfer files from the camera to a personal computer.</p>
    <p num="p-0123">Memory <b>510</b> (as well as other types of memory and storage devices discussed herein) may comprise any number of different types of memory. In some embodiments, different types of memory may be more suitable for different purposes. In some embodiments, memory <b>510</b> may comprise a primary memory and a secondary memory. Primary memory, for example, may be fast, expensive, volatile memory that is used by the processor <b>505</b> in performing various calculations. RAM is one common example of primary memory. An example of a camera including a RAM is depicted in <figref idrefs="DRAWINGS">FIG. 6B</figref>. In contrast, secondary memory may be slower, less expensive, and non-volatile memory that is used for storing information over a longer period of time. A hard disk is one example of a secondary memory.</p>
    <p num="p-0124">It will be understood that different types of memory may run at different speeds and thus may be more suitable for different purposes. For example, a captured image buffer on a camera may store and access images very quickly, whereas it may take a relatively longer period of time to store or access data on a hard disc such as an IBM Microdrive. Those skilled in the art understand that there are a variety of different ways of measuring the speed of a memory.</p>
    <p num="p-0125">It will be understood that memory may be read-only, rewriteable, or once-writeable. For example, ROM that stores a program for the camera may be read-only, whereas RAM used for image processing may be rewriteable. It will also be understood that memory may be internal or external. For example, a camera may store images on an internal RAM and/or on a digital wallet or other portable hard drive.</p>
    <p num="p-0126">Referring again to <figref idrefs="DRAWINGS">FIG. 5</figref>, the memory <b>510</b> stores a program <b>515</b> for controlling the processor <b>505</b>. The program <b>515</b> may comprise instructions (e.g., Digita® imaging software, image recognition software) for capturing images and/or for one or more other functions. The processor <b>505</b> performs instructions of the program <b>515</b>, and thereby operates in accordance with the present invention, and particularly in accordance with the methods described in detail herein. The program <b>515</b> may be stored in a compressed, uncompiled and/or encrypted format. The program <b>515</b> furthermore includes program elements that may be necessary, such as an operating system, a database management system and “device drivers” for allowing the processor <b>505</b> to interface with computer peripheral devices. Appropriate program elements are known to those skilled in the art, and need not be described in detail herein.</p>
    <p num="p-0127">According to one embodiment of the present invention, the instructions of the program <b>515</b> may be read into a main memory from another computer-readable medium, such from a ROM to RAM. Execution of sequences of the instructions in program <b>515</b> causes processor <b>505</b> to perform the process steps described herein. In alternate embodiments, hard-wired circuitry may be used in place of, or in combination with, software instructions for implementation of the processes of the present invention. Thus, embodiments of the present invention are not limited to any specific combination of hardware and software. In one embodiment, execution of sequences of the instructions in a program of a server <b>550</b> in communication with camera <b>530</b> may also cause processor <b>505</b> to perform some of the process steps described herein.</p>
    <p num="p-0128">The memory <b>510</b> optionally also stores one or more databases, such as any of the exemplary databases described in <figref idrefs="DRAWINGS">FIG. 4</figref>. Examples of a memory of a camera storing various databases are discussed herein with respect to <figref idrefs="DRAWINGS">FIGS. 6A and 6B</figref>.</p>
    <p num="p-0129">The processor <b>505</b> is preferably also in communication with one or more imaging devices <b>535</b> (e.g., a lens, an image sensor) embodied in the camera <b>530</b>. Various types of imaging devices are discussed herein and in particular with respect to <figref idrefs="DRAWINGS">FIGS. 6A and 6B</figref>.</p>
    <p num="p-0130">The processor <b>505</b> is preferably also in communication with one or more input devices <b>525</b> (e.g., a button, a touch screen) and output devices <b>540</b>. Various types of input devices and output devices are described herein and in particular with respect to <figref idrefs="DRAWINGS">FIGS. 6A and 6B</figref>.</p>
    <p num="p-0131">Such one or more output devices <b>540</b> may comprise, for example, an audio speaker (e.g., for outputting information to a user), an infra-red transmitter (e.g., for transmitting a suggested meta-tag to a user's PDA), a display device (e.g., a liquid crystal display (LCD)), a radio transmitter, and a printer (e.g., for printing an image).</p>
    <p num="p-0132">An input device <b>525</b> is capable of receiving an input (e.g., from a user or another device) and may be a component of camera <b>530</b>. An input device <b>525</b> may communicate with or be part of another device (e.g., a server, a PDA). For cameras, common input devices include a button or dial. Some other examples of input devices include: a keypad, a button, a handle, a keypad, a touch screen, a microphone, an infrared sensor, a voice recognition module, a motion detector, a network card, a universal serial bus (USB) port, a GPS receiver, a radio frequency identification (RFID) receiver, an RF receiver, a thermometer, a pressure sensor, and an infra-red port (e.g., for receiving communications from with a second camera or another device such as a smart card or PDA of a user).</p>
    <p num="p-0133">Referring now to <figref idrefs="DRAWINGS">FIG. 6A</figref>, illustrated therein is a block diagram of one embodiment <b>600</b> of a camera (e.g., camera <b>330</b> of <figref idrefs="DRAWINGS">FIG. 3</figref>, camera <b>530</b> of <figref idrefs="DRAWINGS">FIG. 5</figref>). The camera <b>600</b> comprises a processor <b>605</b>, such as one or more Intel Pentium™ processors. The processor <b>605</b> is in communication with a memory <b>610</b> and a communication port <b>695</b> (e.g., for communicating with one or more other devices). The memory <b>610</b> may comprise or include any type of computer-readable medium, and stores a program <b>615</b> for controlling the processor <b>605</b>. The processor <b>605</b> performs instructions of the program <b>615</b>, and thereby operates in accordance with various processes of the present invention, and particularly in accordance with the methods described in detail herein.</p>
    <p num="p-0134">The memory <b>610</b> stores a plurality of databases, including an acquire condition database <b>620</b>, an acquired image log <b>625</b>, an image rating database <b>630</b>, an image database <b>635</b>, a compression condition database <b>640</b>, and a compression tracking database <b>645</b>. Examples of each of these databases are described in detail below and example structures are depicted with sample entries in the accompanying figures.</p>
    <p num="p-0135">The processor <b>605</b> is preferably also in communication (directly or indirectly) with a lens <b>660</b> (e.g., made of glass), an image sensor <b>665</b>, one or more controls <b>670</b> (e.g., an exposure control), one or more sensors <b>675</b>, one or more output devices <b>680</b> (e.g., a liquid crystal display (LCD)), and a power supply <b>685</b> (e.g., a battery, a fuel cell, a solar cell). Various examples of these types of components are described herein.</p>
    <p num="p-0136">A processor of a camera <b>600</b> may be capable of executing instructions (e.g., stored in memory <b>610</b>) such as software (e.g., for wireless and/or digital imaging, such as Digital® software from Flashpoint Technology, Inc.).</p>
    <p num="p-0137">As indicated in <figref idrefs="DRAWINGS">FIG. 6A</figref>, a camera may include one or more input devices capable of receiving data, signals, and indications from various sources. Lenses, sensors, communication ports and controls are well known types of input devices.</p>
    <p num="p-0138">Various types of lenses that may be used with cameras are well known, including telephoto, wide-angle, macro, and zoom lenses.</p>
    <p num="p-0139">As will be understood by those of skill in the art, an image sensor may be an area that is responsive to light and may be used to capture an image. An image sensor may or may not be an electronic device. Some examples of image sensors include, without limitation: a CCD (Charge Coupled Device) and a CMOS (Complementary Metal Oxide Semiconductor) image sensor, such as the X3® PRO 10M™ CMOS image sensor by Foveon. An image sensor may comprise software or other means for image identification/recognition. “Image sensor” may be most often used to refer to an electronic image sensor, but those skilled in the art will recognize that various other technologies (e.g., a light sensitive film) may also function as image sensors.</p>
    <p num="p-0140">A camera may include one or more output devices <b>680</b>. Examples of output devices include, without limitation: a display (e.g., a color or black-and-white liquid crystal display (LCD) screen), an audio speaker (e.g., for outputting questions), a printer (e.g., for printing images), a light emitting diode (LED) (e.g., for indicating that a self-timer is functioning), and a touch screen. A display may be useful, for example, for displaying images and/or for displaying camera settings.</p>
    <p num="p-0141">The camera <b>600</b> may also include one or more communication ports <b>695</b> for use in communicating with one or more other devices. For example, a USB (universal serial bus) or Firewire® (IEEE-1394 standard) connection port may be used to exchange images and other types of data with a personal computer or digital wallet (e.g., an Apple iPod™). The camera may be in communication with a cellular telephone, wireless-enabled PDA or other device capable of wireless communications. Images and other data may be transmitted to and from the camera <b>600</b> using such a wireless communications device. For example, the SH251I™ cellular telephone by Sharp Corporation includes a 3.1 megapixel CCD camera, and allows users to receive image files via e-mail. In yet another example, a camera may include a radio antenna for communicating with a radio beacon. For instance, a subject of a photo may carry a radio beacon that may communicate with the camera and provide information that is useful in determining settings for the camera (e.g., information about the light incident on the subject).</p>
    <p num="p-0142">As will be understood by those skilled in the art, a camera may include one or more controls <b>670</b> or other input devices. Examples of controls <b>670</b> include, without limitation: a button (e.g., a shutter button), a switch (e.g., an on/off switch), a dial (e.g., a mode selection dial), a keypad, a touch screen, a microphone, a bar code reader (e.g., such as the one on the 1991 version of the Canon EOS Elan™), a remote control (e.g., such as the one on the Canon Powershot G2™), a sensor, a trackball, a joystick, a slider bar, and a continuity sensor.</p>
    <p num="p-0143">Controls <b>670</b> of the camera <b>600</b> or other type of imaging device may be used to perform a variety of functions. In accordance with various embodiments of the present invention, a control may be used, without limitation, to adjust a setting or other parameter, provide an indication (e.g., a response to a prompt), or operate the camera. For example, a user may press the shutter button on the camera to capture an image. Controls may be used to adjust one or more settings on the camera. For example, a user may use “up” and “down” buttons on a camera to adjust the white balance on the camera. In another example, a user may use a mode dial on the camera to select a plurality of settings simultaneously. For example, a user may use a control to indicate to the camera that he would like stored images to be compressed, or to any adjust any of various other types of parameters of how the camera is to operate and/or interact with the user. In another example, a user may use a control to indicate to the camera that he would like the camera to provide audio prompts that guide him in capturing images. As discussed herein, controls may be used to provide an indication to the camera. For example, the camera may output a question to a user (e.g., “Are you taking a picture of a sunset?”) and the user may use a control to indicate his response to the question.</p>
    <p num="p-0144">Various types of sensors <b>675</b> that may be included in a camera <b>600</b> include, without limitation: a light sensor, a proximity sensor (e.g., to determine whether a user is looking through a viewfinder of the camera), a motion sensor (e.g., to detect movement of the camera), an accelerometer, an image sensor, a range sensor (e.g., for determining the distance to a subject), a microphone (e.g., for recording audio that corresponds to a scene), a global positioning system (GPS) device (e.g., for determining a camera's location), a camera orientation sensor (e.g., an electronic compass), a tilt sensor (e.g., for determining a camera's orientation), an altitude sensor, a humidity sensor, a clock (e.g., indicating the time of day, day of the week, month, year), and a temperature/infrared sensor.</p>
    <p num="p-0145">According to some embodiments, a microphone may be useful for allowing a user to control the camera using voice commands. Voice recognition software (e.g., ViaVoice™ from IBM Voice Systems, OpenSpeech from Speechworks International, Nuance 8.0 from Nuance Communications, and Dragon Naturally Speaking from Dragon Systems) is known to those skilled in the art and need not be described further herein.</p>
    <p num="p-0146">Referring now to <figref idrefs="DRAWINGS">FIG. 6B</figref>, illustrated therein is a block diagram of another embodiment <b>650</b> of a camera. Like the camera <b>600</b> depicted in <figref idrefs="DRAWINGS">FIG. 6A</figref>, the exemplary camera <b>650</b> of <figref idrefs="DRAWINGS">FIG. 6B</figref> comprises a processor <b>605</b> in communication (directly or indirectly) with a memory <b>610</b>, a communication port <b>695</b>, a lens <b>660</b>, an image sensor <b>665</b>, one or more controls <b>670</b>, one or more sensors <b>675</b>, one or more output devices <b>680</b>, and a power supply <b>685</b>. Various examples of these types of components are described herein.</p>
    <p num="p-0147">The memory <b>610</b> may comprise or include any type of computer-readable medium, and stores a program <b>615</b> for controlling the processor <b>605</b>. The processor <b>605</b> performs instructions of the program <b>615</b>, and thereby operates in accordance with various processes of the present invention, and particularly in accordance with the methods described in detail herein. The memory <b>610</b> stores a plurality of databases, including an acquire condition database <b>620</b>, an acquired image log <b>625</b>, an image rating database <b>630</b>, a compression condition database <b>640</b>, and a compression tracking database <b>645</b>.</p>
    <p num="p-0148">One difference between the camera <b>600</b> (<figref idrefs="DRAWINGS">FIG. 6A</figref>) and the camera <b>650</b> (<figref idrefs="DRAWINGS">FIG. 6B</figref>) is that camera <b>650</b> includes different exemplary allocations of memory (which may or may not be different types of memory). In addition to the memory <b>610</b>, processor <b>605</b> is in communication with a memory <b>612</b> storing an image database <b>635</b>. In one embodiment, the memory <b>612</b> is a removable non-volatile memory for storing images (e.g., in the image database <b>635</b>). In one embodiment, the memory <b>610</b> is non-removable non-volatile memory.</p>
    <p num="p-0149">Processor <b>605</b> of camera <b>650</b> is also in communication with a RAM <b>690</b> that may be useful in some embodiments for executing instructions (e.g., of the program <b>615</b>).</p>
    <p num="p-0150">Processor <b>605</b> of camera <b>650</b> is also in communication with a captured image buffer <b>667</b> for transferring images from the image sensor <b>665</b>. In one embodiment, the captured image buffer <b>667</b> comprises RAM.</p>
    <p num="p-0151">Of course, it will be understood in light of the present disclosure that various other embodiments are also possible, including embodiments with different types of memory or arrangements of memory. For example, images may be stored in a memory that is not removable. In such an embodiment, a communication port of a camera may be used to transfer images to another device (e.g., server <b>550</b>, computing device <b>120</b>).</p>
    <p num="p-0152">As will be understood by those skilled in the art, a setting for a camera may be a parameter that affects how the camera operates (e.g., how the camera captures at least one image). Examples of types of settings on a camera include, without limitation: exposure settings, lens settings, digitization settings, flash settings, multi-frame settings, power settings, output settings, function settings, and mode settings. Some more detailed examples of these types of settings are discussed further below.</p>
    <p num="p-0153">Exposure settings may affect the exposure of an acquired image. Examples of exposure settings include, without limitation: shutter speed, aperture, image sensor sensitivity (e.g., measured as ISO or ASA), white balance, color hue, and color saturation.</p>
    <p num="p-0154">Lens settings may affect a lens on a camera and/or how a lens acquires an image. Examples of lens settings include, without limitation: focus (e.g., near or far), optical zoom (e.g., telephoto, wide angle), optical filters (e.g., ultraviolet, prism), an indication of which lens to use (e.g., for a camera that has multiple lenses) or which portion of a lens to use, field of view, and image stabilization (e.g., active or passive image stabilization).</p>
    <p num="p-0155">Digitization settings may affect how a camera creates a digital representation of an image. Examples of digitization settings include, without limitation: resolution (e.g., 1600×1200 or 640×480), compression (e.g., for an image that is stored in JPG format), color depth/quantization, digital zoom, and cropping. For instance, a cropping setting may indicate how the camera should crop an acquired digital image when storing it to memory.</p>
    <p num="p-0156">In some embodiments, a compression setting may be a parameter used by an image compression program to determine how much an image is compressed. In some embodiments, a compression setting for an image may be determined based on an image rating and/or how an image is acquired.</p>
    <p num="p-0157">Flash settings may affect how a flash on a camera operates. Examples of flash settings include, without limitation: flash brightness, red-eye reduction, and flash direction (e.g., for a bounce flash).</p>
    <p num="p-0158">Multi-frame settings may affect how a camera captures a plurality of images. Examples of multi-frame settings include, without limitation: a burst mode (e.g., taking a plurality of pictures in response to one press of a shutter button), auto-bracketing (e.g., taking a plurality of pictures with different exposure settings), a movie mode (e.g., capturing a movie), and image combination (e.g., using Canon's PhotoStitch™ program to combine a plurality of images into a single image).</p>
    <p num="p-0159">Power settings may affect the supply of power to one or more of a camera's electronic components. Examples of power settings include, without limitation: on/off and “Power-Save” mode (e.g., various subsystems on a camera may be put into “Power-Save” mode to prolong battery life).</p>
    <p num="p-0160">Output settings may affect how the camera outputs information (e.g., to a user, to a server, to another device). Examples of output settings include, without limitation: language (e.g., what language is used to output prompts, questions, or other information to a user), viewfinder settings (e.g., whether a digital viewfinder on the camera is enabled, how a heads-up-display outputs information to a user), audio output settings (e.g., whether the camera beeps when it captures an image, whether questions may be output audibly), and display screen settings (e.g., how long the camera displays images on its display screen after capturing them).</p>
    <p num="p-0161">In accordance with one or more embodiments of the present invention, a camera may be operable to acquire images and to perform one or more of a variety of other functions. A function setting may cause one or more functions to be performed (and/or prevent one or more functions from being performed). For example, if an auto-rotate setting on a camera is enabled, then the camera may automatically rotate a captured image so that it is stored and displayed right side up, even if the camera was held at an angle when the image was captured. Other examples of functions that may be performed by a camera include, without limitation: modifying an image (e.g., cropping, filtering, editing, adding meta-tags), cropping an image (e.g., horizontal cropping, vertical cropping, aspect ratio), rotating an image (e.g., 90 degrees clockwise), filtering an image with a digital filter (e.g., emboss, remove red-eye, sharpen, add shadow, increase contrast), adding a meta-tag to an image, displaying an image (e.g., on a LCD screen of the camera), and transmitting an image to another device (e.g., a personal computer, a printer, a television).</p>
    <p num="p-0162">One way to adjust a setting on the camera is to change the camera's mode. For example, if the camera were to be set to “Fluorescent Light” mode, then the settings of the camera would be adjusted to the exemplary values listed in this column (i.e., the aperture would be set to automatic, the shutter speed would be set to 1/125 sec, the film speed would be set to 200 ASA, etc.).</p>
    <p num="p-0163">In accordance with some embodiments of the present invention, a mode refers to one or more parameters that may affect the operation of the camera. A setting may be one type of parameter. Indicating a mode to the camera may be a convenient way of adjusting a plurality of settings on the camera (e.g., as opposed to adjusting each setting individually). There are many types of modes. Some types, for example, may affect settings (e.g., how images are acquired). Some exemplary modes are discussed herein, without limitation, and other types of modes will be apparent to those skilled in the art in light of the present disclosure. A “Sports” mode, for example, may describe settings appropriate for capturing images of sporting events (e.g., fast shutter speeds). For instance, a user may operate a control (e.g., a dial) to indicate that the camera should be in “Sports” mode, in which the shutter speed on the camera is faster than 1/250 sec and burst capturing of three images is enabled. An exemplary “Fluorescent Light” mode may establish settings appropriate for capturing images under fluorescent lights (e.g., white balance). A “Sunny Beach” mode may describe settings appropriate for capturing images on sunny beaches, and a “Sunset” mode may describe settings appropriate for capturing images of sunsets (e.g., neutral density filter). An exemplary “Portrait” mode may establish settings appropriate for capturing close-up images of people (e.g., adjusting for skin tones). A “Power-Save” mode may describe settings appropriate for minimizing the amount of power consumed by a camera. A “Silent” mode may describe settings that prevent the camera from making noises (e.g., audible beeps). A “Macro” mode may describe settings appropriate for capturing images that are within a predetermined distance of a camera.</p>
    <p num="p-0164">Databases</p>
    <p num="p-0165">Referring now to <figref idrefs="DRAWINGS">FIG. 7</figref>, an exemplary tabular representation <b>700</b> illustrates one embodiment of acquire condition database <b>420</b> (or acquire condition database <b>620</b>) that may be stored, for example, in an imaging device <b>110</b> and/or computing device <b>120</b>. The tabular representation <b>700</b> of the acquire condition database includes a number of example records or entries, each defining a condition that may be useful for determining whether one or more images should be acquired. Those skilled in the art will understand that the acquire condition database may include any number of entries.</p>
    <p num="p-0166">The tabular representation <b>700</b> also defines fields for each of the entries or records. The exemplary fields specify: (i) an acquire condition identifier <b>705</b> that uniquely identifies a particular acquire condition, and (ii) an acquire condition <b>710</b> that includes an indication of a condition for acquiring at least one image.</p>
    <p num="p-0167">An acquire condition database may be useful for various types of processes described herein. In some embodiments, an acquire condition databse may be used to store conditions. If, for example, a processor (e.g., processor <b>405</b>) determines a stored acquire condition to be true, the processor may direct an imaging device (e.g., imaging device <b>210</b>) to acquire one or more images (e.g., automatically). For instance, an example acquire condition <b>705</b> identified as “AC-47532524-01” corresponds to a condition <b>710</b> described by “(CAMERA_VIEWFINDER.IN_USE=‘TRUE’).” According to this example entry, if a camera viewfinder is in use, the camera will automatically acquire at least one image.</p>
    <p num="p-0168">Referring now to <figref idrefs="DRAWINGS">FIG. 8</figref>, an exemplary tabular representation <b>800</b> illustrates one embodiment of acquired image log <b>425</b> (or acquired image log <b>625</b>) that may be stored, for example, in a computing device <b>400</b>, computing device <b>120</b>, storage device <b>240</b>, and/or camera <b>530</b>. The tabular representation <b>800</b> of the acquired image log includes a number of example records or entries, each describing an acquired image. Those skilled in the art will understand that the image database may include any number of entries.</p>
    <p num="p-0169">The tabular representation <b>800</b> also defines fields for each of the entries or records. The exemplary fields specify: (i) an image identifier <b>805</b> that uniquely identifies an image, (ii) a time <b>810</b> that indicates when the image was acquired, (iii) a reason <b>815</b> that indicates why the image was acquired, (iv) an overall rating <b>820</b> that indicates a quality of the image, (v) an image stored <b>825</b> that indicates if the acquired image is stored (e.g., in a secondary memory), and (vi) a compression setting <b>830</b> that indicates a value of a compression setting associated with the image (if any).</p>
    <p num="p-0170">In some embodiments, an image may be acquired (e.g., automatically) by an imaging device in response to a determination (e.g., by a processor) that an acquire condition is satisfied. In some embodiments, the reason <b>815</b> may store one or more acquire condition identifiers corresponding to respective acquire conditions that were satisfied and thus prompted an imaging device to acquire the corresponding image(s) automatically. In some embodiments, the reason <b>815</b> may include a description of a corresponding acquired condition (e.g., such as condition <b>710</b>).</p>
    <p num="p-0171">In some embodiments, the reason <b>815</b> may store an indication that an acquired image was acquired in response to some manual interaction of a user with an imaging device, such as the user initiating a self-timer of a camera or using a shutter button. In one example, the sample data in the tabular representation <b>800</b> indicates that an image identified as “WEDDING-02” was acquired because a “USER PRESSED SHUTTER BUTTON.”</p>
    <p num="p-0172">As discussed herein, in some embodiments an overall rating <b>820</b> may be determined for an image that indicates a quality of the image. As also discussed herein, in some embodiments a processor may determine (e.g., based on a quality of an image) whether to store (e.g., in a removable memory) an image that was acquired (e.g., automatically). For example, an automatically-acquired image may only be stored in a flash memory card if it has an overall rating <b>820</b> of “4.0” or greater. The information in image stored <b>825</b> preferably includes an indication (e.g., “YES,” “NO”) of whether the corresponding acquired image was also stored (e.g., in a memory other than an image buffer).</p>
    <p num="p-0173">The tabular representation <b>800</b> includes some example entries of acquired images. For instance, the sample data in the tabular representation <b>800</b> indicates that an image identified as “WEDDING-01” was acquired based on the acquire condition identified as “AC-47532524-01” at “1:40 PM Aug. 3, 2002.” The image is associated with an overall rating of “7.7” and was stored at a compressing setting of “95%.” The example overall rating <b>825</b> for “WEDDING-01” corresponds to the overall rating <b>1025</b> and <b>930</b> depicted in the example image database (<figref idrefs="DRAWINGS">FIG. 10</figref>) and example image rating database <b>430</b> (<figref idrefs="DRAWINGS">FIG. 9</figref>) for that image, respectively. In another example, an image identified as “WEDDING-02” was acquired because a “USER PRESSED SHUTTER BUTTON” and stored at a compression setting of “95%.” In another example, an acquired image identified as “WEDDING-03” with an overall rating of “3.4” was not stored.</p>
    <p num="p-0174">Referring now to <figref idrefs="DRAWINGS">FIG. 9</figref>, an exemplary tabular representation <b>900</b> illustrates one embodiment of an image rating database <b>430</b> (or image rating database <b>630</b>) that may be stored, for example, in a computing device <b>400</b>, imaging device <b>110</b>, camera <b>600</b>, and/or storage device <b>240</b>. The tabular representation <b>900</b> of the image rating database includes a number of example records or entries, each describing one or more ratings associated with an acquired image. Those skilled in the art will understand that the image database may include any number of entries.</p>
    <p num="p-0175">The tabular representation <b>900</b> also defines fields for each of the entries or records. The exemplary fields specify: (i) an image identifier <b>905</b> that uniquely identifies an acquired image, (ii) an exposure rating <b>910</b> that includes a description or other indication of the exposure of the acquired image, (iii) a sharpness rating <b>915</b> that includes a description or other indication of the sharpness of the acquired image, (iv) a composition rating <b>920</b> that includes a description or other indication of the composition of the acquired image, (v) a subject rating <b>925</b> that includes a description or other indication of the subject of the acquired image, and (vi) an overall rating <b>930</b> that includes a description or other indication of the quality of an acquired image (e.g., based on one or more types of ratings).</p>
    <p num="p-0176">In some embodiments, the image identifier <b>905</b> may correspond to an image identifier stored in an acquired image log (e.g., as depicted in <figref idrefs="DRAWINGS">FIG. 8</figref>) and/or stored in an image database (e.g., as depicted in <figref idrefs="DRAWINGS">FIG. 10</figref>).</p>
    <p num="p-0177">According to some embodiments of the present invention, methods and apparatus are provided for determining ratings of an image in one or more categories. Such ratings may be represented as numerical values (as depicted in the sample data of <figref idrefs="DRAWINGS">FIG. 9</figref>), but of course may be expressed in any of various other ways, such as a letter- or word-based grading system (e.g., “A,” “B,” “GOOD,” “POOR”), deemed appropriate for describing a particular characteristic of an image. In the sample data of <figref idrefs="DRAWINGS">FIG. 9</figref>, a higher numerical rating corresponds to a determination of a higher quality in the corresponding category (e.g., exposure, composition). As described herein, ratings may be useful, in accordance with some embodiments, for determining whether to store an acquired image and/or for determining whether to compress or delete an image.</p>
    <p num="p-0178">An exposure rating <b>910</b> preferably indicates the relative quality of the exposure of an acquired image. For instance, an over- or under-exposed image may receive a lower exposure rating than a properly exposed image.</p>
    <p num="p-0179">A sharpness rating <b>915</b> preferably indicates the relative sharpness or level of focus of an image. For instance, a sharper image may have a higher sharpness rating than a blurred or poorly focused image.</p>
    <p num="p-0180">A composition rating <b>920</b> preferably indicates the relative quality of how an image is composed. For instance, an image that is well-oriented and centered may receive a higher composition rating than an image that is not aimed as precisely.</p>
    <p num="p-0181">A subject rating <b>925</b> preferably includes an indication of how interesting the subject might be to a user of a camera. For instance, a higher subject rating may indicate that a user does (or is likely to) find an image's subject more interesting than an image with a lower subject rating. In some embodiments, images acquired manually (e.g., by a user pressing a shutter button) are not rated for subject because it may be assumed that images acquired manually are interesting to a user of a camera. Alternatively, for the same reason, manually-acquired images may be assigned the highest subject rating (or any other predetermined subject rating).</p>
    <p num="p-0182">An overall rating <b>930</b> preferably includes an indication of the relative quality of an image based on one or more ratings in a respective category. For example, the overall rating <b>930</b> of an automatically-captured image may be equal to the average of the ratings in all rating categories (e.g., subject, sharpness) for that image. For instance, the overall rating <b>930</b> for the image “WEDDING-01” is depicted as “7.7,” which is the numerical average of the indicted exposure rating <b>910</b> (“8.5”), sharpness rating <b>915</b> (“7.2”), composition rating <b>920</b> (“7.1”) and subject rating <b>925</b> (“8.0”).</p>
    <p num="p-0183">Referring now to <figref idrefs="DRAWINGS">FIG. 10</figref>, an exemplary tabular representation <b>1000</b> illustrates one embodiment of image database <b>435</b> (or image database <b>635</b>) that may be stored, for example, in a computing device <b>120</b>, server <b>550</b>, and/or storage device <b>240</b>. The tabular representation <b>1000</b> of the image database includes a number of example records or entries, each describing a captured image. Those skilled in the art will understand that the image database may include any number of entries.</p>
    <p num="p-0184">The tabular representation <b>1000</b> also defines fields for each of the entries or records. The exemplary fields specify: (i) an image identifier <b>1005</b> that uniquely identifies an image, (ii) an image format <b>1010</b> that indicates a format of a file storing the image, (iii) a file size <b>1015</b> that indicates a size of the file storing the image, (iv) a method <b>1020</b> that indicates how an image was captured (e.g., manually or automatically), (v) an overall rating <b>1025</b> that indicates a quality of the image, and (vi) meta-data <b>1030</b> that indicates any of various types of supplemental information (e.g., keyword, category, subject, description, location, camera settings when the image was captured) associated with the image.</p>
    <p num="p-0185">With respect to the image identifier <b>1005</b>, in some embodiments a camera may automatically assign an identifier to an image. In some embodiments a user may use a control (e.g., a keypad) of a camera to indicate an identifier for an image (and/or to modify an identifier previously assigned to the image).</p>
    <p num="p-0186">With respect to the image format <b>1010</b>, images may be stored in a variety of different file formats. Some examples of formats include, without limitation: JPEG (a lossy, compressed 24-bit color image storage format developed by Joint Photographic Experts Group), JFIF (JPEG File Interchange Format), TIFF (Tagged Image File), BMP (Microsoft Windows Bitmap), RAW (a file format that is native to a camera), PicSurf variable resolution file format, Kodak Photo CD (Image Pac), and PICT (Macintosh Picture).</p>
    <p num="p-0187">It will be understood by those skilled in the art that a variety of different types of meta-data <b>1030</b> are possible, including position (e.g., GPS coordinates where the image was captured), orientation (e.g., of the camera), altitude, camera settings (e.g., aperture and shutter speed used to capture the image, auto-bracketing settings), illumination (e.g., daylight, tungsten, florescent, IR, flash), lens setting (e.g., distance, zoom position, macro), scene data (e.g., “blue sky,” “water,” “grass,” “faces”), subject motion, image content (e.g., subjects), image categorization, sound annotations, date and time (e.g., when an image was captured), preferred cropping, and scale. In some embodiments, the method <b>1020</b> and/or the overall rating <b>1025</b> may be considered meta-data and may be included (alternatively or in addition) in meta-data <b>1030</b>. Other types of meta-data, meta-tagging and meta-information are discussed herein.</p>
    <p num="p-0188">The tabular representation <b>1000</b> includes some example entries of captured images. For instance, an image identified as “WEDDING-01” is described as being in a “JPEG” image format. Other example formats include Tagged Image File Format (TIFF) and RAW, which may refer to a file format that is native to a particular camera (e.g., an uncompressed, unprocessed format). “WEDDING-01” has an indicated file size of “1494 KB” was captured with a method described as “AUTOMATIC.” The image is associated with an overall rating of “7.7” and with the meta-data, “SUBJECTS: ALICE, BOB.” The overall rating <b>1025</b> for “WEDDING-01” corresponds to the overall rating <b>820</b> and <b>930</b> depicted in the example image acquired log <b>425</b> (<figref idrefs="DRAWINGS">FIG. 8</figref>) and example image rating database <b>430</b> (<figref idrefs="DRAWINGS">FIG. 9</figref>) for that image, respectively.</p>
    <p num="p-0189">An image database may be useful for various types of processes described herein. In some embodiments, an image database may be used to store images and/or information about images acquired and stored by a camera (e.g., camera <b>210</b>, camera <b>530</b>). For example, as discussed further herein, a camera may acquire an image and rate the acquired image. If, according to various considerations, it is determined that the acquired image should be stored (e.g., in a secondary memory), information about the stored image (and/or the stored image) may be stored in an image database. In some embodiments, information about images that were not stored in a secondary memory is not stored in the image database <b>435</b>. For example, image “WEDDING-03,” described in <figref idrefs="DRAWINGS">FIG. 8</figref> and <figref idrefs="DRAWINGS">FIG. 9</figref>, is not included in the tabular representation <b>1000</b> of the image database <b>635</b> (e.g., because its overall rating of “3.4” is lower than a predetermined threshold for storing the image).</p>
    <p num="p-0190">In some embodiments, an image file may be stored in an image database (e.g., in a corresponding record of image database <b>635</b>). In other embodiments, an image database may store an indication of a pointer (e.g., a filepath, a memory address) to where an image file is stored. In some embodiments, the image identifier (e.g., image identifier <b>905</b> or <b>1005</b>) may comprise such a pointer.</p>
    <p num="p-0191">In some embodiments, image database <b>635</b> may be stored in a removable, non-volatile memory.</p>
    <p num="p-0192">In accordance with some embodiments, as discussed further herein, storing an image may include compressing the image. Compressing an image may include determining a representation of an image that may be stored in less space. For example, an image that would require 10 Mb of memory to store in an uncompressed format may be compressed so that it only occupies 1 Mb of memory. Compressing an image is particularly useful for reducing the amount of memory required to store an image and thereby increasing the number of images that the camera may store in memory. Various forms of image compression and algorithms or processes are known to those skilled in the art for compressing images and need not be described in detail herein. Some examples of image compression include JPEG, a lossy form of compression, and LZW (Lempel-Ziv-Welch), a lossless form of compression used in the GIF and TIFF file formats.</p>
    <p num="p-0193">Referring now to <figref idrefs="DRAWINGS">FIG. 11</figref>, an exemplary tabular representation <b>1100</b> illustrates one embodiment of compression condition database <b>440</b> (or compression condition database <b>640</b>) that may be stored, for example, in an imaging device <b>110</b>, server <b>550</b> and/or camera <b>650</b>. The tabular representation <b>1100</b> of the compression condition database includes a number of example records or entries, each defining a condition that may be useful for determining whether one or more images should be compressed or deleted. Those skilled in the art will understand that the compression condition database may include any number of entries.</p>
    <p num="p-0194">The tabular representation <b>1100</b> also defines fields for each of the entries or records. The exemplary fields specify: (i) a compression condition <b>1105</b> that includes an indication of a condition for compressing one or more images, (ii) a selection condition <b>1110</b> that includes an indication of a condition for selecting one or more images to compress, and (iii) an amount to compress <b>1115</b> that includes an indication of how much to compress one or more selected images.</p>
    <p num="p-0195">A compression condition database may be useful for various types of processes described herein. In some embodiments, a compression condition database may be used to store one or more compression conditions. If, for example, a processor (e.g., processor <b>405</b>) determines a stored compression condition has been met, the processor may direct a computing device (e.g., computing device <b>220</b>) or an imaging device (e.g., imaging device <b>210</b>, camera <b>530</b>) to compress or delete one or more images (e.g., automatically). Compression (and/or deletion) of image files may be useful for managing memory for storing images. For instance, compressing or deleting an image may free up memory for capturing additional images.</p>
    <p num="p-0196">It will be readily understood that an image may be compressed based on one or more compression parameters. For example, one or more compression parameters may affect how a computer program compresses an image. One common type of compression parameter is a compression setting, such as amount to compress <b>1115</b>, which may affect how much an image is compressed. For example, many JPEG image compression programs allow a user to specify a compression setting or quality setting on a 0-100 scale, with 0 corresponding to a high level of compression (and smaller file size) and 100 corresponding to a lower level of compression (and larger file size). The compression setting used in these JPEG image compression programs is often referred to as a percentage (e.g., 20% compression, 76% compression), even though this compression setting seldom reflects the actual compression ratio achieved by the compression. As is known to those skilled in the art, different image compression programs may operate based on different compression parameters, including different compression settings.</p>
    <p num="p-0197">The tabular representation <b>1100</b> includes example data that may be stored in a compression condition database. For instance, one example compression condition <b>1105</b> is described by “(AMOUNT_OF_FREE_MEMORY&lt;10 MB).” According to this example entry, if an amount of free memory available to an imaging device is less than 10 MB, it may be determined (e.g., by a processor <b>405</b> or <b>505</b>) to compress one or more images. In some embodiments, if a compression condition is true, a corresponding selection condition may be used to identify one or more stored images to compress. For instance, the example compression condition <b>1105</b> discussed above is associated with a selection condition <b>1110</b> described by “(IMAGE_CAPTURED_AUTOMATICALLY) AND IMAGE_RATING&lt;=7.0).” According to this example entry, an image may be selected for compression (e.g., automatically by the processor <b>405</b>) if the image was (i) captured automatically and (ii) has an image rating (e.g., an associated overall rating) that is less than “7.0.” Any number of images meeting these criteria may be selected, as deemed appropriate for the particular application. In some embodiments, if one or more images are selected for compression, how much a particular image is compressed may be based on a mathematical formula or other condition. According to the sample entry, if an image is selected based on the example selection condition <b>1110</b>, it will be compressed (e.g., in accordance with an image compression program) based on the formula indicated in the amount to compress <b>1115</b>, which indicates that a compression of “70%” will be applied if the associated image rating is between “6.0” and “7.0.” A compression of “60%” will be applied if the rating is less than or equal to “6.0.”</p>
    <p num="p-0198">Referring now to <figref idrefs="DRAWINGS">FIG. 12</figref>, an exemplary tabular representation <b>1200</b> illustrates one embodiment of compression tracking database <b>450</b> (or compression tracking database <b>650</b>) that may be stored, for example, in an imaging device <b>110</b>, server <b>550</b> and/or camera <b>650</b>. The tabular representation <b>1200</b> of the compression tracking database includes a number of example records or entries, each indicating information about a respective image. Those skilled in the art will understand that the compression tracking database may include any number of entries.</p>
    <p num="p-0199">The tabular representation <b>1200</b> also defines fields for each of the entries or records. The tabular representation <b>1200</b> also defines fields for each of the entries or records. The exemplary fields specify: (i) an image identifier <b>1205</b> that uniquely identifies an image, (ii) an original file size <b>1210</b> that indicates a size of the file including the image when it was first stored, (iii) selected for compression <b>1215</b> that indicates whether the corresponding image has been selected for compression, and (iv) a current file size <b>1220</b> that indicates a current size of the file including the image.</p>
    <p num="p-0200">In some embodiments, the compression tracking database may indicate a previous file size of an image, which may or may not be the same as a file size of an image when it was first stored.</p>
    <p num="p-0201">In some embodiments, the original file size <b>1210</b> indicates a size of a file that is uncompressed. In other embodiments, the original file size <b>1210</b> may indicate a size of a file that is compressed (e.g., where a camera automatically compresses a file when it first stores it).</p>
    <p num="p-0202">The selected for compression <b>1215</b> preferably indicates (e.g., “YES,” “NO”) whether an image has been selected for compression (e.g., based on a selection condition <b>1110</b> (<figref idrefs="DRAWINGS">FIG. 11</figref>)).</p>
    <p num="p-0203">In some embodiments, current file size <b>1220</b> will be the same as the original file size <b>1210</b> if the corresponding image has not been compressed (or if the image has not been compressed any further).</p>
    <p num="p-0204">In some embodiments, the compression tracking database may include information about one or more of (i) an amount of memory used before one or more images are compressed, (ii) an amount of memory used after one or more images are compressed, and (iii) an amount of memory made available (e.g., freed up) by compressing one or more images.</p>
    <p num="p-0205">The tabular representation <b>1200</b> includes example data that may be stored in a compression tracking database. For instance, with respect to the sample record for an image “WEDDING-01,” the original file size was “1494 KB,” the image is not selected for compression, and the current file size is also “1494 KB.” In another example, the image “WEDDING-04” had an original file size of “968 KB,” was selected for compression, and now has a current file size of “586 KB.”</p>
    <p num="p-0206">Processes</p>
    <p num="p-0207">An image may be captured based one or more settings. For example, an image that is captured by a camera may depend on the current aperture, shutter speed, zoom, focus, resolution, and compression settings. Similarly, an image may be captured based on a current mode of the camera (e.g., “Sunset” mode, “Sunny Beach” mode). For example, the camera may have a “Sunset” mode, which describes settings appropriate for capturing images of sunsets.</p>
    <p num="p-0208">In accordance with some embodiments of the present invention, images may be captured (e.g., using an imaging device <b>110</b>) in a variety of ways. It will be readily understood that some types of cameras may capture one or more images based on or in response to an indication by a user. For instance, a user may operate a control on a camera (e.g., a shutter button) to capture an image. Some examples, without limitation, include: a camera may capture an image when a user presses the shutter button on the camera, a camera may capture an image based on a self-timer set by a user, a camera may capture an auto-bracketed set of images in response to a user pressing the shutter button, and a camera may capture a sequence of images (e.g., of a sporting event) in response to a user holding down the shutter button on the camera (e.g., when the camera is in a burst mode).</p>
    <p num="p-0209">Various embodiments of the present invention provide for methods and apparatus for capturing an image automatically and/or capturing an image manually. It will be readily understood that capturing an image manually may include receiving an indication from a user that an image should be captured. Some examples of receiving an indication from a user include, without limitation: a user pressing a shutter button or other shutter control of a camera, thereby manually capturing an image; a user setting a self-timer on a camera (e.g., by putting the camera in a self-timer mode and/or pressing a shutter button), thereby indicating that the camera should capture an image after a predetermined period of time (e.g., in fifteen seconds); a user holding down the shutter button on a camera, indicating that the camera should capture a series of images (e.g., when taking pictures of a sporting event); a user putting a camera in a burst mode, in which the camera captures a sequence of images (e.g., three) each time the user presses the shutter button; and a user putting a camera into an auto-bracketing mode, in which the camera captures a series of images using different exposure settings each time the user presses the shutter button on the camera.</p>
    <p num="p-0210">In contrast, automatically capturing an image may not involve receiving any indication from a user that an image should be captured. For example, a camera consistent with some embodiments of the present invention may capture an image automatically without the user ever pressing the shutter button on the camera. Unlike capturing an image manually, capturing an image automatically may include, without limitation, one or more of the following:</p>
    <p num="p-0211">capturing an image without a user pressing the shutter button on the camera</p>
    <p num="p-0212">capturing an image without an indication from a user</p>
    <p num="p-0213">capturing an image without a direct indication from the user</p>
    <p num="p-0214">capturing an image without receiving an input from the user</p>
    <p num="p-0215">capturing an image without receiving an indication that the user would like to capture the image</p>
    <p num="p-0216">capturing an image without the user's knowledge</p>
    <p num="p-0217">not providing an indication to a user that an image has been captured</p>
    <p num="p-0218">capturing an image without accessing information provided by a user</p>
    <p num="p-0219">capturing an image based on a condition</p>
    <p num="p-0220">capturing an image based on a condition that was not set by a user</p>
    <p num="p-0221">capturing an image while the camera is being held by a user</p>
    <p num="p-0222">capturing an image independently of a user pressing a shutter button (or other type of shutter control) of the camera</p>
    <p num="p-0223">determining whether to capture an image</p>
    <p num="p-0224">determining whether to capture an image automatically</p>
    <p num="p-0225">According to some embodiments of the present invention, a user may or may not be aware that an image has been captured automatically. For example, a user's camera may not beep (e.g., it may be set to beep when an image is captured manually by pressing a shutter button), display an image that has been captured, or provide any other indication that it has captured an image, as is typically done by digital cameras that capture images manually. Automatically capturing an image quietly and inconspicuously may help to prevent the camera from distracting a user who is in the midst of composing a shot. For example, a user may find it annoying or distracting to have the camera automatically flash or beep when he is about to capture an important image (e.g., manually by pressing a shutter button). In a second example, capturing images without a user's knowledge may allow the camera to give the user a pleasant surprise when the user reviews his captured images and finds that the camera captured images automatically in addition to the images that he captured manually. In another example, a user may manually capture a plurality of images at a birthday party, but miss capturing an image of the birthday boy opening one of the gifts. Fortunately, the camera may have automatically captured one or more images of this special event (even though the user may not have known at the time).</p>
    <p num="p-0226">In accordance with at least one embodiment of the present invention, a camera may capture an image automatically while a user is composing a shot. For example, a user may aim the camera at a subject and begin to compose a shot (e.g., adjusting the zoom on the camera, etc.). While the user is still composing the shot (i.e., before the user presses the shutter button on the camera to capture an image), the camera may capture one or more images automatically. For example, the camera may capture images of scenes that the user aims the camera at, even if the user does not press the shutter button on the camera.</p>
    <p num="p-0227">Some types of cameras that capture images automatically only store such images temporarily (e.g., in volatile memory). The images are typically overwritten soon after they are stored.</p>
    <p num="p-0228">Some embodiments of the present invention may include capturing an image automatically and storing this image in memory that is not non-volatile and/or not automatically overwritten. In some embodiments, an automatically-captured image may be stored in that same type of memory used to store images captured manually by a user.</p>
    <p num="p-0229">In one example, an acquired image may be stored in a camera's non-volatile memory. Storing a captured image in non-volatile memory is different from storing an image in volatile memory such as an image buffer or RAM. For instance, when some types of cameras are turned off, any image that is stored in volatile memory is deleted. In accordance with one embodiment of the present invention, an automatically-captured image is stored in non-volatile memory and thus would be preserved even if the camera is turned off.</p>
    <p num="p-0230">In another example, an image may be stored in a removable memory (e.g., a flash memory card). Removable memory may be larger relative to available non-removable memory of a camera. Some embodiments of the present invention provide the benefit of a camera that may acquire large numbers of images (and/or larger sized image files) automatically and store then in larger, removable storage devices. The availability of removable memory to store automatically-captured images means that the camera will not run out of available memory space as quickly as if it were restricted to storing automatically-captured images in the camera's image buffer or other non-removable memory.</p>
    <p num="p-0231">Referring now to <figref idrefs="DRAWINGS">FIG. 13</figref>, a flowchart illustrates a process <b>1300</b> that is consistent with one or more embodiments of the present invention. For illustrative purposes only, process <b>1300</b> will be described as if a camera (e.g., camera <b>600</b>) is performing all of the steps. The process <b>1300</b>, and all other processes described herein unless expressly specified otherwise, may be performed by an imaging device (e.g., a camera), a computing device (e.g., a camera, a server), a storage device (e.g., a removable flash card) and/or a combination thereof (e.g., a computing device in communication with an imaging device and a storage device). Each of these devices is described in detail herein. Further, the process <b>1300</b>, and all other processes described herein unless expressly specified otherwise, may include steps in addition to those expressly depicted in the Figures or described in the specification, without departing from the spirit and scope of the present invention. Similarly, the steps of process <b>1300</b> and any other process described herein, unless expressly specified otherwise, may be performed in an order other than depicted in the Figures or described in the specification, as appropriate.</p>
    <p num="p-0232">Methods consistent with one or more embodiments of the present invention may include one or more of the following steps of process <b>1300</b>, each of which is described in further detail herein. In other words, some embodiments of the present invention may be generally described by only one or more of the following steps. Some embodiments may comprise one or more additional and/or one or more substituted steps. Of course, the practice of any of the general steps of process <b>1300</b> may comprise various other processes or sub-steps, as discussed herein.</p>
    <p num="p-0233">In step <b>1305</b>, a camera determines whether to acquire an image. Various ways of determining to (or whether to) acquire an image, including based on a determination that one or more conditions are satisfied or on one or more sensors, are discussed herein. In step <b>1310</b>, the camera determines whether to store an acquired image (e.g., the image acquired in step <b>1305</b>). Various ways of determining to (or whether to) store an acquired image, including based on one or more ratings associated with the acquired image, are discussed herein. In step <b>1315</b>, the camera determines how to store an image (e.g., the acquired image). Various ways of determining how to store an image, including based on available memory, compression conditions and/or selection conditions are discussed herein. Some embodiments of the present invention comprise at least one of the steps <b>1305</b>, <b>1310</b> and <b>1315</b> and may further comprise a general step of acquiring an image (e.g., temporarily storing it in an image buffer). Some embodiments of the present invention comprise at least one of the steps <b>1305</b>, <b>1310</b> and <b>1315</b> and may further comprise a general step of storing an acquired image (e.g., in non-volatile memory).</p>
    <p num="p-0234">According to one illustrative embodiment consistent with the general process <b>1300</b>, a camera processor (e.g., processor <b>605</b>) determines to acquire an image (e.g., based on an acquire condition). An image is received by an image sensor (e.g., image sensor <b>665</b>). In one example, a CCD sensor of a camera may be used to covert incident photons into electrical charges and an A2D (analog-to-digital) converter may be used to convert these electrical charges into digital information. Some types of sensors are discussed herein and others will be readily known to those skilled in the art.</p>
    <p num="p-0235">The received image is temporarily stored in a buffer for processing. In one example, an image may be transferred from a CCD sensor to a captured image buffer (e.g., captured image buffer <b>667</b>), where the image may be stored temporarily (e.g., while it is processed by a camera or other computing device). In one example, one or more images may be stored in the captured image buffer <b>667</b> while they are rated by the camera <b>650</b> (e.g., in accordance with instructions of a program <b>615</b>). Various examples of rating images are discussed herein.</p>
    <p num="p-0236">The processor determines to store the image and the image is compressed. For example, a processor <b>605</b> on the camera <b>600</b> may use a JPEG compression algorithm to generate or otherwise determine a compressed version of the image recorded in step <b>1505</b>. For instance, as discussed herein, an image may be compressed based on how it is rated (e.g., lower rated images may be compressed more). The image is then stored in an image database. For example, a recorded image may be stored in non-volatile memory, image database <b>625</b> (e.g., in memory <b>610</b> or <b>612</b>), an EEPROM, a CompactFlash card, or a hard disk. As discussed herein, various types of information relating to an image (e.g., a rating) may also be stored (e.g., as meta-data) in the image database or otherwise associated with a stored image. Various ways of storing an image are discussed herein.</p>
    <p num="p-0237">Determining whether to acquire an image may comprise one or more of: automatically determining whether to acquire an image, determining whether an image sensor should be activated, determining whether to actuate a shutter on the camera, determining whether to acquire information from an image sensor, determining whether to store information from an image sensor, and determining whether to process information from an image sensor.</p>
    <p num="p-0238">There are a variety of different ways in which a camera consistent with one or more embodiments of the present invention may determine whether to capture an image. In some embodiments, a rules-based system may be appropriate. For example, a camera may store or otherwise have access to an acquire condition database, such as the exemplary one depicted in <figref idrefs="DRAWINGS">FIG. 7</figref>. If, for example, a condition listed in the acquire condition database is true, then the camera may determine to acquire one or more image based on that condition. In some embodiments, a camera may use a neural network to analyze information received from one or more sensors on the camera (e.g., a light sensor, a microphone, and image sensor) and may automatically determine whether to acquire an image based on the analysis.</p>
    <p num="p-0239">In some embodiments, one or more images may be acquired based on a condition (e.g., an acquire condition). Acquire conditions may be useful in triggering or enabling a variety of different functions, including, without limitation: determining whether to acquire an image, determining when to acquire an image, determining what image to acquire, and determining how to acquire an image.</p>
    <p num="p-0240">Conditions and the performance of one or more actions based on a condition are discussed variously herein. Accordingly, it will be understood that acquiring an image based on a condition may include, without limitation: acquiring an image when a condition occurs, in response to a condition, when a condition is true, in response to a condition occurring, after a condition is true, at substantially the same time that a condition occurs, at substantially the same time that a condition becomes true, because of a condition, because a condition occurred, and because a condition is true.</p>
    <p num="p-0241">Also, it will be readily understood in light of discussions herein with respect to conditions, that an acquire condition may comprise a Boolean expression and/or may be based on one or more factors. Various examples of factors upon which a condition may be based are discussed herein.</p>
    <p num="p-0242">According to at least one embodiment, an acquire condition (or any other type of condition described herein) may comprise a Boolean expression. The Boolean expression, for example, may reference one or more variables or factors and may include Boolean modifiers and conjunctions (e.g., AND, OR, XOR, NOT, NAND), comparators (e.g., &gt;, &lt;, =, &gt;=, &lt;=, !=), mathematical operations (e.g., +, −, *, /, mean, standard deviation, logarithm, derivative, integral), functions (e.g., search_term_in_database( ), autocorrelation( ), dilate( ), fourier_transform( ), template_match( )), and/or constants (e.g., 10, 20 pixels, 300 milliseconds, 4 lumens, 0.02, 15%, pi, TRUE, yellow, “raining,” 5200 K). Some examples of conditions comprising Boolean expressions include, without limitation:</p>
    <p num="p-0243">
      <tables id="TABLE-US-00001" num="00001"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="203pt" align="left"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">(camera_viewfinder_in_use) AND (available_memory &gt; 50 Mb)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">(average_audio_noise_level &gt;= 70 dB)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">(approx_camera_roll = HORIZONTAL) OR</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">(approx_camera_roll = VERTICAL)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">(peak_color_intensity (image08243) &lt; 100)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0244">A condition may be based on one or more factors. Examples of factors include, without limitation: factors affecting the occurrence of a condition, factors affecting whether a condition is true, factors causing a condition to occur, and factors causing a condition to become true. In some embodiments, at least one image may be acquired based on one or more factors.</p>
    <p num="p-0245">Some general categories of factors include, without limitation: information from sensors, time-related factors, information about images stored in memory, factors relating to a state of the camera, characteristics of a user (e.g., habits, preferences), and information from a database.</p>
    <p num="p-0246">Some examples of factors relating to information from sensors include, without limitation:</p>
    <p num="p-0247">orientation of the camera—For example, the camera may include an orientation sensor (e.g., a tilt sensor) that determines when the camera is being aimed horizontally. Based on this, the camera may automatically acquire an image, since a user of the camera may be composing a shot and the automatically acquired image may be a helpful addition to any image that may be acquired manually by the user.</p>
    <p num="p-0248">a lack of movement of the camera—For example, a lack of movement (e.g., as indicated by a motion sensor) may indicate that the user is aiming the camera and/or composing a shot. In another example, if the lens cap of the camera is off and the camera is not moving, this may be an indication that a user is composing a shot with the camera. In another example, the camera may automatically acquire a plurality of images while a user is composing a shot.</p>
    <p num="p-0249">motion of the camera—For example, the camera may automatically acquire a plurality of images as a user pans the camera across a scene. In some embodiments, these images may later be combined into a single panoramic image. In another example, the camera may include an accelerometer or other motion sensor that determines when a user lifts the camera (e.g., to aim the camera and/or manually capture an image).</p>
    <p num="p-0250">position of the camera—According to one embodiment, the camera may capture images whenever the user is holding the camera at face-level. In another embodiment, the camera may capture images for a predetermined period of time (e.g., ten seconds) after a user raises the camera to face level.</p>
    <p num="p-0251">an indication that a user is using the camera's viewfinder—For example, the camera may use a proximity sensor to determine when a user is holding the camera up to his face and/or looking through the camera's optical viewfinder. If it is determined that a user is looking through the viewfinder on the camera, this may be a good indication that the user is aiming the camera at an interesting scene. In another example, the camera may have a light sensor located near the camera's viewfinder. If a user holds the camera up to his face, then this light sensor may be occluded and therefore not sense very much light (and/or sense a change in light), thus providing an indication that the camera's viewfinder may be in use. Conversely, if the light sensor senses a predetermined amount of light, then this may be an indication that the user is not holding the camera close to his face and/or is not using the viewfinder. In one embodiment, the camera may automatically acquire one or more images based on usage of the viewfinder.</p>
    <p num="p-0252">an indication that a user is using the camera's viewfinder (e.g., via an image sensor)—In a third example of the camera using a sensor to determine that its viewfinder is in use, the camera may include a secondary image sensor that faces the user of the camera (e.g., an image sensor that “looks” out of the camera's optical viewfinder). This secondary image sensor may be used to determine whether or not a user is holding the camera up to his face. For example, if the secondary image sensor “sees” an image of a user's face or eye, then this may be an indication that the user is looking through the camera's viewfinder. Conversely, if the secondary image sensor does not see an image of a user's face or eye, then this may be an indication that the user is not looking through the viewfinder and may not be aiming the camera at an interesting scene.</p>
    <p num="p-0253">location of the camera (e.g., determined via a GPS sensor)</p>
    <p num="p-0254">ambient light (e.g., determined via a light sensor)—For example, if a light sensor on the camera determines that a user is manually capturing images in low light conditions, then the camera may automatically acquire one or more auto-bracketed images, thereby providing insurance that the user captures at least one image that is exposed correctly.</p>
    <p num="p-0255">sounds and audio—For example, the camera may include a microphone. If this microphone senses an increase in the noise level, then this may be a sign that an event is occurring (e.g., a touchdown is being scored in a football game, something amusing just happened at a birthday party or wedding). Based on this increase in noise level (e.g., an condition), the camera may automatically acquire at least one image, based on the assumption (as embodied in the acquire condition) that an increased noise level may indicative of interesting images that should be captured.</p>
    <p num="p-0256">the range to a subject (e.g., as determined using a range sensor)—For example, the camera may determine that the subject of a scene has just moved into the focal range of the camera (a condition). Based on this, the camera may automatically acquire an image of the scene.</p>
    <p num="p-0257">a touch sensor—For example, the camera may have a touch sensor that determines when the user is holding the camera. This may be useful in determining if the user is aiming the camera at a scene, and therefore may be a good condition for acquiring an image automatically.</p>
    <p num="p-0258">signals from other devices (e.g., a radio beacon carried by a subject).</p>
    <p num="p-0259">Examples of time-related factors may include, without limitation: the duration of a condition (e.g., for the last ten seconds, for a total of fifteen minutes), the current time of day, week, month, or year (e.g., 12:23 pm Sep. 6, 2002), a duration of time after a condition occurs (e.g., two seconds after a previous image is captured), an estimated amount of time until a condition occurs (e.g., ten minutes until the camera's batteries run out, twenty minutes before the sun goes down). For example, the camera may automatically acquire an image if a user has been aiming the camera at the same object for longer than two seconds. In a second example, the camera may automatically acquire one or more images of a scene if a user spends more than ten seconds adjusting settings on the camera before manually capturing an image of the scene. In another example, a camera may be configured (e.g., in accordance with an acquire condition) to periodically capture images as long as another condition is true. For example, the camera may capture three images per second as long as the camera is held still and the user is looking through the viewfinder of the camera. In some embodiments, such a succession of images may be captured with one or more different settings (e.g., different exposure settings, different focus settings) or auto-bracketed.</p>
    <p num="p-0260">The camera may determine whether to acquire an image based on an image. For example, the camera may acquire a first image and then determine whether to acquire a second image based on this first image. For example, the camera may capture an image based on one or more of: an image that was captured manually by a user, an image that was acquired automatically by the camera (e.g., and stored in temporary memory), and one or more images stored in the camera's secondary memory (e.g., a CompactFlash card).</p>
    <p num="p-0261">In one example, one or more images may be acquired based on a test or temporary image. For instance, a camera may automatically acquire a test image of a scene and determine whether the scene is interesting or not (e.g., using a scene analysis system). If the scene in the test image appears to be interesting, then the camera may acquire one or more additional images of the scene (e.g., with different exposure settings, etc). The camera may then determine whether or not to acquire at least one additional image based on the analysis of the temporary image. One method of acquiring a temporary image and using the temporary image to determine settings on a camera for capturing a second image and suitable for use with one or more embodiments of the present invention is described in U.S. Pat. No. 6,301,440.</p>
    <p num="p-0262">In another example, a user may manually capture one or more images using a camera. The camera may then analyze these images (e.g., using an image analysis program) and determine whether or not to acquire addition images automatically. For example, the camera may determine that one or more images captured manually by a user are poorly exposed, blurred, or otherwise low quality. Based on this, the camera may determine to acquire at least one additional image (e.g., with different settings). For example, the camera may automatically acquire an auto-bracketed set of images of a scene based on an image that was captured manually by a user.</p>
    <p num="p-0263">In another example, a camera may acquire an image based on the quality of a previously acquired image. For example, the camera may acquire a first image and then determine a rating of the first image. Based on this rating, the camera may determine whether to acquire a second image. In a more detailed example, the camera may acquire an image and rate this image as 3 out of 10 (a poorer rating) because the image is blurred. Based on this, the camera may acquire a second image. In yet another example, the camera may acquire an image and rate this image as an 8 out of 10 (a better rating) because the image shows a complex and interesting scene. Based on this, the camera may acquire additional images of the scene.</p>
    <p num="p-0264">Some other factors relating to images may include: subjects (e.g., a person, a landscape, an animal), scenery (e.g., background, lighting), exposure of images (e.g., brightness, contrast, hue, saturation), framing (e.g., organization of subjects within the image), focus (e.g., sharpness, depth of field), digitization (e.g., resolution, quantization, compression), meta-information associated with an image (e.g., camera settings, identities of people in an image), and movement of subjects (e.g., a person, an animal, a vehicle).</p>
    <p num="p-0265">Some examples of factors relating to habits include a user's habits when operating camera (e.g., the user forgets to take off the lens cap, the user turns the camera on and off a lot). For example, if a user tends to zoom in and out when composing a shot, then the camera may automatically acquire images while the user operating the zoom in and zoom out controls on the camera. In another example, if a user tends to spend at least fifteen seconds composing a shot, then the camera may wait ten seconds after the user starts looking through the viewfinder before it acquires any images automatically.</p>
    <p num="p-0266">Some factors may relate to a user's preferences for capturing images (e.g., the user likes high contrast pictures, the user likes softening filters, the user saves images at best quality JPG compression). In one example, an acquire condition may be used to adjust the settings of the camera based on one or more of the user's preferences.</p>
    <p num="p-0267">Some examples of factors relating to information stored in a database include: templates or other information useful in recognizing or processing an image, images stored in the camera's memory (e.g., a captured image database), indications by a user (e.g., the camera may automatically acquire a plurality of images if a user indicates that he is aiming the camera at an unusual or important scene), predicted weather conditions (e.g., if a user is capturing images on a beach, then the camera may automatically acquire more images during the morning if it is predicted that the weather will be overcast and rainy during the afternoon), current weather conditions, topography, vegetation, locations of landmarks, light sources (e.g., all of the lights in this building are fluorescent), anticipated events (e.g., Old Faithful may prompt the camera to automatically acquire a plurality of images when Old Faithful erupts, even if a user only captures one image manually of the geyser), the current score of a baseball game or other sports event, sunrise and sunset times (e.g., if a user is taking pictures at a picnic, then the camera may acquire more images automatically if the sun will set soon and the picnic is about to end), high and low tide times, and information about a scene.</p>
    <p num="p-0268">Some examples of factors relating to the state of the camera include, without limitation: current and past settings (e.g., shutter speed, aperture, mode), parameters that affect the operation of the camera, current and past modes (e.g., “Sports” mode, “Manual” mode, “Macro” mode, “Twilight” mode, “Fluorescent Light” mode, “Silent” mode, “Portrait” mode, “Output Upon Request” mode, “Power-Save” mode), images stored in memory (e.g., total images stored, amount of memory remaining), current mode (e.g., “Sports” mode), and battery charge level. For example, the camera may determine to acquire an image automatically if a user zooms in on a subject. In a second example, the camera may determine to acquire a plurality of auto-bracketed images automatically if the user spends more than five seconds adjusting the white balance setting on the camera. In another example, the camera may acquire fewer images automatically or completely stop acquiring images automatically if the camera is running out of memory. In another example, the camera may stop acquiring images automatically if the image buffer is full. In yet another example, the camera may determine how many images to acquire automatically based on the amount of memory the camera has available. Acquiring fewer images automatically when the camera is low on primary or secondary memory may help the camera to avoid running out of memory. In another example, the camera may cease capturing images automatically if the camera's batteries begin to run low. In another example, the camera may acquire more images automatically if the camera's batteries are fully charged or if a user indicates that he has additional batteries.</p>
    <p num="p-0269">In accordance with some embodiments of the present invention, a camera may determine to acquire a relatively large number of images automatically and/or may automatically acquire images relatively frequently. For example, in accordance with an example acquire condition, whenever a user holds the camera steady for at least a second, the camera may begin to acquire auto-bracketed images. For instance, the camera may automatically acquire a set of twelve auto-bracketed images while a user is composing a shot for one manually-captured image.</p>
    <p num="p-0270">In another example, whenever a user is looking through the camera's viewfinder (an acquire condition), the camera may capture images semi-continuously (e.g., like a video camera). For instance, the camera may acquire images at a rate of three images per second as long as a user is looking through the viewfinder of the video camera. Note that this means the camera could acquire thirty images automatically while a user is looking through the viewfinder for ten seconds.</p>
    <p num="p-0271">In another example, whenever a user presses a shutter button on the camera (a condition), the camera may capture an image of a scene (i.e., a manually-captured image). In addition, the camera may acquire one or more images automatically based on the image that was captured manually. For example, if the camera determines that the manually-captured image is under-exposed (a condition), then the camera may acquire an auto-bracketed set of images at various different exposure settings, thereby increasing the likelihood that the user captures at least one well-exposed image of the scene.</p>
    <p num="p-0272">In some embodiments of the present invention, a camera may not perform a step of determining whether to acquire an image. For example, the camera may acquire images continuously or semi-continuously (e.g., like a video camera) whenever the camera is on. The camera may then determine whether or not to store the images.</p>
    <p num="p-0273">As discussed above with respect to general steps <b>1310</b> and <b>1315</b>, a device consistent with the present invention may make various determinations relating to the storing of an image that may have been acquired automatically. A camera may determine whether to store an image (step <b>1310</b>). For example, the camera may determine whether an image should be stored in secondary memory or deleted/overwritten. A camera may determine how to store an image (step <b>1315</b>). For example, a camera may determine whether an image should be compressed, and if so, how much the image should be compressed. In some embodiments, a camera may determine where (e.g., which of various available storage devices) to store an image.</p>
    <p num="p-0274">A camera may determine whether to store and/or how to store an image based on one or more conditions. Such conditions may be based on one or more factors, such as those factors above with respect to acquire conditions. Some examples of determining whether and/or how to store an image that was acquired automatically include:</p>
    <p num="p-0275">If a user is holding the camera still and horizontal while the image is acquired (a condition), then the image may be stored.</p>
    <p num="p-0276">If the subject of the image is more than three feet from the camera and less than ten feet from the camera (a condition), then the image may be stored and compressed by using a JPEG compression setting of 75%.</p>
    <p num="p-0277">Alternatively, or in addition, a camera may determine whether to store and/or how to store an image based on the image itself. This may be done, for example, by evaluating the quality of the image or one or more characteristics of the image. For example, the camera may evaluate an image (e.g., using an image processing program) to determine the quality of the image. If the image is high quality (e.g., well-exposed, not blurred, well-framed subject), then the image may be stored by the camera in secondary memory. If the image is low quality (e.g., underexposed, blurred, or poorly composed), then the image may be compressed and stored or just deleted or overwritten.</p>
    <p num="p-0278">The term “quality” is used herein in a broad sense and may be used to refer to a variety of different factors that affect whether an image is (or is likely to be) desirable to a user. The “quality” of an image may be indicative of any of various factors, some of which include, without limitation: how visually appealing the image is (e.g., pleasing, engaging), how well the image was captured or acquired (e.g., exposure, camera movement, framing, noise), how desirable the image is to the user (e.g., based on user preferences), how memorable the image may be to a user or subject, how interesting or unique the image is (e.g., capturing the exact moment of the new year in Times Square).</p>
    <p num="p-0279">According to some embodiments, determining the quality of an image may include one or more of: determining one or more characteristics of the image, and determining a rating of the image.</p>
    <p num="p-0280">Some examples of characteristics of an image that may be indicative of the quality of an image include, without limitation:</p>
    <p num="p-0281">sharpness of the image—For example, a camera may determine if the subject of an image is in focus. In a second example, the camera may determine whether the background of the image is in focus. Images that are sharp and in focus may be determined to be of higher quality (e.g., worth storing), whereas images that are blurred, fuzzy, or out of focus may be determined to be of lower quality.</p>
    <p num="p-0282">exposure of the image—For example, the camera may determine if an image is exposed correctly. Images that are exposed correctly may be considered higher quality, whereas images that are over-exposed or under-exposed may be deemed to be of lower quality. In a second example, the camera may determine the exposure of specific portions of an image. For example, the quality of an image may depend on whether a person's face in an image is correctly exposed.</p>
    <p num="p-0283">colors of the image—For example, the camera may determine a color histogram for the image and determine whether to store the image based on this. Images that have more colors or brighter colors may be more appealing to people and therefore may be considered to be higher quality. Images what are monotone, have too much contrast, or are color-saturated may be considered to be lower quality.</p>
    <p num="p-0284">composition of the image—For example, the camera may determine the organization of subjects within an image and compare this to known templates of well-composed images, thereby determining if the image is well-composed. In a second example, an image of a person that does not include the person's feet may be considered to be lower quality than an image that does include the person's feet.</p>
    <p num="p-0285">movement in an image—For example, the camera may determine if the subject of an image is blurred by movement. Depending on the subject matter of an image (e.g., sports, running water) or a user's preferences, an image that is blurred by movement may be considered to be higher or lower quality.</p>
    <p num="p-0286">subject(s) of the image—For example, the camera may use object recognition software to determine what object or objects are the subject of an image. Certain subjects may be more interesting or appealing to a user than other subjects, so images of these subjects may be considered to be of high quality. For example, images of Alice may be considered to be more valuable/higher quality than images of buildings or traffic lights. In a second example, images of the birthday girl at a birthday party may be considered to be higher quality (i.e., more important) than images of other children at the birthday party. Note that an image that is blurred or poorly exposed may be considered to be a good quality image if it captures an important subject (e.g., Barry Bonds hitting his 600 th home run).</p>
    <p num="p-0287">background of an image. For example, the camera may determine what landscape, scenery, building, or other objects are in the background of an image. Images in which the background of an image is visually appealing may be considered to be of higher quality.</p>
    <p num="p-0288">face recognition—For example, the camera may use face recognition software to identify a person in an image (e.g., “Alice”). The camera may then save or discard an image based on the subject of the image (e.g., saving all images of Alice and deleting all images of Bob). In a second example, the camera may determine whether anybody blinked in an image of a group of people. If somebody blinked (i.e., somebody's eyes are shut in the image) or looked away (i.e., somebody is not looking at the camera), then the camera may determine that the image is lower quality.</p>
    <p num="p-0289">correspondence to a user's preferences—For example, a user may indicate that he prefers images to be slightly blurred (e.g., for a softening effect in portraits). Based on this, the camera may determine images that are slightly blurred to be of higher quality than images that are very sharp. In a second example, a user may prefer that images of people have warmer colors while images of landscapes have cooler colors. Based on this preference, the camera may determine the quality of an image based on the subject matter of the image (i.e., people or landscape), the coloration of the image (i.e., warmer/redder or cooler/bluer), and the user's preferences.</p>
    <p num="p-0290">artificial intelligence—For example, the camera may use an artificial intelligence system (e.g., a neural net) to determine which images are most appealing to a user. In one example, the camera may determine a user's preferences based on images that the user captures using the camera. In a second example, the camera may ask a user one or more questions about his preferences (e.g., asking the user to indicate which image he prefers from a group of images), and then use the user's responses to train a neural net to determine which images are most appealing to the user.</p>
    <p num="p-0291">noise—For example, the camera may determine the amount of noise in an image based on image analysis or settings of the camera when the image was captured. Images that have a large amount of digitization or quantization noise may be considered to be lower quality than images than have less noise or better digitization or quantization.</p>
    <p num="p-0292">meta-data—As is known to those skilled in the art, various meta-data may be associated with an image, including information about the scene, location, time, exposure, lighting, or subject of the image. In one example, images with more meta-data or more useful meta-data may be considered by the camera to be of higher “quality” (e.g., because they are easier for a user to search and sort). For example, an image that is meta-tagged with information about the subject of the image (e.g., “Alice”) as well as the location of the image (e.g., “Yosemite National Park”) may be considered to be higher quality (more valuable to a user) than a similar image that has no meta-tags.</p>
    <p num="p-0293">similarity to other images—For example, the camera may compare an image that has been acquired to one or more images that have already been stored in the camera's secondary memory. If the acquired image is nearly identical to a plurality of images already stored in the camera's memory, then the camera may consider the acquired image to be lower quality than an image that is unique and different, since a user would likely be uninterested in capturing multiple images that are nearly identical to each other.</p>
    <p num="p-0294">In some embodiments, determining the quality of an image may include determining one or more ratings for the image. Ratings may be determined based on a variety of different factors, including characteristics of an image that relate to the quality of an image (see above). For example, images captured by the camera may be rated on a scale of 0 to 10, with 0 corresponding to an image that should definitely be deleted and 10 corresponding to an image that should definitely be stored. Images with other ratings may be compressed based on their ratings. For example, an image that is rated a 4 may be compressed more than an image that is rated a 6.</p>
    <p num="p-0295">In one embodiment, a camera may use a rating function to determine a rating for an image. A rating function may be a mathematical formula, equation, function, or process that may be used to determine a rating of an image. A rating function may reference one or more variables (i.e., factors) and may include mathematical operations (e.g. +, −, *, /, mean, standard deviation, logarithm, derivative, integral), functions (e.g., search_term_in_database( ), autocorrelation( ), dilate( ), fourier_transform( ), template_match( )), and/or constants (e.g., 10, 20 pixels, 300 milliseconds, 4 lumens, 0.02, 15%, pi, TRUE, yellow, “raining”, 5200 K). Some examples of rating functions include:</p>
    <p num="p-0296">
      <tables id="TABLE-US-00002" num="00002"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="203pt" align="left"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">sharpness_of (edge_detect (image_910284))</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">(number_of_colors_in_image / max_possible_colors) * 10</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">user_rating_of_person (subject_of_image (image_49325))</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">100/(noise_level (image_234859))</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">3 + sum_all (meta_data (image_172498),</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">values_of_each_type_of_meta_data)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0297">In some embodiments, an image may be assigned a plurality of ratings. For example, an image may be assigned a plurality of ratings corresponding to a plurality of different categories (e.g., categorical ratings). For instance, an image may be given an exposure rating that is indicative of how well exposed the image is, a sharpness rating indicative of how sharp the image is, and a composition rating indicative of how well composed the image is. The example image rating database shown in <figref idrefs="DRAWINGS">FIG. 9</figref> shows one example of categorical ratings that may be applied to images.</p>
    <p num="p-0298">In some embodiments, a camera may use a plurality of different rating functions to rate an image. For example, the camera may use a plurality of artificial intelligence programs or agents to rate images. Each agent may rate images differently, so an image that receives a rating of 6 out of 10 from one agent may receive a rating of 8.5 out of 10 from a second agent. In one example, each agent may select images based on different criteria. For example, a first agent may be configured to prefer (i.e., rate highly) images of groups of people, whereas a second agent may give higher ratings to images of beautiful landscapes. The ratings from the plurality of agents may approximate a user's own preferences for different types of images.</p>
    <p num="p-0299">In some embodiments, an image may receive an overall rating based on one or more of a plurality of ratings (e.g., a plurality of categorical ratings). For example, the overall rating may be a simple average of the categorical ratings, as depicted in <figref idrefs="DRAWINGS">FIG. 9</figref>. Of course, an overall rating for an image may be determined in a variety of other ways as well. For example, the overall rating of an image may be determined as the weighted average of the image's categorical ratings (e.g., exposure may be weighted more than subject).</p>
    <p num="p-0300">It will be readily understood that ratings of images may be expressed in a quantitative format. For example, a quantitative rating for an image may be expressed as: 76 out of the range [0, 100], 45.3 out of the range [0, 60], −0.4 out of the range [−1, 1] or 213 on a scale that starts at 0 and has no upper limit. Ratings may not be bounded, may include negative numbers, and may, of course, include numbers other than whole integers, as deemed appropriate for a particular application.</p>
    <p num="p-0301">Of course, ratings may be expressed qualitatively. Qualitative ratings, for example, may be especially useful because they may provide more descriptive information (e.g., about what is good or bad about an image). Some examples of qualitative ratings include:</p>
    <p num="p-0302">“excellent”, “good”, “fair”, “mediocre”, “horrible”</p>
    <p num="p-0303">“over-exposed”, “under-exposed”, “correctly exposed”</p>
    <p num="p-0304">“extra-sharp”, “sharp”, “slightly blurred”, “very blurred”</p>
    <p num="p-0305">“face(s) blocked”, “face(s) easy to see”, “face(s) difficult to see”</p>
    <p num="p-0306">“artistic”, “snapshot”</p>
    <p num="p-0307">“lots of useful meta-data”, “some useful meta-data”, “no meta-data/useless meta-data”</p>
    <p num="p-0308">“Subject: Alice”, “Subject: Bob”, “Subjects: Alice and Bob”</p>
    <p num="p-0309">In some embodiments, images may be rated relative to other images (e.g., graded on a curve). For example, an image of average quality may receive a rating of 0, an image of above average quality may receive a rating of +3.2, and an image of below average quality may receive a rating of −2.7. Images may be rated relative to any other group of images, including:</p>
    <p num="p-0310">other images of the same scene—For example, a camera may rate all pictures of Alice relative to each other to determine which is the best picture of Alice. In a second example, the camera may rate each of the images in an auto-bracketed set relative to each other.</p>
    <p num="p-0311">other images captured by the camera during a specified time period (e.g., during the last five minutes, since the camera was turned on).</p>
    <p num="p-0312">other images stored in a camera's secondary, removable or non-volatile memory—For example, an image may be rated relative to other images stored on the camera's flash memory card.</p>
    <p num="p-0313">other images in a certain category—For example, an image of Alice may be rated relative to other images of Alice. In a second example, an image of a sunset over a beach may be rated relative to other images of sunrises and sunsets, or alternatively relative to other images of beaches.</p>
    <p num="p-0314">similar images—For example, the camera may compare an image that has been acquired to one or more images that have already been stored in the camera's secondary memory. If the acquired image is nearly identical to a plurality of images already stored in the camera's memory, then the camera may give the image a low rating, since a user would likely be uninterested in capturing multiple images that are nearly identical to each other.</p>
    <p num="p-0315">One or more images may be rated as a group and receive a group rating. For example, the camera may acquire a set of auto-bracketed images and determine a rating for this entire set of images. The camera may then store the images, for example, based on the group rating.</p>
    <p num="p-0316">As discussed above, an imaging device in accordance with some embodiments of the present invention may determine whether to store an image based on the quality of the image. In some embodiments, an imaging device may determine whether and/or how to compress (or delete) an image based on a quality of the image. For example, images that receive ratings of higher than a threshold value may be stored in the camera's secondary memory. In another example, an image that receives a rating of 8/10 may be compressed using a JPEG compression setting of 60%. In another example, an image that receives a rating of less than a threshold value may be deleted from the camera's memory.</p>
    <p num="p-0317">As discussed herein, storing an image may include one or more of: storing the image in secondary memory, storing the image in non-volatile memory, storing the image in removable memory, transferring the image from primary memory to secondary memory, transferring the image from volatile memory to non-volatile memory, transferring the image from non-removable memory to removable memory, and compressing the image.</p>
    <p num="p-0318">It will be readily understood that images may be deleted in a variety of different ways. For example, deleting an image may include: deleting the image from memory, deleting the image from primary memory, deleting the image from secondary memory, overwriting the image in memory, marking the image as deleted and/or marking the image to be overwritten.</p>
    <p num="p-0319">In accordance with some embodiments of the present invention, storing an image based on the quality of the image may include one or more of: storing the image based on a rating of the image, automatically determining whether to store the image, determining whether to store the image based on the quality of the image, determining whether to store the image based on a rating of the image, automatically determining how to store the image, determining how to store the image based on the quality of the image, and determining how to store the image based on a rating of the image.</p>
    <p num="p-0320">In accordance with some embodiments of the present invention, deleting an image based on the quality of the image may include one or more of: deleting the image based on a rating of the image, determining whether to delete the image based on the quality of the image, and determining whether to delete the image based on a rating of the image.</p>
    <p num="p-0321">Some embodiments of the present invention provide for compressing an image based on the quality of the image. Compressing an image based on the quality of the image may include one or more of: compressing the image based on a rating of the image, determining how much to compress the image, determining how much to compress a file that stores the image, determining whether to compress the image, determining whether to compress a file that stores the image, determining a compression setting for compressing the image, and automatically adjusting a compression setting for compressing the image.</p>
    <p num="p-0322">In one example of processing an image based on a rating of the image, a camera may compare a rating of an image to a threshold value (e.g., to determine if the rating is better or worse than the threshold value). This threshold value may be predetermined or may be determined based on one or more other factors. Such threshold values may be expressed as conditions (e.g., as a compression condition in compression condition database <b>440</b> or <b>640</b>).</p>
    <p num="p-0323">For example, a camera may store any image that receives a rating of 5.0 or higher. Thus, an image that receives an overall rating of 6.8 may be saved, whereas an image that receives an overall rating of 4.2 may be deleted. In another example, a camera may determine a threshold value based on one or more stored images. For example, the camera may determine the average rating of one or more stored images. A new image acquired by the camera may only be saved if the rating of the new image is greater than the average rating of the stored images.</p>
    <p num="p-0324">In some embodiments, a camera may determine how much to compress an image based on a rating of the image (e.g., an image's overall rating, an exposure rating of an image). For clarity, the following examples describe affecting the compression of an image by adjusting a compression setting for an image compression program (e.g., a JPEG image compression program). It should be understood by those skilled in the art that the camera may affect how much an image is compressed in a variety of other ways as well.</p>
    <p num="p-0325">In one example, an image may be compressed based on a mathematical function of its rating. For example, the camera may adjust the compression setting for a JPEG compression program to be: compression_setting=10+(9*image_rating). Thus, an image with a rating of 6.3 might be compressed with a compression setting of 67%. Note that a wide variety of mathematical functions are know to those skilled in the art and need not be described in detail herein.</p>
    <p num="p-0326">In another example, a rating of an image may be compared to a threshold value (e.g., a predetermined threshold value, a rating of another image). For example, the camera may compress any image that receives a rating of 7.0 or lower. Thus, an image that receives a rating of 6.3 may be compressed, whereas an image that receives a rating of 7.5 may not be compressed or may be compressed by a lesser amount.</p>
    <p num="p-0327">In another example, an image may be compressed based on a condition relating to a rating of the image. For example, the camera may store a database that includes the following exemplary rules:</p>
    <p num="p-0328">
      <tables id="TABLE-US-00003" num="00003"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="203pt" align="left"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">if (image_rating &lt; 2) then (compression_setting = 30%)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">if (2 &lt;= image_rating &lt; 5) then (compression_setting = 50%)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">if (5 &lt;= image_rating &lt; 8) then (compession_setting = 80%)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">if (8 &lt; image_rating) then (compression_setting = 100%)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0329">In some embodiments, an image may be stored, deleted, or compressed based on a categorical rating of the image. For example, an image may be compressed with a compression setting equal to: compression_setting=30+70*(image_sharpness_rating). In another example, a categorical rating of an image may be compared to a threshold value. For example, an image may be deleted if its sharpness rating is less than 3 out of 10.</p>
    <p num="p-0330">In some embodiments, an image may be stored, deleted, or compressed based on a plurality of ratings of the image. For example, an image may be compressed based on a plurality of ratings of the image. For example, an image may be compressed with a compression setting of 80% if the image received an exposure rating of better than 7 and a sharpness rating of better than 8. If the image's exposure rating is better than 7 but the image's sharpness rating is worse than 8, then the image may be compressed with a compression setting of 60%. In another example, a plurality of ratings of an image may be compared to one or more threshold values. For example, an image may be stored if its sharpness rating is greater than 3 out of 10, its exposure rating is greater than 2 out of 10, and its subject relevancy rating is greater than 4 out of 10.</p>
    <p num="p-0331">In some embodiments, an image may be stored, deleted, or compressed based on a categorization of the image. For example, different types of images may be compressed based on different compression settings. For example, an image of a landscape that receives an 8 rating may be compressed with a compression setting of 80%, whereas a portrait that receives an 8 rating may be compressed with a compression setting of 90%. Varying the amount of compression for different types of images may be particularly appropriate if a user is interested in storing certain images at higher quality than other images. In another example, different types of images may be compared to different threshold values. For example, images that belong in a first category (e.g., pictures of Alice) may be compared to a first threshold value (e.g., 4.5), whereas images that belong in a second category (e.g., pictures of Bob) may be compared to a second threshold value (e.g., 5.3). Therefore, an image of Alice that receives an overall rating of 5.0 may be saved, whereas an image of Bob that receives the same rating may be discarded. Comparing different types of images to different threshold values may be particularly appropriate if a user would prefer to capture images of a certain type.</p>
    <p num="p-0332">In some embodiments, an image may be stored, deleted, or compressed based on one or more other images. For example, a camera may compare the ratings of two or more images. For example, two images of a waterfall may be acquired by the camera (e.g., as part of an auto-bracketed set). The camera may rate the two images and then compare the ratings of the two images. Based on this comparison, the camera may save the better image of the two and delete the worse image of the two. In another example, a camera may determine how much to compress an image based on one or more stored images. For example, the camera may determine the average rating of one or more stored images and the amount of memory. A new image acquired by the camera may be compressed according to the formula: compression_setting=70+3* (new_image_rating−average_image_rating). In another example, a camera may compare the ratings of four images and sort the images based on their ratings. The best image may be not be compressed at all, the second best image may be compressed with a compression setting of 80%, and the remaining two images may be compressed with a compression setting of 50%. In another example, the camera may acquire an image of Alice and rate this image as 6 out of 10. However, since the camera already has twelve images of Alice that have ratings of 8 out of 10 or higher, the new image of Alice (the one rated 6 out of 10) may be deleted.</p>
    <p num="p-0333">Storing, compressing, and/or deleting an image may also be performed based on a variety of other factors, including one or more of:</p>
    <p num="p-0334">indications from a user—For example, a user may indicate that all images of Alice should be compressed with a compression setting of 85%. In a second example, a user may indicate the camera should only store the best image from any auto-bracketed set. In a third example, images that are captured automatically within 10 seconds of a user pressing the shutter button on the camera may automatically be stored.</p>
    <p num="p-0335">habits or preferences of a user—For example, a user may indicate that he prefers images of people to images of landscapes. Based on this, the camera may set a higher threshold rating for storing images of landscapes and a lower threshold rating for storing images of people.</p>
    <p num="p-0336">state of the camera—For example, the camera may compress acquired images by a greater amount if it is running out of space in memory. In a second example, the camera may not bother compressing images if it is about to run out of batteries and it has a large amount of unused secondary memory. See below for further examples of storing, deleting, or compressing an image based on an amount of space that the camera has available in memory.</p>
    <p num="p-0337">capture conditions—For example, images that are captured based on the user holding the camera steady may be compressed with a compression setting of 80%, while images that are captured based on sounds recorded by a microphone may be compressed with a compression setting of 60%.</p>
    <p num="p-0338">In some embodiments, an image may be stored, deleted, or compressed based on an amount of memory that is available to the camera. For example, the camera may determine whether to store or delete an image based on the quality of the image and the amount of memory space available. For example, an automatically-captured image may be stored by the camera if the image receives a rating of greater than 6 out of 10 and the camera has at least 16 Mb of secondary memory free. If the camera has only 10 Mb of memory free, then an image may need to have a rating of better than 8 out of 10 in order to be stored and not deleted.</p>
    <p num="p-0339">In another example, a camera may determine how much to compress an image based on how much memory the camera has free and the quality of the image. For example, the camera may compress images according to the formula: compression_setting=50*(free_memory/total_memory)+5*image_rating. Images may be compressed by a greater amount if the camera is running low on memory.</p>
    <p num="p-0340">Optionally, an image (including images captured automatically) may be meta-tagged. Meta-tagging is used to refer to the general process of associating supplementary information with an image that is captured by an imaging device. The supplementary information associated with an image may be referred to as meta-data (or a “meta-tag”). Meta-data associated with an image may be stored in the same file as an image (e.g., a TIFF image file), or in an associated file (e.g., an image rating database). Examples of meta-data that may be stored with an automatically-captured image may include, without limitation:</p>
    <p num="p-0341">at least one rating of the image—For example, the camera may rate an image as 7.8 out of 10. This rating may be stored as meta-data in a file along with the image. In a second example, the camera may determine a plurality of ratings of the image (e.g., in different categories, or by different agents) and store one or more of this plurality of ratings as meta-data associated with the image.</p>
    <p num="p-0342">an indication of why the image was captured—For example, the camera may store an indication of a capture condition that caused an image to be captured. Examples of reasons that the camera may capture an image include capture conditions, and indications by a user (e.g., a user pressing the shutter button on the camera).</p>
    <p num="p-0343">other meta-data—A variety of other types of meta-data are known to those skilled in the art, including: time and date (when an image was captured), camera settings (e.g., what aperture, shutter speed were used to capture the image, auto-bracketing settings), position (e.g., GPS coordinates where the image was captured), orientation (e.g., of the camera), image content (e.g., subjects), categorization, scene data (blue sky/water/grassifaces, illumination), subject motion, sound annotations, preferred cropping, and scale.</p>
    <p num="p-0344">Associating meta-data with an image may be helpful for a variety of different processes and applications, including sorting of images, display of images, and compression/deletion of images. For example, images may be ordered according to their ratings (e.g., highest quality images first), or stored in folders based on content or quality (e.g., a first folder for high quality image of Alice, a second folder for medium-quality images of Alice, and a third folder for high quality images of Bob). In another example, it may be helpful to display meta-data to a user when displaying a stored image to a user. For instance, information about when, how, and why an image was captured may be displayed as text in a sidebar next to a displayed image. Note that images may be displayed using a variety of different devices, including the camera, a personal computer, or a digital picture frame. In another example, a camera may compress or delete one or more images if it is running low on memory space. For example, the camera may compress all images that have ratings worse than 5 out of 10, while leaving all images with higher ratings uncompressed.</p>
    <p num="p-0345">Referring now to <figref idrefs="DRAWINGS">FIG. 14</figref>, a flowchart illustrates a process <b>1400</b> that is consistent with one or more embodiments of the present invention. The process <b>1400</b> is a method for acquiring one or more images. For illustrative purposes only, the process <b>1400</b> is described as being performed by a camera (e.g., camera <b>210</b>). Of course, the process <b>1400</b> may be performed by any type of imaging device <b>110</b>, or an imaging device <b>110</b> in conjunction with a computing device <b>120</b>, for example.</p>
    <p num="p-0346">In step <b>1405</b>, a camera acquires an image independent of (or absent) a user's operation of a shutter control (e.g., a shutter button). In one example, the camera acquires an image of a scene automatically, but not in response (either directly or indirectly) to a user pressing a shutter button of the camera.</p>
    <p num="p-0347">It will be understood that many types of cameras require a user to use a shutter control to initiate the taking of pictures in an auto-bracketed mode, a burst mode, or a self-timer mode. For example, a self-timer mode of a typical camera requires a user to press a shutter button. The pressing of the shutter button initiates a countdown of a predetermined time period, and the camera takes a picture at the end of the predetermined period of time. In contrast, in step <b>1405</b> the acquiring of an image by the camera is absent such use of a shutter control by a user. For example, the camera may acquire an image based on one or more acquire conditions, as discussed further herein. In some embodiments, a plurality of images may be acquired independent of (or absent) a user's use of a shutter control.</p>
    <p num="p-0348">In step <b>1410</b>, the camera determines whether to store the acquired image. Various ways of determining whether to store an acquired image are discussed herein.</p>
    <p num="p-0349">Referring now to <figref idrefs="DRAWINGS">FIG. 15</figref>, a flowchart illustrates a process <b>1500</b> that is consistent with one or more embodiments of the present invention. The process <b>1500</b> is a method for acquiring an image automatically. For illustrative purposes only, the process <b>1500</b> is described as being performed by a camera (e.g., camera <b>210</b>).</p>
    <p num="p-0350">In step <b>1505</b>, a camera determines the occurrence of a condition. For example, the camera determines that the acquire condition <b>705</b> “AC-47532524-01” in the acquire condition database <b>620</b> has occurred (e.g., information from a proximity sensor indicates that the camera viewfinder is in use). In step <b>1510</b>, the camera acquires an image automatically based on the occurrence of the condition. For example, the camera may hold an image in an image buffer for additional processing. In step <b>1515</b>, the camera determines whether to store the image. Various ways of determine whether to store an image are described herein. For example, the camera may rate the image based on one or more characteristics and/or an amount of available memory. If it is determined not to store the image, the process <b>1500</b> ends. Otherwise, in step <b>1520</b>, the camera determines how much to compress the acquired image, as discussed herein. In step <b>1525</b>, the camera stores the image (compressed or uncompressed) in a secondary memory, such as an external hard drive, Web server, or flash memory card, and the process <b>1500</b> ends. Preferably, the secondary memory is non-volatile.</p>
    <p num="p-0351">In accordance with some embodiments, a camera may perform a process of managing one or more automatically-captured images. For example, a camera may automatically compress or delete one or more images in order to free up memory on the camera.</p>
    <p num="p-0352">A general process in accordance with one or more embodiments of the present invention may include one or more of the following steps: determining whether to compress or delete at least one image stored in memory, determining which image(s) to compress or delete, determining how much to compress an image, and compressing or deleting at least one image stored in memory.</p>
    <p num="p-0353">As noted above, in one embodiment compressing or deleting an image may be performed automatically (e.g., by a camera processor). Automatically compressing or deleting an image may include one or more of the situations: a user may not provide an indication that an image should be deleted or compressed, a user may not be aware that the camera has deleted or compressed at least one image, a user may not request that the camera delete or compress at least one image, one or more images may be deleted or compressed without interaction by a user, the camera may determine whether to compress or delete at least one image without assistance from a user, the camera may determine which image(s) to compress or delete without assistance from a user, the camera may determine how much to compress at least one image without assistance from a user, and the camera may compress or delete at least one image without assistance from a user.</p>
    <p num="p-0354">In some embodiments, a camera may automatically compress or delete manually-captured images (e.g., images captured in direct response to a user pressing the shutter button). For example, a camera may determine that an image a user captured is of poor quality and then automatically delete or compress the image (e.g., without the user's express permission). Some types of users (e.g., photographers who typically capture large numbers of images) may find it helpful to have the camera automatically manage a set of manually-captured images.</p>
    <p num="p-0355">In accordance with one or more embodiments, a camera may determine to compress or delete at least one image stored in memory based on a condition (e.g., a compression condition). For example, if a camera is running out of secondary memory (e.g., a Compact Flash card), the camera may determine that one or more images stored in secondary memory should be compressed or deleted to free up memory space and make room for additional images.</p>
    <p num="p-0356">In addition to other factors discussed herein, some examples of factors that may be used by a camera to determine whether to compress or delete an image include, without limitation: factors relating to the camera's memory usage, factors relating to capturing images, indications by a user, and factors relating to images stored in memory.</p>
    <p num="p-0357">Some examples of factors relating to the camera's memory usage include:</p>
    <p num="p-0358">an amount of memory that is free—For example, the camera may determine that it needs to free up some memory (e.g., by compressing or deleting images) if it has less than 5 Mb of secondary memory available.</p>
    <p num="p-0359">an amount of memory that is used—For example, the camera may determine that one or more images should be compressed because more than 200 Mb of the camera's 256 Mb Flash memory card has been used.</p>
    <p num="p-0360">a ratio or percentage of memory that is used—For example, the camera may decide to compress one or more images if more than 75% of its total memory is used.</p>
    <p num="p-0361">an amount of memory occupied by an image—For example, the camera may automatically delete or compress an image if the image occupies more than 1 Mb of memory.</p>
    <p num="p-0362">an amount of memory occupied by a group of images—For example, the camera may allocate 50 Mb of memory for automatically-captured images of Alice. Some images of Alice may be compressed or deleted if the total amount of memory used for images of Alice is greater than 50 Mb.</p>
    <p num="p-0363">an amount of memory occupied by automatically-captured images—For example, the camera may determine to compress or delete one or more automatically-captured images if automatically-captured images take up more than 20% of the camera's memory and the camera has less than 5 Mb of memory remaining.</p>
    <p num="p-0364">an amount of space that an image occupies in primary memory—For example, the camera may acquire one or more images and store these images in an image buffer. However, the camera's secondary memory (e.g., a flash memory card) may be mostly or completely full, meaning that there is no space in secondary memory for the newly acquired images to be stored. The camera may then compress or delete one or more images from secondary memory in order to make space for the newly acquired images. That is, the camera may automatically compress or delete one or more images if the amount of space taken up by images in primary memory is greater than the amount of space available in secondary memory. This in turn may enable the camera to transfer one or more images from primary memory (e.g., an image buffer) to secondary memory (e.g., a flash memory card).</p>
    <p num="p-0365">a number of images stored in memory—For example, the camera may limit the total number of automatically-captured images that may be stored in memory. For example, if the camera limits the number of automatically-captured images to 100 and the camera has already stored 100 images, then it may determine that it should delete one or more images to make room for future automatically-captured images.</p>
    <p num="p-0366">It will be understood that an amount of memory may be measured in a variety of different ways, including bits, bytes, blocks, disk area, a number of images, a number of files, a percentage of memory, or a ratio of memory.</p>
    <p num="p-0367">Some examples of factors relating to capturing images include, without limitation:</p>
    <p num="p-0368">the camera captures an image manually—For example, the camera may determine to automatically compress or delete one or more images to make room for a manually-captured image.</p>
    <p num="p-0369">the camera captures an image automatically—For example, the camera acquires an image automatically and determines a rating for this image. The rating of this image may then be compared with the ratings of one or more automatically-captured images stored in memory (e.g., secondary memory). If the rating of the newly-acquired image is better than a rating of one of the automatically-captured images stored in memory, then the camera may delete or compress the automatically-captured image stored in memory.</p>
    <p num="p-0370">images stored in an image buffer after being acquired—For example, the camera may automatically compress or delete one or more automatically-captured images if the amount of memory required for images stored in the image buffer is greater than the amount of secondary memory that is unused.</p>
    <p num="p-0371">Some examples of indications by a user include, without limitation:</p>
    <p num="p-0372">manually capturing an image—For example, a user may press the shutter button on the camera to indicate that he would like to manually capture an image. In order to make space for the manually-captured image, the camera may compress or delete one or more automatically-captured images.</p>
    <p num="p-0373">operating controls on the camera—For example, a user may press a button on the camera to indicate that he would like the camera to automatically compress or delete one or more images. See Section 6.1 for details about controls on the camera.</p>
    <p num="p-0374">settings on the camera—For example, the camera may include a setting that allows a user to specify the maximum amount of memory on the camera that can be taken up by automatically-captured images.</p>
    <p num="p-0375">Some examples of factors relating to images stored in memory include:</p>
    <p num="p-0376">subjects of one or more images stored in memory—For example, the camera may group images together based on their subjects or categories (e.g., images of Alice, images of beaches). If the total amount of memory occupied by automatically-captured images of beaches is greater than 10% of secondary memory, then the camera may determine to compress or delete one or more images of beaches.</p>
    <p num="p-0377">the quality of one or more images stored in memory (e.g., ratings)—For example, the camera may determine that one or more automatically-captured images should be compressed if 95% of the camera's memory is full and the images have ratings of less than a threshold value.</p>
    <p num="p-0378">As discussed herein, one example of a condition is a comparison between an amount of memory and a threshold value. That is, the camera may determine to compress or delete at least one image based on how an amount of memory compares to a threshold value. For example, one or more images may be compressed if the total amount of free memory in a CompactFlash card is less than 10 Mb. Similarly, multiple amounts of memory may be compared to multiple threshold values as part of a condition. A threshold value may be predetermined or may be determined based on one or more other factors. Some examples of conditions of this type include:</p>
    <p num="p-0379">
      <tables id="TABLE-US-00004" num="00004"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="left"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">(percentage_of_memory_occupied &gt;= 75%)</td>
              </tr> <tr class="description-tr"> <td class="description-td">(free_memory &lt; 20 Mb)</td>
              </tr> <tr class="description-tr"> <td class="description-td">((total_memory_AC_images − memory_used_AC_images) &lt; 15 Mb)</td>
              </tr> <tr class="description-tr"> <td class="description-td">(free_memory &lt; 20 Mb) and</td>
              </tr> <tr class="description-tr"> <td class="description-td">(percentage_of_memory_AC_images &gt; 50%)</td>
              </tr> <tr class="description-tr"> <td class="description-td">(memory_used (image_buffer) &gt;= memory_available</td>
              </tr> <tr class="description-tr"> <td class="description-td">(secondary_memory))</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0380">The exemplary compression condition database depicted in <figref idrefs="DRAWINGS">FIG. 11</figref> gives one example of how the camera may determine whether to compress or delete one or more images based on a compression condition. For example, whenever any of the compression conditions <b>1105</b> are true, then the camera may determine that it should compress or delete at least one image.</p>
    <p num="p-0381">According to some embodiments, a camera may also determine which images to compress or delete. This process may include selecting one or more images from the images stored in the camera's memory. For example, after the camera determines that one or more images should be compressed or deleted, the camera may select which images should be compressed or deleted.</p>
    <p num="p-0382">For example, a camera may select a single image to compress or delete. For instance, the camera may determine to compress a poorly exposed image of Alice next to a campfire. In another example, a camera may select a plurality of images to compress. For instance, the camera may automatically compress all images that have been captured in the last 15 minutes. In another example, a camera may select a plurality of images to delete. For instance, the camera may automatically delete all images that have ratings of worse than 1.2. In another example, a camera may select at least one image to compress and at least one image to delete. For instance, the camera may automatically compress all images that have ratings of worse than 5.3 but better than 1.2 and delete all images that have ratings worse than 1.2.</p>
    <p num="p-0383">In some embodiments, an imaging device may determine one or more images to compress or delete based on a condition (e.g., selection condition <b>1110</b>). For example, the camera may determine to compress or delete images for which the following exemplary conditions are true:</p>
    <p num="p-0384">
      <tables id="TABLE-US-00005" num="00005"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="21pt" align="left"> </colspec> <colspec colname="1" colwidth="196pt" align="left"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">  (overall_rating_of_image &lt; 1.2)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">  (reason_for_capturing_image !=</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">  ‘MANUALLY_CAPTURED_IMAGE’)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">  (rating_of_image &lt; 4) AND</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">  (compressibility_of_image (0.1_setting) &gt; 20%)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">  (image_captured_automatically) AND (correlation</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">(image, any_manually_captured_image) &gt; 0.9)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0385">Some examples of factors that may be considered when determining which image(s) to compress or delete include, without limitation:</p>
    <p num="p-0386">the quality of at least one image</p>
    <p num="p-0387">the compressibility of at least one image</p>
    <p num="p-0388">meta-data associated with at least one image (e.g., time, location, subject, associated images)</p>
    <p num="p-0389">image content</p>
    <p num="p-0390">an amount of memory</p>
    <p num="p-0391">a user's preferences</p>
    <p num="p-0392">Some examples of selecting one or more images to compress or delete based on the quality of at least one image include, without limitation:</p>
    <p num="p-0393">The camera may compress one or more low quality images, but leave one or more higher quality images uncompressed. For example, the camera may compress images with ratings less than a threshold value. Note that a threshold value may be predetermined or may be determined based on one or more other factors.</p>
    <p num="p-0394">The camera may determine a rating for an image and determine whether the image should be compressed or deleted based on this rating. For example, after the camera determines that one or more images should be compressed or deleted, the camera may determine a rating for each image stored in memory. All images with ratings of less than 5 may then be compressed.</p>
    <p num="p-0395">The camera may determine ratings of a plurality of images. Based on the plurality of ratings, the camera may select one or more images to be compressed or deleted. For example, the camera may determine ratings for a plurality of images and then rank the images according to their ratings. The three images with the lowest ratings may then be deleted.</p>
    <p num="p-0396">The camera may store an indication of the quality of an image (e.g., a rating) as meta-data associated with the image. When it comes time to compress or delete one or more images (e.g., based on a compression condition <b>1105</b>), the camera may retrieve this stored indication of the quality of the image and use it to determine whether an image should be compressed or deleted.</p>
    <p num="p-0397">As mentioned above, a camera consistent with some embodiments may determine at least one image to compress or delete based on the compressibility of one or more images (i.e., how much one or more images may be compressed). Note that compressibility may be measured in a variety of different ways, including:</p>
    <p num="p-0398">an amount of memory that would be vacated by compressing an image—For example, compressing a first image may free up 100 kb of memory on the camera, whereas compressing a second image may free up 200 kb of memory. Based on this, the camera may determine to compress the second image rather than the first image, thereby freeing up more memory on the camera.</p>
    <p num="p-0399">an amount of memory that would be occupied by a compressed image—For example, compressing a first image with a JPEG compression setting of 80% may result in a file size of 892 kb, whereas compressing a second image with a JPEG compression setting of 80% may result in a file size of 763 kb. Based on this, the camera may determine to compress the second image and not the first image. Note that in some cases it may be necessary to create a compressed version of an image in order to determine the file size of the compressed image.</p>
    <p num="p-0400">a compression setting necessary to achieve a desired amount of compression—For example, 10% of the information in a first image may need to be discarded by a compression program in order to reduce the file size of the image by 200 kb. In contrast, only 5% of the information in a second image may need to be discarded by a compression program in order to reduce the second image by 200 kb. Based on this, the camera may compress the second image instead of the first image, thereby reducing the amount of information that needs to be discarded in order to free up a given amount of memory.</p>
    <p num="p-0401">an amount of compression achievable with a particular compression setting—For example, compressing a first image using a JPEG compression setting of 75% may result in a 30% reduction in the file size of the first image, whereas compression compressing a second image using a JPEG compression setting of 75% may result in a 30% reduction in the file size of the second image.</p>
    <p num="p-0402">an amount of compressibility of a plurality of images—For example, the camera may compress one or more images as a group (e.g., based on similarities between the images). For example, the camera may determine whether to compress a group of auto-bracketed images based on how much the entire group of images may be compressed.</p>
    <p num="p-0403">In one example, selecting one or more images to compress or delete based on meta-data associated with at least one image, each time a camera automatically captures an image, the camera may determine a rating for the image and store the rating of the image as meta-data associated with the image. If, at a later time, the camera determines that one or more images should be compressed or deleted, then the camera may retrieve the rating associated with the image and determine whether the image should be compressed or deleted based on this rating.</p>
    <p num="p-0404">In another example, a camera may store information about how or when an image is captured as meta-data associated with the image. In response to the determination that one or more images should be compressed, the camera may select images based on this meta-data (e.g., all images that were captured using a flash may be compressed).</p>
    <p num="p-0405">In another example, information about the subject of an image (e.g., determined by the camera, or supplied by a user) may be stored as meta-data associated with the image. A camera may compress or delete images based on their subjects. For example, the camera may automatically compress all images stored in memory except for those images that include Alice. In yet another example, meta-data associated with an image may indicate whether the image has been compressed before, and if so, how much the image was compressed. In one example, a camera may refrain from compressing images that have been compressed before.</p>
    <p num="p-0406">Some examples of selecting one or more images to compress or delete based on image content include:</p>
    <p num="p-0407">The camera may use an image analysis program to analyze one or more images stored in memory to determine which of these images should be compressed or deleted and which of these images should remain unaltered.</p>
    <p num="p-0408">The camera may analyze the images stored in memory to determine which images are overexposed, which are underexposed, and which are correctly exposed. Overexposed or underexposed images may be compressed or deleted.</p>
    <p num="p-0409">The camera may use image recognition software to determine the subjects of one or more images stored in memory and then compress or delete images based on the subjects of images. For example, the camera may analyze one or more image to determine which images are close-ups of people. The camera may then compress all images that are not close-ups of people.</p>
    <p num="p-0410">The camera may select images to compress or delete so that it maintains at least one high quality image of each subject. For example, before compressing any images, the camera may store three images of Alice, two images of Bob, and one image of Carly. Based on this, the camera may choose to compress two images of Alice and one image of Bob, leaving one image of Alice, one image of Bob, and one image of Carly unaltered.</p>
    <p num="p-0411">Images that were captured as a group may be compressed as a group. For example, the camera may automatically capture an auto-bracketed set of images (e.g., all images of the same scene). If the camera later determines that one or more automatically-captured images need to be compressed, then each image in the set of auto-bracketed images may be compressed.</p>
    <p num="p-0412">As mentioned earlier, a camera may select one or more images to be compressed or deleted based on an amount of memory. For example, a camera may determine that 25 Mb of memory should be vacated to make room for images that may be captured by the camera in the future (e.g., because the camera needs this space to store one or more manually-captured images). Based on this, the camera may select an appropriate combination of automatically-captured images that take up at least 25 Mb of memory and delete these images. Other examples of factors relating to an amount of memory include: an amount of memory that should be vacated, an amount of memory that is occupied by one or more images, an amount of memory needed to store one or more images, an amount of memory that is free, an amount of memory that would be occupied by a compressed image, and an amount of memory that would be vacated by compressing an image.</p>
    <p num="p-0413">As discussed herein, in some embodiments, a user's preferences or indications from a user may affect which images are compressed or deleted. For example, a user may indicate that he prefers images of a certain type. Based on this preference, the camera may determine to compress or delete certain images but leave other images unaltered. For example, a user may indicate that he is most interested in saving images of groups of people. Based on this, the camera may compress any automatically-captured images that do not include groups of people.</p>
    <p num="p-0414">In another example, a camera may use an artificial intelligence program to determine a user's preferences (e.g., by tracking which images a user captures manually and which images the user chooses to delete). For example, the camera may determine that a user dislikes images that have busy or complicated backgrounds. Based on this, the camera may compress or delete one or more images that have busy or complicated backgrounds.</p>
    <p num="p-0415">In another example, a user may indicate that he plans on capturing one or more images of a certain type. The camera may select one or more images to compress or delete based on this indication. For example a user may indicate that he plans on capturing a plurality of images of Alice. Based on this, the camera may reduce the number of images of Bob stored in memory to make room for the images of Alice that the user anticipates capturing.</p>
    <p num="p-0416">In another example, a camera may offer the user a choice of which images should be compressed or deleted. For example, the camera may prompt a user, “Do you want to compress the images of Alice, the images of Bob, or the images with the lowest ratings?” If the user responds that he would like to compress the images of Bob, then the camera may compress the images of Bob based on the user's response. In yet another example, a camera may display an image to a user and prompt the user to indicate whether the image should be compressed.</p>
    <p num="p-0417">The example compression condition database <b>440</b> depicted in <figref idrefs="DRAWINGS">FIG. 11</figref> shows one example of how the camera may determine one or more images to compress or delete. According to this example, the camera determines whether it should compress or delete images based on a compression condition <b>1105</b> and then determines which images to compress of delete based on a selection condition <b>1110</b>. For example, if the amount of free memory on the camera is less than 10 MB (a compression condition), then the camera may select all automatically-captured images with ratings of less than 7.0 to be compressed. In some embodiments, however, the camera may not determine which images to compress or delete. For example, the camera may automatically compress all images stored in memory or all automatically-captured images stored in the camera's secondary memory.</p>
    <p num="p-0418">In some embodiments, a camera may determine how much to compress one or more images. This may include determining an amount of compression. For example, the camera may determine whether an image should be compressed to 75% of its original size or 80% of its original size. Note that an amount of compression may be measured in a variety of different ways, including: a compression setting to use when compressing one or more images, an amount of memory to free, and an amount of memory to be occupied by one or more images.</p>
    <p num="p-0419">As mentioned above, the camera may determine a compression setting (e.g., compression setting <b>1115</b>) that controls how much one or more images are compressed. For example, the camera may determine whether an image should be compressed with a JPEG compression setting of 60% or a JPEG compression setting of 80%. Note that a compression setting may affect how much an image is compressed by an image compression program.</p>
    <p num="p-0420">As mentioned above, a camera may determine an amount of memory to free. Note that “freeing” memory may include removing data from the memory (e.g., at least a portion of an image file), marking the memory as vacant, reformatting the memory, or otherwise making the memory available to store other data. Examples of the camera determining an amount of memory to free include:</p>
    <p num="p-0421">The camera may determine that 25 Mb of memory should be freed to make room for images that may be captured by the camera in the future.</p>
    <p num="p-0422">The camera may determine that the file size of an image should be reduced by 300 kb.</p>
    <p num="p-0423">The camera may determine to delete 4 images, each of which occupies 900 kb.</p>
    <p num="p-0424">The camera may determine that a group of images (e.g., an auto-bracketed set of images of Bob with his car) should be compressed enough to free up 1200 kb of memory.</p>
    <p num="p-0425">As mentioned above, a camera may determine an amount of memory to be occupied by one or more images. For example, the camera may determine that an image should be compressed so that its file size is approximately 500 kb. In another example, the camera may determine that a group of images (e.g., an auto-bracketed set of images of the Statue of Liberty) should occupy no more than 10 Mb. In another example, the camera may determine that a group of images (e.g., images of Alice on the beach) should occupy 10% of the camera's total memory. In another example, the camera may determine that a first image should be compressed so that it takes up ½ of the amount of memory that is occupied by a second image.</p>
    <p num="p-0426">In some embodiments, a camera may determine a desired amount of compression, and determine how much to compress a plurality of images based on this desired amount of compression. A desired amount of compression may be a total amount of compression for a plurality of images. For example, the camera may determine that 40 Mb of memory should be freed by compressing a plurality of images. Based on this desired amount of compression, the camera may determine how much to compress a plurality of images. Some examples include:</p>
    <p num="p-0427">The camera may compress a plurality of images so that the total amount of memory freed by compressing the images is approximately equal to the desired amount of memory to be freed. Note that the total amount of memory freed by compressing the images may be determined by summing the amount of memory vacated by compressing the first image plus the amount of memory vacated by compressing the second image, etc.</p>
    <p num="p-0428">The camera may compress a plurality of images so that the total amount of memory freed by compressing the images is greater than or equal to the desired amount of memory to be freed.</p>
    <p num="p-0429">In one example, the compression tracking database <b>645</b> depicted in <figref idrefs="DRAWINGS">FIG. 12</figref> shows how a camera may compress a plurality of images stored in the camera's memory, thereby freeing up a desired amount of memory.</p>
    <p num="p-0430">In some embodiments, a camera may determine how much to compress at least one image based on a variety of different factors described herein, including: an amount of memory, the quality of the at least one image, the compressibility of the at least one image, meta-data associated with the at least one image (e.g., time, location, subject, associated images), image content, a user's preferences, and other images.</p>
    <p num="p-0431">In one embodiment, a camera may determine an amount of memory that should be vacated. For example, the camera may determine a total amount of memory to be vacated (e.g., 20 Mb). The camera may then determine how much to compress one or more images based on this total amount of memory. For example, the camera may determine how much each image should be compressed so that the total amount of memory vacated is 20 Mb. For example, image #8423 may be compressed by 100 kb, image #5892 may be compressed by 250 kb, etc.</p>
    <p num="p-0432">In another embodiment, a camera may determine an amount of memory needed to store one or more images. For example, one or more manually-captured images stored in camera's image buffer may need to be transferred to the camera's secondary memory. The total amount of secondary memory needed to store these images may be 15 Mb. Based on this amount of memory (i.e., 15 Mb), the camera may then determine how much to compress each image stored in secondary memory. For example, image #4894 may be compressed by 15%, image #3187 may be compressed by 0%, etc.</p>
    <p num="p-0433">In some embodiments, a camera may determine an anticipated amount of memory that may be needed. For example, the camera may anticipate (e.g., based on a user's image capturing habits, or an indication by a user) that the camera may need an additional 20 Mb of memory to capture more images. Based on this, the camera may determine how much to compress one or more images.</p>
    <p num="p-0434">A camera may determine how much to compress one or more images based on the quality of the one or more images. For example, low quality images may be compressed more than high quality images. In one example, a rating of an image may be compared to a threshold value (e.g., a predetermined threshold value, a rating of another image). If the rating is greater than the threshold value, then the image may be compressed by a first amount (e.g., with a compression setting of 80%). If the rating is less than the threshold value, then the image may be compressed by a second amount (e.g., with a compression setting of 60%).</p>
    <p num="p-0435">In another example, a camera may determine that a plurality of images should be compressed. Of this plurality of images, all images with ratings greater than a 5 may be compressed by a first amount (e.g., at least 100 kb) and all image with ratings less than 5 may be compressed by a second amount (e.g., at least 200 kb). In another example, an image may be compressed based on a mathematical function of its rating. For example, the camera may adjust the compression setting for a JPEG compression program to be: compression_setting=10+(9*image_rating). Thus, an image with a rating of 6.3 might be compressed with a compression setting of 67%.</p>
    <p num="p-0436">In another example, an image may be compressed based on a categorical rating of the image. For instance, an image may be compressed with a compression setting equal to: compression_setting=30+70*(image_sharpness_rating). In another example, an image may be compressed based on a plurality of ratings of the image. For instance, an image may be compressed with a compression setting of 80% if the image received an exposure rating of better than 7 and a sharpness rating of better than 8. If the image's exposure rating is better than 7 but the image's sharpness rating is worse than 8, then the image may be compressed with a compression setting of 60%.</p>
    <p num="p-0437">As mentioned above, a camera may determine how much to compress an image based on the compressibility of the at least one image. For example, images that are more compressible (i.e., images that can be compressed more with less loss of quality) may be compressed more than images that are less compressible (i.e., images that lose more quality when compressed). For example, the camera may compress a highly compressible image by 30%, where as a less compressible images may only be compressed by 15%.</p>
    <p num="p-0438">In some embodiments, a camera may determine how much to compress an image based on meta-data associated with the image. Examples include:</p>
    <p num="p-0439">The camera may determine how much to compress an image based on a rating of the image that is stored as meta-data associated with the image. For example, a rating of an automatically-captured image may be determined and stored with the image when the image is captured. See above for details about determining how much to compress an image based on a rating of the image.</p>
    <p num="p-0440">Meta-data associated with an image may indicate whether the image has been compressed before, and if so, how much the image was compressed. In one example, the camera may compress images based on how much they were previous compressed. For example, the camera may determine to never compress an image by more than 50%. If an image has already been compressed by 40%, then the camera may only compress this image by an additional 10% relative to the original size of the image.</p>
    <p num="p-0441">Information about the subject of an image (e.g., determined by the camera, or supplied by a user) may be stored as meta-data associated with the image. The camera may user this information to determine how much to compress an image. For example, images of Alice may be compressed 10% more than images of Bob.</p>
    <p num="p-0442">The camera may store information about how or when an image is captured as meta-data associated with the image. The camera may compress an images based on this information. For example, images that were automatically captured at approximately the same time that a user manually captured one or more images may be compressed less than images that were automatically captured at other times.</p>
    <p num="p-0443">In some embodiments, a camera may determine how much to compress an image based on image content of the at least one image. Examples include:</p>
    <p num="p-0444">The camera may use an image analysis program to analyze one or more images stored in memory to determine how much each of these images should be compressed.</p>
    <p num="p-0445">The camera may analyze the images stored in memory to determine which images are overexposed, which are underexposed, and which are correctly exposed. Overexposed or underexposed images may be compressed more than correctly exposed images.</p>
    <p num="p-0446">The camera may use image recognition software to determine the subjects of one or more images stored in memory and then determine how much to compress the images based on the subjects of images. For example, the camera may compress images of landscapes by 40% and close-up images of people by 5%.</p>
    <p num="p-0447">The camera may compress images so that it maintains at least one high quality image of each subject. For example, all of the images of Alice except for one may be compressed by 50%, and the other images Alice may be compressed by 0%.</p>
    <p num="p-0448">Images that were captured as a group may be compressed as a group. For example, the camera may automatically capture a 5-image burst set of images (e.g., images of a sporting event). In order to maintain consistency in the 5-image group, all of the images may be compressed by the same amount, even if one of the images is significantly higher or lower quality than the rest of the group.</p>
    <p num="p-0449">In some embodiments, the camera may determine how much to compress an image based on user preferences. Examples include:</p>
    <p num="p-0450">A user may indicate that he prefers images of a certain type. Based on this preference, the camera may determine to compress certain images more than others. For example, a user may indicate that he is most interested in printing images of groups of people, but will mostly likely not print images of landscapes. Based on this, the camera may compress automatically-captured images of landscapes 30% more than automatically-captured images of people.</p>
    <p num="p-0451">The camera may use an artificial intelligence program to determine a user's preferences (e.g., by tracking which images a user captures manually, which images the user chooses to delete, and which images the user sends directly to a printer). For example, the camera may determine that a user dislikes images that have busy or complicated backgrounds. Based on this, the camera may determine that images that have busy or complicated backgrounds should be compressed more than images with simple backgrounds.</p>
    <p num="p-0452">A user may indicate that he plans on capturing 15 more images in addition to those that are already stored by the camera. In response to this indication, the camera may compress images stored in the camera's memory enough to make room for the 15 additional images that the user wants to capture.</p>
    <p num="p-0453">The camera may prompt a user to indicate how much he would like to compress one or more images. For example, the camera may output a prompt to user “How much would you like to compress the automatically-captured images of Alice at the beach?” The user may then respond to this prompt (e.g., by using a dial on the camera to select the “high quality” compression setting. Based on this response, the camera may compress the images of Alice at the beach using a JPEG compression setting of 90%.</p>
    <p num="p-0454">In some embodiments, the camera may determine how much to compress an image based on factors relating to one or more other images. Examples include:</p>
    <p num="p-0455">The camera may compare the ratings of four images and sort the images based on their ratings. The best image may be not be compressed at all, the second best image may be compressed with a compression setting of 80%, and the remaining two images may be compressed with a compression setting of 50%.</p>
    <p num="p-0456">A group of images may be compressed based on the average quality of the images in the group. For example, a group of 5 images may have ratings of 9, 6, 5, 5, and 4. The camera may determine that the average rating of this group of images is 5.8 and then compress all of these images based on this 5.8 rating (i.e., the image that rated a 9 would be compressed using the same compression setting as the image that was rated a 4).</p>
    <p num="p-0457">One way for the camera to determine an amount of compression is to use a mathematical formula or function. This mathematical formula may reference one or more variables (i.e., factors) and may include various mathematical operations (e.g. +, −, *, /, mean, standard deviation, logarithm, derivative, integral), functions (e.g., search_term_in_database( ), autocorrelation( ), dilate( ), fourier_transform( ), template_match( )), and constants (e.g., 10, 20 pixels, 300 milliseconds, 4 lumens, 0.02, 15%, pi, TRUE, yellow, “raining”, 5200 K). Note that a wide variety of mathematical functions are know to those skilled in the art and need not be described in detail herein.</p>
    <p num="p-0458">For example, images may be compressed according to the following formula: percentage_of_compression=(total_memory_to_free/total_original_size_of_images)*(1+(rating_of_image/10)−(avg_image_rating/10)). Note that according to the above formula, the camera may compress a plurality of images based on an amount of memory that should be freed and the quality of the images. Images with higher ratings will be compressed less than images with lower ratings, but all images will be compressed based on the amount of memory to be freed. Other formulas include
<br>compression_setting=70+3*(image_rating−average_image_rating)<br>compression_setting=50*(1−(memory_to_free/max_image_size))+5*image_rating</p>
    <p num="p-0459">In some embodiments, an image may be compressed based on a condition or stepwise function relating to a rating of the image. For example, the camera may compress an automatically-captured image stored in secondary memory according to the following rules:</p>
    <p num="p-0460">
      <tables id="TABLE-US-00006" num="00006"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="203pt" align="left"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">if (image_rating &lt; 2) then (compression_setting = 30%)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">if (2 &lt;= image_rating &lt; 5) then (compression_setting = 50%)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">if (5 &lt;= image_rating &lt; 8) then (compession_setting = 80%)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">if (8 &lt; image_rating) then (compression_setting = 100%)</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0461">It is worthwhile to note that deletion may be viewed as an extreme form of compression. For example, compressing an image by 100% (i.e., compressing an image so that is 100% smaller than its original size) is more or less equivalent to deleting the image. Similarly, the amount of memory taken up by an image that is compressed to 1% of its original size may be insignificant in many cases. While the layperson typically differentiates between compression and deletion, one who is skilled in the art will recognize that determining an amount to compress an image may include determining whether to compress or delete the image.</p>
    <p num="p-0462">Note that it is also possible that the camera may not determine how much to compress one or more images. For example, the camera may always compress images by the same amount. In a second example, the camera may not compress images at all, but rather may only delete images. Therefore, no step of determining how much to compress an image may be performed.</p>
    <p num="p-0463">According to some embodiments, managing one or more automatically-captured images may comprise compressing or deleting at least one image from a memory or storage device. Various methods of compressing and deleting images are known to those skilled in the art and need not be described in detail herein.</p>
    <p num="p-0464">In accordance with some embodiments, one or more images may be deleted or compressed automatically. For example, a user may not provide any indication that images should be compressed or deleted.</p>
    <p num="p-0465">In accordance with some embodiments, a camera may provide one or more indications to a user relating to compressing or deleting one or more images. This indication may be output to a user using an output device (e.g., an LCD screen, an audio speaker). Some examples include:</p>
    <p num="p-0466">The camera may indicate to a user that one or more images have been compressed or deleted. For example, the camera may use an LCD screen to display a message to a user, “Automatically-captured images #123, 124, and 125 have been deleted.”</p>
    <p num="p-0467">The camera may indicate to a user that one or more images may be compressed or deleted. For example, the camera may use an LCD screen to display a message to a user, “I'm going to delete 3 automatically-captured images of Alice.” In one embodiment, a user may confirm or otherwise respond to a prompt such as this one. See below for further details.</p>
    <p num="p-0468">The camera may indicate to a user that one or more images are currently being compressed or deleted. For example, the camera may output an audio message, “Deleting low-quality images that were captured automatically.” In a second example, the camera may beep each time it deletes an automatically-captured image.</p>
    <p num="p-0469">The camera may indicate how one or more images have been compressed or deleted. For example, the camera may output an audio message to a user indicating, “An automatically-captured image of Alice on the beach has been compressed using a compression setting of 75%.”</p>
    <p num="p-0470">The camera may indicate why one or more images have been compressed or deleted. For example, the camera may use an LCD screen to display a message to a user, “Automatically-captured images #123, 124, and 125 have been compressed to make room for additional manually-captured images. These images were selected for compression because they all have ratings worse than 4.0.”</p>
    <p num="p-0471">In some embodiments, the camera may prompt a user to confirm that one or more images should be compressed or deleted or provide other information relating to compressing or deleting images. Examples include:</p>
    <p num="p-0472">The camera may prompt a user to indicate whether a memory management function should be performed (i.e., whether one or more images should be compressed or deleted). For example, the camera may output a message to a user, “You only have 1 Mb of memory left. Would you like the camera to compress automatically-captured images to free up more memory?”</p>
    <p num="p-0473">The camera may prompt a user to indicate whether one or more images should be compressed or deleted. For example, the camera may output a prompt to a user, “Images #2341, 2342, and 2345 have been selected to be deleted. Do you want to delete these images?” Note that it may be particularly appropriate to prompt a user before compressing or deleting one or more manually-captured images.</p>
    <p num="p-0474">The camera may prompt a user to indicate which images should be compressed or deleted. For example, the camera may display a set of image thumbnails to the user and ask the user to select which images should be deleted from memory.</p>
    <p num="p-0475">The camera may prompt a user to indicate how much one or more images should be compressed. For example, the camera may display an image to a user and prompt the user to indicate how much the image should be compressed.</p>
    <p num="p-0476">Alternatively, a camera may not provide any indication relating to the compression or deletion of an image. As mentioned earlier, this may be acceptable to a user because the images that may be compressed or deleted may be automatically-captured images. Since the user never captured these images in the first place, he may be unconcerned about the camera deleting these images automatically. In addition, note that prompting a user to provide information relating to compressing or deleting one or more images (e.g., whether an image should be compressed/deleted, how much to compress and image) may be bothersome or annoying to the user.</p>
    <p num="p-0477">Referring now to <figref idrefs="DRAWINGS">FIG. 16</figref>, a flowchart illustrates a process <b>1600</b> that is consistent with one or more embodiments of the present invention. The process <b>1500</b> is a method for managing images automatically. For illustrative purposes only, the process <b>1600</b> is described as being performed by a camera (e.g., camera <b>210</b>).</p>
    <p num="p-0478">In step <b>1605</b>, a camera determines whether the camera is running low on memory. In step <b>1610</b>, the camera determines whether one or more images should be compressed. If not the process ends. Otherwise, in step <b>1615</b>, the camera determines which one or more images should be compressed. In step <b>1620</b>, the camera determines how much to compress each of the selected images. In step <b>1625</b>, the camera compresses the image(s) and stores the compressed versions of the images.</p>
    <heading>Alternative Embodiments</heading> <p num="p-0479">According to some embodiments of the present invention, alternatively, or in addition to automatically compressing or deleting an image, the camera may automatically transfer an image to a second device. For example, the camera may include a wireless communication port that allows the camera to transmit images to a second electronic device (e.g., a computer server, personal computer, portable hard drive, digital picture frame, or other electronic device). The second electronic device may then store copies of the images. After transferring the images to this second electronic device, the camera may delete the images, since the images are now stored securely on the second electronic device.</p>
    <p num="p-0480">In one example, a camera may include a cellular telephone or be connected to a cellular telephone with wireless modem capabilities (e.g., a cellular telephone on a 2.5 G or 3 G wireless network). Using the cellular telephone, the camera may transmit one or more images to a computer server, which may store the images. In another example, a camera may communicate with a portable hard drive such as an Apple iPod (e.g., using a Firewire cable or a Bluetooth communication link). To free up memory on the camera, the camera may transfer images to the portable hard drive. In yet another example, a camera may have an Internet connection (e.g., using the 802.11 wireless protocol) and use this connection to transmit images to a personal computer that is connection to the Internet.</p>
    <p num="p-0481">In accordance with some embodiments, transferring an image from the camera to a second electronic device, a camera may effectively expand its available memory. That is, some or all of the memory on the second electronic device may be available to the camera for storing images. In some embodiments, a camera may determine whether to transmit one or more images to a second electronic device. For example, the camera may determine whether it is running low on memory and therefore should free up some memory by transmitting one or more images to a second electronic device and then deleting them. This process may be performed based on a variety of factors, including, without limitation: an amount of memory (e.g., an amount of memory on the camera that is free, an amount of memory on the second electronic device that is free), an amount of bandwidth (e.g., an amount of bandwidth available for transmitting images to the second electronic device), factors relating to capturing images, a user's preferences, and factors relating to images stored in memory.</p>
    <p num="p-0482">In some embodiments, Similarly, a camera may determine which images to transmit to a second electronic device. For example, the camera may free up some memory by transmitting images of Alice to a second electronic device, but keep all images of Bob stored in the camera's secondary memory for viewing using the camera. Note that the camera may determine which images to transmit based on a variety of factors, including: the quality of at least one image (e.g., as measured by a rating), the compressibility of at least one image, image content (e.g., the subject of an image), a user's preferences, meta-data associated with at least one image (e.g., time, location, subject, associated images), an amount of memory (e.g., an amount of memory on the camera that is free, an amount of memory on the second electronic device that is free), and an amount of bandwidth (e.g., an amount of bandwidth available for transmitting images to the second electronic device).</p>
    <p num="p-0483">Since the bandwidth of a connection between the camera and a second electronic device may be limited, the camera may compress one or more images when transmitting them to a second electronic device. In addition, the camera may determine whether to compress an image when transmitting it to a second electronic device. For example, low quality images may be compressed before being transmitted to a second electronic device, whereas high quality images may be transmitted at full resolution to the second electronic device. Various ways of making such a determination are discussed herein. Similarly, the camera may determine how much to compress one or more images when transmitting the one or more images to a second electronic device, as discussed herein. This determination may be made based on a variety of different factors, including: an amount of memory (e.g., an amount of memory on the camera that is free, an amount of memory on the second electronic device that is free), and an amount of bandwidth (e.g., an amount of bandwidth available for transmitting images to the second electronic device).</p>
    <p num="p-0484">In some embodiments, a camera may delete or compress an image after transmitting it to a second electronic device, thereby saving memory. Since a copy of the image may be stored on the second electronic device, there may be no danger of losing or degrading the image by deleting or compressing it on the camera. Of course, a camera need not delete or compress an image after transmitting the image to a second electronic device. For example, the camera may transmit an image to a second electronic device in order to create a backup copy of the image. It may be helpful to store duplicate copies of an image on the camera and on the second electronic device in a variety of circumstances. For instance, a user of the camera may be concerned about breaking or losing the camera. By storing a second copy of an image on a second electronic device, the user has some assurance that his image will not be lost completely if the camera is misplaced or broken. In another example, an image may be transmitted to a second electronic device but not stored on the second electronic device. For example a user may transmit a copy of an image to his friend's PDA or cell phone so that the friend can view the image.</p>
    <p num="p-0485">In one alternate embodiment, a camera may only capture images automatically and may not capture images manually. For example, the camera may not have a shutter button or other shutter control. Instead, the camera may only capture images automatically, e.g., at times when the camera determines are appropriate for capturing images. To use the camera, a user may simply aim the camera at scenes that he thinks are interesting. The camera may adjust its settings and capture images in an appropriate, fully automatic manner.</p>
    <p num="p-0486">To allow the user to indicate his preferences relating to automatically-captured images, in some embodiments a camera may have a control that allows a user to indicate a rating of one or more images or scenes. For example, the camera may have a rating dial or other input that a user may adjust to indicate a rating of a current image or scene. For example, a user may set the ratings dial to “8—very interesting” when a clown arrives at a child's birthday party, whereas it may be more appropriate to set the ratings dial to “3—less interesting” when children are leaving to go home after the birthday party. It is hoped that by providing a ratings dial or other simple control to a user, the user will be able to focus his attention on which moments and scenes he wants to capture rather than the technical aspects of composing good photographs.</p>
    <p num="p-0487">While the majority of the examples in this disclosure have described a user operating the camera (e.g., holding the camera in his hands), it should be noted that the camera may not by held or operated by a user. For example, a camera may by mounted to a wall, telephone pole, or other stable platform in a public place and automatically capture images of this public place. For instance, a camera at an amusement park may automatically capture images of children with their favorite cartoon character mascots. In another example, a camera may be mounted on an autonomous or radio-controlled robot. For example, the camera may be mounted on a miniature blimp that may fly around the inside of a basketball stadium. The camera/blimp may automatically capture images of a basketball game, or people in the stands watching the basketball game. In another example, a camera may be carried by a user, but not in the user's hands. For example, the camera may be mounted on a baseball cap that is worn by a user, leaving the user's hands free for other activities. As the user proceeds through the activities of his day (e.g., sightseeing with his family), the camera may automatically capture and manage images.</p>
    <p num="p-0488">According to some embodiments, images captured by the camera may be rated and then displayed based on these ratings. For example, images that were captured automatically may be displayed in order of their ratings (e.g., highest rated images first). In a second example, only highly-rated images may be displayed to a user. A general process may include one or more of the steps of: determining an image, determining a rating for the image, and displaying the image to a user based on the rating for the image. An alternate general process may include the steps of determining a plurality of images, determining a rating for each of the plurality of images, and displaying at least one of the plurality of images to a user based on at least one of the ratings. In some embodiments, a camera or other device including a display may only display those images that have ratings higher than a threshold value, may determine an order to display the plurality of images based on at least one of the ratings, and/or may display the plurality of images based on at least one of the ratings. In some embodiments, the rating may be based on the quality of the image, the desirability of the image, the exposure of the image, and/or a comparison of the image to at least one second image. In some embodiments, at least one of the plurality of images may be captured automatically.</p>
    <p num="p-0489">Although the methods and apparatus of the present invention have been described herein in terms of particular embodiments, those skilled in the art will recognize that various embodiments of the present invention may be practiced with modification and alteration without departing from the teachings disclosed herein.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5266985">US5266985</a></td><td class="patent-data-table-td patent-date-value">Oct 28, 1992</td><td class="patent-data-table-td patent-date-value">Nov 30, 1993</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Camera with optimum composition determinator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5831670">US5831670</a></td><td class="patent-data-table-td patent-date-value">Jun 18, 1996</td><td class="patent-data-table-td patent-date-value">Nov 3, 1998</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Camera capable of issuing composition information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6094215">US6094215</a></td><td class="patent-data-table-td patent-date-value">Jan 6, 1998</td><td class="patent-data-table-td patent-date-value">Jul 25, 2000</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method of determining relative camera orientation position to create 3-D visual images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6301440">US6301440</a></td><td class="patent-data-table-td patent-date-value">Apr 13, 2000</td><td class="patent-data-table-td patent-date-value">Oct 9, 2001</td><td class="patent-data-table-td ">International Business Machines Corp.</td><td class="patent-data-table-td ">System and method for automatically setting image acquisition controls</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6757693">US6757693</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 3, 2001</td><td class="patent-data-table-td patent-date-value">Jun 29, 2004</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">System and method of data transmission/reception</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6765612">US6765612</a></td><td class="patent-data-table-td patent-date-value">Dec 9, 1996</td><td class="patent-data-table-td patent-date-value">Jul 20, 2004</td><td class="patent-data-table-td ">Flashpoint Technology, Inc.</td><td class="patent-data-table-td ">Method and system for naming images captured by a digital camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6847388">US6847388</a></td><td class="patent-data-table-td patent-date-value">Jun 29, 2001</td><td class="patent-data-table-td patent-date-value">Jan 25, 2005</td><td class="patent-data-table-td ">Flashpoint Technology, Inc.</td><td class="patent-data-table-td ">Method and system for accelerating a user interface of an image capture unit during play mode</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6914625">US6914625</a></td><td class="patent-data-table-td patent-date-value">Oct 29, 1999</td><td class="patent-data-table-td patent-date-value">Jul 5, 2005</td><td class="patent-data-table-td ">Ipac Acquisition Subsidiary I, Llc</td><td class="patent-data-table-td ">Method and apparatus for managing image categories in a digital camera to enhance performance of a high-capacity image storage media</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6977680">US6977680</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 2000</td><td class="patent-data-table-td patent-date-value">Dec 20, 2005</td><td class="patent-data-table-td ">Seiko Epson Corporation</td><td class="patent-data-table-td ">Image data reduction and processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7286168">US7286168</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 11, 2002</td><td class="patent-data-table-td patent-date-value">Oct 23, 2007</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing apparatus and method for adding blur to an image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7362359">US7362359</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 19, 2003</td><td class="patent-data-table-td patent-date-value">Apr 22, 2008</td><td class="patent-data-table-td ">Fujifilm Corporation</td><td class="patent-data-table-td ">Electronic device with an imaging function, image data output system, and image data output method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7508444">US7508444</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 22, 1998</td><td class="patent-data-table-td patent-date-value">Mar 24, 2009</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Electronic camera with quick view and quick erase features</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7701490">US7701490</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 2006</td><td class="patent-data-table-td patent-date-value">Apr 20, 2010</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Automatically transmitting images from an electronic camera to a service provider using a network configuration file</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020054224">US20020054224</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 21, 2001</td><td class="patent-data-table-td patent-date-value">May 9, 2002</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Customizing digital image transfer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020149689">US20020149689</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 12, 2002</td><td class="patent-data-table-td patent-date-value">Oct 17, 2002</td><td class="patent-data-table-td ">Masato Sannoh</td><td class="patent-data-table-td ">Image pick-up device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030193610">US20030193610</a></td><td class="patent-data-table-td patent-date-value">Sep 8, 1998</td><td class="patent-data-table-td patent-date-value">Oct 16, 2003</td><td class="patent-data-table-td ">Hirotake Nozaki</td><td class="patent-data-table-td ">Electronic camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040056966">US20040056966</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 23, 2001</td><td class="patent-data-table-td patent-date-value">Mar 25, 2004</td><td class="patent-data-table-td ">Schechner Yoav Y.</td><td class="patent-data-table-td ">Method and apparatus for image mosaicing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040075756">US20040075756</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 21, 2002</td><td class="patent-data-table-td patent-date-value">Apr 22, 2004</td><td class="patent-data-table-td ">Bean Heather N.</td><td class="patent-data-table-td ">Method and digital camera for indicating when image data has been captured for a three-dimensional target object</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=xT7UBgABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2000209483A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGbcUY-NRJS8k6huhF8xHVMaYFAhA">JP2000209483A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=xT7UBgABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH11136557A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEfYruBMZe5SH4H-yGI8LOBJf0WdQ">JPH11136557A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Office Action for Application No. EP 04815525.3, dated Nov. 17, 2009; 4 pp.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Office Action for Australian Application No. 2004311841 mailed Aug. 7, 2007, 1 pg.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Office Action for Canadian Application No. 2,544,135 mailed Nov. 26, 2010, 3 pp.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Office Action for Canadian Application No. 2,554,135 mailed Dec. 30, 2008, 3 pp.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Office Action for European Application No. 04815525.3 mailed Nov. 23, 2007, 5 pp.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Office Action for Japanese Application No. 2006-547417 mailed Sep. 12, 2008, 2 pp.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">PCT International Search Report for PCT/US2004/043460 mailed Feb. 16, 2006, 4 pp.</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">PCT Written Opinion for PCT/US 2004/043460 mailed Jul. 6, 2006, 3 pp.</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">ProPhoto Home Wireless Image Transmitter, http://www.prophotohome.com/forum/pro-photo-wiki-select-articles/73285-wireless-image-transmitter.html, download date Nov. 2, 2010, 4 pp.</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Shutterfly Online Photo Sharing http://www.shutterfly.com/refdesk/get-sub-tran.jsp, download date Nov. 2, 2010, 3 pp.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Shutterfly Online Photo Sharing http://www.shutterfly.com/refdesk/get—sub—tran.jsp, download date Nov. 2, 2010, 3 pp.</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Supplementary European Search Report, Aug. 14, 2007, 2 pp.</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">WiPics From ProPHOTO WIKI, http://www.prophotowiki.com/w/index.php/WiPics, download date Nov. 1, 2010, 3 pp.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8159546">US8159546</a></td><td class="patent-data-table-td patent-date-value">Jan 8, 2010</td><td class="patent-data-table-td patent-date-value">Apr 17, 2012</td><td class="patent-data-table-td ">Making Everlasting Memories, Llc</td><td class="patent-data-table-td ">Image capture and distribution system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8170349">US8170349</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 18, 2008</td><td class="patent-data-table-td patent-date-value">May 1, 2012</td><td class="patent-data-table-td ">Yahoo! Inc.</td><td class="patent-data-table-td ">Graphical rating conversion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8209051">US8209051</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 27, 2006</td><td class="patent-data-table-td patent-date-value">Jun 26, 2012</td><td class="patent-data-table-td ">Intouch Technologies, Inc.</td><td class="patent-data-table-td ">Medical tele-robotic system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8224108">US8224108</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 4, 2010</td><td class="patent-data-table-td patent-date-value">Jul 17, 2012</td><td class="patent-data-table-td ">DigitalOptics Corporation Europe Limited</td><td class="patent-data-table-td ">Digital image processing using face detection information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8225210">US8225210</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 8, 2007</td><td class="patent-data-table-td patent-date-value">Jul 17, 2012</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing apparatus and control method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8265399">US8265399</a></td><td class="patent-data-table-td patent-date-value">Dec 2, 2009</td><td class="patent-data-table-td patent-date-value">Sep 11, 2012</td><td class="patent-data-table-td ">DigitalOptics Corporation Europe Limited</td><td class="patent-data-table-td ">Detecting orientation of digital images using face detection information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8374176">US8374176</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 9, 2007</td><td class="patent-data-table-td patent-date-value">Feb 12, 2013</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Method and apparatus for providing internet protocol datacasting (IPDC) service, and method and apparatus for processing IPDC service</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8375283">US8375283</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 20, 2006</td><td class="patent-data-table-td patent-date-value">Feb 12, 2013</td><td class="patent-data-table-td ">Nokia Corporation</td><td class="patent-data-table-td ">System, device, method, and computer program product for annotating media files</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8488012">US8488012</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 3, 2008</td><td class="patent-data-table-td patent-date-value">Jul 16, 2013</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Automatic image-capturing apparatus, automatic image-capturing control method, image display system, image display method, display control apparatus, and display control method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8587693">US8587693</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 17, 2010</td><td class="patent-data-table-td patent-date-value">Nov 19, 2013</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Determination of storage availability for files to be stored at one or more device quality parameter settings</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8633995">US8633995</a></td><td class="patent-data-table-td patent-date-value">Mar 9, 2012</td><td class="patent-data-table-td patent-date-value">Jan 21, 2014</td><td class="patent-data-table-td ">Making Everlasting Memories, Llc</td><td class="patent-data-table-td ">Image capture and distribution system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8743261">US8743261</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 28, 2013</td><td class="patent-data-table-td patent-date-value">Jun 3, 2014</td><td class="patent-data-table-td ">Verizon Patent And Licensing Inc.</td><td class="patent-data-table-td ">Camera data management and user interface apparatuses, systems, and methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070293265">US20070293265</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 20, 2006</td><td class="patent-data-table-td patent-date-value">Dec 20, 2007</td><td class="patent-data-table-td ">Nokia Corporation</td><td class="patent-data-table-td ">System, device, method, and computer program product for annotating media files</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080008175">US20080008175</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 9, 2007</td><td class="patent-data-table-td patent-date-value">Jan 10, 2008</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd</td><td class="patent-data-table-td ">Method and apparatus for providing internet protocol datacasting(ipdc) service, and method and apparatus for processing ipdc service</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090115865">US20090115865</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 3, 2008</td><td class="patent-data-table-td patent-date-value">May 7, 2009</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Automatic image-capturing apparatus, automatic image-capturing control method, image display system, image display method, display control apparatus, and display control method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110037778">US20110037778</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 29, 2009</td><td class="patent-data-table-td patent-date-value">Feb 17, 2011</td><td class="patent-data-table-td ">Perception Digital Limited</td><td class="patent-data-table-td ">Apparatus And Method For Adjusting An Image In A Screen Of A Handheld Device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110096187">US20110096187</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 4, 2010</td><td class="patent-data-table-td patent-date-value">Apr 28, 2011</td><td class="patent-data-table-td ">Tessera Technologies Ireland Limited</td><td class="patent-data-table-td ">Digital Image Processing Using Face Detection Information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120120268">US20120120268</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 17, 2010</td><td class="patent-data-table-td patent-date-value">May 17, 2012</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Content parameter control for available memory</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S231200">348/231.2</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005760000">H04N5/76</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0001210000">H04N1/21</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0001000000">H04N1/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/2129">H04N1/2129</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/218">H04N2201/218</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/214">H04N2201/214</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2101/00">H04N2101/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/216">H04N2201/216</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/34">G11B27/34</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/28">G11B27/28</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/2112">H04N1/2112</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/034">G11B27/034</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/105">G11B27/105</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N5/23222">H04N5/23222</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/00204">H04N1/00204</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/2137">H04N1/2137</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=xT7UBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/3027">G11B27/3027</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N1/00C3</span>, <span class="nested-value">H04N1/21B3</span>, <span class="nested-value">H04N5/232J</span>, <span class="nested-value">G11B27/34</span>, <span class="nested-value">H04N1/21B3F</span>, <span class="nested-value">G11B27/30C</span>, <span class="nested-value">G11B27/034</span>, <span class="nested-value">G11B27/28</span>, <span class="nested-value">G11B27/10A1</span>, <span class="nested-value">H04N1/21B3E</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Dec 17, 2013</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:WALKER DIGITAL, LLC;REEL/FRAME:031797/0629</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20131101</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">INVENTOR HOLDINGS, LLC, CONNECTICUT</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 12, 2013</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120915</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1-10, 12-26, 28 AND 29 ARE CANCELLED. CLAIMS 11 AND 27 ARE DETERMINED TO BE PATENTABLE AS AMENDED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 20, 2012</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120130</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 12, 2007</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">WALKER DIGITAL, LLC, CONNECTICUT</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:WALKER, JAY S.;JORASCH, JAMES A.;SAMMON, RUSSELL P.;REEL/FRAME:019413/0266;SIGNING DATES FROM 20070425 TO 20070426</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:WALKER, JAY S.;JORASCH, JAMES A.;SAMMON, RUSSELL P.;SIGNING DATES FROM 20070425 TO 20070426;REEL/FRAME:019413/0266</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U3MV6QAqPGARfMy0tDNxik6S4ZEPg\u0026id=xT7UBgABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3piUfgtV7G8qpLnlZKarPRj_k6lQ\u0026id=xT7UBgABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2863sZ8Oz2e8PN_Xgnbd9aroLrqg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_and_apparatus_for_automatically_c.pdf?id=xT7UBgABERAJ\u0026output=pdf\u0026sig=ACfU3U1jxcIvA9akjypJD6dc1Lmb_zQmPw"},"sample_url":"http://www.google.com/patents/reader?id=xT7UBgABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>