<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5877445 - System for generating prescribed duration audio and/or video sequences - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="System for generating prescribed duration audio and/or video sequences"><meta name="DC.contributor" content="Geoffrey Calvin Hufford" scheme="inventor"><meta name="DC.contributor" content="Christopher P. Hufford" scheme="inventor"><meta name="DC.contributor" content="Kevin C. Klingler" scheme="inventor"><meta name="DC.contributor" content="Sonic Desktop Software" scheme="assignee"><meta name="DC.date" content="1997-10-24" scheme="dateSubmitted"><meta name="DC.description" content="A block sequence compiler for compiling a sequence of audio and/or video blocks (e.g., audio tracks, MIDI, video clips, animation, etc.) suitable for producing one or more audio and/or video output sequences (i.e., audio, video, or multimedia) each having a duration corresponding to user-prescribed criteria. In a preferred embodiment, a user chooses an audio and/or video source segment from a predefined library and prescribes the duration of an audio and/or video sequence. Prior to depositing each audio and/or video segment in the library, the segment is partitioned into audio and/or video blocks that are identified in a corresponding characteristic data table with characteristics including (1) duration, (2) suitability for being used as a beginning or ending of an audio and/or video sequence, and (3) compatibility with each block. Using this characteristic table and the user-prescribed criteria, i.e., duration, the block sequence compiler generates a plurality of audio and/or video sequences satisfying the user-prescribed criteria which can be reviewed, e.g., played, and/or saved for future use."><meta name="DC.date" content="1999-3-2" scheme="issued"><meta name="DC.relation" content="US:5300725" scheme="references"><meta name="DC.relation" content="US:5455378" scheme="references"><meta name="DC.relation" content="US:5521323" scheme="references"><meta name="citation_patent_number" content="US:5877445"><meta name="citation_patent_application_number" content="US:08/957,422"><link rel="canonical" href="http://www.google.com/patents/US5877445"/><meta property="og:url" content="http://www.google.com/patents/US5877445"/><meta name="title" content="Patent US5877445 - System for generating prescribed duration audio and/or video sequences"/><meta name="description" content="A block sequence compiler for compiling a sequence of audio and/or video blocks (e.g., audio tracks, MIDI, video clips, animation, etc.) suitable for producing one or more audio and/or video output sequences (i.e., audio, video, or multimedia) each having a duration corresponding to user-prescribed criteria. In a preferred embodiment, a user chooses an audio and/or video source segment from a predefined library and prescribes the duration of an audio and/or video sequence. Prior to depositing each audio and/or video segment in the library, the segment is partitioned into audio and/or video blocks that are identified in a corresponding characteristic data table with characteristics including (1) duration, (2) suitability for being used as a beginning or ending of an audio and/or video sequence, and (3) compatibility with each block. Using this characteristic table and the user-prescribed criteria, i.e., duration, the block sequence compiler generates a plurality of audio and/or video sequences satisfying the user-prescribed criteria which can be reviewed, e.g., played, and/or saved for future use."/><meta property="og:title" content="Patent US5877445 - System for generating prescribed duration audio and/or video sequences"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("T0_sU6bmOozwoASA3oCIBg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CRI"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("T0_sU6bmOozwoASA3oCIBg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CRI"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5877445?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5877445"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=9dJJBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5877445&amp;usg=AFQjCNGKlaOh-PGxxbW5azwmRvOoa4V1IQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5877445.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5877445.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5877445" style="display:none"><span itemprop="description">A block sequence compiler for compiling a sequence of audio and/or video blocks (e.g., audio tracks, MIDI, video clips, animation, etc.) suitable for producing one or more audio and/or video output sequences (i.e., audio, video, or multimedia) each having a duration corresponding to user-prescribed criteria....</span><span itemprop="url">http://www.google.com/patents/US5877445?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5877445 - System for generating prescribed duration audio and/or video sequences</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5877445 - System for generating prescribed duration audio and/or video sequences" title="Patent US5877445 - System for generating prescribed duration audio and/or video sequences"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5877445 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/957,422</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Mar 2, 1999</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Oct 24, 1997</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Sep 22, 1995</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/DE69633863D1">DE69633863D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE69633863T2">DE69633863T2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0852049A1">EP0852049A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0852049A4">EP0852049A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0852049B1">EP0852049B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5693902">US5693902</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO1997011450A1">WO1997011450A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08957422, </span><span class="patent-bibdata-value">957422, </span><span class="patent-bibdata-value">US 5877445 A, </span><span class="patent-bibdata-value">US 5877445A, </span><span class="patent-bibdata-value">US-A-5877445, </span><span class="patent-bibdata-value">US5877445 A, </span><span class="patent-bibdata-value">US5877445A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Geoffrey+Calvin+Hufford%22">Geoffrey Calvin Hufford</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Christopher+P.+Hufford%22">Christopher P. Hufford</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Kevin+C.+Klingler%22">Kevin C. Klingler</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Sonic+Desktop+Software%22">Sonic Desktop Software</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5877445.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5877445.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5877445.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (84),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (22),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (7)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5877445&usg=AFQjCNF7g7KipHM1sr5QLV66y-jlTK7D7A">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5877445&usg=AFQjCNH234CFs-vwVdkYHtgZRPTlt8O2pQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5877445A%26KC%3DA%26FT%3DD&usg=AFQjCNEJu83cYUiFvpxQRwBeh0S1VKKFQQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54408889" lang="EN" load-source="patent-office">System for generating prescribed duration audio and/or video sequences</invention-title></span><br><span class="patent-number">US 5877445 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37883325" lang="EN" load-source="patent-office"> <div class="abstract">A block sequence compiler for compiling a sequence of audio and/or video blocks (e.g., audio tracks, MIDI, video clips, animation, etc.) suitable for producing one or more audio and/or video output sequences (i.e., audio, video, or multimedia) each having a duration corresponding to user-prescribed criteria. In a preferred embodiment, a user chooses an audio and/or video source segment from a predefined library and prescribes the duration of an audio and/or video sequence. Prior to depositing each audio and/or video segment in the library, the segment is partitioned into audio and/or video blocks that are identified in a corresponding characteristic data table with characteristics including (1) duration, (2) suitability for being used as a beginning or ending of an audio and/or video sequence, and (3) compatibility with each block. Using this characteristic table and the user-prescribed criteria, i.e., duration, the block sequence compiler generates a plurality of audio and/or video sequences satisfying the user-prescribed criteria which can be reviewed, e.g., played, and/or saved for future use.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(12)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-7.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-7.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-8.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-8.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-9.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-9.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-10.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-10.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-11.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-11.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5877445-12.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5877445-12.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(20)</span></span></div><div class="patent-text"><div mxw-id="PCLM5359461" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>We claim:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A system for compiling data blocks for producing a prescribed duration output sequence suitable for driving an output transducer, said system comprising:<div class="claim-text">a data storage library storing one or more source segments wherein each source segment is capable of being partitioned into a plurality of data blocks;</div> <div class="claim-text">a stored data table comprised of one or more groups of table entries, each such group being associated with a different one of said source segments and wherein each table entry defines a data block within the associated source segment;</div> <div class="claim-text">each said table entry additionally identifying characteristics of the associated data block including its duration, its suitability to begin or end an output sequence, and its interblock compatibility;</div> <div class="claim-text">a user interface for enabling a user to prescribe an output sequence duration; and</div> <div class="claim-text">a block sequence compiler for iteratively compiling a list of one or more output sequences each essentially conforming to said prescribed output sequence duration and wherein each output sequence is comprised of a plurality of data blocks selected according to said table entry characteristics.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The system of claim 1 additionally comprising means for displaying said list of one or more output sequences.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The system of claim 1 additionally comprising means to store at least one said output sequence from said list.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The system of claim 1 additionally comprising means for driving an output transducer according to an output sequence selected from said list.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The system of claim 1 wherein said table entries additionally include data identifying a mood parameter for each said data block and said user interface additionally enables a user to prescribe a mood parameter and said block sequence compiler selects data blocks according to said user-prescribed mood parameter.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The system of claim 1 wherein said table entries additionally include data identifying a fadeable parameter for each said data block and said block sequence compiler selects an ending data block having said fadeable parameter set and wherein such fadeable data blocks can be truncated to achieve output sequences of said user-prescribed output sequence duration.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The system of claim 1 wherein said table entries additionally include data identifying an intensity parameter for each said data block and said user interface additionally enables a user to prescribe an intensity curve and said block sequence compiler selects data blocks according to said user-prescribed intensity curve.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The system of claim 1 wherein said table additionally comprises data identifying a hit point parameter for each said data block for specifying when an intensity burst is present within said data block and said user interface additionally prescribes an intensity burst location and said block sequence compiler compiles output sequences of said data blocks according to said user-prescribed intensity burst location.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The system of claim 1 wherein said user interface additionally enables a user to prescribe one of said source segments and said block sequence compiler compiles output sequences of data blocks selected from said user-prescribed source segment.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The system of claim 1 wherein said table entries additionally include data identifying a static parameter for each said data block and said block sequence compiler can select an ending data block having said static parameter set and wherein such static data blocks can be extended to form output sequences of said user-prescribed output sequence duration.</div>
    </div>
    </div> <div class="claim"> <div num="11" class="claim">
      <div class="claim-text">11. A method for compiling data blocks for producing a prescribed duration output sequence suitable for driving an output transducer, said method comprising the steps of:<div class="claim-text">providing data in a data storage library corresponding to at least one source segment;</div> <div class="claim-text">partitioning said source segment into a plurality of data blocks;</div> <div class="claim-text">indicating characteristics corresponding to the duration of each data block;</div> <div class="claim-text">indicating characteristics of each data block corresponding to the suitability of each data block to begin or end an output sequence and the interblock compatibility of each data block;</div> <div class="claim-text">defining a desired duration for an output sequence; and</div> <div class="claim-text">iteratively compiling a list of one or more output sequences essentially conforming to said prescribed output sequence duration and wherein each output sequence is comprised of a plurality of data blocks selected according to said table entry characteristics.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The method of claim 11 additionally comprising the step of selecting one of said source segments and wherein said iteratively compiling step compiles sequences of data blocks from those data blocks corresponding to a selected source segment.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The method of claim 11 additionally comprising the step of displaying said compiled list of one or more output sequences.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The method of claim 11 additionally comprising the steps of:<div class="claim-text">selecting one of said output sequences from said compiled list; and</div> <div class="claim-text">outputting a sequence of data blocks corresponding to said selected output sequence.</div> </div>
    </div>
    </div> <div class="claim"> <div num="15" class="claim">
      <div class="claim-text">15. A method for compiling data blocks for producing a prescribed duration output sequence suitable for driving an output transducer wherein said output sequence is comprised of a plurality of data blocks corresponding to portions of a source segment and indicating characteristics of each data block corresponding to its duration, its suitability of each data block to begin or end an output sequence, and its interblock compatibility, said method comprising the steps of:<div class="claim-text">defining a desired output sequence duration; and</div> <div class="claim-text">iteratively compiling a list of one or more output sequences each comprised of a plurality of data blocks according to said desired output sequence duration such that each said output sequence is comprised of a plurality of data blocks conforming to its indicated characteristics.</div> </div>
    </div>
    </div> <div class="claim"> <div num="16" class="claim">
      <div class="claim-text">16. A system for compiling data blocks for producing an output sequence suitable for repeatable driving an output transducer, said system comprising:<div class="claim-text">a data storage library for storing one or more source segments wherein each source segment is capable of being partitioned into a Plurality of data blocks;</div> <div class="claim-text">a stored data table comprised of one or more groups of table entries, each such group being associated with a different one of said source segments and wherein each table entry defines a data block within the associated source segment;</div> <div class="claim-text">each said table entry additionally identifying characteristics of the associated data block including its duration and its interblock compatibility;</div> <div class="claim-text">a user interface for enabling a user to prescribe an output sequence duration corresponding to the durations of said data blocks comprising an output sequence; and</div> <div class="claim-text">a block sequence compiler for iteratively compiling a list of one or more repeatable output sequences each comprised of a plurality of data blocks selected to essentially conform to said user-prescribed output sequence duration and wherein each output sequence is comprised of a Plurality of data blocks selected according to said table entry characteristics.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The system of claim 16 additionally comprising means for displaying said list of one or more output sequences.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. The system of claim 16 wherein each said repeatable sequence comprises at least a first data block and a last data block and wherein said last data block of each said repeatable output sequence is selected such that the first data block of each said repeatable output sequence is compatible, according to said table entries, to sequentially follow said last data block of each said repeatable output sequence.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The system of claim 16 wherein said table entries additionally include a reversible parameter to identify data blocks suitable for playing both in a forward or in a reverse direction and each said data block selected by said block sequence compiler has said reversible parameter set.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The system of claim 16 additionally comprising means for driving an output transducer according to an output sequence selected from said list.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67251406" lang="EN" load-source="patent-office" class="description">
    <p>This application is a continuation in part of application Ser. No. 08/532,527, filed Sep. 22, 1995, now U.S. Pat. No. 5,693,902.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>The present invention relates generally to hardware/software systems for generating audio and/or video sequences of prescribed duration and more particularly to such systems suitable for generating and correlating such sequences for producing multimedia presentations.</p>
    <p>Exemplary multimedia presentations are formed from video source material, e.g., a video segment such as a film clip, and audio source material, e.g., an audio segment such as a sound track. Typically, the video source segment must be edited many times before an aesthetically satisfactory and proper duration video output sequence is achieved. The audio source segment must similarly be edited to form an audio output sequence that matches the duration of the edited video output sequence.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention is directed toward a system for compiling a sequence of data blocks for producing an audio and/or video output sequence having a duration corresponding to user-prescribed criteria.</p>
    <p>In a preferred embodiment, a user (via a keyboard and/or mouse and a display monitor) chooses an audio and/or video source segment from a data storage library storing data representing original sound tracks, MIDI data, film clips, animation clips, etc., and prescribes the desired duration of an audio and/or video output sequence. Each segment in the data storage library is divided into data blocks whose characteristics are identified in a stored characteristic data table. Exemplary characteristics include (1) duration, (2) suitability for being used as a beginning or ending of an output sequence, and (3) interblock compatibility. Using this stored characteristic table and user-prescribed criteria (e.g., a duration specified via the keyboard), a block sequence compiler (preferably a software program executed by a computer) generates a plurality of audio and/or video block sequences satisfying these criteria which can be reviewed (e.g., played via an audio and/or video output device or displayed on a monitor) and/or saved for future use.</p>
    <p>In an exemplary use, the block sequence compiler compiles a first output sequence suitable for presentation on a first channel. Optionally, the block sequence compiler can also compile one or more additional output sequences compatible with the first output sequence (according to additional stored characteristic table parameters) suitable for presentation on additional output channels to create a multimedia presentation.</p>
    <p>In a further aspect of a preferred embodiment, the block sequence compiler is responsive a user-prescribed mood parameter stored in the characteristic table.</p>
    <p>In a still further aspect of a preferred embodiment, the stored characteristic table additionally contains a parameter that identifies blocks that are fadeable. When a fadeable block is selected as an end block, the block sequence compiler can truncate the fadeable end block to generate an output sequence of the prescribed length which might otherwise not be achievable.</p>
    <p>In a further aspect of a preferred embodiment, the block sequence compiler is responsive to a user-prescribed intensity parameter stored in the stored characteristic table.</p>
    <p>In a still further aspect of a preferred embodiment, each block is identified in the stored characteristic table as having a hit point that defines the location (when present) of an intensity burst. The block sequence compiler can use the hit point parameter to place an intensity burst at a user-prescribed location in the compiled output sequence.</p>
    <p>In another aspect of a preferred embodiment, the system enables a user to generate a sequence (or subsequence) of data blocks which can be executed one or more times, e.g., looping, to form an output sequence of extended duration. In a first variation, the compiler selects the last block of a sequence which is compatible with the first block to generate a repeatable sequence. Accordingly, the repeatable sequence can be repetitively executed from the first to the last block and then looped back to the first block. In a second variation, blocks in the repeatable sequence are selected which have a reversible attribute, i.e., blocks that can be played either in a forward or a reverse direction. Accordingly, the repeatable sequence can be repetitively played in a forward direction from the first to the last block and then in a reverse direction from the last block to the first block, again resulting in a sequence having an extended duration.</p>
    <p>Other features and advantages of the present invention should become apparent from the following description of the presently-preferred embodiments, taken in conjunction with the accompanying drawings, which illustrate, by way of example, the principles of the present invention.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 comprises a functional block diagram of a block sequence compiler in accordance with the present invention for generating audio and/or video sequences having user-prescribed durations;</p>
    <p>FIG. 2 is a simplified diagram of a characteristic table showing the parameters associated with each audio and/or video block;</p>
    <p>FIG. 3A is a simplified flow chart of the operation of the system of FIG. 1;</p>
    <p>FIG. 3B is a simplified flow chart depicting the process implemented by the block sequence compiler;</p>
    <p>FIG. 4 is an exemplary characteristic table for a fifty second source audio and/or video segment;</p>
    <p>FIG. 5 shows the iterations performed by the block sequence compiler according to the flow chart of FIG. 3B on the characteristic table data of FIG. 4;</p>
    <p>FIG. 6 is a simplified flow chart depicting the process implemented by the block sequence compiler to compile a repeatable audio and/or video sequence generated by looping the last block to the first block of the compiled sequence;</p>
    <p>FIG. 7 shows the iterations performed by the block sequence compiler according to the flow chart of FIG. 6 on the characteristic table data of FIG. 8;</p>
    <p>FIG. 8 is an exemplary characteristic table for a fifty second source audio and/or video segment used in conjunction with the flow chart of FIG. 6;</p>
    <p>FIG. 9 is a simplified flow chart depicting the process implemented by the block sequence compiler by selecting blocks having a reversible attribute to compile a repeatable audio and/or video sequence;</p>
    <p>FIG. 10 is an exemplary characteristic table for a fifty second source audio and/or video segment used in conjunction with the flow chart of FIG. 9;</p>
    <p>FIG. 11 is block diagram an exemplary system for generating multiple compatible audio and/or video channels, i.e., multimedia, according to user-prescribed criteria; and</p>
    <p>FIG. 12 is a simplified diagram showing multiple audio and/or video channels generated by the exemplary system of FIG. 11.</p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>With reference now to the drawings, and particularly to FIG. 1, there is shown a block diagram of a preferred embodiment of an audio and/or video sequence generator 10 of the present invention for compiling a sequence of data blocks suitable for producing an audio and/or video output sequence having a duration corresponding to user-prescribed criteria. In a preferred embodiment, the sequence generator 10 is comprised of a computer-executed software program, generally initially present on a floppy disk, and which preferably finally resides on the hard disk of a personal computer (PC) 12, e.g., a Macintosh or IBM compatible PC, controlled by a processor 13. As such the following discussion, relates to these preferred PC environments. However, different computer platforms or hardware-only implementations are also considered within the scope of the invention.</p>
    <p>The sequence generator 10 is primarily comprised of (1) a data storage library 14 (preferably comprised of data blocks corresponding to or pointing to audio tracks, MIDI data, video clips, animation, or any other data representative of sound or visual information) and (2) a block sequence compiler 16. In operation, a user interface 17, e.g., a keyboard/mouse 18, enables a user to select a source segment 28 from the data storage library 14 and prescribe a duration. This information is communicated to the block sequence compiler 16 which, under control of a software program executed by the processor 13 in the PC 12, fetches blocks of audio and/or video source information (preferably digital data) from the data storage library 14 and, according to compilation criteria described further below, compiles a list of potential audio and/or video sequences that are preferably temporarily stored within a potential block sequence list depository 19. In the case of audio (e.g., an audio track or MIDI data) output sequence, the user can select to play the audio sequence via a sound card/speaker 20, review a list of potential block sequences via a monitor 21, or store selected sequences for future use, e.g., on a hard disk 22. Alternatively, in the case of a video sequence (e.g., video clip or animation data), the user can select to play the video sequence (preferably via a video card 24 and monitor 21), review a list of potential block sequences via the monitor 21, or store selected sequences for future use, e.g., on the hard disk 22. In either case, the block sequence compiler 16 can preferably be directed to only compile a single audio and/or video output sequence and then wait until prompted by the user to generate a next audio and/or video output sequence.</p>
    <p>The data storage library 14 preferably contains library entries 26 pertaining to a plurality of audio and/or video source segments. Each library entry 26 is comprised of (1) an audio and/or video source segment 28 and (2) a stored characteristic data table 30 which describes the partitioning of the audio and/or video source segment 28 into multiple data blocks and the characteristics of each block. Although, the source segment 28 is shown as being located within the data storage library 14, one of ordinary skill in the art will recognize that the source segment 28 can alternatively be physically located outside of the library, e.g., on a CD-ROM or DVD, and referenced, e.g., by pointers, by the characteristic table 30. FIG. 2 shows an exemplary structure for the characteristic table 30. Each entry 26 in the characteristic table 30 contains a definition/pointer 32 which includes identifying information for the library entry, e.g., a title and the physical location of the audio and/or video source segment 28, e.g., a CD-ROM file. Each characteristic table entry 30 is further divided into a plurality of entries that define blocks, i.e., audio and/or video data blocks, and associated characteristics for the audio and/or video from the audio and/or video source segment 28.</p>
    <p>In a simplified example, an audio and/or video source segment 28 is divided into five blocks: A, B, C, D, E, F where the sequence ABCDEF corresponds to the audio and/or video source segment 28. Although, other combinations of blocks, e.g., FEDCBA, can also create audio and/or video sequences, not all block sequences will create aesthetically reasonable audio and/or video sequences. Thus, information is preferably derived to determine interblock compatibility, i.e., the ability of a block to sequentially follow (or alternatively sequentially precede) each other block according to aesthetic, e.g., musical, criteria. For example, while block C may reasonably follow block B, it may not be aesthetically reasonable for it to follow block A. Additionally, while some blocks, e.g., A, are suitable according to aesthetic criteria to reasonably start an audio and/or video sequence, other blocks are not. Similarly, only certain blocks, e.g., F, are suitable according to aesthetic criteria to reasonably end an audio and/or video sequence. Lastly, not all audio and/or video source segments 28 can reasonably be divided into fixed length blocks. In fact, using reasonable aesthetic criteria, blocks will generally be differently sized. Consequently, audio and/or video sequences of many different durations can be achieved by combining different combinations of these differently-sized blocks. However, as previously described, the available combinations are limited by the compatibility between potentially adjacent blocks as well as their suitability to begin or end an audio and/or video sequence. Corresponding to these criteria, data in the characteristic table 30 contains parameters for each audio and/or video block pertaining to a (1) duration 34, (2) type attribute (e.g., beginning/ending) 36, and (3) an interblock compatibility list 38 (e.g., a list of which blocks can aesthetically follow and/or precede the current block). Additionally, information (not shown) identifying the physical location of each audio and/or video block in the audio and/or video source segment 28 is preferably retained in the characteristic table 30. While data in the characteristic table 30 can be manually generated, automated procedures are also possible.</p>
    <p>FIG. 3B shows a simplified flow chart exemplary of the iterative process implemented by the block sequence compiler 16 after being provided the user-prescribed data (as shown in FIG. 3A). As previously described, after the user has determined a selection 40 from the data storage library 14 and a duration 42, the block sequence compiler 16 operates on the data in the characteristic table 30 according to the flow chart of FIG. 3B. Accordingly, a list of potential output sequences is compiled that conform to the characteristic table 30 and these sequences are stored in the potential block sequence list 19. In order to conform to the characteristic table, each block in an output sequence must be compatible with each adjacent block according to its interblock compatibility characteristic 38, i.e., each block must be compatible with blocks which directly precede and follow in an output sequence. Additionally, it is preferable that each sequence begin with a block having a beginning characteristic 38 set and end with a block having an ending characteristic 36 set.</p>
    <p>FIG. 4 shows an exemplary characteristic table for a fifty second audio and/or video source segment 28. In this example, the source segment is partitioned into ten blocks, each being five seconds long. (While fixed length blocks exist in this example, this is generally not the case). In this example, blocks A and C have been marked as potential beginnings and blocks E and J have been marked as potential endings. In the example shown in FIG. 5, the user has selected a duration 42 of thirty-five seconds for this source segment 28. Accordingly, FIG. 5 shows the iterations performed by the block sequence compiler 16 on the characteristic table 30 of FIG. 4 according to the flow chart of FIG. 3B. FIG. 5 shows that the original audio and/or video sequence has now been rearranged into three potential sequences (ABCDEFGJ, ABCDEFHE, CDEFGHIJ) that each (1) have the prescribed duration, (2) begin with a beginning block, and (3) end with an ending block.</p>
    <p>In an exemplary audio environment, the generator 10 allows users to quickly and easily create movie or record quality music soundtracks for any application or document that can import sound. The sequence generator 10 is able to accomplish this by processing an audio source segment, e.g., music, in response to user inputs. The user selects a musical style and sub-style from a list, then specifies the length (preferably in minutes, seconds and tenths of seconds). A musical source segment is selected from the library that meets the user's needs and a custom version of that music is created that is exactly (within user-prescribed criteria) the specified length. If the user doesn't like the selected music, the user can hear a different version of the same music or a different piece music--all of the versions presented will fit the user's specifications.</p>
    <p>By using music and its corresponding characteristic table 30 and input from the user, the block sequence compiler 16 can customize the following aspects of the music:</p>
    <p>The length of the music can be customized in tenths of a second increments from seconds to hours.</p>
    <p>Different versions of the same piece of music (sometimes hundreds of thousands of options) can be generated.</p>
    <p>In an alternative embodiment, the block sequence compiler 16 can customize the intensity of the music. The user can define a desired intensity curve 44. This will allow the user to have the program make a piece of music that begins softly (perhaps while an announcer speaks) and builds to a climax (perhaps when the narration has ended). In this embodiment, an intensity parameter 46 is added to the characteristic table 30 for each block and the block sequence compiler 16 selects blocks that most closely correspond to the prescribed intensity curve 44.</p>
    <p>In a next alternative embodiment, the user can specify a mood selection 48 to modify the mood of the music without changing any other characteristics. In this embodiment, a mood parameter 50 is added to characteristic table 30. Additionally, multiple renditions of the audio source segment 28 are prerecorded corresponding to different moods. The block sequence compiler 16 will then select renditions that correspond to the prescribed mood parameter 50.</p>
    <p>In another alternative embodiment, a user can specify a first duration of background music followed by a second duration of introductory music. The compiler 16 will be able to locate two different pieces of music and make a smooth, musical, transition between them.</p>
    <p>In an additional alternative embodiment, blocks can be identified with a fadeable parameter 52 in the characteristic table 30. When a block is fadeable, its duration can be truncated to become a satisfactory end block, even if its duration would normally be too long. The compiler 16 can then truncate the fadeable block to achieve the user-prescribed duration. Additionally, the intensity of the end of the fadeable block will fade at a prescribed rate to reduce the effects of the truncation.</p>
    <p>In still another embodiment, each block can be identified in the characteristic table 30 as having a hit point parameter 54 that defines the location (when present) of an intensity burst. When prescribed by the user, the block sequence compiler 16 can use the hit point parameter 54 to place an intensity burst at a user-prescribed location (e.g., defined by intensity curve 44) in the generated audio output sequence.</p>
    <p>Similar aspects of a corresponding video (e.g., video clip or animation) sequence can also be customized by the compiler 16 according to data within the characteristic table 30. For example, if a static parameter 55 is placed within the characteristic table 30, this parameter can be used to identify blocks, preferably additionally having an ending type 36, that can be extended to a desired duration and thus can be used to simplify matching the user-prescribed duration 42. Accordingly, especially in a video environment, the last block can end with a still picture (a "freeze frame") that can be maintained as long as required to produce a sequence having the prescribed duration 42.</p>
    <p>The following defines the data structure for each block of the characteristic table in this exemplary audio embodiment:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________fileInfo  a pointer to which audio source segment this     block is associated withblockStart     the sample number within the audio source     segment at which this block beginsblockLength     the number of samples that this block contains.     The end sample number is derived by adding     blockStart and blockLengthblockName the name to display on this block (no longer     than 15 charactersblockDesc the long text description of this block (up to     63 characters)compatibility     an array of bits specifying this block's     compatibility with all other blocks in this file     (described below)usageFlags     bit flags indicating properties of this block     (described below)nextBlock the block number of the best block to following     this blockquickEnd  the block number of the best next block to end     the music quicklyblockSection     a section number of this block assigned for use     in grouping sub-blocks into grouped blocks for     displayblockPriority     a priority number of this block assigned for use     in displaying blocks at different detail levelsblockType a set of bits specifying if this block should be     displayed, if the block is in-use, and other     status flags. USER<sub>--</sub> BLOCK<sub>--</sub> TYPE,     INVISIBLE<sub>--</sub> BLOCK<sub>--</sub> TYPE,     AVAILABLE<sub>--</sub> BLOCK<sub>--</sub> TYPEselected  a True/False flag indicating if the block is     currently selectedintensity each block is assigned an intensity index in     relation to the other blocks in the file. The     higher the intensity number, the more intense     the audio in the block is in relation to the     other blocks.hitPoint  the sample number, if any, of a musical "Hit"     within the block. (0 for no significant hit)moodIndex a number grouping this blocks mood with other     blocks mood. All blocks with the same moodIndex     will have the same mood.next      a pointer to the next block______________________________________</pre>
    
    <p>Compatibility</p>
    <p>Each block has an array of unsigned longs which are used as an array of bits. Each bit corresponds to a block from the data storage library 14, e.g., bit 15 should be set if the block is compatible with block 15. Compatible blocks are blocks which sound musically correct when they are played one after the other. For example, Block A should be flagged as compatible with Block B when it sounds musically correct to listen to Block A followed by Block B. If Block B was the 24th block from the library source segment, then bit 24 of Block A's compatibility array should be set.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________USAGEFLAGSDEAD<sub>--</sub> END<sub>--</sub> FLAG            Set if this block will lead you directly            toward an ending. Set this bit if this            block is a bad choice to build a long            cue            (1L&lt;&lt;0)NEXT<sub>--</sub> CONTIGUOUS<sub>--</sub> FLAG            Set this bit if the next block doesn't            need a crossfade to make a good            sounding transition            (1L&lt;&lt;1)FADEABLE<sub>--</sub> BLOCK            Set this bit to signal that this block            can be effectively faded (in volume)            to any length.            (1L&lt;&lt;2)BEGINING<sub>--</sub> BLOCK            Set this bit if the block is a good            choice (sounds musically correct) to            begin a selection            (1L&lt;&lt;30) // 0x40000000ENDING<sub>--</sub> BLOCK            Set this bit if the block is a good            choice to end a selection            (1L&lt;&lt;31) // 0x80000000______________________________________</pre>
    
    <p>While some of the above functions (further defined in the data structure below) can be applied to existing music (through a process of specifying block characteristics), some are dependent on a custom music library in which music is composed and performed in a specific format.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________struct BlockStruct {SoundFileInfoPtr        fileInfo; //                    pointer to file                    struct for this blockunsigned long        blockStart;//                    sample numberunsigned long        blockLength;//                    number of samplesStr15        blockName;Str63        blockDesc;    unsigned long            compatibility COMPAT<sub>--</sub> SIZE!;    unsigned long            usageFlags;    short        nextBlock;    short        quickEnd;    unsigned char            blockSection;    unsigned char            blockPriority;    BlockTypes   blockType;    Boolean      selected;    BlockStructPtr            next;};______________________________________</pre>
    
    <p>HINTING/WARNING</p>
    <p>Using the characteristic table data associated with each data block, the user is assisted by visually displaying information about the blocks. Block attributes including beginnings, endings and compatibility are all displayed.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Beginning-    displayed by a stair-step pattern on         the left edge of the blockEnding-       displayed by a stair-step pattern on         the right edge of the blockCompatibility-         the rightmost end cap of a selection         in the sequence window is colored and         all of the compatible blocks in the         block window will have their left end         caps colored.Warning-      when two non-compatible blocks are         next to each other, we display a red         edge at their junction.______________________________________</pre>
    
    <p>The process of specifying characteristics of music and sound is both musical and technical. This process is used to provide as much information as possible about each piece of music or sound so that the compiler 16 can make informed, musical decisions, when it manipulates the music according to requests from users. This process includes the following:</p>
    <p>1. Block Start and End: The beginning and ending of each discrete music section (block) is determined. This necessarily determines the length of each block. Listen to the piece of music and divide it into segments based on musical phrases and musical uses called blocks. On average, there are fifteen blocks per minute of music.</p>
    <p>2. Block Name: Code each block with a name and description.</p>
    <p>3. Beginning Blocks: For each block a determination is made as to whether it would make a good way to start a musical section or phrase.</p>
    <p>4. Ending Blocks: Same concept as that described for Beginning Blocks.</p>
    <p>5. Block Compatibility: Each block is tested for its specific compatibility to each and every other block which comprise the source audio segment.</p>
    <p>6. Intensity: Code each block's musical intensity relative to other blocks.</p>
    <p>7. Fadeable Block: Each block has a determination made as to whether it sounds musically viable to fade or not.</p>
    <p>In a further aspect of the present invention, a user may alternatively prescribe a repeatable audio and/or video sequence (or subsequence), e.g., a looping sequence, that is capable of repeating and thus has an extended duration. In this embodiment, a last block 56 of a compiled sequence 58 is chosen that is compatible (according to compatibility data 38) with a first block 60 of the compiled sequence 58. While the beginning/ending attribute 36 is of limited significance with such a repeatable sequence (and accordingly an ending attribute is preferably not required), it is still aesthetically preferable that the sequence initially begin with a block having a beginning attribute. Additionally, while a principal duration 62 of the compiled block sequence (the time duration from the beginning of the first block of the repeatable sequence to the end of the last block of the repeatable sequence) does not alter the duration of the looping sequence (i.e., repeating a twenty second portion thirty-five times or repeating a thirty-five second portion twenty times both result in the same extended durations), the aesthetic effect of such sequences are generally effected by the principal duration 62. Accordingly, it is preferable that the block sequence compiler 16 accept directions via user interface 17 to determine the sequence of blocks according to duration 42.</p>
    <p>Accordingly, using the exemplary flow chart of FIG. 6, a user specifies duration 42 to specify the principal duration 62. FIG. 7 shows the processing of the data of FIG. 8 according to the flow chart of FIG. 6 for a principal duration of thirty-five seconds (compiling sequences ABCDEFGJ and ABCDEFHE). Accordingly, it is noted that while the end block of the principal loop may have an ending attribute 36 (e.g., block E), this is not a requirement of the algorithm of FIG. 6. Additionally, FIG. 7 shows the alternative processing when the algorithm of FIG. 6 is altered to eliminate the restriction (specified in program step 64) that requires that the compiled sequence begin with a block having a beginning attribute 36. Consequently, a sequence of CDEFGHIJ is compiled.</p>
    <p>In a next variation, e.g., in a visual environment, portions of the source audio and/or video segment 28 are determined which can play equally well in a forward or in a reverse direction. Accordingly, an infinite loop can be defined by selecting a sequence of compatible blocks accordingly to compatibility list 38 that additionally have a reversible attribute 66 set. Accordingly, if block sequence compiler 16 operates on the data of FIG. 10 according to the algorithm of FIG. 9 and a prescribed duration 42 of twenty seconds, a sequence of CDEF, CDCD, or CDED will result. When played, these sequences will preferably reverse in direction at the end of the last block and at the beginning of the first block (when being played backwards).</p>
    <p>While the above description has primarily discussed uses where the entire sequence is repeatable, alternative uses are also considered within the scope of the present invention. For example, the repeatable sequence could be only a portion, i.e., a subsequence, of the compiled output sequence. In an exemplary case, a first portion of the output sequence is compiled according to first user-specified duration (J), a second portion of the output sequence is compiled according to a second user prescribed principal duration (K) that is repeatable a user-specified number of times (L), and a third portion of the output sequence is compiled according to a third user-specified duration (M). Consequently, the resulting duration will be J+(K*L)+M.</p>
    <p>As described, embodiments of the invention are suitable for generating audio and/or video output sequence suitable for presentation on a single output channel, e.g., as a single audio track, a single MIDI output, a single video clip output, a single animation, etc. In an exemplary use, it may be required to compile a thirty second video sequence as a video output to combine with an existing audio track, e.g., assorted pictures of a new car with a predefined description of its features, or to add a musical interlude to a predefined video clip, and thus create a car commercial. However, it may also be desirable to compile both a video sequence and an audio sequence to satisfy the user-defined duration criteria 42, e.g., thirty seconds. However, it will generally be significant that the audio and video channels correlate, e.g., an audio track describing braking characteristics should not be combined with video clips of crash tests. Therefore, FIG. 11 shows a simplified block diagram of an embodiment that enables compiling (using multiple block sequence compilers 16a-16n or preferably by time sharing a single block sequence compiler 16) multiple channels of audio and video 68a-68n, i.e., multimedia, and cross-correlating the potential block sequence lists 19 using cross-correlator 70 to ensure compatibility between the multiple channels. To achieve this task, the cross-correlator 70 operates upon additional compatibility data 38, e.g., data which shows the interblock compatibility between the blocks in each channel 68, i.e., interchannel compatibility. For the example of FIG. 12, the characteristic table 30 contains additional compatibility data 38 to ensure that BLOCK 1<sub>n</sub> is compatible with both BLOCK 1<sub>1</sub> and BLOCK 2<sub>1</sub> (since the blocks sizes are not the same on CHANNEL<sub>1</sub> and CHANNEL<sub>n</sub>, BLOCK 1<sub>n</sub> overlaps both BLOCK 1<sub>1</sub> and a portion of BLOCK 2<sub>1</sub>).</p>
    <p>Although the present invention has been described in detail with reference only to the presently-preferred embodiments, those of ordinary skill in the art will appreciate that various modifications can be made without departing from the invention. Accordingly, the invention is defined by the following claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5300725">US5300725</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 13, 1992</td><td class="patent-data-table-td patent-date-value">Apr 5, 1994</td><td class="patent-data-table-td ">Casio Computer Co., Ltd.</td><td class="patent-data-table-td ">Automatic playing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5455378">US5455378</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 17, 1994</td><td class="patent-data-table-td patent-date-value">Oct 3, 1995</td><td class="patent-data-table-td ">Coda Music Technologies, Inc.</td><td class="patent-data-table-td ">Intelligent accompaniment apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5521323">US5521323</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 21, 1993</td><td class="patent-data-table-td patent-date-value">May 28, 1996</td><td class="patent-data-table-td ">Coda Music Technologies, Inc.</td><td class="patent-data-table-td ">Real-time performance score matching</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6194647">US6194647</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 18, 1999</td><td class="patent-data-table-td patent-date-value">Feb 27, 2001</td><td class="patent-data-table-td ">Promenade Co., Ltd</td><td class="patent-data-table-td ">Method and apparatus for producing a music program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6281421">US6281421</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 10, 2000</td><td class="patent-data-table-td patent-date-value">Aug 28, 2001</td><td class="patent-data-table-td ">Yamaha Corporation</td><td class="patent-data-table-td ">Remix apparatus and method for generating new musical tone pattern data by combining a plurality of divided musical tone piece data, and storage medium storing a program for implementing the method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6395969">US6395969</a></td><td class="patent-data-table-td patent-date-value">Jul 28, 2000</td><td class="patent-data-table-td patent-date-value">May 28, 2002</td><td class="patent-data-table-td ">Mxworks, Inc.</td><td class="patent-data-table-td ">System and method for artistically integrating music and visual effects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6452083">US6452083</a></td><td class="patent-data-table-td patent-date-value">Jul 2, 2001</td><td class="patent-data-table-td patent-date-value">Sep 17, 2002</td><td class="patent-data-table-td ">Sony France S.A.</td><td class="patent-data-table-td ">Incremental sequence completion system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6545209">US6545209</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 5, 2001</td><td class="patent-data-table-td patent-date-value">Apr 8, 2003</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Music content characteristic identification and matching</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6608249">US6608249</a></td><td class="patent-data-table-td patent-date-value">May 21, 2002</td><td class="patent-data-table-td patent-date-value">Aug 19, 2003</td><td class="patent-data-table-td ">Dbtech Sarl</td><td class="patent-data-table-td ">Automatic soundtrack generator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6636220">US6636220</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 30, 2000</td><td class="patent-data-table-td patent-date-value">Oct 21, 2003</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Video-based rendering</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6815600">US6815600</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2002</td><td class="patent-data-table-td patent-date-value">Nov 9, 2004</td><td class="patent-data-table-td ">Alain Georges</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6867358">US6867358</a></td><td class="patent-data-table-td patent-date-value">Jul 28, 2000</td><td class="patent-data-table-td patent-date-value">Mar 15, 2005</td><td class="patent-data-table-td ">Sandor Mester, Jr.</td><td class="patent-data-table-td ">Method and apparatus for producing improvised music</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6888999">US6888999</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 7, 2002</td><td class="patent-data-table-td patent-date-value">May 3, 2005</td><td class="patent-data-table-td ">Magix Ag</td><td class="patent-data-table-td ">Method of remixing digital information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6897368">US6897368</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2002</td><td class="patent-data-table-td patent-date-value">May 24, 2005</td><td class="patent-data-table-td ">Alain Georges</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6916978">US6916978</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2002</td><td class="patent-data-table-td patent-date-value">Jul 12, 2005</td><td class="patent-data-table-td ">Alain Georges</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6933432">US6933432</a></td><td class="patent-data-table-td patent-date-value">Mar 28, 2002</td><td class="patent-data-table-td patent-date-value">Aug 23, 2005</td><td class="patent-data-table-td ">Koninklijke Philips Electronics N.V.</td><td class="patent-data-table-td ">Media player with DJ mode</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6958441">US6958441</a></td><td class="patent-data-table-td patent-date-value">Dec 19, 2002</td><td class="patent-data-table-td patent-date-value">Oct 25, 2005</td><td class="patent-data-table-td ">Alain Georges</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6960714">US6960714</a></td><td class="patent-data-table-td patent-date-value">Dec 19, 2002</td><td class="patent-data-table-td patent-date-value">Nov 1, 2005</td><td class="patent-data-table-td ">Media Lab Solutions Llc</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6972363">US6972363</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2002</td><td class="patent-data-table-td patent-date-value">Dec 6, 2005</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6977335">US6977335</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2002</td><td class="patent-data-table-td patent-date-value">Dec 20, 2005</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6979767">US6979767</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2002</td><td class="patent-data-table-td patent-date-value">Dec 27, 2005</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6986102">US6986102</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and configurable model for storing hierarchical data in a non-hierarchical data repository</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7007034">US7007034</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Feb 28, 2006</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">File structure for storing content objects in a data repository</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7015389">US7015389</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2002</td><td class="patent-data-table-td patent-date-value">Mar 21, 2006</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7022906">US7022906</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2002</td><td class="patent-data-table-td patent-date-value">Apr 4, 2006</td><td class="patent-data-table-td ">Media Lab Solutions Llc</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7026534">US7026534</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2002</td><td class="patent-data-table-td patent-date-value">Apr 11, 2006</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7043488">US7043488</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">May 9, 2006</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and system for storing hierarchical content objects in a data repository</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7071402">US7071402</a></td><td class="patent-data-table-td patent-date-value">Aug 13, 2003</td><td class="patent-data-table-td patent-date-value">Jul 4, 2006</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Automatic soundtrack generator in an image record/playback device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7076035">US7076035</a></td><td class="patent-data-table-td patent-date-value">Jan 4, 2002</td><td class="patent-data-table-td patent-date-value">Jul 11, 2006</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Methods for providing on-hold music using auto-composition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7076494">US7076494</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Jul 11, 2006</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Providing a functional layer for facilitating creation and manipulation of compilations of content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7078609">US7078609</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 2003</td><td class="patent-data-table-td patent-date-value">Jul 18, 2006</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Interactive digital music recorder and player</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7089239">US7089239</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Aug 8, 2006</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and system for preventing mutually exclusive content entities stored in a data repository to be included in the same compilation of content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7102069">US7102069</a></td><td class="patent-data-table-td patent-date-value">Nov 12, 2002</td><td class="patent-data-table-td patent-date-value">Sep 5, 2006</td><td class="patent-data-table-td ">Alain Georges</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7120273">US7120273</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 31, 2002</td><td class="patent-data-table-td patent-date-value">Oct 10, 2006</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, Lp.</td><td class="patent-data-table-td ">Apparatus and method for image group integrity protection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7169996">US7169996</a></td><td class="patent-data-table-td patent-date-value">Jan 7, 2003</td><td class="patent-data-table-td patent-date-value">Jan 30, 2007</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Systems and methods for generating music using data/music data file transmitted/received via a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7176372">US7176372</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 2003</td><td class="patent-data-table-td patent-date-value">Feb 13, 2007</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Interactive digital music recorder and player</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7194676">US7194676</a></td><td class="patent-data-table-td patent-date-value">Mar 1, 2002</td><td class="patent-data-table-td patent-date-value">Mar 20, 2007</td><td class="patent-data-table-td ">Avid Technology, Inc.</td><td class="patent-data-table-td ">Performance retiming effects on synchronized data in an editing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7340481">US7340481</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Mar 4, 2008</td><td class="patent-data-table-td ">International Business Machines Corp.</td><td class="patent-data-table-td ">Method and system for adding user-provided content to a content object stored in a data repository</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7356766">US7356766</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Apr 8, 2008</td><td class="patent-data-table-td ">International Business Machines Corp.</td><td class="patent-data-table-td ">Method and system for adding content to a content object stored in a data repository</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7389034">US7389034</a></td><td class="patent-data-table-td patent-date-value">Dec 12, 2001</td><td class="patent-data-table-td patent-date-value">Jun 17, 2008</td><td class="patent-data-table-td ">Digital Networks North America, Inc.</td><td class="patent-data-table-td ">Data entry via on-screen display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7401097">US7401097</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Jul 15, 2008</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method for creating compilations of content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7491878">US7491878</a></td><td class="patent-data-table-td patent-date-value">Feb 13, 2007</td><td class="patent-data-table-td patent-date-value">Feb 17, 2009</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Method and apparatus for automatically creating musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7504576">US7504576</a></td><td class="patent-data-table-td patent-date-value">Feb 10, 2007</td><td class="patent-data-table-td patent-date-value">Mar 17, 2009</td><td class="patent-data-table-td ">Medilab Solutions Llc</td><td class="patent-data-table-td ">Method for automatically processing a melody with sychronized sound samples and midi events</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7574276">US7574276</a></td><td class="patent-data-table-td patent-date-value">Dec 21, 2005</td><td class="patent-data-table-td patent-date-value">Aug 11, 2009</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">System and methods for providing automatic classification of media entities according to melodic movement properties</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7613993">US7613993</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Nov 3, 2009</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Prerequisite checking in a system for creating compilations of content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7642444">US7642444</a></td><td class="patent-data-table-td patent-date-value">Nov 13, 2007</td><td class="patent-data-table-td patent-date-value">Jan 5, 2010</td><td class="patent-data-table-td ">Yamaha Corporation</td><td class="patent-data-table-td ">Music-piece processing apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7655855">US7655855</a></td><td class="patent-data-table-td patent-date-value">Jan 26, 2007</td><td class="patent-data-table-td patent-date-value">Feb 2, 2010</td><td class="patent-data-table-td ">Medialab Solutions Llc</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7702014">US7702014</a></td><td class="patent-data-table-td patent-date-value">Dec 16, 1999</td><td class="patent-data-table-td patent-date-value">Apr 20, 2010</td><td class="patent-data-table-td ">Muvee Technologies Pte. Ltd.</td><td class="patent-data-table-td ">System and method for video production</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7754959">US7754959</a></td><td class="patent-data-table-td patent-date-value">Dec 1, 2005</td><td class="patent-data-table-td patent-date-value">Jul 13, 2010</td><td class="patent-data-table-td ">Magix Ag</td><td class="patent-data-table-td ">System and method of automatically creating an emotional controlled soundtrack</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7797272">US7797272</a></td><td class="patent-data-table-td patent-date-value">May 5, 2004</td><td class="patent-data-table-td patent-date-value">Sep 14, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">System and method for dynamic playlist of media</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7807916">US7807916</a></td><td class="patent-data-table-td patent-date-value">Aug 25, 2006</td><td class="patent-data-table-td patent-date-value">Oct 5, 2010</td><td class="patent-data-table-td ">Medialab Solutions Corp.</td><td class="patent-data-table-td ">Method for generating music with a website or software plug-in using seed parameter values</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7812240">US7812240</a></td><td class="patent-data-table-td patent-date-value">Oct 10, 2008</td><td class="patent-data-table-td patent-date-value">Oct 12, 2010</td><td class="patent-data-table-td ">Yamaha Corporation</td><td class="patent-data-table-td ">Fragment search apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7847178">US7847178</a></td><td class="patent-data-table-td patent-date-value">Feb 8, 2009</td><td class="patent-data-table-td patent-date-value">Dec 7, 2010</td><td class="patent-data-table-td ">Medialab Solutions Corp.</td><td class="patent-data-table-td ">Interactive digital music recorder and player</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7863511">US7863511</a></td><td class="patent-data-table-td patent-date-value">Feb 7, 2008</td><td class="patent-data-table-td patent-date-value">Jan 4, 2011</td><td class="patent-data-table-td ">Avid Technology, Inc.</td><td class="patent-data-table-td ">System for and method of generating audio sequences of prescribed duration</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7895243">US7895243</a></td><td class="patent-data-table-td patent-date-value">Aug 31, 2007</td><td class="patent-data-table-td patent-date-value">Feb 22, 2011</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and system for moving content in a content object stored in a data repository</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7928310">US7928310</a></td><td class="patent-data-table-td patent-date-value">Nov 25, 2003</td><td class="patent-data-table-td patent-date-value">Apr 19, 2011</td><td class="patent-data-table-td ">MediaLab Solutions Inc.</td><td class="patent-data-table-td ">Systems and methods for portable audio synthesis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8006186">US8006186</a></td><td class="patent-data-table-td patent-date-value">Dec 22, 2000</td><td class="patent-data-table-td patent-date-value">Aug 23, 2011</td><td class="patent-data-table-td ">Muvee Technologies Pte. Ltd.</td><td class="patent-data-table-td ">System and method for media production</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8026436">US8026436</a></td><td class="patent-data-table-td patent-date-value">Apr 13, 2009</td><td class="patent-data-table-td patent-date-value">Sep 27, 2011</td><td class="patent-data-table-td ">Smartsound Software, Inc.</td><td class="patent-data-table-td ">Method and apparatus for producing audio tracks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8082279">US8082279</a></td><td class="patent-data-table-td patent-date-value">Apr 18, 2008</td><td class="patent-data-table-td patent-date-value">Dec 20, 2011</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">System and methods for providing adaptive media property classification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8153878">US8153878</a></td><td class="patent-data-table-td patent-date-value">May 26, 2009</td><td class="patent-data-table-td patent-date-value">Apr 10, 2012</td><td class="patent-data-table-td ">Medialab Solutions, Corp.</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8247676">US8247676</a></td><td class="patent-data-table-td patent-date-value">Aug 8, 2003</td><td class="patent-data-table-td patent-date-value">Aug 21, 2012</td><td class="patent-data-table-td ">Medialab Solutions Corp.</td><td class="patent-data-table-td ">Methods for generating music using a transmitted/received music data file</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8269092">US8269092</a></td><td class="patent-data-table-td patent-date-value">Apr 5, 2006</td><td class="patent-data-table-td patent-date-value">Sep 18, 2012</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Musical content reproducing device and musical content reproducing method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8357847">US8357847</a></td><td class="patent-data-table-td patent-date-value">Jul 12, 2007</td><td class="patent-data-table-td patent-date-value">Jan 22, 2013</td><td class="patent-data-table-td ">Mxp4</td><td class="patent-data-table-td ">Method and device for the automatic or semi-automatic composition of multimedia sequence</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8589777">US8589777</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Nov 19, 2013</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and system for calculating cost of a compilation of content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8649891">US8649891</a></td><td class="patent-data-table-td patent-date-value">Jul 31, 2009</td><td class="patent-data-table-td patent-date-value">Feb 11, 2014</td><td class="patent-data-table-td ">Nero Ag</td><td class="patent-data-table-td ">Audio signal generator, method of generating an audio signal, and computer program for generating an audio signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8674206">US8674206</a></td><td class="patent-data-table-td patent-date-value">Oct 4, 2010</td><td class="patent-data-table-td patent-date-value">Mar 18, 2014</td><td class="patent-data-table-td ">Medialab Solutions Corp.</td><td class="patent-data-table-td ">Systems and methods for creating, modifying, interacting with and playing musical compositions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8704073">US8704073</a></td><td class="patent-data-table-td patent-date-value">Dec 3, 2010</td><td class="patent-data-table-td patent-date-value">Apr 22, 2014</td><td class="patent-data-table-td ">Medialab Solutions, Inc.</td><td class="patent-data-table-td ">Interactive digital music recorder and player</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8755667">US8755667</a></td><td class="patent-data-table-td patent-date-value">Jun 16, 2008</td><td class="patent-data-table-td patent-date-value">Jun 17, 2014</td><td class="patent-data-table-td ">Digital Networks North America, Inc.</td><td class="patent-data-table-td ">Data entry via on-screen display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1604180B?cl=en">CN1604180B</a></td><td class="patent-data-table-td patent-date-value">Sep 30, 2004</td><td class="patent-data-table-td patent-date-value">Dec 15, 2010</td><td class="patent-data-table-td "></td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1132889A2?cl=en">EP1132889A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 5, 2001</td><td class="patent-data-table-td patent-date-value">Sep 12, 2001</td><td class="patent-data-table-td ">KCE Tokyo Inc.</td><td class="patent-data-table-td ">Game machine and game program distribution method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1170722A1?cl=en">EP1170722A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 4, 2000</td><td class="patent-data-table-td patent-date-value">Jan 9, 2002</td><td class="patent-data-table-td ">Sony France S.A.</td><td class="patent-data-table-td ">Incremental sequence completion system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1734505A1?cl=en">EP1734505A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 31, 2005</td><td class="patent-data-table-td patent-date-value">Dec 20, 2006</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Music composition data edition device and music composition data edition method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1791111A1?cl=en">EP1791111A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 25, 2005</td><td class="patent-data-table-td patent-date-value">May 30, 2007</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Content creating device and content creating method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1830347A1?cl=en">EP1830347A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 9, 2005</td><td class="patent-data-table-td patent-date-value">Sep 5, 2007</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Music composition data reconstruction device, music composition data reconstruction method, music content reproduction device, and music content reproduction method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1876583A1?cl=en">EP1876583A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 5, 2006</td><td class="patent-data-table-td patent-date-value">Jan 9, 2008</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Musical content reproducing device and musical content reproducing method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1923863A1?cl=en">EP1923863A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 16, 2007</td><td class="patent-data-table-td patent-date-value">May 21, 2008</td><td class="patent-data-table-td ">Yamaha Corporation</td><td class="patent-data-table-td ">Music-piece processing apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1956586A2?cl=en">EP1956586A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 8, 2008</td><td class="patent-data-table-td patent-date-value">Aug 13, 2008</td><td class="patent-data-table-td ">Avid Technology, Inc.</td><td class="patent-data-table-td ">System and method of generating audio sequences of prescribed duration</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2048654A1?cl=en">EP2048654A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 10, 2008</td><td class="patent-data-table-td patent-date-value">Apr 15, 2009</td><td class="patent-data-table-td ">Yamaha Corporation</td><td class="patent-data-table-td ">Musical fragment search apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2073193A1?cl=en">EP2073193A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 17, 2007</td><td class="patent-data-table-td patent-date-value">Jun 24, 2009</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Method and device for generating a soundtrack</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2159797A1?cl=en">EP2159797A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 28, 2008</td><td class="patent-data-table-td patent-date-value">Mar 3, 2010</td><td class="patent-data-table-td ">Nero AG</td><td class="patent-data-table-td ">Audio signal generator, method of generating an audio signal, and computer program for generating an audio signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2001009874A1?cl=en">WO2001009874A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 28, 2000</td><td class="patent-data-table-td patent-date-value">Feb 8, 2001</td><td class="patent-data-table-td ">Sandor Mester Jr</td><td class="patent-data-table-td ">Method and apparatus for producing improvised music</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2003083824A2?cl=en">WO2003083824A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 26, 2003</td><td class="patent-data-table-td patent-date-value">Oct 9, 2003</td><td class="patent-data-table-td ">Koninkl Philips Electronics Nv</td><td class="patent-data-table-td ">Media player with &#39;dj&#39; mode</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2004057570A1?cl=en">WO2004057570A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 10, 2003</td><td class="patent-data-table-td patent-date-value">Jul 8, 2004</td><td class="patent-data-table-td ">David A Eves</td><td class="patent-data-table-td ">Ordering audio signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2008020321A2?cl=en">WO2008020321A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 12, 2007</td><td class="patent-data-table-td patent-date-value">Feb 21, 2008</td><td class="patent-data-table-td ">Mxp4</td><td class="patent-data-table-td ">Method and device for the automatic or semi-automatic composition of a multimedia sequence</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2008072143A1?cl=en">WO2008072143A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 6, 2007</td><td class="patent-data-table-td patent-date-value">Jun 19, 2008</td><td class="patent-data-table-td ">Koninkl Philips Electronics Nv</td><td class="patent-data-table-td ">Musical composition system and method of controlling a generation of a musical composition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2008099406A2?cl=en">WO2008099406A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 14, 2008</td><td class="patent-data-table-td patent-date-value">Aug 21, 2008</td><td class="patent-data-table-td ">Imagine Ltd</td><td class="patent-data-table-td ">Live images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2009107137A1?cl=en">WO2009107137A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 26, 2009</td><td class="patent-data-table-td patent-date-value">Sep 3, 2009</td><td class="patent-data-table-td ">Technion Research &amp; Development Foundation Ltd.</td><td class="patent-data-table-td ">Interactive music composition method and apparatus</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc084/defs084.htm&usg=AFQjCNEZRFtAyKTfNudgc-XVt2-VboD77Q#C084S602000">84/602</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc084/defs084.htm&usg=AFQjCNEZRFtAyKTfNudgc-XVt2-VboD77Q#C084S609000">84/609</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc707/defs707.htm&usg=AFQjCNE7Q7Bg2eD2wcE_fXEcdOe7Yesevw#C707SE17009">707/E17.009</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc084/defs084.htm&usg=AFQjCNEZRFtAyKTfNudgc-XVt2-VboD77Q#C084S610000">84/610</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc084/defs084.htm&usg=AFQjCNEZRFtAyKTfNudgc-XVt2-VboD77Q#C084S649000">84/649</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc084/defs084.htm&usg=AFQjCNEZRFtAyKTfNudgc-XVt2-VboD77Q#C084S650000">84/650</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0017300000">G06F17/30</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10H0001000000">G10H1/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30017">G06F17/30017</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30749">G06F17/30749</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10H2250/035">G10H2250/035</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10H1/0033">G10H1/0033</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10H2210/125">G10H2210/125</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30743">G06F17/30743</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10H2240/085">G10H2240/085</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10H2240/131">G10H2240/131</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9dJJBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10H1/0025">G10H1/0025</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06F17/30U1</span>, <span class="nested-value">G06F17/30U2</span>, <span class="nested-value">G10H1/00M5</span>, <span class="nested-value">G10H1/00R</span>, <span class="nested-value">G06F17/30E</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jul 24, 2012</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-20 IS CONFIRMED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 15, 2012</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120330</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 1, 2010</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 9, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SMARTSOUND SOFTWARE, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:SONIC DESKTOP SOFTWARE, INC.;REEL/FRAME:018505/0940</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20021009</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 20, 2006</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 7, 2002</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 24, 1997</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SONIC DESKTOP SOFTWARE, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:HUFFORD, GEOFFREY C.;HUFFORD, CHRISTOPHER P.;KLINGLER, KEVIN C.;REEL/FRAME:008888/0869</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19971021</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0OXxBvkWroew5PEa6QFc0rW22hDw\u0026id=9dJJBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U07OBfZT9no9EzctXFKjSkCHD5pYw\u0026id=9dJJBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1a4wEWIQHArqF4z8oFscaQ5AQbUg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/System_for_generating_prescribed_duratio.pdf?id=9dJJBAABERAJ\u0026output=pdf\u0026sig=ACfU3U38SYsx_cqFFQckeDIvpjJqK10SEQ"},"sample_url":"http://www.google.com/patents/reader?id=9dJJBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>