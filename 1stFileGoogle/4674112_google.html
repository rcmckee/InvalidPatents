<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US4674112 - Character pattern recognition and communications apparatus - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Character pattern recognition and communications apparatus"><meta name="DC.contributor" content="George V. Kondraske" scheme="inventor"><meta name="DC.contributor" content="Adnan Shennib" scheme="inventor"><meta name="DC.contributor" content="Board Of Regents, The University Of Texas System" scheme="assignee"><meta name="DC.date" content="1985-9-6" scheme="dateSubmitted"><meta name="DC.description" content="A communication apparatus and method designed to interface with a standard, twelve key, dual tone, multiple frequency telephone, which allows easy, non-verbal entry of a message. Although particularly designed for use by the hearing and/or speech impaired with a dual tone telephone, the apparatus is equally adapted for use with practically any communication network where a keyboard with a limited number of keys is utilized and ambiguity resolution necessary. Generally speaking, the apparatus is connected to the earpiece of a receiving telephone and includes a tone pickup and decoder, a pre-programmed microcomputer and a message display panel. The message sender depresses a single key which corresponds to the alphabetic letter in the word being sent - because most keys on a telephone represent three letters, such a word is ambiguous when sent. The apparatus receives the ambiguous word and resolves the ambiguity in favor of a preprogrammed word which is displayed to the person receiving the message. Although the apparatus can be programmed to recognize words, the apparatus is programmed with a vocabulary of syllabic elements which are used to reconstruct the word. This approach enables an expanded word recognition capability while minimizing memory requirements."><meta name="DC.date" content="1987-6-16" scheme="issued"><meta name="DC.relation" content="US:4307266" scheme="references"><meta name="DC.relation" content="US:4578540" scheme="references"><meta name="DC.relation" content="US:4608460" scheme="references"><meta name="DC.relation" content="US:4633041" scheme="references"><meta name="citation_reference" content="Rabiner et al., &quot;Digital Techniques for Computer Voice Response: Implementations and Applications&quot;, Proceedings of the IEEE, vol. 64, No. 4, Apr. 1976, pp. 416-433."><meta name="citation_reference" content="Rabiner et al., Digital Techniques for Computer Voice Response: Implementations and Applications , Proceedings of the IEEE, vol. 64, No. 4, Apr. 1976, pp. 416 433."><meta name="citation_reference" content="Smith et al., &quot;Alphabetic Data Entry Via the Touch-Tone Pad: A Comment&quot;, Human Factors, vol. 13(2), Apr. 1971, pp. 189-190."><meta name="citation_reference" content="Smith et al., Alphabetic Data Entry Via the Touch Tone Pad: A Comment , Human Factors, vol. 13(2), Apr. 1971, pp. 189 190."><meta name="citation_patent_number" content="US:4674112"><meta name="citation_patent_application_number" content="US:06/773,371"><link rel="canonical" href="http://www.google.com/patents/US4674112"/><meta property="og:url" content="http://www.google.com/patents/US4674112"/><meta name="title" content="Patent US4674112 - Character pattern recognition and communications apparatus"/><meta name="description" content="A communication apparatus and method designed to interface with a standard, twelve key, dual tone, multiple frequency telephone, which allows easy, non-verbal entry of a message. Although particularly designed for use by the hearing and/or speech impaired with a dual tone telephone, the apparatus is equally adapted for use with practically any communication network where a keyboard with a limited number of keys is utilized and ambiguity resolution necessary. Generally speaking, the apparatus is connected to the earpiece of a receiving telephone and includes a tone pickup and decoder, a pre-programmed microcomputer and a message display panel. The message sender depresses a single key which corresponds to the alphabetic letter in the word being sent - because most keys on a telephone represent three letters, such a word is ambiguous when sent. The apparatus receives the ambiguous word and resolves the ambiguity in favor of a preprogrammed word which is displayed to the person receiving the message. Although the apparatus can be programmed to recognize words, the apparatus is programmed with a vocabulary of syllabic elements which are used to reconstruct the word. This approach enables an expanded word recognition capability while minimizing memory requirements."/><meta property="og:title" content="Patent US4674112 - Character pattern recognition and communications apparatus"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("uqvtU6DoIoPEsATn6IHQCg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("PAN"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("uqvtU6DoIoPEsATn6IHQCg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("PAN"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us4674112?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US4674112"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=7r4lBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS4674112&amp;usg=AFQjCNGgAMtlFECBa9Zc0tUuauRXRx9jWQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US4674112.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US4674112.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US4674112" style="display:none"><span itemprop="description">A communication apparatus and method designed to interface with a standard, twelve key, dual tone, multiple frequency telephone, which allows easy, non-verbal entry of a message. Although particularly designed for use by the hearing and/or speech impaired with a dual tone telephone, the apparatus is...</span><span itemprop="url">http://www.google.com/patents/US4674112?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US4674112 - Character pattern recognition and communications apparatus</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US4674112 - Character pattern recognition and communications apparatus" title="Patent US4674112 - Character pattern recognition and communications apparatus"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US4674112 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 06/773,371</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Jun 16, 1987</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Sep 6, 1985</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Sep 6, 1985</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">06773371, </span><span class="patent-bibdata-value">773371, </span><span class="patent-bibdata-value">US 4674112 A, </span><span class="patent-bibdata-value">US 4674112A, </span><span class="patent-bibdata-value">US-A-4674112, </span><span class="patent-bibdata-value">US4674112 A, </span><span class="patent-bibdata-value">US4674112A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22George+V.+Kondraske%22">George V. Kondraske</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Adnan+Shennib%22">Adnan Shennib</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Board+Of+Regents,+The+University+Of+Texas+System%22">Board Of Regents, The University Of Texas System</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US4674112.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US4674112.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US4674112.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (4),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (4),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (50),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (11),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/4674112&usg=AFQjCNGHYwNss8B2cu6mphsq-qHagvYdQg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D4674112&usg=AFQjCNH9algsVgbGwm1GXMeUvBgEI1kfJw">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D4674112A%26KC%3DA%26FT%3DD&usg=AFQjCNHTg70rqh5wxzvRNbzcWhXOBuGGiA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT53200716" lang="EN" load-source="patent-office">Character pattern recognition and communications apparatus</invention-title></span><br><span class="patent-number">US 4674112 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA36680727" lang="EN" load-source="patent-office"> <div class="abstract">A communication apparatus and method designed to interface with a standard, twelve key, dual tone, multiple frequency telephone, which allows easy, non-verbal entry of a message. Although particularly designed for use by the hearing and/or speech impaired with a dual tone telephone, the apparatus is equally adapted for use with practically any communication network where a keyboard with a limited number of keys is utilized and ambiguity resolution necessary. Generally speaking, the apparatus is connected to the earpiece of a receiving telephone and includes a tone pickup and decoder, a pre-programmed microcomputer and a message display panel. The message sender depresses a single key which corresponds to the alphabetic letter in the word being sent - because most keys on a telephone represent three letters, such a word is ambiguous when sent. The apparatus receives the ambiguous word and resolves the ambiguity in favor of a preprogrammed word which is displayed to the person receiving the message. Although the apparatus can be programmed to recognize words, the apparatus is programmed with a vocabulary of syllabic elements which are used to reconstruct the word. This approach enables an expanded word recognition capability while minimizing memory requirements.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(6)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4674112-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4674112-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4674112-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4674112-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4674112-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4674112-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4674112-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4674112-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4674112-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4674112-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4674112-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4674112-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(14)</span></span></div><div class="patent-text"><div mxw-id="PCLM4041320" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>We claim:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A communications apparatus comprising:<div class="claim-text">receiving means operably connectable to a telephone or the like for receiving a series of transmitted tones corresponding to an input word and for decoding the tones into a series of codes, each tone being representative of a letter of the word, which letter is one of two or more alphabetic characters corresponding to the tone;</div> <div class="claim-text">controller means coupled to said receiving means for processing said series of codes and outputting a signal indicative of a particular word which corresponds to said series of codes, said controller means including, recognition means for matching said series of codes with a programmed code sequence indicative of said particular word,</div> <div class="claim-text">said recognition means including a stored vocabulary comprising a plurality of syllabic elements, each being representative of one or more alphabetic characters, said recognition means being operable for matching said series of codes with one or more syllabic elements and outputting a signal indicative of a particular word represented by said one or more syllabic elements; and</div> <div class="claim-text">indicating means for receiving said signal and communicating the signal in a form perceptible to the user.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The apparatus according to claim 1, wherein said receiving means includes an inductive pickup couplable to the ear piece of a telephone receiver.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The apparatus according to claim 1, wherein said receiving means includes an amplifier section for receiving and amplifying said tones.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The apparatus according to claim 1, wherein said receiving means includes a tone-decoder for decoding the tones into a binary code.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The apparatus according to claim 1, wherein said indicating means includes a visual display for communicating said particular word.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The apparatus according to claim 5, wherein said indicating means comprises a liquid crystal display module.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The apparatus according to claim 1, wherein said receiving means is operable for receiving tones indicative of numeric characters, said controller means is operable for receiving and processing said numeric-representative tones and outputting a numeric-representative signal, and said indicating means being operable for displaying said numeric-representative signal.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The apparatus according to claim 1, said recognition means including mapping means operably coupled to said receiving means and operable for identifying the two or more alphabetic characters represented by a discrete tone.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The apparatus according to claim 8, said mapping means operable for utilizing said programmed code sequence and said identified two or more alphabetic characters for generating an ASCII code representative of each character of said particular word, said plurality of ASCII codes generated being output from said controller means as a portion of said signal.</div>
    </div>
    </div> <div class="claim"> <div num="10" class="claim">
      <div class="claim-text">10. A method of communicating, utilizing a signal-generating keyboard where at least some of the keys represent two or more alphabetic characters, comprising the steps of:<div class="claim-text">inputting a word into said keyboard by depressing a single key for each alphabetic character of said word;</div> <div class="claim-text">transmitting signals generated by the key depressions;</div> <div class="claim-text">receiving said transmitted signals and decoding the signals into binary code;</div> <div class="claim-text">matching said binary code with one or more pre-programmed codes, each pre-programmed code being representative of a syllabic element;</div> <div class="claim-text">Forming a representation of the word from the one or more syllabic elements represented by the matched one or more pre-programmed codes; and</div> <div class="claim-text">outputting the word representation in a form perceptible to the user.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The method of claim 10, wherein the outputting step includes displaying said word in a visually perceptible form.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The method of claim 10, wherein the signal generated by the keyboard is a dual tone multiple frequency and the keyboard comprises a touch-tone telephone.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The method according to claim 10, wherein each pre-programmed code of the syllabic elements corresponds to the key depressed and the position of the character of the syllabic element on that key including the steps of:<div class="claim-text">providing an ASCII mapping table presenting the</div> <div class="claim-text">ASSCII strings corresponding to respective alphabetic characters;</div> <div class="claim-text">identifying the ASCII string for each character of each matched syllabic element by<div class="claim-text">entering the mapping table with reference to the key depressed on the keyboard for each character of the matched one or more syllabic elements,</div> <div class="claim-text">cross-referencing the position of the character on said depressed key to determine the discrete ASCII string for the alphabetic character; and</div> </div> <div class="claim-text">outputting the ASCII string for each character of each syllabic element to an output buffer.</div> </div>
    </div>
    </div> <div class="claim"> <div num="14" class="claim">
      <div class="claim-text">14. A method of recognizing an input word from an input series of codes in which each input code represents one letter of the word which letter is one of two or more letters that the code corresponds with, comprising the steps of:<div class="claim-text">establishing a limited vocabulary of syllabic elements representing one or more letters and comprising one or more codes in a lookup table, in which said word is not represented by a single syllabic element in the lookup table,<div class="claim-text">the lookup table being separated into segments according to the number of letters of the syllabic elements;</div> </div> <div class="claim-text">matching the series of codes to two or more syllabic elements comprising the substeps of considering two or more successive codes of said word as a group,<div class="claim-text">entering the lookup table in the segment corresponding to the number of codes in said group,</div> <div class="claim-text">comparing said group of codes with the codes of each syllabic element in said segment until a match is found, or if no match is found, decrementing the number of codes in the group, entering the lookup table in another segment corresponding to the number of codes in said decremented group, and comparing the decremented group of codes with codes of each syllabic element in said another segment until a match is found, or if no match is found, successively decrementing the number of codes in the group and comparing the decremented group of codes with the codes of each syllabic element in another segment until a match is found, and</div> <div class="claim-text">considering the remaining unmatched codes in said word as one or more additional groups and repeating the entering and comparing steps using each additional group until all of the syllabic elements of the word are identified; and</div> </div> <div class="claim-text">outputting the two or more matched syllabic elements as said word.</div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES65593331" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>The present invention relates to an apparatus and method for communicating by manual entry on a keypad using a minimum of key stroke entries. More particularly, the invention relates to an apparatus and method for use by the hearing or speech impaired to communicate over the telephone network using a standard twelve key, dual tone, multi-frequency telephone.</p>
    <p>2. Description of the Prior Art</p>
    <p>For the hearing or speech impaired to effectively communicate over a long distance, several methods have been devised which enable nonverbal communication over a communications network, such as a telephone grid. Such devices include relatively expensive and nonportable radio teletype terminals and communications-adapted computer terminals. Such terminal keyboards typically employ a standard "QWERTY" keyboard which enables the passage of messages by simply typing in the entire message. Such terminals are, of course, deficient in that they are not only expensive, but also are bulky and difficult to transport.</p>
    <p>It has been recognized that it is desirable to use a standard 12 key, dual tone multiple frequency (DTMF or Touch-tone) telephone to communicate between the hearing or speech impaired. Utilizing such a standard "Touch-tone" telephone would be inexpensive and provide a partial solution to the problem of transporting bulky communication equipment. A primary difficulty with using such "Touch-tone" telephones is that the industry standard telephone keypad utilizes 12 keys. Ten of the keys represent a single numeric character, while 8 of the keys each represent 3 alphabetic characters.</p>
    <p>To utilize such a standard "Touch-tone" telephone for nonverbal communication, past solutions have used multiple keystroke entries to identify a particular alphabetic letter. For example, a first depression identifies which key the desired letter appears on and a second depression identifies which letter of the three possibilities is desired for input.</p>
    <p>The necessity for depressing two keys to identify one letter, is of course a major impedimate to effective telecommunication using a standard "Touch-tone" telephone. That is, even short messages require a large number of keystrokes to enter the message.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The problems outlined above are in large measure solved by the communications apparatus and chatacter pattern recognition method of the present invention. That is, the method and apparatus hereof provides for a single keystroke to identify which alphabetic character is desired. Because each keystroke can represent three possibilities, each keystroke transmitted--and therefore the composite word--is inherently ambiguous. The apparatus hereof receives the ambiguous word and reconstructs and displays the word based upon a preprogrammed ambiguity resolution. To simplify operation and memory size, the apparatus recognizes a particular word in terms of syllabic elements. The syllabic elements can comprise any number of alphabetic characters (for example, from 1 to 9 alphabetic characters).</p>
    <p>Generally speaking, the apparatus hereof includes a receiving mechanism coupled to a telephone which receives a series of transmitted tones corresponding to an inputted word. With a standard "Touch-tone" telephone, each tone received by the receiving mechanism represents three possible alphabetic characters. The receiving mechanism translates each tone into a code--a series of codes corresponding to a word. A controller receives the series of codes and outputs a signal indicative of a particular word which corresponds to the series of codes. The controller advantageously has a recognition means which matches the series of codes received with a programmed code sequence indicative of the particular word. Once the particular word is identified, a signal representative of the particular word is passed to an indicating means which displays the word to the receiving person.</p>
    <p>Preferably, the receiving mechanism amplifies the ambiguous tone and decodes the tone into binary code. The binary code is passed to the controller which is preferably a preprogrammed microcomputer. The microcomputer fetches the word or syllabic element vocabulary from memory and begins comparing the binary code with the vocabulary. The controller constructs a particular word corresponding to the received binary code and generates a signal to the indicating mechanism representative of that particular word.</p>
    <p>Preferably, the indicating means comprises a liquid crystal diode display which visually represents the word or message to the user. In another embodiment, a speech synthesizer audibly communicates the word or message to the user.</p>
    <p>The preferred communication method of the present invention contemplates inputting a word or series of words into a standard "Touch-tone" telephone keyboard by depressing a single key for each alphabetic character of the word. The characters are thus transmitted as a series of tones which are decoded by the apparatus hereof into a binary code. The binary code is matched with a preprogrammed vocabulary code representive of an alphabetic character string, such as a word or syllabic element. The word is then output to the receiving person. Although the preferred embodiment anticipates using the apparatus hereof as a receiving unit, it will be appreciated that the apparatus can be easily modified within the scope of the present invention to act as a transmission unit. For example, the apparatus can be modified to utilize a speech synthesizer, with the message sender inputting a word or a series of words into the telephone with the apparatus converting the input into an audible message.</p>
    <p>Another important alternative is to utilize the apparatus and method for other modes of communication. For example, the apparatus and method hereof can be incorporated into a paging system network, radio telephone network, or practically any communications network where ambiguity resolution is necessary because of limited keystroke inputs.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is a diagramatic view of a typical transmitting and receiving telephone to which the apparatus hereof is operably connected;</p>
    <p>FIG. 2 is a plan layout of a dual tone, multiple frequency, twelve key telephone keyboard;</p>
    <p>FIG. 3 is a block diagram of the system components of the apparatus hereof;</p>
    <p>FIG. 4 is a schematic representation of the look-up table and ASCII mapping table utilized by the present invention; and</p>
    <p>FIGS. 5-8 are flow-charts illustrative of the software utilized in the apparatus of the present invention, where-</p>
    <p>FIG. 5 is a flowchart of the main program for determining whether a numeric or alphabetic character is input,</p>
    <p>FIGS. 6 and 7 depict the alphabetic subroutine,</p>
    <p>FIG. 8 illustrates the numeric subroutine.</p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>Turning now to the drawings, a communications apparatus 10 is illustrated in FIG. 1 in conjunction with a telephone network having a sending telephone 12 and receiving telephone 14. Each telephone 12, 14 has a hand piece 16 and a twelve key "Touch-tone" key pad 18. Each telephone 12, 14 represents a common, industry standard touch tone system in which a key closure generates two tones according to the dual tone multiple frequency standard. As can be seen from FIG. 2, the standard industry key pad 18 presents twelve keys containing alphabetic and numeric characters, as well as the asterisk (*) and number ("#") characters. FIG. 2 differs slightly from the industry standard in that in a standard touch tone telephone, the alphabetic characters "Q" and "Z" are omitted. In FIG. 2, the letters "Q" and "Z" are carried by the key representative of numeral "1".</p>
    <p>Comparing FIGS. 1 and 3, the communications apparatus 10 is shown in more detail. Broadly speaking (see FIG. 1), the apparatus 10 includes receiving means 20, controller means 22, and indicating means 24. In more detail, the receiving means 20 includes an inductive pick-up 26 attachable to the ear portion of the hand piece 16 by a suction cup. In the preferred embodiment, a preamp 28 provides a fixed gain of 60 dB to the automatic gain control amplifier 30. The automatic gain control amplifier 30 has a gain range of 0.1-20 dB resulting in a total gain for the amplifier section (28,30) in the range of 30-100 dB. The output of the automatic gain control (1.5 volts p--p) is fed to a filter section 32 (AMI S3525A intergraded circuit) to separate the high and low dual tone multiple frequency bands. As shown in FIG. 6, the high and low group filter outputs are fed to a tone decoder 34 (e.g., Mostek MK-5102). The tone decoder 34 provides a four-bit binary code to the controller means 22 for each signal received at its input.</p>
    <p>The controller means 22 preferably incorporates a microcomputer (Intel 8051) with on-chip RAM and ROM. In FIG. 3, the controller means 22 is illustrated somewhat schematically and depicts the microcomputer 40, ROM 42 (preferably 8K byte EPROM) and 64 bytes8 RAM 44. Preferably, the programed vocabulary is stored on the ROM 42 with the RAM 44 used to store word codes as received, thus providing a buffer to the indicating means 24.</p>
    <p>Preferably, the indicating means 24 includes a liquid crystal diode (LCD) display 50 capable of displaying two rows of alpha numeric characters of twenty characters per row. A character generator 52 is coupled to the RAM 44 and the LCD display 50 to generate standard dot matrix characters on the display 50. The LCD display 50 also addresses the RAM 44 to periodically scan ASCII character data in the RAM 44.</p>
    <heading>Software</heading> <p>FIGS. 4-8 generally refer to the implementation of the recognition process employed by the controller means 22. FIG. 4 illustrates an example of a recognition search initiated in a segmented look-up table (left-hand portion of FIG. 4). The right-hand portion of FIG. 4 illustrates the ASCII mapping table where the ASCII code for the proper character is stored and fetched for each alpha numeric character. It should be apparent that use of the mapping table results in a considerable memory saving over the alternative of storing complete ASCII strings in memory. FIGS. 5-8 illustrate the flow-charts for the operating programs. The flow-charts are self explanatory. The operation of the lookup table and ASCII mapping table is readily apparent from a comparison of FIGS. 4 and 6-7.</p>
    <heading>Operation</heading> <p>The initial problem addressed by the present invention was to provide a simple method for the hearing or speech impaired to communicate using standard "Touch-tone" telephones without the need for complicated equipment, such as teletypes, etc. Several devices and methods have been devised which allow for effective communication, but are slow and difficult to use; a large number of keystrokes are involved in inputting a message. As can be seen from FIG. 2, most keys represent three alphabetic letters. Therefore, in the past, a single letter has been input using two keystrokes. For example, to input the alphabetic letter "H" in the word "HELP", the Operator would first push the number "4" key (row 2 column 1) followed by the "0" key (row 4, column 2) to designate the second character on the number "4" key.</p>
    <p>In a broad sense, the present invention recognizes the possibility of using a microprocessor-based device to enable a single keystroke per alphabetic letter. That is, it has been found that most English words are identified by the keystroke sequence required to enter the letters of the word--a character pattern recogniton. Of course, the invention is equally applicable to the identification of words in other languages as well.</p>
    <p>For example, to enter the word "HELP" the numbered keys "4, 3, 5, and 7" are depressed followed by a "*". The "*" key is used to delineate the end of a word. The term "word code" is used to denote the key sequence for a particular word; that is "4357" is the word code for the word "HELP." Of the 3<sup>4</sup> possibilities (3 characters on each key, four keys to enter the word), there is only one English word--"HELP"--from the 3<sup>4</sup> possibilities involved.</p>
    <p>Because each key on a standard "Touch-tone" keyboard presents three alphabetic characters per key, using the single keystroke entry contemplated by the present invention results in an inherently ambiguous key code. Thus, the dual tones for each key depression presents an ambiguous series of tones to the receiver. However, as with the word "HELP," it was found that over 96% of the most commonly used words could be identified by the word codes generated.</p>
    <p>Therefore, in a broad sense, the apparatus 10 could incorporate a stored vocabulary of word codes and the corresponding ASCII representation for each word in a memory look-up table. When a sequence of word codes is entered followed by an "*", a search could be initiated in memory which points to the correct ASCII characters to be displayed. In practice, storing complete word codes and ASCII representations in memory was found to limit word recognition capability to the stored word vocabulary, and even then, large memory size was necessary.</p>
    <p>In the preferred embodiment, "syllabic elements" are stored in memory and combined to create the words. For example, the "CON" letter group in contest, silicon, conference, contact, etc. is such a stored syllabic element. Thus, the vocabulary stored in the preferred embodiment includes common letter-groups, suffixes, prefixes, single letters, and a few complete words, genericly referred to as "syllabic elements." In the preferred embodiment, it was found most efficient to include several letter strings which provide and enhance word recognition capability; therefore the vocabulary of syllabic elements in the preferred embodiment includes elements having one alphabetic letter to as many as nine alphabetic letters. Most syllabic elements have a three to six letter group size.</p>
    <p>To further reduce memory size, the preferred embodiment enclosed incorporates an ASCII mapping table illustrated schematically in FIG. 4. That is, instead of allocating memory for the ASCII representation for each syllabic element, the ASCII representation is developed from the mapping table.</p>
    <p>In use, the receiving individual must attach the conductive pick-up 26 to the ear portion of the hand piece 16 (see FIG. 1). The sending individual simply enters the desired alphabetic letters of the desired message on the touch-tone telephone 12 sequentially. The asterisk key "*" is used as a space to separate words. The number key "#" is used before or after any information that should be interpretated as numeric information. Of course, the sender cannot use abbreviations. The apparatus 10 responds in real time, beginning the recognition process as soon as the space key is received. The text of the message is displayed on the LCD display 50 from the lower left position to the right. When the lower row is filled the entire row is scrolled upward to allow new text to appear in the lower row.</p>
    <p>As can be seen from FIG. 3, the series of tones constituting each word are decoded into a binary code. In the preferred embodiment each key depression represents a "key code" indicative of the key depressed. Two key codes are entered per byte, thus, the first byte contains the four bit binary code representation of the first two key codes of a word. The word code comprises a series of key codes entered between the asterisk "*," and in the preferred embodiment can occupy up to 7 bytes, accommodating word sizes up to fourteen characters. If the word has an odd number of characters, and therefore an odd number of key codes, the last key code is stored in the high order four bits of the last byte and the low order bits are set to zero.</p>
    <p>The microcomputer 40 (FIG. 3) reads the four bit binary code upon receiving a latch signal from the tone decoder 34. The program (FIGS. 5-8) and stored syllabic element vocabulary are fetched from ROM 42. The word recognition process is initiated as soon as an entire word code is received (as indicated by the asterisk input).</p>
    <p>Turning to FIG. 4, the recognition search is initiated in the segmented look-up table that contains the key codes in the four bit format for the syllabic element vocabulary. The look-up table is segmented according to syllabic element size with the size of the word to be decoded determining the point of entry into the look-up table. In the preferred embodiment, there are nine segments in the look-up table corresponding to syllabic elements ranging from one to nine characters in size. For words having more than nine characters, the search is initiated in the ninth segment and a new word code corresponding to the first nine keystrokes (key codes) of the word is formed (see also FIG. 6). Of course, the size of the syllabic element is known upon entry into a given segment, therefore the number of bytes required to store the key codes for each of the syllabic elements will also be known.</p>
    <p>Although the word code typically occupies more than one byte, only the first byte is checked for a match initially. The other bytes are checked only when a match occurs for all the previous bytes for the given syllabic element. If no match is detected, the search proceeds to the next syllabic element in the segment of the table. If no match is found in the segment of the table for the syllabic element size equal to the size of the word, the search is continued in the segment of the next lower size. That is, the word code is recomputed to exclude the last received key code for later use in the recognition process. This procedure is repeated until a match occurs. At the latest, a match will occur upon entering the single character segment of the look-up table.</p>
    <p>After the first syllabic element is identified, the search is repeated using a reduced word code. The reduced word code comprises the original word code less the first N characters, where N is the size of the first syllabic element identified. This cycle is repeated until the complete word is identified. Most words are identified by connected syllabic elements 2 to 4 characters in size. However, there are a limited number of large syllabic elements of 5 to 9 characters which are used to identify words that are difficult to separate into unambiguous short syllabic elements.</p>
    <p>Some syllabic elements have the same word code and therefore can have multiple interpretations. Such multiple meaning syllabic elements are specially flagged in the look-up table and stored in a way that the most frequently occurring interpretation is decoded first. If the element displayed on the LCD display 50 does not make sense to the reader, he can replace the string with the alternate interpretation by pressing a retry button (such as the operator or "O" key). Of course, in many cases the user can interpret such alternative interpretations from the context of the other syllabic elements forming the word or other words in the message.</p>
    <p>Although the display could be generated by storing a pointer to the proper ASCII string representing each syllabic element in the look-up table, the preferred embodiment utilizes an indirect referencing technique. As illustrated in FIG. 4, an ASCII mapping table is utilized to identify the proper ASCII string for the syllabic element recognized in the look-up table. The first input to the ASCII mapping table is the key code which is known and limits the possible choices for the alphabetic character to a maximum of three.</p>
    <p>The second pointer to the ASCII mapping table is generated to correspond with the position of the alphabetic character on the particular key depressed. To this end, a series of letter position mapping codes (LPMC) bytes are formulated for each word code. Each LPMC byte contains four 2-bit letter position codes (LPC). Each LPC can take the value of either 1, 2, or 3 depending upon the letter position on the key. As can be seen from FIG. 4, the binary representation of the letter position is used to enter the ASCII mapping table, 01 for the first letter positioning, 10 for the second letter positioning and 11 for the third letter positioning. Thus, the key code (KC) and letter position code (LPC) act as column and row pointers into the ASCII mapping table to find the proper ASCII code for the character. The ASCII code is fetched and moved to an output buffer. This method requires only 27 bytes of ASCII character storage as each possible character is stored only once, and an additional 8 bits per 4 characters to store the letter position codes (LPC).</p>
    <p>FIG. 4 illustrates the recognition process for the word "HELP". The word code, "4357" is passed to the four character segment of the look-up table. As previously discussed, the microcomputer 40 begins the search process until a match is formed. The matched word code points to a letter position mapping code (LPMC) byte. As illustrated in FIG. 4, the first letter position code (LPC) in the letter positioning mapping code (LPMC) byte has the binary code (10) for "2" which is the letter position of "H" on the number "4" key. The LPC is used as the column pointer in the ASCII mapping table with the key code used as the row pointer to identify the letter "H".</p>
    <p>In practice, the apparatus 10 recognizes the entered words as fast as the words can be entered by the sender. Thus, the apparatus 10 is real time, displaying the decoded word on the LCD display 50 less than 1 second after the asterisk key is depressed. A prime advantage of the method and apparatus 10 is that single character entry is sufficient for communication. This represents a significant advance as a communication aid for the handicapped.</p>
    <p>Of course, the apparatus 10 hereof is equally adaptable for use in many other situations. For example, with a paging system where space is limited, a small number of keys could be incorporated to efficiently send a message using the single character entry recognition of the present invention.</p>
    <p>Although the present invention contemplates that the sender will simply use a standard touch-tone telephone and the receiver will utilize the apparatus 10, roles could be reversed. The apparatus 10 can be used as a sending device which incorporates a speech synthesizer. That is, the sender would couple the device 10 to the mouth section of hand piece 16 of the sending telephone 12 and generate the message on the key pad 18. Apparatus 10 would generate synthetic speech audibly conveyed to the receiving telephone 14.</p>
    <p>Still another alternative would be to use the apparatus 10 of the present invention for remote computer control by non-handicapped individuals. For example, using the single character entry, words like PRINT, LIST, SAVE could be easily recognized and the output controlled. If fact, better results and an expanded vocabulary can be obtained if the characters on the standard telephone key pad 18 are distributed differently. That is, the sender could use an overlay with optimum character distribution to send his message. While this approach may be feasible for remote computer use, simplicity considerations for the handicapped dictate using the standard key pad 18 with suboptimum character distribution.</p>
    <p>The apparatus 10 could also be used for consumers to enter orders to a vendor's computer. Many variations exist; the apparatus 10 enabling the entry of messages easily into a computer or practically any message receiver.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4307266">US4307266</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 11, 1980</td><td class="patent-data-table-td patent-date-value">Dec 22, 1981</td><td class="patent-data-table-td ">Messina John D</td><td class="patent-data-table-td ">Communication apparatus for the handicapped</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4578540">US4578540</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 20, 1982</td><td class="patent-data-table-td patent-date-value">Mar 25, 1986</td><td class="patent-data-table-td ">At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Telecommunications systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4608460">US4608460</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 17, 1984</td><td class="patent-data-table-td patent-date-value">Aug 26, 1986</td><td class="patent-data-table-td ">Itt Corporation</td><td class="patent-data-table-td ">Comprehensive automatic directory assistance apparatus and method thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4633041">US4633041</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 9, 1984</td><td class="patent-data-table-td patent-date-value">Dec 30, 1986</td><td class="patent-data-table-td ">At&amp;T Information Systems Inc.</td><td class="patent-data-table-td ">Station set directory assistance arrangement</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Rabiner et al., "<a href='http://scholar.google.com/scholar?q="Digital+Techniques+for+Computer+Voice+Response%3A+Implementations+and+Applications"'>Digital Techniques for Computer Voice Response: Implementations and Applications</a>", Proceedings of the IEEE, vol. 64, No. 4, Apr. 1976, pp. 416-433.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Rabiner et al., Digital Techniques for Computer Voice Response: Implementations and Applications , Proceedings of the IEEE, vol. 64, No. 4, Apr. 1976, pp. 416 433.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Smith et al., "<a href='http://scholar.google.com/scholar?q="Alphabetic+Data+Entry+Via+the+Touch-Tone+Pad%3A+A+Comment"'>Alphabetic Data Entry Via the Touch-Tone Pad: A Comment</a>", Human Factors, vol. 13(2), Apr. 1971, pp. 189-190.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Smith et al., Alphabetic Data Entry Via the Touch Tone Pad: A Comment , Human Factors, vol. 13(2), Apr. 1971, pp. 189 190.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4737980">US4737980</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 19, 1985</td><td class="patent-data-table-td patent-date-value">Apr 12, 1988</td><td class="patent-data-table-td ">Amtelco</td><td class="patent-data-table-td ">Computer data entry method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4754474">US4754474</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 21, 1985</td><td class="patent-data-table-td patent-date-value">Jun 28, 1988</td><td class="patent-data-table-td ">Feinson Roy W</td><td class="patent-data-table-td ">Interpretive tone telecommunication method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4817129">US4817129</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 5, 1987</td><td class="patent-data-table-td patent-date-value">Mar 28, 1989</td><td class="patent-data-table-td ">Telac Corp.</td><td class="patent-data-table-td ">Method of and means for accessing computerized data bases utilizing a touch-tone telephone instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5210689">US5210689</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 28, 1990</td><td class="patent-data-table-td patent-date-value">May 11, 1993</td><td class="patent-data-table-td ">Semantic Compaction Systems</td><td class="patent-data-table-td ">System and method for automatically selecting among a plurality of input modes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5285493">US5285493</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 25, 1991</td><td class="patent-data-table-td patent-date-value">Feb 8, 1994</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Radio tele-communication device with received message displaying feature</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5521960">US5521960</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 3, 1994</td><td class="patent-data-table-td patent-date-value">May 28, 1996</td><td class="patent-data-table-td ">Aronow; Alan H.</td><td class="patent-data-table-td ">Interactive telephonic device for `VCO` relay communication</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5521986">US5521986</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 30, 1994</td><td class="patent-data-table-td patent-date-value">May 28, 1996</td><td class="patent-data-table-td ">American Tel-A-Systems, Inc.</td><td class="patent-data-table-td ">Compact data input device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5548634">US5548634</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 5, 1994</td><td class="patent-data-table-td patent-date-value">Aug 20, 1996</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Alphanumeric registration method and device of a system with alphanumeric entry keys</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5592538">US5592538</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 10, 1993</td><td class="patent-data-table-td patent-date-value">Jan 7, 1997</td><td class="patent-data-table-td ">Momentum, Inc.</td><td class="patent-data-table-td ">Telecommunication device and method for interactive voice and data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5619563">US5619563</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 19, 1994</td><td class="patent-data-table-td patent-date-value">Apr 8, 1997</td><td class="patent-data-table-td ">Lucent Technologies Inc.</td><td class="patent-data-table-td ">Mnemonic number dialing plan</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5818437">US5818437</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 26, 1995</td><td class="patent-data-table-td patent-date-value">Oct 6, 1998</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Reduced keyboard disambiguating computer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5828991">US5828991</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 30, 1995</td><td class="patent-data-table-td patent-date-value">Oct 27, 1998</td><td class="patent-data-table-td ">The Research Foundation Of The State University Of New York</td><td class="patent-data-table-td ">Sentence reconstruction using word ambiguity resolution</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5872837">US5872837</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 27, 1996</td><td class="patent-data-table-td patent-date-value">Feb 16, 1999</td><td class="patent-data-table-td ">Mci Worldcom, Inc.</td><td class="patent-data-table-td ">System and method for transmitting data and commands using a telephone</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5950123">US5950123</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 26, 1996</td><td class="patent-data-table-td patent-date-value">Sep 7, 1999</td><td class="patent-data-table-td ">Telefonaktiebolaget L M</td><td class="patent-data-table-td ">Cellular telephone network support of audible information delivery to visually impaired subscribers</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5953541">US5953541</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 24, 1997</td><td class="patent-data-table-td patent-date-value">Sep 14, 1999</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Disambiguating system for disambiguating ambiguous input sequences by displaying objects associated with the generated input sequences in the order of decreasing frequency of use</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6009444">US6009444</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 24, 1997</td><td class="patent-data-table-td patent-date-value">Dec 28, 1999</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Text input device and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6011554">US6011554</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 26, 1996</td><td class="patent-data-table-td patent-date-value">Jan 4, 2000</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Reduced keyboard disambiguating system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6182040">US6182040</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 21, 1998</td><td class="patent-data-table-td patent-date-value">Jan 30, 2001</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Voice-synthesizer responsive to panel display message</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6307549">US6307549</a></td><td class="patent-data-table-td patent-date-value">Oct 18, 1999</td><td class="patent-data-table-td patent-date-value">Oct 23, 2001</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Reduced keyboard disambiguating system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6375467">US6375467</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 22, 2001</td><td class="patent-data-table-td patent-date-value">Apr 23, 2002</td><td class="patent-data-table-td ">Sonia Grant</td><td class="patent-data-table-td ">Sound comprehending and recognizing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6556841">US6556841</a></td><td class="patent-data-table-td patent-date-value">May 3, 1999</td><td class="patent-data-table-td patent-date-value">Apr 29, 2003</td><td class="patent-data-table-td ">Openwave Systems Inc.</td><td class="patent-data-table-td ">Spelling correction for two-way mobile communication devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6625600">US6625600</a></td><td class="patent-data-table-td patent-date-value">May 1, 2001</td><td class="patent-data-table-td patent-date-value">Sep 23, 2003</td><td class="patent-data-table-td ">Telelogue, Inc.</td><td class="patent-data-table-td ">Method and apparatus for automatically processing a user&#39;s communication</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6636162">US6636162</a></td><td class="patent-data-table-td patent-date-value">May 23, 2000</td><td class="patent-data-table-td patent-date-value">Oct 21, 2003</td><td class="patent-data-table-td ">America Online, Incorporated</td><td class="patent-data-table-td ">Reduced keyboard text input system for the Japanese language</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6646573">US6646573</a></td><td class="patent-data-table-td patent-date-value">Dec 3, 1999</td><td class="patent-data-table-td patent-date-value">Nov 11, 2003</td><td class="patent-data-table-td ">America Online, Inc.</td><td class="patent-data-table-td ">Reduced keyboard text input system for the Japanese language</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6799303">US6799303</a></td><td class="patent-data-table-td patent-date-value">Jul 26, 2001</td><td class="patent-data-table-td patent-date-value">Sep 28, 2004</td><td class="patent-data-table-td ">Marvin R. Blumberg</td><td class="patent-data-table-td ">Speed typing apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6885317">US6885317</a></td><td class="patent-data-table-td patent-date-value">Dec 9, 1999</td><td class="patent-data-table-td patent-date-value">Apr 26, 2005</td><td class="patent-data-table-td ">Eatoni Ergonomics, Inc.</td><td class="patent-data-table-td ">Touch-typable devices based on ambiguous codes and methods to design such devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7257528">US7257528</a></td><td class="patent-data-table-td patent-date-value">Feb 13, 1998</td><td class="patent-data-table-td patent-date-value">Aug 14, 2007</td><td class="patent-data-table-td ">Zi Corporation Of Canada, Inc.</td><td class="patent-data-table-td ">Method and apparatus for Chinese character text input</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7519748">US7519748</a></td><td class="patent-data-table-td patent-date-value">Jun 16, 2005</td><td class="patent-data-table-td patent-date-value">Apr 14, 2009</td><td class="patent-data-table-td ">Microth, Inc.</td><td class="patent-data-table-td ">Stroke-based data entry device, system, and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7679534">US7679534</a></td><td class="patent-data-table-td patent-date-value">Jun 10, 2004</td><td class="patent-data-table-td patent-date-value">Mar 16, 2010</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Contextual prediction of user words and user actions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7712053">US7712053</a></td><td class="patent-data-table-td patent-date-value">Jun 20, 2002</td><td class="patent-data-table-td patent-date-value">May 4, 2010</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Explicit character filtering of ambiguous text entry</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7720682">US7720682</a></td><td class="patent-data-table-td patent-date-value">Feb 7, 2006</td><td class="patent-data-table-td patent-date-value">May 18, 2010</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Method and apparatus utilizing voice input to resolve ambiguous manually entered text input</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7761175">US7761175</a></td><td class="patent-data-table-td patent-date-value">Sep 27, 2001</td><td class="patent-data-table-td patent-date-value">Jul 20, 2010</td><td class="patent-data-table-td ">Eatoni Ergonomics, Inc.</td><td class="patent-data-table-td ">Method and apparatus for discoverable input of symbols on a reduced keypad</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7769592">US7769592</a></td><td class="patent-data-table-td patent-date-value">Feb 22, 2002</td><td class="patent-data-table-td patent-date-value">Aug 3, 2010</td><td class="patent-data-table-td ">Nuance Communications, Inc.</td><td class="patent-data-table-td ">Automatic selection of a disambiguation data field for a speech interface</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7800587">US7800587</a></td><td class="patent-data-table-td patent-date-value">Aug 11, 2005</td><td class="patent-data-table-td patent-date-value">Sep 21, 2010</td><td class="patent-data-table-td ">Tip Communications, Llc</td><td class="patent-data-table-td ">Touch-type key input apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7881936">US7881936</a></td><td class="patent-data-table-td patent-date-value">Jun 1, 2005</td><td class="patent-data-table-td patent-date-value">Feb 1, 2011</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Multimodal disambiguation of speech recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7979425">US7979425</a></td><td class="patent-data-table-td patent-date-value">Oct 25, 2006</td><td class="patent-data-table-td patent-date-value">Jul 12, 2011</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Server-side match</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8200865">US8200865</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 2003</td><td class="patent-data-table-td patent-date-value">Jun 12, 2012</td><td class="patent-data-table-td ">Eatoni Ergonomics, Inc.</td><td class="patent-data-table-td ">Efficient method and apparatus for text entry based on trigger sequences</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8381137">US8381137</a></td><td class="patent-data-table-td patent-date-value">Mar 16, 2010</td><td class="patent-data-table-td patent-date-value">Feb 19, 2013</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Explicit character filtering of ambiguous text entry</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8392453">US8392453</a></td><td class="patent-data-table-td patent-date-value">Jun 25, 2004</td><td class="patent-data-table-td patent-date-value">Mar 5, 2013</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Nonstandard text entry</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8583440">US8583440</a></td><td class="patent-data-table-td patent-date-value">Aug 26, 2005</td><td class="patent-data-table-td patent-date-value">Nov 12, 2013</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Apparatus and method for providing visual indication of character ambiguity during text entry</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8606582">US8606582</a></td><td class="patent-data-table-td patent-date-value">Oct 12, 2012</td><td class="patent-data-table-td patent-date-value">Dec 10, 2013</td><td class="patent-data-table-td ">Tegic Communications, Inc.</td><td class="patent-data-table-td ">Multimodal disambiguation of speech recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8620826">US8620826</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 2008</td><td class="patent-data-table-td patent-date-value">Dec 31, 2013</td><td class="patent-data-table-td ">Amazon Technologies, Inc.</td><td class="patent-data-table-td ">System and method for receiving requests for tasks from unregistered devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8706747">US8706747</a></td><td class="patent-data-table-td patent-date-value">Sep 30, 2003</td><td class="patent-data-table-td patent-date-value">Apr 22, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Systems and methods for searching using queries written in a different character-set and/or language from the target pages</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8782568">US8782568</a></td><td class="patent-data-table-td patent-date-value">Jan 23, 2013</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Nuance Communications, Inc.</td><td class="patent-data-table-td ">Explicit character filtering of ambiguous text entry</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE43082">USRE43082</a></td><td class="patent-data-table-td patent-date-value">Dec 9, 1999</td><td class="patent-data-table-td patent-date-value">Jan 10, 2012</td><td class="patent-data-table-td ">Eatoni Ergonomics, Inc.</td><td class="patent-data-table-td ">Touch-typable devices based on ambiguous codes and methods to design such devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1106746C?cl=en">CN1106746C</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 18, 1995</td><td class="patent-data-table-td patent-date-value">Apr 23, 2003</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Mnemonic number dialing plan</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0319193A2?cl=en">EP0319193A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 23, 1988</td><td class="patent-data-table-td patent-date-value">Jun 7, 1989</td><td class="patent-data-table-td ">Bernard N. Riskin</td><td class="patent-data-table-td ">Method and apparatus for identifying words entered on DTMF pushbuttons</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1992012491A1?cl=en">WO1992012491A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 27, 1991</td><td class="patent-data-table-td patent-date-value">Jul 23, 1992</td><td class="patent-data-table-td ">Semantic Compaction Sys</td><td class="patent-data-table-td ">System and method for automatically selecting among a plurality of input modes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1994021077A1?cl=en">WO1994021077A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 9, 1994</td><td class="patent-data-table-td patent-date-value">Sep 15, 1994</td><td class="patent-data-table-td ">Momentum Inc</td><td class="patent-data-table-td ">Telecommunication device and method for interactive voice and data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2001069895A1?cl=en">WO2001069895A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 12, 2001</td><td class="patent-data-table-td patent-date-value">Sep 20, 2001</td><td class="patent-data-table-td ">Giuseppe Baldino</td><td class="patent-data-table-td ">Telephonic device for deaf-mutes</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc379/defs379.htm&usg=AFQjCNEr2i5HiMlkBIt1vZADj0MjdHVCTw#C379S093180">379/93.18</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc379/defs379.htm&usg=AFQjCNEr2i5HiMlkBIt1vZADj0MjdHVCTw#C379S093370">379/93.37</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc379/defs379.htm&usg=AFQjCNEr2i5HiMlkBIt1vZADj0MjdHVCTw#C379S052000">379/52</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc379/defs379.htm&usg=AFQjCNEr2i5HiMlkBIt1vZADj0MjdHVCTw#C379S906000">379/906</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09B0021000000">G09B21/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04M0011060000">H04M11/06</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=Y10S379/906">Y10S379/906</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M11/066">H04M11/066</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7r4lBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G09B21/00">G09B21/00</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G09B21/00</span>, <span class="nested-value">H04M11/06D</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20050930</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 7, 1998</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 28, 1994</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 29, 1990</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 9, 1986</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">BOARD OF REGENTS, THE UNIVERSITY OF TEXAS SYSTEM,</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST.;ASSIGNORS:KONDRASKE, GEORGE V.;SHENNIB, ADNAN;REEL/FRAME:004512/0901;SIGNING DATES FROM 19851118 TO 19851220</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U2J6jy4YdJ4ky3al0gbSf5bzqPExA\u0026id=7r4lBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3J6Pl4IaA3ROg-TPfqyMRXMOB5yA\u0026id=7r4lBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U21wIvzCgXh_ocmXMZeS22kzfin5g","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Character_pattern_recognition_and_commun.pdf?id=7r4lBAABERAJ\u0026output=pdf\u0026sig=ACfU3U1Rku_cVjQDwF1dOF49s490cEPvxQ"},"sample_url":"http://www.google.com/patents/reader?id=7r4lBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>