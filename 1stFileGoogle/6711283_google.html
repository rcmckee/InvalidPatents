<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6711283 - Fully automatic rapid microscope slide scanner - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Fully automatic rapid microscope slide scanner"><meta name="DC.contributor" content="Dirk G. Soenksen" scheme="inventor"><meta name="DC.contributor" content="Aperio Technologies, Inc." scheme="assignee"><meta name="DC.date" content="2000-5-3" scheme="dateSubmitted"><meta name="DC.description" content="Apparatus for and method of fully automatic rapid scanning and digitizing of an entire microscope sample, or a substantially large portion of a microscope sample, using a linear array detector synchronized with a positioning stage that is part of a computer controlled microscope slide scanner. The invention provides a method for composing the image strips obtained from successive scans of the sample into a single contiguous digital image. The invention also provides a method for statically displaying sub-regions of this large digital image at different magnifications, together with a reduced magnification macro-image of the entire sample. The invention further provides a method for dynamically displaying, with or without operator interaction, portions of the contiguous digital image. In one preferred embodiment of the invention, all elements of the scanner are part of a single-enclosure that has a primary connection to the Internet or to a local intranet. In this embodiment, the preferred sample type is a microscope slide and the illumination and imaging optics are consistent with transmission mode optics optimized for diffraction-limited digital imaging."><meta name="DC.date" content="2004-3-23" scheme="issued"><meta name="DC.relation" content="EP:0339582:A2" scheme="references"><meta name="DC.relation" content="EP:0871052:A1" scheme="references"><meta name="DC.relation" content="US:3643015" scheme="references"><meta name="DC.relation" content="US:4673988" scheme="references"><meta name="DC.relation" content="US:4700298" scheme="references"><meta name="DC.relation" content="US:4744642" scheme="references"><meta name="DC.relation" content="US:4760385" scheme="references"><meta name="DC.relation" content="US:4777525" scheme="references"><meta name="DC.relation" content="US:4845552" scheme="references"><meta name="DC.relation" content="US:4960999" scheme="references"><meta name="DC.relation" content="US:5086477" scheme="references"><meta name="DC.relation" content="US:5495535" scheme="references"><meta name="DC.relation" content="US:5578832" scheme="references"><meta name="DC.relation" content="US:5644356" scheme="references"><meta name="DC.relation" content="US:5672861" scheme="references"><meta name="DC.relation" content="US:5710835" scheme="references"><meta name="DC.relation" content="US:5714756" scheme="references"><meta name="DC.relation" content="US:5793969" scheme="references"><meta name="DC.relation" content="US:5834758" scheme="references"><meta name="DC.relation" content="US:5872591" scheme="references"><meta name="DC.relation" content="US:5912699" scheme="references"><meta name="DC.relation" content="US:5922282" scheme="references"><meta name="DC.relation" content="US:5943122" scheme="references"><meta name="DC.relation" content="US:5963314" scheme="references"><meta name="DC.relation" content="US:5991444" scheme="references"><meta name="DC.relation" content="US:5999662" scheme="references"><meta name="DC.relation" content="US:6002789" scheme="references"><meta name="DC.relation" content="US:6005964" scheme="references"><meta name="DC.relation" content="US:6049421" scheme="references"><meta name="DC.relation" content="US:6272235" scheme="references"><meta name="DC.relation" content="WO:1998039728:A1" scheme="references"><meta name="DC.relation" content="WO:1998044446:A1" scheme="references"><meta name="citation_patent_number" content="US:6711283"><meta name="citation_patent_application_number" content="US:09/563,437"><link rel="canonical" href="http://www.google.com/patents/US6711283"/><meta property="og:url" content="http://www.google.com/patents/US6711283"/><meta name="title" content="Patent US6711283 - Fully automatic rapid microscope slide scanner"/><meta name="description" content="Apparatus for and method of fully automatic rapid scanning and digitizing of an entire microscope sample, or a substantially large portion of a microscope sample, using a linear array detector synchronized with a positioning stage that is part of a computer controlled microscope slide scanner. The invention provides a method for composing the image strips obtained from successive scans of the sample into a single contiguous digital image. The invention also provides a method for statically displaying sub-regions of this large digital image at different magnifications, together with a reduced magnification macro-image of the entire sample. The invention further provides a method for dynamically displaying, with or without operator interaction, portions of the contiguous digital image. In one preferred embodiment of the invention, all elements of the scanner are part of a single-enclosure that has a primary connection to the Internet or to a local intranet. In this embodiment, the preferred sample type is a microscope slide and the illumination and imaging optics are consistent with transmission mode optics optimized for diffraction-limited digital imaging."/><meta property="og:title" content="Patent US6711283 - Fully automatic rapid microscope slide scanner"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("BYrtU_uGGs6_sQSE0oC4Dg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("FRA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("BYrtU_uGGs6_sQSE0oC4Dg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("FRA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6711283?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6711283"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=oXNlBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6711283&amp;usg=AFQjCNF1Sf0xDR4JOeI-kA4ItVvWtD5UbA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6711283.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6711283.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6711283" style="display:none"><span itemprop="description">Apparatus for and method of fully automatic rapid scanning and digitizing of an entire microscope sample, or a substantially large portion of a microscope sample, using a linear array detector synchronized with a positioning stage that is part of a computer controlled microscope slide scanner. The invention...</span><span itemprop="url">http://www.google.com/patents/US6711283?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6711283 - Fully automatic rapid microscope slide scanner</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6711283 - Fully automatic rapid microscope slide scanner" title="Patent US6711283 - Fully automatic rapid microscope slide scanner"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6711283 B1</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/563,437</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Mar 23, 2004</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">May 3, 2000</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">May 3, 2000</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/DE60135562D1">DE60135562D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1317685A2">EP1317685A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1317685B1">EP1317685B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1990667A1">EP1990667A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2282230A2">EP2282230A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2282230A3">EP2282230A3</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6917696">US6917696</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7035478">US7035478</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7428324">US7428324</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7457446">US7457446</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7646495">US7646495</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7826649">US7826649</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7949168">US7949168</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7978894">US7978894</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8055042">US8055042</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8094902">US8094902</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8385619">US8385619</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8731260">US8731260</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8755579">US8755579</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20040170312">US20040170312</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20040252875">US20040252875</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20050270638">US20050270638</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070036462">US20070036462</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20090028414">US20090028414</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20090141126">US20090141126</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20090303321">US20090303321</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20110037847">US20110037847</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20110044518">US20110044518</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20110221882">US20110221882</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120075457">US20120075457</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120113242">US20120113242</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130162802">US20130162802</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2001084209A2">WO2001084209A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2001084209A3">WO2001084209A3</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2001084209B1">WO2001084209B1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09563437, </span><span class="patent-bibdata-value">563437, </span><span class="patent-bibdata-value">US 6711283 B1, </span><span class="patent-bibdata-value">US 6711283B1, </span><span class="patent-bibdata-value">US-B1-6711283, </span><span class="patent-bibdata-value">US6711283 B1, </span><span class="patent-bibdata-value">US6711283B1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Dirk+G.+Soenksen%22">Dirk G. Soenksen</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Aperio+Technologies,+Inc.%22">Aperio Technologies, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6711283.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6711283.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6711283.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (32),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (149),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (22),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (9)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6711283&usg=AFQjCNH7t1Aa91ahDsXnGdmlilli1zLrwg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6711283&usg=AFQjCNFxxHZ91o0O7402ph6RoBoI4wJAQA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6711283B1%26KC%3DB1%26FT%3DD&usg=AFQjCNHJQhG8cspNc2Edow6hPelmr_aSiw">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55238458" lang="EN" load-source="patent-office">Fully automatic rapid microscope slide scanner</invention-title></span><br><span class="patent-number">US 6711283 B1</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50639647" lang="EN" load-source="patent-office"> <div class="abstract">Apparatus for and method of fully automatic rapid scanning and digitizing of an entire microscope sample, or a substantially large portion of a microscope sample, using a linear array detector synchronized with a positioning stage that is part of a computer controlled microscope slide scanner. The invention provides a method for composing the image strips obtained from successive scans of the sample into a single contiguous digital image. The invention also provides a method for statically displaying sub-regions of this large digital image at different magnifications, together with a reduced magnification macro-image of the entire sample. The invention further provides a method for dynamically displaying, with or without operator interaction, portions of the contiguous digital image. In one preferred embodiment of the invention, all elements of the scanner are part of a single-enclosure that has a primary connection to the Internet or to a local intranet. In this embodiment, the preferred sample type is a microscope slide and the illumination and imaging optics are consistent with transmission mode optics optimized for diffraction-limited digital imaging.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(7)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6711283B1/US06711283-20040323-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6711283B1/US06711283-20040323-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6711283B1/US06711283-20040323-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6711283B1/US06711283-20040323-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6711283B1/US06711283-20040323-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6711283B1/US06711283-20040323-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6711283B1/US06711283-20040323-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6711283B1/US06711283-20040323-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6711283B1/US06711283-20040323-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6711283B1/US06711283-20040323-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6711283B1/US06711283-20040323-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6711283B1/US06711283-20040323-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6711283B1/US06711283-20040323-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6711283B1/US06711283-20040323-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(19)</span></span></div><div class="patent-text"><div mxw-id="PCLM8643203" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is: </claim-statement> <div class="claim"> <div num="1" id="US-6711283-B1-CLM-00001" class="claim">
      <div class="claim-text">1. A system for creating a contiguous digital image of a portion of a microscope sample, comprising:</div>
      <div class="claim-text">a motorized stage configured to support a microscope sample and move the microscope sample at a substantially constant velocity; </div>
      <div class="claim-text">an illumination system configured to illuminate a portion of the microscope sample; </div>
      <div class="claim-text">an objective lens positioned for viewing the illuminated portion of the microscope sample; </div>
      <div class="claim-text">a focus map having a plurality of focus points on the microscope sample; </div>
      <div class="claim-text">a line scan camera optically coupled with the objective lens, the line scan camera configured to create a digital image strip of a portion of the microscope sample, the digital image strip captured while the microscope sample is moving at substantially constant velocity; </div>
      <div class="claim-text">a focusing system configured to focus the line scan camera during creation of each digital image strip in accordance with the focus map; </div>
      <div class="claim-text">an image composer configured to align adjacent digital image strips into a contiguous digital image of a portion of the microscope sample; and </div>
      <div class="claim-text">a data storage area configured to store the contiguous digital image. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6711283-B1-CLM-00002" class="claim">
      <div class="claim-text">2. The system of <claim-ref idref="US-6711283-B1-CLM-00001">claim 1</claim-ref>, wherein the motorized stage further comprises:</div>
      <div class="claim-text">a first motor configured to move the microscope sample in a first direction in the sample plane; and </div>
      <div class="claim-text">a second motor configured to move the microscope sample in a second direction in the sample plane, wherein the second direction is orthogonal to the first direction. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6711283-B1-CLM-00003" class="claim">
      <div class="claim-text">3. The system of <claim-ref idref="US-6711283-B1-CLM-00002">claim 2</claim-ref>, wherein the first motor is a servo motor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6711283-B1-CLM-00004" class="claim">
      <div class="claim-text">4. The system of <claim-ref idref="US-6711283-B1-CLM-00001">claim 1</claim-ref>, wherein the illuminated portion of the microscope sample comprises a linear field of view.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6711283-B1-CLM-00005" class="claim">
      <div class="claim-text">5. The system of <claim-ref idref="US-6711283-B1-CLM-00004">claim 4</claim-ref>, wherein the illumination system is optimized to uniformly illuminate the linear field of view.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6711283-B1-CLM-00006" class="claim">
      <div class="claim-text">6. The system of <claim-ref idref="US-6711283-B1-CLM-00001">claim 1</claim-ref>, wherein the focus map is non-planar.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" id="US-6711283-B1-CLM-00007" class="claim">
      <div class="claim-text">7. The system of <claim-ref idref="US-6711283-B1-CLM-00001">claim 1</claim-ref>, wherein the line scan camera is configured to capture red, green and blue color signals through discrete linear array sensors, wherein each linear array sensor is configured to capture 8 bits of data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" id="US-6711283-B1-CLM-00008" class="claim">
      <div class="claim-text">8. The system of <claim-ref idref="US-6711283-B1-CLM-00001">claim 1</claim-ref>, wherein the focusing system comprises a piezo positioner that is communicatively coupled to a piezo controller.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" id="US-6711283-B1-CLM-00009" class="claim">
      <div class="claim-text">9. The system of <claim-ref idref="US-6711283-B1-CLM-00008">claim 8</claim-ref>, wherein the piezo controller and the piezo positioner are configured to adjust the focus of the line scan camera at least 10 times per second.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" id="US-6711283-B1-CLM-00010" class="claim">
      <div class="claim-text">10. The system of <claim-ref idref="US-6711283-B1-CLM-00001">claim 1</claim-ref>, wherein the contiguous digital image is a diffraction-limited contiguous digital image.</div>
    </div>
    </div> <div class="claim"> <div num="11" id="US-6711283-B1-CLM-00011" class="claim">
      <div class="claim-text">11. A method for creating a contiguous digital image of a portion of a microscope sample, comprising:</div>
      <div class="claim-text">focusing a line scan camera on a plurality of focus points within a microscope sample; </div>
      <div class="claim-text">creating a focus map comprising the plurality of focus points; </div>
      <div class="claim-text">moving a microscope sample at substantially constant velocity relative to the line scan camera having a linear field of view, wherein a first strip of the microscope sample is exposed to the field of view of the line scan camera during said motion; </div>
      <div class="claim-text">illuminating a portion of the first strip while the microscope sample is in motion; </div>
      <div class="claim-text">scanning the first strip with the line scan camera while the sample is in motion; </div>
      <div class="claim-text">adjusting the focus of the line scan camera during said scanning in accordance with the focus map; </div>
      <div class="claim-text">storing a digital image of the first strip; </div>
      <div class="claim-text">moving a microscope sample at substantially constant velocity relative to the line scan camera, wherein a substantially unscanned second strip of the microscope sample is exposed to the field of view of the line scan camera during said motion; </div>
      <div class="claim-text">illuminating a portion of the second strip while the microscope sample is in motion; </div>
      <div class="claim-text">scanning the second strip with the line scan camera while the sample is in motion; </div>
      <div class="claim-text">adjusting the focus of the line scan camera during said scanning; </div>
      <div class="claim-text">storing a digital image of the second strip; and </div>
      <div class="claim-text">composing the digital image of the first strip and the digital image of the second strip into a contiguous digital image. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" id="US-6711283-B1-CLM-00012" class="claim">
      <div class="claim-text">12. The method of <claim-ref idref="US-6711283-B1-CLM-00011">claim 11</claim-ref>, wherein the focus map is non-planar.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" id="US-6711283-B1-CLM-00013" class="claim">
      <div class="claim-text">13. The method of <claim-ref idref="US-6711283-B1-CLM-00011">claim 11</claim-ref>, wherein each moving step is carried out by a servo motor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" id="US-6711283-B1-CLM-00014" class="claim">
      <div class="claim-text">14. The method of <claim-ref idref="US-6711283-B1-CLM-00011">claim 11</claim-ref>, wherein each adjusting step is carried out by a piezo positioner communicatively coupled with a piezo controller.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" id="US-6711283-B1-CLM-00015" class="claim">
      <div class="claim-text">15. The method of <claim-ref idref="US-6711283-B1-CLM-00011">claim 11</claim-ref>, wherein the digital image of the first strip has a first length and a first width and the digital image of the second strip has a second length and a second width, and wherein the first length and the second length are not equal.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" id="US-6711283-B1-CLM-00016" class="claim">
      <div class="claim-text">16. The method of <claim-ref idref="US-6711283-B1-CLM-00015">claim 15</claim-ref>, wherein the first width and the second width are equal.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" id="US-6711283-B1-CLM-00017" class="claim">
      <div class="claim-text">17. The method of <claim-ref idref="US-6711283-B1-CLM-00015">claim 15</claim-ref>, wherein the first width and the second width are not equal.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" id="US-6711283-B1-CLM-00018" class="claim">
      <div class="claim-text">18. The method of <claim-ref idref="US-6711283-B1-CLM-00011">claim 11</claim-ref>, wherein the first strip comprises a first perimeter edge of the sample and an opposing perimeter edge of the sample, wherein the first edge and the opposing edge are separated by at least 2 micrometers.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" id="US-6711283-B1-CLM-00019" class="claim">
      <div class="claim-text">19. The method of <claim-ref idref="US-6711283-B1-CLM-00011">claim 11</claim-ref>, wherein the second strip comprises a first perimeter edge of the sample and an opposing perimeter edge of the sample, wherein the first edge and the opposing edge are separated by a least 2 micrometers.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES54150923" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>The present invention relates generally to the field of optical microscopy and pertains more specifically to a fully automatic rapid microscope slide scanner.</p>
    <p>2. Discussion of the Prior Art</p>
    <p>One of the inherent limitations of optical microscopy is the tradeoff between the field of view, the portion of the sample that can be viewed through the eyepieces of a microscope, and the magnification at which the sample can be viewed. While higher magnification microscope objective lenses with higher numerical apertures (NA) provide the microscopist with an enlarged and often higher resolution image, the field of view decreases dramatically with increases in magnification, in proportion to the square of the magnification. Even at very low magnifications such as 1.25 times (1.25Ã—), only a small area of a typical microscope slide can be viewed through the binoculars of a conventional microscope. The field of view limitation of optical microscopy requires that the microscopist manually scan a slide at low magnification to obtain an overall view of the sample or specimen. When an area of interest appears in one of the lower magnification fields of view, the microscopist manually selects a higher magnification objective lens to obtain an enlarged higher resolution view of a proportionately smaller area of the specimen. For samples such as histological specimens that are viewed by a pathologist, it is typical for the pathologist to frequently switch back and forth between a lower magnification objective lens with a larger field of view, for purposes of orienting himself or herself with respect to the specimen, and one or more higher magnification, smaller field of view objective lenses for purposes of viewing the sample in greater detail.</p>
    <p>One approach to overcome the optical microscopy limitation of simultaneously achieving both a large field of view, and high magnification, is to capture multiple individual digital images from contiguous fields of view, thereby creating a large field of view image. A scanning system is used to move the sample, while a rectangular optical sensor such as an area scan charge-coupled device (CCD) camera captures an image of each field of view at the desired magnification. The process of assembling these smaller fields of view (hereinafter â€œimage tilesâ€) into one coherent image is called image tiling. Early image tiling systems, such as the system discussed in U.S. Pat. No. 4,760,385 (Jannson et al.) were based on creating a contiguous high resolution tiled image from approximately thirty-six individual video frame image tiles captured in a region of the sample that was previously and interactively selected by an operator. Similar but more sophisticated image tiling system have more recently become available. One such system is sold by Bacus Laboratories, Inc., Downers Grove, Ill., under the name Bacus Laboratories Inc., Slide Scanner (hereinafter â€œBLISSâ€). Elements of the BLISS system are described in Patent Cooperation Treaty publications WO 98/39728 and WO 98/44446.</p>
    <p>The BLISS system is designed primarily for the anatomic pathologist who has a need to combine the anatomic orientation of a histological specimen that is obtained at very low magnification, together with several high magnification views of areas of the specimen that have been interactively selected by the pathologist from the low magnification tiled image, also referred to as a macro image. The BLISS system enables the pathologist to quickly flip back and forth between selected high resolution micro images of selected areas captured at 20Ã— or 40Ã—, and a low resolution macro image captured at 1.25Ã—, emulating in some sense the pathologist's manual use of a conventional microscope. Alternatively, the BLISS system user interface provides separate split screens on a display monitor whereby the pathologist is shown an overall macro view and a marker showing where the current higher magnification view is located. A tiled image is constructed by assembling several adjacent, original microscope views at a first magnification to obtain an overall macro view of the specimen, together with several adjacent original microscope views at a higher magnification to create a combined data structure. The data structure is obtained by digitally scanning and storing the low magnification image tiles with their mapping coordinates and likewise, digitally scanning and storing higher magnification image tiles with their mapping coordinates. Furthermore, a pathologist may interactively select only those diagnostically significant areas of the specimen for digital scanning and storing to reduce significantly the number of image pixels stored at high resolution. The data structure, akin to a virtual microscope slide, may then be transferred to a remote viewer over a network such as the Internet. The remote user is thus provided with a series of abutted, tiled images, with each image tile being substantially equal to one small optical field of view at each of two different optical magnifications.</p>
    <p>The BLISS system is integrated around a computer-controlled, automated microscope such as the Axioplan-2 microscope system sold by Carl Zeiss, Inc., Thornwood, N.Y. This type of high-end microscope has capabilities for computer-control of several subsystems, including the illumination subsystem, the focusing subsystem, the microscope objective lens subsystem, the filtering subsystem, as well as multiple field and condenser diaphragms or optical stops which may be used to achieve optimum Koehler illumination. Essentially, all moveable elements of the microscope can be controlled from the computer; and in principle, from a remote location via the Internet. Positions for all diaphragms and other settings such as focus and illumination level are stored by the computer, enabling microscope objective lenses to be changed without manual intervention. The BLISS system is also equipped with a computer controlled two-axis (x/y for left/right/up/down motion) translation stage that achieves 0.1 micrometer positioning accuracy using position encoders and closed-loop feedback control to provide superior positioning performance. A CCD camera with 752 by 480 pixels, and an image frame grabber are also integrated into the BLISS system.</p>
    <p>Because it is based on image tiling, the BLISS system suffers from several known disadvantages of the image tiling approach. For example, a first disadvantage of the BLISS system is that it takes a long time, typically twenty minutes or longer to acquire the tiled data structures. These time estimates are without consideration for any additional delays that may be incurred during manual intervention, for example, prior to acquiring high magnification tiled images from selected areas of the low magnification macro image. Tiling involves moving a slide on a motorized stage, in discrete steps equal to the width of a single field of view, and with respect to a stationary area scan camera such as the CCD camera used by the BLISS system. An image tile is acquired at every step. Individual images are then tiled together to create a larger seamless image of the area of interest. Image tiling is relatively slow because of the need to minimize any significant relative motion between the sample and the camera while the image is captured. A major cause of relative motion is the settling time of the mechanical positioning stage after issuing sequential stop and go commands. To acquire images without unacceptable smearing requires waiting until the stage has settled, ideally to within less than one pixel. For example, at a 40Ã— magnification, the width of a single image tile captured by a one-half inch format CCD camera corresponds to 160 micrometers of the sample. At this magnification, each individual pixel in a 752-pixel wide CCD camera subtends approximately 0.2 micrometers of the sample. A single tiling step thus requires a relatively large 160 micrometer movement, with associated acceleration and deceleration of the mechanical stage. In order to avoid any smearing of the image, the image tile should be captured only after the mechanical stage has settled to less than one pixel, or about 0.2 micrometers, of motion. U.S. Pat. No. 5,912,699 (Hayenga et al.) addresses this well known settling time limitation of conventional image tiling systems by proposing an alternate method that combines image tiling using conventional area scan cameras with strobe light synchronization. The slow capture times of tiling systems, including the BLISS system, limits the practical utility of image tiling to a two-step process, with extensive manual intervention between the capture of an initial very low magnification macro image and the subsequent selection of small areas for higher magnification capture.</p>
    <p>The slow acquisition time associated with tiling systems leads to a second disadvantage of the BLISS system, that being the need for manual intervention during the process of creating the tiled data structure. After pre-scanning a slide at a very low microscope objective lens magnification of 1.25Ã—, the BLISS operator inspects the macro-image for relevant regions of interest to be scanned using a higher magnification objective lens. While one motivation for the manual intervention may be to limit the size of the final data structure, manual intervention is absolutely essential to define smaller areas which can be acquired in a reasonable time. For example, it would not be practical, because of acquisition time considerations, to use the BLISS system to scan an entire microscope slide at 20Ã— magnification. At a 20Ã— magnification, approximately 16,300 individual image tiles must be captured to digitize a two inch by one inch area of a microscope slide using a 752 by 480 pixel one-half inch format area scan CCD. Assuming further that it takes approximately one second to acquire each image tile, due in large part to the relatively long mechanical settling times associated with each of the 16,300 repeated stop-and-go commands, the total acquisition time would be four and one-half hours. At a 40Ã— magnification, the acquisition time would quadruple to eighteen hours. Even at a 10Ã— magnification the acquisition time would exceed one hour. However, at the BLISS system's very low magnification of 1.25Ã—, only 64 image tiles are needed to create a macro-image of a two inch by one inch area of a microscope slide. The total acquisition time for such a macroimage is about one minute.</p>
    <p>Understanding now that the acquisition time limitations of any image tiling system require the capture of a very low magnification macro-image, followed by the interactive selection from this macro image of small areas to be captured at higher magnification, a third disadvantage of the BLISS system becomes apparent. This third disadvantage resides in the realization that locating areas of interest from a very low magnification macro-image is practically limited to samples in which anatomic reference information is available. The BLISS system thus has limited utility for non-histological samples such as Pap smears, because such cytological samples inherently lack any information about anatomic orientation. In such samples the cells are more or less randomly distributed over a large area of the microscope slide. Without the ability to define, using the macro image, the specific smaller regions of interest that are to be tiled at higher optical magnifications, the only alternative is to scan and digitize the entire sample. However, as described previously, the long acquisition times required by the image tiling method make this alternative virtually impractical. Stated differently, without manual intervention to define specific and significantly smaller areas of the microscope slide for image tiling at higher magnifications, an impossibility for cytological samples, a tiling approach has limited utility. One would prefer a system for scanning microscope slides which is fully automatic, without the need for manual intervention. Such a system would also be suitable for all types of microscope slides, regardless of whether or not the slide contains anatomic reference information.</p>
    <p>A fourth disadvantage of the BLISS system is its complexity and expense. The BLISS system is based largely on off-the-shelf components, including a high-end, fully automated third-party microscope with multiple objective lenses and an expensive closed x/y stage control loop. The suggested end-user price of the BLISS system is well above $100,000. The multiple automated elements of the BLISS system represent a complicated system that, in spite of its extensive automation, may be difficult to operate and maintain. One would prefer a system for scanning microscope slides which is simple and reliable, and which can be made available for about one third of the cost of the BLISS system.</p>
    <p>Inherent in the cost disadvantage of the BLISS system are several limitations of any microscope slide scanning system that is based on a conventional microscope. The most expensive component of the BLISS system is the automated microscope itself. One of the reasons for incorporating a fully automatic microscope into the BLISS system is the need for automatically changing many settings when the microscope objective lens turret is rotated automatically to change microscope objective lenses, for example, from 1.25Ã— to 40Ã—. A typical microscope, upon changing the microscope objective lens, will have a different optimal plane of focus and require new settings for the field and condenser diaphragms to achieve Koehler illumination. Also, a different intensity of illumination will be needed to optimally fill the dynamic range of the CCD. The need for such extensive automation is eliminated if the requirement for changing microscope objective lenses can be eliminated. One would prefer a rapid scanning method that can not only overcome the field of view limitations of traditional optical microscopy but that can also eliminate the need for multiple microscope objective lenses, providing a substantial cost advantage over image tiling systems such as BLISS. The need for a single microscope objective lens is also closely related to eliminating the constraints imposed by the optics of a conventional microscope. One would prefer a system based on an optical design that ensures that microscope slides are scanned and digitized at diffraction-limited resolutions, that is, all possible spatial details available at the resolution of the microscope objective lens are captured by the digital image. Once a diffraction-limited digital image has been captured, degenerate lower resolution and magnification images can be created using standard computational algorithms.</p>
    <p>In many microscopy applications it is necessary that the entire sample, or a large portion of a sample, be searched for defects or for the presence or absence of a special object or objects, for example, abnormal cells. Microscopy becomes very labor intensive when large portions of a sample, or even the entire sample, must be manually scanned at low resolutions, typically 10Ã— to 20Ã—, in order to identify specific areas of interest for subsequent higher resolution interrogation. Extended manual screening or continued viewing of a single field causes eyestrain, fatigue, and visual habituation that can negatively affect productivity and accuracy. The problem of rapidly finding and locating relevant areas of interest for subsequent higher resolution interrogation has been addressed using conventional real-time scanning systems that combine microscopes with ancillary linear array detectors and automated positioning tables, all controlled by a computer. Some approaches, such as the system discussed in U.S. Pat. No. 5,922,282 (Ledley et al.), are based on storing the x/y stage coordinates of relevant objects found on regions of the physical slide to enable relocation of the object, in this case mycobacteria on a customized glass microscope slide. The x/y coordinates of the mycobacteria are obtained using specialized real-time pattern recognition circuitry that is applied to the intensity information measured by a line scan camera that is synchronized to a stage which is moved in relatively large five micrometer steps. Alternatively, an area scan sensor such as a video camera can be used as the basis for deriving the x/y coordinates of selected objects, in conjunction with similar circuitry. In this latter case, the stage is moved in larger steps corresponding to a complete image field, similar to the stage movements required by the tiling method. Focus is maintained using instantaneous automated focus control. An alternate system described in U.S. Pat. No. 4,700,298 (Palcic et al.) uses a linear array CCD attached to a commercially available microscope, with means for autofocus, to scan large areas for purposes of recording, in real time, the x/y coordinates of cells growing in a tissue flask. These known methods and systems are all based on the real-time analysis of digital information that is acquired and processed during the scanning process. In many cases, specialized circuitry is used to immediately process the intensity data that has been read out from the linear array detector, enabling a decision to be made in real-time. An alternative novel approach is to use a linear array sensor to rapidly assemble a large contiguous image of the entire microscope slide at optical resolutions sufficient for automating the labor intensive aspects of manual slide scanning. One would prefer a system that can be used, together with digital image processing methods, as an alternative to manual slide scanning.</p>
    <p>Another common problem associated with manual scanning of microscope slides is that portions of a slide are easily missed during manual x/y scanning of a slide. Relocation to previously identified cells can be difficult, especially after the slide has been removed from the microscope. The problem of not missing any areas of a slide during manual x/y scanning has been addressed by position encoding quality assurance systems that record the x/y position and dwell time of areas of the physical slide that have been examined manually, thus highlighting areas of the slide that were missed or possibly viewed too quickly. U.S. Pat. No. 5,793,969 (Kamentsky et al.) discusses a method for quality assurance of a Pap smear slide that has been previously reviewed by a technologist. This method is based on recording the x/y stage coordinates of all fields visited by the technologist during the slide review, and creating an x/y map of relative slide dwell times.</p>
    <p>A definite need exists for a simple and reliable system that can rapidly scan and digitize an entire microscope slide. The scanning and digitization should be performed at optical resolutions comparable to those used for the manual scanning of microscope slides, thereby enabling the application of image processing algorithms to the digital imagery data set, in lieu of, or in addition to, manually scanning an entire slide. Ideally, such a system should not require any type of manual intervention during the image acquisition process. Such a system should also be suitable for all types of microscope specimens, regardless of whether or not the slide contains anatomic reference information. Ideally, such a system should have a lower cost than conventional systems. Such a system should also not be constrained by the limitations and inherent cost of conventional off-the-shelf microscopes, enabling an optical design that allows the capture of diffraction-limited digital images. A primary purpose of the present invention is to solve these needs and to provide further, related advantages.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention provides an apparatus for and a method of fully automatic rapid scanning and digitizing of an entire microscope sample, or a substantially large portion of a microscope sample, using a linear array detector synchronized with a positioning stage that is part of a computer controlled microscope slide scanner. The invention also provides a method for composing the image strips obtained from successive scans of the sample into a single contiguous digital image. The invention further provides a method for statically displaying sub-regions of this large digital image at different magnifications, together with a reduced magnification macro image of the entire sample. The invention also provides a method for dynamically displaying, with or without operator interaction, portions of the contiguous digital image. In one preferred embodiment of the invention, all elements of the scanner are part of a single-enclosure that has a primary connection to a network such as the Internet or a local intranet. In this embodiment, the preferred sample type is a microscope slide and the illumination and imaging optics are consistent with transmission mode optics optimized for diffraction-limited digital imaging.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWING</heading> <p>The above and other objects and advantages of the present invention will be more readily appreciated from the following detailed description when read in conjunction with the accompanying drawing, wherein:</p>
    <p>FIG. 1 is a block diagram of a preferred embodiment of an optical microscopy system according to the present invention;</p>
    <p>FIG. 2 is a block diagram of a second embodiment of an optical microscopy system according to the present invention;</p>
    <p>FIGS. 3A-3C illustrates a manner in which contiguous image strips acquired by a linear array detector digitizes a portion of a sample according to the present invention;</p>
    <p>FIG. 4 is a simplified flow chart of the operation of an optical microscopy system according to the present invention;</p>
    <p>FIGS. 5A-5B are a schematic diagram of an image viewing frame according to the present invention; and</p>
    <p>FIGS. 6A-6B are a schematic diagram of a dynamic image viewing frame according to the present invention.</p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>Turning first to FIG. 1, a block diagram of a preferred embodiment of an optical microscopy system <b>10</b> according to the present invention is shown. The heart of the system <b>10</b> is a microscope slide scanner <b>11</b> that serves to scan and digitize a specimen or sample <b>12</b>. The sample <b>12</b> can be anything that may be interrogated by optical microscopy. For instance, the sample <b>12</b> may be a microscope slide or other sample type that may be interrogated by optical microscopy. A microscope slide is frequently used as a viewing substrate for specimens that include tissues and cells, chromosomes, DNA, protein, blood, bone marrow, urine, bacteria, beads, biopsy materials, or any other type of biological material or substance that is either dead or alive, stained or unstained, labeled or unlabeled. The sample <b>12</b> may also be an array of any type of DNA or DNA-related material such as cDNA or RNA or protein that is deposited on any type of slide or other substrate, including any and all samples commonly known as a microarrays. The sample <b>12</b> may be a microtiter plate, for example a 96-well plate. Other examples of the sample <b>12</b> include integrated circuit boards, electrophoresis records, petri dishes, film, semiconductor materials, forensic materials, or machined parts.</p>
    <p>The scanner <b>11</b> includes a motorized stage <b>14</b>, a microscope objective lens <b>16</b>, a line scan camera <b>18</b>, and a data processor <b>20</b>. The sample <b>12</b> is positioned on the motorized stage <b>14</b> for scanning. The motorized stage <b>14</b> is connected to a stage controller <b>22</b> which is connected in turn to the data processor <b>20</b>. The data processor <b>20</b> determines the position of the sample <b>12</b> on the motorized stage <b>14</b> via the stage controller <b>22</b>. In the presently preferred embodiment, the motorized stage <b>14</b> moves the sample <b>12</b> in at least the two axes (x/y) that are in the plane of the sample <b>12</b>. Fine movements of the sample <b>12</b> along the optical z-axis may also be necessary for certain applications of the scanner <b>11</b>, for example, for focus control. Z-axis movement is preferably accomplished with a piezo positioner <b>24</b>, such as the PIFOC from Polytec PI or the MIPOS <b>3</b> from Piezosystem Jena. The piezo positioner <b>24</b> is attached directly to the microscope objective <b>16</b> and is connected to and directed by the data processor <b>20</b> via a piezo controller <b>26</b>. A means of providing a coarse focus adjustment may also be needed and can be provided by z-axis movement as part of the motorized stage <b>14</b> or a manual rack-and-pinion coarse focus adjustment (not shown).</p>
    <p>In the presently preferred embodiment, the motorized stage <b>14</b> includes a high precision positioning table with ball bearing linear ways to provide smooth motion and excellent straight line and flatness accuracy. For example, the motorized stage <b>14</b> could include two Daedal model 106004 tables stacked one on top of the other. Other types of motorized stages <b>14</b> are also suitable for the scanner <b>11</b>, including stacked single axis stages based on ways other than ball bearings, single- or multiple-axis positioning stages that are open in the center and are particularly suitable for trans-illumination from below the sample, or larger stages that can support a plurality of samples. In the presently preferred embodiment, motorized stage <b>14</b> includes two stacked single-axis positioning tables, each coupled to two millimeter lead-screws and Nema-<b>23</b> stepping motors. At the maximum lead screw speed of twenty-five revolutions per second, the maximum speed of the sample <b>12</b> on the motorized stage <b>14</b> is fifty millimeters per second. Selection of a lead screw with larger diameter, for example five millimeters, can increase the maximum speed to more than 100 millimeters per second. The motorized stage <b>14</b> can be equipped with mechanical or optical position encoders which has the disadvantage of adding significant expense to the system. Consequently, the presently preferred embodiment does not include position encoders. However, if one were to use servo motors in place of stepping motors, then one would have to use position feedback for proper control.</p>
    <p>Position commands from the data processor <b>20</b> are converted to motor current or voltage commands in the stage controller <b>22</b>. In the presently preferred embodiment, the stage controller <b>22</b> includes a 2-axis servo/stepper motor controller (Compumotor 6K2) and two 4-amp microstepping drives (Compumotor OEMZL4). Microstepping provides a means for commanding the stepper motor in much smaller increments than the relatively large single 1.8 degree motor step. For example, at a microstep of 100, the sample <b>12</b> can be commanded to move at steps as small as 0.1 micrometer. A microstep of 25,000 is used in the presently preferred embodiment of this invention. Smaller step sizes are also possible. It should be obvious that the optimum selection of the motorized stage <b>14</b> and the stage controller <b>22</b> depends on many factors, including the nature of the sample <b>12</b>, the desired time for sample digitization, and the desired resolution of the resulting digital image of the sample <b>12</b>.</p>
    <p>The microscope objective lens <b>16</b> can be any microscope objective lens commonly available. One of ordinary skill in the art will realize that the choice of which objective lens to use will depend on the particular circumstances. In the preferred embodiment of the present invention, the microscope objective lens <b>16</b> is of the infinity-corrected type.</p>
    <p>The sample <b>12</b> is illuminated by an illumination system <b>28</b> that includes a light source <b>30</b> and illumination optics <b>32</b>. The light source <b>30</b> in the presently preferred embodiment includes a variable intensity halogen light source with a concave reflective mirror to maximize light output and a KG-1 filter to suppress heat. However, the light source <b>30</b> could also be any other type of arc-lamp, laser, or other source of light. The illumination optics <b>32</b> in the presently preferred embodiment include a standard Kohler illumination system with two conjugate planes that are orthogonal to the optical axis. The illumination optics <b>32</b> are representative of the bright-field illumination optics that can be found on most commercially available compound microscopes sold by companies such as Carl Zeiss, Nikon, Olympus, or Leica. One set of conjugate planes includes (i) a field iris aperture illuminated by the light source <b>30</b>, (ii) the object plane that is defined by the focal plane of the sample <b>12</b>, and (iii) the plane containing the light-responsive elements of the line scan camera <b>18</b>. A second conjugate plane includes (i) the filament of the bulb that is part of the light source <b>30</b>, (ii) the aperture of a condenser iris that sits immediately before the condenser optics that are part of the illumination optics <b>32</b>, and (iii) the back focal plane of the microscope objective lens <b>16</b>. In the presently preferred embodiment, the sample <b>12</b> is illuminated and imaged in transmission mode, with the line scan camera <b>18</b> sensing optical energy that is transmitted by the sample <b>12</b>, or conversely, optical energy that is absorbed by the sample <b>12</b>.</p>
    <p>The scanner <b>11</b> of the present invention is equally suitable for detecting optical energy that is reflected from the sample <b>12</b>, in which case the light source <b>30</b>, the illumination optics <b>32</b>, and the microscope objective lens <b>16</b> must be selected based on compatibility with reflection imaging. One possible embodiment may therefore be illumination through a fiber optic bundle that is positioned above the sample <b>12</b>. Other possibilities include excitation that is spectrally conditioned by a monochromator. If the microscope objective lens <b>16</b> is selected to be compatible with phase-contrast microscopy, then the incorporation of at least one phase stop in the condenser optics that are part of the illumination optics <b>32</b> will enable the scanner <b>11</b> to be used for phase contrast microscopy. To one of ordinary skill in the art, the modifications required for other types of microscopy such as differential interference contrast and confocal microscopy should be readily apparent. Overall, the scanner <b>11</b> is suitable, with appropriate but well-known modifications, for the interrogation of microscopic samples in any known mode of optical microscopy.</p>
    <p>Between the microscope objective lens <b>16</b> and the line scan camera <b>18</b> are situated the line scan camera focusing optics <b>34</b> that focus the optical signal captured by the microscope objective lens <b>16</b> onto the light-responsive elements of the line scan camera <b>18</b>. In a modern infinity-corrected microscope the focusing optics between the microscope objective lens and the eyepiece optics, or between the microscope objective lens and an external imaging port, consist of an optical element known as a tube lens that is part of a microscope's observation tube. Many times the tube lens consists of multiple optical elements to prevent the introduction of coma or astigmatism. One of the motivations for the relatively recent change from traditional finite tube length optics to infinity corrected optics was to increase the physical space in which the optical energy from the sample <b>12</b> is parallel, meaning that the focal point of this optical energy is at infinity. In this case, accessory elements like dichroic mirrors or filters can be inserted into the infinity space without changing the optical path magnification or introducing undesirable optical artifacts.</p>
    <p>Infinity-corrected microscope objective lenses are typically inscribed with an infinity mark. The magnification of an infinity corrected microscope objective lens is given by the quotient of the focal length of the tube lens divided by the focal length of the objective lens. For example, a tube lens with a focal length of 180 millimeters will result in 20Ã— magnification if an objective lens with 9 millimeter focal length is used. One of the reasons that the objective lenses manufactured by different microscope manufacturers are not compatible is because of a lack of standardization in the tube lens focal length. For example, a 20Ã— objective lens from Olympus, a company that uses a 180 millimeter tube lens focal length, will not provide a 20Ã— magnification on a Nikon microscope that is based on a different tube length focal length of 200 millimeters. Instead, the effective magnification of such an Olympus objective lens engraved with 20Ã— and having a 9 millimeter focal length will be 22.2Ã—, obtained by dividing the 200 millimeter tube lens focal length by the 9 millimeter focal length of the objective lens. Changing the tube lens on a conventional microscope is virtually impossible without disassembling the microscope. The tube lens is part of a critical fixed element of the microscope. Another contributing factor to the incompatibility between the objective lenses and microscopes manufactured by different manufacturers is the design of the eyepiece optics, the binoculars through which the specimen is observed. While most of the optical corrections have been designed into the microscope objective lens, most microscope users remain convinced that there is some benefit in matching one manufacturers' binocular optics with that same manufacturers' microscope objective lenses to achieve the best visual image.</p>
    <p>The line scan camera focusing optics <b>34</b> include a tube lens optic mounted inside of a mechanical tube. Since the scanner <b>11</b>, in its preferred embodiment, lacks binoculars or eyepieces for traditional visual observation, the problem suffered by conventional microscopes of potential incompatibility between objective lenses and binoculars is immediately eliminated. One of ordinary skill will similarly realize that the problem of achieving parfocality between the eyepieces of the microscope and a digital image on a display monitor is also eliminated by virtue of not having any eyepieces. Since the scanner <b>11</b> also overcomes the field of view limitation of a traditional microscope by providing a field of view that is practically limited only by the physical boundaries of the sample <b>12</b>, the importance of magnification in an all-digital imaging microscope such as provided by the present scanner <b>11</b> is limited. Once a portion of the sample <b>12</b> has been digitized, it is straightforward to apply electronic magnification, sometimes known as electric zoom, to an image of the sample <b>12</b> in order to increase its magnification. Increasing the magnification of an image electronically has the effect of increasing the size of that image on the monitor that is used to display the image. If too much electronic zoom is applied, then the display monitor will be able to show only portions of the magnified image. It is not possible, however, to use electronic magnification to display information that was not present in the original optical signal that was digitized in the first place. Since one of the objectives of the scanner <b>11</b> is to provide high quality digital images, in lieu of visual observation through the eyepieces of a microscope, it is important that the content of the images acquired by the scanner <b>11</b> include as much image detail as possible. The term resolution is typically used to describe such image detail and the term diffraction-limited is used to describe the wavelength-limited maximum spatial detail available in an optical signal. The scanner <b>11</b> provides diffraction-limited digital imaging by selection of a tube lens focal length that is matched according to the well know Nyquist sampling criteria to both the size of an individual pixel element in a light-sensing camera such as the line scan camera <b>18</b> and to the numerical aperture of the microscope objective lens <b>16</b>. It is well known that numerical aperture, not magnification, is the resolution-limiting attribute of a microscope objective lens <b>16</b>.</p>
    <p>An example will help to illustrate the optimum selection of a tube lens focal length that is part of the line scan camera focusing optics <b>34</b>. Consider again the 20Ã— microscope objective lens <b>16</b> with 9 millimeter focal length discussed previously and assume that this objective lens has a numerical aperture of 0.50. Assuming no appreciable degradation from the condenser, the diffraction-limited resolving power of this objective lens at a wavelength of 500 nanometers is approximately 0.6 micrometers, obtained using the well-known Abbe relationship. Assume further that the line scan camera <b>18</b>, which in its preferred embodiment has a plurality of 14 micrometer square pixels, is used to detect a portion of the sample <b>12</b>. In accordance with sampling theory, it is necessary that at least two sensor pixels subtend the smallest resolvable spatial feature. In this case, the tube lens must be selected to achieve a magnification of 46.7, obtained by dividing 28 micrometers, which corresponds to two 14 micrometer pixels, by 0.6 micrometers, the smallest resolvable feature dimension. The optimum tube lens optic focal length is therefore about 420 millimeters, obtained by multiplying 46.7 by 9. The line scan focusing optics <b>34</b> with a tube lens optic having a focal length of 420 millimeters will therefore be capable of acquiring images with the best possible spatial resolution, similar to what would be observed by viewing a specimen under a microscope using the same 20Ã— objective lens. To reiterate, the scanner <b>11</b> utilizes a traditional 20Ã— microscope objective lens <b>16</b> in a higher magnification optical configuration, in this example about 47Ã—, in order to acquire diffraction-limited digital images. If a traditional 20Ã— magnification objective lens <b>16</b> with a higher numerical aperture were used, say 0.75, the required tube lens optic magnification for diffraction-limited imaging would be about 615 millimeters, corresponding to an overall optical magnification of 68Ã—. Similarly, if the numerical aperture of the 20Ã— objective lens were only 0.3, the optimum tube lens optic magnification would only be about 28Ã—, which corresponds to a tube lens optic focal length of approximately 252 millimeters. The line scan camera focusing optics <b>34</b> are modular elements of the scanner <b>11</b> and can be interchanged as necessary for optimum digital imaging. The advantage of diffraction-limited digital imaging is particularly significant for applications, for example bright field microscopy, in which the reduction in signal brightness that accompanies increases in magnification is readily compensated by increasing the intensity of an appropriately designed illumination system <b>28</b>.</p>
    <p>In principle, it is possible to attach external magnification-increasing optics to a conventional microscope-based digital imaging system to effectively increase the tube lens magnification so as to achieve diffraction-limited imaging as has just been described for the present scanner <b>11</b>; however, the resulting decrease in the field of view is often unacceptable, making this approach impractical. Furthermore, many users of microscopes typically do not understand enough about the details of diffraction-limited imaging to effectively employ these techniques on their own. In practice, digital cameras are attached to microscope ports with magnification-decreasing optical couplers to attempt to increase the size of the field of view to something more similar to what can be seen through the eyepiece. The standard practice of adding de-magnifying optics is a step in the wrong direction if the goal is to obtain diffraction-limited digital images.</p>
    <p>In a conventional microscope, different power objectives lenses are typically used to view the specimen at different resolutions and magnifications. Standard microscopes have a nosepiece that holds five objectives lenses. In an all-digital imaging system such as the present scanner <b>11</b> there is a need for only one microscope objective lens <b>16</b> with a numerical aperture corresponding to the highest spatial resolution desirable. The presently preferred embodiment of the scanner <b>11</b> provides for only one microscope objective lens <b>16</b>. Once a diffraction-limited digital image has been captured at this resolution, it is straightforward using standard digital image processing techniques, to present imagery information at any desirable reduced resolutions and magnifications.</p>
    <p>The presently preferred embodiment of the scanner <b>11</b> is based on a Dalsa SPARK line scan camera <b>18</b> with 1024 pixels (picture elements) arranged in a linear array, with each pixel having a dimension of 14 by 14 micrometers. Any other type of linear array, whether packaged as part of a camera or custom-integrated into an imaging electronic module, can also be used. The linear array in the presently preferred embodiment effectively provides eight bits of quantization, but other arrays providing higher or lower level of quantization may also be used. Alternate arrays based on 3-channel red-green-blue (RGB) color information or time delay integration (TDI), may also be used. TDI arrays provide a substantially better signal-to-noise ratio (SNR) in the output signal by summing intensity data from previously imaged regions of a specimen, yielding an increase in the SNR that is in proportion to the square-root of the number of integration stages. TDI arrays can comprise multiple stages of linear arrays. TDI arrays are available with 24, 32, 48, 64, 96, or even more stages. The scanner <b>11</b> also supports linear arrays that are manufactured in a variety of formats including some with 512 pixels, some with 1024 pixels, and others having as many as 4096 pixels. Appropriate, but well known, modifications to the illumination system <b>28</b> and the line scan camera focusing optics <b>34</b> may be required to accommodate larger arrays. Linear arrays with a variety of pixel sizes can also be used in scanner <b>11</b>. The salient requirement for the selection of any type of line scan camera <b>18</b> is that the sample <b>12</b> can be in motion with respect to the line scan camera <b>18</b> during the digitization of the sample <b>12</b> in order to obtain high quality images, overcoming the static requirements of the conventional imaging tiling approaches known in the prior art.</p>
    <p>The output signal of the line scan camera <b>18</b> is connected to the data processor <b>20</b>. The data processor <b>20</b> in the presently preferred embodiment includes a central processing unit with ancillary electronics, for example a motherboard, to support at least one signal digitizing electronics board such as an imaging board or a frame grabber. In the presently preferred embodiment, the imaging board is an EPIX PIXCID<b>24</b> PCI bus imaging board, however, there are many other types of imaging boards or frame grabbers from a variety of manufacturers which could be used in place of the EPIX board. An alternate embodiment could be a line scan camera that uses an interface such as IEEE 1394, also known as Firewire, to bypass the imaging board altogether and store data directly on a data storage <b>38</b>, such as a hard disk.</p>
    <p>The data processor <b>20</b> is also connected to a memory <b>36</b>, such as random access memory (RAM), for the short-term storage of data, and to the data storage <b>38</b>, such as a hard drive, for long-term data storage. Further, the data processor <b>20</b> is connected to a communications port <b>40</b> that is connected to a network <b>42</b> such as a local area network (LAN), a wide area network (WAN), a metropolitan area network (MAN), an intranet, an extranet, or the global Internet. The memory <b>36</b> and the data storage <b>38</b> are also connected to each other. The data processor <b>20</b> is also capable of executing computer programs, in the form of software, to control critical elements of the scanner <b>11</b> such as the line scan camera <b>18</b> and the stage controller <b>22</b>, or for a variety of image-processing functions, image-analysis functions, or networking. The data processor <b>20</b> can be based on any operating system, including operating systems such as Windows, Linux, OS/2, Mac OS, and Unix. In the presently preferred embodiment, the data processor <b>20</b> operates based on the Windows NT operating system.</p>
    <p>The data processor <b>20</b>, memory <b>36</b>, data storage <b>38</b>, and communication port <b>40</b> are each elements that can be found in a conventional computer. One example would be a personal computer such as a Dell Dimension XPS T500 that features a Pentium III 500 MHz processor and up to 756 megabytes (MB) of RAM. In the presently preferred embodiment, the computer, elements which include the data processor <b>20</b>, memory <b>36</b>, data storage <b>38</b>, and communications port <b>40</b> are all internal to the scanner <b>11</b>, so that the only connection of the scanner <b>11</b> to the other elements of the system <b>10</b> is the communication port <b>40</b>. In an alternate embodiment of the scanner <b>11</b>, the computer elements would be external to the scanner <b>11</b> with a corresponding connection between the computer elements and the scanner <b>11</b>.</p>
    <p>The scanner <b>11</b>, in the presently preferred embodiment of the invention, integrates optical microscopy, digital imaging, motorized sample positioning, computing, and network-based communications into a single-enclosure unit. The major advantage of packaging the scanner <b>11</b> as a single-enclosure unit with the communications port <b>40</b> as the primary means of data input and output are reduced complexity and increased reliability. The various elements of the scanner <b>11</b> are optimized to work together, in sharp contrast to traditional microscope-based imaging systems in which the microscope, light source, motorized stage, camera, and computer are typically provided by different vendors and require substantial integration and maintenance.</p>
    <p>The communication port <b>40</b> provides a means for rapid communications with the other elements of the system <b>10</b>, including the network <b>42</b>. The presently preferred communications protocol for the communications port <b>40</b> is a carrier-sense multiple-access collision detection protocol such as Ethernet, together with the TCP/IP protocol for transmission control and internetworking. The scanner <b>11</b> is intended to work with any type of transmission media, including broadband, baseband, coaxial cable, twisted pair, fiber optics, DSL or wireless.</p>
    <p>In the presently preferred embodiment, control of the scanner <b>11</b> and review of the imagery data captured by the scanner <b>11</b> are performed on a computer <b>44</b> that is connected to the network <b>42</b>. The computer <b>44</b>, in its presently preferred embodiment, is connected to a display monitor <b>46</b> to provide imagery information to an operator. A plurality of computers <b>44</b> may be connected to the network <b>42</b>. In the presently preferred embodiment, the computer <b>44</b> communicates with the scanner <b>11</b> using a network browser such as Internet Explorer from Microsoft or Netscape Communicator from AOL. Images are stored on the scanner <b>11</b> in a common compressed format such a JPEG which is an image format that is compatible with standard image-decompression methods that are already built into most commercial browsers. Other standard or non-standard, lossy or lossless, image compression formats will also work. In the presently preferred embodiment, the scanner <b>11</b> is a webserver providing an operator interface that is based on webpages that are sent from the scanner <b>11</b> to the computer <b>44</b>. For dynamic review of imagery data, the currently preferred embodiment of the scanner <b>11</b> is based on playing back, for review on the display monitor <b>46</b> that is connected to the computer <b>44</b>, multiple frames of imagery data using standard multiple-frame browser compatible software packages such as Media-Player from Microsoft, Quicktime from Apple Computer, or RealPlayer from Real Networks. In the presently preferred embodiment, the browser on the computer <b>44</b> uses the hypertext transmission protocol (http) together with TCP for transmission control.</p>
    <p>There are, and will be in the future, many different means and protocols by which the scanner <b>11</b> could communicate with the computer <b>44</b>, or a plurality of computers. While the presently preferred embodiment is based on standard means and protocols, the approach of developing one or multiple customized software modules known as applets is equally feasible and may be desirable for selected future applications of the scanner <b>11</b>. Further, there are no constraints that computer <b>44</b> be of any specific type such as a personal computer (PC) or be manufactured by any specific company such as Dell. One of the advantages of a standardized communications port <b>40</b> is that any type of computer <b>44</b> operating common network browser software can communicate with the scanner <b>11</b>.</p>
    <p>If one so desires, it is possible, with some modifications to the scanner <b>11</b>, to obtain spectrally resolved images. Spectrally resolved images are images in which spectral information is measured at every image pixel. Spectrally resolved images could be obtained by replacing the line scan camera <b>18</b> of the scanner <b>11</b> with an optical slit and an imaging spectrograph. The imaging spectrograph uses a two-dimensional CCD detector to capture wavelength-specific intensity data for a column of image pixels by using a prism or grating to disperse the optical signal that is focused on the optical slit along each of the rows of the detector.</p>
    <p>Turning now to FIG. 2, a block diagram of a second embodiment of an optical microscopy system <b>10</b> according to the present invention is shown. In this system <b>10</b>, the scanner <b>11</b> is more complex and expensive than the currently preferred embodiment shown in FIG. <b>1</b>. The additional attributes of the scanner <b>11</b> that are shown do not all have to be present for any alternate embodiment to function correctly. FIG. 2 is intended to provide a reasonable example of additional features and capabilities that could be incorporated into the scanner <b>11</b>.</p>
    <p>The alternate embodiment of FIG. 2 provides for a much greater level of automation than the presently preferred embodiment of FIG. 1. A more complete level of automation of the illumination system <b>28</b> is achieved by connections between the data processor <b>20</b> and both the light source <b>30</b> and the illumination optics <b>32</b> of the illumination system <b>28</b>. The connection to the light source <b>30</b> may control the voltage, or current, in an open or closed loop fashion, in order to control the intensity of the light source <b>30</b>. Recall that the light source <b>30</b> is a halogen bulb in the presently preferred embodiment. The connection between the data processor <b>20</b> and the illumination optics <b>32</b> could provide closed loop control of the field iris aperture and the condenser iris to provide a means for ensuring that optimum KÃ¶hler illumination is maintained.</p>
    <p>Use of the scanner <b>11</b> for fluorescence imaging requires easily recognized modifications to the light source <b>30</b>, the illumination optics <b>32</b>, and the microscope objective lens <b>16</b>. The second embodiment of FIG. 2 also provides for a fluorescence filter cube <b>50</b> that includes an excitation filter, a dichroic filter, and a barrier filter. The fluorescence filter cube <b>50</b> is positioned in the infinity corrected beam path that exists between the microscope objective lens <b>16</b> and line scan camera focusing optics <b>34</b>. One embodiment for fluorescence imaging could include the addition of a filter wheel or tunable filter into the illumination optics <b>32</b> to provide appropriate spectral excitation for the variety of fluorescent dyes or nano-crystals available on the market.</p>
    <p>The addition of at least one beam splitter <b>52</b> into the imaging path allows the optical signal to be split into at least two paths. The primary path is via the line scan camera focusing optics <b>34</b>, as discussed previously, to enable diffraction-limited imaging by the line scan camera <b>18</b>. A second path is provided via an area scan camera focusing optics <b>54</b> for imaging by an area scan camera <b>56</b>. It should be readily apparent that proper selection of these two focusing optics can ensure diffraction-limited imaging by the two camera sensors having different pixel sizes. The area scan camera <b>56</b> can be one of many types that are currently available, including a simple color video camera, a high performance, cooled, CCD camera, or a variable integration time fast frame camera. The area scan camera <b>56</b> provides a traditional imaging system configuration for the scanner <b>11</b>. The area scan camera <b>56</b> is connected to the data processor <b>20</b>. If two cameras are used, for example the line scan camera <b>18</b> and the area scan camera <b>56</b>, both camera types could be connected to the data processor using either a single dual-purpose imaging board, two different imaging boards, or the IEEE1394 Firewire interface, in which case one or both imaging boards may not be needed. Other related methods of interfacing imaging sensors to the data processor <b>20</b> are also available.</p>
    <p>While the primary interface of the scanner <b>11</b> to the computer <b>44</b> is via the network <b>42</b>, there may be instances, for example a failure of the network <b>42</b>, where it is beneficial to be able to connect the scanner <b>11</b> directly to a local output device such as a display monitor <b>58</b> and to also provide local input devices such as a keyboard and mouse <b>60</b> that are connected directly into the data processor <b>20</b> of the scanner <b>11</b>. In this instance, the appropriate driver software and hardware would have to be provided as well.</p>
    <p>The second embodiment shown in FIG. 2 also provides for a much greater level of automated imaging performance. Enhanced automation of the imaging of the scanner <b>11</b> can be achieved by closing the focus control loop comprising the piezo positioner <b>24</b>, the piezo controller <b>26</b>, and the data processor <b>20</b> using well-known methods of autofocus. The second embodiment also provides for a motorized nose-piece <b>62</b> to accommodate several objectives lenses. The motorized nose-piece <b>62</b> is connected to and directed by the data processor <b>20</b> through a nose-piece controller <b>64</b>.</p>
    <p>There are other features and capabilities of the scanner <b>11</b> which could be incorporated. For example, the process of scanning the sample <b>12</b> with respect to the microscope objective lens <b>16</b> that is substantially stationary in the x/y plane of the sample <b>12</b> could be modified to comprise scanning of the microscope objective lens <b>16</b> with respect to a stationary sample <b>12</b>. Scanning the sample <b>12</b>, or scanning the microscope objective lens <b>16</b>, or scanning both the sample <b>12</b> and the microscope objective lens <b>16</b> simultaneously, are possible embodiments of the scanner <b>11</b> which can provide the same large contiguous digital image of the sample <b>12</b> as discussed previously.</p>
    <p>The scanner <b>11</b> also provides a general purpose platform for automating many types of microscope-based analyses. The illumination system <b>28</b> could be modified from a traditional halogen lamp or arc-lamp to a laser-based illumination system to permit scanning of the sample <b>12</b> with laser excitation. Modifications, including the incorporation of a photomultiplier tube or other non-imaging detector, in addition to or in lieu of the line scan camera <b>18</b> or the area scan camera <b>56</b>, could be used to provide a means of detecting the optical signal resulting from the interaction of the laser energy with the sample <b>12</b>.</p>
    <p>Turning now to FIGS. 3A-3C, the manner in which contiguous image strips are acquired by a linear array detector according to the present invention is shown. The line scan camera <b>18</b> of FIG. 1 observes a line scan camera field of view <b>70</b> as shown in FIG. <b>3</b>A. The line scan camera field of view <b>70</b> comprises the region of the sample <b>12</b> of FIG. 1 that is imaged by a multitude of individual pixel elements <b>72</b> that are arranged in a linear fashion into a linear array <b>74</b> as shown in FIG. <b>3</b>B. The linear array <b>74</b> of the presently preferred embodiment comprises 1024 of the individual pixel elements <b>72</b>, with each of the pixel elements <b>72</b> being 14 micrometers square. The physical dimensions of the linear array <b>74</b> of the presently preferred embodiment are 14.34 millimeters by 14 micrometers. Assuming, for purposes of discussion of the operation of the scanner <b>11</b>, that the magnification between the sample <b>12</b> and the line scan camera <b>18</b> is ten, then the line scan camera field of view <b>70</b> corresponds to a region of the sample <b>12</b> that has dimensions equal to 1.43 millimeters by 1.4 micrometers. Each pixel element <b>72</b> images an area about 1.4 micrometers by 1.4 micrometers.</p>
    <p>FIG. 3C illustrates that during digital scanning of the sample <b>12</b>, an image <b>76</b> is acquired in image strips, such as image strip <b>77</b>, starting with a first image strip <b>78</b>, followed by a second image strip <b>80</b>, and so on, until the last image strip <b>82</b> necessary to digitize the image <b>76</b> has been acquired. One of ordinary skill in the art will realize that the scanning may be either top-to-bottom or bottom-to-top or may start any point on the sample. The digital scanning may also involve vertical image strips rather than horizontal image strips. While desirable, it is also not necessary that the image strips be acquired in a contiguous manner. The image <b>76</b> can comprise the entire sample <b>12</b> or only a portion of the sample <b>12</b>. In the presently preferred embodiment of the scanner <b>11</b>, the scanning and digitization is performed in a direction of travel <b>84</b> that alternates between image strips, as shown in FIG. <b>3</b>A. This type of bi-directional scanning provides for a more rapid digitization process than uni-directional scanning, a method of scanning and digitization which requires the same direction of travel <b>84</b> for each image strip.</p>
    <p>The capabilities of the line scan camera <b>18</b> typically determine whether scanning can be done bi-directionally, as in the currently preferred embodiment of the scanner <b>11</b>, or uni-directionally. Uni-directional systems often comprise more than one linear array <b>74</b>, such as a three channel color array <b>86</b> or a multi-channel TDI array <b>88</b> shown in FIG. <b>3</b>B. The color array <b>86</b> detects the RGB intensities required for obtaining a color image. An alternate embodiment for obtaining color information uses a prism to split the broadband optical signal into the three color channels. The TDI array <b>88</b> could be used in an alternate embodiment of the scanner <b>11</b> to provide a means of increasing the effective integration time of the line scan camera <b>18</b>, while maintaining a fast data rate, and without significant loss in the signal-to-noise ratio of the digital imagery data.</p>
    <p>Turning now to FIG. 4, a simplified flow chart of the operation of an optical microscopy system <b>10</b> according to the present invention is shown. The sample <b>12</b> is loaded into scanner <b>11</b> at step <b>200</b>. The simplest method of sample loading is for an operator to physically place or position the sample <b>12</b> on the motorized stage <b>14</b>. The most advanced method of sample loading is for the scanner <b>11</b> to automatically load one or multiple samples <b>12</b> from a sample cassette that has been previously loaded. Other embodiments for sample loading are known in the art. In the presently preferred embodiment of this invention, sample loading is performed manually to reduce system cost and mechanical complexity.</p>
    <p>The scanner <b>11</b> is initialized at step <b>201</b> by commands issued from the computer <b>44</b>, or similarly from buttons that may be part of an alternate embodiment of the scanner <b>11</b>. Initialization parameters, including the desired resolution of the digitization process, the portion of the sample <b>12</b> to be digitized to create the image <b>76</b>, and the name of a relevant calibration file are entered by an operator at step <b>201</b>. The scanner <b>11</b> defaults to digitizing the entire sample unless instructed otherwise. It is important to note that after loading the sample and initializing the scanner, there should be no need for the manual intervention of the operator in the image acquisition process that follows.</p>
    <p>The automatic scanning and digitization of the sample <b>12</b> into the image <b>76</b> includes steps <b>202</b> through <b>210</b>. These steps are orchestrated by the data processor <b>20</b> which synchronizes the read-out of imagery data from the line scan camera <b>18</b> one line or image strip at a time, while the sample <b>12</b> is moved at substantially constant velocity on the motorized stage <b>14</b> that is under control of the stage controller <b>22</b>. The scanner <b>11</b> commences the automatic digitization of the sample <b>12</b> at step <b>202</b> with the movement of the sample <b>12</b> and the acquisition of a single line image from the line scan camera <b>18</b>, starting in a predetermined region of the sample <b>12</b>, for example the upper left-hand corner of the sample <b>12</b> as shown in FIG. <b>3</b>C. In step <b>202</b>, the motorized stage <b>14</b> is moved with respect to the line scan camera <b>18</b> in the bi-directional back and forth manner discussed previously. The control logic of the decision block of step <b>204</b> determines whether the end of an image strip, such as the image strip <b>77</b>, has been reached. There are many possible ways to implement this logic, some without position feedback from a position encoder. For example, the total number of image lines read out by the line scan camera <b>18</b> could be used as a means of knowing when the end of the image strip has been reached. Other parameters such as total elapsed scan time or calibration markings that are part of, or positioned in close proximity to, the sample <b>18</b> could also be used. Optical limit switches are provided in the motorized stage <b>14</b> of the presently preferred embodiment of the scanner <b>11</b> to indicate when it is time to reposition the motorized stage <b>14</b> for a new scan. If the end of the image strip <b>77</b> has not been reached at step <b>204</b>, then the digitization process continues with step <b>202</b>, the acquisition of the next line image. The sample <b>12</b> continues to move at approximately constant velocity at all times during the digitization process, and any required focus adjustments are made in parallel with the on-going motion of the mechanical stage <b>14</b> as indicated in step <b>206</b>. Because the focus will not change dramatically from one image strip to the next, focus adjustments are made relatively slowly and gradually. Assuming again, for purposes of discussion of operation of the scanner <b>11</b>, that the area of the sample <b>12</b> to be digitized at a magnification of 10Ã— is 50 millimeters by 25 millimeters, then eighteen image strips, similar to the image strip <b>77</b>, each of dimension 1.43 millimeters by 50 millimeters must be acquired to generate the image <b>76</b>. Each image strip <b>77</b> would comprise about 36,000 by 1024 pixel elements, with the entire image <b>76</b> comprising approximately 36,000 by 18,000 pixels. Unless and until the process of digitizing the desired portion of the sample <b>12</b> to create the image <b>76</b> has finished, as determined by the decision logic of step <b>208</b>, the positioning of the sample <b>12</b> for a new scan occurs at step <b>210</b>. Step <b>210</b> includes movement of the motorized stage <b>14</b> from one image strip to another in order to position the motorized stage <b>14</b> for a new scan.</p>
    <p>The total time required to acquire the image <b>76</b> is proportional to the line rate at which the line scan camera <b>18</b> can digitize information. In the presently preferred embodiment of the scanner <b>11</b>, the line rate is 27,600 lines per second, or 28.3 million pixels per second, for the DALSA SPARK model SP12-01K30 that is used. At a line rate of 27,600 pixels per second, each image strip <b>77</b> comprising, for purposes of discussion, 36,000 by 1024 pixels can be digitized in about 1.3 seconds (36,000/27,600). The motorized stage <b>14</b> in the present embodiment thus moves at approximately 38 millimeters per second along the x-axis, covering the entire length of the 50 millimeters image strip <b>77</b> during these 1.3 seconds. Since the image <b>76</b> comprises 18 image strips <b>77</b>, 23.4 seconds are required to digitize the desired portion of the sample <b>12</b>. As discussed previously, this time is only valid for a bi-directional line scan camera, such as used in the preferred embodiment of the present invention, that can scan from right to left and also from left to right along the x-axis. An alternated embodiment could utilize a uni-directional type of the line scan camera which can scan only from left to right. In this case, the motorized stage <b>14</b> is returned at maximum stage velocity to the same left reference position along the x-axis and all image strips, such as the image strip <b>77</b>, are acquired in a uni-directional manner going only from left to right. After completing the digitization of an individual image strip, such as the image strip <b>77</b>, the motorized stage <b>14</b> decelerates, comes to a stop, moves downward along the y-axis and accelerates again to scan the subsequent image strip. Allowances, in both time and distance, have to be made for the motorized stage <b>14</b> to accelerate and decelerate at the beginning and end of each image strip that is scanned so as to ensure that the motorized stage <b>14</b> is moving at substantially constant velocity during the scanning and digitization process. The additional time required for acceleration and deceleration depends on the x-axis performance of the motorized stage <b>14</b> and the x-axis attributes of the stage controller <b>22</b>. In the presently preferred embodiment, the acceleration and deceleration times, using S-curve profiles for smooth motion and minimum jerk, are approximately 0.7 seconds. The consideration of acceleration and deceleration of the motorized stage <b>14</b> require that during the new scan set-up comprising step <b>210</b>, the line scan camera <b>18</b> moves off the edges of the portion of the sample <b>12</b> that is to be digitized. The new scan set-up time depends on the particular y-axis performance of the motorized stage <b>14</b>, and the y-axis attributes of the stage controller <b>22</b>, and is approximately one-half second in the presently preferred embodiment of the invention. Thus, a total of 25.2 seconds, obtained by multiplying 18 image strips times 1.4 seconds, are added for acceleration and deceleration along the x-axis at the beginning and end of each image strip, and an additional nine seconds are added to reposition the motorized along the y-axis for the next scan. The total time required for all portions of the process required to capture the image <b>76</b> in the present example is therefore about one minute for a bi-directional scanning embodiment.</p>
    <p>The scanner <b>11</b> can be further optimized to minimize the total acquisition time of the image <b>76</b> even more. The image acquisition time that can be achieved by the scanner <b>11</b> depends in part on the line rate of the line scan camera <b>18</b>. At the line rate of 27,600 lines per second of the present example, each line image is captured in about 0.04 milliseconds. Illumination from the light source that includes a 50 watt bulb, provides sufficient light to register a signal with sufficient signal-to-noise ratio on the line scan camera. At faster read-out rates, the exposure time per line is reduced and improvements and enhancements to the illumination system <b>28</b> of the scanner <b>11</b> may be required. Similarly, for applications of the scanner <b>11</b> in which less light is available, for example fluorescence, the effective line integration time must be increased. A TDI type of line scan camera provides an excellent means of increasing the effective integration time while maintaining a fast data read-out, without significant loss in the signal-to-noise ratio of the imagery data.</p>
    <p>Faster line scan cameras are commercially available and can be synchronized with faster motorized stages. Alternatively, selection of a linear array, such as linear array <b>74</b>, but with more than 1024 pixel elements <b>72</b> would reduce the number of image strips that have to be scanned to capture image <b>76</b>, and require fewer acceleration and deceleration cycles. Arrays comprising 2048 or more pixels often have proportionately smaller line rates than arrays with 1024 pixels. The reduced line rate of such larger arrays has the dual benefit of reducing the maximum velocity required by the motorized stage <b>14</b>, while increasing the line integration time, all without a reduction in total image capture time. The disadvantage of larger format linear arrays is that larger and more expensive optics and illumination systems are required to provide a high quality optical signal without vignetting and other optical aberrations. It is even possible to use multiple sensors to reduce the overall image acquisition time further.</p>
    <p>The scanner <b>11</b>, in its presently preferred embodiment, performs the digitization of the sample using microscope objective lenses having a relatively large depth of field so as to eliminate or minimize the cost and complexity of dynamic autofocus. The theoretical depth of field of an objective lens with numerical aperture (NA) of 0.15 is greater than twenty micrometers. The depth of field degrades to about five micrometers at NA equal to 0.3 and to about 1.8 micrometers at NA equal to 0.5. Depending on the application, the entire sample or portions of the sample <b>12</b> may be scanned without any need to adjust the focal plane, even when using objective lenses with moderate numerical apertures. Selection of relatively low NA objective lenses is consistent with one application of the scanner <b>11</b> in which it is used as an aid to extensive manual scanning of the sample <b>12</b>. Such conventional manual scanning is typically performed at low numerical apertures and low magnifications. The image <b>76</b> of the sample <b>12</b> can thus be used cost-effectively as the basis for a subsequently higher resolution interrogation of selected areas of the sample <b>12</b>. Based on the decision logic that comprises step <b>220</b>, either a conventional optical microscope as indicated in step <b>222</b> or a higher resolution embodiment of the scanner <b>11</b> as shown in step <b>224</b> can be used for the higher resolution review of the sample <b>12</b>. In the latter case, dynamic autofocus may be necessary. The high-resolution digitization of an entire sample <b>12</b>, such as a microscope slide, or large portions of the sample <b>12</b>, may not be practical or cost-effective using currently available computing power. However, future cost reductions of, and improvements in, data processing, memory, and data storage are expected to make high-resolution rapid digitization a reality.</p>
    <p>The need for focusing during scanning is indicated in step <b>206</b> and is very much dependent on the particular application of the scanner <b>11</b>. The scanner <b>11</b> uses a calibration method in which a standardized calibration sample of predetermined shape and size is digitized and the best focus is determined as a function of the x/y position of the motorized stage <b>14</b> using methods that are well known in the art. During the scanning and digitization process, the position of the microscope objective lens <b>16</b> is moved in accordance with this x/y focus map. Many different approaches to autofocus are known in the art that could be used to change the relative position of the microscope objective lens <b>16</b> with respect to the sample <b>12</b>. A vertical (z) axis component of the motorized stage <b>14</b> can be used for autofocus, although the presently preferred method of the invention is to move the microscope objective lens <b>16</b> instead using the commercially available piezo positioner <b>24</b>. While the total range of the piezo positioner <b>24</b> that is attached to the microscope objective lens <b>16</b> is relatively small, typically 100 micrometers, the bandwidth of a piezo is higher than that of a heavy motorized stage. The higher piezo bandwidth, typically 150 Hertz, is more desirable than a stiffer mechanical stage to minimize vibrations associated with small focus changes.</p>
    <p>One of the benefits of the scanner <b>11</b> is the rapid digitization of a large portion of the sample <b>12</b>, in order to provide the image <b>76</b> that can be processed efficiently and cost effectively when compared to labor intensive manual scanning of the sample <b>12</b>. Consistent with this, the scanner <b>11</b>, in its most basic embodiment, does not require the complexity of dynamic autofocus that is found in some conventional imaging systems. Pre-scanning and mapping of the best focus as a function of x/y position provides adequate focus for most applications. An alternate but more expensive embodiment of the scanner <b>11</b> provides extensive autofocus capabilities using an ancillary area scan camera such as the area scan camera <b>56</b>. More advanced calibration methods in which the spatial information for autofocusing is part of the sample <b>12</b>, for example, a glass microscope slide with calibration markings, are also possible.</p>
    <p>The overall quality of the image <b>76</b> is related to the ability of the sample <b>12</b> to be moved at substantially constant velocity. Sampling errors leading to image distortion can occur if the synchrony between the line scan camera <b>18</b> and the motorized stage <b>14</b> are not adequately preserved. Depending on the application and the need for image resolution, the scanner <b>11</b> supports different approaches for capturing data in synchrony with sample movement. Pre-scanning of a calibration target of known shape, for example a Ronchi ruling on a microscope slide, is one means by which the scanner <b>11</b> achieves constant sample velocities. Capabilities are provided in the data processor <b>20</b> to control both the time profile of position commands that are sent to the motorized stage <b>14</b> and to dynamically change the line data read-out rate of the line scan camera <b>18</b>. Since the majority of velocity related errors in the motorized stage <b>14</b> are reproducible, the optimization of the position profile or the optimization of the line scan camera <b>18</b> readout-rate, so as to obtain optimum images during the calibration scan is sufficient to provide excellent images when the sample <b>12</b> is subsequently scanned and digitized. An alternate embodiment of the scanner <b>11</b> that is more suitable for digitizing high-resolution images utilizes position feedback from the motorized stage <b>14</b>. The presently preferred embodiment of the scanner <b>11</b> is able to generate high quality images at low to moderate resolutions using calibration methods applied to a calibration target, without the need for feedback from expensive position encoders.</p>
    <p>Assuming that the 36,000 by 18,000 pixel image discussed previously as an example is captured at eight bits (one byte) of quantization per pixel, 648 million bytes (megabytes or MB) of RAM are required to store all of the data for all of the image strips <b>77</b> in their uncompressed raw format in the memory <b>36</b>. A plurality of image strips <b>77</b> are assembled into the image <b>76</b> during step <b>212</b>. There are many possible ways to assemble the image from the multiple image strips <b>77</b> acquired during the digitization of the sample <b>12</b>. The image assembly method of the currently preferred embodiment of the invention is to scan the sample <b>12</b> so as to slightly overlap the image strips <b>77</b>, for example by 10-20 pixels, and to use these overlapping pixels to fine-tune the x/y alignment of the image strips <b>77</b> into a contiguous image <b>76</b>. Using JPEG or other image compression methods, the data size of the image <b>76</b>, or the size of individual image strips <b>77</b>, can be reduced to five to ten percent, or less, of their original sizeâ€”in many cases without appreciable loss in the information content required by a particular application. The scanner <b>11</b> is also capable of eliminating from the image <b>76</b> those empty areas that do not contain any meaningful imagery data, further reducing the data storage requirements of the image <b>76</b>.</p>
    <p>One of the motivations for digitizing the sample <b>12</b> into a large contiguous image <b>76</b>, typically at the low to moderate optical resolutions that are used for manually scanning of the sample <b>12</b> under a conventional optical microscope, is to be able to apply specialized computer programs to the resulting imagery data. In step <b>214</b>, the analysis of the image <b>76</b> that represents a digitized portion of the sample <b>12</b>, comprises a variety of methods such as the application of morphological algorithms to identify and locate specific types of objects in the image <b>76</b>, for example, normal or abnormal cells. Other examples of analysis methods functions might include counting or measuring algorithms, or comparison or quality assurance algorithms to identify defects in the image <b>76</b>, or other types of algorithms to differentiate the image <b>76</b> from previously measured similar images. It should be clear that once the digitization of the image of the sample <b>12</b> has been completed, the analysis methods that comprise step <b>214</b> do not require that the sample <b>12</b> be physically present or available. The methods of step <b>214</b> can be applied automatically, or as part of an iterative process involving an operator who interactively reviews the image <b>76</b> as shown in step <b>216</b>, on the computer monitor <b>46</b> that is connected to the scanner <b>11</b> via the network <b>42</b>.</p>
    <p>A decision to return for a high resolution interrogation of selected areas of the sample <b>12</b>, using information obtained from the image <b>76</b>, for example object coordinates obtained from the analysis of the image <b>76</b> in steps <b>214</b> and <b>216</b>, is made as part of step <b>218</b>. If the decision logic in step <b>218</b> does not return the analysis to the sample <b>12</b>, then the operator's task is complete. If the operator wishes to return to the sample <b>12</b> as part of step <b>218</b>, the decision logic of step <b>220</b> determines whether the high-resolution interrogation is conducted on a conventional optical microscope as shown in step <b>222</b>, or using the scanner <b>11</b> as per step <b>224</b>. It should be realized that coordinate information obtained from a low to moderate resolution analysis of the image <b>76</b> is sufficient to guide the higher resolution interrogation of the sample <b>12</b> on a conventional microscope. The high-resolution review of the sample <b>12</b> using the scanner <b>11</b> comprises step <b>224</b> and includes the ability to remotely control the scanner <b>11</b> using many of the previously described features of the alternate embodiment of FIG. <b>2</b>. For example, the position of the motorized stage <b>14</b>, as well as the position of the piezo positioner <b>24</b>, and the illumination intensity of the light source <b>30</b> may be under remote control of the operator during step <b>224</b>. Real-time imagery, for example from the area scan camera <b>56</b> may be the basis for this review rather than digitized information from the sample <b>12</b>. Alternatively, the operator may select smaller portions of the sample <b>12</b> to be digitized at higher resolutions using either the line scan camera <b>18</b> or the area scan camera <b>56</b>. In the former case, the process would return to the steps <b>202</b> through <b>210</b> comprising the digitization of the sample <b>12</b> and then return directly to step <b>224</b>. Autofocus would be utilized as required based on the size of the portion of the sample <b>12</b> to be digitized and the depth of field of the microscope objective lens <b>16</b> that is utilized.</p>
    <p>Turning now to FIGS. 5A-5B, a schematic of an image viewing frame <b>100</b> according to the present invention is shown which represents one embodiment of a graphical user interface for displaying the image <b>76</b> on the display monitor <b>46</b> for purposes of interactive reviewing of the image <b>76</b> as per step <b>216</b>. The display of the image <b>76</b> that may be on the order of 36,000 by 18,000 pixels or larger, such as the image <b>76</b> described in a prior example, is not possible on a conventional monitor or display device such as display monitor <b>46</b>. The maximum number of pixels on currently available monitors such as a 19-inch Hitachi CM751 monitor is about 1600 by 1200 pixels, with 1024 by 768 pixels being more typical. Only portions of the image <b>76</b> can therefore be displayed at any one time at the full resolution of the entire image <b>76</b>. However, it is possible to display a macro image <b>102</b>, that is a reduced resolution version of the image <b>76</b> on the display monitor <b>46</b>, together with a higher resolution zoom image <b>104</b> that corresponds to a portion of the image <b>76</b>. The region of the macro image <b>102</b> that is displayed in the zoom image <b>104</b> is indicated on the macro image <b>102</b> itself as a zoom region <b>106</b> that can be interactively sized and moved over the entire macro image <b>102</b> by the operator. In its simplest embodiment, the zoom region <b>106</b> is a fixed rectangular region, but other icons or shapes, including manually drawn regions, could also be implemented. The zoom region <b>106</b> provides a critical reference between the macro image <b>102</b> and the zoom image <b>104</b>. An expanded view of the macro image <b>102</b> is shown in FIG. 5B, highlighting the presence, for illustrative purposes only, of eight schematic objects in the macro image <b>102</b>, shown here as four circles and four rectangles and designated as O<b>1</b> <b>108</b>, O<b>2</b> <b>110</b>, O<b>3</b> <b>112</b>, O<b>4</b> <b>114</b>, O<b>5</b> <b>116</b>, O<b>6</b> <b>118</b>, O<b>7</b> <b>120</b> and O<b>8</b> <b>122</b>. Each of the objects in a similar class, in this case similar shape, are distinguished from the other objects in the same class by a unique pattern. The use of very simple objects is intended only to illustrate and clarify the relationship between the different types of information displayed in the image viewing frame <b>100</b>. In this case, objects O<b>1</b> <b>108</b> and O<b>2</b> <b>112</b> are within the zoom region <b>106</b> and are thus displayed in the zoom image <b>104</b> that is part of an operator sizable zoom window <b>124</b>. The user has the ability, using icons that are part of a user command window <b>126</b> that is also part of the image viewing frame <b>100</b>, to increase the electronic zoom of the zoom image <b>104</b>. In one embodiment, these icons would be clicked using a mouse as a pointing device, however other means of pointing to an icon or invoking the function associated with an icon are known in the art and can be used here as well. Command icons may be incorporated into any of the windows that are part of the image viewing frame <b>100</b>, including the user command window <b>126</b>. For example, an electronic zoom icon can be part of the zoom window <b>124</b>. As the electronic zoom is increased, the size of the zoom region <b>106</b> is decreased on the macro image <b>102</b> so as to maintain a constant sized zoom image <b>104</b>.</p>
    <p>General information about any of the images can be displayed as part of the window corresponding to that image. For example, a macro window <b>128</b> might display the size of the macro image <b>102</b> in pixels, the size of the zoom region <b>106</b> in pixels, and the center pixel coordinates of the zoom region <b>106</b>. The zoom window <b>124</b> might display the amount of electronic zoom applied to the zoom image <b>104</b> together with a reference to a physical dimension. The size and shape of all windows such as the macro window <b>128</b> and the zoom window <b>124</b> can be changed interactively by the operator, similar to the way that any windows-based software operates, to accommodate different sample types with different aspect ratios.</p>
    <p>The results of step <b>214</b>, the application of specialized computer programs to the image <b>76</b>, are displayed in an object window <b>130</b> of the image viewing frame <b>100</b>. The object window <b>130</b> in the presently preferred embodiment of this invention comprises a multitude of object images, such as object image <b>132</b>, that each correspond to different portions of the large contiguous digital image <b>76</b>. Depending on their size, the object images <b>132</b> can be displayed as reduced resolution thumbprint images in an image gallery type arrangement. Clicking or pointing in one of the object images <b>132</b> also results in display of that the object image <b>132</b> at full resolution as the zoom image <b>104</b> that is part of the zoom window <b>124</b>. The criteria for displaying object images <b>132</b> in the object window <b>130</b> are based on the specialized computer programs that are applied to the image <b>76</b> in step <b>214</b>. In the present example, the specialized computer program would use simple boundary detection and segmentation algorithms to search the image <b>76</b> for the presence of all objects, in this case objects O<b>1</b> <b>108</b> through O<b>8</b> <b>122</b>, and display these objects as object images <b>132</b> in the object window <b>130</b>. A different specialized computer program, for example one that is capable of counting objects and distinguishing circles from squares, could then be applied to each of the object images <b>132</b> to provide a further level of classification. The results, in this case numerical results, could be displayed in an analysis window <b>134</b> of the image viewing frame <b>100</b>. The analysis window <b>134</b> in the present example could contain the total count of objects, in this case eight, as well as the total count of objects in either of the two classes of shapes, square and round. There are many types of specialized computer programs which could be applied to the image <b>76</b>, and many types of object images <b>132</b> which could be displayed in the object window <b>130</b> as a result of applying such specialized computer programs to the image <b>76</b>. Also, there are many types of more refined specialized computer programs that could be applied to the multitude of object images <b>132</b> to provide a higher level of object classification for subsequent display in the analysis window <b>134</b> in a variety of formats. The user commands window <b>126</b> of the image viewing frame <b>100</b> provides a window for interactively selecting the attributes of the image analysis that is performed as part of step <b>214</b>, and the criteria for the review of the image <b>76</b> in step <b>216</b>.</p>
    <p>Turning now to FIGS. 6A-6B, a schematic of a dynamic image viewing frame <b>150</b> which represents a graphical user interface according to the present invention for dynamically displaying the image <b>76</b> on the display monitor <b>46</b> for purposes of interactive reviewing the image <b>76</b> as per step <b>216</b>. The method of interactively reviewing the image <b>76</b> is intended to offer a digital imaging alternative to manually scanning the sample <b>12</b> at low to moderate resolutions under a conventional microscope while at the same time viewing the optical signal through the eyepieces of the microscope. One of the objects of the presently preferred invention is to provide a means of replacing manual scanning of the sample <b>12</b> by dynamically viewing the image <b>76</b> that is a digitization of a portion of the sample <b>12</b>, and preferably a diffraction-limited digitization of the sample <b>12</b>, on the display monitor <b>46</b>. There are many advantages to this approach, including a more comfortable and controlled viewing environment in which intelligent scanning and electronic zooming methods applied to the digital imagery data can increase the productivity of an operator charged with finding selected objects, for example abnormal cells, in the image. Specific objects that are identified can then be relocated, depending on the decision logic of steps <b>218</b> and <b>220</b>, under a conventional microscope or using the scanner <b>11</b>. Another advantage, afforded by the connection of the scanner <b>11</b> to the network <b>42</b>, is that the dynamic review of the image <b>76</b> can be performed remotely without requiring access to the sample <b>12</b>. Further, reviewing a digitized version of the sample <b>12</b>, namely the image <b>76</b>, lends itself to a variety of techniques for monitoring the specific areas of the image <b>76</b> that have been viewed. It is also straightforward to measure the time that the operator has spent viewing specific areas of the image <b>76</b>.</p>
    <p>The dynamic image viewing frame <b>150</b> includes the same macro image <b>102</b> within the macro window <b>128</b> as that in the previously discussed image viewing frame <b>100</b> of FIG. <b>5</b>A. The dynamic image viewing frame <b>150</b> also includes the zoom image <b>104</b> within the zoom window <b>124</b> and the zoom region <b>106</b> that relates the macro image <b>102</b> to the zoom image <b>104</b>, similar to the image viewing frame <b>100</b> described previously. While the size of all windows can be changed by the operator, the zoom window <b>124</b> in the dynamic image viewing frame <b>150</b> will typically be smaller than in the previously described image viewing frame <b>100</b> to allow a movie image <b>152</b> to be displayed with sufficient resolution within a movie window <b>154</b>. The movie image <b>152</b> is a full resolution dynamic image that is updated, as required, to simulate scanning the image <b>76</b> at a speed and direction determined by the operator. Returning again to the example of an image, such as the image <b>76</b>, that is 36,000 by 18,000 pixels, the movie image <b>152</b> could be generated by dividing the large image <b>76</b> into multiple movie image strips <b>156</b> that can be displayed at a user-selectable resolution on the display monitor <b>46</b>. For example, if the desired movie image resolution is 600 by 600 pixels, then the image <b>76</b> would be divided into thirty movie image strips <b>156</b> of 600 by 36,000 pixels, or alternatively, into sixty movie image strips <b>156</b> of 600 by 18,000 pixels. The movie image strip <b>156</b> is then displayed in the movie window <b>154</b> of the dynamic image viewing frame <b>150</b> so as to simulate scanning of the image <b>76</b> of the sample <b>12</b>. One way to simulate this scanning along either the x- or y-axis is to remove at least one previously shown column of pixels along one edge of the movie image <b>152</b> while adding at least one new column of image pixels along the opposing edge of the movie image <b>152</b>. A series of movie images <b>152</b> that differs from each other as described can comprise the individual frames of a digital movie that is played and displayed in the movie window <b>154</b> on the display monitor <b>46</b> using conventional browser software such as Media Player from Microsoft. This type of simulated. scanning is similar to what might be observed in the binoculars of a conventional microscope while manually scanning the sample <b>12</b>.</p>
    <p>One potential disadvantage of this type of simulated scanning of the image <b>76</b> of the sample <b>12</b> is that objects in the movie image <b>152</b> are typically in motion, making it more challenging for an operator to identify objects, or requiring the operator to execute multiple stop-and-go commands during the process of scanning the image <b>76</b> of the sample <b>12</b>. An alternate scanning method without the negative effects of motion can also be achieved with the scanner <b>11</b>. This alternate process comprises dividing the movie image strip <b>156</b> into contiguous image fields of, for example, 600 by 600 pixels each, and then displaying these contiguous images one at a time, preferably with some overlap between images, as a series of movie images <b>152</b>. The specific reference to a 600 by 600 pixel image is only meant to illustrate the principles of the idea, as images of other size can also be used. It should be apparent that there are many methods for dynamically reviewing the image <b>76</b> that provide an advantage over viewing the sample <b>12</b> on a conventional microscope. A scan tracker <b>158</b> could be shown on the macro image <b>102</b> itself to indicate those regions of the image <b>76</b> that have previously been viewed as movie images <b>152</b>. Since the operator can control the speed of the simulated scanning of the image <b>76</b>, the operator may spend more time on some areas than on others. The scan tracker <b>158</b> could be color coded, for example, to indicate relative dwell times, providing immediate feedback to the operator regarding the thoroughness of the review of the image <b>76</b>. Other more advanced simulated image scanning methods are also possible. For example, specialized computer algorithms might rank areas of the image <b>76</b> in terms of their importance and present the movie images <b>152</b> according to such relative importance criteria. For sparse images, empty areas could be skipped entirely, making the operator more efficient by not requiring viewing of essentially blank fields on the image <b>76</b>. Specialized computer algorithms could be employed to eliminate from the movie image <b>152</b> certain elements of the image <b>76</b>. For example, clutter or objects or cells that may not be important for the analysis of image <b>76</b>, or may not be relevant in making a diagnosis associated with image <b>76</b>, could be eliminated from the image <b>76</b> prior to the display of the movie image <b>152</b>. Ergonomic controllers such as joysticks, trackballs, gamepads, or footpedals could also be utilized to provide further performance improvements over clicking and pointing icons or buttons in the user commands window <b>126</b> of the dynamic image viewing frame <b>150</b>. Examples of functions that could be useful to dynamically review the image <b>76</b> include functions such as forward play, backward play, fast forward, rewind, pause, loop, and other functions similar to what can be found in a conventional video playing or editing environment. It should also be realized that depending on the circumstances, there may be a need to store individual image frames, object coordinates, or other data for future reference or subsequent review of the image <b>76</b>.</p>
    <p>While the invention has been illustrated and described by means of specific embodiments, it is to be understood that numerous changes and modifications may be made therein without departing from the spirit and scope of the invention as defined in the appended claims and equivalents thereof.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3643015">US3643015</a></td><td class="patent-data-table-td patent-date-value">Jun 19, 1970</td><td class="patent-data-table-td patent-date-value">Feb 15, 1972</td><td class="patent-data-table-td ">Davidovits Paul</td><td class="patent-data-table-td ">Scanning optical microscope</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4673988">US4673988</a></td><td class="patent-data-table-td patent-date-value">Apr 22, 1985</td><td class="patent-data-table-td patent-date-value">Jun 16, 1987</td><td class="patent-data-table-td ">E.I. Du Pont De Nemours And Company</td><td class="patent-data-table-td ">Electronic mosaic imaging process</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4700298">US4700298</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 14, 1984</td><td class="patent-data-table-td patent-date-value">Oct 13, 1987</td><td class="patent-data-table-td ">Branko Palcic</td><td class="patent-data-table-td ">Dynamic microscope image processing scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4744642">US4744642</a></td><td class="patent-data-table-td patent-date-value">Nov 7, 1986</td><td class="patent-data-table-td patent-date-value">May 17, 1988</td><td class="patent-data-table-td ">Olympus Optical Co., Ltd.</td><td class="patent-data-table-td ">Microscope</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4760385">US4760385</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 1986</td><td class="patent-data-table-td patent-date-value">Jul 26, 1988</td><td class="patent-data-table-td ">E. I. Du Pont De Nemours And Company</td><td class="patent-data-table-td ">Electronic mosaic imaging process</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4777525">US4777525</a></td><td class="patent-data-table-td patent-date-value">Dec 23, 1985</td><td class="patent-data-table-td patent-date-value">Oct 11, 1988</td><td class="patent-data-table-td ">Preston Jr Kendall</td><td class="patent-data-table-td ">For generating images of a specimen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4845552">US4845552</a></td><td class="patent-data-table-td patent-date-value">Aug 20, 1987</td><td class="patent-data-table-td patent-date-value">Jul 4, 1989</td><td class="patent-data-table-td ">Bruno Jaggi</td><td class="patent-data-table-td ">Quantitative light microscope using a solid state detector in the primary image plane</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4960999">US4960999</a></td><td class="patent-data-table-td patent-date-value">Feb 13, 1989</td><td class="patent-data-table-td patent-date-value">Oct 2, 1990</td><td class="patent-data-table-td ">Kms Fusion, Inc.</td><td class="patent-data-table-td ">Scanning and storage of electrophoretic records</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5086477">US5086477</a></td><td class="patent-data-table-td patent-date-value">Aug 7, 1990</td><td class="patent-data-table-td patent-date-value">Feb 4, 1992</td><td class="patent-data-table-td ">Northwest Technology Corp.</td><td class="patent-data-table-td ">Automated system for extracting design and layout information from an integrated circuit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5495535">US5495535</a></td><td class="patent-data-table-td patent-date-value">Jan 28, 1993</td><td class="patent-data-table-td patent-date-value">Feb 27, 1996</td><td class="patent-data-table-td ">Orbotech Ltd</td><td class="patent-data-table-td ">Method of inspecting articles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5578832">US5578832</a></td><td class="patent-data-table-td patent-date-value">Sep 2, 1994</td><td class="patent-data-table-td patent-date-value">Nov 26, 1996</td><td class="patent-data-table-td ">Affymetrix, Inc.</td><td class="patent-data-table-td ">Method and apparatus for imaging a sample on a device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5644356">US5644356</a></td><td class="patent-data-table-td patent-date-value">Feb 1, 1995</td><td class="patent-data-table-td patent-date-value">Jul 1, 1997</td><td class="patent-data-table-td ">Rank Cintel Limited</td><td class="patent-data-table-td ">High resolution film scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5672861">US5672861</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 17, 1995</td><td class="patent-data-table-td patent-date-value">Sep 30, 1997</td><td class="patent-data-table-td ">Ultrapointe Corporation</td><td class="patent-data-table-td ">Method and apparatus for automatic focusing of a confocal laser microscope</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5710835">US5710835</a></td><td class="patent-data-table-td patent-date-value">Nov 14, 1995</td><td class="patent-data-table-td patent-date-value">Jan 20, 1998</td><td class="patent-data-table-td ">The Regents Of The University Of California, Office Of Technology Transfer</td><td class="patent-data-table-td ">Storage and retrieval of large digital images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5714756">US5714756</a></td><td class="patent-data-table-td patent-date-value">Sep 13, 1996</td><td class="patent-data-table-td patent-date-value">Feb 3, 1998</td><td class="patent-data-table-td ">Park Scientific Instruments</td><td class="patent-data-table-td ">Scanning probe microscope having a single viewing device for on-axis and oblique angle views</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5793969">US5793969</a></td><td class="patent-data-table-td patent-date-value">Jan 11, 1996</td><td class="patent-data-table-td patent-date-value">Aug 11, 1998</td><td class="patent-data-table-td ">Neopath, Inc.</td><td class="patent-data-table-td ">Network review and analysis of computer encoded slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5834758">US5834758</a></td><td class="patent-data-table-td patent-date-value">Sep 4, 1996</td><td class="patent-data-table-td patent-date-value">Nov 10, 1998</td><td class="patent-data-table-td ">Affymetrix, Inc.</td><td class="patent-data-table-td ">Method and apparatus for imaging a sample on a device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5872591">US5872591</a></td><td class="patent-data-table-td patent-date-value">Feb 21, 1996</td><td class="patent-data-table-td patent-date-value">Feb 16, 1999</td><td class="patent-data-table-td ">Pakon, Inc.</td><td class="patent-data-table-td ">Film scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5912699">US5912699</a></td><td class="patent-data-table-td patent-date-value">Sep 7, 1994</td><td class="patent-data-table-td patent-date-value">Jun 15, 1999</td><td class="patent-data-table-td ">Neopath, Inc.</td><td class="patent-data-table-td ">Method and apparatus for rapid capture of focused microscopic images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5922282">US5922282</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 7, 1995</td><td class="patent-data-table-td patent-date-value">Jul 13, 1999</td><td class="patent-data-table-td ">Ledley; Robert S.</td><td class="patent-data-table-td ">Super fast tuberculosis diagnosis and sensitivity testing method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5943122">US5943122</a></td><td class="patent-data-table-td patent-date-value">Jul 10, 1998</td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td ">Nanometrics Incorporated</td><td class="patent-data-table-td ">Integrated optical measurement instruments</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5963314">US5963314</a></td><td class="patent-data-table-td patent-date-value">Oct 15, 1996</td><td class="patent-data-table-td patent-date-value">Oct 5, 1999</td><td class="patent-data-table-td ">Ultrapointe Corporation</td><td class="patent-data-table-td ">Laser imaging system for inspection and analysis of sub-micron particles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5991444">US5991444</a></td><td class="patent-data-table-td patent-date-value">Jun 25, 1997</td><td class="patent-data-table-td patent-date-value">Nov 23, 1999</td><td class="patent-data-table-td ">Sarnoff Corporation</td><td class="patent-data-table-td ">Method and apparatus for performing mosaic based image compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5999662">US5999662</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 1998</td><td class="patent-data-table-td patent-date-value">Dec 7, 1999</td><td class="patent-data-table-td ">Sarnoff Corporation</td><td class="patent-data-table-td ">System for automatically aligning images to form a mosaic image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6002789">US6002789</a></td><td class="patent-data-table-td patent-date-value">May 22, 1998</td><td class="patent-data-table-td patent-date-value">Dec 14, 1999</td><td class="patent-data-table-td ">Pilot Industries, Inc.</td><td class="patent-data-table-td ">Bacteria colony counter and classifier</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6005964">US6005964</a></td><td class="patent-data-table-td patent-date-value">Jan 24, 1996</td><td class="patent-data-table-td patent-date-value">Dec 21, 1999</td><td class="patent-data-table-td ">The Board Of Trustees Of The University Of Illinois</td><td class="patent-data-table-td ">Automatic machine vision microscope slide inspection system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6049421">US6049421</a></td><td class="patent-data-table-td patent-date-value">Jan 20, 1998</td><td class="patent-data-table-td patent-date-value">Apr 11, 2000</td><td class="patent-data-table-td ">Morphometrix Technologies Inc.</td><td class="patent-data-table-td ">Automated scanning of microscope slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6272235">US6272235</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 27, 1998</td><td class="patent-data-table-td patent-date-value">Aug 7, 2001</td><td class="patent-data-table-td ">Bacus Research Laboratories, Inc.</td><td class="patent-data-table-td ">Method and apparatus for creating a virtual microscope slide</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0339582A2?cl=en">EP0339582A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 25, 1989</td><td class="patent-data-table-td patent-date-value">Nov 2, 1989</td><td class="patent-data-table-td ">Olympus Optical Co., Ltd.</td><td class="patent-data-table-td ">Fluorescence microscope system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0871052A1?cl=en">EP0871052A1</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 1998</td><td class="patent-data-table-td patent-date-value">Oct 14, 1998</td><td class="patent-data-table-td ">Carl Zeiss</td><td class="patent-data-table-td ">Confocal microscope with movable scanning table</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1998039728A1?cl=en">WO1998039728A1</a></td><td class="patent-data-table-td patent-date-value">Mar 2, 1998</td><td class="patent-data-table-td patent-date-value">Sep 11, 1998</td><td class="patent-data-table-td ">Bacus Res Lab Inc</td><td class="patent-data-table-td ">Method and apparatus for creating a virtual microscope slide</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1998044446A1?cl=en">WO1998044446A1</a></td><td class="patent-data-table-td patent-date-value">Mar 2, 1998</td><td class="patent-data-table-td patent-date-value">Oct 8, 1998</td><td class="patent-data-table-td ">Bacus Res Lab Inc</td><td class="patent-data-table-td ">Method and apparatus for acquiring and reconstructing magnified specimen images from a computer-controlled microscope</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6924929">US6924929</a></td><td class="patent-data-table-td patent-date-value">Mar 28, 2003</td><td class="patent-data-table-td patent-date-value">Aug 2, 2005</td><td class="patent-data-table-td ">National Institute Of Radiological Sciences</td><td class="patent-data-table-td ">Microscope apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6982741">US6982741</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 23, 2001</td><td class="patent-data-table-td patent-date-value">Jan 3, 2006</td><td class="patent-data-table-td ">Leica Microsystems Wetzlar Gmbh</td><td class="patent-data-table-td ">Method and apparatus for coding live images in microscopy</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7079673">US7079673</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 5, 2002</td><td class="patent-data-table-td patent-date-value">Jul 18, 2006</td><td class="patent-data-table-td ">University Of Medicine &amp; Denistry Of Nj</td><td class="patent-data-table-td ">Systems for analyzing microtissue arrays</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7110586">US7110586</a></td><td class="patent-data-table-td patent-date-value">Jan 5, 2004</td><td class="patent-data-table-td patent-date-value">Sep 19, 2006</td><td class="patent-data-table-td ">Bacus Laboratories, Inc.</td><td class="patent-data-table-td ">Apparatus for remote control of a microscope</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7113625">US7113625</a></td><td class="patent-data-table-td patent-date-value">Jan 13, 2005</td><td class="patent-data-table-td patent-date-value">Sep 26, 2006</td><td class="patent-data-table-td ">U.S. Pathology Labs, Inc.</td><td class="patent-data-table-td ">System and method for image analysis of slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7116440">US7116440</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 26, 2004</td><td class="patent-data-table-td patent-date-value">Oct 3, 2006</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Image processing and analysis framework</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7120281">US7120281</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 16, 2002</td><td class="patent-data-table-td patent-date-value">Oct 10, 2006</td><td class="patent-data-table-td ">Leica Microsystems Cms Gmbh,</td><td class="patent-data-table-td ">Method; microscope system and software program for the observation of dynamic processes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7134093">US7134093</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 18, 2001</td><td class="patent-data-table-td patent-date-value">Nov 7, 2006</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Graphical user interface for direct control of display of data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7136539">US7136539</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 25, 2002</td><td class="patent-data-table-td patent-date-value">Nov 14, 2006</td><td class="patent-data-table-td ">Weyl John A</td><td class="patent-data-table-td ">Drug sample identification peripheral</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7146372">US7146372</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 16, 2004</td><td class="patent-data-table-td patent-date-value">Dec 5, 2006</td><td class="patent-data-table-td ">Olympus America Inc.</td><td class="patent-data-table-td ">Method and apparatus for creating a virtual microscope slide</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7155049">US7155049</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 31, 2001</td><td class="patent-data-table-td patent-date-value">Dec 26, 2006</td><td class="patent-data-table-td ">Trestle Acquisition Corp.</td><td class="patent-data-table-td ">System for creating microscopic digital montage images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7171030">US7171030</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 5, 2003</td><td class="patent-data-table-td patent-date-value">Jan 30, 2007</td><td class="patent-data-table-td ">University Of Medicine &amp; Denistry Of New Jersey</td><td class="patent-data-table-td ">Systems for analyzing microtissue arrays</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7212660">US7212660</a></td><td class="patent-data-table-td patent-date-value">Oct 26, 2005</td><td class="patent-data-table-td patent-date-value">May 1, 2007</td><td class="patent-data-table-td ">Clarient, Inc.</td><td class="patent-data-table-td ">System and method for finding regions of interest for microscopic digital montage imaging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7224839">US7224839</a></td><td class="patent-data-table-td patent-date-value">May 30, 2003</td><td class="patent-data-table-td patent-date-value">May 29, 2007</td><td class="patent-data-table-td ">Clarient, Inc.</td><td class="patent-data-table-td ">Compression packaged image transmission for telemicroscopy</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7235777">US7235777</a></td><td class="patent-data-table-td patent-date-value">Mar 1, 2006</td><td class="patent-data-table-td patent-date-value">Jun 26, 2007</td><td class="patent-data-table-td ">Carl Zeiss Jena Gmbh</td><td class="patent-data-table-td ">Light scanning microscope and use</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7248282">US7248282</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 12, 2003</td><td class="patent-data-table-td patent-date-value">Jul 24, 2007</td><td class="patent-data-table-td ">Fairfield Imaging Limited</td><td class="patent-data-table-td ">Microscopy imaging system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7253385">US7253385</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 18, 2005</td><td class="patent-data-table-td patent-date-value">Aug 7, 2007</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Microscope image acquiring system with separate microscope and imaging instrument controllers that operate cooperatively</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7257268">US7257268</a></td><td class="patent-data-table-td patent-date-value">Feb 9, 2004</td><td class="patent-data-table-td patent-date-value">Aug 14, 2007</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Systems and methods for image pattern recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7298885">US7298885</a></td><td class="patent-data-table-td patent-date-value">Nov 27, 2002</td><td class="patent-data-table-td patent-date-value">Nov 20, 2007</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Biological growth plate scanner with automated image processing profile selection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7298886">US7298886</a></td><td class="patent-data-table-td patent-date-value">Sep 5, 2003</td><td class="patent-data-table-td patent-date-value">Nov 20, 2007</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Counting biological agents on biological growth plates</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7312432">US7312432</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 8, 2002</td><td class="patent-data-table-td patent-date-value">Dec 25, 2007</td><td class="patent-data-table-td ">Dmetrix, Inc.</td><td class="patent-data-table-td ">Single axis illumination for multi-axis imaging system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7319031">US7319031</a></td><td class="patent-data-table-td patent-date-value">Nov 27, 2002</td><td class="patent-data-table-td patent-date-value">Jan 15, 2008</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Mounting platform for biological growth plate scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7351574">US7351574</a></td><td class="patent-data-table-td patent-date-value">Nov 27, 2002</td><td class="patent-data-table-td patent-date-value">Apr 1, 2008</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Apparatus for monitoring and detecting bacteria and other biological agents in food and laboratory samples</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7391894">US7391894</a></td><td class="patent-data-table-td patent-date-value">Jul 12, 2006</td><td class="patent-data-table-td patent-date-value">Jun 24, 2008</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Ais, Inc.</td><td class="patent-data-table-td ">System and method for remote navigation of a specimen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7417735">US7417735</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 5, 2005</td><td class="patent-data-table-td patent-date-value">Aug 26, 2008</td><td class="patent-data-table-td ">Idc, Llc</td><td class="patent-data-table-td ">Systems and methods for measuring color and contrast in specular reflective devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7418118">US7418118</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 27, 2001</td><td class="patent-data-table-td patent-date-value">Aug 26, 2008</td><td class="patent-data-table-td ">Furnas Steven J</td><td class="patent-data-table-td ">Method and apparatus for diagnosing pathogenic or allergenic microorganisms or microparticles at a remote location</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7421102">US7421102</a></td><td class="patent-data-table-td patent-date-value">Sep 6, 2005</td><td class="patent-data-table-td patent-date-value">Sep 2, 2008</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Ais, Inc.</td><td class="patent-data-table-td ">System and method for finding regions of interest for microscopic digital montage imaging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7426424">US7426424</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 11, 2005</td><td class="patent-data-table-td patent-date-value">Sep 16, 2008</td><td class="patent-data-table-td ">Murata Kikai Kabushiki Kaisha</td><td class="patent-data-table-td ">Moving body system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7428324">US7428324</a></td><td class="patent-data-table-td patent-date-value">Apr 21, 2006</td><td class="patent-data-table-td patent-date-value">Sep 23, 2008</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">System and method for data management in a linear-array-based microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7432486">US7432486</a></td><td class="patent-data-table-td patent-date-value">Jul 5, 2007</td><td class="patent-data-table-td patent-date-value">Oct 7, 2008</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Microscope image acquiring system with separate microscope and imaging instrument controllers that operate cooperatively</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7439478">US7439478</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 16, 2004</td><td class="patent-data-table-td patent-date-value">Oct 21, 2008</td><td class="patent-data-table-td ">Palantyr Research, Llc</td><td class="patent-data-table-td ">Imaging system, methodology, and applications employing reciprocal space optical design having at least one pixel being scaled to about a size of a diffraction-limited spot defined by a microscopic optical system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7446783">US7446783</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 12, 2001</td><td class="patent-data-table-td patent-date-value">Nov 4, 2008</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">System and method for manipulating an image on a screen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7457446">US7457446</a></td><td class="patent-data-table-td patent-date-value">Jul 1, 2005</td><td class="patent-data-table-td patent-date-value">Nov 25, 2008</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Fully automatic rapid microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7463761">US7463761</a></td><td class="patent-data-table-td patent-date-value">May 27, 2005</td><td class="patent-data-table-td patent-date-value">Dec 9, 2008</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Systems and methods for creating and viewing three dimensional virtual slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7486886">US7486886</a></td><td class="patent-data-table-td patent-date-value">Jan 11, 2006</td><td class="patent-data-table-td patent-date-value">Feb 3, 2009</td><td class="patent-data-table-td ">Olympus Corporation</td><td class="patent-data-table-td ">Photo-micrographing device and its control method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7496225">US7496225</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 4, 2003</td><td class="patent-data-table-td patent-date-value">Feb 24, 2009</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Biological growth plate scanner with automated intake</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7505616">US7505616</a></td><td class="patent-data-table-td patent-date-value">Jul 12, 2006</td><td class="patent-data-table-td patent-date-value">Mar 17, 2009</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Ais, Inc.</td><td class="patent-data-table-td ">System and method for reconstructing a diagnostic trajectory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7518652">US7518652</a></td><td class="patent-data-table-td patent-date-value">Apr 16, 2004</td><td class="patent-data-table-td patent-date-value">Apr 14, 2009</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Method and apparatus for pre-focus in a linear array based slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7528943">US7528943</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 27, 2005</td><td class="patent-data-table-td patent-date-value">May 5, 2009</td><td class="patent-data-table-td ">Kla-Tencor Technologies Corporation</td><td class="patent-data-table-td ">Method and apparatus for simultaneous high-speed acquisition of multiple images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7547874">US7547874</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 18, 2007</td><td class="patent-data-table-td patent-date-value">Jun 16, 2009</td><td class="patent-data-table-td ">Dmetrix, Inc.</td><td class="patent-data-table-td ">Single axis illumination for multi-axis imaging system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7570795">US7570795</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 18, 2006</td><td class="patent-data-table-td patent-date-value">Aug 4, 2009</td><td class="patent-data-table-td ">Mitutoyo Corporation</td><td class="patent-data-table-td ">Multi-region autofocus tool and mode</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7593581">US7593581</a></td><td class="patent-data-table-td patent-date-value">Oct 19, 2004</td><td class="patent-data-table-td patent-date-value">Sep 22, 2009</td><td class="patent-data-table-td ">Carl Zeiss Micro Imaging Gmbh</td><td class="patent-data-table-td ">Process for the acquisition of images from a sample with a microscope</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7596249">US7596249</a></td><td class="patent-data-table-td patent-date-value">Feb 24, 2003</td><td class="patent-data-table-td patent-date-value">Sep 29, 2009</td><td class="patent-data-table-td ">Olympus America Inc.</td><td class="patent-data-table-td ">Focusable virtual microscopy apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7601938">US7601938</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 27, 2006</td><td class="patent-data-table-td patent-date-value">Oct 13, 2009</td><td class="patent-data-table-td ">Palantyr Research, Llc</td><td class="patent-data-table-td ">Imaging system, methodology, and applications employing reciprocal space optical design</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7602524">US7602524</a></td><td class="patent-data-table-td patent-date-value">Sep 29, 2006</td><td class="patent-data-table-td patent-date-value">Oct 13, 2009</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Image processing and analysis framework</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7602996">US7602996</a></td><td class="patent-data-table-td patent-date-value">Feb 4, 2004</td><td class="patent-data-table-td patent-date-value">Oct 13, 2009</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Microscope system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7607106">US7607106</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 6, 2005</td><td class="patent-data-table-td patent-date-value">Oct 20, 2009</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">Image display system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7646495">US7646495</a></td><td class="patent-data-table-td patent-date-value">Aug 25, 2009</td><td class="patent-data-table-td patent-date-value">Jan 12, 2010</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">System and computer readable medium for pre-focus of digital slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7653260">US7653260</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 17, 2004</td><td class="patent-data-table-td patent-date-value">Jan 26, 2010</td><td class="patent-data-table-td ">Carl Zeis MicroImaging GmbH</td><td class="patent-data-table-td ">System and method of registering field of view</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7668362">US7668362</a></td><td class="patent-data-table-td patent-date-value">May 26, 2005</td><td class="patent-data-table-td patent-date-value">Feb 23, 2010</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">System and method for assessing virtual slide image quality</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7689024">US7689024</a></td><td class="patent-data-table-td patent-date-value">Dec 8, 2008</td><td class="patent-data-table-td patent-date-value">Mar 30, 2010</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Systems and methods for creating and viewing three dimensional virtual slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7702181">US7702181</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 23, 2005</td><td class="patent-data-table-td patent-date-value">Apr 20, 2010</td><td class="patent-data-table-td ">Ffei Limited</td><td class="patent-data-table-td ">Method and apparatus for forming a multiple focus stack image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7706632">US7706632</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 17, 2008</td><td class="patent-data-table-td patent-date-value">Apr 27, 2010</td><td class="patent-data-table-td ">Ffei Limited</td><td class="patent-data-table-td ">Method and apparatus for forming a multiple focus stack image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7738688">US7738688</a></td><td class="patent-data-table-td patent-date-value">Feb 26, 2004</td><td class="patent-data-table-td patent-date-value">Jun 15, 2010</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">System and method for viewing virtual slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7738689">US7738689</a></td><td class="patent-data-table-td patent-date-value">Sep 13, 2007</td><td class="patent-data-table-td patent-date-value">Jun 15, 2010</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Counting biological agents on biological growth plates</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7756357">US7756357</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 17, 2004</td><td class="patent-data-table-td patent-date-value">Jul 13, 2010</td><td class="patent-data-table-td ">Olympus Corporation</td><td class="patent-data-table-td ">Microscope system for obtaining high and low magnification images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7773126">US7773126</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 26, 2006</td><td class="patent-data-table-td patent-date-value">Aug 10, 2010</td><td class="patent-data-table-td ">Itt Manufacturing Enterprises, Inc.</td><td class="patent-data-table-td ">Mosaic image collector including an embedded atomic clock</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7787674">US7787674</a></td><td class="patent-data-table-td patent-date-value">Jan 27, 2006</td><td class="patent-data-table-td patent-date-value">Aug 31, 2010</td><td class="patent-data-table-td ">Aperio Technologies, Incorporated</td><td class="patent-data-table-td ">Systems and methods for viewing three dimensional virtual slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7792338">US7792338</a></td><td class="patent-data-table-td patent-date-value">Aug 11, 2005</td><td class="patent-data-table-td patent-date-value">Sep 7, 2010</td><td class="patent-data-table-td ">Olympus America Inc.</td><td class="patent-data-table-td ">Method and apparatus of mechanical stage positioning in virtual microscopy image capture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7801352">US7801352</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2006</td><td class="patent-data-table-td patent-date-value">Sep 21, 2010</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Image acquiring apparatus, image acquiring method, and image acquiring program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7804979">US7804979</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 30, 2004</td><td class="patent-data-table-td patent-date-value">Sep 28, 2010</td><td class="patent-data-table-td ">Bowe Bell + Howell Company</td><td class="patent-data-table-td ">Feeder control system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7822257">US7822257</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 8, 2006</td><td class="patent-data-table-td patent-date-value">Oct 26, 2010</td><td class="patent-data-table-td ">Olympus Corporation</td><td class="patent-data-table-td ">Observation apparatus and observation method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7826649">US7826649</a></td><td class="patent-data-table-td patent-date-value">Sep 22, 2008</td><td class="patent-data-table-td patent-date-value">Nov 2, 2010</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Data management in a linear-array-based microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7840908">US7840908</a></td><td class="patent-data-table-td patent-date-value">Sep 13, 2002</td><td class="patent-data-table-td patent-date-value">Nov 23, 2010</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">High resolution display of large electronically stored or communicated images with real time roaming</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7844125">US7844125</a></td><td class="patent-data-table-td patent-date-value">Mar 10, 2009</td><td class="patent-data-table-td patent-date-value">Nov 30, 2010</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Systems and methods for image pattern recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7860292">US7860292</a></td><td class="patent-data-table-td patent-date-value">Mar 24, 2010</td><td class="patent-data-table-td patent-date-value">Dec 28, 2010</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Creating and viewing three dimensional virtual slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7863552">US7863552</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 22, 2004</td><td class="patent-data-table-td patent-date-value">Jan 4, 2011</td><td class="patent-data-table-td ">Palantyr Research Llc</td><td class="patent-data-table-td ">Digital images and related methodologies</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7865008">US7865008</a></td><td class="patent-data-table-td patent-date-value">Feb 4, 2009</td><td class="patent-data-table-td patent-date-value">Jan 4, 2011</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Biological growth plate scanner with automated intake</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7869641">US7869641</a></td><td class="patent-data-table-td patent-date-value">May 27, 2009</td><td class="patent-data-table-td patent-date-value">Jan 11, 2011</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Gmbh</td><td class="patent-data-table-td ">System and method for finding regions of interest for microscopic digital montage imaging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7876948">US7876948</a></td><td class="patent-data-table-td patent-date-value">Jul 24, 2009</td><td class="patent-data-table-td patent-date-value">Jan 25, 2011</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Gmbh</td><td class="patent-data-table-td ">System for creating microscopic digital montage images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7885447">US7885447</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2006</td><td class="patent-data-table-td patent-date-value">Feb 8, 2011</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Image acquiring apparatus including macro image acquiring and processing portions, image acquiring method, and image acquiring program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7893988">US7893988</a></td><td class="patent-data-table-td patent-date-value">Apr 14, 2009</td><td class="patent-data-table-td patent-date-value">Feb 22, 2011</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Method for pre-focus of digital slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7901933">US7901933</a></td><td class="patent-data-table-td patent-date-value">Sep 8, 2010</td><td class="patent-data-table-td patent-date-value">Mar 8, 2011</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Methods of processing a biological growth plate in a biological growth plate scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7912267">US7912267</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 17, 2009</td><td class="patent-data-table-td patent-date-value">Mar 22, 2011</td><td class="patent-data-table-td ">Olympus Corporation</td><td class="patent-data-table-td ">Virtual-slide specimen image acquisition apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7916913">US7916913</a></td><td class="patent-data-table-td patent-date-value">Jun 26, 2009</td><td class="patent-data-table-td patent-date-value">Mar 29, 2011</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Gmbh</td><td class="patent-data-table-td ">System and method for reconstructing a diagnostic trajectory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7916916">US7916916</a></td><td class="patent-data-table-td patent-date-value">Sep 3, 2009</td><td class="patent-data-table-td patent-date-value">Mar 29, 2011</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Gmbh</td><td class="patent-data-table-td ">System and method for remote navigation of a specimen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7925067">US7925067</a></td><td class="patent-data-table-td patent-date-value">Aug 28, 2009</td><td class="patent-data-table-td patent-date-value">Apr 12, 2011</td><td class="patent-data-table-td ">Olympus America Inc.</td><td class="patent-data-table-td ">Focusable virtual microscopy apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7940998">US7940998</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 12, 2006</td><td class="patent-data-table-td patent-date-value">May 10, 2011</td><td class="patent-data-table-td ">Tripath Imaging, Inc.</td><td class="patent-data-table-td ">System and method for re-locating an object in a sample on a slide with a microscope imaging device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7941275">US7941275</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 2005</td><td class="patent-data-table-td patent-date-value">May 10, 2011</td><td class="patent-data-table-td ">Ventana Medical Systems, Inc.</td><td class="patent-data-table-td ">Method and system for automated detection of immunohistochemical (IHC) patterns</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7949168">US7949168</a></td><td class="patent-data-table-td patent-date-value">Oct 28, 2010</td><td class="patent-data-table-td patent-date-value">May 24, 2011</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Data management in a linear-array-based microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7957575">US7957575</a></td><td class="patent-data-table-td patent-date-value">Jun 8, 2010</td><td class="patent-data-table-td patent-date-value">Jun 7, 2011</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Counting biological agents on biological growth plates</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7978894">US7978894</a></td><td class="patent-data-table-td patent-date-value">Oct 22, 2010</td><td class="patent-data-table-td patent-date-value">Jul 12, 2011</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Fully automatic rapid microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7978898">US7978898</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 2010</td><td class="patent-data-table-td patent-date-value">Jul 12, 2011</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Image acquiring apparatus, image acquiring method, and image acquiring program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7979212">US7979212</a></td><td class="patent-data-table-td patent-date-value">Jan 31, 2005</td><td class="patent-data-table-td patent-date-value">Jul 12, 2011</td><td class="patent-data-table-td ">Ventana Medical Systems, Inc.</td><td class="patent-data-table-td ">Method and system for morphology based mitosis identification and classification of digital images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7986456">US7986456</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 30, 2005</td><td class="patent-data-table-td patent-date-value">Jul 26, 2011</td><td class="patent-data-table-td ">WestfÃ¤lische Wilhelms-UniversitÃ¤t MÃ¼nster</td><td class="patent-data-table-td ">Scanner arrangement and method for optically scanning an object</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8010555">US8010555</a></td><td class="patent-data-table-td patent-date-value">Jun 28, 2007</td><td class="patent-data-table-td patent-date-value">Aug 30, 2011</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">System and method for managing images over a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8036422">US8036422</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 6, 2011</td><td class="patent-data-table-td patent-date-value">Oct 11, 2011</td><td class="patent-data-table-td ">Bell And Howell, Llc</td><td class="patent-data-table-td ">Verification system and method in a document processing environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8036868">US8036868</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 2009</td><td class="patent-data-table-td patent-date-value">Oct 11, 2011</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Gmbh</td><td class="patent-data-table-td ">Intergrated systems and methods of virtual or live microscope slide presentation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8055042">US8055042</a></td><td class="patent-data-table-td patent-date-value">Dec 24, 2008</td><td class="patent-data-table-td patent-date-value">Nov 8, 2011</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Fully automatic rapid microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8059336">US8059336</a></td><td class="patent-data-table-td patent-date-value">May 2, 2008</td><td class="patent-data-table-td patent-date-value">Nov 15, 2011</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Rapid microscope scanner for volume image acquisition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8086077">US8086077</a></td><td class="patent-data-table-td patent-date-value">Jun 29, 2007</td><td class="patent-data-table-td patent-date-value">Dec 27, 2011</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Method for storing and retrieving large images via DICOM</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8094914">US8094914</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 15, 2005</td><td class="patent-data-table-td patent-date-value">Jan 10, 2012</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Microscope system and image processing method used for observation of a specimen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8094916">US8094916</a></td><td class="patent-data-table-td patent-date-value">Jan 12, 2011</td><td class="patent-data-table-td patent-date-value">Jan 10, 2012</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Biological growth plate scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8098884">US8098884</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 5, 2011</td><td class="patent-data-table-td patent-date-value">Jan 17, 2012</td><td class="patent-data-table-td ">Bell And Howell, Llc</td><td class="patent-data-table-td ">Verification system and method in a document processing environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8103082">US8103082</a></td><td class="patent-data-table-td patent-date-value">Feb 23, 2010</td><td class="patent-data-table-td patent-date-value">Jan 24, 2012</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Optimizing virtual slide image quality</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8106942">US8106942</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2006</td><td class="patent-data-table-td patent-date-value">Jan 31, 2012</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Image acquiring apparatus, image acquiring method, and image acquiring program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8107770">US8107770</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 2007</td><td class="patent-data-table-td patent-date-value">Jan 31, 2012</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Microscope system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8126250">US8126250</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2006</td><td class="patent-data-table-td patent-date-value">Feb 28, 2012</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Image acquiring apparatus, image acquiring method, and image acquiring program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8135236">US8135236</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 30, 2011</td><td class="patent-data-table-td patent-date-value">Mar 13, 2012</td><td class="patent-data-table-td ">Tri-Path Imaging, Inc.</td><td class="patent-data-table-td ">System and method for re-locating an object in a sample on a slide with a microscope imaging device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8164622">US8164622</a></td><td class="patent-data-table-td patent-date-value">Feb 27, 2007</td><td class="patent-data-table-td patent-date-value">Apr 24, 2012</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">System and method for single optical axis multi-detector microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8189891">US8189891</a></td><td class="patent-data-table-td patent-date-value">Aug 30, 2010</td><td class="patent-data-table-td patent-date-value">May 29, 2012</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Viewing three dimensional digital slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8199358">US8199358</a></td><td class="patent-data-table-td patent-date-value">Apr 22, 2009</td><td class="patent-data-table-td patent-date-value">Jun 12, 2012</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Digital slide image analysis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8260026">US8260026</a></td><td class="patent-data-table-td patent-date-value">May 4, 2011</td><td class="patent-data-table-td patent-date-value">Sep 4, 2012</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Counting biological agents on biological growth plates</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8290346">US8290346</a></td><td class="patent-data-table-td patent-date-value">Sep 25, 2008</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">Large format video archival, storage, and retrieval system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8306300">US8306300</a></td><td class="patent-data-table-td patent-date-value">Apr 8, 2011</td><td class="patent-data-table-td patent-date-value">Nov 6, 2012</td><td class="patent-data-table-td ">Olympus America Inc.</td><td class="patent-data-table-td ">Focusable virtual microscopy apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8331627">US8331627</a></td><td class="patent-data-table-td patent-date-value">Sep 26, 2008</td><td class="patent-data-table-td patent-date-value">Dec 11, 2012</td><td class="patent-data-table-td ">Agency For Science, Technology And Research</td><td class="patent-data-table-td ">Method and system for generating an entirely well-focused image of a large three-dimensional scene</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8341548">US8341548</a></td><td class="patent-data-table-td patent-date-value">Sep 28, 2009</td><td class="patent-data-table-td patent-date-value">Dec 25, 2012</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">Image display system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8385619">US8385619</a></td><td class="patent-data-table-td patent-date-value">Nov 8, 2011</td><td class="patent-data-table-td patent-date-value">Feb 26, 2013</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Fully automatic rapid microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8411970">US8411970</a></td><td class="patent-data-table-td patent-date-value">May 21, 2010</td><td class="patent-data-table-td patent-date-value">Apr 2, 2013</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">Method and system for determining statistical data for image pixels having a higher bit depth per band</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8417013">US8417013</a></td><td class="patent-data-table-td patent-date-value">Feb 27, 2009</td><td class="patent-data-table-td patent-date-value">Apr 9, 2013</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Information management in automated processing of biological growth media</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8428887">US8428887</a></td><td class="patent-data-table-td patent-date-value">Nov 9, 2011</td><td class="patent-data-table-td patent-date-value">Apr 23, 2013</td><td class="patent-data-table-td ">Ventana Medical Systems, Inc.</td><td class="patent-data-table-td ">Method for automated processing of digital images of tissue micro-arrays (TMA)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8456522">US8456522</a></td><td class="patent-data-table-td patent-date-value">Feb 22, 2011</td><td class="patent-data-table-td patent-date-value">Jun 4, 2013</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Achieving focus in a digital pathology system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8463741">US8463741</a></td><td class="patent-data-table-td patent-date-value">Sep 4, 2009</td><td class="patent-data-table-td patent-date-value">Jun 11, 2013</td><td class="patent-data-table-td ">Omnyx, LLC</td><td class="patent-data-table-td ">Digital pathology system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8467083">US8467083</a></td><td class="patent-data-table-td patent-date-value">Jun 12, 2012</td><td class="patent-data-table-td patent-date-value">Jun 18, 2013</td><td class="patent-data-table-td ">Aperio Technologies, Inc.</td><td class="patent-data-table-td ">Framework for processing the content of a digital image of a microscope sample</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8478073">US8478073</a></td><td class="patent-data-table-td patent-date-value">Dec 21, 2011</td><td class="patent-data-table-td patent-date-value">Jul 2, 2013</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Microscope system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8515683">US8515683</a></td><td class="patent-data-table-td patent-date-value">Apr 4, 2011</td><td class="patent-data-table-td patent-date-value">Aug 20, 2013</td><td class="patent-data-table-td ">Ventana Medical Systems, Inc.</td><td class="patent-data-table-td ">Method and system for automated detection of immunohistochemical (IHC) patterns</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8532383">US8532383</a></td><td class="patent-data-table-td patent-date-value">Sep 15, 2011</td><td class="patent-data-table-td patent-date-value">Sep 10, 2013</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">Method of processing a viewport within large format imagery</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8532397">US8532397</a></td><td class="patent-data-table-td patent-date-value">Sep 15, 2011</td><td class="patent-data-table-td patent-date-value">Sep 10, 2013</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">Method of creating a container file for large format imagery and organizing data within the container file</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8565480">US8565480</a></td><td class="patent-data-table-td patent-date-value">Dec 28, 2010</td><td class="patent-data-table-td patent-date-value">Oct 22, 2013</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">Creating and viewing three dimensional virtual slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8571286">US8571286</a></td><td class="patent-data-table-td patent-date-value">Apr 23, 2012</td><td class="patent-data-table-td patent-date-value">Oct 29, 2013</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">System and method for quality assurance in pathology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8582849">US8582849</a></td><td class="patent-data-table-td patent-date-value">Jul 15, 2011</td><td class="patent-data-table-td patent-date-value">Nov 12, 2013</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">Viewing digital slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8620047">US8620047</a></td><td class="patent-data-table-td patent-date-value">May 29, 2012</td><td class="patent-data-table-td patent-date-value">Dec 31, 2013</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">Viewing three dimensional digital slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8625920">US8625920</a></td><td class="patent-data-table-td patent-date-value">Jun 21, 2004</td><td class="patent-data-table-td patent-date-value">Jan 7, 2014</td><td class="patent-data-table-td ">Olympus America Inc.</td><td class="patent-data-table-td ">Method and apparatus for creating a virtual microscope slide</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8644690">US8644690</a></td><td class="patent-data-table-td patent-date-value">Sep 17, 2012</td><td class="patent-data-table-td patent-date-value">Feb 4, 2014</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">Large format video archival, storage, and retrieval system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8705825">US8705825</a></td><td class="patent-data-table-td patent-date-value">Feb 9, 2012</td><td class="patent-data-table-td patent-date-value">Apr 22, 2014</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">Signal to noise ratio in digital pathology image analysis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8731260">US8731260</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2012</td><td class="patent-data-table-td patent-date-value">May 20, 2014</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">Data management in a linear-array-based microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8743195">US8743195</a></td><td class="patent-data-table-td patent-date-value">Oct 23, 2009</td><td class="patent-data-table-td patent-date-value">Jun 3, 2014</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">Whole slide fluorescence scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8755579">US8755579</a></td><td class="patent-data-table-td patent-date-value">Feb 20, 2013</td><td class="patent-data-table-td patent-date-value">Jun 17, 2014</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">Fully automatic rapid microscope slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8755609">US8755609</a></td><td class="patent-data-table-td patent-date-value">Aug 9, 2013</td><td class="patent-data-table-td patent-date-value">Jun 17, 2014</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">Method of processing a viewport within large format imagery</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8759080">US8759080</a></td><td class="patent-data-table-td patent-date-value">Feb 2, 2009</td><td class="patent-data-table-td patent-date-value">Jun 24, 2014</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Back side plate illumination for biological growth plate scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8768106">US8768106</a></td><td class="patent-data-table-td patent-date-value">Aug 9, 2013</td><td class="patent-data-table-td patent-date-value">Jul 1, 2014</td><td class="patent-data-table-td ">Pixia Corp.</td><td class="patent-data-table-td ">Container file for large format imagery and method of creating the container file and organizing data within the container file</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8773520">US8773520</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 6, 2011</td><td class="patent-data-table-td patent-date-value">Jul 8, 2014</td><td class="patent-data-table-td ">Panasonic Healthcare Co., Ltd.</td><td class="patent-data-table-td ">Control device, control program, and control method for observation unit, and observation system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8774518">US8774518</a></td><td class="patent-data-table-td patent-date-value">Aug 1, 2012</td><td class="patent-data-table-td patent-date-value">Jul 8, 2014</td><td class="patent-data-table-td ">Nec Laboratories America, Inc.</td><td class="patent-data-table-td ">Digital pathology system with low-latency analytics</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8780401">US8780401</a></td><td class="patent-data-table-td patent-date-value">Jun 18, 2013</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">Systems and methods for analyzing digital slide images using algorithms constrained by parameter data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8781261">US8781261</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 2011</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Leica Biosystems Imaging, Inc.</td><td class="patent-data-table-td ">Storing and retrieving large images via DICOM</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100188424">US20100188424</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 14, 2009</td><td class="patent-data-table-td patent-date-value">Jul 29, 2010</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Image outputting system, image outputting method, and image outputting program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100208054">US20100208054</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 30, 2010</td><td class="patent-data-table-td patent-date-value">Aug 19, 2010</td><td class="patent-data-table-td ">Vivid Medical, Inc.</td><td class="patent-data-table-td ">Disposable microscope and portable display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110164125">US20110164125</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 6, 2011</td><td class="patent-data-table-td patent-date-value">Jul 7, 2011</td><td class="patent-data-table-td ">Sanyo Electric Co., Ltd.</td><td class="patent-data-table-td ">Control device, control program, and control method for observation unit, and observation system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110175995">US20110175995</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 30, 2011</td><td class="patent-data-table-td patent-date-value">Jul 21, 2011</td><td class="patent-data-table-td ">Tripath Imaging, Inc.</td><td class="patent-data-table-td ">System and method for re-locating an object in a sample on a slide with a microscope imaging device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130169975">US20130169975</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 26, 2012</td><td class="patent-data-table-td patent-date-value">Jul 4, 2013</td><td class="patent-data-table-td ">Hon Hai Precision Industry Co., Ltd.</td><td class="patent-data-table-td ">Computing device and method for scanning edges of an object</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130292559">US20130292559</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 29, 2013</td><td class="patent-data-table-td patent-date-value">Nov 7, 2013</td><td class="patent-data-table-td ">Life Technologies Corporation</td><td class="patent-data-table-td ">Spectral Calibration Method and System for Multiple Instruments</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE39977">USRE39977</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 11, 2005</td><td class="patent-data-table-td patent-date-value">Jan 1, 2008</td><td class="patent-data-table-td ">Chemimage Corporation</td><td class="patent-data-table-td ">Near infrared chemical imaging microscope</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE42220">USRE42220</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 25, 2007</td><td class="patent-data-table-td patent-date-value">Mar 15, 2011</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Microscopy</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1610166A1?cl=en">EP1610166A1</a></td><td class="patent-data-table-td patent-date-value">Jun 15, 2005</td><td class="patent-data-table-td patent-date-value">Dec 28, 2005</td><td class="patent-data-table-td ">Fujifilm Electronic Imaging Limited</td><td class="patent-data-table-td ">Method and apparatus for forming a multiple focus stack image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2004079523A2?cl=en">WO2004079523A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 27, 2004</td><td class="patent-data-table-td patent-date-value">Sep 16, 2004</td><td class="patent-data-table-td ">Aperio Technologies Inc</td><td class="patent-data-table-td ">Image processing and analysis framework</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2005119575A2?cl=en">WO2005119575A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 27, 2005</td><td class="patent-data-table-td patent-date-value">Dec 15, 2005</td><td class="patent-data-table-td ">Aperio Technologies Inc</td><td class="patent-data-table-td ">Systems and methods for creating and viewing three dimensional virtual slides</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2010126903A1?cl=en">WO2010126903A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 27, 2010</td><td class="patent-data-table-td patent-date-value">Nov 4, 2010</td><td class="patent-data-table-td ">Constitution Medical Investors, Inc.</td><td class="patent-data-table-td ">Systems and methods for analyzing body fluids</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013013117A1?cl=en">WO2013013117A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 20, 2012</td><td class="patent-data-table-td patent-date-value">Jan 24, 2013</td><td class="patent-data-table-td ">Mikroscan Technologies, Inc.</td><td class="patent-data-table-td ">Network-based pathology system with desktop slide scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2013152171A1?cl=en">WO2013152171A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 4, 2013</td><td class="patent-data-table-td patent-date-value">Oct 10, 2013</td><td class="patent-data-table-td ">Memorial Sloan-Kettering Cancer Center</td><td class="patent-data-table-td ">System, device, method and computer-accessible medium for imaging large areas with microscopic resolution</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S133000">382/133</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S128000">382/128</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G21K0007000000">G21K7/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G02B0021360000">G02B21/36</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01N0021170000">G01N21/17</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0001040000">H04N1/04</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G02B0021320000">G02B21/32</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G02B0021000000">G02B21/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0001000000">G06T1/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G02B0021260000">G02B21/26</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G02B21/002">G02B21/002</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G02B21/34">G02B21/34</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G02B21/365">G02B21/365</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G02B21/367">G02B21/367</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G02B21/32">G02B21/32</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=oXNlBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G02B21/26">G02B21/26</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G02B21/34</span>, <span class="nested-value">G02B21/26</span>, <span class="nested-value">G02B21/36V</span>, <span class="nested-value">G02B21/32</span>, <span class="nested-value">G02B21/00M4</span>, <span class="nested-value">G02B21/36V1</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Apr 25, 2014</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">LEICA BIOSYSTEMS IMAGING, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:APERIO TECHNOLOGIES, INC.;REEL/FRAME:032763/0113</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20130513</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 4, 2011</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1-7, 10-13, 18 AND 19 ARE CANCELLED. NEW CLAIM 20 IS ADDED AND DETERMINED TO BE PATENTABLE. CLAIMS 8, 9 AND 14-17 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 22, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 2, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20091123</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 24, 2009</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">APERIO TECHNOLOGIES, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:SOENKSEN, DIRK G.;REEL/FRAME:022299/0691</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20090220</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 25, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 21, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">APERIO TECHNOLOGIES, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">RELEASE BY SECURED PARTY;ASSIGNOR:BFI BUSINESS FINANCE;REEL/FRAME:017978/0147</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060718</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">APERIO TECHNOLOGIES, INC.,CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">RELEASE BY SECURED PARTY;ASSIGNOR:BFI BUSINESS FINANCE;REEL/FRAME:17978/147</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 9, 2005</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">BFI BUSINESS FINANCE, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:APERIO TECHNOLOGIES, INC.;REEL/FRAME:015980/0539</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20050321</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">BFI BUSINESS FINANCE,CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:APERIO TECHNOLOGIES, INC.;REEL/FRAME:15980/539</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 3, 2003</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">APERIO TECHNOLOGIES, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:SOENKSEN, DIRK G.;REEL/FRAME:014652/0486</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20031024</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">APERIO TECHNOLOGIES, INC. 1430 VANTAGE COURT, SUIT</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1jNVStg-lhOQp3j7p_yuWu9YkVTQ\u0026id=oXNlBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U1aoSGM7_bOYEqFpyjgxCHV0-OAlA\u0026id=oXNlBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2IPN_WRGLGOCsP3-AnT9iQGV4ATg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Fully_automatic_rapid_microscope_slide_s.pdf?id=oXNlBAABERAJ\u0026output=pdf\u0026sig=ACfU3U0HVjs16MImxNGbXMZ_Sum4jBP8uA"},"sample_url":"http://www.google.com/patents/reader?id=oXNlBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>