<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6993169 - System and method for finding regions of interest for microscopic digital ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="System and method for finding regions of interest for microscopic digital montage imaging"><meta name="DC.contributor" content="Arthur W. Wetzel" scheme="inventor"><meta name="DC.contributor" content="R. Gilbertson II John" scheme="inventor"><meta name="DC.contributor" content="Jeffrey A. Beckstead" scheme="inventor"><meta name="DC.contributor" content="Patricia A. Feineigle" scheme="inventor"><meta name="DC.contributor" content="Christopher R. Hauser" scheme="inventor"><meta name="DC.contributor" content="Frank A. Palmieri, Jr." scheme="inventor"><meta name="DC.contributor" content="Trestle Corporation" scheme="assignee"><meta name="DC.date" content="2001-1-11" scheme="dateSubmitted"><meta name="DC.description" content="A system for processing a thumbnail image from a microscope slide to determine tissue locations on the slide. The system comprises an image cropping component, a tissue finding component, and a scan control component. The image cropping component crops the thumbnail image and removes portions of the image that fall outside of determined slide boundaries. The cropped image from the image cropping component is inputted into the tissue finding component. The tissue finding component identifies tissue regions by applying a sequence of filters that incorporate knowledge of typical appearance and location of tissue and non-tissue slide regions. The tissue finding component outputs a tiling matrix whose values indicate which tiles should be imaged. The scan control component interprets the tiling matrix and transposes positions of the tiling matrix into actual stage coordinate for a microscopic imaging."><meta name="DC.date" content="2006-1-31" scheme="issued"><meta name="DC.relation" content="US:3999047" scheme="references"><meta name="DC.relation" content="US:4150360" scheme="references"><meta name="DC.relation" content="US:4199748" scheme="references"><meta name="DC.relation" content="US:4213036" scheme="references"><meta name="DC.relation" content="US:4523278" scheme="references"><meta name="DC.relation" content="US:4742558" scheme="references"><meta name="DC.relation" content="US:4779151" scheme="references"><meta name="DC.relation" content="US:4965725" scheme="references"><meta name="DC.relation" content="US:5068906" scheme="references"><meta name="DC.relation" content="US:5072382" scheme="references"><meta name="DC.relation" content="US:5073857" scheme="references"><meta name="DC.relation" content="US:5099521" scheme="references"><meta name="DC.relation" content="US:5107422" scheme="references"><meta name="DC.relation" content="US:5123056" scheme="references"><meta name="DC.relation" content="US:5143193" scheme="references"><meta name="DC.relation" content="US:5163095" scheme="references"><meta name="DC.relation" content="US:5216500" scheme="references"><meta name="DC.relation" content="US:5216596" scheme="references"><meta name="DC.relation" content="US:5218645" scheme="references"><meta name="DC.relation" content="US:5252487" scheme="references"><meta name="DC.relation" content="US:5257182" scheme="references"><meta name="DC.relation" content="US:5260871" scheme="references"><meta name="DC.relation" content="US:5268966" scheme="references"><meta name="DC.relation" content="US:5287272" scheme="references"><meta name="DC.relation" content="US:5297034" scheme="references"><meta name="DC.relation" content="US:5313532" scheme="references"><meta name="DC.relation" content="US:5333207" scheme="references"><meta name="DC.relation" content="US:5363258" scheme="references"><meta name="DC.relation" content="US:5428690" scheme="references"><meta name="DC.relation" content="US:5471561" scheme="references"><meta name="DC.relation" content="US:5473706" scheme="references"><meta name="DC.relation" content="US:5499097" scheme="references"><meta name="DC.relation" content="US:5505946" scheme="references"><meta name="DC.relation" content="US:5544650" scheme="references"><meta name="DC.relation" content="US:5544996" scheme="references"><meta name="DC.relation" content="US:5625765" scheme="references"><meta name="DC.relation" content="US:5636425" scheme="references"><meta name="DC.relation" content="US:5680694" scheme="references"><meta name="DC.relation" content="US:5687251" scheme="references"><meta name="DC.relation" content="US:5700125" scheme="references"><meta name="DC.relation" content="US:5768125" scheme="references"><meta name="DC.relation" content="US:5784162" scheme="references"><meta name="DC.relation" content="US:5796861" scheme="references"><meta name="DC.relation" content="US:5835620" scheme="references"><meta name="DC.relation" content="US:5838837" scheme="references"><meta name="DC.relation" content="US:5848177" scheme="references"><meta name="DC.relation" content="US:5933519" scheme="references"><meta name="DC.relation" content="US:6031930" scheme="references"><meta name="DC.relation" content="US:6081612" scheme="references"><meta name="DC.relation" content="US:6101265" scheme="references"><meta name="DC.relation" content="US:6151405" scheme="references"><meta name="DC.relation" content="US:6272235" scheme="references"><meta name="DC.relation" content="US:6498006" scheme="references"><meta name="DC.relation" content="WO:1992013308:A1" scheme="references"><meta name="citation_reference" content="&quot;An Efficient Method for Automated Segmentation of Histochemically Stained Slides&quot;, Gaddipati et al., IEEE-EMBC and CMBEC (1995)."><meta name="citation_reference" content="&quot;Analytical and Quantitative Cycology and Hiscology&quot;, Chromatin Texture Measurement by Markovian Analysis, Dawson et al."><meta name="citation_reference" content="&quot;Automatic Threshold Selection Using Histogram Quantization&quot;, Wang et al., Journal of BioMedical Optics, vol. 2, No. 2 (Apr. 1997)."><meta name="citation_reference" content="&quot;Biomarkers of Premalignant Breast Disease and Their Use as Surrogate Endpoints in Clinical Trials of Chemopreventive Agents&quot;, Boone et al., The Breast Journal, vol. 1, No. 4 (1995)."><meta name="citation_reference" content="&quot;Cervical Cell Recognition and Morphometric Grading by Image Analysis&quot;, James W. Bacus, Journal of Cellular Biochemistry, Supplement 23:33-42 (1995)."><meta name="citation_reference" content="&quot;Detection and Characterization of Microcalcifications in Mammographic Images&quot;, Pereira et al."><meta name="citation_reference" content="&quot;Development of Breast Cancer Chemopreventive Drugs&quot;, Kelloff et al., Journal of Cellular Biochemistry, 17G:2-13 (1993)."><meta name="citation_reference" content="&quot;Development of Surrogate Endpoint Biomarkers for Clinical Trials of Cancer Chemopreventive Agents: Relationships to Fundamental Properties of Preinvasive (Intraepithelial) Neoplasia&quot;, Boone et al., Journal of Cellular Biochemistry, Supplement 19:10-22 (1994)."><meta name="citation_reference" content="&quot;FSED-Feature Selective Edge Detection&quot;, Borga et al. (2000)."><meta name="citation_reference" content="&quot;Hough Spectrum and Geometric Texture Feature Analysis&quot;, Zhang et al."><meta name="citation_reference" content="&quot;Markovian Analysis of Cervical Cell Images&quot;, Norman J. Pressman, The Journal of Histochemistry and Cytochemistry, vol. 24., No. 1, pp. 138-144 (1976)."><meta name="citation_reference" content="&quot;Quantiation of Preinvasive Neoplastic Progression in Animal Models of Chemical Carcinogenesis&quot;, Bacus et al., Journal of Cellular Biochemistry Supplements 28/29:21-38 (1997)."><meta name="citation_reference" content="&quot;Segmentation of Mammograms Using Multiple Linked Self-Organizing Neural Networks&quot;, Dance et al., Med. Phys. 22(2) (Feb. 1995)."><meta name="citation_reference" content="&quot;The Image Processing Handbook&quot;, John C. Russ-2nd ed."><meta name="citation_patent_number" content="US:6993169"><meta name="citation_patent_application_number" content="US:09/758,037"><link rel="canonical" href="http://www.google.com/patents/US6993169"/><meta property="og:url" content="http://www.google.com/patents/US6993169"/><meta name="title" content="Patent US6993169 - System and method for finding regions of interest for microscopic digital montage imaging"/><meta name="description" content="A system for processing a thumbnail image from a microscope slide to determine tissue locations on the slide. The system comprises an image cropping component, a tissue finding component, and a scan control component. The image cropping component crops the thumbnail image and removes portions of the image that fall outside of determined slide boundaries. The cropped image from the image cropping component is inputted into the tissue finding component. The tissue finding component identifies tissue regions by applying a sequence of filters that incorporate knowledge of typical appearance and location of tissue and non-tissue slide regions. The tissue finding component outputs a tiling matrix whose values indicate which tiles should be imaged. The scan control component interprets the tiling matrix and transposes positions of the tiling matrix into actual stage coordinate for a microscopic imaging."/><meta property="og:title" content="Patent US6993169 - System and method for finding regions of interest for microscopic digital montage imaging"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("bqbtU4LFKMr-oQTK5YCACg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("NZL"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("bqbtU4LFKMr-oQTK5YCACg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("NZL"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6993169?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6993169"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=Q7VwBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6993169&amp;usg=AFQjCNG6ms0VBWNI80_hLjiv6uoFp9jonw" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6993169.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6993169.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20020090120"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US6993169"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6993169" style="display:none"><span itemprop="description">A system for processing a thumbnail image from a microscope slide to determine tissue locations on the slide. The system comprises an image cropping component, a tissue finding component, and a scan control component. The image cropping component crops the thumbnail image and removes portions of the...</span><span itemprop="url">http://www.google.com/patents/US6993169?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6993169 - System and method for finding regions of interest for microscopic digital montage imaging</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6993169 - System and method for finding regions of interest for microscopic digital montage imaging" title="Patent US6993169 - System and method for finding regions of interest for microscopic digital montage imaging"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6993169 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/758,037</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Jan 31, 2006</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jan 11, 2001</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jan 11, 2001</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7212660">US7212660</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7421102">US7421102</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7869641">US7869641</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20020090120">US20020090120</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20060029266">US20060029266</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20060045320">US20060045320</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20080123919">US20080123919</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20100002918">US20100002918</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2002056256A2">WO2002056256A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2002056256A3">WO2002056256A3</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09758037, </span><span class="patent-bibdata-value">758037, </span><span class="patent-bibdata-value">US 6993169 B2, </span><span class="patent-bibdata-value">US 6993169B2, </span><span class="patent-bibdata-value">US-B2-6993169, </span><span class="patent-bibdata-value">US6993169 B2, </span><span class="patent-bibdata-value">US6993169B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Arthur+W.+Wetzel%22">Arthur W. Wetzel</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22R.+Gilbertson+II+John%22">R. Gilbertson II John</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jeffrey+A.+Beckstead%22">Jeffrey A. Beckstead</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Patricia+A.+Feineigle%22">Patricia A. Feineigle</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Christopher+R.+Hauser%22">Christopher R. Hauser</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Frank+A.+Palmieri,+Jr.%22">Frank A. Palmieri, Jr.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Trestle+Corporation%22">Trestle Corporation</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6993169.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6993169.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6993169.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (54),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (14),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (7),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (11),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (14)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6993169&usg=AFQjCNHGs14dwQLxo8kq90xsPmLrwI_8hg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6993169&usg=AFQjCNFHFKqyRe7CeZoVLAUQ4pjnfgJFCw">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6993169B2%26KC%3DB2%26FT%3DD&usg=AFQjCNHjAucL9--jAugyO4Ua2Zv_vlWhaA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55511793" lang="EN" load-source="patent-office">System and method for finding regions of interest for microscopic digital montage imaging</invention-title></span><br><span class="patent-number">US 6993169 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50923478" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">A system for processing a thumbnail image from a microscope slide to determine tissue locations on the slide. The system comprises an image cropping component, a tissue finding component, and a scan control component. The image cropping component crops the thumbnail image and removes portions of the image that fall outside of determined slide boundaries. The cropped image from the image cropping component is inputted into the tissue finding component. The tissue finding component identifies tissue regions by applying a sequence of filters that incorporate knowledge of typical appearance and location of tissue and non-tissue slide regions. The tissue finding component outputs a tiling matrix whose values indicate which tiles should be imaged. The scan control component interprets the tiling matrix and transposes positions of the tiling matrix into actual stage coordinate for a microscopic imaging.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(5)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6993169B2/US06993169-20060131-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6993169B2/US06993169-20060131-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6993169B2/US06993169-20060131-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6993169B2/US06993169-20060131-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6993169B2/US06993169-20060131-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6993169B2/US06993169-20060131-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6993169B2/US06993169-20060131-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6993169B2/US06993169-20060131-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6993169B2/US06993169-20060131-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6993169B2/US06993169-20060131-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(12)</span></span></div><div class="patent-text"><div mxw-id="PCLM8953436" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A method for processing a low resolution image from a slide to determine a specimen locations on the slide, the method comprising:
<div class="claim-text">cropping the low resolution image to remove portions of the low resolution image that correspond to non-slide objects, said cropping including determining a location of at least one boundary by searching at least one interval corresponding to at least one boundary region;</div>
<div class="claim-text">inputting the cropped image into a tissue finding component, wherein the tissue finding component identifies a region containing the specimen by applying a filter that incorporates knowledge of typical appearance and location of specimen and non-specimen slide regions and outputs a matrix whose values indicate which regions of the slide should be imaged, the matrix not including portions of the image falling outside of the boundary; and</div>
<div class="claim-text">transposing positions of the matrix into actual stage coordinates, and capturing a microscopic image at those stage coordinates.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the cropping further comprises:
<div class="claim-text">determining location of a slide boundary by searching upper and lower intervals corresponding to boundary regions expected to contain upper and lower edges of the slide; and</div>
<div class="claim-text">not including in the matrix portions of the image falling outside of the determined slide boundary.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising converting a copy of the low resolution image to a grayscale image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the low resolution image is a color image, further comprising cropping the color low resolution image at the slide boundary.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising reducing the color image size to produce a small thumbnail image of the specimen for rapid visual identification.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising identifying pixel blocks in the cropped image that are likely to contain remaining slide edge features; and
<div class="claim-text">flagging these features as edges that should not be considered for high resolution imaging.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">converting a copy of the low resolution image to grayscale; and</div>
<div class="claim-text">analyzing at least one of mean and standard deviation of local pixel intensities to generate a threshold value.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, further comprising using the pixel intensity to differentiate tissue-containing regions from blank regions and other non-tissue containing regions.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising applying a morphological filter to the matrix to identify slide regions that can be imaged individually during a high-resolution imaging process.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the low resolution image is taken automatically without human intervention, the low resolution image is cropped automatically without human intervention, the specimen containing region is identified automatically without human intervention, and the positions of the matrix are transposed automatically without human intervention.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising flat-field correcting the image using a blank slide image to remove anomalies from the low resolution image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the components are software components executed by a computer.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES15975980" lang="EN" load-source="patent-office" class="description">
    <heading>FIELD OF THE INVENTION</heading> <p num="p-0002">The present invention relates to microscopic digital imaging of complete tissue sections for medical and research use. In particular it describes a method to find regions of interest for high throughput montage imaging of microscope slides using a standard microscope and cameras.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p num="p-0003">Laboratories in many biomedical specialties, such as anatomic pathology, hematology, and microbiology, examine tissue under a microscope for the presence and the nature of disease. In recent years, these laboratories have shown a growing interest in microscopic digital imaging as an adjunct to direct visual examination. Digital imaging has a number of advantages including the ability to document disease, share findings, collaborate (as in telemedicine), and analyze morphologic findings by computer. Though numerous studies have shown that digital image quality is acceptable for most clinical and research use, some aspects of microscopic digital imaging are limited in application.</p>
    <p num="p-0004">Perhaps the most important limitation to microscopic digital imaging is a “sub-sampling” problem encountered in all single frame images. The sub-sampling problem has two components: a field of view problem and a resolution-based problem. The field of view problem occurs when an investigator looking at a single frame cannot determine what lies outside the view of an image on a slide. The resolution-based problem occurs when the investigator looking at an image is limited to the resolution of the image. The investigator cannot “zoom in” for a closer examination or “zoom out” for a bird's eye view. Significantly, the field of view and resolution-based problems are inversely related. Thus, as one increases magnification to improve resolution, one decreases the field of view. For example, as a general rule, increasing magnification by a factor of two decreases the field of view by a factor of four.</p>
    <p num="p-0005">To get around the limitations of single frame imaging, developers have looked at two general options. The first option takes the general form of “dynamic-robotic” imaging, in which a video camera on the microscope transmits close to real time images to the investigator looking at a monitor, while the investigator operates the microscope by remote control. Though such systems have been used successfully for telepathology, they do not lend themselves to documentation, collaboration, or computer based analysis.</p>
    <p num="p-0006">The second option being investigated to overcome the limitations inherit in single frame imaging is a montage (or “virtual slide”) approach. In this method, a robotic microscope systematically scans the entire slide, taking an image at every field. The individual images are then “knitted” together in a software application to form a very large data set with very appealing properties. The robotic microscope can span the entire slide area at a resolution limited only by the power of the optical system and camera. Software exists to display this data set at any resolution on a computer screen, allowing the user to zoom in, zoom out, and pan around the data set as if using a physical microscope. The data set can be stored for documentation, shared over the Internet, or analyzed by computer programs.</p>
    <p num="p-0007">The “virtual slide” option has some limitations, however. One of the limitations is file size. For an average tissue section, the data generated at 0.33 um/pixel can be between two and five gigabytes uncompressed. In an extreme case, the data generated from one slide can be up to thirty-six gigabytes.</p>
    <p num="p-0008">A much more difficult limitation with the prior systems is an image capture time problem. Given an optical primary magnification of twenty and a two-third inch CCD, the system field of view is approximately (8.8 mm×6.6 mm)/20=0.44×0.33 mm. A standard microscope slide typically has a specimen area of 25 mm×50 mm or 12.5 square centimeters. This requires over eighty-six hundred fields to image this entire specimen region. However, the average tissue section for anatomic pathology is approximately 2.25 square centimeters. This only requires approximately fifteen hundred fields to cover the tissue alone, approximately 80 percent less fields.</p>
    <p num="p-0009">Traditionally, field rate in montage systems is limited by three factors—camera frame rate, image processing speed, and the rate of slide motion between fields. Given today's technology, the limiting factor can be reduced to only the camera frame rate. Using a 10 frame per second camera for the example above, imaging the entire slide would require 860 seconds or 14.33 minutes. If only the region of interest was imaged, this average time could be reduced to 150 seconds or 2.5 minutes; substantially increasing the slide throughput of an imaging system.</p>
    <p num="p-0010">Thus, a system is needed to automatically find the region of interest on a microscope slide and image only this region.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p num="p-0011">The present invention relates to a method and system for processing a thumbnail image from a microscope slide to determine tissue locations on the slide. The system comprises an image cropping component, a tissue finding component, and a scan control component. The image cropping component crops the thumbnail image and removes portions of the image that fall outside of determined slide boundaries. The cropped image from the image cropping component is inputted into the tissue finding component. The tissue finding component identifies tissue regions by applying a sequence of filters that incorporate knowledge of typical appearance and location of tissue and non-tissue slide regions. The tissue finding component outputs a tiling matrix whose values indicate which tiles should be imaged. The scan control component interprets the tiling matrix and transposes positions of the tiling matrix into actual stage coordinate for a microscopic imaging.</p>
    <p num="p-0012">Accordingly, it is an object of the invention to provide a microscopic imaging system for whole slide montage in which standard microscope optics, off the shelf cameras and a simple motorized stage can be used to select the region of interest, image only this section and produce perfectly aligned image tiles.</p>
    <p num="p-0013">The present invention uses a pre-scan process applied to a macroscopic image of the entire slide, to guide a high-resolution slide scanning process and ensure high-quality images of the entire specimen are acquired. The pre-scan process includes an image cropping component, a tissue-finding component, and a scan control component. The image cropping and tissue finding components identify interesting regions on the slide to be scanned. The scan control component generates the control parameters for a motorized microscopic imaging system.</p>
    <p num="p-0014">It is another object of the invention to use a high-resolution slide scanning process to control the operation of the motorized stage and camera. This process utilizes information gathered by the pre-scan process, namely the imaging regions, to control the positioning of the stage to image only the regions of interest and to ensure the individual images are well aligned.</p>
    <p num="p-0015">Additional features and advantages of the invention will be set forth in the description that follows, and in part will be apparent from the description, or may be learned by practice of the invention. The objectives and advantages of the invention to be realized and attained by the microscopic image capture system will be pointed out in the written description and claims hereof as well as the appended drawings.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0016">The accompanying drawings, which are included to provide a further understanding of the invention and are incorporated in and constitute a part of this specification, illustrate embodiments of the invention that together with the description serve to explain the principles of the invention.</p>
      <p num="p-0017"> <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates an isometric view of the system in a preferred embodiment;</p>
      <p num="p-0018"> <figref idrefs="DRAWINGS">FIG. 2</figref> represents the results of the macroscopic image after the cropping component has been applied to remove non-slide regions;</p>
      <p num="p-0019"> <figref idrefs="DRAWINGS">FIG. 3</figref> represents the results of the find tissue component; and</p>
      <p num="p-0020"> <figref idrefs="DRAWINGS">FIG. 4</figref> is an overlay of <figref idrefs="DRAWINGS">FIGS. 2 and 3</figref> representing the regions of the slide to be imaged.</p>
    </description-of-drawings> <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p num="p-0021">Reference will now be made in detail to the preferred embodiments of the present invention, examples of which are illustrated in the accompanying drawings. The following paragraphs describe the functionality of the inventive system and method for high throughput montage imaging of microscope slides using a standard microscope and cameras.</p>
    <p num="p-0022"> <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates a preferred embodiment of the invention. In this embodiment, a slide <b>112</b> to be imaged is placed on a thumbnail imaging position in a slide holder on a motorized stage <b>102</b>. A single frame image containing the entire slide is taken with a macro camera <b>106</b>. This low-resolution image is analyzed by software components to determine the locations of tissue on slide <b>112</b>. This information can then be used to generate control parameters for stage <b>102</b> and microscopic camera <b>104</b> to ensure that the scanning process captures high quality images of only the tissue regions, substantially reducing the time to scan an average slide.</p>
    <p num="p-0023">As is obvious to one skilled in the art, although capturing the single macroscopic image saves time, it is not necessary for the operation of the invention. Multiple macroscopic images may be required to generate control parameters to the accuracy required based on the ratio of the macroscopic to microscopic magnifications and the camera specifications of each camera, if separate cameras are utilized.</p>
    <p num="p-0024">Specifically in a preferred embodiment, a pre-scan processing of the low-resolution or thumbnail image includes an image cropping component, a tissue-finding component and a scan control component. The image cropping component and tissue finding component identify tissue regions on the slide to be scanned. The scan control component generates the necessary control parameters to scan only the regions of interest under the microscopic optics.</p>
    <p num="p-0025">The first step in processing the thumbnail image consists of flat-field correcting the macroscopic thumbnail image using a similar image obtained from the same camera and a blank slide. This removes any spatial light anomalies from the thumbnail image, which may reduce the efficiency of the tissue-finding component. Given the format, or size, of the camera and the aspect ratio of the slide, a portion of the image will contain non-slide objects such as the slide carrier. To remove these features, the thumbnail image is cropped to extract only the slide information.</p>
    <p num="p-0026">The image cropping is accomplished via a two-pass process. The first pass determines an approximate location of the slide boundary, and the second pass fine-tunes this estimate. The search for the boundary is conducted over upper and lower intervals corresponding to the regions expected to contain the upper and lower slide edges, respectively. For this discussion, the slide or region of interest is assumed to be positioned near the center, vertically, in the thumbnail image. To facilitate this and subsequent processing steps, a copy of the thumbnail image is converted to grayscale. The portion of the image falling outside of the identified slide boundary is removed. It should be noted that the original color image is also cropped at the estimated edge locations, and then is uniformly reduced in size to produce a small thumbnail image of the slide for rapid, visual slide identification.</p>
    <p num="p-0027">Since the slide may not be oriented perfectly horizontal in the original thumbnail image, the identified slide edges are likely to lie at an angle. Thus, even after cropping, there may be remnants of the slide edges or cover slip in the cropped image. Therefore, the image-cropping component attempts to identify pixel blocks that likely contain these remaining edges and flags these blocks as edges that will not be considered for high resolution imaging by the tissue finding component.</p>
    <p num="p-0028">The resulting cropped grayscale image generated by the image-cropping component serves as input to the tissue finding component. This component locates regions in the thumbnail image that contain tissue of interest to a specialist. In order to minimize the time and storage space required to accomplish high-resolution slide imaging, the inventive system captures only those regions of the slide that contain tissue. This approach requires that regions containing tissue be identified in the thumbnail image.</p>
    <p num="p-0029">The tissue finding component identifies tissue regions via a sequence of filters that incorporate knowledge of the typical appearance and location of tissue and non-tissue slide regions. Initial filtering steps analyze the mean and standard deviation of the local pixel intensities. Pixel mean intensities are used to differentiate tissue-containing regions from blank and other non-tissue regions, such as those containing the slide label or other markings. The standard deviation data represents the amount of variation in pixel values and thus is a good indicator of the border between tissue and the blank slide. The mean and standard deviation data is combined to generate a threshold value that is used to make an initial classification of tissue versus non-tissue. Subsequently, morphological filters are applied to refine the classification based on the size and position of neighboring groups of potential tissue pixels.</p>
    <p num="p-0030">The filters which comprise the tissue finding component process the pixels of the cropped grayscale thumbnail image in groups that correspond to slide regions, or tiles, that can be imaged individually during the high-resolution scanning process. These filters ensure that tiles only partially filled with tissue are classified as tissue-containing tiles. The final output of the filter sequence is a tiling matrix whose values indicate which tiles should be imaged; the tiling matrix subsequently guides the high-resolution scanning process.</p>
    <p num="p-0031">The above description was based on using the mean and standard deviation of the local pixels as the basis for detecting regions of interest. It is obvious to one skill in the art that other image characteristics can be also used to identify the specimen from non-items of interest such as dust and scratches.</p>
    <p num="p-0032">This description was also based on processing a gray scale macroscopic image, the same processing tools can be applied to each of the color components (traditionally, red, green and blue) of a color image. Additional processing tools can also be applied between the color components to refine the tissue finding accuracy and to remove features such as labels and writing that are not critical to the application.</p>
    <p num="p-0033">An example of the image cropping and find tissue processing are shown in <figref idrefs="DRAWINGS">FIGS. 2</figref>, <b>3</b> and <b>4</b>. <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates the macroscopic image after flat-field correction and image cropping. <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates the results of the find tissue component. The resulting tile matrix shown in <figref idrefs="DRAWINGS">FIG. 3</figref> has a one-to-one correspondence to the field of view of the microscopic camera. White pixels (binary 1) signify field to be capture and black pixels represent regions not to image. <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates an overlay <figref idrefs="DRAWINGS">FIGS. 2 and 3</figref> representing the sections of the slide to be imaged. For this application (anatomical pathology), it is imperative to image all suspect regions that may contain tissue so conservative criteria were used in the find tissue component, resulting in cover slip edges and writing etched into the slide to be identified as to be imaged. The savings in the acquisition time is representative by the ratio of the white to black areas of <figref idrefs="DRAWINGS">FIG. 3</figref>. For this image, only 53% of the slide region is to be imaged, including the label and cover slip edges, and etched writing on the slide.</p>
    <p num="p-0034">At the completion of the find tissue component, the scan control component interprets the find tissue tile matrix (<figref idrefs="DRAWINGS">FIG. 3</figref>) and transposes the positions into actual stage coordinates for the microscopic imaging. A program running on a host computer controls the operation by communicating with a stage controller and microscopic camera <b>104</b>. Actual scanning can occur in any fashion such as by rows or columns, or in a step fashion to image neighboring areas.</p>
    <p num="p-0035">The foregoing description has been directed to specific embodiments of this invention. It will be apparent, however, that other variations and modifications may be made to the described embodiments, with the attainment of some or all of their advantages. Therefore, it is the object of the appended claims to cover all such variations and modifications as come within the true spirit and scope of the invention.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3999047">US3999047</a></td><td class="patent-data-table-td patent-date-value">Nov 25, 1974</td><td class="patent-data-table-td patent-date-value">Dec 21, 1976</td><td class="patent-data-table-td ">Green James E</td><td class="patent-data-table-td ">Method and apparatus utilizing color algebra for analyzing scene regions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4150360">US4150360</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 14, 1977</td><td class="patent-data-table-td patent-date-value">Apr 17, 1979</td><td class="patent-data-table-td ">Grumman Aerospace Corporation</td><td class="patent-data-table-td ">Method and apparatus for classifying biological cells</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4199748">US4199748</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 1978</td><td class="patent-data-table-td patent-date-value">Apr 22, 1980</td><td class="patent-data-table-td ">Rush-Presbyterian-St. Luke&#39;s Medical Center</td><td class="patent-data-table-td ">Automated method and apparatus for classification of cells with application to the diagnosis of anemia</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4213036">US4213036</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 1977</td><td class="patent-data-table-td patent-date-value">Jul 15, 1980</td><td class="patent-data-table-td ">Grumman Aerospace Corporation</td><td class="patent-data-table-td ">Method for classifying biological cells</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4523278">US4523278</a></td><td class="patent-data-table-td patent-date-value">Jun 7, 1984</td><td class="patent-data-table-td patent-date-value">Jun 11, 1985</td><td class="patent-data-table-td ">Prof. Dr.-Ing. Werner H. Bloss</td><td class="patent-data-table-td ">Method of automatic detection of cells and determination of cell features from cytological smear preparations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4742558">US4742558</a></td><td class="patent-data-table-td patent-date-value">Feb 7, 1985</td><td class="patent-data-table-td patent-date-value">May 3, 1988</td><td class="patent-data-table-td ">Nippon Telegraph &amp; Telephone Public Corporation</td><td class="patent-data-table-td ">Image information retrieval/display apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4779151">US4779151</a></td><td class="patent-data-table-td patent-date-value">Jul 31, 1985</td><td class="patent-data-table-td patent-date-value">Oct 18, 1988</td><td class="patent-data-table-td ">Odetics, Inc.</td><td class="patent-data-table-td ">Robotic tape cassette handling system with rotary loading and unloading mechanism</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4965725">US4965725</a></td><td class="patent-data-table-td patent-date-value">Apr 8, 1988</td><td class="patent-data-table-td patent-date-value">Oct 23, 1990</td><td class="patent-data-table-td ">Nueromedical Systems, Inc.</td><td class="patent-data-table-td ">Neural network based automated cytological specimen classification system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5068906">US5068906</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 1989</td><td class="patent-data-table-td patent-date-value">Nov 26, 1991</td><td class="patent-data-table-td ">Toa Medical Electronics Co., Ltd.</td><td class="patent-data-table-td ">Processor for extracting and memorizing cell images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5072382">US5072382</a></td><td class="patent-data-table-td patent-date-value">Oct 2, 1989</td><td class="patent-data-table-td patent-date-value">Dec 10, 1991</td><td class="patent-data-table-td ">Kamentsky Louis A</td><td class="patent-data-table-td ">Methods and apparatus for measuring multiple optical properties of biological specimens</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5073857">US5073857</a></td><td class="patent-data-table-td patent-date-value">Aug 28, 1989</td><td class="patent-data-table-td patent-date-value">Dec 17, 1991</td><td class="patent-data-table-td ">Accuron Corporation</td><td class="patent-data-table-td ">Method and apparatus for cell analysis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5099521">US5099521</a></td><td class="patent-data-table-td patent-date-value">Nov 21, 1988</td><td class="patent-data-table-td patent-date-value">Mar 24, 1992</td><td class="patent-data-table-td ">Toa Medical Electronics Co., Ltd.</td><td class="patent-data-table-td ">Cell image processing method and apparatus therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5107422">US5107422</a></td><td class="patent-data-table-td patent-date-value">Sep 14, 1990</td><td class="patent-data-table-td patent-date-value">Apr 21, 1992</td><td class="patent-data-table-td ">Kamentsky Louis A</td><td class="patent-data-table-td ">Method and apparatus for measuring multiple optical properties of biological specimens</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5123056">US5123056</a></td><td class="patent-data-table-td patent-date-value">Feb 2, 1990</td><td class="patent-data-table-td patent-date-value">Jun 16, 1992</td><td class="patent-data-table-td ">Siemens Medical Systems, Inc.</td><td class="patent-data-table-td ">Whole-leg x-ray image processing and display techniques</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5143193">US5143193</a></td><td class="patent-data-table-td patent-date-value">May 14, 1991</td><td class="patent-data-table-td patent-date-value">Sep 1, 1992</td><td class="patent-data-table-td ">Ronald Geraci</td><td class="patent-data-table-td ">Automated library article terminal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5163095">US5163095</a></td><td class="patent-data-table-td patent-date-value">Feb 26, 1991</td><td class="patent-data-table-td patent-date-value">Nov 10, 1992</td><td class="patent-data-table-td ">Toa Medical Electronics Co., Ltd.</td><td class="patent-data-table-td ">Processor for extracting and memorizing cell images, and method of practicing same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5216500">US5216500</a></td><td class="patent-data-table-td patent-date-value">Jul 15, 1991</td><td class="patent-data-table-td patent-date-value">Jun 1, 1993</td><td class="patent-data-table-td ">Rj Lee Group, Inc.</td><td class="patent-data-table-td ">Simultaneously recording of video image and microscope stage position data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5216596">US5216596</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 5, 1990</td><td class="patent-data-table-td patent-date-value">Jun 1, 1993</td><td class="patent-data-table-td ">Corabi International Telemetrics, Inc.</td><td class="patent-data-table-td ">Telepathology diagnostic network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5218645">US5218645</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 1991</td><td class="patent-data-table-td patent-date-value">Jun 8, 1993</td><td class="patent-data-table-td ">Cell Analysis Systems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for separating cell objects for analysis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5252487">US5252487</a></td><td class="patent-data-table-td patent-date-value">Jan 27, 1993</td><td class="patent-data-table-td patent-date-value">Oct 12, 1993</td><td class="patent-data-table-td ">Cell Analysis Systems, Inc.</td><td class="patent-data-table-td ">Quantitative analysis of tumors</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5257182">US5257182</a></td><td class="patent-data-table-td patent-date-value">Jan 29, 1991</td><td class="patent-data-table-td patent-date-value">Oct 26, 1993</td><td class="patent-data-table-td ">Neuromedical Systems, Inc.</td><td class="patent-data-table-td ">Morphological classification system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5260871">US5260871</a></td><td class="patent-data-table-td patent-date-value">Jul 31, 1991</td><td class="patent-data-table-td patent-date-value">Nov 9, 1993</td><td class="patent-data-table-td ">Mayo Foundation For Medical Education And Research</td><td class="patent-data-table-td ">Method and apparatus for diagnosis of breast tumors</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5268966">US5268966</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 1991</td><td class="patent-data-table-td patent-date-value">Dec 7, 1993</td><td class="patent-data-table-td ">International Remote Imaging Systems, Inc.</td><td class="patent-data-table-td ">Method of differentiating particles based upon a dynamically changing threshold</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5287272">US5287272</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 11, 1989</td><td class="patent-data-table-td patent-date-value">Feb 15, 1994</td><td class="patent-data-table-td ">Neuromedical Systems, Inc.</td><td class="patent-data-table-td ">Automated cytological specimen classification system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5297034">US5297034</a></td><td class="patent-data-table-td patent-date-value">Jan 5, 1993</td><td class="patent-data-table-td patent-date-value">Mar 22, 1994</td><td class="patent-data-table-td ">Corabi International Telemetrics, Inc.</td><td class="patent-data-table-td ">Telepathology diagnostic network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5313532">US5313532</a></td><td class="patent-data-table-td patent-date-value">Oct 28, 1991</td><td class="patent-data-table-td patent-date-value">May 17, 1994</td><td class="patent-data-table-td ">Massachusetts Institute Of Technology</td><td class="patent-data-table-td ">Recognition of patterns in images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5333207">US5333207</a></td><td class="patent-data-table-td patent-date-value">Sep 14, 1992</td><td class="patent-data-table-td patent-date-value">Jul 26, 1994</td><td class="patent-data-table-td ">Neuromedical Systems, Inc.</td><td class="patent-data-table-td ">Inspection apparatus and method with inspection auditing for images presented on a display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5363258">US5363258</a></td><td class="patent-data-table-td patent-date-value">May 19, 1993</td><td class="patent-data-table-td patent-date-value">Nov 8, 1994</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Robotic manipulator with ejector tab</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5428690">US5428690</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 18, 1992</td><td class="patent-data-table-td patent-date-value">Jun 27, 1995</td><td class="patent-data-table-td ">Becton Dickinson And Company</td><td class="patent-data-table-td ">Method and apparatus for automated assay of biological specimens</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5471561">US5471561</a></td><td class="patent-data-table-td patent-date-value">May 19, 1993</td><td class="patent-data-table-td patent-date-value">Nov 28, 1995</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Automated storage library with rotatable arm and oblique angle effectors</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5473706">US5473706</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 14, 1994</td><td class="patent-data-table-td patent-date-value">Dec 5, 1995</td><td class="patent-data-table-td ">Becton Dickinson And Company</td><td class="patent-data-table-td ">Method and apparatus for automated assay of biological specimens</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5499097">US5499097</a></td><td class="patent-data-table-td patent-date-value">Sep 19, 1994</td><td class="patent-data-table-td patent-date-value">Mar 12, 1996</td><td class="patent-data-table-td ">Neopath, Inc.</td><td class="patent-data-table-td ">Method and apparatus for checking automated optical system performance repeatability</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5505946">US5505946</a></td><td class="patent-data-table-td patent-date-value">Apr 1, 1994</td><td class="patent-data-table-td patent-date-value">Apr 9, 1996</td><td class="patent-data-table-td ">Trustees Of Univ Of Pa</td><td class="patent-data-table-td ">Bowman-birk inhibitor concentrate compositions and methods for the treatment of pre-malignant tissue</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5544650">US5544650</a></td><td class="patent-data-table-td patent-date-value">Feb 14, 1994</td><td class="patent-data-table-td patent-date-value">Aug 13, 1996</td><td class="patent-data-table-td ">Neuromedical Systems, Inc.</td><td class="patent-data-table-td ">Automated specimen classification system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5544996">US5544996</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 1995</td><td class="patent-data-table-td patent-date-value">Aug 13, 1996</td><td class="patent-data-table-td ">White Consolidated Industries, Inc.</td><td class="patent-data-table-td ">Automated storage and retrieval system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5625765">US5625765</a></td><td class="patent-data-table-td patent-date-value">Nov 8, 1994</td><td class="patent-data-table-td patent-date-value">Apr 29, 1997</td><td class="patent-data-table-td ">Criticom Corp.</td><td class="patent-data-table-td ">Vision systems including devices and methods for combining images for extended magnification schemes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5636425">US5636425</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 1996</td><td class="patent-data-table-td patent-date-value">Jun 10, 1997</td><td class="patent-data-table-td ">Best; Norman D.</td><td class="patent-data-table-td ">Method for processing and assembly of small parts utilizing a robot</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5680694">US5680694</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 1996</td><td class="patent-data-table-td patent-date-value">Oct 28, 1997</td><td class="patent-data-table-td ">Best; Norman D.</td><td class="patent-data-table-td ">Apparatus for processing and assembly of small parts utilizing a robot</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5687251">US5687251</a></td><td class="patent-data-table-td patent-date-value">Feb 21, 1995</td><td class="patent-data-table-td patent-date-value">Nov 11, 1997</td><td class="patent-data-table-td ">Cedars-Sinai Medical Center</td><td class="patent-data-table-td ">Method and apparatus for providing preferentially segmented digital images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5700125">US5700125</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 1996</td><td class="patent-data-table-td patent-date-value">Dec 23, 1997</td><td class="patent-data-table-td ">Storage Technology Corporation</td><td class="patent-data-table-td ">Gravity feed pass-thru port for automated cartridge library</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5768125">US5768125</a></td><td class="patent-data-table-td patent-date-value">Dec 8, 1995</td><td class="patent-data-table-td patent-date-value">Jun 16, 1998</td><td class="patent-data-table-td ">Asm International N.V.</td><td class="patent-data-table-td ">Apparatus for transferring a substantially circular article</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5784162">US5784162</a></td><td class="patent-data-table-td patent-date-value">Dec 12, 1995</td><td class="patent-data-table-td patent-date-value">Jul 21, 1998</td><td class="patent-data-table-td ">Applied Spectral Imaging Ltd.</td><td class="patent-data-table-td ">Spectral bio-imaging methods for biological research, medical diagnostics and therapy</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5796861">US5796861</a></td><td class="patent-data-table-td patent-date-value">Jul 11, 1997</td><td class="patent-data-table-td patent-date-value">Aug 18, 1998</td><td class="patent-data-table-td ">Frim International, Inc.</td><td class="patent-data-table-td ">Mosaic construction, processing, and review of very large electronic micrograph composites</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5835620">US5835620</a></td><td class="patent-data-table-td patent-date-value">Dec 19, 1995</td><td class="patent-data-table-td patent-date-value">Nov 10, 1998</td><td class="patent-data-table-td ">Neuromedical Systems, Inc.</td><td class="patent-data-table-td ">Boundary mapping system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5838837">US5838837</a></td><td class="patent-data-table-td patent-date-value">Apr 8, 1996</td><td class="patent-data-table-td patent-date-value">Nov 17, 1998</td><td class="patent-data-table-td ">Sharp Kabushiki Kaisha</td><td class="patent-data-table-td ">Image synthesizing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5848177">US5848177</a></td><td class="patent-data-table-td patent-date-value">Feb 27, 1997</td><td class="patent-data-table-td patent-date-value">Dec 8, 1998</td><td class="patent-data-table-td ">Board Of Trustees Operating Michigan State University</td><td class="patent-data-table-td ">Method and system for detection of biological materials using fractal dimensions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5933519">US5933519</a></td><td class="patent-data-table-td patent-date-value">Jun 3, 1997</td><td class="patent-data-table-td patent-date-value">Aug 3, 1999</td><td class="patent-data-table-td ">Neo Path, Inc.</td><td class="patent-data-table-td ">Classifier development method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6031930">US6031930</a></td><td class="patent-data-table-td patent-date-value">Aug 23, 1996</td><td class="patent-data-table-td patent-date-value">Feb 29, 2000</td><td class="patent-data-table-td ">Bacus Research Laboratories, Inc.</td><td class="patent-data-table-td ">Method and apparatus for testing a progression of neoplasia including cancer chemoprevention testing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6081612">US6081612</a></td><td class="patent-data-table-td patent-date-value">Feb 27, 1998</td><td class="patent-data-table-td patent-date-value">Jun 27, 2000</td><td class="patent-data-table-td ">Electro Optical Sciences Inc.</td><td class="patent-data-table-td ">Systems and methods for the multispectral imaging and characterization of skin tissue</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6101265">US6101265</a></td><td class="patent-data-table-td patent-date-value">Mar 3, 1997</td><td class="patent-data-table-td patent-date-value">Aug 8, 2000</td><td class="patent-data-table-td ">Bacus Research Laboratories, Inc.</td><td class="patent-data-table-td ">Method and apparatus for acquiring and reconstructing magnified specimen images from a computer-controlled microscope</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6151405">US6151405</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 28, 1997</td><td class="patent-data-table-td patent-date-value">Nov 21, 2000</td><td class="patent-data-table-td ">Chromavision Medical Systems, Inc.</td><td class="patent-data-table-td ">System and method for cellular specimen grading</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6272235">US6272235</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 27, 1998</td><td class="patent-data-table-td patent-date-value">Aug 7, 2001</td><td class="patent-data-table-td ">Bacus Research Laboratories, Inc.</td><td class="patent-data-table-td ">Method and apparatus for creating a virtual microscope slide</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6498006">US6498006</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 24, 1998</td><td class="patent-data-table-td patent-date-value">Dec 24, 2002</td><td class="patent-data-table-td ">Johnson T. Wong</td><td class="patent-data-table-td ">Administering mixture of liposome and drug</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1992013308A1?cl=en">WO1992013308A1</a></td><td class="patent-data-table-td patent-date-value">Jan 28, 1992</td><td class="patent-data-table-td patent-date-value">Aug 6, 1992</td><td class="patent-data-table-td ">Neuromedical Systems Inc</td><td class="patent-data-table-td ">Morphological classification system and method</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="An+Efficient+Method+for+Automated+Segmentation+of+Histochemically+Stained+Slides"'>An Efficient Method for Automated Segmentation of Histochemically Stained Slides</a>", Gaddipati et al., IEEE-EMBC and CMBEC (1995).</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Analytical+and+Quantitative+Cycology+and+Hiscology"'>Analytical and Quantitative Cycology and Hiscology</a>", Chromatin Texture Measurement by Markovian Analysis, Dawson et al.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Automatic+Threshold+Selection+Using+Histogram+Quantization"'>Automatic Threshold Selection Using Histogram Quantization</a>", Wang et al., Journal of BioMedical Optics, vol. 2, No. 2 (Apr. 1997).</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Biomarkers+of+Premalignant+Breast+Disease+and+Their+Use+as+Surrogate+Endpoints+in+Clinical+Trials+of+Chemopreventive+Agents"'>Biomarkers of Premalignant Breast Disease and Their Use as Surrogate Endpoints in Clinical Trials of Chemopreventive Agents</a>", Boone et al., The Breast Journal, vol. 1, No. 4 (1995).</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Cervical+Cell+Recognition+and+Morphometric+Grading+by+Image+Analysis"'>Cervical Cell Recognition and Morphometric Grading by Image Analysis</a>", James W. Bacus, Journal of Cellular Biochemistry, Supplement 23:33-42 (1995).</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Detection+and+Characterization+of+Microcalcifications+in+Mammographic+Images"'>Detection and Characterization of Microcalcifications in Mammographic Images</a>", Pereira et al.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Development+of+Breast+Cancer+Chemopreventive+Drugs"'>Development of Breast Cancer Chemopreventive Drugs</a>", Kelloff et al., Journal of Cellular Biochemistry, 17G:2-13 (1993).</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Development+of+Surrogate+Endpoint+Biomarkers+for+Clinical+Trials+of+Cancer+Chemopreventive+Agents%3A+Relationships+to+Fundamental+Properties+of+Preinvasive+%28Intraepithelial%29+Neoplasia"'>Development of Surrogate Endpoint Biomarkers for Clinical Trials of Cancer Chemopreventive Agents: Relationships to Fundamental Properties of Preinvasive (Intraepithelial) Neoplasia</a>", Boone et al., Journal of Cellular Biochemistry, Supplement 19:10-22 (1994).</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="FSED-Feature+Selective+Edge+Detection"'>FSED-Feature Selective Edge Detection</a>", Borga et al. (2000).</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Hough+Spectrum+and+Geometric+Texture+Feature+Analysis"'>Hough Spectrum and Geometric Texture Feature Analysis</a>", Zhang et al.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Markovian+Analysis+of+Cervical+Cell+Images"'>Markovian Analysis of Cervical Cell Images</a>", Norman J. Pressman, The Journal of Histochemistry and Cytochemistry, vol. 24., No. 1, pp. 138-144 (1976).</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Quantiation+of+Preinvasive+Neoplastic+Progression+in+Animal+Models+of+Chemical+Carcinogenesis"'>Quantiation of Preinvasive Neoplastic Progression in Animal Models of Chemical Carcinogenesis</a>", Bacus et al., Journal of Cellular Biochemistry Supplements 28/29:21-38 (1997).</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Segmentation+of+Mammograms+Using+Multiple+Linked+Self-Organizing+Neural+Networks"'>Segmentation of Mammograms Using Multiple Linked Self-Organizing Neural Networks</a>", Dance et al., Med. Phys. 22(2) (Feb. 1995).</td></tr><tr><td class="patent-data-table-td ">14</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="The+Image+Processing+Handbook"'>The Image Processing Handbook</a>", John C. Russ-2nd ed.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7627153">US7627153</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 2005</td><td class="patent-data-table-td patent-date-value">Dec 1, 2009</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Gmbh</td><td class="patent-data-table-td ">Repositioning inaccuracies in an automated imaging system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7869641">US7869641</a></td><td class="patent-data-table-td patent-date-value">May 27, 2009</td><td class="patent-data-table-td patent-date-value">Jan 11, 2011</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Gmbh</td><td class="patent-data-table-td ">System and method for finding regions of interest for microscopic digital montage imaging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7876948">US7876948</a></td><td class="patent-data-table-td patent-date-value">Jul 24, 2009</td><td class="patent-data-table-td patent-date-value">Jan 25, 2011</td><td class="patent-data-table-td ">Carl Zeiss Microimaging Gmbh</td><td class="patent-data-table-td ">System for creating microscopic digital montage images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7970208">US7970208</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 29, 2005</td><td class="patent-data-table-td patent-date-value">Jun 28, 2011</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Apparatus to detect homogeneous region of image using adaptive threshold</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8126267">US8126267</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 2007</td><td class="patent-data-table-td patent-date-value">Feb 28, 2012</td><td class="patent-data-table-td ">Albany Medical College</td><td class="patent-data-table-td ">Methods and apparatuses for analyzing digital images to automatically select regions of interest thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8780139">US8780139</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 2006</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Adobe Systems Incorporated</td><td class="patent-data-table-td ">Resolution monitoring when using visual manipulation tools</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110085075">US20110085075</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 7, 2009</td><td class="patent-data-table-td patent-date-value">Apr 14, 2011</td><td class="patent-data-table-td ">Academisch Medisch Centrum Bij De Universiteit Van</td><td class="patent-data-table-td ">Method for Imaging an Object</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S128000">382/128</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S079000">348/79</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S299000">382/299</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009320000">G06K9/32</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009000000">G06K9/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/3233">G06K9/3233</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00134">G06K9/00134</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Q7VwBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00127">G06K9/00127</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06K9/00B1</span>, <span class="nested-value">G06K9/00B</span>, <span class="nested-value">G06K9/32R</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jul 31, 2013</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 31, 2009</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 7, 2009</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIM 1 IS DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 2-12, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. NEW CLAIMS 13-21 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 14, 2008</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">INTERSCOPE TECHNOLOGIES, INC., PENNSYLVANIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:ISCOPE ACQUISITION CORP.;REEL/FRAME:020507/0629</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20031016</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">TRESTLE CORPORATION, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">FICTITIOUS NAME STATEMENT;ASSIGNOR:TRESTLE ACQUISITION CORP.;REEL/FRAME:020507/0247</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20030606</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 7, 2007</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CARL ZEISS MICROIMAGING AIS, INC., NEW YORK</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:CLARIENT, INC.;REEL/FRAME:020072/0662</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20071016</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 22, 2007</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CLARIENT, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:CLRT ACQUISITION LLC;REEL/FRAME:018787/0870</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20070105</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 14, 2006</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060804</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 28, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CLRT ACQUISITION LLC, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:TRESTLE ACQUISITION CORP.;REEL/FRAME:018323/0858</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">TRESTLE ACQUISITION CORP., A WHOLLY OWNED SUBSIDIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">TERMINATION OF PATENT SECURITY AGREEMENT RECORDED AT REEL FRAME NO. 017811/0685;ASSIGNOR:CLARIENT, INC.;REEL/FRAME:018313/0808</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060922</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 27, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">TRESTLE ACQUISITION CORP., A WHOLLY-OWNED SUBSIDIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">TERMINATION OF PATENT SECURITY AGREEMENT RECORDED AT REEL/FRAME NO. 017223/0757;ASSIGNOR:CLARIENT, INC.;REEL/FRAME:018313/0364</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060922</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 20, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CLARIENT, INC., A DELAWARE CORPORATION, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:TRESTLE ACQUISITION CORP., A DELAWARE CORPORATION;REEL/FRAME:017811/0685</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060619</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 28, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CLARIENT, INC., A DELAWARE CORPORATION, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:TRESTLE ACQUISITION CORP., A DELAWARE CORPORATION;REEL/FRAME:017223/0757</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060227</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 21, 2005</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">TRESTLE CORPORATION, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INTERSCOPE TECHNOLOGIES, INC.;REEL/FRAME:016127/0447</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20050412</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 7, 2003</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CAPE ANDOVER CAPITAL PARTNERS LLC, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INTERSCOPE TECHNOLOGIES, INC.;REEL/FRAME:014681/0775</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">ISCOPE ACQUISITION CORP., PENNSYLVANIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:CAPE ANDOVER CAPITAL PARTNERS LLC;REEL/FRAME:014674/0513</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20030728</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 17, 2001</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">INTERSCOPE TECHNOLOGIES, INC., PENNSYLVANIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:WETZEL, ARTHUR W.;GILBERTSON, II, JOHN R.;BECKSTEAD, JEFFREY A.;AND OTHERS;REEL/FRAME:011819/0597;SIGNING DATES FROM 20010416 TO 20010426</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U17lJY6oUea7h97v6wt8Tq8HJ-Ddw\u0026id=Q7VwBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U1qB23PJiEmuywlhmESkFzw_rb7ng\u0026id=Q7VwBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1ddSSgI-ML9FRxbX_nAIC8tyuj-w","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/System_and_method_for_finding_regions_of.pdf?id=Q7VwBAABERAJ\u0026output=pdf\u0026sig=ACfU3U3b_JX3zaPNeAsfWzC5jK5vNmZmFg"},"sample_url":"http://www.google.com/patents/reader?id=Q7VwBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>