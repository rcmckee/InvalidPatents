<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7189985 - Tracking separation between an object and a surface using a reducing structure - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4ff636b3d23669b7103f3b3a3a18b4cd/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4ff636b3d23669b7103f3b3a3a18b4cd__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Tracking separation between an object and a surface using a reducing structure"><meta name="DC.contributor" content="Tong Xie" scheme="inventor"><meta name="DC.contributor" content="Marshall T DePue" scheme="inventor"><meta name="DC.contributor" content="Susan Hunter" scheme="inventor"><meta name="DC.contributor" content="Avago Technologies General Ip (Singapore) Pte. Ltd." scheme="assignee"><meta name="DC.date" content="2004-10-30" scheme="dateSubmitted"><meta name="DC.description" content="Tracking separation between an object and a surface involves illuminating the surface and reducing the collection angle of light that reflects off of the surface in response to a change in separation between the object and the surface. Reducing the collection angle of light that reflects off of the surface causes the amount of light that is detected to be dependent on the separation distance between the object and the surface. The amount of detected light is then used as an indication of the separation distance."><meta name="DC.date" content="2007-3-13" scheme="issued"><meta name="DC.relation" content="US:5644139" scheme="references"><meta name="DC.relation" content="US:5729009" scheme="references"><meta name="DC.relation" content="US:6222174" scheme="references"><meta name="DC.relation" content="US:6642506" scheme="references"><meta name="DC.relation" content="US:6747284" scheme="references"><meta name="citation_patent_number" content="US:7189985"><meta name="citation_patent_application_number" content="US:10/977,720"><link rel="canonical" href="http://www.google.com/patents/US7189985"/><meta property="og:url" content="http://www.google.com/patents/US7189985"/><meta name="title" content="Patent US7189985 - Tracking separation between an object and a surface using a reducing structure"/><meta name="description" content="Tracking separation between an object and a surface involves illuminating the surface and reducing the collection angle of light that reflects off of the surface in response to a change in separation between the object and the surface. Reducing the collection angle of light that reflects off of the surface causes the amount of light that is detected to be dependent on the separation distance between the object and the surface. The amount of detected light is then used as an indication of the separation distance."/><meta property="og:title" content="Patent US7189985 - Tracking separation between an object and a surface using a reducing structure"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("3qjpU_WJBsi4sATsyILYAw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407464522.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("GBR"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("3qjpU_WJBsi4sATsyILYAw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407464522.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("GBR"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7189985?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7189985"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=nGt6BAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7189985&amp;usg=AFQjCNELQnrjoeBZk-iQKAqfPOuUYZdhhQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7189985.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7189985.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20060091298"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US7189985"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7189985" style="display:none"><span itemprop="description">Tracking separation between an object and a surface involves illuminating the surface and reducing the collection angle of light that reflects off of the surface in response to a change in separation between the object and the surface. Reducing the collection angle of light that reflects off of the surface...</span><span itemprop="url">http://www.google.com/patents/US7189985?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7189985 - Tracking separation between an object and a surface using a reducing structure</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7189985 - Tracking separation between an object and a surface using a reducing structure" title="Patent US7189985 - Tracking separation between an object and a surface using a reducing structure"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7189985 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 10/977,720</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Mar 13, 2007</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Oct 30, 2004</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Oct 30, 2004</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US20060091298">US20060091298</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">10977720, </span><span class="patent-bibdata-value">977720, </span><span class="patent-bibdata-value">US 7189985 B2, </span><span class="patent-bibdata-value">US 7189985B2, </span><span class="patent-bibdata-value">US-B2-7189985, </span><span class="patent-bibdata-value">US7189985 B2, </span><span class="patent-bibdata-value">US7189985B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Tong+Xie%22">Tong Xie</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Marshall+T+DePue%22">Marshall T DePue</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Susan+Hunter%22">Susan Hunter</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Avago+Technologies+General+Ip+(Singapore)+Pte.+Ltd.%22">Avago Technologies General Ip (Singapore) Pte. Ltd.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7189985.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7189985.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7189985.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (5),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (15),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (6),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (6)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=nGt6BAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7189985&usg=AFQjCNH8-sWiuN91Y6JhFAlRD4vt0o4eKA">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=nGt6BAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7189985&usg=AFQjCNHhvL3u0AVy4aO2Texe6zHzGeTrrA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=nGt6BAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7189985B2%26KC%3DB2%26FT%3DD&usg=AFQjCNGY-DhAnifPaZfnWcsC6ixFrxIMHg">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55715417" lang="EN" load-source="patent-office">Tracking separation between an object and a surface using a reducing structure</invention-title></span><br><span class="patent-number">US 7189985 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA51122566" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">Tracking separation between an object and a surface involves illuminating the surface and reducing the collection angle of light that reflects off of the surface in response to a change in separation between the object and the surface. Reducing the collection angle of light that reflects off of the surface causes the amount of light that is detected to be dependent on the separation distance between the object and the surface. The amount of detected light is then used as an indication of the separation distance.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(7)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7189985B2/US07189985-20070313-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7189985B2/US07189985-20070313-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7189985B2/US07189985-20070313-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7189985B2/US07189985-20070313-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7189985B2/US07189985-20070313-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7189985B2/US07189985-20070313-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7189985B2/US07189985-20070313-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7189985B2/US07189985-20070313-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7189985B2/US07189985-20070313-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7189985B2/US07189985-20070313-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7189985B2/US07189985-20070313-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7189985B2/US07189985-20070313-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7189985B2/US07189985-20070313-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7189985B2/US07189985-20070313-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(20)</span></span></div><div class="patent-text"><div mxw-id="PCLM9176755" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A method for tracking separation between an object and a surface comprising:
<div class="claim-text">illuminating a surface;</div>
<div class="claim-text">reducing a collection angle of light that is incident on a sensor in response to a change in separation between an object and the surface;</div>
<div class="claim-text">detecting light subjected to the reduced collection angle; and</div>
<div class="claim-text">determining separation between the object and the surface in response to the detected light.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein determining separation between the object and the surface comprises comparing a characteristic of the detected light to a lift threshold.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref> wherein the lift threshold is defined in terms of light intensity.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref> further including indicating a lift condition when the detected light reaches the lift threshold.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein detecting light subjected to the reduced collection angle comprises detecting light with an image sensor, the image sensor including an array of individual photosensors that generate navigation information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref> wherein determining separation between the object and the surface comprises comparing a characteristic of the navigation information to a lift threshold.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref> further including indicating a lift condition when the compared characteristic of the navigation information reaches the lift threshold.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein the characteristic of the navigation information is one of total intensity, bright pixel count, dark pixel count, and intensity gradient.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein reducing the collection angle involves subjecting the reflected light to an aperture.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein reducing the collection angle involves subjecting the reflected light to a lens.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. An optical navigation device comprising:
<div class="claim-text">a light source configured to illuminate a surface;</div>
<div class="claim-text">a sensor configured to generate navigation information in response to light that reflects off of the surface;</div>
<div class="claim-text">a reducing structure, located in an optical path between the light source and the sensor, configured to reduce a collection angle of light that is incident on the sensor in response to a change in separation between the optical navigation device and the surface;</div>
<div class="claim-text">a navigation engine configured to generate lateral position information relative to the surface in response to the navigation information; and</div>
<div class="claim-text">lift detection logic configured to generate lift information related to the optical navigation device relative to the surface in response to the navigation information from the sensor.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein the lift detection logic is further configured to compare a characteristic of the navigation information to a lift threshold.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The system of <claim-ref idref="CLM-00012">claim 12</claim-ref> wherein the lift detection logic is further configured to indicate a lift condition when the compared characteristic of the navigation information reaches the lift threshold.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref> wherein the characteristic of the navigation information is one of total intensity, bright pixel count, dark pixel count, and intensity gradient.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref> wherein the generation of lateral position information by the navigation engine is suspended when the lift detection logic indicates a lift condition.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein the reducing structure comprises an aperture.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. A method for tracking separation between an optical navigation device and a surface comprising:
<div class="claim-text">illuminating a surface with light from an optical navigation device;</div>
<div class="claim-text">reducing a collection angle of light that is incident on a sensor in response to a change in separation between the optical navigation device and the surface;</div>
<div class="claim-text">collecting navigation information from light that reflects off of the surface and is subjected to the reduced collection angle; and</div>
<div class="claim-text">using the navigation information to track the lateral position of the optical navigation device relative to the surface and to identify a lift condition of the optical navigation device relative to the surface.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref> wherein determining separation between the optical navigation device and the surface comprises comparing a characteristic of the navigation information to a lift threshold.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text">19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref> further including indicating a lift condition when the compared characteristic of the navigation information reaches the lift threshold.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text">20. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref> further including suspending the tracking of lateral position when a lift condition is indicated.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES16199299" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p num="p-0002">A known optical navigation technique involves illuminating a surface, capturing successive images of the illuminated surface, and correlating the successive images with each other to determine relative lateral displacement between the images. Examples of the optical navigation technique are described in U.S. Pat. No. 5,644,139, entitled NAVIGATION TECHNIQUE FOR DETECTING MOVEMENT OF NAVIGATION SENSORS RELATIVE TO AN OBJECT, and U.S. Pat. No. 6,222,174, entitled METHOD OF CORRELATING IMMEDIATELY ACQUIRED AND PREVIOUSLY STORED FEATURE INFORMATION FOR MOTION SENSING, both of which are incorporated by reference herein. Another optical navigation technique utilizes spatial filtering as described in U.S. Pat. No. 5,729,009, entitled METHOD FOR GENERATING QUASI-SINUSOIDAL SIGNALS. These optical navigation techniques are used to track the lateral movement of a navigation device such as a computer mouse relative to a navigation surface.</p>
    <p num="p-0003">In many optical navigation applications there is a need to determine the separation distance between the optical navigation device and the navigation surface. For example, it is desirable to know when a computer mouse has been lifted off of the surface so that the navigation function can be suspended. Suspending the navigation function while the computer mouse is lifted off of the surface enables a user to move a cursor over long distances by “skating” the mouse. With a computer mouse that uses a rolling ball to track lateral motion, there is no need to detect lift off from the surface because the ball stops rolling as soon as it looses contact with the navigation surface. In contrast, a computer mouse that uses optical navigation may continue to track changes in lateral position while the mouse is lifted off of the surface and moved across the surface. Continuing to track changes in lateral position while the mouse is lifted off the surface makes it difficult to skate the mouse.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p num="p-0004">In accordance with the invention, a method for tracking separation between an object and a surface involves illuminating the surface and reducing the collection angle of light that reflects off of the surface in response to a change in separation between the object and the surface. Reducing the collection angle of light that reflects off of the surface causes the amount of light that is detected to be dependent on the separation distance between the object and the surface. The amount of detected light is then used as an indication of the separation distance.</p>
    <p num="p-0005">An optical navigation device that is configured for lift detection typically includes a light source, a sensor, and a reducing structure. The reducing structure is configured to pass light at a first collection angle when the surface is in a near position. The intensity of the light received at the sensor with the surface in this position is basically the same as it would be without the reducing structure. When the surface changes to a far position (e.g., by lifting the optical navigation device off of the navigation surface), the reducing structure causes the collection angle of the reflected light to be reduced. The reduction in the collection angle reduces the amount of reflected light that is collected by the image sensor. The reduction in the amount of collected light is used to identify the lift condition.</p>
    <p num="p-0006">Other aspects and advantages of the present invention will become apparent from the following detailed description, taken in conjunction with the accompanying drawings, illustrating by way of example the principles of the invention.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0007"> <figref idrefs="DRAWINGS">FIG. 1</figref> depicts the path that light travels between a light source, a surface, and a sensor when the surface is in a near position.</p>
      <p num="p-0008"> <figref idrefs="DRAWINGS">FIG. 2</figref> depicts the path that light travels between a light source, a surface, and a sensor when the surface is in a far position.</p>
      <p num="p-0009"> <figref idrefs="DRAWINGS">FIG. 3</figref> depicts the light source, sensor, and surface positions from <figref idrefs="DRAWINGS">FIG. 1</figref> with the addition of a reducing structure that is configured to reduce the collection angle of the light relative to the sensor.</p>
      <p num="p-0010"> <figref idrefs="DRAWINGS">FIG. 4</figref> depicts the reduced collection angle that exists when the surface is in the far position as opposed to the near position shown in <figref idrefs="DRAWINGS">FIG. 3</figref>.</p>
      <p num="p-0011"> <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates changes in the intensity center of the reflected light that occur with changes in the surface position due to the reducing structure.</p>
      <p num="p-0012"> <figref idrefs="DRAWINGS">FIG. 6</figref> depicts a graph of light intensity at a sensor vs. the separation distance between a surface and an optical navigation device for the case in which a reducing structure is not used and for the case in which a reducing structure is used.</p>
      <p num="p-0013"> <figref idrefs="DRAWINGS">FIG. 7A</figref> depicts a system for tracking separation between a surface and a light source/image sensor that utilizes collimated light where the surface and the light source/image sensor are separated by a distance that is optimized for optical navigation in the lateral direction.</p>
      <p num="p-0014"> <figref idrefs="DRAWINGS">FIG. 7B</figref> depicts the system of <figref idrefs="DRAWINGS">FIG. 7A</figref> where the surface and the light source/image sensor are separated by a distance that is greater than the separation distance of <figref idrefs="DRAWINGS">FIG. 7A</figref>.</p>
      <p num="p-0015"> <figref idrefs="DRAWINGS">FIG. 8A</figref> depicts image information captured by the image sensor with the surface located in the position of <figref idrefs="DRAWINGS">FIG. 7A</figref>.</p>
      <p num="p-0016"> <figref idrefs="DRAWINGS">FIG. 8B</figref> depicts image information captured by the image sensor with the surface located in the position of <figref idrefs="DRAWINGS">FIG. 7B</figref>.</p>
      <p num="p-0017"> <figref idrefs="DRAWINGS">FIG. 9</figref> depicts an example of an optical navigation device having a light source, a collimating lens, a reducing structure, an image sensor, and a processor that includes lift detection logic and a navigation engine.</p>
      <p num="p-0018"> <figref idrefs="DRAWINGS">FIG. 10</figref> depicts the relationship between the navigation and lift detection operations that are performed by the navigation engine and lift detection logic.</p>
      <p num="p-0019"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a process flow diagram of a method for tracking separation between an object and a surface.</p>
    </description-of-drawings> <p num="p-0020">Throughout the description similar reference numbers are used to identify similar elements.</p>
    <heading>DETAILED DESCRIPTION</heading> <p num="p-0021">In accordance with the invention, the collection angle of light relative to a sensor is reduced to produce an optical system that can track separation between an object and a surface. The basic principles of the separation tracking technique are described with reference to <figref idrefs="DRAWINGS">FIGS. 1–5</figref>. <figref idrefs="DRAWINGS">FIG. 1</figref> depicts a light source <b>12</b>, a sensor <b>14</b>, and a surface <b>16</b> that is separated from the light source <b>12</b> and sensor by a first distance (where the surface is referred to as being in the near position). The sensor <b>14</b> may be a 1-dimensional (1-D) or 2-dimensional (2-D) sensor array that includes an array of individual photosensors that generate navigation information such as image information or spatial filtering information or a single sensor such as a single photodiode. <figref idrefs="DRAWINGS">FIG. 1</figref> also depicts the path that light <b>18</b>, <b>20</b> travels between the light source <b>12</b>, the surface <b>16</b>, and the sensor <b>14</b>. The path is shown relative to the center of the sensor <b>14</b>. When the surface is in the near position, the light reflects off of the surface as indicated by light path <b>20</b>. The collection angle of the reflected light relative to the center of the sensor <b>14</b> is identified as α.</p>
    <p num="p-0022"> <figref idrefs="DRAWINGS">FIG. 2</figref> depicts the path that light <b>18</b>, <b>20</b> travels between the light source <b>12</b>, the surface <b>16</b>, and the sensor <b>14</b> when the surface <b>16</b> and light source/sensor <b>12</b>, <b>14</b> are separated by a second distance (where the surface is referred to as being in the far position). When the surface <b>16</b> is in the far position, the light reflects off of the surface as indicated by light path <b>20</b>. As depicted in <figref idrefs="DRAWINGS">FIG. 2</figref>, the collection angle, α, of the light relative to the center of the sensor <b>14</b> does not change from the collection angle depicted in <figref idrefs="DRAWINGS">FIG. 1</figref>. That is, the collection angles, α, in <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref> are the same. Because the collection angle does not change as the separation distance between the surface <b>16</b> and the light source/sensor <b>12</b>, <b>14</b> changes, the intensity of the light detected by the sensor <b>14</b> remains nearly constant or changes very slowly with changes in the separation distance. Although the example of <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref> describes diverging light, the light source <b>12</b> may produce collimated or converging light. In these cases, the collection angle may change somewhat with changes in the separation distance depending on the implementation specifics. In these configurations, the light detected by the sensor changes slowly with changes in the separation distance. The light intensity measurements in these configurations are not particularly useful for separation tracking.</p>
    <p num="p-0023">In accordance with the invention, separation between the surface and the light source/sensor is tracked by reducing the collection angle of light in response to a change in separation between the surface and the light source/image sensor. <figref idrefs="DRAWINGS">FIG. 3</figref> depicts the light source <b>12</b>, sensor <b>14</b>, and surface <b>16</b> positions from <figref idrefs="DRAWINGS">FIG. 1</figref> with the addition of a reducing structure <b>24</b> that is configured to reduce the collection angle of light relative to the sensor <b>14</b> in response to a change in the separation distance. In the embodiment of <figref idrefs="DRAWINGS">FIG. 3</figref>, the reducing structure <b>24</b> is an aperture <b>26</b> that is located in an optical path between the light source <b>12</b> and the sensor <b>14</b>. Specifically, the reducing structure is configured to reduce the collection angle of the light that reflects off of the surface when the separation distance between the surface <b>16</b> and the light source/sensor <b>12</b>, <b>14</b> is increased from a near position to a far position.</p>
    <p num="p-0024">As depicted in <figref idrefs="DRAWINGS">FIG. 3</figref>, the reducing structure <b>24</b> is configured to pass light <b>20</b> at the collection angle α when the surface is in the near position. In this configuration, the intensity of the light received by the sensor <b>14</b> is basically the same as it would be without the reducing structure <b>24</b>. However, when the surface <b>16</b> changes to the far position (either by movement of the light source/sensor <b>12</b>, <b>14</b>, movement of the surface <b>16</b>, or movement of both the light source/sensor <b>12</b>, <b>14</b> and the surface <b>16</b>), the reducing structure <b>24</b> causes the collection angle of the reflected light to be reduced. <figref idrefs="DRAWINGS">FIG. 4</figref> depicts the light source <b>12</b>, sensor <b>14</b>, and reducing structure <b>24</b> of <figref idrefs="DRAWINGS">FIG. 3</figref> with the surface <b>16</b> located in the far position as opposed to the near position. As depicted in <figref idrefs="DRAWINGS">FIG. 4</figref>, the reducing structure <b>24</b> causes the collection angle to be reduced from collection angle α to collection angle β, where β&lt;α. The reduction in the collection angle from α to β causes a reduction in the amount of light that is collected by the sensor <b>12</b>. The reduction in the amount of collected light is used to track the separation between the surface <b>16</b> and the light source/sensor <b>12</b>, <b>14</b>.</p>
    <p num="p-0025">While <figref idrefs="DRAWINGS">FIGS. 3 and 4</figref> depict a change in the collection angle relative to the center of the sensor <b>14</b>, the reducing effect of the reducing structure <b>24</b> can also be illustrated relative to the intensity center of the reflected light. <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates how the intensity center <b>30</b> of the reflected light <b>32</b>, <b>34</b> changes with changes in the surface <b>16</b> position. Referring to <figref idrefs="DRAWINGS">FIG. 5</figref>, the system is configured such that the intensity center of the reflected light <b>34</b> is at the center of the sensor <b>14</b> when the surface <b>16</b> is in the near position. However, as the surface <b>16</b> moves further away from the light source/sensor <b>12</b>, <b>14</b>, the reducing structure <b>24</b> causes the intensity center <b>30</b> of the reflected light <b>32</b> to shift away from the center of the sensor <b>14</b>. As configured in FIG. <b>5</b>, when the surface <b>16</b> is in the far position, the intensity center of the reflected light is outside the footprint of the sensor <b>14</b>. The shift in the intensity center of the reflected light changes the intensity of light that is detected by the sensor <b>14</b>. The change in the detected light is used to track separation between the surface <b>16</b> and the light source/sensor <b>12</b>, <b>14</b>.</p>
    <p num="p-0026">As stated above, the change in the detected light caused by the reducing structure <b>24</b> in response to increased separation between the surface <b>16</b> and the light source/sensor <b>12</b>, <b>14</b> is used to track separation between the surface <b>16</b> and the light source/sensor <b>12</b>, <b>14</b>. In an embodiment in accordance with the invention, the technique is used to determine when an optical navigation device, such as an optical computer mouse, is lifted off of a surface. Detecting when an optical navigation device has been lifted off of a surface (referred to herein as a “lift condition”) involves establishing a lift threshold that is expressed as a characteristic of the detected light (e.g., light intensity), detecting the light that is incident on the sensor, and then comparing the characteristic of the detected light to the lift threshold. If the amount of light detected by the sensor drops below the lift threshold, a lift condition is identified. Once the amount of light detected by the sensor goes above the lift threshold, the lift condition is ended.</p>
    <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 6</figref> depicts a graph of total light intensity, I, at the sensor vs. the separation distance (e.g., the z dimension) between a surface and an optical navigation device for the case in which a reducing structure is not used (graph line <b>40</b>) and for the case in which a reducing structure is used (graph line <b>42</b>). The graph also depicts a lift threshold (dashed line <b>44</b>) and a tracking threshold (dashed line <b>46</b>) relative to the two graphs. In the case where a reducing structure is not used (graph line <b>40</b>), the intensity of the detected light decreases relatively slowly as the distance between the surface and the optical navigation device increases. In this case, the light intensity never drops below the lift threshold over the separation distance that is included in the graph.</p>
    <p num="p-0028">In the case where a reducing structure is used (graph line <b>42</b>), the intensity of the detected light decreases relatively quickly as the distance between the surface and the optical navigation device increases. At the point where the light intensity drops below the lift threshold (referred to as the lift distance Z<sub>lift</sub>), a lift condition is identified. The lift condition exists for as long as the detected light intensity remains below the lift threshold. The sensitivity of lift detection can be adjusted by adjusting the lift threshold. For example, lowering the lift threshold will cause a lift condition to be indicated at a larger separation distance. In a computer mouse application, the lift threshold may be pre-established to indicate a lift condition as soon as the computer mouse looses contact with the navigation surface. The lift threshold may be pre-established at a fixed setting by the product manufacturer. Alternatively, the lift threshold may be adjusted by the user of the mouse through, for example, a software interface.</p>
    <p num="p-0029">The tracking threshold <b>46</b> depicted in <figref idrefs="DRAWINGS">FIG. 6</figref> indicates the minimum light intensity that is required to support reliable lateral position tracking (e.g., in the x-y plane). The point at which the light intensity drops below the tracking threshold is identified as the tracking limit (Z<sub>limit</sub>). The tracking limit is depicted relative to the lift threshold to illustrate that a lift condition is reached at a separation distance that is less than the tracking limit (i.e., Z<sub>lift</sub>&lt;Z<sub>limit</sub>). That is, a lift condition exists even though reliable lateral position tracking is still possible. Although the optical navigation device is capable of reliably tracking lateral motion while the optical navigation device is lifted off of the surface, in computer mouse applications, it is desirable to purposefully suspend lateral navigation once the computer mouse is lifted off of the surface so that a user can move a cursor long distances by skating the computer mouse. In an alternative embodiment, the reducing structure is placed at a specific distance and with a specific configuration to create a condition in which the lift distance equals the tracking limit (i.e., Z<sub>lift</sub>=Z<sub>limit</sub>). In this case, the lateral position tracking is stopped at the tracking limit.</p>
    <p num="p-0030"> <figref idrefs="DRAWINGS">FIGS. 7A and 7B</figref> depict a system <b>50</b> for tracking separation between a surface <b>16</b> and a light source/sensor <b>12</b>, <b>14</b> that utilizes a 1-D or 2-D image sensor as the sensor and collimated light <b>52</b>. The system <b>50</b> includes a lens <b>54</b> to collimate light from the light source <b>12</b> and a reducing structure <b>24</b> that includes an aperture <b>26</b> and a lens <b>56</b> to reduce the collection angle of the reflected light relative to the image sensor <b>14</b>. <figref idrefs="DRAWINGS">FIG. 7A</figref> depicts the case in which the surface <b>16</b> and the light source/image sensor <b>12</b>, <b>14</b> are separated by a distance that is optimized for optical navigation in the lateral direction (e.g., the x-y plane). For example, in an optical mouse application, this is the separation that exists when the computer mouse is sitting on top of the navigation surface. <figref idrefs="DRAWINGS">FIG. 7B</figref> depicts the case in which the surface <b>16</b> and the light source/image sensor <b>12</b>, <b>14</b> are separated by a distance (e.g., in the z-dimension) that is greater than the separation distance of <figref idrefs="DRAWINGS">FIG. 7A</figref> by Δz. For example, in an optical mouse application this is the separation that exists when the computer mouse has been lifted off of the navigation surface.</p>
    <p num="p-0031">Operation of the system <b>50</b> depicted in <figref idrefs="DRAWINGS">FIGS. 7A and 7B</figref> begins with generating light from the light source <b>12</b>. The light from the light source <b>12</b> is collimated by the lens <b>54</b> and the collimated light <b>52</b> is incident on the surface <b>16</b>. A portion of the collimated light reflects off of the surface <b>16</b> and is subjected to the reducing structure <b>24</b>. Light that passes through the reducing structure <b>24</b> and that is within the collection angle from which light is received by the image sensor <b>14</b> is detected by the image sensor <b>14</b>. The light detected by the image sensor <b>14</b> is converted to navigation information that is used to determine if a lift off condition exists. When the separation distance depicted in <figref idrefs="DRAWINGS">FIG. 7A</figref> exists, most of the reflected light passes through the reducing structure and the intensity center of the reflected light is aligned near the center of the image sensor <b>14</b>. The collection angle of the light relative to the image sensor <b>14</b> is identified in <figref idrefs="DRAWINGS">FIG. 7A</figref> as α. An example of the navigation information <b>58</b> captured by the image sensor <b>14</b> in this case is depicted in <figref idrefs="DRAWINGS">FIG. 8A</figref>. As depicted in <figref idrefs="DRAWINGS">FIG. 8A</figref>, the intensity of the detected light is greatest near the center of the image sensor <b>14</b> and decreases as the distance from the center increases.</p>
    <p num="p-0032">When the separation distance depicted in <figref idrefs="DRAWINGS">FIG. 7B</figref> exists, a portion of the reflected light is prevented from being detected by the image sensor <b>14</b>. This is the case because the reducing structure <b>24</b> causes the collection angle of the light to shrink from a first collection angle to a reduced collection angle in response to the change in separation as described above with reference to <figref idrefs="DRAWINGS">FIGS. 1–5</figref>. The reduced collection angle of the light relative to the image sensor <b>14</b> is identified in <figref idrefs="DRAWINGS">FIG. 7B</figref> as β, where β&lt;α. An example of the navigation information <b>60</b> captured by the image sensor <b>14</b> in this case is depicted in <figref idrefs="DRAWINGS">FIG. 8B</figref>. As depicted in <figref idrefs="DRAWINGS">FIG. 8B</figref>, the intensity center of the detected light is no longer near the center of the image sensor <b>14</b> but has shifted towards an edge of the image sensor <b>14</b>. The change in the detected navigation information is used to determine whether or not a lift condition exists.</p>
    <p num="p-0033">Different characteristics of the detected light can be used to determine if a lift condition exists depending on the implementation (e.g., single sensor, image correlation, spatial filtering). For example, the navigation information in the form of 1-D or 2-D image information can be reduced to a single total light intensity value that is used as the basis for lift detection. In this case, the lift threshold is pre-established as a light intensity value that is compared to the detected light intensity value. Alternatively, the navigation information can be examined in terms of, for example, a count of the number of light pixels (i.e., the number of individual photosensors that have a minimum brightness), a count of the number of dark pixels, the center of mass of the light distribution over the detector pixels, or a measure of the change in light intensity (i.e., the light gradient). Although some characteristics of the detected light are described, other characteristics of the detected light can be used to determine a lift condition.</p>
    <p num="p-0034">In an embodiment in accordance with the invention, the above-described technique for tracking separation between a surface and a light source/image sensor is incorporated into an optical navigation device such as a computer mouse. <figref idrefs="DRAWINGS">FIG. 9</figref> depicts an example of an optical navigation device <b>70</b> that optionally includes glide pads <b>72</b>, a light source <b>12</b>, a collimating lens <b>54</b>, a reducing structure <b>24</b>, a sensor <b>14</b> such as a 1-D or 2-D image sensor, and a processor <b>74</b> having lift detection logic <b>76</b> and a navigation engine <b>78</b>. The light source <b>12</b>, collimating lens <b>54</b>, reducing structure <b>24</b>, and sensor <b>14</b> are configured as described above with reference to <figref idrefs="DRAWINGS">FIGS. 3–7</figref> to enable lift detection. The glide pads <b>14</b> allow the optical navigation device <b>70</b> to move over the navigation surface <b>16</b> and ensure that a constant distance is maintained between the optical navigation device <b>70</b> and the navigation surface <b>16</b> while the optical navigation device <b>70</b> sits on the surface. The navigation engine <b>78</b> is configured to track lateral motion of the computer mouse (i.e., motion in the x-y plane) relative to the surface <b>16</b>. The navigation engine <b>78</b> tracks lateral motion by, for example, correlating successive frames of image information or spatial filtering to determine relative lateral displacement. Examples of these optical navigation techniques are described in the previously referenced U.S. patents. Although some examples of navigation techniques are described herein, the particular navigation technique used does not limit the invention. Other navigation techniques are expected to be used with the invention. Further, navigation techniques that use electromagnetic signals in spectrums other than the visible spectrum may be used with the invention.</p>
    <p num="p-0035">The lift detection logic <b>76</b> determines whether or not a lift condition exists by comparing navigation information to, for example, a pre-established lift threshold. <figref idrefs="DRAWINGS">FIG. 10</figref> depicts the relationship between the navigation and lift detection operations that are performed by the navigation engine <b>78</b> and lift detection logic <b>76</b>. At block <b>80</b>, navigation information is collected by the sensor <b>14</b>. At block <b>82</b>, the navigation information is compared to the lift threshold by the lift detection logic <b>76</b>. At decision point <b>84</b>, it is determined whether or not a lift condition exists. In an embodiment in accordance with the invention, a lift condition exists when a characteristic of the detected light reaches the lift threshold as described above. If it is determined that a lift condition does not exist (i.e., the computer mouse is sitting on the navigation surface), then the navigation information is used by the navigation logic <b>78</b> to track lateral position (block <b>86</b>). If on the other hand, a lift condition does exist (i.e., the computer mouse has been lifted off of the navigation surface), lateral position tracking is suspended (block <b>88</b>). In this embodiment in accordance with the invention, the lift detection logic <b>76</b> is configured to produce a binary output that indicates whether or not a lift condition exists. The navigation function is then either activated or suspended in response to the binary output from the lift detection logic <b>76</b>.</p>
    <p num="p-0036"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a process flow diagram of a method for tracking separation between an object and a surface. At block <b>90</b>, a surface is illuminated. At block <b>92</b>, a collection angle of light that is incident on a sensor is reduced in response to a change in separation between an object and the surface. At block <b>94</b>, light subjected to the reduced collection angle is detected. At block <b>96</b>, separation between the object and the surface is determined in response to the detected light.</p>
    <p num="p-0037">Although the reducing structure <b>24</b> is depicted as an aperture <b>26</b> or an aperture and lens <b>56</b> in <figref idrefs="DRAWINGS">FIGS. 3</figref>, <b>4</b>, <b>7</b>A, <b>7</b>B, and <b>9</b>, the reducing structure can be any element or combination of elements that reduces the collection angle of light relative to a sensor in response to a change in separation between the surface and the light source/sensor <b>12</b>, <b>14</b>. For example, the reducing structure may include an aperture, a lens, a reflective element, absorbing element, or any combination thereof.</p>
    <p num="p-0038">Although very basic optical path arrangements are described with reference to <figref idrefs="DRAWINGS">FIGS. 3–9</figref>, other more complex optical path arrangements are contemplated. For example, an actual implementation may include an optical path that includes multiple optical elements (e.g., reflectors, lenses) to manipulate the light path from the light source to the image sensor. Further, the separation tracking technique can be implemented using collimated light, diverging light, converging light, or any combination thereof.</p>
    <p num="p-0039">The navigation information includes image information as depicted in <figref idrefs="DRAWINGS">FIGS. 8A and 8B</figref> when image correlation is used for lateral position tracking. Alternatively, the navigation information could include, for example, spatially filtered data when spatial filtering is used for lateral position tracking.</p>
    <p num="p-0040">As used herein, the light source generates an electromagnetic signal in the visible spectrum. However, the terms “light” and “illuminating” should not be limited to electromagnetic signals in the visible spectrum. The technique for tracking separation can be applied to electromagnetic energy outside of the visible spectrum (e.g., radio frequency, infrared, and terahertz signals).</p>
    <p num="p-0041">Although the separation tracking technique is described in conjunction with an optical navigation device that uses a sensor such as a 1-D or 2-D sensor array to track lateral position, the separation tracking technique can be implemented without lateral position tracking. In an implementation that does not include lateral position tracking, separation tracking can be accomplished with a single photosensor instead of a more complex image sensor, which includes an array of individual photosensors. When a single photosensor is used, separation is determined in response to the output from the single photosensor.</p>
    <p num="p-0042">Although specific embodiments in accordance with the invention have been described and illustrated, the invention is not to be limited to the specific forms or arrangements of parts so described and illustrated. The scope of the invention is to be defined by the claims appended hereto and their equivalents.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5644139">US5644139</a></td><td class="patent-data-table-td patent-date-value">Aug 14, 1996</td><td class="patent-data-table-td patent-date-value">Jul 1, 1997</td><td class="patent-data-table-td ">Allen; Ross R.</td><td class="patent-data-table-td ">Navigation technique for detecting movement of navigation sensors relative to an object</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5729009">US5729009</a></td><td class="patent-data-table-td patent-date-value">Jun 7, 1995</td><td class="patent-data-table-td patent-date-value">Mar 17, 1998</td><td class="patent-data-table-td ">Logitech, Inc.</td><td class="patent-data-table-td ">Method for generating quasi-sinusoidal signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6222174">US6222174</a></td><td class="patent-data-table-td patent-date-value">Mar 5, 1999</td><td class="patent-data-table-td patent-date-value">Apr 24, 2001</td><td class="patent-data-table-td ">Hewlett-Packard Company</td><td class="patent-data-table-td ">Method of correlating immediately acquired and previously stored feature information for motion sensing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6642506">US6642506</a></td><td class="patent-data-table-td patent-date-value">Jun 1, 2000</td><td class="patent-data-table-td patent-date-value">Nov 4, 2003</td><td class="patent-data-table-td ">Mitutoyo Corporation</td><td class="patent-data-table-td ">Speckle-image-based optical position transducer having improved mounting and directional sensitivities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6747284">US6747284</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 30, 2002</td><td class="patent-data-table-td patent-date-value">Jun 8, 2004</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">Position sensing device having a movable photosensing element</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7321359">US7321359</a></td><td class="patent-data-table-td patent-date-value">Jul 30, 2003</td><td class="patent-data-table-td patent-date-value">Jan 22, 2008</td><td class="patent-data-table-td ">Avago Technologies Ecbu Ip (Singapore) Pte. Ltd.</td><td class="patent-data-table-td ">Method and device for optical navigation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7399954">US7399954</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 2005</td><td class="patent-data-table-td patent-date-value">Jul 15, 2008</td><td class="patent-data-table-td ">Avago Technologies Ecbu Ip Pte Ltd</td><td class="patent-data-table-td ">System and method for an optical navigation device configured to generate navigation information through an optically transparent layer and to have skating functionality</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7442916">US7442916</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 25, 2006</td><td class="patent-data-table-td patent-date-value">Oct 28, 2008</td><td class="patent-data-table-td ">Avago Technologies General Ip (Singapore) Pte. Ltd.</td><td class="patent-data-table-td ">Lift detection adapted for navigation on a transparent structure</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7550710">US7550710</a></td><td class="patent-data-table-td patent-date-value">Jun 21, 2005</td><td class="patent-data-table-td patent-date-value">Jun 23, 2009</td><td class="patent-data-table-td ">Renishaw Plc</td><td class="patent-data-table-td ">Scale and readhead apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7737948">US7737948</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 20, 2005</td><td class="patent-data-table-td patent-date-value">Jun 15, 2010</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Speckle navigation system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7755604">US7755604</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 19, 2006</td><td class="patent-data-table-td patent-date-value">Jul 13, 2010</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Optical navigation sensor with tracking and lift detection for optically transparent contact surfaces</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7773070">US7773070</a></td><td class="patent-data-table-td patent-date-value">May 9, 2005</td><td class="patent-data-table-td patent-date-value">Aug 10, 2010</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Optical positioning device using telecentric imaging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7872639">US7872639</a></td><td class="patent-data-table-td patent-date-value">Sep 18, 2006</td><td class="patent-data-table-td patent-date-value">Jan 18, 2011</td><td class="patent-data-table-td ">Logitech Europe S.A.</td><td class="patent-data-table-td ">Optical displacement detection over varied surfaces</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7898524">US7898524</a></td><td class="patent-data-table-td patent-date-value">Jun 20, 2006</td><td class="patent-data-table-td patent-date-value">Mar 1, 2011</td><td class="patent-data-table-td ">Logitech Europe S.A.</td><td class="patent-data-table-td ">Optical displacement detection over varied surfaces</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8279178">US8279178</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 30, 2007</td><td class="patent-data-table-td patent-date-value">Oct 2, 2012</td><td class="patent-data-table-td ">Avago Technologies Ecbu Ip (Singapore) Pte. Ltd.</td><td class="patent-data-table-td ">System and method for performing optical navigation using horizontally oriented imaging lens</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8345003">US8345003</a></td><td class="patent-data-table-td patent-date-value">Jul 26, 2010</td><td class="patent-data-table-td patent-date-value">Jan 1, 2013</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Optical positioning device using telecentric imaging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8570194">US8570194</a></td><td class="patent-data-table-td patent-date-value">Sep 5, 2008</td><td class="patent-data-table-td patent-date-value">Oct 29, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Clutch-height adjustment in an optical tracking device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8711096">US8711096</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 2009</td><td class="patent-data-table-td patent-date-value">Apr 29, 2014</td><td class="patent-data-table-td ">Cypress Semiconductor Corporation</td><td class="patent-data-table-td ">Dual protocol input device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110095984">US20110095984</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 4, 2011</td><td class="patent-data-table-td patent-date-value">Apr 28, 2011</td><td class="patent-data-table-td ">Avago Technologies Ecbu Ip (Singapore) Pte. Ltd.</td><td class="patent-data-table-td ">Optical navigation system and method of estimating motion with optical lift detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120038554">US20120038554</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 27, 2011</td><td class="patent-data-table-td patent-date-value">Feb 16, 2012</td><td class="patent-data-table-td ">Pixart Imaging Inc.</td><td class="patent-data-table-td ">Lift detection method for optical mouse and optical mouse with lift detection function</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=nGt6BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc250/defs250.htm&usg=AFQjCNE2JFZGWgKce_vsAhza5snqYsKAQg#C250S559290">250/559.29</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=nGt6BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc250/defs250.htm&usg=AFQjCNE2JFZGWgKce_vsAhza5snqYsKAQg#C250S559380">250/559.38</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=nGt6BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc250/defs250.htm&usg=AFQjCNE2JFZGWgKce_vsAhza5snqYsKAQg#C250S559240">250/559.24</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=nGt6BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01N0021860000">G01N21/86</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=nGt6BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/0317">G06F3/0317</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06F3/03H3</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jun 18, 2013</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 3, 8 AND 14 ARE CANCELLED.CLAIMS 1, 2, 4, 6, 7, 11, 12, 13, 17, 18 AND 19 ARE DETERMINED TO BE PATENTABLE AS AMENDED.CLAIMS 5, 9, 10, 15, 16 AND 20, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE.NEW CLAIMS 21-61 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 16, 2012</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">PIXART IMAGING INC., TAIWAN</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AVAGO TECHNOLOGIES GENERAL IP (SINGAPORE) PTE.LTD.;REEL/FRAME:029308/0214</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20121102</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 23, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110616</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 11, 2010</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 22, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AVAGO TECHNOLOGIES GENERAL IP PTE. LTD., SINGAPORE</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;REEL/FRAME:017206/0666</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20051201</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AVAGO TECHNOLOGIES GENERAL IP PTE. LTD.,SINGAPORE</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100203;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100223;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100225;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100309;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100316;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100323;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100413;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100420;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100427;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100504;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100518;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;US-ASSIGNMENT DATABASE UPDATED:20100525;REEL/FRAME:17206/666</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGILENT TECHNOLOGIES, INC.;REEL/FRAME:17206/666</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 29, 2005</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AGILENT TECHNOLOGIES, INC., COLORADO</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:XIE, TONG;DEPUE, MARSHALL T.;HUNTER, SUSAN;REEL/FRAME:015834/0141</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20041029</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4ff636b3d23669b7103f3b3a3a18b4cd.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1hgjud63nqn_ndHHoqU5eh5uXqUw\u0026id=nGt6BAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0d6qvtVddtK910_n-hZQ6WSLgKiQ\u0026id=nGt6BAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U0jAYeT5ERxpvunaxTtb2MITdVgzQ","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Tracking_separation_between_an_object_an.pdf?id=nGt6BAABERAJ\u0026output=pdf\u0026sig=ACfU3U1XqfbVeuPChZmtCpHY_fwVEosGDQ"},"sample_url":"http://www.google.com/patents/reader?id=nGt6BAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>