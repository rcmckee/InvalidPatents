<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6880004 - Method for restoring a portion of a communication session transmitted over a ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method for restoring a portion of a communication session transmitted over a computer network"><meta name="DC.contributor" content="Mordechai Nisani" scheme="inventor"><meta name="DC.contributor" content="Eitan Bar" scheme="inventor"><meta name="DC.contributor" content="Sts Software Systems Ltd." scheme="assignee"><meta name="DC.date" content="2004-10-13" scheme="dateSubmitted"><meta name="DC.description" content="Restoring at least a portion of a telephone communication session, in which at least the following occur. Data packets transmitted over a computer network are received. Audio or video data contained in the data packets is stored. The portion of the telephone communication session from the audio or video data contained in the data packets is restored. A terminal having a user interface, a data entry device and a display unit suitable for outputting audio data, video data, or both audio and video is provided. The portion of the telephone communication session is output using the display unit."><meta name="DC.date" content="2005-4-12" scheme="issued"><meta name="DC.relation" content="EP:0841832:A2" scheme="references"><meta name="DC.relation" content="US:5101402" scheme="references"><meta name="DC.relation" content="US:5351243" scheme="references"><meta name="DC.relation" content="US:5430709" scheme="references"><meta name="DC.relation" content="US:5515376" scheme="references"><meta name="DC.relation" content="US:5664226" scheme="references"><meta name="DC.relation" content="US:5689641" scheme="references"><meta name="DC.relation" content="US:5717879" scheme="references"><meta name="DC.relation" content="US:5742833" scheme="references"><meta name="DC.relation" content="US:5848233" scheme="references"><meta name="DC.relation" content="US:5964839" scheme="references"><meta name="DC.relation" content="US:6122665" scheme="references"><meta name="DC.relation" content="WO:1997041674:A2" scheme="references"><meta name="DC.relation" content="WO:1999044363:A1" scheme="references"><meta name="DC.relation" content="WO:2000028425:A1" scheme="references"><meta name="DC.relation" content="WO:2000052916:A1" scheme="references"><meta name="citation_reference" content="Madeline Bodin, &quot;Keeping An eye On Your Agents,&quot; Call Center Magazine, Feb. 1993, 4 pages."><meta name="citation_reference" content="Schulzrinne et al.: &quot;RFC 1889: RTP: A Transport Protocol for Real-Time Applications,&quot; Network Working Group Request for Comments, Jan. 1996 (complete document, p. 1-75)."><meta name="citation_patent_number" content="US:6880004"><meta name="citation_patent_application_number" content="US:10/962,679"><link rel="canonical" href="http://www.google.com/patents/US6880004"/><meta property="og:url" content="http://www.google.com/patents/US6880004"/><meta name="title" content="Patent US6880004 - Method for restoring a portion of a communication session transmitted over a computer network"/><meta name="description" content="Restoring at least a portion of a telephone communication session, in which at least the following occur. Data packets transmitted over a computer network are received. Audio or video data contained in the data packets is stored. The portion of the telephone communication session from the audio or video data contained in the data packets is restored. A terminal having a user interface, a data entry device and a display unit suitable for outputting audio data, video data, or both audio and video is provided. The portion of the telephone communication session is output using the display unit."/><meta property="og:title" content="Patent US6880004 - Method for restoring a portion of a communication session transmitted over a computer network"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("OKDtU4b3B7a7sQTtoILACw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("USA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("OKDtU4b3B7a7sQTtoILACw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("USA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6880004?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6880004"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=yhVsBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6880004&amp;usg=AFQjCNFMVifsuJL2OtOKYTcNgSpTpmIu_A" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6880004.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6880004.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20050033840"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US6880004"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6880004" style="display:none"><span itemprop="description">Restoring at least a portion of a telephone communication session, in which at least the following occur. Data packets transmitted over a computer network are received. Audio or video data contained in the data packets is stored. The portion of the telephone communication session from the audio or video...</span><span itemprop="url">http://www.google.com/patents/US6880004?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6880004 - Method for restoring a portion of a communication session transmitted over a computer network</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6880004 - Method for restoring a portion of a communication session transmitted over a computer network" title="Patent US6880004 - Method for restoring a portion of a communication session transmitted over a computer network"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6880004 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 10/962,679</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Apr 12, 2005</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Oct 13, 2004</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Aug 26, 1998</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6865604">US6865604</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6871229">US6871229</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7581001">US7581001</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20050033838">US20050033838</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20050033839">US20050033839</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20050033840">US20050033840</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20050198252">US20050198252</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">10962679, </span><span class="patent-bibdata-value">962679, </span><span class="patent-bibdata-value">US 6880004 B2, </span><span class="patent-bibdata-value">US 6880004B2, </span><span class="patent-bibdata-value">US-B2-6880004, </span><span class="patent-bibdata-value">US6880004 B2, </span><span class="patent-bibdata-value">US6880004B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Mordechai+Nisani%22">Mordechai Nisani</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Eitan+Bar%22">Eitan Bar</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Sts+Software+Systems+Ltd.%22">Sts Software Systems Ltd.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6880004.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6880004.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6880004.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (16),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (2),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (3),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (19),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (6)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6880004&usg=AFQjCNGJ-juKMhTdLwN4-IpaNfbJtgjYcg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6880004&usg=AFQjCNE_j4NGgITaggsGIQ-EPtpHkmtQlQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6880004B2%26KC%3DB2%26FT%3DD&usg=AFQjCNHjCfaM_0vC9I506ILOBDFUBYFs9Q">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55405461" lang="EN" load-source="patent-office">Method for restoring a portion of a communication session transmitted over a computer network</invention-title></span><br><span class="patent-number">US 6880004 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50808786" lang="EN" load-source="patent-office"> <div num="P-00001" class="abstract">Restoring at least a portion of a telephone communication session, in which at least the following occur. Data packets transmitted over a computer network are received. Audio or video data contained in the data packets is stored. The portion of the telephone communication session from the audio or video data contained in the data packets is restored. A terminal having a user interface, a data entry device and a display unit suitable for outputting audio data, video data, or both audio and video is provided. The portion of the telephone communication session is output using the display unit.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(9)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6880004B2/US06880004-20050412-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6880004B2/US06880004-20050412-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6880004B2/US06880004-20050412-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6880004B2/US06880004-20050412-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6880004B2/US06880004-20050412-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6880004B2/US06880004-20050412-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6880004B2/US06880004-20050412-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6880004B2/US06880004-20050412-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6880004B2/US06880004-20050412-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6880004B2/US06880004-20050412-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6880004B2/US06880004-20050412-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6880004B2/US06880004-20050412-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6880004B2/US06880004-20050412-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6880004B2/US06880004-20050412-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6880004B2/US06880004-20050412-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6880004B2/US06880004-20050412-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6880004B2/US06880004-20050412-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6880004B2/US06880004-20050412-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(11)</span></span></div><div class="patent-text"><div mxw-id="PCLM8828479" lang="EN" load-source="patent-office" class="claims">
  <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
    <div class="claim-text">1. In a communication system including computer network-based telephones, a method for restoring at least a portion of a telephone communication session, the method comprising:
<div class="claim-text">(a) receiving data packets transmitted over a computer network; </div>
<div class="claim-text">(b) analyzing a data portion of the data packets to determine the telephone communication session to which the data packets belong; </div>
<div class="claim-text">(c) storing audio or video data contained in the data packets; </div>
<div class="claim-text">(d) restoring the portion of the telephone communication session from the audio or video data contained in the data packets; </div>
<div class="claim-text">(e) providing a terminal having a user interface, a data entry device and a display unit suitable for outputting audio data, video data, or both audio and video; and </div>
<div class="claim-text">(f) outputting the portion of the telephone communication session using the display unit. </div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
    <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising steps of receiving a command via the data entry device and using the command to determine filtering information, wherein the storing step stores audio or video data contained in data packets that satisfy the filtering information.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
    <div class="claim-text">3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the restoring step includes the steps of obtaining time-stamp data from each of the data packets and re-assembling the telephone communication session using the time-stamp data to maintain an overall timing among the data packets that comprise the telephone communication session.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
    <div class="claim-text">4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the step of obtaining time-stamp data comprises examining the data packets to determine a time stamp for each of the data packets.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
    <div class="claim-text">5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the outputting step further comprises the step of displaying any video data included in the restored portion of the communication session on a computer monitor, a video monitor or a display screen.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
    <div class="claim-text">6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the outputting step further comprises the step of producing any audio data included in the restored portion of the communication session through an earphone or a loudspeaker.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
    <div class="claim-text">7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, including the additional steps of determining which data packets comprise the portion of the telephone communication session on the basis of information extracted from a header of the data packets.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
    <div class="claim-text">8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the information extracted from the header includes one of a source IP address and a destination IP address.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
    <div class="claim-text">9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the restoring step occurs at the terminal.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
    <div class="claim-text">10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the restoring step occurs remote from the terminal.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
    <div class="claim-text">11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising the step of receiving a request issued from the terminal, wherein the outputting step is in response to the request.</div>
  </div>
</div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES15851023" lang="EN" load-source="patent-office" class="description">
<p num="P-00002">This application is a continuation of U.S. application Ser. No. 09/664,755, which was filed on Sep. 19, 2000, which is a continuation-in-part of U.S. application Ser. No. 09/140,453, filed on Aug. 26, 1998, now U.S. Pat. No. 6,122,665, issued on Sep. 19, 2000, which are hereby incorporated by reference as if set forth in their respective entireties herein.</p>
<heading>FIELD AND BACKGROUND</heading> <p num="P-00003">The present invention is of a method and a system for the management of communication sessions for computer network-based telephone communication, and in particular for the identification of packets containing audio and/or video data, for the storage of these packets, and for the reconstruction of selected communication sessions for audio and/or video display as needed.</p>
  <p num="P-00004">The integration of the computer into office communication systems has enabled many functions previously performed by separate devices to be combined into a single management system operated through a computer. For example, computer-based voice logging systems enable a computer to receive voice communication through a hardware connection to the regular telephony network, to record either a conversation, in which at least two parties converse, or a message from at least one party to one or more parties, and to replay these recorded conversations or messages upon request. These voice logging systems can replace mechanical telephone answering machines.</p>
  <p num="P-00005">The computer logging systems have many advantages over the mechanical answering machines. For example, the voice messages can be stored in a computer-based storage medium, such as a DAT cassette, which has a greater storage capacity than regular audio cassettes. Furthermore, the stored voice messages can be organized in a database, such that the messages can retrieved according to time, date, channel, dialed number or caller identification, for example. Such organization is not possible with a mechanical telephone answering machine. Thus, computer logging systems for voice messages have many advantages over mechanical answering machines.</p>
  <p num="P-00006">Unfortunately, currently available computer logging systems have the disadvantage of being unable to record telephone communication sessions, whether conversations or messages, for voice communication being performed through a LAN (local area network) or a WAN (wide area network). Although these logging systems can play back voice messages to a remote user through a LAN, for example, they cannot record such a message if it is transmitted by a LAN-based telephone. Such LAN and WAN based telephone communication has become more popular recently, since it enables telephone communication to be performed between various parties at physically separated sites without paying for local regular telephony network services, thereby saving money.</p>
  <p num="P-00007">Furthermore, LAN and WAN based telephone communication also facilitates the transmission of video as well as audio information. Video information certainly cannot be recorded by currently available computer logging systems. Thus, the inability of computer logging systems to record telephone communication sessions for telephone communication being performed through a LAN or a WAN, including both video and audio data, is a significant disadvantage of these systems.</p>
  <p num="P-00008">There is therefore a need for, and it would be highly advantageous to have, a system and a method for recording telephone communication sessions performed over a computer network such as a LAN or a WAN, which would record both audio and video information, organize such information, and then display such information upon request.</p>
  <heading>SUMMARY OF THE INVENTION</heading> <p num="P-00009">It is one object of the present invention to provide a system and a method for recording communication sessions performed over a computer network.</p>
  <p num="P-00010">It is another object of the present invention to provide such a system and method for analyzing data transmitted over the computer network in order to detect audio and video data for recording.</p>
  <p num="P-00011">It is still another object of the present invention to provide such a system and method for displaying recorded video and audio data upon request.</p>
  <p num="P-00012">It is yet another object of the present invention to provide such a system and method for analyzing, recording and displaying communication sessions conducted with a LAN-based telephone system.</p>
  <p num="P-00013">These and other objects of the present invention are explained in further detail with regard to the drawings, description and claims provided below.</p>
  <p num="P-00014">The present invention provides a system and a method for analyzing data packets on a computer network, for selectively recording audio and video data packets, for organizing this stored information and for displaying the stored information upon request, such that communication sessions with computer network-based “telephone” systems can be logged.</p>
  <p num="P-00015">According to the teachings of the present invention, there is provided a system for managing a communication session over a computer network, the system comprising: (a) a network connector for connecting to the computer network and for receiving data packets from the computer network; (b) a filtering unit for filtering the data packets and for accepting the data packets substantially only if the data packets contain data selected from the group consisting of audio data and video data, such that the data packets form at least a portion of the communication session and such that the data packets are selected data packets; (c) a management unit for receiving the selected data packets and for storing the selected data packets, such that the selected data packets are stored data packets; and (d) a storage medium for receiving and for storing the stored data packets from the management unit, such that the at least a portion of the communication session is stored.</p>
  <p num="P-00016">Preferably, the system further comprises (e) a data restore unit for retrieving and displaying the at least a portion of the communication session, the data restore unit requesting the data packets from the storage medium through the management unit, and the data restore unit reconstructing the data packets for displaying the at least a portion of the communication session.</p>
  <p num="P-00017">More preferably, the data restore unit further comprises a communication session display unit for displaying the at least a portion of the communication session. Most preferably, the communication session display unit is selected from the group consisting of a video unit and an audio unit.</p>
  <p num="P-00018">According to preferred embodiments of the present invention, the system further comprises (f) a database connected to the filtering unit for storing filtering information, the filtering information including at least one IP address of a party whose communication sessions are monitored; wherein the filtering unit accepts the data packets according to the filtering information, such that the filtering unit substantially only accepts the data packets if the data packets fulfill the filtering information.</p>
  <p num="P-00019">Preferably, the system further comprises (g) a user computer for receiving at least one command of a user and for displaying information to the user, such that the user determines the filtering information according to the at least one command of the user.</p>
  <p num="P-00020">More preferably, the computer network is selected from the group consisting of a LAN (local area network) and a WAN (wide area network). Most preferably, the computer network is a LAN (local area network).</p>
  <p num="P-00021">According to further preferred embodiments of the present invention, the LAN is divided into at least two segments, the system further comprising: (h) a local management unit for each segment, the local management unit including the filtering unit and the management unit; and (i) a central management unit for controlling the local management units, the central management unit controlling storage in the storage medium.</p>
  <p num="P-00022">Preferably, the network connector is a network interface card.</p>
  <p num="P-00023">According to another embodiment of the present invention, there is provided a method for storing at least a portion of a communication session performed on a computer network, the communication session being performed between a packet source and a packet destination, the steps of the method being performed by a data processor, the method comprising the steps of: (a) receiving a data packet from the packet source on the computer network; (b) analyzing the data packet to determine if the data packet is an IP packet; (c) if the data packet is the IP packet, filtering the IP packet to determine a type of the IP packet; and (d) storing the IP packet to form a stored data packet according to the type, such that the stored data packet forms at least a portion of the communication session. Preferably, the step of analyzing the data packet is performed by examining a header of the data packet.</p>
  <p num="P-00024">According to a preferred embodiment of the present invention, the step of filtering the IP packet is performed by examining the header of the IP packet.</p>
  <p num="P-00025">Preferably, the step of filtering the IP packet further comprises the steps of: (i) examining the header of the IP packet to determine an IP address of the packet source; (ii) determining if the IP address is a recorded IP address; (iii) passing the IP packet to form a passed IP packet substantially only if the IP address is the recorded IP address; and (iv) alternatively, dumping the IP packet.</p>
  <p num="P-00026">More preferably, the step of determining if the IP address is the recorded IP address is performed by comparing the IP address to a list of IP addresses from packet sources, such that if the IP address is included in the list, the IP address is the recorded IP address.</p>
  <p num="P-00027">Also preferably, the step of filtering the IP packet further comprises the steps of: (v) determining whether the passed IP packet is an H.225 packet, a H.245 packet, an RTP packet or an RTCP packet; (vi) if the type of the passed IP packet is the H.225 packet, determining whether the H.225 packet is a setup packet or a connect packet; (vii) if the H.225 packet is the setup packet, setting a status flag as “start session request”; (viii) alternatively, if the H.225 packet is the connect packet and the status flag is “start session request”, storing at least one detail of the communication session; and (ix) setting the status flag as “wait for logic channel”.</p>
  <p num="P-00028">More preferably, the step of filtering the IP packet further comprises the steps of: (x) alternatively, if the type of the passed IP packet is the H.245 packet, determining whether the H.245 packet is an open logical channel request packet, an open logical channel acknowledgment packet or a terminal capability set packet; (xi) if the H.245 packet is the open logical channel request packet and the status flag is “wait for logic channel”, setting the status flag as “wait for acknowledgment”; (xii) alternatively, if the H.245 packet is the open logical channel acknowledgment packet and the status flag is “wait for acknowledgment”, performing the steps of: (A) setting the status flag as “wait for terminal capability”; and (B) saving a transport address of the destination of the communication session; and (xiii) also alternatively, if the H.245 packet is the terminal capability set packet, performing the steps of: (A) storing a capability of the packet destination from the terminal capability packet; and (B) setting the status flag as “in call process”.</p>
  <p num="P-00029">Most preferably, if the status flag is “in call process” and the type of the passed IP packet is the RTP packet, the RTP packet is stored. Also most preferably, if the status flag is “in call process” and the type of the passed IP packet is the RTCP packet, the RTCP packet is stored.</p>
  <p num="P-00030">According to another preferred embodiment of the present invention, the method further comprises the steps of: (e) retrieving the stored data packet to form a retrieved data packet; and (i) reconstructing at least a portion of the communication session according to the retrieved data packet.</p>
  <p num="P-00031">Preferably, the step of retrieving the data packet includes the steps of: (i) receiving a source IP address of the packet source, a start time of the communication session, and an end time of the communication session; and (ii) selecting at least one communication session according to the source IP address, the start time and the end time.</p>
  <p num="P-00032">Also preferably, the step of reconstructing at least a portion of the communication session includes displaying audio data.</p>
  <p num="P-00033">Alternatively and also preferably, the step of reconstructing at least a portion of the communication session includes displaying video data.</p>
  <p num="P-00034">More preferably, the step of reconstructing at least a portion of the communication session further comprises the steps of: (i) retrieving substantially only RTP packets; (ii) examining a header of the RTP packets to determine a time stamp for each of the RTP packets; and (iii) displaying the RTP packets in an order according to the time stamp.</p>
  <p num="P-00035">Hereinafter, the term “communication session” includes both a conversation, in which at least two parties converse by exchanging audio and/or video information in “real time”, and a message, in which at least one party records such audio and/or video information for reception by at least one other party at a later date.</p>
  <p num="P-00036">Hereinafter, the term “Internet” is used to generally designate the global, linked web of thousands of networks which is used to connect computers all over the world. As used herein, the term “intranet” includes other types of computer networks, such as LAN (local area networks) or WAN (wide area networks). The term “computer network” includes any connection between at least two computers which permits the transmission of data, including both Internet and intranet. The term “regular telephony network” includes POTS (plain old telephone system) and substantially any other type of telephone network which provides services through a regular telephone services provider, but which specifically excludes audio and/or video communication performed through any type of computer network.</p>
  <p num="P-00037">Hereinafter, the term “computer” includes, but is not limited to, personal computers (PC) having an operating system such as DOS, Windows™, OS/2™ or Linux; MacIntosh™ computers; computers having JAVA™-OS as the operating system; and graphical workstations such as the computers of Sun Microsystems™ and Silicon Graphics™, and other computers having some version of the UNIX operating system such as AIX or SOLARIS™ of Sun Microsystems™; or any other known and available operating system. Hereinafter, the term “Windows™” includes but is not limited to Windows95™, Windows 3.x™ in which “x” is an integer such as “1”, Windows NT™, Windows98™, Windows CE™ and any upgraded versions of these operating systems by Microsoft Inc. (Seattle, Wash., USA).</p>
  <p num="P-00038">Hereinafter, the term “logging” refers to the process of analyzing data packets on a network to locate audio and/or video data, and of recording such data in an organized system. Hereinafter, the term “display” includes both the visual display of video data, and the production of sound for audio data.</p>
<description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="P-00039">The invention is herein described, by way of example only, with reference to the accompanying drawings, wherein:</p>
    <p num="P-00040"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a schematic block diagram of an exemplary communication session monitoring system according to the present invention;</p>
    <p num="P-00041"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a schematic block diagram of the software modules required for operating the system of <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
    <p num="P-00042"> <figref idrefs="DRAWINGS">FIGS. 3A-3D</figref> are flowcharts of exemplary filtering and recording methods according to the present invention;</p>
    <p num="P-00043"> <figref idrefs="DRAWINGS">FIGS. 4A-4D</figref> are schematic block diagrams showing the headers of H.225 (FIG. <b>4</b>A), H.245 (FIG. <b>4</b>B), RTP (<figref idrefs="DRAWINGS">FIG. 4C</figref>) and RTCP (<figref idrefs="DRAWINGS">FIG. 4D</figref>) packets, as they relate to the present invention;</p>
    <p num="P-00044"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a flowchart of an exemplary communication session playback method according to the present invention;</p>
    <p num="P-00045"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a schematic block diagram of an exemplary first embodiment of a basic system using the communication session monitoring system of <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref> according to the present invention; and</p>
    <p num="P-00046"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a schematic block diagram of an exemplary second embodiment of a zone system according to the present invention.</p>
  </description-of-drawings> <heading>DESCRIPTION OF BACKGROUND ART</heading> <p num="P-00047">The following description is intended to provide a description of certain background methods and technologies which are optionally used in the method and system of the present invention. The present invention is specifically not drawn to these methods and technologies alone. Rather, they are used as tools to accomplish the goal of the present invention, which is a system and a method for analyzing data packets on a computer network, for selectively recording audio and video data packets, for organizing this stored information and for displaying the stored information upon request, such that communication sessions with computer network-based “telephone” systems can be logged.</p>
  <p num="P-00048">The system and method of the present invention is particularly intended for operation with computer networks constructed according to the ITU-T Recommendation H.323 for visual telephone systems and equipment for local area networks which provide a non-guaranteed quality of service. Recommendation H.323 is herein incorporated by reference in order to further describe the hardware requirements and operating protocols for such computer networks, and is hereinafter referred to as “H.323”.</p>
  <p num="P-00049">H.323 describes terminals, equipment and services for multimedia communication over Local Area Networks (LAN) which do not provide a guaranteed quality of service. Computer terminals and equipment which fulfill H.323 may carry real-time voice, data and video, or any combination, including videotelephony.</p>
  <p num="P-00050">The LAN over which such terminals communicate can be a single segment or ring, or optionally can include multiple segments with complex topologies. These terminals are optionally integrated into computers or alternatively are implemented in stand-alone devices such as videotelephones. Support for voice data is required, while support for general data and video data are optional, but if supported, the ability to use a specified common mode of operation is required, so that all terminals supporting that particular media type can communicate. The H.323 Recommendation allows more than one channel of each type to be in use. Other Recommendations in the H.323-Series which are also incorporated by reference include H.225.0 packet and synchronization; H.245 control, H.261 and H.263 video codecs, G.711, G.722, G.728, G.729, and G.723 audio codecs, and the T.120-Series of multimedia communications protocols.</p>
  <p num="P-00051">ITU-T Recommendation H.245.0 covers the definition of Media stream packetization and synchronization for visual telephone systems. ITU-T Recommendation H.245.0 defines the Control protocol for multimedia communications, and is hereinafter referred to as “H.245”. H.245 is incorporated by reference as is fully set forth herein.</p>
  <p num="P-00052">The logical channel signaling procedures of H.245 describes the content of each logical channel when the channel is opened. Procedures are provided for the communication of the functional capabilities of receivers and transmitters, so that transmissions are limited to information which can be decoded by the receivers, and so that receivers may request a particular desired mode from transmitters.</p>
  <p num="P-00053">H.245 signaling is established between two endpoints: an endpoint and a multipoint controller, or an endpoint and a Gatekeeper. The endpoint establishes exactly one H.245 Control Channel for each call that the endpoint is participating in. The channel must then operate according to H.245. Support for multiple calls and hence for multiple H.245 Control Channels is possible.</p>
  <p num="P-00054">The RAS signaling function uses H.225.0 messages to perform registration, admissions, bandwidth changes, status, and disengage procedures between endpoints and Gatekeepers. In LAN environments that do not have a Gatekeeper, the RAS Signaling Channel is not used. In LAN environments which contain a Gatekeeper, such that the LAN includes at least one Zone, the RAS Signaling Channel is opened between the endpoint and the Gatekeeper. The RAS Signaling Channel is opened prior to the establishment of any other channels between H.323 endpoints.</p>
  <p num="P-00055">The call signaling function uses H.225.0 call signaling to establish a connection between two H.323 endpoints. The Call Signaling Channel is independent from the RAS Channel and the H.245 Control Channel. The Call Signaling Channel is opened prior to the establishment of the H.245 Channel and any other logical channels between H.323 endpoints. In systems that do not have a Gatekeeper, the Call Signaling Channel is opened between the two endpoints involved in the call. In systems which contain a Gatekeeper, the Call Signaling Channel is opened between the end point and the Gatekeeper, or between the endpoints themselves as chosen by the Gatekeeper.</p>
  <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p num="P-00056">The present invention provides a system and a method for analyzing data packets on a computer network, for selectively recording audio and video data packets, for organizing this stored information and for displaying the stored information upon request, such that communication sessions with computer network-based “telephone” systems can be logged.</p>
  <p num="P-00057">The principles and operation of a method and a system according to the present invention may be better understood with reference to the drawings and the accompanying description.</p>
  <p num="P-00058">Referring now to the drawings, <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram of an exemplary system for logging and displaying audio and/or visual data from communication sessions performed over a computer network. A computer logging system <b>10</b> features a user computer <b>12</b> connected to a communication session management unit <b>13</b>. Communication session management unit <b>13</b> is in turn connected to an intranet <b>14</b> through a network interface card (NIC) <b>16</b>.</p>
  <p num="P-00059">User computer <b>12</b> includes a user interface <b>18</b>, which is preferably a GUI (graphical user interface), which is displayed on a display unit <b>20</b>. User interface <b>18</b> preferably enables the user to enter such information as the definition of the parties whose calls should to be monitored and/or logged, and which also preferably enables the user to enter at least one command for retrieving and displaying a communication session.</p>
  <p num="P-00060">Display unit <b>20</b> is preferably a computer monitor. The user is able to interact with user computer <b>12</b> by entering data and commands through a data entry device <b>22</b>. Data entry device <b>22</b> preferably includes at least a keyboard or a pointing device such as a mouse, and more preferably includes both a keyboard and a pointing device. According to one preferred embodiment of the present invention, user computer <b>12</b> is a PC (personal computer). Alternatively and preferably, user computer <b>12</b> is a “thin client” such a net computer which is a computer able to communicate on an IP-based network. One example of such a net computer is the JavaStation™ (Sun Microsystems). The advantage of such net computers is that they allow the user to interact with complex, sophisticated software programs, yet generally do not have all of the powerful computing capabilities of currently available PC computers.</p>
  <p num="P-00061">Intranet <b>14</b> could be a LAN or a WAN, for example. The connection between communication session management unit <b>13</b> and intranet <b>14</b> occurs through NIC <b>16</b>. NIC <b>16</b> is preferably any standard, off-the-shelf commercial product which enables communication session management unit <b>13</b> to be connected to any suitable computer network (for example, Etherlink II ISA/PCMCIA Adapter or Etherlink III PCI Bus-Master Adapter (3c590) of 3-Corn™, or NE2000 Adapter of Novell™ or any other such suitable product). Examples of such suitable computer networks include, but are not limited to, any standard LAN such as Ethernet (IEEE Standard 802.3), Fast Ethernet (IEEE Standard 802.10), Token Ring (IEEE Standard 802.5) and FDDI.</p>
  <p num="P-00062">All data packet traffic on intranet <b>14</b> is passed to a filtering module <b>24</b> through NIC <b>16</b>. As shown in more detail in <figref idrefs="DRAWINGS">FIG. 3</figref> below, filtering module <b>24</b> screens the data packets in order to determine which data packets fulfill the following criteria. Briefly, the data packets should be IP packets with headers according to the H.225 and H.245 standards, indicating voice and/or video traffic. As noted previously, these standards define media stream packet construction and synchronization for visual telephone systems and the control protocol for multimedia communications.</p>
  <p num="P-00063">Filtering module <b>24</b> then preferably passes substantially only those data packets which meet these criteria to a management module <b>28</b>. In the Zone Configuration of the system of the present invention, shown in <figref idrefs="DRAWINGS">FIG. 7</figref> below, filtering module <b>24</b> preferably also transfers messages from other communication session management units.</p>
  <p num="P-00064">Management module <b>28</b> receives the data packets passed through by filtering module <b>24</b>, and analyzes the received data packets. Optionally and preferably, a database <b>26</b> stores such information as the IP addresses of parties whose communication sessions should be logged, as well as the conversion table associating each party with at least one IP address, for example. The stored list of IP addresses representing those parties whose calls should be logged is preferably user-defined. As used herein, the term “party” refers to a person or persons communicating through a computer network-based telephone system. The latter preferred requirement significantly reduces the amount of data stored by including only data which is of interest to the user. Management module <b>28</b> analyzes and manages data in accordance with the applicable H.225 and H.245 specifications, including the H.245 control function, RAS signaling function and call signaling function, substantially as described above in the “Description of the Background Art” section.</p>
  <p num="P-00065">Management module <b>28</b> analyzes the packets in order to determine the specific communication session to which the data packets belong, the type of data compression being used (if any), and whether the data packets were sent from an IP address which should be monitored. Management module <b>28</b> must perform this analysis since filtering module <b>24</b> simply passes all data packets which fulfill the criteria described briefly above (see <figref idrefs="DRAWINGS">FIGS. 3A-3D</figref> for more detail). Since these packets are passed without regard to any of the information stored in database <b>26</b>, management module <b>28</b> must compare the rules of database <b>26</b> to the information present in the packet header of each packet in order to determine whether the received packet should be stored.</p>
  <p num="P-00066">Those received packets which fulfill the rules of database <b>26</b> are then stored in a storage medium <b>30</b>, which is preferably a high capacity digital data storage device such as a hard disk magnetic storage device, an optical disk, a CD-ROM, a ZIP or DVD drive, or a DAT cassette, or a combination of such devices according to the operational needs of specific applications, or any other suitable storage media. Preferably, the specific communication session or “telephone call”, with which each data packet is associated, is also stored in order for that session to be reconstructed and displayed at a later time.</p>
  <p num="P-00067">Upon request by the user, management module <b>28</b> can then retrieve one or more data packets from storage medium <b>30</b> which are associated with one or more communication sessions. The retrieved packet or packets are then transferred to a data restore module <b>32</b>. Data restore module <b>32</b> is preferably capable of manipulating these retrieved packets to restore a particular communication session by using the RTP (Real Time Protocol). As described in further detail below with regard to <figref idrefs="DRAWINGS">FIGS. 4C and 5</figref>, in those systems which follow the RTP, the data packets are sent with a time stamp in the header rather than just a sequence number. Such a time stamp is necessary for audio and video stream data, in order for the data packets to be reassembled such that the overall timing of the stream of data is maintained. Without such a time stamp, the proper timing would not be maintained, and the audio or video streams could not be accurately reconstructed.</p>
  <p num="P-00068">The communication sessions are restored from the reconstructed streams of data packets by using the applicable audio and/or video CODEC's. A CODEC is a non-linear method for the conversion of analog and digital data. Thus, an audio CODEC enables the digitized audio data in relevant data packets to be converted to analog audio data for display to the user as audible sounds, for example. Suitable CODEC's are described in greater detail below with regard to FIG. <b>5</b>.</p>
  <p num="P-00069">In order for the user to receive the display of the reconstructed communication session, system <b>10</b> preferably features an audio unit <b>34</b> and a video unit <b>36</b>, collectively referred to as a “communication session display unit”. More preferably, both audio unit <b>34</b> and video unit <b>36</b> are capable of both receiving audio or video input, respectively, and of displaying audio or video output. At the very least, audio unit <b>34</b> and video unit <b>36</b> should be able to display audio or video output, respectively. For example, audio unit <b>34</b> could optionally include an microphone for input and a speaker or an earphone for output. Video unit <b>36</b> could optionally include a video monitor or display screen for output and a video camera for input, for example.</p>
  <p num="P-00070"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a schematic block diagram of system <b>10</b> of <figref idrefs="DRAWINGS">FIG. 1</figref>, showing the overall system of software modules of system <b>10</b> in more detail. Reference is also made, where appropriate, to flow charts showing the operation of these software modules in more detail (<figref idrefs="DRAWINGS">FIGS. 3A-3D</figref> and FIG. <b>5</b>), as well as to descriptions of the headers of the different types of data packets (FIGS. <b>4</b>A-<b>4</b>D).</p>
  <p num="P-00071">As shown, system <b>10</b> again includes a connection to intranet <b>14</b> through NIC <b>16</b>. As the packets are transmitted through intranet <b>14</b>, NIC <b>16</b> intercepts these data packets and passes them to filtering module <b>24</b>.</p>
  <p num="P-00072">Filtering module <b>24</b> has two components. A first filtering component <b>38</b> examines the header of the data packet, which should be an IP type packet with the correct header, as shown in <figref idrefs="DRAWINGS">FIG. 4A</figref> below. Next, first filtering component <b>38</b> passes the data packet to a second filtering component <b>40</b>. Second filtering component <b>40</b> then determines the type of IP data packet, which could be constructed according to the H.225, H.245, RTP or RTCP standards.</p>
  <p num="P-00073">As shown with reference to <figref idrefs="DRAWINGS">FIG. 3A</figref>, first filtering component <b>38</b> and second filtering component <b>40</b> operate as follows. In step one, a packet is received by filtering module <b>24</b>. The packet is given to first filtering component <b>38</b>, which then determines whether the packet is an IP type packet in step two. Such a determination is performed according to the structure of the header of the data packet, an example of which is shown in <figref idrefs="DRAWINGS">FIG. 4A. A</figref> header <b>42</b> is shown as a plurality of boxes, each of which represents a portion or “field” of the header. The number of bytes occupied by each portion is also shown, it being understood that each layer consists of 32 bits. The first portion of the header, a “VERS” portion <b>44</b>, is the protocol version number. Next, an “H. LEN” portion <b>46</b> indicates the number of 32-bit quantities in the header. A “SERVICE TYPE” portion <b>48</b> indicates whether the sender prefers the datagram to travel over a route with minimal delay or a route with maximal throughput. A “TOTAL LENGTH” portion <b>50</b> indicates the total number of octets in both the header and the data.</p>
  <p num="P-00074">In the next layer, an “IDENTIFICATION” portion <b>52</b> identifies the packet itself. A “FLAGS” portion <b>54</b> indicates whether the datagram is a fragment or a complete datagram. A “FRAGMENT OFFSET” portion <b>56</b> species the location of this fragment in the original datagram, if the datagram is fragmented. In the next layer, a “TIME TO LIVE” portion <b>58</b> contains a positive integer between 1 and 255, which is progressively decremented at each route traveled. When the value becomes 0, the packet will no longer be passed and is returned to the sender. A “TYPE” portion <b>60</b> indicates the type of data being passed. A “HEADER CHECKSUM” portion <b>62</b> enables the integrity of the packet to be checked by comparing the actual checksum to the value recorded in portion <b>62</b>.</p>
  <p num="P-00075">The next layer of header <b>42</b> contains the source IP address <b>64</b>, after which the following layer contains the destination IP address <b>66</b>. An optional IP OPTIONS portion <b>68</b> is present, after which there is padding (if necessary) and a data portion <b>70</b> of the packet containing the data begins.</p>
  <p num="P-00076">The structure of the header of the data packet is examined by first filtering component <b>38</b> to determine whether this header has the necessary data fields in the correct order, such that the header of the data packet has a structure according to header <b>42</b>. First filtering component <b>38</b> only allows those packets with the correct header structure to pass, as shown in step <b>3</b>A. Otherwise, the packets are dumped as shown in step <b>3</b>B.</p>
  <p num="P-00077">Those packets with the correct header, or “IP packets”, are then passed to second filtering component <b>40</b>. Second filtering component <b>40</b> then performs the remainder of the filtering steps. In step <b>3</b>A, second filtering component <b>40</b> examines the IP packets to determine their type from the data portion of the packet as shown in FIG. <b>4</b>A. The packets could be in one of four categories: H.225, H.245, RTP and RTCP. The steps of the method for H.225 packets are shown in <figref idrefs="DRAWINGS">FIG. 3A</figref>, while the procedures for the remaining packet types are shown in <figref idrefs="DRAWINGS">FIGS. 3B-3D</figref>, respectively.</p>
  <p num="P-00078">Once the type of the packet has been determined, both the packet itself and the information regarding the type of packet are both passed to management module <b>28</b>, as shown in FIG. <b>2</b>. The packet is then passed to the relevant component within management module <b>28</b>, also as shown in <figref idrefs="DRAWINGS">FIG. 2</figref>, for the recording process to be performed. The recorded packets are stored in storage module <b>30</b>, as described in greater detail below with regard to <figref idrefs="DRAWINGS">FIGS. 3C and 3D</figref>.</p>
  <p num="P-00079">If the packet has been determined to be an H.225 packet according to the header of the packet (see FIG. <b>4</b>B), the packet is passed to an H.225 call control module <b>78</b> within management module <b>28</b>, as shown in FIG. <b>2</b>. The steps of the management method are as follows, with reference to FIG. <b>3</b>A. In step <b>4</b>A of <figref idrefs="DRAWINGS">FIG. 3A</figref>, the H.225 packet is examined to see if it is a setup packet, which is determined according to the structure of the data in the packet. This structure is specified in the H.225.0 recommendation, and includes at least the following types of information:
</p> <ul> <li id="ul200001-p00080" num="00080">protocolIdentifier (the version of H.225.0 which is supported);</li> <li id="ul200001-p00081" num="00081">h245Address (specific transport address on which H.245 signaling is to be established by the calling endpoint or gatekeeper);</li> <li id="ul200001-p00082" num="00082">sourceAddress (the H.323.sub.—ID's for the source);</li> <li id="ul200001-p00083" num="00083">sourceInfo (contains an EndpointType to enable the party being called to determine whether the call includes a gateway or not); and</li> <li id="ul200001-p00084" num="00084">destinationaddress (this is the address to which the endpoint wants to be connected).</li> </ul> <p num="P-00085">Other types of data are also required, as specified in the H.225.0 Recommendation. This data structure enables H.225 call control module <b>78</b> to determine whether the packet is a setup packet.</p>
  <p num="P-00086">If this packet is a setup packet, then the first branch of the method is followed. The source port is taken from a source port field <b>74</b> of an H.225 header <b>72</b>, and the destination port is taken from a destination port field <b>76</b> (see FIG. <b>4</b>B). In step <b>5</b>A, database <b>26</b> of <figref idrefs="DRAWINGS">FIG. 1</figref> is then examined to determine whether either of the corresponding terminals is defined as a recording terminal; that is, whether communication sessions initiated by the IP address of this terminal should be monitored. If true, then in step <b>6</b>A, the terminal status is set as a start session request from the terminal corresponding to the source port.</p>
  <p num="P-00087">Alternatively, the packet is examined to see if it is a connect packet in step <b>4</b>B, which is determined according to the structure of the data in the packet. This structure is specified in the H.225.0 recommendation, and includes at least the following types of information:
</p> <ul> <li id="ul200001-p00088" num="00088">protocolIdentifier (the version of H.225.0 which is supported);</li> <li id="ul200001-p00089" num="00089">h245Address (specific transport address on which H.245 signaling is to be established by the calling endpoint or gatekeeper);</li> <li id="ul200001-p00090" num="00090">destinationInfo (contains an EndpointType to enable the caller to determine whether the call includes a gateway or not); and</li> <li id="ul200001-p00091" num="00091">conferenceID (contains a unique identifying number to identify the particular conference).</li> </ul> <p num="P-00092">If the packet is a connect packet, then the second branch of the method is followed. In step <b>5</b>B, the flag indicating the terminal status is examined to determine if the terminal status is set as a start session request. In step <b>6</b>B, the details of the call signal are saved in a call progress database <b>78</b> of storage medium <b>30</b> (see FIG. <b>2</b>). These details preferably include the source and destination IP addresses, the source and destination ports; the time at which the communication session was initiated, and any other relevant information. In step <b>7</b>B, the status of the terminal is set to “wait for the logic channel”.</p>
  <p num="P-00093">If the packet has been determined to be an H.245 packet by second filtering component <b>40</b>, the packet is passed to an H.245 call control module <b>82</b> within management module <b>28</b>, as shown in FIG. <b>2</b>. Such H.245 packets are necessary for H.245 signaling. H.245 signaling is established between two endpoints: an endpoint and a multipoint controller, or an endpoint and a Gatekeeper (see <figref idrefs="DRAWINGS">FIGS. 6 and 7</figref> below for examples and a description of such endpoints). Each endpoint is capable of calling and of being called as part of a communication session. However, the system of the present invention only monitors, rather than initiating, such communication sessions. Thus, the system of the present invention uses the H.245 signaling to determine when the communication session has started in order to effectively record the necessary data packets for the storage and later reconstruction of the session.</p>
  <p num="P-00094">The steps of the management method for H.245 packets are as follows, with reference to FIG. <b>3</b>B. In step <b>1</b>A of <figref idrefs="DRAWINGS">FIG. 3B</figref>, the H.245 packet is examined to determine if it is an open logical channel request packet. If it is, then in step <b>2</b>A, the terminal status is examined to determine if the status is “wait for the logical channel”. If so, then in step <b>3</b>A the terminal status is set to “wait for acknowledgment”.</p>
  <p num="P-00095">Alternatively, the H.245 packet is examined to determine if it is an open logical channel acknowledgment packet, as shown in step <b>1</b>B. If it is, then in step <b>2</b>B, the terminal status is examined to determine if the status is “wait for acknowledgment”. If so, then in step <b>3</b>B the terminal status is set to “wait for terminal capability”. In step <b>4</b>B, the transport address of the “called” or destination terminal is saved. This transport address is taken from the destination port field <b>76</b> of header <b>72</b> (see FIG. <b>4</b>B). It should be noted that H.225 and H.245 packets have identical header structures.</p>
  <p num="P-00096">Also alternatively, the H.245 packet is examined to determine if it is a terminal capability set packet, as shown in step <b>1</b>C. If it is, then in step <b>2</b>C, the terminal capability is saved in call progress database <b>80</b> (see FIG. <b>2</b>). In step <b>3</b>C, the terminal status is set to “in call process”, such that the communication session has been determined to be opened and such that management module <b>28</b> can now receive RTP data packets.</p>
  <p num="P-00097">If the packet has been determined to be a RTP packet by second filtering component <b>40</b>, the packet is passed to a RAS (registration, admissions and status) control module <b>84</b> within management module <b>28</b>, as shown in FIG. <b>2</b>. The steps of the management method for RTP packets are as follows, with reference to FIG. <b>3</b>C. In step <b>1</b> of <figref idrefs="DRAWINGS">FIG. 3C</figref>, the terminal status is examined to see if it is “in call process”. If so then in step <b>2</b>, the RTP packets are saved in a RTP database <b>86</b> within storage medium <b>30</b> (see FIG. <b>2</b>). <figref idrefs="DRAWINGS">FIG. 4C</figref> shows the structure of the RTP packet header, which can be used to identify the communication session from which the packet was taken.</p>
  <p num="P-00098">Finally, if the packet has been determined to be a RTCP packet by second filtering component <b>40</b>, the packet is passed to a RTCP control module <b>88</b> within management module <b>28</b>, as shown in FIG. <b>2</b>. The steps of the management method for RTCP packets are as follows, with reference to FIG. <b>3</b>D. In step <b>1</b> of <figref idrefs="DRAWINGS">FIG. 3D</figref>, the terminal status is examined to see if it is “in call process”. If so then in step <b>2</b>, the RTCP packets are saved in call progress database <b>80</b> within storage medium <b>30</b> (see FIG. <b>2</b>). <figref idrefs="DRAWINGS">FIG. 4D</figref> shows the structure of the RTCP packet header, which can be used to identify the communication session from which the packet was taken.</p>
  <p num="P-00099">Thus, <figref idrefs="DRAWINGS">FIGS. 3A-3D</figref> illustrate the method of the present invention with regard to the filtering and storage of data packets which constitute the recorded communication session, as recorded by the system of the present invention as shown in <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref>. Of course, in addition to recording such communication sessions, the system of the present invention is also able to retrieve and to replay these communication sessions to the user. The stored communication session, composed of stored data packets, can be retrieved and displayed by data restore unit <b>32</b> of <figref idrefs="DRAWINGS">FIG. 2</figref>, in conjunction with audio unit <b>34</b> and video unit <b>36</b>. The method of retrieving and replaying sessions of interest is shown in <figref idrefs="DRAWINGS">FIG. 5</figref>, while certain other relevant portions of the system of the present invention are shown in FIG. <b>2</b>.</p>
  <p num="P-00100">In step <b>1</b> of <figref idrefs="DRAWINGS">FIG. 5</figref>, the user inputs the information concerning the communication session which is to be retrieved and replayed. This information preferably includes the terminal number, or other designation information concerning at least one of the parties of the communication session of interest; the time at which the session started; and the time at which the session ended. However, alternatively other information could be included in place of this information, as long as sufficient information is provided for the communication session of interest to be identified.</p>
  <p num="P-00101">In step <b>2</b> of <figref idrefs="DRAWINGS">FIG. 5</figref>, call progress database <b>80</b> (see <figref idrefs="DRAWINGS">FIG. 2</figref>) is searched by data restore unit <b>32</b> in order to find the details of the communication session(s) in the specified time range. These details are then compared to the information entered by the user to locate at least one communication session of interest in the call range.</p>
  <p num="P-00102">In step <b>3</b>, RTP database <b>86</b> of storage medium <b>30</b> (see <figref idrefs="DRAWINGS">FIG. 2</figref>) is searched, again by data restore unit <b>32</b>, to find substantially all data packets from the at least one communication session in the specified call range. Optionally and preferably, in step <b>4</b>, if the audio portion communication session was recorded in stereo, then the data packets are divided into different audio channels.</p>
  <p num="P-00103">In step <b>5</b>, the data packets are restored by data restore unit <b>32</b> by an RTP (Real Time Protocol) software module <b>91</b> within data restore unit <b>32</b>. RTP software module <b>91</b> orders the data packets within each channel according to the time stamp of each packet. As shown in <figref idrefs="DRAWINGS">FIG. 4C</figref>, an RTP packet header <b>92</b> features several important fields: a timestamp field <b>94</b>, a synchronization source (SSRC) identifiers field <b>96</b> and a contributing source (CSRC) identifiers field <b>98</b>. SSRC field <b>96</b> is used to determine the source of the RTP packets (the sender), which has a unique identifying address (the SSRC identifier). The CSRC identifier in CSRC field <b>98</b> is used in a conference with multiple parties, and indicates the SSRC identifier of all parties. Timestamp field <b>94</b> is used by RTP software module <b>91</b> to determine the relative time at which the data in each packet should be displayed.</p>
  <p num="P-00104">For example, preferably the audio stream data of the audio speech of one person is synchronized to that person's lip movements as shown in the video stream, a process known as “lip synchronization”. Such synchronization requires more than simply replaying audio and video data at certain relative time points, since the audio and video data packets may not arrive at the same time, and may therefore have slightly different timestamps.</p>
  <p num="P-00105">Once the data packet has been correctly synchronized, the control of the display of the audio data is then performed by an audio component <b>102</b> of data restore unit <b>32</b> according to one or more audio CODEC's (see FIG. <b>2</b>). The control of the display of the video data is then performed by a video component <b>104</b> of data restore unit <b>32</b> according to one or more video CODEC's (see FIG. <b>2</b>).</p>
  <p num="P-00106">Suitable CODEC's include, but are not limited to, an audio codec using CCITT Recommendation G.711(1988), Pulse Code Modulation (PCM) of voice frequencies; an audio codec using CCITT Recommendation G.722 (1988), 7 kHz audio-coding within 64 kbit/s; an audio codec using ITU-T Recommendation G.723.1 (1996), Speech coders: Dual rate speech coder for multimedia communications transmitting at 5.3. and 6.3 Kbps; an audio codec using CCITT Recommendation G.728 (1992), Coding of speech at 16 Kbps using low-delay code excited linear prediction; an audio codec using ITU-T Recommendation G.729 (1996), Coding of speech at 8 Kbps using conjugate structure algebraic code-excited linear-prediction (CS-ACELP); a video codec using ITU-T Recommendation H.261 (1993), Video codec for audiovisual services at p×64 kbit/s; a video code using ITU-T Recommendation H.263 (1996), Video coding for low bit rate communication; and substantially any other similar coding standard.</p>
  <p num="P-00107">As shown in <figref idrefs="DRAWINGS">FIG. 2</figref>, the audio data is displayed by audio unit <b>34</b>, which could include a loudspeaker, for example. The video data is displayed by video unit <b>36</b>, which could include a display monitor screen, for example. Step <b>5</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> is then preferably repeated, such that substantially the entirety of the communication session is displayed. As shown in step <b>6</b>, each data packet of the communication session is examined to see if the call time is over. If the individual session has not completed, preferably step <b>5</b> is repeated. Alternatively and preferably, if the call time is over, then call progress database <b>80</b> is searched to see if other communication sessions were recorded within the given time period, as shown in step <b>7</b>. If there is at least one other such communication session, then preferably the method of <figref idrefs="DRAWINGS">FIG. 5</figref> is repeated, starting from step <b>2</b>.</p>
  <p num="P-00108">According to preferred embodiments of the present invention, several configurations of the computer logging system are possible, examples of which are shown in <figref idrefs="DRAWINGS">FIGS. 6 and 7</figref>.</p>
  <p num="P-00109">According to a first embodiment of the system of the present invention, shown in <figref idrefs="DRAWINGS">FIG. 6</figref>, a typical basic configuration system <b>104</b> includes a single communication session management unit <b>13</b>, substantially as shown in <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref>, according to the present invention. Communication session management unit <b>13</b> manages communication in a stand-alone intranet such as a LAN <b>106</b>. LAN <b>106</b> is connected both to communication session management unit <b>13</b> and to a plurality of terminals <b>108</b>, designated as “T<b>1</b>”, “T<b>2</b>” and so forth, which follow the H.323 protocol. Each terminal <b>108</b> is an endpoint on LAN <b>106</b> which provides for real-time, two-way communications with another terminal <b>108</b>, a gateway <b>110</b>, or a multipoint control unit <b>112</b>. This communication consists of control, indications, audio streams, video streams, and/or data. Terminal <b>108</b> is optionally only capable of providing such communication for audio only, audio and data, audio and video, or audio, data and video. As noted previously in the “Description of the Background Art” section, the H.323 entity could be a terminal which is capable of providing audio and/or video communication as a “LAN telephone”, but could also be a stand-alone audio or video telephone.</p>
  <p num="P-00110">Gateway <b>110</b> (GW) is constructed according to H.323 and is an endpoint on LAN <b>106</b> which provides for real-time, two-way communications between terminals <b>108</b> on LAN <b>106</b> and other suitable terminals on a WAN (not shown), or to another such Gateway (not shown). Other suitable terminals include those complying with Recommendations H.310 (H.320 on B-ISDN), H.320 (ISDN), H.321 (ATM), H.322 (GQOS-LAN), H.324 (GSTN), H.324M (Mobile), and V.70 (DSVD).</p>
  <p num="P-00111">Multipoint Control Unit (MCU) <b>112</b> is an endpoint on LAN <b>106</b> which enables three or more terminals <b>108</b> and gateways <b>110</b> to participate in a multipoint conference.</p>
  <p num="P-00112">Preferably, system <b>104</b> also features a gatekeeper (GK) <b>114</b>, which is an H.323 entity on LAN <b>106</b> which provides address translation and controls access to LAN <b>106</b> for terminals <b>108</b>, gateways <b>110</b> and MCUs <b>112</b>. Gatekeeper <b>114</b> may also provide other services to terminals <b>108</b>, gateways <b>10</b> and MCUs <b>112</b> such as bandwidth management and locating gateways <b>110</b>. Preferably, gatekeeper <b>114</b> enables the IP address of terminals <b>108</b> on LAN <b>106</b> to be determined, such that the correct IP address can be determined “on the fly”.</p>
  <p num="P-00113">In addition, LAN <b>106</b> may support non audio visual devices for regular T.120 data applications such as electronic whiteboards, still image transfer, file exchange, database access, etc.</p>
  <p num="P-00114">In basic system <b>104</b>, a single, stand-alone communication session management unit <b>13</b> is used for monitoring, logging and retrieval of all audio and/or visual calls either between any two or more terminals <b>108</b> attached to LAN <b>106</b> or any call to which one or more of these terminals <b>108</b> is a party. However, for the preferred embodiment of the system of <figref idrefs="DRAWINGS">FIG. 6</figref> which includes gatekeeper <b>114</b>, as well as for the system of <figref idrefs="DRAWINGS">FIG. 7</figref>, once the communication session has been opened, preferably RAS control module <b>84</b> also performs RAS signaling between the management control module and NIC <b>16</b> where necessary for the configuration of the system. Such signaling uses H.225.0 messages to perform registration, admissions, bandwidth changes, status, and disengage procedures between endpoints and gatekeepers. These messages are passed on a RAS Signaling Channel, which is independent from the Call Signaling Channel and the H.245 Control Channel. H.245 open logical channel procedures are not used to establish the RAS Signaling Channel. In LAN environments which contain a Gatekeeper (a Zone), the RAS Signaling Channel is opened between the endpoint and the Gatekeeper. The RAS Signaling Channel is opened prior to the establishment of any other channels between H.323 endpoints.</p>
  <p num="P-00115"> <figref idrefs="DRAWINGS">FIG. 7</figref> shows a second embodiment of the system of the present invention as a zone configuration system <b>116</b>. A zone <b>118</b> is the collection of all terminals (Tx) <b>108</b>, gateways (GW) <b>110</b>, and Multipoint Control Units (MCU) <b>112</b> managed by a single gatekeeper (GK) <b>114</b>. Zone <b>118</b> includes at least one terminal <b>108</b>, but does not necessarily include one or more gateways <b>110</b> or MCUs <b>112</b>. Zone <b>118</b> has only one gatekeeper <b>114</b> as shown. However, in the preferred embodiment shown, zone <b>118</b> is preferably independent of LAN topology and preferably includes multiple LAN segments <b>120</b> which are connected using routers (R) <b>122</b> as shown or other similar devices.</p>
  <p num="P-00116">Each monitored LAN segment <b>120</b> has a local communication management unit <b>124</b> according to the present invention, of which two are shown. A central management unit <b>126</b> according to the present invention controls all local communication management units <b>124</b>. In addition to centralized database and control services, central management unit <b>126</b> can be used for the real-time monitoring and off-line restoration of audio and/or video communication sessions from a single point. Central management unit <b>126</b> is optionally and preferably either a dedicated unit similar in structure to local communication management units <b>124</b> but without the storage capability, or central management unit <b>126</b> is alternatively and preferably integrated with local communication management units <b>124</b> to provide the functionality of both local communication management unit <b>124</b> and central management unit <b>126</b> in a single station. Local communication management units <b>124</b> are preferably either communication management units <b>13</b> substantially as described in <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref>, or alternatively and preferably are simpler units which lack the capability to retrieve and display a communication session locally.</p>
  <p num="P-00117">In still another preferred embodiment of the present invention (not shown), multi-user operation based on Client/Server architecture is preferably supported for basic system <b>104</b> and zone system <b>116</b>. An unlimited number of “Client” stations may be connected anywhere on the LAN, providing users with management and monitoring/retrieval capabilities determined by the authorization level of each specific user.</p>
  <p num="P-00118">It will be appreciated that the above descriptions are intended only to serve as examples, and that many other embodiments are possible within the spirit and the scope of the present invention.</p>
</div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5101402">US5101402</a></td><td class="patent-data-table-td patent-date-value">May 24, 1988</td><td class="patent-data-table-td patent-date-value">Mar 31, 1992</td><td class="patent-data-table-td ">Digital Equipment Corporation</td><td class="patent-data-table-td ">Apparatus and method for realtime monitoring of network sessions in a local area network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5351243">US5351243</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 1991</td><td class="patent-data-table-td patent-date-value">Sep 27, 1994</td><td class="patent-data-table-td ">Digital Equipment Corporation</td><td class="patent-data-table-td ">Monitor for packets on a communications network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5430709">US5430709</a></td><td class="patent-data-table-td patent-date-value">Jun 17, 1992</td><td class="patent-data-table-td patent-date-value">Jul 4, 1995</td><td class="patent-data-table-td ">Hewlett-Packard Company</td><td class="patent-data-table-td ">Network monitoring method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5515376">US5515376</a></td><td class="patent-data-table-td patent-date-value">Jul 19, 1993</td><td class="patent-data-table-td patent-date-value">May 7, 1996</td><td class="patent-data-table-td ">Alantec, Inc.</td><td class="patent-data-table-td ">Communication apparatus and methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5664226">US5664226</a></td><td class="patent-data-table-td patent-date-value">Sep 8, 1994</td><td class="patent-data-table-td patent-date-value">Sep 2, 1997</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System for merging plurality of atomic data elements into single synchronized file by assigning ouput rate to each channel in response to presentation time duration</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5689641">US5689641</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 1993</td><td class="patent-data-table-td patent-date-value">Nov 18, 1997</td><td class="patent-data-table-td ">Vicor, Inc.</td><td class="patent-data-table-td ">Multimedia collaboration system arrangement for routing compressed AV signal through a participant site without decompressing the AV signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5717879">US5717879</a></td><td class="patent-data-table-td patent-date-value">Nov 3, 1995</td><td class="patent-data-table-td patent-date-value">Feb 10, 1998</td><td class="patent-data-table-td ">Xerox Corporation</td><td class="patent-data-table-td ">System for the capture and replay of temporal data representing collaborative activities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5742833">US5742833</a></td><td class="patent-data-table-td patent-date-value">Nov 30, 1995</td><td class="patent-data-table-td patent-date-value">Apr 21, 1998</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Programmable power management system and method for network computer stations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5848233">US5848233</a></td><td class="patent-data-table-td patent-date-value">Dec 9, 1996</td><td class="patent-data-table-td patent-date-value">Dec 8, 1998</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">In a computer network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5964839">US5964839</a></td><td class="patent-data-table-td patent-date-value">May 27, 1998</td><td class="patent-data-table-td patent-date-value">Oct 12, 1999</td><td class="patent-data-table-td ">At&amp;T Corp</td><td class="patent-data-table-td ">System and method for monitoring information flow and performing data collection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6122665">US6122665</a></td><td class="patent-data-table-td patent-date-value">Aug 26, 1998</td><td class="patent-data-table-td patent-date-value">Sep 19, 2000</td><td class="patent-data-table-td ">Sts Software System Ltd.</td><td class="patent-data-table-td ">Communication management system for computer network-based telephones</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0841832A2?cl=en">EP0841832A2</a></td><td class="patent-data-table-td patent-date-value">Oct 29, 1997</td><td class="patent-data-table-td patent-date-value">May 13, 1998</td><td class="patent-data-table-td ">AT&amp;amp;T Corp.</td><td class="patent-data-table-td ">Promiscuous network monitoring utilizing multicasting within a switch</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1997041674A2?cl=en">WO1997041674A2</a></td><td class="patent-data-table-td patent-date-value">Apr 29, 1997</td><td class="patent-data-table-td patent-date-value">Nov 6, 1997</td><td class="patent-data-table-td ">3Com Corp</td><td class="patent-data-table-td ">Packet filtering based on socket or application identification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1999044363A1?cl=en">WO1999044363A1</a></td><td class="patent-data-table-td patent-date-value">Feb 24, 1999</td><td class="patent-data-table-td patent-date-value">Sep 2, 1999</td><td class="patent-data-table-td ">Ridgeway Systems And Software</td><td class="patent-data-table-td ">Audio-video packet synchronisation at network gateway</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000028425A1?cl=en">WO2000028425A1</a></td><td class="patent-data-table-td patent-date-value">Nov 10, 1999</td><td class="patent-data-table-td patent-date-value">May 18, 2000</td><td class="patent-data-table-td ">Genesys Telecomm Lab Inc</td><td class="patent-data-table-td ">Method and apparatus for determining and initiating interaction directionality within a multimedia communication center</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000052916A1?cl=en">WO2000052916A1</a></td><td class="patent-data-table-td patent-date-value">Mar 3, 2000</td><td class="patent-data-table-td patent-date-value">Sep 8, 2000</td><td class="patent-data-table-td ">Gric Communications Inc</td><td class="patent-data-table-td ">Method and system for internet telephony using gateway</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Madeline Bodin, "<a href='http://scholar.google.com/scholar?q="Keeping+An+eye+On+Your+Agents%2C"'>Keeping An eye On Your Agents,</a>" Call Center Magazine, Feb. 1993, 4 pages.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Schulzrinne et al.: "<a href='http://scholar.google.com/scholar?q="RFC+1889%3A+RTP%3A+A+Transport+Protocol+for+Real-Time+Applications%2C"'>RFC 1889: RTP: A Transport Protocol for Real-Time Applications,</a>" Network Working Group Request for Comments, Jan. 1996 (complete document, p. 1-75).</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7400579">US7400579</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 28, 2001</td><td class="patent-data-table-td patent-date-value">Jul 15, 2008</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and apparatus for per-call filtering of H.323 packets</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120002945">US20120002945</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 15, 2011</td><td class="patent-data-table-td patent-date-value">Jan 5, 2012</td><td class="patent-data-table-td ">Falco Michael A</td><td class="patent-data-table-td ">Rtp-formatted media clips</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE40634">USRE40634</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 2006</td><td class="patent-data-table-td patent-date-value">Feb 10, 2009</td><td class="patent-data-table-td ">Verint Americas</td><td class="patent-data-table-td ">Voice interaction analysis module</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc709/defs709.htm&usg=AFQjCNFBXWYqUOVuuxerz7B8cqt9daJk7Q#C709S224000">709/224</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc709/defs709.htm&usg=AFQjCNFBXWYqUOVuuxerz7B8cqt9daJk7Q#C709S204000">709/204</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc379/defs379.htm&usg=AFQjCNEr2i5HiMlkBIt1vZADj0MjdHVCTw#C379S088010">379/88.01</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0015160000">G06F15/16</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04L0029060000">H04L29/06</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04L0029080000">H04L29/08</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0015173000">G06F15/173</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L65/608">H04L65/608</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L65/80">H04L65/80</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L43/026">H04L43/026</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L29/06027">H04L29/06027</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L65/1043">H04L65/1043</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L67/2819">H04L67/2819</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=yhVsBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L67/14">H04L67/14</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04L29/08N13</span>, <span class="nested-value">H04L29/06C2</span>, <span class="nested-value">H04L29/06M8</span>, <span class="nested-value">H04L29/06M6P</span>, <span class="nested-value">H04L29/06M2N3</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Sep 27, 2012</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 29, 2008</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 23, 2007</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20070912</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 5, 2005</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 17, 2004</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">STS SYSTEMS LTD., ISRAEL</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:NICE SYSTEMS LTD.;REEL/FRAME:015389/0565</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20041116</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">STS SYSTEMS LTD. 8 HAPNINA STREET P.O. BOX 690RA A</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:NICE SYSTEMS LTD. /AR;REEL/FRAME:015389/0565</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1RE2wRFXTi_CXbuK_H91FtHEpvcw\u0026id=yhVsBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U1XlJFOaSo31YPS4WcR0tTX71uSwQ\u0026id=yhVsBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1qfEY-fCALjKXvYK22iMaGQNOgtg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_for_restoring_a_portion_of_a_comm.pdf?id=yhVsBAABERAJ\u0026output=pdf\u0026sig=ACfU3U2sNBvSNiqX6U8pLRV272q31nhVOg"},"sample_url":"http://www.google.com/patents/reader?id=yhVsBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>