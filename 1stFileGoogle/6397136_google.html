<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6397136 - System for determining the occupancy state of a seat in a vehicle - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="System for determining the occupancy state of a seat in a vehicle"><meta name="DC.contributor" content="David S. Breed" scheme="inventor"><meta name="DC.contributor" content="Wendell Johnson" scheme="inventor"><meta name="DC.contributor" content="Wilbur E. DuVall" scheme="inventor"><meta name="DC.contributor" content="Jeffrey L. Morin" scheme="inventor"><meta name="DC.contributor" content="Kunhong Xu" scheme="inventor"><meta name="DC.contributor" content="Andrew J. Varga" scheme="inventor"><meta name="DC.contributor" content="Automotive Technologies International Inc." scheme="assignee"><meta name="DC.date" content="1999-12-29" scheme="dateSubmitted"><meta name="DC.description" content="System for determining the occupancy of a seat in a vehicle using a variety of transducers and pattern recognition technologies and techniques that applies to any combination of transducers that provide information about seat occupancy. These include weight sensors, capacitive sensors, inductive sensors, ultrasonic, optical, electromagnetic, motion, infrared, and radar among others. The system includes a processor coupled to the transducers for receiving the data from the transducers and processing the data to obtain an output indicative of the current occupancy state of the seat. An algorithm is resident in the processor and is created from a plurality of data sets, each representing a different occupancy state of the seat and being formed from data from the transducers while the seat is in that occupancy state. The algorithm produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from the transducers. The algorithm may be a neural network or neural fuzzy algorithm generated by an appropriate algorithm-generating program."><meta name="DC.date" content="2002-5-28" scheme="issued"><meta name="DC.relation" content="EP:0669227" scheme="references"><meta name="DC.relation" content="US:3275975" scheme="references"><meta name="DC.relation" content="US:4691569" scheme="references"><meta name="DC.relation" content="US:4881270" scheme="references"><meta name="DC.relation" content="US:4906940" scheme="references"><meta name="DC.relation" content="US:5008946" scheme="references"><meta name="DC.relation" content="US:5031154" scheme="references"><meta name="DC.relation" content="US:5071160" scheme="references"><meta name="DC.relation" content="US:5074583" scheme="references"><meta name="DC.relation" content="US:5118134" scheme="references"><meta name="DC.relation" content="US:5181254" scheme="references"><meta name="DC.relation" content="US:5214744" scheme="references"><meta name="DC.relation" content="US:5235339" scheme="references"><meta name="DC.relation" content="US:5298732" scheme="references"><meta name="DC.relation" content="US:5305012" scheme="references"><meta name="DC.relation" content="US:5330226" scheme="references"><meta name="DC.relation" content="US:5366241" scheme="references"><meta name="DC.relation" content="US:5390136" scheme="references"><meta name="DC.relation" content="US:5398185" scheme="references"><meta name="DC.relation" content="US:5413378" scheme="references"><meta name="DC.relation" content="US:5454591" scheme="references"><meta name="DC.relation" content="US:5482314" scheme="references"><meta name="DC.relation" content="US:5490069" scheme="references"><meta name="DC.relation" content="US:5585625" scheme="references"><meta name="DC.relation" content="US:5602734" scheme="references"><meta name="DC.relation" content="US:5605348" scheme="references"><meta name="DC.relation" content="US:5626359" scheme="references"><meta name="DC.relation" content="US:5636864" scheme="references"><meta name="DC.relation" content="US:5653462" scheme="references"><meta name="DC.relation" content="US:5684701" scheme="references"><meta name="DC.relation" content="US:5702123" scheme="references"><meta name="DC.relation" content="US:5722686" scheme="references"><meta name="DC.relation" content="US:5782485" scheme="references"><meta name="DC.relation" content="US:5829782" scheme="references"><meta name="DC.relation" content="US:5845000" scheme="references"><meta name="DC.relation" content="US:5954360" scheme="references"><meta name="DC.relation" content="US:6007095" scheme="references"><meta name="DC.relation" content="US:6078854" scheme="references"><meta name="DC.relation" content="US:6081757" scheme="references"><meta name="citation_reference" content="Integrated CAE Modeling of Intelligent Restraint Systems, M. Murad et al., SAE Technical Paper Series No. 2000-01-0606, Mar. 6-9, 2000."><meta name="citation_patent_number" content="US:6397136"><meta name="citation_patent_application_number" content="US:09/474,147"><link rel="canonical" href="http://www.google.com/patents/US6397136"/><meta property="og:url" content="http://www.google.com/patents/US6397136"/><meta name="title" content="Patent US6397136 - System for determining the occupancy state of a seat in a vehicle"/><meta name="description" content="System for determining the occupancy of a seat in a vehicle using a variety of transducers and pattern recognition technologies and techniques that applies to any combination of transducers that provide information about seat occupancy. These include weight sensors, capacitive sensors, inductive sensors, ultrasonic, optical, electromagnetic, motion, infrared, and radar among others. The system includes a processor coupled to the transducers for receiving the data from the transducers and processing the data to obtain an output indicative of the current occupancy state of the seat. An algorithm is resident in the processor and is created from a plurality of data sets, each representing a different occupancy state of the seat and being formed from data from the transducers while the seat is in that occupancy state. The algorithm produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from the transducers. The algorithm may be a neural network or neural fuzzy algorithm generated by an appropriate algorithm-generating program."/><meta property="og:title" content="Patent US6397136 - System for determining the occupancy state of a seat in a vehicle"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("dlPsU4LHCtTSsASYlIDICw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CZE"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("dlPsU4LHCtTSsASYlIDICw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CZE"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6397136?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6397136"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=vf1ZBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6397136&amp;usg=AFQjCNFrM5hiJiuyltVP92K-0B0cc6o2FA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6397136.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6397136.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6397136" style="display:none"><span itemprop="description">System for determining the occupancy of a seat in a vehicle using a variety of transducers and pattern recognition technologies and techniques that applies to any combination of transducers that provide information about seat occupancy. These include weight sensors, capacitive sensors, inductive sensors,...</span><span itemprop="url">http://www.google.com/patents/US6397136?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6397136 - System for determining the occupancy state of a seat in a vehicle</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6397136 - System for determining the occupancy state of a seat in a vehicle" title="Patent US6397136 - System for determining the occupancy state of a seat in a vehicle"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6397136 B1</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/474,147</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">May 28, 2002</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Dec 29, 1999</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Feb 6, 1997</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Lapsed</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/DE10084638T0">DE10084638T0</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE10084638T1">DE10084638T1</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6459973">US6459973</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20020082756">US20020082756</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2001014910A2">WO2001014910A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2001014910A3">WO2001014910A3</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09474147, </span><span class="patent-bibdata-value">474147, </span><span class="patent-bibdata-value">US 6397136 B1, </span><span class="patent-bibdata-value">US 6397136B1, </span><span class="patent-bibdata-value">US-B1-6397136, </span><span class="patent-bibdata-value">US6397136 B1, </span><span class="patent-bibdata-value">US6397136B1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22David+S.+Breed%22">David S. Breed</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Wendell+Johnson%22">Wendell Johnson</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Wilbur+E.+DuVall%22">Wilbur E. DuVall</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jeffrey+L.+Morin%22">Jeffrey L. Morin</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Kunhong+Xu%22">Kunhong Xu</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Andrew+J.+Varga%22">Andrew J. Varga</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Automotive+Technologies+International+Inc.%22">Automotive Technologies International Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6397136.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6397136.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6397136.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (39),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (1),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (51),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (31),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (11)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6397136&usg=AFQjCNHZ3oiBxyrunA2OY9dHMVrbpbBfBQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6397136&usg=AFQjCNH7W_ByyNxH5aE8JguP6CB46XelLA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6397136B1%26KC%3DB1%26FT%3DD&usg=AFQjCNHzFxUh27Hem5ZMhm5mfhfSBBsbnA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54915170" lang="EN" load-source="patent-office">System for determining the occupancy state of a seat in a vehicle</invention-title></span><br><span class="patent-number">US 6397136 B1</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50322977" lang="EN" load-source="patent-office"> <div class="abstract">System for determining the occupancy of a seat in a vehicle using a variety of transducers and pattern recognition technologies and techniques that applies to any combination of transducers that provide information about seat occupancy. These include weight sensors, capacitive sensors, inductive sensors, ultrasonic, optical, electromagnetic, motion, infrared, and radar among others. The system includes a processor coupled to the transducers for receiving the data from the transducers and processing the data to obtain an output indicative of the current occupancy state of the seat. An algorithm is resident in the processor and is created from a plurality of data sets, each representing a different occupancy state of the seat and being formed from data from the transducers while the seat is in that occupancy state. The algorithm produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from the transducers. The algorithm may be a neural network or neural fuzzy algorithm generated by an appropriate algorithm-generating program.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(13)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6397136B1/US06397136-20020528-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(70)</span></span></div><div class="patent-text"><div mxw-id="PCLM8296739" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>We claim: </claim-statement> <div class="claim"> <div num="1" id="US-6397136-B1-CLM-00001" class="claim">
      <div class="claim-text">1. A system for determining the occupancy state of a seat in a vehicle in combination with the vehicle, the system comprising:</div>
      <div class="claim-text">a plurality of transducers arranged in the vehicle, each of said transducers providing data relating to the occupancy state of the seat; and </div>
      <div class="claim-text">processor means coupled to said transducers for receiving the data from said transducers and processing the data to obtain an output indicative of the current occupancy state of the seat, said processor means comprising a trained pattern recognition algorithm created from a plurality of data sets, each of said data sets representing a different occupancy state of the seat and being formed from data from said transducers while the seat is in that occupancy state, </div>
      <div class="claim-text">said trained pattern recognition algorithm producing the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from said transducers. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6397136-B1-CLM-00002" class="claim">
      <div class="claim-text">2. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein each of said transducers generates only a single stream of data relating to the occupancy state of the seat and said processor means are arranged to accept only the single stream of data from each of said transducers such that the stream of data from each of said transducers is passed to said processor means without combining with another stream of data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6397136-B1-CLM-00003" class="claim">
      <div class="claim-text">3. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein at least one of said transducers is a reclining angle detecting sensor for detecting a tilt angle of a back portion of the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6397136-B1-CLM-00004" class="claim">
      <div class="claim-text">4. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein one of said transducers is a seat position sensor for detecting the position of the seat relative to a fixed reference point in the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6397136-B1-CLM-00005" class="claim">
      <div class="claim-text">5. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein one of said transducers is a heartbeat sensor for sensing a heartbeat of an occupying item of the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6397136-B1-CLM-00006" class="claim">
      <div class="claim-text">6. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said transducers include a plurality of weight sensors, each of said weight sensors measuring the weight applied onto the seat at a different location.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" id="US-6397136-B1-CLM-00007" class="claim">
      <div class="claim-text">7. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said transducers include a weight sensor arranged to measure the weight applied to a surface of a seat portion of the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" id="US-6397136-B1-CLM-00008" class="claim">
      <div class="claim-text">8. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said transducers include a force, pressure or strain gage arranged to measure the weight applied to the entire seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" id="US-6397136-B1-CLM-00009" class="claim">
      <div class="claim-text">9. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00008">claim 8</claim-ref>, wherein the seat includes a support structure for supporting the seat above a floor of a passenger compartment of the vehicle, said force, pressure or strain gage being attached to the support structure.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" id="US-6397136-B1-CLM-00010" class="claim">
      <div class="claim-text">10. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said transducers include a plurality of electromagnetic wave sensors capable of receiving waves at least from a space above the seat, each of said electromagnetic wave sensors being arranged at a different location.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" id="US-6397136-B1-CLM-00011" class="claim">
      <div class="claim-text">11. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said transducers include at least two ultrasonic sensors capable of receiving waves at least from a space above the seat, each of said ultrasonic sensors being arranged at a different location.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" id="US-6397136-B1-CLM-00012" class="claim">
      <div class="claim-text">12. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00011">claim 11</claim-ref>, wherein a first one of said two ultrasonic sensors is arranged on or adjacent to a ceiling of the vehicle and a second one of said two ultrasonic sensors is arranged at a different location in the vehicle such that an axis connecting said first and second ultrasonic sensors is substantially parallel to a second axis traversing a volume in the vehicle above the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" id="US-6397136-B1-CLM-00013" class="claim">
      <div class="claim-text">13. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00012">claim 12</claim-ref>, wherein said second ultrasonic sensor is arranged on an instrument panel of the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" id="US-6397136-B1-CLM-00014" class="claim">
      <div class="claim-text">14. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00013">claim 13</claim-ref>, wherein said transducers further include a third ultrasonic sensor arranged on an interior side surface of the passenger compartment.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" id="US-6397136-B1-CLM-00015" class="claim">
      <div class="claim-text">15. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00014">claim 14</claim-ref>, wherein said transducers further include a fourth ultrasonic sensor arranged on or adjacent an interior side surface of the passenger compartment.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" id="US-6397136-B1-CLM-00016" class="claim">
      <div class="claim-text">16. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00011">claim 11</claim-ref>, wherein said ultrasonic sensors are capable of transmitting waves at least into the space above the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" id="US-6397136-B1-CLM-00017" class="claim">
      <div class="claim-text">17. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00011">claim 11</claim-ref>, wherein said ultrasonic sensors are aimed such that the ultrasonic fields generated thereby cover a substantial portion of the volume surrounding the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" id="US-6397136-B1-CLM-00018" class="claim">
      <div class="claim-text">18. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00011">claim 11</claim-ref>, wherein the system further comprises horns for adjusting the transducer field angles of said ultrasonic sensors to reduce reflections off of fixed surfaces within the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" id="US-6397136-B1-CLM-00019" class="claim">
      <div class="claim-text">19. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00011">claim 11</claim-ref>, wherein the system further comprises grills for adjusting the transducer field angles of said ultrasonic sensors.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" id="US-6397136-B1-CLM-00020" class="claim">
      <div class="claim-text">20. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said transducers include four ultrasonic sensors capable of receiving waves at least from a space above the seat, said ultrasonic sensors being arranged at corners of an approximate rhombus which surrounds the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" id="US-6397136-B1-CLM-00021" class="claim">
      <div class="claim-text">21. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said transducers include a plurality of ultrasonic sensors capable of transmitting waves at least into a space above the seat and receiving waves at least from the space above the seat, each of said ultrasonic sensors being arranged at a different location, said ultrasonic sensors having different transmitting and receiving frequencies and being arranged in the vehicle such that sensors having adjacent transmitting and receiving frequencies are not within a direct ultrasonic field of each other.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" id="US-6397136-B1-CLM-00022" class="claim">
      <div class="claim-text">22. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein the trained pattern recognition algorithm is a neural network or neural fuzzy algorithm.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" id="US-6397136-B1-CLM-00023" class="claim">
      <div class="claim-text">23. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein at least one of said transducers is a capacitive sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" id="US-6397136-B1-CLM-00024" class="claim">
      <div class="claim-text">24. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said transducers are selected from a group consisting of seat belt buckle sensors, seatbelt payout sensors, infrared sensors, inductive sensors and radar sensors.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" id="US-6397136-B1-CLM-00025" class="claim">
      <div class="claim-text">25. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, further comprising control means coupled to said processor means for controlling a component or device in the vehicle in consideration of the output indicative of the current occupancy state of the seat obtained from said processor means.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" id="US-6397136-B1-CLM-00026" class="claim">
      <div class="claim-text">26. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00025">claim 25</claim-ref>, wherein the component or device is an airbag system including at least one deployable airbag and said control means control at least one parameter of the deployment of said at least one airbag including the inflation rate, the deflation rate, the incoming gas flow rate and the exiting gas flow rate.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" id="US-6397136-B1-CLM-00027" class="claim">
      <div class="claim-text">27. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said transducers include sensors capable of receiving waves modified by passing through a space above the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" id="US-6397136-B1-CLM-00028" class="claim">
      <div class="claim-text">28. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00001">claim 1</claim-ref>, wherein said plurality of transducers includes a wave-receiving transducer and a non-wave-receiving transducer.</div>
    </div>
    </div> <div class="claim"> <div num="29" id="US-6397136-B1-CLM-00029" class="claim">
      <div class="claim-text">29. A system for determining the occupancy state of a seat in a vehicle in combination with the vehicle, the system comprising:</div>
      <div class="claim-text">a plurality of transducers arranged in the vehicle, each of said transducers generating only a single stream of data relating to the occupancy state of the seat, and </div>
      <div class="claim-text">processor means coupled to said transducers for receiving only the single stream of data from each of said transducers such that the stream of data from each of said transducers is passed to said processor means from said transducer without combining with another stream of data and processing the streams of data to obtain an output indicative of the current occupancy state of the seat, said processor means comprising an algorithm created from a plurality of data sets, each of said data sets representing a different occupancy state of the seat and being formed from separate streams of data, each only from one of said transducers, while the seat is in that occupancy state, </div>
      <div class="claim-text">said algorithm producing the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from separate streams of data, each only from one of said transducers. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" id="US-6397136-B1-CLM-00030" class="claim">
      <div class="claim-text">30. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said algorithm is a neural network or neural fuzzy algorithm.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" id="US-6397136-B1-CLM-00031" class="claim">
      <div class="claim-text">31. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein one of said transducers is a weight sensor arranged in the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="32" id="US-6397136-B1-CLM-00032" class="claim">
      <div class="claim-text">32. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein one of said transducers is a reclining angle detecting sensor for detecting a tilt angle of a back portion of the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" id="US-6397136-B1-CLM-00033" class="claim">
      <div class="claim-text">33. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein one of said transducers is a seat position sensor for detecting the position of the seat relative to a fixed reference point in the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="34" id="US-6397136-B1-CLM-00034" class="claim">
      <div class="claim-text">34. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said transducers include a plurality of weight sensors, each of said weight sensors measuring the weight applied onto the seat at a different location.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="35" id="US-6397136-B1-CLM-00035" class="claim">
      <div class="claim-text">35. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said transducers include a weight sensor arranged to measure the weight applied to a surface of a seat portion of the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="36" id="US-6397136-B1-CLM-00036" class="claim">
      <div class="claim-text">36. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said transducers include a force, pressure or strain gage arranged to measure the weight applied to the entire seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="37" id="US-6397136-B1-CLM-00037" class="claim">
      <div class="claim-text">37. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said transducers include a plurality of electromagnetic wave sensors capable of receiving waves at least from a space above the seat, each of said electromagnetic wave sensors being arranged at a different location.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="38" id="US-6397136-B1-CLM-00038" class="claim">
      <div class="claim-text">38. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said transducers include at least two ultrasonic sensors capable of receiving waves at least from a space above the seat, each of said ultrasonic sensors being arranged at a different location.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="39" id="US-6397136-B1-CLM-00039" class="claim">
      <div class="claim-text">39. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00038">claim 38</claim-ref>, wherein a first one of said two ultrasonic sensors is arranged on or adjacent to a ceiling of the vehicle and a second one of said two ultrasonic sensors is arranged at a different location in the vehicle such that an axis connecting said first and second ultrasonic sensors is substantially parallel to a second axis traversing a volume in the vehicle above the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="40" id="US-6397136-B1-CLM-00040" class="claim">
      <div class="claim-text">40. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00038">claim 38</claim-ref>, wherein the system further comprises horns for adjusting the transducer field angles of said ultrasonic sensors to reduce reflections off of fixed surfaces within the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="41" id="US-6397136-B1-CLM-00041" class="claim">
      <div class="claim-text">41. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said transducers include a plurality of ultrasonic sensors capable of transmitting waves at least into a space above the seat and receiving waves at least from the space above the seat, each of said ultrasonic sensors being arranged at a different location, said ultrasonic sensors having different transmitting and receiving frequencies and being arranged in the vehicle such that sensors having adjacent transmitting and receiving frequencies are not within a direct ultrasonic field of each other.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="42" id="US-6397136-B1-CLM-00042" class="claim">
      <div class="claim-text">42. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein at least one of said transducers is a capacitive sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="43" id="US-6397136-B1-CLM-00043" class="claim">
      <div class="claim-text">43. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said transducers are selected from a group consisting of seat belt buckle sensors, seatbelt payout sensors, infrared sensors, inductive sensors and radar sensors.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="44" id="US-6397136-B1-CLM-00044" class="claim">
      <div class="claim-text">44. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, further comprising control means coupled to said processor means for controlling a component or device in the vehicle in consideration of the output indicative of the current occupancy state of the seat obtained from said processor means.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="45" id="US-6397136-B1-CLM-00045" class="claim">
      <div class="claim-text">45. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00044">claim 44</claim-ref>, wherein the component or device is an airbag system including at least one deployable airbag, said control means controlling at least one parameter of the deployment of said at least one airbag including the inflation rate, the deflation rate, the incoming gas flow rate and the exiting gas flow rate.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="46" id="US-6397136-B1-CLM-00046" class="claim">
      <div class="claim-text">46. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said transducers include sensors capable of receiving waves modified by passing through a space above the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="47" id="US-6397136-B1-CLM-00047" class="claim">
      <div class="claim-text">47. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said plurality of transducers includes a wave-receiving transducer and a non-wave-receiving transducer.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="48" id="US-6397136-B1-CLM-00048" class="claim">
      <div class="claim-text">48. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00029">claim 29</claim-ref>, wherein said algorithm is a trained pattern recognition algorithm.</div>
    </div>
    </div> <div class="claim"> <div num="49" id="US-6397136-B1-CLM-00049" class="claim">
      <div class="claim-text">49. A system for determining the occupancy state of a seat in a vehicle in combination with the vehicle, the system comprising:</div>
      <div class="claim-text">a plurality of transducers including at least two wave-receiving transducers arranged in the vehicle, each of said transducers providing data relating to the occupancy state of the seat, a first one of said wave-receiving transducers being arranged over a front portion of the seat or in front of the seat and a second one of said wave-receiving transducers being arranged over a rear portion of the seat or behind the seat, and </div>
      <div class="claim-text">a processor coupled to said transducers for receiving data from said transducers and processing the data to obtain an output indicative of the current occupancy state of the seat, said processor comprising an algorithm which produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from said transducers. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="50" id="US-6397136-B1-CLM-00050" class="claim">
      <div class="claim-text">50. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said algorithm is created from a plurality of data sets, each of said data sets representing a different occupancy state of the seat and being formed from data from said transducers while the seat is in that occupancy state.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="51" id="US-6397136-B1-CLM-00051" class="claim">
      <div class="claim-text">51. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said first and second wave-receiving transducers are arranged to receive ultrasonic waves.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="52" id="US-6397136-B1-CLM-00052" class="claim">
      <div class="claim-text">52. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein each of said transducers generates only a single stream of data relating to the occupancy state of the seat and said processor means are arranged to accept only the single stream of data from each of said transducers such that the stream of data from each of said transducers is passed to said processor means without combining with another stream of data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="53" id="US-6397136-B1-CLM-00053" class="claim">
      <div class="claim-text">53. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said first wave-receiving transducer is arranged on an instrument panel of the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="54" id="US-6397136-B1-CLM-00054" class="claim">
      <div class="claim-text">54. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said plurality of transducers further includes a third wave-receiving transducer arranged on an interior side surface of the passenger compartment.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="55" id="US-6397136-B1-CLM-00055" class="claim">
      <div class="claim-text">55. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00054">claim 54</claim-ref>, wherein said plurality of transducers further includes a fourth wave-receiving transducer arranged on or adjacent an interior side surface of the passenger compartment.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="56" id="US-6397136-B1-CLM-00056" class="claim">
      <div class="claim-text">56. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said wave-receiving transducers are capable of transmitting waves at least into the space above the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="57" id="US-6397136-B1-CLM-00057" class="claim">
      <div class="claim-text">57. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00056">claim 56</claim-ref>, wherein said wave-receiving transducers are aimed such that the wave fields generated thereby cover a substantial portion of the volume surrounding the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="58" id="US-6397136-B1-CLM-00058" class="claim">
      <div class="claim-text">58. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein the system further comprises horns for adjusting the transducer field angles of said wave-receiving transducers to reduce reflections off of fixed surfaces within the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="59" id="US-6397136-B1-CLM-00059" class="claim">
      <div class="claim-text">59. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein the system further comprises grills for adjusting the transducer field angles of said wave-receiving transducers to reduce reflections off of fixed surfaces within the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="60" id="US-6397136-B1-CLM-00060" class="claim">
      <div class="claim-text">60. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said plurality of transducers includes a weight sensor arranged in the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="61" id="US-6397136-B1-CLM-00061" class="claim">
      <div class="claim-text">61. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said plurality of transducers includes a reclining angle detecting sensor for detecting a tilt angle of a back portion of the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="62" id="US-6397136-B1-CLM-00062" class="claim">
      <div class="claim-text">62. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said plurality of transducers includes a seat position sensor for detecting the position of the seat relative to a fixed reference point in the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="63" id="US-6397136-B1-CLM-00063" class="claim">
      <div class="claim-text">63. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said plurality of transducers includes a plurality of weight sensors, each of said weight sensors measuring the weight applied onto the seat at a different location.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="64" id="US-6397136-B1-CLM-00064" class="claim">
      <div class="claim-text">64. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said plurality of transducers includes a weight sensor arranged to measure the weight applied to a surface of a seat portion of the seat.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="65" id="US-6397136-B1-CLM-00065" class="claim">
      <div class="claim-text">65. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00049">claim 49</claim-ref>, wherein said plurality of transducers includes a force, pressure or strain gage arranged to measure the weight of the entire seat.</div>
    </div>
    </div> <div class="claim"> <div num="66" id="US-6397136-B1-CLM-00066" class="claim">
      <div class="claim-text">66. A system for determining the occupancy state of a seat in a vehicle in combination with the vehicle, the system comprising:</div>
      <div class="claim-text">a plurality of transducers including at least two wave-receiving transducers, each of said transducers providing data relating to the occupancy state of the seat, a first one of said wave-receiving transducers being arranged on a top of a dashboard or instrument panel of the vehicle and a second one of said wave-receiving transducers being arranged at a different location in the vehicle such that an axis connecting said first and second wave-receiving transducers passes through a volume above the seat; and </div>
      <div class="claim-text">a processor coupled to said transducers for receiving data from said transducers and processing the data to obtain an output indicative of the current occupancy state of the seat, said processor comprising an algorithm which produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from said transducers. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="67" id="US-6397136-B1-CLM-00067" class="claim">
      <div class="claim-text">67. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00066">claim 66</claim-ref>, wherein each of said transducers generates only a single stream of data relating to the occupancy state of the seat and said processor means are arranged to accept only the single stream of data from each of said transducers such that the stream of data from each of said transducers is passed to said processor means without combining with another stream of data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="68" id="US-6397136-B1-CLM-00068" class="claim">
      <div class="claim-text">68. The vehicle of <claim-ref idref="US-6397136-B1-CLM-00066">claim 66</claim-ref>, wherein said second wave-receiving transducer is arranged on a ceiling of the vehicle.</div>
    </div>
    </div> <div class="claim"> <div num="69" id="US-6397136-B1-CLM-00069" class="claim">
      <div class="claim-text">69. A system for determining the occupancy state of a seat in a vehicle in combination with the vehicle, the system comprising:</div>
      <div class="claim-text">a plurality of transducers arranged in the vehicle, each of said transducers providing data relating to the occupancy state of the seat, at least one of said transducers being a capacitive or electric field sensor; and </div>
      <div class="claim-text">processor means coupled to said transducers for receiving the data from said transducers and processing the data to obtain an output indicative of the current occupancy state of the seat, said processor means comprising an algorithm created from a plurality of data sets, each of said data sets representing a different occupancy state of the seat and being formed from data from said transducers while the seat is in that occupancy state, </div>
      <div class="claim-text">said algorithm producing the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from said transducers. </div>
    </div>
    </div> <div class="claim"> <div num="70" id="US-6397136-B1-CLM-00070" class="claim">
      <div class="claim-text">70. A system for determining the occupancy state of a seat in a vehicle in combination with the vehicle, the system comprising:</div>
      <div class="claim-text">a plurality of transducers arranged in the vehicle, each of said transducers providing data relating to the occupancy state of the seat, at least one of said transducers being selected from a group consisting of seat belt buckle sensors, seatbelt payout sensors and inductive sensors; and </div>
      <div class="claim-text">processor means coupled to said transducers for receiving the data from said transducers and processing the data to obtain an output indicative of the current occupancy state of the seat, said processor means comprising an algorithm created from a plurality of data sets, each of said data sets representing a different occupancy state of the seat and being formed from data from said transducers while the seat is in that occupancy state, </div>
      <div class="claim-text">said algorithm producing the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from said transducers.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES53570428" lang="EN" load-source="patent-office" class="description">
    <heading>CROSS REFERENCE TO RELATED APPLICATIONS</heading> <p>This application claims priority under 35 U.S.C. 119(e) of U.S. provisional patent application Ser. No. 60/136,163 filed May 27, 1999.</p>
    <p>This application is continuation-in-part of U.S. patent application Ser. No. 09/382,406 filed Aug. 24, 1999 which is a continuation-in-part of U.S. patent application Ser. No. 08/919,823, filed Aug. 28, 1997 now U.S. Pat. No. 5,943,295, which in turn is a continuation-in-part of U.S. patent application Ser. No. 08/798,029 filed Feb. 6, 1997, now abandoned.</p>
    <p>This application is related to: (i) U.S. Pat. No. 5,653,462 entitled Vehicle Occupant Position and Velocity Sensor filed Jul. 21, 1995, which is a continuation of U.S. patent application Ser. No. 08/040,978 filed Mar. 31, 1993, now abandoned, which in turn is a continuation of U.S. patent application Ser. No. 07/878,571 filed May 5, 1992, now abandoned; (ii) U.S. Pat. No. 5,829,782 entitled Vehicle Interior Identification and Monitoring System filed May 9, 1994; (iii) U.S. Pat. No. 5,845,000 entitled Optical Identification and Monitoring System Using Pattern Recognition for Use with Vehicles filed Jun. 7, 1995; (iv) U.S. Pat. No. 5,822,707 entitled Automatic Vehicle Seat Adjuster filed Jun. 7, 1995; (v) U.S. Pat. No. 5,748,473 entitled Automatic Vehicle Seat Adjuster filed June 7, 1995; and, (vi) U.S. Pat. No. 5,835,613 entitled Optical Identification and Monitoring System Using Pattern Recognition for use with Vehicles filed Jun. 7, 1995, which are all incorporated by reference herein.</p>
    <heading>FIELD OF THE INVENTION</heading> <p>The present invention relates generally to the fields of sensing, detecting, monitoring and/or identifying various objects, and parts thereof, which are located within the passenger compartment of a motor vehicle. In particular, the present invention relates to an efficient and highly reliable system for evaluating the occupancy of a vehicle by detecting the presence and optionally orientation of objects in the seats of the passenger compartment, e.g., a rear facing child seat (RFCS) situated in the passenger compartment in a location where it may interact with a deploying occupant protection apparatus, such as an airbag, and/or for detecting an out-of-position occupant. The system permits the control and selective suppression of deployment of the occupant protection apparatus when the deployment may result in greater injury to the occupant than the crash forces themselves. This is accomplished in part through a specific placement of transducers of the system, the use of a pattern recognition system, possibly a trained neural network, and/or a novel analysis of the signals from the transducers.</p>
    <p>The application of the occupant position sensor to a new automobile vehicle model is called applications engineering. Applications engineering of occupant sensors comprises, inter alia, determining the location of the transducers, designing the transducer holders, determining the wiring layout, performing a tolerance study on the transducer locations and angular orientation, designing the circuits for the particular vehicle model, interfacing or integrating the circuits into the vehicle electronic system, and adapting the occupant sensor system to the particular vehicle model.</p>
    <p>All of the above aspects of application engineering, with the exception of the system adaptation, are standard processes that do not differ significantly from the application engineering of any electronic system to a new vehicle model. The system adaptation, however, is unique in that it requires considerable skill and expertise and the use of novel technologies to create a system that is optimized for a particular vehicle.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Prior Art on Sensing of Out-of-position Occupants and Rear Facing Child Seats</p>
    <p>Whereas thousands of lives have been saved by airbags, a large number of people have also been injured, some seriously, by the deploying airbag, and thus significant improvements to the airbag system are necessary. As discussed in detail in one or more of the patents and patent applications cross-referenced above, for a variety of reasons, vehicle occupants may be too close to the airbag before it deploys and can be seriously injured or killed as a result of any deployment thereof. Also, a child in a rear facing child seat which is placed on the right front passenger seat is in danger of being seriously injured if the passenger airbag deploys. For these reasons and, as first publicly disclosed in Breed, D. S. How Airbags Work presented at the International Conference on Seatbelts and Airbags in 1993, in Canada, occupant position sensing and rear facing child seat detection is required in order to minimize the damages caused by deploying airbags. It also may be required in order to minimize the damage caused by the deployment of other types of occupant protection and/or restraint devices which might be installed in the vehicle.</p>
    <p>Initially, these systems will solve the out-of-position occupant and the rear facing child seat problems related to current airbag systems and prevent unneeded and unwanted airbag deployments when a front seat is unoccupied. However, airbags are now under development to protect rear seat occupants in vehicle crashes and all occupants in side impacts. A system is therefore needed to detect the presence of occupants, determine if they are out-of-position (defined below) and to identify the presence of a rear facing child seat in the rear seat. Future automobiles are expected to have eight or more airbags as protection is sought for rear seat occupants and from side impacts. In addition to eliminating the disturbance and possible harm of unnecessary airbag deployments, the cost of replacing these airbags will be excessive if they all deploy in an accident needlessly.</p>
    <p>Inflators now exist which will adjust the amount of gas flowing to or from the airbag to account for the size and position of the occupant and for the severity of the accident. The vehicle identification and monitoring system (VIMS) discussed in U.S. Pat. No. 5,829,782, and U.S. patent application Ser. No. 08/798,029 filed Feb. 6, 1997 among others, will control such inflators based on the presence and position of vehicle occupants or of a rear facing child seat. The instant invention is concerned with the process of adapting the vehicle interior monitoring systems to a particular vehicle model and achieving a high system accuracy and reliability as discussed in greater detail below.</p>
    <p>The automatic adjustment of the deployment rate of the airbag based on occupant identification and position and on crash severity has been termed smart airbags. Central to the development of smart airbags is the occupant identification and position determination systems described in the above-referenced patents and patent applications and to the methods described herein for adapting those systems to a particular vehicle model. To complete the development of smart airbags, an anticipatory crash detecting system such as disclosed in U.S. patent application Ser. No. 08/247,760 filed May 23, 1994 is also desirable. Prior to the implementation of anticipatory crash sensing, the use of a neural network smart crash sensor which identifies the type of crash and thus its severity based on the early part of the crash acceleration signature should be developed and thereafter implemented. U.S. Pat. No. 5,684,701 (Breed) describes a crash sensor based on neural networks. This crash sensor, as with all other crash sensors, determines whether or not the crash is of sufficient severity to require deployment of the airbag and, if so, initiates the deployment. A neural network based on a smart airbag crash sensor could also be designed to identify the crash and categorize it with regard to severity thus permitting the airbag deployment to be matched not only to the characteristics and position of the occupant but also the severity and timing of the crash itself (this being described in U.S. patent application Ser. No. 08/798,029 referenced above).</p>
    <p>The need for an occupant out-of-position sensor has also been observed by others and several methods have been described in certain U.S. patents for determining the position of an occupant of a motor vehicle. However, no patents have been found that describe the methods of adapting such sensors to a particular vehicle model to obtain high system accuracy. Each of these systems will be discussed below and have significant limitations.</p>
    <p>In White et al. (U.S. Pat. No. 5,071,160), for example, a single acoustic sensor and detector is described and, as illustrated, is mounted lower than the steering wheel. White et al. correctly perceive that such a sensor could be defeated, and the airbag falsely deployed, by an occupant adjusting the control knobs on the radio and thus they suggest the use of a plurality of such sensors. White et al. does not disclose where the such sensors would be mounted, other than on the instrument panel below the steering wheel, or how they would be combined to uniquely monitor particular locations in the passenger compartment and to identify the object(s) occupying those locations. The adaptation process to vehicles is not described.</p>
    <p>Mattes et al. (U.S. Pat. No. 5,118,134) describe a variety of methods for measuring the change in position of an occupant including ultrasonic, active or passive infrared radiation and microwave radar sensors, and an electric eye. The use of these sensors is to measure the change in position of an occupant during a crash and they use that information to assess the severity of the crash and thereby decide whether or not to deploy the airbag. They are thus using the occupant motion as a crash sensor. No mention is made of determining the out-of-position status of the occupant or of any of the other features of occupant monitoring as disclosed in the above-referenced patents and/or patent applications. It is interesting to note that nowhere does Mattes et al. discuss how to use a combination of ultrasonic sensors/transmitters to identify the presence of a human occupant and then to find his/her location in the passenger compartment.</p>
    <p>The object of an occupant out-of-position sensor is to determine the location of, e.g., the head and/or chest of the vehicle occupant in the passenger compartment to enable the location of the head and/or chest to be determined relative to the occupant protection apparatus, e.g., airbag, since it is the impact of either the head or chest with the deploying airbag which can result in serious injuries. Both White et al. and Mattes et al. disclose only lower mounting locations of their sensors which are mounted in front of the occupant such as on the dashboard or below the steering wheel. Both such mounting locations are particularly prone to detection errors due to positioning of the occupant's hands, arms and legs. This would require at least three, and preferably more, such sensors and detectors and an appropriate logic circuitry which ignores readings from some sensors if such readings are inconsistent with others, for the case, for example, where the driver's arms are the closest objects to two of the sensors. The determination of the proper transducer mounting locations, aiming and field angles for a particular vehicle model are not disclosed in either White et al. or Mattes et al. and are part of the vehicle model adaptation process described herein.</p>
    <p>White et al. also describe the use of error correction circuitry, without defining or illustrating the circuitry, to differentiate between the velocity of one of the occupant's hands, as in the case where he/she is adjusting the knob on the radio, and the remainder of the occupant. Three ultrasonic sensors of the type disclosed by White et al. might, in some cases, accomplish this differentiation if two of them indicated that the occupant was not moving while the third was indicating that he or she was moving. Such a combination, however, would not differentiate between an occupant with both hands and arms in the path of the ultrasonic transmitter at such a location that they were blocking a substantial view of the occupant's head or chest. Since the sizes and driving positions of occupants are extremely varied, trained pattern recognition systems, such as neural networks, are required when a clear view of the occupant, unimpeded by his/her extremities, cannot be guaranteed. White et al. do not suggest the use of such neural networks.</p>
    <p>Fujita et al., in U.S. Pat. No. 5,074,583, describe another method of determining the position of the occupant but do not use this information to control and suppress deployment of an airbag if the occupant is out-of-position, or if a rear facing child seat is present. In fact, the closer that the occupant gets to the airbag, the faster the inflation rate of the airbag is according to the Fujita et al. patent, which thereby increases the possibility of injuring the occupant. Fujita et al. do not measure the occupant directly but instead determine his or her position indirectly from measurements of the seat position and the vertical size of the occupant relative to the seat. This occupant height is determined using an ultrasonic displacement sensor mounted directly above the occupant's head.</p>
    <p>It is important to note that in all cases in the above-cited prior art, except those assigned to the current assignee of the instant invention, no mention is made of the method of determining transducer location, deriving the algorithms or other system parameters that allow the system to accurately identify and locate an object in the vehicle. In contrast, in one implementation of the instant invention, the return ultrasonic echo pattern over several milliseconds corresponding to the entire portion of the passenger compartment volume of interest is analyzed from multiple transducers and sometimes combined with the output from other transducers, providing distance information to many points on the items occupying the passenger compartment.</p>
    <p>Many of the teachings of this invention are based on pattern recognition technologies as taught in numerous textbooks and technical papers. Central to the diagnostic teachings of this invention is the manner in which the diagnostic module determines a normal pattern from an abnormal pattern and the manner in which it decides what data to use from the vast amount of data available. This is accomplished using pattern recognition technologies, such as artificial neural networks, and training. The theory of neural networks including many examples can be found in several books on the subject including: <i>Techniques And Application Of Neural Networks</i>, edited by Taylor, M. and Lisboa, P., Ellis Horwood, West Sussex, England, 1993; <i>Naturally Intelligent Systems</i>, by Caudill, M. and Butler, C., MIT Press, Cambridge Mass., 1990; J. M. Zaruda, <i>Introduction to Artificial Neural Systems</i>, West publishing Co., New York, 1992 and, <i>Digital Neural Networks</i>, by Kung, S. Y., PTR Prentice Hall, Englewood Cliffs, N.J., 1993, Eberhart, R., Simpson, P. and Dobbins, R., <i>Computational Intelligence PC Tools </i>Acadeimc Press, Inc., 1996, Orlando, Fla., all of which are included herein by reference. The neural network pattern recognition technology is one of the most developed of pattern recognition technologies.</p>
    <p>Other patents describing occupant sensor systems include U.S. Pat. No. 5,482,314 (Corrado et al.) and U.S. Pat. No. 5,890,085 (Corrado et al.). These patents describe a system for sensing the presence, position and type of an occupant in a seat of a vehicle for use in enabling or disabling a related airbag activator. A preferred implementation of the system includes two or more different but collocated sensors which provide information about the occupant and this information is fused or combined in a microprocessor circuit to produce an output signal to the airbag controller. According to Corrado et al., the fusion process produces a decision as to whether to enable or disable the airbag with a higher reliability than a single phenomena sensor or non-fused multiple sensors. By fusing the information from the sensors to make a determination as to the deployment of the airbag, each sensor has only a partial effect on the ultimate deployment determination. The sensor fusion process is a crude pattern recognition process based on deriving the fusion rules by a trial and error process.</p>
    <p>The sensor fusion method of Corrado et al. requires that information from the sensors be combined prior to processing in the microprocessor, e.g., entry into the algorithm thereof. This combination could be found to unnecessarily complicate the processing of the data from the sensors and other data processing methods might provide better results. For example, as discussed more fully below, it has been found to be advantageous to use a more efficient pattern recognition algorithm such as a neural network or fuzzy logic algorithm which is arranged to receive a separate stream of data from each sensor, without that data being combined with data from the other sensors (as in done in Corrado et al.). In this regard, it is critical to appreciate that sensor fusion is a form of pattern recognition but is not a neural network and that significant and fundamental differences exist between sensor fusion and neural networks. Thus, some embodiments of the invention described below differ from that of Corrado et al. because they include a microprocessor which is arranged to accept only a separate stream of data from each sensor such that the stream of data from the sensors are not combined with one another. Further, the microprocessor processes each separate stream of data independent of the processing of the other streams of data (i.e., without the use of any fusion matrix as in Corrado et al.).</p>
    <p>2. Definitions</p>
    <p>The use of pattern recognition, or more particularly how it is used, is central to the instant invention. In the above-cited prior art, except in that assigned to the current assignee of the instant invention, pattern recognition which is based on training, as exemplified through the use of neural networks, is not mentioned for use in monitoring the interior passenger compartment or exterior environments of the vehicle. Thus, the methods used to adapt such systems to a vehicle are also not mentioned.</p>
    <p>Pattern recognition as used herein will generally mean any system which processes a signal that is generated by an object (e.g., representative of a pattern of returned or received impulses, waves or other physical property specific to and/or characteristic of and/or representative of that object) or is modified by interacting with an object, in order to determine to which one of a set of classes that the object belongs. Such a system might determine only that the object is or is not a member of one specified class, or it might attempt to assign the object to one of a larger set of specified classes, or find that it is not a member of any of the classes in the set. The signals processed are generally a series of electrical signals coming from transducers that are sensitive to acoustic (ultrasonic) or electromagnetic radiation (e.g., visible light, infrared radiation, capacitance or electric and magnetic fields), although other sources of information are frequently included. Pattern recognition systems generally involve the creation of the set of rules that permit the pattern to be recognized. These rules can be created by fuzzy logic systems, statistical correlations, or through sensor fusion methodologies as well as by trained pattern recognition systems such as neural networks.</p>
    <p>A trainable or a trained pattern recognition system as used herein generally means a pattern recognition system which is taught to recognize various patterns constituted within the signals by subjecting the system to a variety of examples. The most successful such system is the neural network. Thus, to generate the pattern recognition algorithm, test data is first obtained which constitutes a plurality of sets of returned waves, or wave patterns, from an object (or from the space in which the object will be situated in the passenger compartment, i.e., the space above the seat) and an indication of the identify of that object, (e.g., a number of different objects are tested to obtain the unique wave patterns from each object). As such, the algorithm is generated, and stored in a computer processor, and which can later be applied to provide the identity of an object based on the wave pattern being received during use by a receiver connected to the processor and other information. For the purposes here, the identity of an object sometimes applies to not only the object itself but also to its location and/or orientation in the passenger compartment. For example, a rear facing child seat is a different object than a forward facing child seat and an out-of-position adult is a different object than a normally seated adult.</p>
    <p>To identify as used herein will generally mean to determine that the object belongs to a particular set or class. The class may be one containing, for example, all rear facing child seats, one containing all human occupants, or all human occupants not sitting in a rear facing child seat depending on the purpose of the system. In the case where a particular person is to be recognized, the set or class will contain only a single element, i.e., the person to be recognized.</p>
    <p>An object in a vehicle or an occupant or occupying item of a seat may be a living occupant such as a human or a dog, another living organism such as a plant, or an inanimate object such as a box or bag of groceries or an empty child seat.</p>
    <p>Out-of-position as used for an occupant will generally means that the occupant, either the driver or a passenger, is sufficiently close to the occupant protection apparatus (airbag) prior to deployment that he or she is likely to be more seriously injured by the deployment event itself than by the accident. It may also mean that the occupant is not positioned appropriately in order to attain beneficial, restraining effects of the deployment of the airbag. As for the occupant being too close to the airbag, this typically occurs when the occupant's head or chest is closer than some distance such as about 5 inches from the deployment door of the airbag module. The actual distance value where airbag deployment should be suppressed depends on the design of the airbag module and is typically farther for the passenger airbag than for the driver airbag.</p>
    <p>Transducer as used herein will generally mean the combination of a transmitter and a receiver. In come cases, the same device will serve both as the transmitter and receiver while in others two separate devices adjacent to each other will be used. In some cases, a transmitter is not used and in such cases transducer will mean only a receiver. Transducers include, for example, capacitive, inductive, ultrasonic, electromagnetic (antenna, CCD, CMOS arrays), weight measuring or sensing devices.</p>
    <p>Adaptation as used here represents the method by which a particular occupant sensing system is designed and arranged for a particular vehicle model. It includes such things as the process by which the number, kind and location of various transducers is determined. For pattern recognition systems, it includes the process by which the pattern recognition system is taught to recognize the desired patterns. In this connection, it will usually include (1) the method of training, (2) the makeup of the databases used for training, testing, and validating the particular system, or, in the case of a neural network, the particular network architecture chosen, (3) the process by which environmental influences are incorporated into the system, and (4) any process for determining the pre-processing of the data or the post processing of the results of the pattern recognition system. The above list is illustrative and not exhaustive. Basically, adaptation includes all of the steps that are undertaken to adapt transducers and other sources of information to a particular vehicle to create the system which accurately identifies and determines the location of an occupant or other object in a vehicle.</p>
    <p>In the description herein on anticipatory sensing, the term approaching when used in connection with the mention of an object or vehicle approaching another will generally mean the relative motion of the object toward the vehicle having the anticipatory sensor system. Thus, in a side impact with a tree, the tree will be considered as approaching the side of the vehicle and impacting the vehicle. In other words, the coordinate system used in general will be a coordinate system residing in the target vehicle. The target vehicle is the vehicle which is being impacted. This convention permits a general description to cover all of the cases such as where (i) a moving vehicle impacts into the side of a stationary vehicle, (ii) where both vehicles are moving when they impact, or (iii) where a vehicle is moving, sideways into a stationary vehicle, tree or wall. Also, for the purposes herein, a wave sensor or wave transducer is any device, which senses waves either ultrasonic or electromagnetic. An electromagnetic wave sensor, for example, includes devices that sense any portion of the electromagnetic spectrum from ultraviolet down to a few hertz. The most commonly used kind of electromagnetic wave sensors include CCD and CMOS arrays for sensing visible and/or infrared, millimeter wave and microwave radar, and capacitive or electric and magnetic field monitoring sensors that rely on the dielectric constant of the object occupying a space. In this regard, reference is made to, for example, U.S. patents by Kithil et al. U.S. Pat. Nos. 5,366,241, 5,602,734, 5,691,693, 5,802,479 and 5,844,486 and Jinno et al. 5,948,031 which are included herein by reference.</p>
    <p>3. Pattern recognition prior art</p>
    <p>Japanese Patent 3-42337 (A) to Ueno describes a device for detecting the driving condition of a vehicle driver comprising a light emitter for irradiating the face of the driver and a means for picking up the image of the driver and storing it for later analysis. Means are provided for locating the eyes of the driver and then the irises of the eyes and then determining if the driver is looking to the side or sleeping. Ueno determines the state of the eyes of the occupant rather than determining the location of the eyes relative to the other parts of the vehicle passenger compartment. Such a system can be defeated if the driver is wearing glasses, particularly sunglasses, or another optical device which obstructs a clear view of his/her eyes. Pattern recognition technologies such as neural networks are not used. The method of finding the eyes is described but not a method of adapting the system to a particular vehicle model.</p>
    <p>U.S. Pat. No. 5,008,946 to Ando uses a complicated set of rules to isolate the eyes and mouth of a driver and uses this information to permit the driver to control the radio, for example, or other systems within the vehicle by moving his eyes and/or mouth. Ando uses natural light and illuminates only the head of the driver. He also makes no use of trainable pattern recognition systems such as neural networks, nor is there any attempt to identify the contents of the vehicle nor of their location relative to the vehicle passenger compartment. Rather, Ando is limited to control of vehicle devices by responding to motion of the driver's mouth and eyes. As with Ueno, a method of finding the eyes is described but not a method of adapting the system to a particular vehicle model.</p>
    <p>U.S. Pat. No. 5,298,732 to Chen also concentrates in locating the eyes of the driver so as to position a light filter between a light source such as the sun or the lights of an oncoming vehicle, and the driver's eyes. Chen does not explain in detail how the eyes are located but does supply a calibration system whereby the driver can adjust the filter so that it is at the proper position relative to his or her eyes. Chen references the use of an automatic equipment for determining the location of the eyes but does not describe how this equipment works. In any event, in Chen, there is no mention of monitoring the position of the occupant, other that the eyes, determining the position of the eyes relative to the passenger compartment, or identifying any other object in the vehicle other than the driver's eyes. Also, there is no mention of the use of a trainable pattern recognition system. A method for finding the eyes is described but not a method of adapting the system to a particular vehicle model.</p>
    <p>U.S. Pat. No. 5,305,012 to Faris also describes a system for reducing the glare from the headlights of an oncoming vehicle. Faris locates the eyes of the occupant by using two spaced apart infrared cameras using passive infrared radiation from the eyes of the driver. Faris is only interested in locating the driver's eyes relative to the sun or oncoming headlights and does not identify or monitor the occupant or locate the occupant, a rear facing child seat or any other object for that matter, relative to the passenger compartment or the airbag. Also, Faris does not use trainable pattern recognition techniques such as neural networks. Faris, in fact, does not even say how the eyes of the occupant are located but refers the reader to a book entitled Robot Vision (1991) by Berthold Horn, published by MIT Press, Cambridge, Mass. Also, Faris uses the passive infrared radiation rather than illuminating the occupant with ultrasonic or electromagnetic radiation as in some implementations of the instant invention. A method for finding the eyes of the occupant is described but not a method of adapting the system to a particular vehicle model.</p>
    <p>The use of neural networks, or neural fuzzy systems, as the pattern recognition technology and the methods of adapting this to a particular vehicle, such as the training methods, is important to this invention since it makes the monitoring system robust, reliable and accurate. The resulting algorithm created by the neural network program is usually only a few hundred lines of code written in the C computer language and is in general fewer lines than when the techniques of the above patents to Ando, Chen and Faris are implemented. As a result, the resulting systems are easy to implement at a low cost making them practical for automotive applications. The cost of the ultrasonic transducers, for example, is expected to be less than about $1 in quantities of one million per year. Similarly, the implementation of the techniques of the above-referenced patents requires expensive microprocessors while the implementation with neural networks and similar trainable pattern recognition technologies permits the use of low cost microprocessors typically costing less than about $5 in quantities of one million per year.</p>
    <p>The present invention uses sophisticated software that develops trainable pattern recognition algorithms such as neural networks. Usually the data is preprocessed, as discussed below, using various feature extraction techniques and the results post-processed to improve system accuracy. A non-automotive example of such a pattern recognition system using neural networks on sonar signals is discussed in two papers by Gorman, R. P. and Sejnowski, T. J. Analysis of Hidden Units in a Layered Network Trained to Classify Sonar Targets, Neural Networks, Vol. 1. pp. 75-89, 1988, and Learned Classification of Sonar Targets Using a Massively Parallel Network, IEEE Transactions on Acoustics, Speech, and Signal Processing, Vol. 36, No. 7, July 1988. Examples of feature extraction techniques can be found in U.S. Pat. No. 4,906,940 entitled Process and Apparatus for the Automatic Detection and Extraction of Features in Images and Displays to Green et al. Examples of other more advanced and efficient pattern recognition techniques can be found in U.S. Pat. No. 5,390,136 entitled Artificial Neuron and Method of Using Same and U.S. Pat. No. 5,517,667 entitled Neural Network That Does Not Require Repetitive Training to Wang, S. T. Other examples include U.S. Pat. No. 5,235,339 (Morrison et al.), U.S. Pat. No. 5,214,744 (Schweizer et al), U.S. Pat. No. 5,181,254 (Schweizer et al), and U.S. Pat. No. 4,881,270 (Knecht et al). All of the references herein are included herein by reference.</p>
    <p>4. Ultrasonics and Optics</p>
    <p>Both laser and non-laser optical systems in general are good at determining the location of objects within the two dimensional plane of the image and a pulsed laser radar system in the scanning mode can determine the distance of each part of the image from the receiver by measuring the time of flight through range gating techniques. It is also possible to determine distance with the non-laser system by focusing, or stereographically if two spaced apart receivers are used and, in some cases, the mere location in the field of view can be used to estimate the position relative to the airbag, for example. Finally, a recently developed pulsed quantum well diode laser also provides inexpensive distance measurements as discussed in U.S. provisional patent application Ser. No. 60/114,507, filed Dec. 31, 1998, which is included herein by reference as if the entire contents were copied here.</p>
    <p>Acoustic systems are additionally quite effective at distance measurements since the relatively low speed of sound permits simple electronic circuits to be designed and minimal microprocessor capability is required. If a coordinate system is used where the z axis is from the transducer to the occupant, acoustics are good at measuring z dimensions while simple optical systems using a single CCD or CMOS arrays are good at measuring x and y dimensions. The combination of acoustics and optics, therefore, permits all three measurements to be made from one location with low cost components as discussed in commonly assigned U.S. Pat. Nos. 5,845,000 and 5,835,613 cross-referenced above.</p>
    <p>One example of a system using these ideas is an optical system which floods the passenger seat with infrared light coupled with a lens and a receiver array, e.g., CCD or CMOS array, which receives and displays the reflected light and an analog to digital converter (ADC) which digitizes the output of the CCD or CMOS and feeds it to an Artificial Neural Network (ANN) or other pattern recognition system for analysis. This system uses an ultrasonic transmitter and receiver for measuring the distances to the objects located in the passenger seat. The receiving, transducer feeds its data into an ADC and from there the converted data is directed into the ANN. The same ANN can be used for both systems thereby providing full three-dimensional data for the ANN to analyze. This system, using low cost components, will permit accurate identification and distance measurements not possible by either system acting alone. If a phased array system is added to the acoustic part of the system, the optical part can determine the location of the driver's ears, for example, and the phased array can direct a narrow beam to the location and determine the distance to the occupant's ears.</p>
    <p>Although the use of ultrasound for distance measurement has many advantages, it also has some drawbacks. First, the speed of sound limits the rate at which the position of the occupant can be updated to approximately 10 milliseconds, which though sufficient for most cases, is marginal if the position of the occupant is to be tracked during a vehicle crash. Second, ultrasound waves are diffracted by changes in air density that can occur when the heater or air conditioner is operated or when there is a high-speed flow of air past the transducer. Third, the resolution of ultrasound is limited by its wavelength and by the transducers, which are high Q tuned devices. Typically, the resolution of ultrasound is on the order of about 2 to 3 inches. Finally, the fields from ultrasonic transducers are difficult to control so that reflections from unwanted objects or surfaces add noise to the data.</p>
    <p>Ultrasonics alone can be used in several configurations for monitoring the interior of a passenger compartment of an automobile as described in the above-referenced patents and patent applications and in particular in U.S. Pat. No. 5,943,295. Using the teachings of this invention, the optimum number and location of the ultrasonic and/or optical transducers can be determined as part of the adaptation process for a particular vehicle model.</p>
    <p>In the cases of the instant invention, as discussed in more detail below, regardless of the number of transducers used, a trained pattern recognition system, as defined above, is used to identify and classify, and in some cases to locate, the illuminated object and its constituent parts.</p>
    <p>5. Applications</p>
    <p>The applications for this technology are numerous as described in the patents and patent applications listed above. However, the main focus of the instant invention is the process and resulting apparatus of adapting the system in the patents and patent applications referenced above for the detection of the presence of an occupied child seat in the rear facing position or an out-of-position occupant and the detection of an occupant in a normal seating position. The system is designed so that in the former two cases, deployment of the occupant protection apparatus (airbag) may be controlled and possibly suppressed and in the latter, it will be controlled and enabled.</p>
    <p>One preferred implementation of a first generation occupant sensing system, which is adapted to various vehicle models using the teachings presented herein, is an ultrasonic occupant position sensor. This system uses an Artificial Neural Network (ANN) to recognize patterns that it has been trained to identify as either airbag enable or airbag disable conditions. The pattern is obtained from four ultrasonic transducers that cover the front passenger seating area. This pattern consists of the ultrasonic echoes bouncing off of the objects in the passenger seat area. The signal from each of the four transducers consists of the electrical image of the return echoes, which is processed by the electronics. The electronic processing comprises amplification, logarithmic compression, rectification, and demodulation (band pass filtering), followed by discretization (sampling) and digitization of the signal. The only software processing required, before this signal can be fed into the artificial neural network, is normalization (i.e., mapping the input to numbers between 0 and 1). Although this is a fair amount of processing, the resulting signal is still considered raw, because all information is treated equally.</p>
    <heading>OBJECTS AND SUMMARY OF THE INVENTION</heading> <p>In general, it is an object of the present invention to provide a new and improved system for identifying the presence, position and/or orientation of an object in a vehicle.</p>
    <p>It is another broad object of the present invention to provide a system for accurately detecting the presence of an occupied rear-facing child seat in order to prevent an occupant protection apparatus, such as an airbag, from deploying, when the airbag would impact against the rear-facing child seat if deployed.</p>
    <p>It is yet another broad object of the present invention to provide a system for accurately detecting the presence of an out-of-position occupant in order to prevent one or more deployable occupant protection apparatus such as airbags from deploying when the airbag(s) would impact against the head or chest of the occupant during its initial deployment phase causing injury or possible death to the occupant.</p>
    <p>This invention is a system designed to identify, locate and monitor occupants, including their parts, and other objects in the passenger compartment and in particular an occupied child seat in the rear facing position or an out-of-position occupant, by illuminating the contents of the vehicle with ultrasonic or electromagnetic radiation, for example, by transmitting radiation waves from a wave generating apparatus into a space above the seat, and receiving radiation modified by passing through the space above the seat using two or more transducers properly located in the vehicle passenger compartment, in specific predetermined optimum location. More particularly, this invention relates to a system including a plurality of transducers appropriately located and mounted and which analyze the received radiation from any object which modifies the waves, in order to achieve an accuracy of recognition heretofore not possible. Outputs from the receivers are analyzed by appropriate computational means employing trained pattern recognition technologies, to classify, identify and/or locate the contents, and/or determine the orientation of, for example, a rear facing child seat. In general, the information obtained by the identification and monitoring system is used to affect the operation of some other system, component or device in the vehicle and particularly the passenger and/or driver airbag systems airbag, which may include a front airbag, a side airbag, a knee bolster, or combinations of the same. However, the information obtained can be used for controlling or affecting the operation of a multitude of other vehicle systems.</p>
    <p>When the vehicle interior monitoring system in accordance with the invention is installed in the passenger compartment of an automotive vehicle equipped with a occupant protection apparatus, such as an inflatable airbag, and the vehicle is subjected to a crash of sufficient severity that the crash sensor has determined that the protection apparatus is to be deployed, the system has determined (usually prior to the deployment) whether a child placed in the rear facing position in the child seat is present and if so, a signal has been sent to the control circuitry that the airbag should be controlled and most likely disabled and not deployed in the crash. It must be understood though that instead of suppressing deployment, it is possible that the deployment may be controlled so that it might provide some meaningful protection for the occupied rear-facing child seat. The system developed using the teachings of this invention also determines the position of the vehicle occupant relative to the airbag and controls and possibly disables deployment of the airbag if the occupant is positioned so that he/she is likely to be injured by the deployment of the airbag. As before, the deployment is not necessarily disabled but may be controlled to provide protection for the out-of-position occupant.</p>
    <p>Principle objects and advantages of the methods in accordance with the invention are:</p>
    <p>1. To provide a reliable system for recognizing the presence of a rear-facing child seat on a particular seat of a motor vehicle.</p>
    <p>2. To provide a reliable system for recognizing the presence of a human being on a particular seat of a motor vehicle.</p>
    <p>3. To provide a reliable system for determining the position, velocity or size of an occupant in a motor vehicle.</p>
    <p>4. To provide a reliable system for determining in a timely manner that an occupant is out-of-position, or will become out-of-position, and likely to be injured by a deploying airbag.</p>
    <p>5. To provide a system in which transducers are located within the passenger compartment at specific locations such that a high reliability of classification of objects and their position is obtained from the signals generated by the transducers.</p>
    <p>6. To provide a system including a variety of transducers such as seatbelt payout sensors, seatbelt buckle sensors, seat position sensors, seatback position sensors, and weight sensors and which is adapted so as to constitute a highly reliable occupant presence and position system when used in combination with electromagnetic, ultrasonic or other radiation sensors.</p>
    <p>Accordingly, in a vehicle including system for determining the occupancy state of a seat therein in accordance with the invention, the system comprises a plurality of transducers arranged in the vehicle, each transducers providing data relating to the occupancy state of the seat, and processor means coupled to the transducers for receiving the data from the transducers and processing the data to obtain an output indicative of the current occupancy state of the seat. The processor means comprise an algorithm created from a plurality of data sets, each representing a different occupancy state of the seat and being formed from data from the transducers while the seat is in that occupancy state. The algorithm produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from the transducers. The algorithm may be a pattern recognition algorithm or neural network algorithm generated by a neural network algorithm-generating program.</p>
    <p>In accordance with some embodiments of the invention, the processor means are arranged to accept only a separate stream of data from each transducer such that the stream of data from each transducer is passed to the processor means without combining with another stream of data. Further, the processor means may be arranged to process each separate stream of data independent of the processing of the other streams of data.</p>
    <p>It is an important feature of the invention that the transducers may be selected from a wide variety of different sensors, all of which are affected by the occupancy state of the seat. That is, different combinations of known sensors can be utilized in the many variations of the invention. For example, the sensors used in the invention may include a weight sensor arranged in the seat, a reclining angle detecting sensor for detecting a tilt angle of the seat between a back portion of the seat and a seat portion of the seat, a seat position sensor for detecting the position of the seat relative to a fixed reference point in the vehicle, a heartbeat sensor for sensing a heartbeat of an occupying item of the seat, a capacitive sensor, a seat belt buckle sensor, a seatbelt payout sensor, an infrared sensors, an inductive sensor, a motion sensor and a radar sensor. The same type of sensor could also be used, preferably situated in a different location, but possibly in the same location for redundancy purposes. For example, the system may include a plurality of weight sensors, each measuring the weight applied onto the seat at a different location. Such weight sensors may include a weight sensor, such as a strain gage, arranged to measure displacement of a surface of a seat portion of the seat and/or a strain, force or pressure gage arranged to measure displacement of the entire seat. In the latter case, the seat includes a support structure for supporting the seat above a floor of a passenger compartment of the vehicle whereby the strain gage can be attached to the support structure.</p>
    <p>In some embodiments, the transducers include a plurality of electromagnetic wave sensors capable of receiving waves at least from a space above the seat, each electromagnetic wave sensor being arranged at a different location.</p>
    <p>In other embodiments, the transducers include at least two ultrasonic sensors capable of receiving waves at least from a space above the seat, each ultrasonic sensor being arranged at a different location. For example, one sensor is arranged on a ceiling of the vehicle and the other is arranged at a different location in the vehicle, preferably so that an axis connecting the sensors is substantially parallel to a second axis traversing a volume in the vehicle above the seat. The second sensor may be arranged on a dashboard or instrument panel of the vehicle. A third ultrasonic sensor can be arranged on an interior side surface of the passenger compartment while a fourth can be arranged on or adjacent an interior side surface of the passenger compartment. The ultrasonic sensors are capable of transmitting waves at least into the space above the seat. Further, the ultrasonic sensors are preferably aimed such that the ultrasonic fields generated thereby cover a substantial portion of the volume surrounding the seat. Horns or grills may be provided for adjusting the transducer field angles of the ultrasonic sensors to reduce reflections off of fixed surfaces within the vehicle or otherwise control the shape of the ultrasonic field.</p>
    <p>The actual location of the ultrasonic sensors can be determined by placing a significant number of ultrasonic sensors in the vehicle and removing those sensors which prove analytically to be redundant.</p>
    <p>The ultrasonic sensors can have different transmitting and receiving frequencies and be arranged in the vehicle such that sensors having adjacent transmitting and receiving frequencies are not within a direct ultrasonic field of each other.</p>
    <p>Once the occupancy state of the seat (or seats) in the vehicle is known, this information can be used to control or affect the operation of a significant number of vehicular systems, components and devices. That is, the systems, components and devices in the vehicle would be controlled in consideration of the occupancy of the seat(s) in the vehicle, possibly to optimize operation of the same. Thus, the vehicle includes control means coupled to the processor means for controlling a component or device in the vehicle in consideration of the output indicative of the current occupancy state of the seat obtained from the processor means. The component or device can be an airbag system including at least one deployable airbag whereby the deployment of the airbag is suppressed, e.g., if the seat is occupied by a rear-facing child seat, or otherwise the parameters of the deployment are controlled.</p>
    <p>In another embodiment of the invention, the system for determining the occupancy state of a seat in a vehicle includes a plurality of transducers arranged in the vehicle, each providing data relating to the occupancy state of the seat, and processor means coupled to the transducers for receiving only a separate stream of data from each transducer (such that the stream of data from each transducer is passed to the processor means without combining with another stream of data) and processing the streams of data to obtain an output indicative of the current occupancy state of the seat. The processor means comprise an algorithm created from a plurality of data sets, each representing a different occupancy state of the seat and being formed from separate streams of data, each only from one transducers, while the seat is in that occupancy state. The algorithm produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from separate streams of data, each only from one transducer. The processor means preferably process each separate stream of data independent of the processing of the other streams of data.</p>
    <p>In yet another embodiment of the invention, the system for determining the occupancy state of a seat in a vehicle includes a plurality of transducers including at least two wave-receiving transducers arranged in the vehicle, each providing data relating to the occupancy state of the seat. One wave-receiving transducer is arranged on or adjacent to a ceiling of the vehicle and a second wave-receiving transducer is arranged at a different location in the vehicle such that an axis connecting these wave-receiving transducers is substantially parallel to a longitudinal axis of the vehicle, substantially parallel to a transverse axis of the vehicle or passes through a volume above the seat. A processor is coupled to the transducers for receiving data from the transducers and processing the data to obtain an output indicative of the current occupancy state of the seat. The processor comprises an algorithm which produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from the transducers.</p>
    <p>In still another embodiment of the invention, the system includes a plurality of transducers arranged in the vehicle, each providing data relating to the occupancy state of the seat, and which include a wave-receiving transducer and a non-wave-receiving transducer. The system also includes processor means coupled to the transducers for receiving the data from the transducers and processing the data to obtain an output indicative of the current occupancy state of the seat. The processor means comprising an algorithm created from a plurality of data sets, each representing a different occupancy state of the seat and being formed from data from the transducers while the seat is in that occupancy state. The algorithm produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from the transducers.</p>
    <p>These and other objects and advantages will become apparent from the following description of the preferred embodiments of the vehicle identification and monitoring system of this invention.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>The following drawings are illustrative of embodiments of the system developed or adapted using the teachings of this invention and are not meant to limit the scope of the invention as encompassed by the claims. In particular, the illustrations below are limited to the monitoring of the front passenger seat for the purpose of describing the system. Naturally, the invention applies as well to adapting the system to the other seating positions in the vehicle and particularly to the driver position.</p>
    <p>FIG. 1 shows a seated-state detecting unit developed in accordance with the present invention and the connections between ultrasonic or electromagnetic sensors, a weight sensor, a reclining angle detecting sensor, a seat track position detecting sensor, a heartbeat sensor, a motion sensor, a neural network circuit, and an airbag system installed within a vehicle compartment;</p>
    <p>FIG. 2 is a perspective view of a vehicle containing two adult occupants on the front seat with the vehicle shown in phantom illustrating one preferred location of the ultrasonic transducers placed according to the methods taught in this invention.</p>
    <p>FIG. 3 is a view as in FIG. 2 with the passenger occupant replaced by a child in a forward facing child seat.</p>
    <p>FIG. 4 is a view as in FIG. 2 with the passenger occupant replaced by a child in a rearward facing child seat.</p>
    <p>FIG. 5 is a view as in FIG. 2 with the passenger occupant replaced by an infant in an infant seat.</p>
    <p>FIG. 6 is a diagram illustrating the interaction of two ultrasonic sensors and how this interaction is used to locate a circle is space.</p>
    <p>FIG. 7 is a view as in FIG. 2 with the occupants removed illustrating the location of two circles in space and how they intersect the volumes characteristic of a rear facing child seat and a larger occupant.</p>
    <p>FIG. 8 illustrates a preferred mounting location of a three-transducer system.</p>
    <p>FIG. 9 illustrates a preferred mounting location of a four-transducer system.</p>
    <p>FIG. 10 is a plot showing the target volume discrimination for two transducers.</p>
    <p>FIG. 11 illustrates a preferred mounting location of a eight-transducer system.</p>
    <p>FIG. 12 is a chart of four typical raw signals which are combined to constitute a vector.</p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>System Adaptation involves the process by which the hardware configuration and the software algorithms are determined for a particular vehicle. Each vehicle model or platform will most likely have a different hardware configuration and different algorithms. Some of the various aspects that make up this process are as follows:</p>
    <p>The determination of the mounting location and aiming of the transducers.</p>
    <p>The determination of the transducer field angles</p>
    <p>The use of a neural network algorithm generating program such as commercially available from NeuralWare to help generate the algorithms.</p>
    <p>The process of the collection of data in the vehicle for neural network training purposes.</p>
    <p>The method of automatic movement of the vehicle seats etc. while data is collected</p>
    <p>The determination of the quantity of data to acquire and the setups needed to achieve a high system accuracy, typically several hundred thousand vectors.</p>
    <p>The collection of data in the presence of varying environmental conditions such as with thermal gradients.</p>
    <p>The photographing of each data setup.</p>
    <p>The makeup of the different databases and the use of three different databases.</p>
    <p>The method by which the data is biased to give higher probabilities for forward facing humans.</p>
    <p>The automatic recording of the vehicle setup including seat, seat back, headrest, window, visor, armrest positions to help insure data integrity.</p>
    <p>The use of a daily setup to validate that the transducer configuration has not changed.</p>
    <p>The method by which bad data is culled from the database.</p>
    <p>The inclusion of the Fourier transforms and other pre-processors of the data in the training process.</p>
    <p>The use of multiple network levels, for example, for categorization and position.</p>
    <p>The use of multiple networks in parallel.</p>
    <p>The use of post processing filters and the particularities of these filters.</p>
    <p>The addition of fuzzy logic or other human intelligence based rules.</p>
    <p>The method by which vector errors are corrected using, for example, a neural network.</p>
    <p>The use of neural works as the pattern recognition algorithm generating system.</p>
    <p>The use of back propagation neural networks from training.</p>
    <p>The use of vector normalization.</p>
    <p>The use of feature extraction techniques including:</p>
    <p>The number of data points prior to a peak.</p>
    <p>The normalization factor.</p>
    <p>The total number of peaks.</p>
    <p>The vector mean or variance.</p>
    <p>The use of other computational intelligence systems such as the genetic algorithms</p>
    <p>The use the data screening techniques.</p>
    <p>The techniques used to develop a stable network including the concepts of a old and a new network.</p>
    <p>The time spent or the number of iterations spent in, and method of, arriving at a stable network.</p>
    <p>The technique where a small amount of data is collected first such as 16 sheets followed by a complete data collection sequence.</p>
    <p>The process of adapting the system to the vehicle begins with a survey of the vehicle model. Any existing sensors, such as seat position sensors, seat back sensors, etc., are immediate candidates for inclusion into the system. Input from the customer will determine what types of sensors would be acceptable for the final system. These sensors can include: seat structure mounted weight sensors, pad type weight sensors, pressure type weight sensors, seat fore and aft position sensors, seat vertical position sensors, seat angular position sensors, seat back position sensors, headrest position sensors, ultrasonic occupant sensors, optical occupant sensors, capacitive sensors, inductive sensors, radar sensors, vehicle velocity and acceleration sensors, brake pressure, seatbelt force, payout and buckle sensors. etc. A candidate array of sensors is then chosen and mounted onto the vehicle.</p>
    <p>The vehicle is also instrumented so that data input by humans is minimized. Thus, the positions of the various components in the vehicle such as the seats, windows, sun visor, armrest, etc. are automatically recorded. Also, the position of the occupant while data is being taken is also absolutely recorded through a variety of techniques such as direct ultrasonic ranging sensors, optical ranging sensors, radar ranging sensors, optical tracking sensors etc. Cameras are also installed to take a picture of the setup to correspond to each vector of data collected or at some other appropriate frequency.</p>
    <p>A standard set of vehicle setups is chosen for initial trial data collection purposes. Typically, the initial trial will consist of between 20,000 and 100,000 setups.</p>
    <p>Initial digital data collection now proceeds for the trial setup matrix. The data is collected from the transducers, digitized and combined to form to a vector of input data for analysis by a neural network program. This analysis should yield a training accuracy of nearly 100%. If this is not achieved, then additional sensors are added to the system or the configuration changed and the data collection and analysis repeated.</p>
    <p>In addition to a variety of seating states for objects in the passenger compartment, the trial database will also include environmental effects such as thermal gradients caused by heat lamps and the operation of the air conditioner and heater. A sample of such a matrix is presented in Appendix 1. After the neural network has been trained on the trial database, the trial database will be scanned for vectors that yield erroneous results (which would likely be considered bad data). A study of those vectors along with vectors from associated in time cases are compared with the photographs to determine whether there is erroneous data present. If so, an attempt is made to determine the cause of the erroneous data. If the cause can be found, for example if a voltage spike on the power line corrupted the data, then the vector will be removed from the database and an attempt is made to correct the data collection process so as to remove such disturbances.</p>
    <p>At this time, some of the sensors may be eliminated from the sensor matrix. This can be determined during the neural network analysis by selectively eliminating sensor data from the analysis to see what the effect if any results. Caution should be exercised here, however, since once the sensors have been initially installed in the vehicle, it requires little additional expense to use all of the installed sensors in future data collection and analysis.</p>
    <p>The neural network that has been developed in this first phase is used during the data collection in the next phases as a instantaneous check on the integrity of the new vectors being collected. Occasionally, a voltage spike or other environmental disturbance will momentarily effect the data from some transducers. It is important to capture this event to first eliminate that data from the database and second to isolate the cause of the erroneous data.</p>
    <p>The next set of data to be collected is the training database. This will be the largest database initially collected and will cover such setups as listed, for example, in Appendix 1. The training database, which may contain 500,000 or more vectors, will be used to begin training of the neural network. While this is taking place additional data will be collected according to Appendix 1 of the independent and validation databases. The training database has been selected so that it uniformly covers all seated states that are known to be likely to occur in the vehicle. The independent database may be similar in makeup to the training database or it may evolve to more closely conform to the occupancy state distribution of the validation database. During the neural network training, the independent database is used to check the accuracy of the neural network and to reject a candidate neural network design if its accuracy, measured against the independent database, is less than that of a previous network architecture.</p>
    <p>Although the independent database is not actually used in the training of the neural network, nevertheless, it has been found that it significantly influences the network structure. Therefore, a third database, the validation or real world database, is used as a final accuracy check of the chosen system. It is the accuracy against this validation database that is considered to be the system accuracy. The validation database is composed of vectors taken from setups which closely correlate with vehicle occupancy in real cars on the roadway. Initially the training database is the largest of the three databases. As time and resources permit the independent database, which perhaps starts out with 100,000 vectors, will continue to grow until it becomes approximately the same size as the training database. The validation database, on the other hand, will typically start out with as few as 50,000 vectors. However, as the hardware configuration is frozen, the validation database will continuously grow until, in some cases, it actually becomes larger than the training database. This is because near the end of the program, vehicles will be operating on highways and data will be collected in real world situations. If in the real world tests, system failures are discovered this can lead to additional data being taken for both the training and independent databases as well as the validation database.</p>
    <p>Once a network has been trained using all of the available data from all of the transducers, it is expected that the accuracy of the network will be very close to 100%. It is usually not practical to use all of the transducers that have been used in the training of the system for final installation in real production vehicle models. This is primarily due to cost and complexity considerations. Usually the automobile manufacturer will have an idea of how many sensors would be acceptable for installation in a production vehicle. For example, the data may have been collected using 20 different transducers but the automobile manufacturer may restrict the final selection to 6 transducers. The next process, therefore, is to gradually eliminate sensors to determine what is the best combination of six sensors, for example, to achieve the highest system accuracy. Ideally, a series of networks would be trained using all combinations of six sensors from the 20 available. The activity would require a prohibitively long time. Certain constraints can be factored into the system from the beginning to start the pruning process. For example, it would probably not make sense to have both optical and ultrasonic sensors present in the same system since it would complicate the electronics. In fact, the automobile manufacturer may have decided initially that an optical system would be too expensive and therefore would not be considered. The inclusion of optical sensors, therefore, serves as a way of determining the loss in accuracy as a function of cost. Various constraints, therefore, usually allow the immediate elimination of a significant number of the initial group of sensors. This elimination and the training on the remaining sensors provides the resulting accuracy loss that results.</p>
    <p>The next step is to remove each of the sensors one at a time and determine which sensor has the least effect on the system accuracy. This process is then repeated until the total number of sensors has been pruned down to the number desired by the customer. At this point, the process is reversed to add in one at a time those sensors that were removed at previous stages. It has been found, for example, that a sensor that appears to be unimportant during the early pruning process can become very important later on. Such a sensor may add a small amount of information due to the presence of various other sensors. Whereas the various other sensors, however, may yield less information than still other sensors and, therefore may have been removed during the pruning process. Reintroducing the sensor that was eliminated early in the cycle therefore can have a significant effect and can change the final choice of sensors to make up the system.</p>
    <p>The above method of reducing the number of sensors that make up the system is but one of a variety approaches which have applicability in different situations. In some cases a Monte Carlo or other statistical approach is warranted, whereas in other cases a design of experiments approach has proven to be the most successful. In many cases, an operator conducting this activity becomes skilled and after a while knows intuitively what set of sensors is most likely to yield the best results. During the process it is not uncommon to run multiple cases on different computers simultaneously. Also, during this process, a database of the cost of accuracy is generated. The automobile manufacturer, for example, may desire to have the total of 6 transducers in the final system, however, when shown the fact that the addition of one or two additional sensors substantially increases the accuracy of the system, the manufacturer may change his mind. Similarly, the initial number of sensors selected may be 6 but the analysis could show that 4 sensors give substantially the same accuracy as 6 and therefore the other 2 can be eliminated at a cost saving.</p>
    <p>While the pruning process is occurring, the vehicle is subjected to a variety of road tests and would be subjected to presentations to the customer. The road tests are tests that are run at different locations than where the fundamental training took place. It has been found that unexpected environmental factors can influence the performance of the system and therefore these tests can provide critical information. The system, therefore, which is installed in the test vehicle should have the capability of recording system failures. This recording includes the output of all of the sensors on the vehicle as well as a photograph of the vehicle setup that caused the error. This data is later analyzed to determine whether the training, independent or validation setups need to be modified and/or whether the sensors or positions of the sensors require modification.</p>
    <p>Once the final set of sensors has been chosen, the vehicle is again subjected to real world testing on highways and at customer demonstrations. Once again any failures are recorded. In this case, however, since the total number of sensors in the system is probably substantially less than the initial set of sensors, certain failures are to be expected. All such failures, if expected, are reviewed carefully with the customer to be sure that the customer recognizes the system failure modes and is prepared to accept the system with those failure modes.</p>
    <p>The system described so far has been based on the use of a single neural network. It is frequently necessary to use multiple neural networks or other pattern recognition systems. For example, for determining the occupancy state of a vehicle seat there are really two requirements. The first requirement is to establish what is occupying the seat and the second requirement is to establish where that object is located. Generally, a great deal of time, typically many seconds, is available for determining whether a forward facing human or an occupied or unoccupied rear facing child seat, for example, occupies the vehicle seat. On the other hand, if the driver of the car is trying to avoid an accident and is engaged in panic braking, the position of an unbelted occupant can be changing rapidly as he or she is moving toward the airbag. Thus, the problem of determining the location of an occupant is time critical. Typically, the position of the occupant in such situations must be determined in less than 20 milliseconds. There is no reason for the system to have to determine that a forward facing human being is in the seat while simultaneously determining where that forward facing human being is. The system already knows that the forward facing human being is present and therefore all of the resources can be used to determine the occupant's position. Thus, in this situation a dual level or modular neural network can be advantageously used. The first level determines the occupancy of the vehicle seat and the second level determines the position of that occupant. In some rare situations, it has been demonstrated that multiple neural networks used in parallel can provide some benefit. This will be discussed in more detail below.</p>
    <p>The data that is fed to the pattern recognition system typically will usually not be the raw vectors of data as captured and digitized from the various transducers. Typically, a substantial amount of preprocessing of the data is undertaken to extract the important information from the data that is fed to the neural network. This is especially true in optical systems and where the quantity of data obtained, if all were used by the neural network, would require very expensive processors. The techniques of preprocessing data will not be described in detail here. However, the preprocessing techniques influence the neural network structure in many ways. For example, the preprocessing used to determine what is occupying a vehicle seat is typically quite different from the preprocessing used to determine the location of that occupant. Some particular preprocessing concepts will be discussed in more detail below.</p>
    <p>Once the pattern recognition system has been applied to the preprocessed data, one or more decisions are available as output. The output from the pattern recognition system is usually based on a snapshot of the output of the various transducers. Thus, it represents one epoch or time period. The accuracy of such a decision can usually be substantially improved if previous decisions from the pattern recognition system are also considered. In the simplest form, which is typically used for the occupancy identification stage, the results of many decisions are averaged together and the resulting averaged decision is chosen as the correct decision. Once again, however, the situation is quite different for dynamic out-of-position. The position of the occupant must be known at that particular epoch and cannot be averaged with his previous position. On the other hand, there is information in the previous positions that can be used to improve the accuracy of the current decision. For example, if the new decision says that the occupant has moved six inches since the previous decision, and, from physics, it is known that this could not possibly take place, than a better estimate of the current occupant position can be made by extrapolating from earlier positions. Alternately, an occupancy position versus time curve can be fitted using a variety of techniques such as the least squares regression method, to the data from previous 10 epochs, for example. This same type of analysis could also be applied to the vector itself rather than to the final decision thereby correcting the data prior to its being entered into the pattern recognition system.</p>
    <p>A pattern recognition system, such as a neural network, can sometimes make totally irrational decisions. This typically happens when the pattern recognition system is presented with a data set or vector that is unlike any vector that has been in its training set. The variety of seating states of a vehicle is unlimited. Every attempt is made to select from that unlimited universe a set of representative cases. Nevertheless, there will always be cases that are significantly different from any that have been previously presented to the neural network. The final step, therefore, to adapting a system to a vehicle, is to add a measure of human intelligence. Sometimes this goes under the heading of fuzzy logic and the resulting system has been termed in some cases a neural fuzzy system. In some cases, this takes the form of an observer studying failures of the system and coming up with rules and that say, for example, that if sensor A perhaps in combination with another sensor produces values in this range than the system should be programmed to override the pattern recognition decision and substitute therefor a human decision.</p>
    <p>An example of this appears in R. Scorcioni, K. Ng, M. M. Trivedi, N. Lassiter; MoNiF: A Modular Neuro-Fuzzy Controller for Race Car Navigation; In Proceedings of the 1997 <i>IEEE Symposium on Computational Intelligence and Robotics Applications</i>, Monterey, Calif., USA July 1997 and describes the case of where an automobile was designed for autonomous operation and trained with a neural network, in one case, and a neural fuzzy system in another case. As long as both vehicles operated on familiar roads both vehicles performed satisfactorily. However, when placed on an unfamiliar road, the neural network vehicle failed while the neural fuzzy vehicle continue to operate successfully. Naturally, if the neural network vehicle had been trained on the unfamiliar road, it might very well have operated successful. Nevertheless, the critical failure mode of neural networks that most concerns people is this uncertainty as to what a neural network will do when confronted with an unknown state.</p>
    <p>One aspect, therefore, of adding human intelligence to the system, is to ferret out those situations where the system is likely to fail. Unfortunately, in the current state-of-the-art, this is largely a trial and error activity. One example is that if the range of certain parts of vector falls outside of the range experienced during training, the system defaults to a particular state. In the case of suppressing deployment of one or more airbags, or other occupant protection apparatus, this case would be to enable airbag deployment even if the pattern recognition system calls for its being disabled.</p>
    <p>The foregoing description is applicable to the systems described in the following drawings and the connection between the foregoing description and the systems described below will be explained below. However, it should be appreciated that the systems shown in the drawings do not limit the applicability of the methods or apparatus described above.</p>
    <p>Referring to the accompanying drawings wherein like reference numbers designate the same or similar elements, FIG. 1 shows a passenger seat <b>1</b> to which an adjustment apparatus including a seated-state detecting system developed according to the present invention may be applied. The seat <b>1</b> includes a horizontally situated bottom seat portion <b>2</b> and a vertically oriented back portion <b>3</b>. The seat portion <b>2</b> is provided with weight measuring means, i.e., one or more weight sensors <b>6</b> and <b>7</b>, that determine the weight of the object occupying the seat, if any. The coupled portion between the seated portion <b>2</b> and the back portion <b>3</b> (also referred to as the seatback) is provided with a reclining angle detecting sensor <b>9</b>, which detects the tilted angle of the back portion <b>3</b> relative to the seat portion <b>2</b>. The seat portion <b>2</b> is provided with a seat track position-detecting sensor <b>10</b>. The seat track position detecting sensor <b>10</b> fulfills a role of detecting the quantity of movement of the seat <b>1</b> which is moved from a back reference position, indicated by the dotted chain line. Embedded within the seatback <b>3</b> is a heartbeat sensor <b>31</b> and a motion sensor <b>33</b>. Attached to the headliner of the vehicle is a capacitance sensor <b>32</b>. The seat <b>1</b> may be the driver seat, the front passenger seat or any other seat in a motor vehicle as well as other seats in transportation vehicles or seats in non-transportation applications.</p>
    <p>Motion sensor <b>33</b> can be a discrete sensor that detects relative motion in the passenger compartment of the vehicle. Such sensors are frequently based on ultrasonics and can measure a change in the ultrasonic pattern that occurs over a short time period. Alternately, the subtracting of one position vector from a previous position vector to achieve a differential position vector can detect motion. For the purposes herein, a motion sensor will be used to mean either a particular device that is designed to detect motion for the creation of a special vector based on vector differences.</p>
    <p>The weight measuring means, such as the sensors <b>6</b> and <b>7</b>, are associated with the seat, and can be mounted into or below the seat portion <b>2</b> or on the seat structure, for example, for measuring the weight applied onto the seat. The weight may be zero if no occupying item is present. Sensors <b>6</b> and <b>7</b> may represent a plurality of different sensors which measure the weight applied onto the seat at different portions thereof or for redundancy purposes, for example, such as by means of an airbag or bladder <b>5</b> in the seat portion <b>2</b>. The bladder <b>5</b> may have one or more compartments. Such sensors may be in the form of strain, force or pressure sensors which measure the force or pressure on the seat portion <b>2</b> or seat back <b>3</b>, displacement measuring sensors which measure the displacement of the seat surface or the entire seat <b>1</b> such as through the use of strain gages mounted on the seat structural members, such as <b>7</b>, or other appropriate locations, or systems which convert displacement into a pressure wherein a pressure sensor can be used as a measure of weight.</p>
    <p>An ultrasonic or optical sensor system <b>12</b> is mounted on the upper portion of the front pillar, A-Pillar, of the vehicle and a similar sensor system <b>11</b> is mounted on the upper portion of the intermediate pillar, B-Pillar. The outputs of the transducers <b>11</b> and <b>12</b> are input to a band pass filter <b>20</b> through a multiplex circuit <b>19</b> which is switched in synchronization with a timing signal from the ultrasonic sensor drive circuit <b>18</b>, and then is amplified by an amplifier <b>21</b>. The band pass filter <b>20</b> removes a low frequency wave component from the output signal and also removes some of the noise. The envelope wave signal is input to an analog/digital converter (ADC) <b>22</b> and digitized as measured data. The measured data is input to a processing circuit <b>23</b>, which is controlled by the timing signal which is in turn output from the sensor drive circuit <b>18</b>.</p>
    <p>Each of the measured data is input to a normalization circuit <b>24</b> and normalized. The normalized measured data is input to the neural network (circuit) <b>25</b> as wave data.</p>
    <p>The output of the weight sensor(s) <b>6</b> and <b>7</b> is amplified by an amplifier <b>26</b> coupled to the weight sensor(s) <b>6</b> and <b>7</b> and the amplified output is input to an analog/digital converter and then directed to the neural network <b>25</b> of the processor means.</p>
    <p>The reclining angle detecting sensor <b>9</b> and the seat track position-detecting sensor <b>10</b> are connected to appropriate electronic circuits. For example, a constant-current can be supplied from a constant-current circuit to the reclining angle detecting sensor <b>9</b>, and the reclining angle detecting sensor <b>9</b> converts a change in the resistance value on the tilt of the back portion <b>3</b> to a specific voltage. This output voltage is input to an analog/digital converter <b>28</b> as angle data, i.e., representative of the angle between the back portion <b>3</b> and the seat portion <b>2</b>. Similarly, a constant current can be supplied from a constant-current circuit to the seat track position detecting sensor <b>10</b> and the seat track position detecting sensor <b>10</b> converts a change in the resistance value based on the track position of the seat portion <b>2</b> to a specific voltage. This output voltage is input to an analog/digital converter <b>29</b> as seat track data. Thus, the outputs of the reclining angle-detecting sensor <b>9</b> and the seat track position-detecting sensor <b>10</b> are input to the analog/digital converters (ADC) <b>28</b> and <b>29</b>, respectively. Each digital data value from the ADCs <b>28</b>,<b>29</b> is input to the neural network <b>25</b>. A more detailed description of this and similar systems can be found in the above-referenced patents and patent applications assigned to the current assignee, all of which are included herein by reference. The system described above is one example of many systems that can be designed using the teachings of this invention for detecting the occupancy state of the seat of a vehicle.</p>
    <p>The neural network <b>25</b> is directly connected to the ADCs <b>28</b> and <b>29</b>, the ADC associated with amplifier <b>25</b> and the normalization circuit <b>24</b>. As such, information from each of the sensors in the system (a stream of data) is passed directly to the neural network <b>25</b> for processing thereby. The streams of data from the sensors are not combined prior to the neural network <b>25</b> and the neural network is designed to accept the separate streams of data (e.g., at least a part of the data at each input node) and process them to provide an output indicative of the current occupancy state of the seat. The neural network <b>25</b> thus includes or incorporates an algorithm derived by training in the manners discussed above and below. Once the current occupancy state of the seat is determined, it is possible to control vehicular components or systems, such as the airbag system, in consideration of the current occupancy state of the seat.</p>
    <p>A section of the passenger compartment of an automobile is shown generally as <b>100</b> in FIG. 2. A driver <b>101</b> of a vehicle sits on a seat <b>102</b> behind a steering wheel, not shown, and an adult passenger <b>103</b> sits on seat <b>104</b> on the passenger side. Two transmitter and receiver assemblies <b>110</b> and <b>111</b>, also referred to herein as transducers, are positioned in the passenger compartment <b>100</b>, one transducer <b>110</b> is arranged on the headliner adjacent or in proximity to the dome light and the other transducer <b>111</b> is arranged on the center of the top of the dashboard or instrument panel of the vehicle. The methodology leading to the placement of these transducers is central to the instant invention as explained in detail below. In this situation, the system developed in accordance with this invention will reliably detect that an occupant is sitting on seat <b>104</b> and deployment of the airbag is enabled in the event that the vehicle experiences a crash. Transducers <b>110</b>, <b>111</b> are placed with their separation axis parallel to the separation axis of the head, shoulder and rear facing child seat volumes of occupants of an automotive passenger seat and in view of this specific positioning, are capable of distinguishing the different configurations. In addition to the ultrasonic transducers <b>110</b>, <b>111</b>, weight-measuring sensors <b>210</b>, <b>211</b>, <b>212</b>, <b>214</b> and <b>215</b> are also present. These weight sensors may be of a variety of technologies including, as illustrated here, strain-measuring transducers attached to the vehicle seat support structure as described in more detail in co-pending U.S. patent application Ser. No. 08/920,822. Naturally other weight systems can be utilized including systems that measure the deflection of, or pressure on, the seat cushion. The weight sensors described here are meant to be illustrative of the general class of weight sensors and not an exhaustive list of methods of measuring occupant weight.</p>
    <p>In FIG. 3, a forward facing child seat <b>120</b> containing a child <b>121</b> replaces the adult passenger <b>103</b> as shown in FIG. <b>2</b>. In this case, it is usually required that the airbag not be disabled in the event of an accident. However, in the event that the same child seat is placed in the rearward facing position as shown in FIG. 4, then the airbag is usually required to be disabled since deployment of the airbag in a crash can seriously injure or even kill the child. Furthermore, as illustrated in FIG. 5, if an infant <b>131</b> in an infant carrier <b>130</b> is positioned in the rear facing position of the passenger seat, the airbag should be disabled for the reasons discussed above. Instead of disabling deployment of the airbag, the deployment could be controlled to provide protection for the child, e.g., to reduce the force of the deployment of the airbag. It should be noted that the disabling or enabling of the passenger airbag relative to the item on the passenger seat may be tailored to the specific application. For example, in some embodiments, with certain forward facing child seats, it may in fact be desirable to disable the airbag and in other cases to deploy a depowered airbag. The selection of when to disable, depower or enable the airbag, as a function of the item in the passenger seat and its location, is made during the programming or training stage of the sensor system and, in most cases, the criteria set forth above will be applicable, i.e., enabling airbag deployment for a forward facing child seat and an adult in a proper seating position and disabling airbag deployment for a rearward facing child seat and infant and for any occupant who is out-of-position and in close proximity to the airbag module. The sensor system developed in accordance with the invention may however be programmed according to other criteria.</p>
    <p>Several systems using other technologies have been devised to discriminate between the four cases illustrated above but none have shown a satisfactory accuracy or reliability of discrimination. Some of these systems appear to work as long as the child seat is properly placed on the seat and belted in. So called tag systems, for example, whereby a device is placed on the child seat which is electromagnetically sensed by sensors placed within the seat have not proven reliable by themselves but can add information to the overall system. When used alone, they function well as long as the child seat is restrained by a seatbelt, but when this is not the case they have a high failure rate. Since the seatbelt usage of the population of the United States is only about 60% at the present time, it is quite likely that a significant percentage of child seats will not be properly belted onto the seat and thus children will be subjected to injury and death in the event of an accident.</p>
    <p>The methodology of this invention was devised to solve this problem. To understand this methodology, consider two ultrasonic transmitters and receivers <b>110</b> and <b>111</b> (transducers) which are connected by an axis AB in FIG. <b>6</b>. Each transmitter radiates a signal which is primarily confined to a cone angle, called the field angle, with its origin at the transmitter. For simplicity, assume that the transmitter and receiver are the same device although in some cases a separate device will be used for each function. When a transducer sends out a burst of waves, to thereby irradiate the passenger compartment with ultrasonic radiation, and then receives a reflection or modified radiation from some object in the passenger compartment, the distance of the object from the transducer can be determined by the time delay between the transmission of the waves and the reception of the reflected or modified waves.</p>
    <p>When looking at a single transducer, it is not possible to determine the direction to the object which is reflecting or modifying the signal but it is possible to know only how far that object is from the transducer, that is a single transducer enables a distance measurement but not a directional measurement. In other words, the object may be at a point on the surface of a three-dimensional spherical segment having its origin at the transducer and a radius equal to the distance. Consider two transducers, such as <b>110</b> and <b>111</b> in FIG. 6, and both transducers receive a reflection from the same object, which is facilitated by proper placement of the transducers, the timing of the reflections depends on the distance from the object to each respective transducer. If it is assumed for the purposes of this analysis that the two transducers act independently, that is, they only listen to the reflections of waves which they themselves transmitted, then each transducer knows the distance to the reflecting object but not its direction. If we assume that the transducer radiates ultrasound in all directions within the field cone angle, each transducer knows that the object is located on a spherical surface A, B a respective known distance from the transducer, that is, each transducer knows that the object is a specific distance from that transducer which may or may not be the same distance between the other transducer and the same object. Since now there are two transducers, and the distance of the reflecting object is known relative to each of the transducers, the actual location of the object resides on a circle which is the intersection of the two spherical surfaces A, and B. This circle is labeled C in FIG. <b>6</b>. At each point along circle C, the distance to the transducer <b>110</b> is the same and the distance to the transducer <b>111</b> is the same. This, of course, is strictly true only for ideal one-dimensional objects.</p>
    <p>For many cases, the mere knowledge that the object lies on a particular circle is sufficient since it is possible to locate the circle such that the only time that an object lies on a particular circle that its location is known. That is, the circle which passes through the area of interest otherwise passes through a volume where no objects can occur. Thus, the mere calculation of the circle in this specific location, which indicates the presence of the object along that circle, provides valuable information concerning the object in the passenger compartment which may be used to control or affect another system in the vehicle such as the airbag system. This of course is based on the assumption that the reflections to the two transducers are in fact from the same object. Care must be taken in locating the transducers such that other objects do not cause reflections that could confuse the system.</p>
    <p>FIG. 7, for example, illustrates two circles D and E of interest which represent the volume which is usually occupied when the seat is occupied by a person not in a child seat, C, or by a forward facing child seat and the volume normally occupied by a rear facing child seat, respectively. Thus, if the circle generated by the system, (i.e., by appropriate processor means which receives the distance determination from each transducer and creates the circle from the intersection of the spherical surfaces which represent the distance from the transducers to the object) is at a location which is only occupied by an adult passenger, the airbag would not be disabled since its deployment in a crash is desired. On the other hand, if a circle is at a location occupied only by a rear facing child seat, the airbag would be disabled.</p>
    <p>The above discussion of course is simplistic in that it is not take into account the volume occupied by the object or the fact the reflections from more than one object surface will be involved. In reality, transducer B is likely to pickup the rear of the occupant's head and transducer A, the front. This makes the situation more difficult for an engineer looking at the data to analyze. It has been found that pattern recognition technologies are able to extract the information from these situations and through a proper application of these technologies, an algorithm can be developed, which when installed as part of the system for a particular vehicle, the system accurately and reliably differentiates between a forward facing and rear facing child seat, for example, or an in-position or out-of-position forward facing human being.</p>
    <p>From the above discussion, a method of transducer location is disclosed which provides unique information to differentiate between (i) a forward facing child seat or a forward properly positioned occupant where airbag deployment is desired and (ii) a rearward facing child seat and an out-of-position occupant where airbag deployment is not desired. In actuality, the algorithm used to implement this theory does not directly calculate the surface of spheres or the circles of interaction of spheres. Instead, a pattern recognition system is used to differentiate airbag-deployment desired cases from those where the airbag should not be deployed. For the pattern recognition system to accurately perform its function, however, the patterns presented to the system must have the requisite information. That is, a pattern of reflected waves from an occupying item in a passenger compartment to various transducers must be uniquely different for cases where airbag deployment is desired from cases where deployment is not desired. The theory described above and in more detail below teaches how to locate transducers within the vehicle passenger compartment so that the patterns of reflected waves will be easily distinguishable for cases where airbag deployment is desired from those where deployment is not desired. In the case presented thus far, it has been shown that in some implementations the use of only two transducers can result in the desired pattern differentiation when the vehicle geometry is such that two transducers can be placed such that the circles D (airbag enabled) and E (airbag disabled) fall outside of the transducer field cones except where they are in the critical regions where positive identification of the condition occurs. Thus, the aiming and field angle of the transducers are important factors to determine in adapting a system to a particular vehicle.</p>
    <p>The use of only two transducers in a system is typically not acceptable since one or both of the transducers can be rendered inoperable by being blocked, for example, by a newspaper. Thus, it is desirable to add a third transducer <b>112</b> as shown in FIG. 8 which now provides a third set of spherical surfaces relative to the third transducer. Transducer <b>112</b> is positioned on the passenger side of the A-pillar (which is a preferred placement if the system is designed to operate on the passenger side of the vehicle). Three spherical surfaces now intersect in only two points and in fact, usually at one point if the aiming angles and field angles are properly chosen. Once again, this discussion is only strictly true for a point object. For a real object, the reflections will come from different surfaces of the object, which usually are at similar distances from the object. Thus, the addition of a third transducer substantially improves system reliability. Finally, with the addition of a fourth transducer <b>113</b> as shown in FIG. 9, even greater accuracy and reliability is attained. Transducer <b>113</b> is positioned on the ceiling of the vehicle close to the passenger side door. In FIG. 9, lines connecting the transducers C and D and the transducers A and B are substantially parallel permitting an accurate determination of asymmetry and thereby object rotation. Thus, for example, if the infant seat is placed on an angle as shown in FIG. 5, this condition can be determined and taken into account when the decision is made to disable the deployment of the airbag.</p>
    <p>The discussion above has centered on locating transducers and designing a system for determining whether the two target volumes, that adjacent the airbag and that adjacent the upper portion of the vehicle seat, are occupied. Other systems have been described in the above referenced patents using a sensor mounted on or adjacent the airbag module and a sensor mounted high in the vehicle to monitor the space near the vehicle seat. Such systems use the sensors as independent devices and do not use the combination of the two sensors to determine where the object is located. In fact, the location of such sensors is usually poorly chosen so that it is easy to blind either or both with a newspaper, for example. Furthermore, no system is known to have been disclosed, except in patents and patent applications assigned to the assignee of this invention, which uses more than two transducers in such a manner that one or more can be blocked without causing serious deterioration of the system. Again, the examples here have been for the purpose of suppressing the deployment of the airbag when it is necessary to prevent injury. The sensor system disclosed can be used for many other purposes such as disclosed in the above-mentioned patent applications assigned to the same assignee as the instant invention. The ability to use the sensors for these other applications in generally lacking in the systems disclosed in the other referenced patents.</p>
    <p>Considering once again the condition of FIGS. 2-7 where two transducers are used, a plot can be made showing the reflection times of the objects which are located in the region of curve E and curve F of FIG. <b>7</b>. This plot is shown on FIG. 10 where the c's represent reflections from rear facing child seats from various tests where the seats were placed in a variety of different positions and similarly the s's and h's represent shoulders and heads respectively of various forward facing human occupants. In these results from actual experiments, the effect of body thickness is present and yet the results still show that the basic principles of separation of key volumes are valid. Note that there is a region of separation between corridors that house the different object classes. It is this fact which is used in conjunction with neural networks, as described in the above referenced patent applications, which permit the design of a system that provides an accurate discrimination of rear facing child seats from forward facing humans. Heretofore before the techniques for locating the transducers to separate these two zones were discovered, the entire discrimination task was accomplished using neural networks. There was significant overlap between the reflections from the various objects and therefore separation was done based on patterns of the reflected waves. By using the technology described herein to carefully orient the transducers so as to create this region of separation of the critical surfaces, wherein all of the rear facing child seat data falls within a known corridor, the task remaining for the neural networks is substantially simplified with the result that the accuracy of identification is substantially improved.</p>
    <p>Three general classes of child seats exist as well as several models which are unique. First, there is the infant only seat as shown in FIG. 5 which is for occupants weighing up to about 20 pounds. This is designed to be only placed in the rear facing position. The second which is illustrated in FIGS. 2 and 3 is for children from about 20 to about 40 pounds and can be used in both the forward and rear facing position and the third is for use only in the forward facing position and is for children weighing over about 40 pounds. All of these seats as well as the unique models are used in test setups according to this invention for adapting a system to a vehicle. For each child seat, there are several hundred unique orientations representing virtually every possible position of that seat within the vehicle. Tests are run, for example, with the seat tilted 22 degrees, rotated 17 degrees, placed on the front of the seat with the seat back fully up with the seat fully back and with the window open as well as all variations of there parameters. A large number of cases are also run, when practicing the teachings of this invention, with various accessories, such as clothing, toys, bottles, blankets etc., added to the child seat.</p>
    <p>Similarly, wide variations are used for the occupants including size, clothing and activities such as reading maps or newspapers, leaning forward to adjust the radio, for example. Also included are cases where the occupant puts his/her feet on the dashboard or otherwise assumes a wide variety of unusual positions. When all of the above configurations are considered along with many others not mentioned, the total number of configurations which are used to train the pattern recognition system can exceed 500,000. The goal is to include in the configuration training set representations of all occupancy states that occur in actual use. Since the system is highly accurate in making the correct decision for cases which are similar to those in the training set, the total system accuracy increases as the size of the training set increases providing the cases are all distinct and not copies of other cases.</p>
    <p>In addition to all of the variations in occupancy states, it is important to consider environmental effects during the data collection. Thermal gradients or thermal instabilities are particularly important since sound waves can be significantly diffracted by density changes in air. There are two aspects of the use of thermal gradients or instability in training. First, the fact that thermal instabilities exist and therefore data with thermal instabilities present should be part of database. For this case, a rather small amount of data collected with thermal instabilities would be used. A much more important use of thermal instability comes from the fact that they add variability to data. Thus, considerably more data is taken with thermal instability and in fact, in some cases almost the entire database is taken with time varying thermal gradients in order to provide variability to the data so that the neural network does not memorize but instead generalizes from the data. This is accomplished by taking the data with a cold vehicle with the heater operating and with a hot vehicle with the air conditioner operating. Additional data is also taken with a heat lamp in a closed vehicle to simulate a stable thermal gradient caused by sun loading.</p>
    <p>To collect data for 500,000 vehicle configurations is not a formidable task. A trained technician crew can typically collect data on in excess on 2000 configurations or vectors per hour. The data is collected typically every 50 to 100 milliseconds. During this time, the occupant is continuously moving, assuming a continuously varying position and posture in the vehicle including moving from side to side, forward and back, twisting his/her head, reading newspapers and books, moving hands, arms, feet and legs, until the desired number of different seated state examples are obtained. In some cases, this process is practiced by confining the motion of an occupant into a particular zone. In some cases, for example, the occupant is trained to exercise these different seated state motions while remaining, in a particular zone that may be the safe zone, the keep out zone, or an intermediate gray zone. In this manner, data is collected representing the airbag disable, depowered airbag enabled or full power airbag enabled states. In other cases, the actual position of the back of the head and/or the shoulders of the occupant are tracked using string pots, high frequency ultrasonic transducers, or optically. In this manner, the position of the occupant can be measured and the decision as to whether this should be a disable or enable airbag case can be decided later. By continuously monitoring the occupant, an added advantage results in that the data can be collected to permit a comparison of the occupant from one seated state to another. This is particularly valuable in attempting to project the future location of an occupant based on a series of past locations as would be desirable for example to predict when an occupant would cross into the keep out zone during a panic braking situation prior to crash.</p>
    <p>It is important to note that it is not necessary to train on every vehicle produced but rather to train on each platform. A platform is an automobile manufacturer's designation of a group of vehicle models that are built on the same vehicle structure.</p>
    <p>A review of the literature on neural networks yields the conclusion that the use of such a large training set is unique in the neural network field. The rule of neural networks is that there must be at least three training cases for each network weight. Thus, for example, if a neural network has 156 input nodes, 10 first hidden layer nodes, 5 second hidden layer nodes, and one output node this results in a total of 1,622 weights. According to conventional theory 5000 training examples should be sufficient. It is highly unexpected, therefore, that greater accuracy would be achieved through 100 times that many cases. It is thus not obvious and cannot be deduced from the neural network literature that the accuracy of the system will improve substantially as the size of the training database increases even to tens of thousands of cases. It is also not obvious looking at the plots of the vectors obtained using ultrasonic transducers that increasing the number of tests or the database size will have such a significant effect on the system accuracy. Each of the vectors is a rather course plot with a few significant peaks and valleys. Since the spatial resolution of the system is typically about 3 to 4 inches, it is once again surprising that such a large database is required to achieve significant accuracy improvements.</p>
    <p>Process For Training a Vehicle</p>
    <p>The process for adapting an ultrasonic system to a vehicle will now be described. A more detailed list of steps is provided in Appendix 3. Although the pure ultrasonic system is described here, a similar set of steps applies when other technologies such as weight and optical or other electromagnetic wave systems are used. This description is thus provided to be exemplary and not limiting:</p>
    <p>1. Select transducer, horn and grill designs to fit the vehicle. At this stage, usually full horns are used which are mounted so that they project into the passenger compartment. No attempt is made at this time to achieve an esthetic matching of the transducers to the vehicle surfaces. An estimate of the desired transducer fields are made at this time either from measurements in the vehicle directly or from CAD drawings.</p>
    <p>2. Make polar plots of the transducer sonic fields. Transducers and candidate horns and grills are assembled and tested to confirm that the desired field angles have been achieved. This frequently requires some adjustment of the transducers in the horn and of the grill. A properly designed grill for ultrasonic systems can perform a similar function as a lens for optical systems.</p>
    <p>3. Check to see that the fields cover the required volumes of the vehicle passenger compartment and do not impinge on adjacent flat surfaces that may cause multipath effects. Redesign horns and grills if necessary.</p>
    <p>4. Install transducers into vehicle.</p>
    <p>5. Map transducer fields in the vehicle and check for multipath effects and proper coverage.</p>
    <p>6. Adjust transducer aim and re-map fields if necessary.</p>
    <p>7. Install daily calibration fixture and take standard setup data.</p>
    <p>8. Acquire 50,000 to 100,000 vectors</p>
    <p>9. Adjust vectors for volume considerations by removing some initial data points if cross talk is present and some final points to keep data in the desired passenger compartment volume.</p>
    <p>10. Normalize vectors.</p>
    <p>11. Run neural network algorithm generating software to create algorithm for vehicle installation.</p>
    <p>12. Check the accuracy of the algorithm. If not sufficiently accurate collect more data where necessary and retrain. If still not sufficiently accurate, add additional transducers to cover holes.</p>
    <p>13. When sufficient accuracy is attained, proceed to collect 500,000 training vectors varying:</p>
    <p>Occupancy (see Appendices 1 and 3):</p>
    <p>Occupant size, position (zones), clothing etc</p>
    <p>Child seat type, size, position etc.</p>
    <p>Empty seat</p>
    <p>Vehicle configuration:</p>
    <p>Seat position</p>
    <p>Window position</p>
    <p>Visor and armrest position</p>
    <p>Presence of other occupants in adjoining seat or rear seat</p>
    <p>Temperature</p>
    <p>Temperature gradientstable</p>
    <p>Temperature turbulenceheater and air conditioner</p>
    <p>Wind turbulenceHigh speed travel with windows open, top down etc</p>
    <p>14. Collect 100,000 vectors of Independent data using other combinations of the above</p>
    <p>15. Collect 50,000 vectors of real world data to represent the acceptance criteria and more closely represent the actual seated state probabilities in the real world.</p>
    <p>16. Train network and create algorithm using the training vectors and the Independent data vectors.</p>
    <p>17. Validate the algorithm using the real world vectors.</p>
    <p>18. Install algorithm into the vehicle and test.</p>
    <p>19. Decide on post processing methodology to remove final holes (areas of inaccuracy) in system</p>
    <p>20. Implement post-processing methods into the algorithm</p>
    <p>21. Final test. The process up until step <b>13</b> involve the use of transducers with full horns mounted on the surfaces of the interior passenger compartment. At some point, the actual transducers which are to be used in the final vehicle must be substituted for the trial transducers. This is either done prior to step <b>13</b> or at this step. This process involves designing transducer holders that blend with the visual surfaces of the passenger compartment so that they can be covered with a properly designed grill that helps control the field and also serves to retain the esthetic quality of the interior. This is usually a lengthy process and involves several consultations with the customer. Usually, therefore, the steps from <b>13</b> through <b>20</b> are repeated at this point after the final transducer and holder design has been selected. The initial data taken with full horns gives a measure of the best system that can be made to operate in the vehicle. Some degradation in performance is expected when the esthetic horns and grills are substituted for the full horns. By conducting two complete data collection cycles an accurate measure of this accuracy reduction can be obtained.</p>
    <p>22. Ship to customers to be used in production vehicles.</p>
    <p>23. Collect additional real world validation data for continuous improvement.</p>
    <p>More detail on the operation of the transducers and control circuitry as well as the neural network is provided in the above referenced patents and patent applications and is included herein as if the entire text of the same were reproduced here. One particular example of a successful neural network for the two transducer case had 78 input nodes, 6 hidden nodes and one output node and for the four transducer case had 176 input nodes 20 hidden layer nodes on hidden layer one, 7 hidden layer nodes on hidden layer <b>2</b> and one output node. The weights of the network were determined by supervised training using the back propagation method as described in the referenced patent applications and in more detail in the references cited therein. Naturally other neural network architectures are possible including RCE, Logicon Projection, Stochastic etc.</p>
    <p>Finally, the system is trained and tested with situations representative of the manufacturing and installation tolerances that occur during the production and delivery of the vehicle as well as usage and deterioration effects. Thus, for example, the system is tested with the transducer mounting positions shifted by up to one inch in any direction and rotated by up to 15 degrees, with a simulated accumulation of dirt and other variations. This tolerance to vehicle variation also sometimes permits the installation of the system onto a different but similar model vehicle with, in many cases, only minimal retraining of the system.</p>
    <p>The speed of sound varies with temperature, humidity, and pressure. This can be compensated for by using the fact that the geometry between the transducers is known and the speed of sound can therefore be measured. Thus, on vehicle startup and as often as desired thereafter, the speed of sound can be measured by one transducer, such as transducer <b>110</b> in FIG. 5, sending, a signal which is directly received by another transducer. Since the distance separating them is known, the speed of sound can be calculated and the system automatically adjusted to remove the variation due to the change in the speed of sound. Therefore, the system operates with same accuracy regardless of the temperature, humidity or atmospheric pressure. It may even be possible to use this technique to also automatically compensate for any effects due to wind velocity through an open window. An additional benefit of this system is that it can be used to determine the vehicle interior temperature for use by other control systems within the vehicle since the variation in the velocity of sound is a strong function of temperature and a weak function of pressure and humidity.</p>
    <p>The problem with the speed of sound measurement described above is that some object in the vehicle may block the path from one transducer to another. This of course could be checked and a correction not be made if the signal from one transducer does not reach the other transducer. The problem, however, is that the path might not be completely blocked but only slightly blocked. This would cause the ultrasonic path length to increase, which would give a false indication of a temperature change. This can be solved by using more than one transducer. All of the transducers can broadcast signals to all of the other transducers. The problem here, of course, is which transducer pair does one believe if they all give different answers. The answer is the one that gives the shortest distance or the greatest calculated speed of sound. By this method, there are a total of 6 separate paths for four ultrasonic transducers.</p>
    <p>An alternative method of determining the temperature is to use the transducer circuit to measure some parameter of the transducer that changes with temperature. For example the natural frequency of ultrasonic transducers changes in a known manner with temperature and therefore by measuring the natural frequency of the transducer the temperature can be determined. Since this method does not require communication between transducers, it would also work in situations where each transducer has a different resonant frequency.</p>
    <p>The process by which all of the distances are carefully measured from each transducer to the other transducers and the algorithm developed to determine the speed of sound, is a significant part of the teachings of the instant invention. Prior to this, the speed of sound calculation was based on a single transmission from one transducer to a known second transducer. This resulted in an inaccurate system design and degraded the accuracy of systems in the field.</p>
    <p>If the electronic control module that is part of the system is located in generally the same environment as the transducers, another method of determining the temperature is available. This method utilizes a device and whose temperature sensitivity is known and which is located in the same box as the electronic circuit. In fact, in many cases, an existing component on the printed circuit board can be monitored to give an indication of the temperature. For example, the diodes in the log comparison circuit have characteristics that their resistance changes in a known manner with temperature. It can be expected that the electronic module will generally be at a higher temperature than the surrounding environment, however, the temperature difference is a known and predictable amount. Thus, a reasonably good estimation of the temperature in the passenger compartment can also be obtained in this manner.</p>
    <p>Another important feature of a system, developed in accordance with the teachings of this invention, is the realization that motion of the vehicle can be used in a novel manner to substantially increase the accuracy of the system. Ultrasonic waves reflect on most objects as light off a mirror. This is due to the relatively long wavelength of ultrasound as compared with light. As a result, certain reflections can overwhelm the receiver and reduce the available information. When readings are taken while the occupant and/or the vehicle is in motion, and these readings averaged over several transmission/reception cycles, the motion of the occupant and vehicle causes various surfaces to change their angular orientation slightly but enough to change the reflective pattern and reduce this mirror effect. The net effect is that the average of several cycles gives a much clearer image of the reflecting object than is obtainable from a single cycle. This then provides a better image to the neural network and significantly improves the identification accuracy of the system. The choice of the number of cycles to be averaged depends on the system requirements. For example, if dynamic out-of-position is required then each vector must be used alone and averaging in the simple sense cannot be used. This will be discussed more detail below.</p>
    <p>When an occupant is sitting in the vehicle during normal vehicle operation, the determination of the occupancy state can be substantially improved by using successive observations over a period of time. This can either be accomplished by averaging the data prior to insertion into a neural network, or alternately the decision of the neural network can be averaged. This is known as the categorization phase of the process. During categorization the occupancy state of the vehicle is determined. Is the vehicle occupied by the forward facing human, an empty seat, a rear facing child seat, or an out-of-position human? Typically many seconds of data can be accumulated to make the categorization decision.</p>
    <p>When a driver senses an impending crash, on the other hand, he or she will typically slam on the brakes to try to slow vehicle prior to impact. If an occupant is unbelted, he or she will begin moving toward the airbag during this panic braking. For the purposes of determining the position of the occupant, there is not sufficient time to average data as in the case of categorization. Nevertheless, there is information in data from previous vectors that can be used to partially correct errors in current vectors, which may be caused by thermal effects, for example. One method is to determine the location of the occupant using the neural network based on previous training. The motion of the occupant can then be compared to a maximum likelihood position based on the position estimate of the occupant at previous vectors. Thus, for example, perhaps the existence of thermal gradients in the vehicle caused an error in the current vector leading to a calculation that the occupant has moved 12 inches since the previous vector. Since this could be a physically impossible move during ten milliseconds, the measured position of the occupant can be corrected based on his previous positions and known velocity. Naturally, if an accelerometer is present in the vehicle and if the acceleration data is available for this calculation, a much higher accuracy prediction can be made. Thus, there is information in the data in previous vectors as well as in the positions of the occupant determined from the this data that can be used to correct erroneous data in the current vector and, therefore, in a manner not too dissimilar from the averaging method for categorization, the position accuracy of the occupant can be known with higher accuracy.</p>
    <p>Returning to the placement of ultrasonic transducers for the ultrasonic occupant position sensor system, as to the more novel features of the invention for the placement of ultrasonic transducers, this application discloses (1) the application of two sensors to single-axis monitoring of target volumes; (2) the method of locating two sensors spanning a target volume to sense object positions, that is, transducers are mounted along the sensing axis beyond the objects to be sensed; (3) the method of orientation of the sensor axis for optimal target discrimination parallel to the axis of separation of distinguishing target features; and (4) the method of defining the head and shoulders and supporting surfaces as defining humans for rear facing child seat detection and forward facing human detection.</p>
    <p>A similar set of observations is available for the use of electromagnetic sensors. Such rules however must take into account that such sensors typically are more accurate in measuring lateral and vertical dimensions relative to the sensor and distances perpendicular to the sensor. This is particularly the case for CMOS and CCD based transducers.Considerable work is ongoing to improve the resolution of the ultrasonic transducers. To take advantage of higher resolution transducers, more closer together data points should be obtained. This means that after the envelope has been extracted from the returned signals, the sampling rate should be increased from approximately 1000 samples per second to perhaps 2000 samples per second or even higher. By doubling or tripling the amount data required to be analyzed, the system which is mounted on the vehicle will require greater computational power. This results in a more expensive electronic system. Not all of the data is of equal importance, however. The position of the occupant in the normal seating position does not need to be known with great accuracy whereas as that occupant is moving toward the keep out zone boundary during pre-crash braking, the spatial accuracy requirements become more important. Fortunately, the neural network algorithm generating system has the capability of indicating to the system designer the relative value of each of the data points used by the neural network. Thus, as many as, for example, 500 data points per vector may be collected and fed to the neural network during the training stage and, after careful pruning, the final number of data points to be used by the vehicle mounted system may be reduced to 150, for example. This technique of using the neural network algorithm-generating program to prune the input data is an important teaching of the present invention. By this method, the advantages of higher resolution transducers can be optimally used without increasing the cost of the electronic vehicle mounted circuits. Also, once the neural network has determined the spacing of the data points, this can be fine-tuned, for example, by acquiring more data points at the edge of the keep out zone as compared to positions well into the safe zone. The initial technique is done be collecting the full 500 data points, for example, while in the system installed in the vehicle the data digitization spacing can be determined by hardware or software so that only the required data is acquired.</p>
    <p>The technique that was described above for the determination of the location of an occupant during panic or braking pre-crash situations involved the use of a modular neural network. In that case, one neural network was used to determine the occupancy state of the vehicle and the second neural network was used to determine the location of the occupant within the vehicle. The method of designing a system utilizing multiple neural networks is a key teaching of the present invention. When this idea is generalized, many potential combinations of multiple neural network architectures become possible. Some of these will now be discussed.</p>
    <p>One of the earliest attempts to use multiple neural networks was to combine different networks trained differently but on substantially the same data under the theory that the errors which affect the accuracy of one network would be independent of the errors which affect the accuracy of another network. For example, for a system containing four ultrasonic transducers, four neural networks could be trained each using a different subset of the four transducer data. Thus, if the transducers are arbitrarily labeled A, B, C and D the then the first neural network would be trained on data from A, B and C. The second neural network would be trained on data from B, C, and D etc. This technique has not met with a significant success since it is an attempt to mask errors in the data rather than to eliminate them. Nevertheless, such a system does perform marginally better in some situations compared to a single network using data from all four transducers. The penalty for using such a system is that the computational time is increased by approximately a factor of three. This significantly affects the cost of the system installed in a vehicle.</p>
    <p>An alternate method of obtaining some of the advantages of the parallel neural network architecture described above, is to form a single neural network but where the nodes of one or more of the hidden layers are not all connected to all of the input nodes. Alternately, if the second hidden layer is chosen, all of the notes from the previous hidden layer are not connected to all of the nodes of the subsequent layer. The alternate groups of hidden layer nodes can then feed to different output notes and the results of the output nodes combined, either through a neural network training process into a single decision or a voting process. This latter approach retains most of the advantages of the parallel neural network while substantially reducing the computational complexity.</p>
    <p>The fundamental problem with parallel networks is that they focus on achieving reliability or accuracy by redundancy rather than by improving the neural network architecture itself or the quality of the data being used. They also increase the cost of the final vehicle installed systems. Alternately, modular neural networks improve the accuracy of the system by dividing up the tasks. For example, if a system is to be designed to determine the type of tree and the type of animal in a particular scene, the modular approach would be to first determine whether the object of interest is an animal or a tree and then use separate neural networks to determine type of tree and the type of animal. When a human looks at a tree he is not ask himself is that a tiger or a monkey. Modular neural network systems are efficient since once the categorization decision is made, the seat is occupied by forward facing human, for example, the location of that object can be determined more accurately and without requiring increased computational resources.</p>
    <p>Another example where modular neural networks have proven valuable is provide a means for separating normal from special cases. It has been found that in some cases, the vast majority of the data falls into what might be termed normal cases that are easily identified with a neural network. The balance of the cases cause the neural network considerable difficulty, however, there are identifiable characteristics of the special cases that permits them to be separated from the normal cases and dealt with separately. Various types of human intelligence rules can be used, in addition to a neural network, to perform this separation including fuzzy logic, statistical filtering using the average class vector of normal cases, the vector standard deviation, and threshold where a fuzzy logic network is used to determine chance of a vector belonging to a certain class. If the chance is below a threshold, the standard neural network is used and if above the special one is used.</p>
    <p>Mean-Variance connections, Fuzzy Logic, Stochastic, and Genetic Algorithm networks, and combinations thereof such as Neuro-Fuzzy systems are other technologies considered. During the process of designing a system to be adapted to a particular vehicle, many different neural network architectures are considered including those mentioned above. The particular choice of architecture is frequently determined on a trial and error basis by the system designer. Although the parallel architecture system described above has not proven to be in general beneficial, one version of this architecture has shown some promise. It is known that when training a neural network, that as the training process proceeds the accuracy of the decision process improves for the training and independent databases. It is also known that the ability of the network to generalize suffers. That is, when the network is presented with a system which is similar to some case in the database but still with some significant differences, the network may make the proper decision in the early stages of training, but the wrong decisions after the network has become fully trained. This is sometimes called the young network vs. old network dilemma. In some cases, therefore, using an old network in parallel with a young network can retain some of the advantages of both networks, that is, the high accuracy of the old network coupled with the greater generality of the young network. Once again, the choice of any of these particular techniques is part of the process of designing a system to be adapted to a particular vehicle and is the prime subject of this invention. The particular combination of tools used depends on the particular application and the experience of the system designer.</p>
    <p>The methods above have been described in connection with the use of ultrasonic transducers. Many of the methods, however, are also applicable to optical, radar, capacitive and other sensing systems and where applicable, this invention is not limited to ultrasonic systems. In particular, an important feature of this invention is the proper placement of three or more separately located receivers such that the system still operates with high reliability if one of the receivers is blocked by some object such as a newspaper. This feature is also applicable to systems using electromagnetic radiation instead of ultrasonic, however the particular locations will differ based on the properties of the particular transducers. Optical sensors based on two-dimensional cameras or other image sensors, for example, are more appropriately placed on the sides of a rectangle surrounding the seat to be monitored rather than at the corners of such a rectangle as is the case with ultrasonic sensors. This is because ultrasonic sensors measure an axial distance from the sensor where the camera is most appropriate for measuring distances up and down and across its field view rather than distances to the object. With the use of electromagnetic radiation and the advances which have recently been made in the field of very low light level sensitivity, it is now possible, in some implementations, to eliminate the transmitters and use background light as the source of illumination along with using a technique such as auto-focusing to obtain the distance from the receiver to the object. Thus, only receivers would be required further reducing the complexity of the system.</p>
    <p>Although implicit in the above discussion, an important feature of this invention which should be emphasized is the method of developing a system having distributed transducer mountings. Other systems which have attempted to solve the rear facing child seat (RFCS) and out-of-position problems have relied on a single transducer mounting location or at most, two transducer mounting locations. Such systems can be easily blinded by a newspaper or by the hand of an occupant, for example, which is imposed between the occupant and the transducers. This problem is almost completely eliminated through the use of three or more transducers which are mounted so that they have distinctly different views of the passenger compartment volume of interest. If the system is adapted using four transducers as illustrated in the distributed system of FIG. 9, for example, the system suffers only a slight reduction in accuracy even if two of the transducers are covered so as to make them inoperable.</p>
    <p>It is important in order to obtain the full advantages of the system when a transducer is blocked, that the training and independent databases contains many examples of blocked transducers. If the pattern recognition system, the neural network in this case, has not been trained on a substantial number of blocked transducer cases, it will not do a good job in recognizing such cases later. This is yet another instance where the makeup of the databases is crucial to the success of designing the system that will perform with high reliability in a vehicle and is an important aspect of the instant invention.</p>
    <p>Other techniques which may or may not be part of the process of designing a system for a particular application include the following:</p>
    <p>1. Fuzzy Logic</p>
    <p>As discussed above, neural networks frequently exhibit the property that when presented with a situation that is totally different from any previously encounter, an irrational decision can result. Frequently when the trained observer looks at input data, certain boundaries to the data become evident and cases that fall outside of those boundaries are indicative of either corrupted data or data from a totally unexpected situation. It is sometimes desirable for the system designer to add rules to handle these cases. These can be fuzzy logic based rules or rules based on human intelligence. One example would be that when certain parts of the data vector fall outside of expected bounds that the system defaults to an airbag enable state.</p>
    <p>2. Genetic Algorithms</p>
    <p>When developing a neural network algorithm for a particular vehicle, there is no guarantee that the best of all possible algorithms has been selected. One method of improving the probability that the best algorithm has been selected is to incorporate some of the principles of genetic algorithms. In one application of this theory, the network architecture and/or the node weights are varied pseudo-randomly to attempt to find other combinations which have higher success rates. The discussion of such genetic algorithms systems appears in the book <i>Computational Intelligence </i>referenced above.</p>
    <p>3. Pre-processing</p>
    <p>For military target recognition is common to use the Fourier transform of the data rather than the data itself. This can be especially valuable for categorization as opposed to location of the occupant and the vehicle. When used with a modular network, for example, the Fourier transform of the data may be used for the categorization neural network and the non-transformed data used for the position determination neural network. Recently wavelet transforms have also been considered as a preprocessor.</p>
    <p>4. Occupant Position Determination Comparison</p>
    <p>Above, under the subject of dynamic out-of-position, it was discussed that the position of the occupant can be used as a filter to determine the quality of the data in a particular vector. This technique can also be used in general as a method to improve the quality of a vector of data based on the previous positions of the occupant. This technique can also be expanded to help differentiate live objects in the vehicle from inanimate objects. For example, a forward facing human will change his position frequently during the travel of the vehicle whereas a box will tend to show considerably less motion. This is also useful, for example, in differentiating a small human from an empty seat. The motion of a seat containing a small human will be significantly different from that of an empty seat even though the particular vector may not show significant differences. That is, a vector formed from the differences from two successive vectors is indicative of motion and thus of an occupant.</p>
    <p>5. Blocked Transducers</p>
    <p>It is sometimes desirable to positively identify a blocked transducer and when such a situation is found to use a different neural network which has only been trained on the subset of unblocked transducers. Such a network, since it has been trained specifically on three transducers, for example, will generally perform more accurately than a network which has been trained on four transducers with one of the transducers blocked some of the time. Once a blocked transducer has been identified the occupant can be notified if the condition persists for more than a reasonable time.</p>
    <p>6. Other Basic Architectures</p>
    <p>The back propagation neural network is a very successful general-purpose network. However, for some applications, there are other neural network architectures that can perform better. If it has been found, for example, that a parallel network as described above results in a significant improvement in the system, then, it is likely that the particular neural network architecture chosen has not been successful in retrieving all of the information that is present in the data. In such a case an RCE, Stochastic, Logicon Projection, or one of the other approximately 30 types of neural network architectures can be tried to see if the results improve. This parallel network test, therefore, is a valuable tool for determining the degree to which the current neural network is capable of using efficiently the available data.</p>
    <p>7. Transducer Geometry</p>
    <p>Another technique, which is frequently used in designing a system for a particular vehicle, is to use a neural network to determine the optimum mounting locations, aiming directions and field angles of transducers. For particularly difficult vehicles it is sometimes desirable to mount a large number of ultrasonic transducers, for example, and then use the neural network to eliminate those transducers which are least significant. This is similar to the technique described above where all kinds of transducers are combined initially and later pruned.</p>
    <p>8. Data Quantity</p>
    <p>Since it is very easy to take large amounts data and yet large databases require considerably longer training time for a neural network, a test of the variability of the database can be made using a neural network. If for example after removing half of the data in the database, the performance of a trained neural network against the validation database does not decrease, then the system designer suspects that the training database contains a large amount of redundant data. Techniques such as similarity analysis can then be used to remove data that is virtually indistinguishable from other data. Since it is important to have a varied database, it is undesirable generally to have duplicate or essentially duplicate vectors in the database since the presence of such vectors can bias system and drive the system more toward memorization and away from generalization.</p>
    <p>9. Environmental Factors</p>
    <p>An evaluation can be made of the beneficial effects of using varying environmental influences during data collection on the accuracy of the system using neural networks along with a technique such as design of experiments.</p>
    <p>10. Database Makeup</p>
    <p>It is generally believed that the training database must be flat meaning that all of the occupancy states that the neural network must recognize must be approximately equally represented in the training database. Typically, the independent database has approximately the same makeup as the training database. The validation database, on the other hand, typically is represented in a non-flat basis with representative cases from real world experience. Since there is no need for the validation database to be flat, it can include many of the extreme cases as well as being highly biased towards the most common cases. This is the theory that is currently being used to determine the makeup of the various databases. The success of this theory continues to be challenged by the addition of new cases to the validation database. When significant failures are discovered in the validation database, the training and independent databases are modified in an attempt to remove the failure.</p>
    <p>11. Biasing</p>
    <p>All seated state occupancy states are not equally important. The final system must be nearly 100% accurate for forward facing in-position humans. Since that will comprise the majority of the real world situations, even a small loss in accuracy here will cause the airbag to be disabled in a situation where it otherwise would be available to protect an occupant. A small decrease in accuracy will thus result in a large increase in deaths and injuries. On the other hand, there are no serious consequences if the airbag is deployed occasionally when the seat is empty. Various techniques are used to bias the data in the database to take this into account. One technique is to give a much higher value to the presence of a forward facing human during the supervised learning process than to an empty seat. Another technique is to include more data for forward facing humans than for empty seats. This, however, can be dangerous as an unbalanced network leads to a loss of generality.</p>
    <p>12. Screening</p>
    <p>It is important that the loop be closed on data acquisition. That is, the data must be checked at the time the data is acquired to the sure that it is good data. Bad data can happen because of electrical disturbances on the power line, sources of ultrasound such as nearby welding equipment, or due to human error. If the data remains in the training database, for example, then it will degrade the performance of the network. Several methods exist for eliminating bad data. The most successful method is to take an initial quantity of data, such as 30,000 to 50,000 vectors, and create an interim network. This is normally done anyway as an initial check on the system capabilities prior to engaging in an extensive data collection process. The network can be trained on this data and, as the real training data is acquired, the data can be tested against the neural network created on the initial data set. Any vectors that fail are examined for reasonableness.</p>
    <p>13. Vector Normalization Method</p>
    <p>Through extensive research it has been found that the vector should be normalized based on all of the data in the vector, that is have all its data values range from 0 to 1. For particular cases, however, it has been fond desirable to apply the normalization process selectively, eliminating or treating differently the data at the early part of the data from each transducer. This is especially the case when there is significant ringing on the transducer or cross talk when a separate send and receive transducer is used. There are times when other vector normalization techniques are required and the neural network system can be used to determine the best vector normalization technique for a particular application.</p>
    <p>14. Feature Extraction</p>
    <p>The success of a neural network system can frequently be aided if additional data is inputted into the network . One example can be the number of 0 data points before the first peak is experience. Alternately, the exact distance to the first peak can be determined prior to the sampling of the data. Other features can include the number of peaks, the distance between the peaks, the width of the largest peak, the normalization factor, the vector mean or standard deviation, etc. These normalization techniques are frequently used at the end of the adaptation process to slightly increase the accuracy of the system.</p>
    <p>15. Noise</p>
    <p>It has been frequently reported in the literature that adding noise to the data that is provided to a neural network can improve the neural network accuracy by leading to better generalization and away from memorization. However, the training of the network in the presence of thermal gradients has been shown to substantially eliminate the need to artificially add noise to the data. Nevertheless, in some cases, improvements have been observed when random arbitrary noise of a rather low level is superimposed on the training data.</p>
    <p>16. Photographic Recording of the Setup</p>
    <p>After all of the data has been collected and used to train a neural network, it is common to find a significant number of vectors which, when analyzed by the neural network, give a weak or wrong decision. These vectors must be carefully studied especially in comparison with adjacent vectors to see if there is an identifiable cause for the weak or wrong decision. Perhaps the occupant was on the borderline of the keep out zone and strayed into the keep out zone during a particular data collection event. For this reason, it is desirable to photograph each setup simultaneous with the collection of the data. This can be done using a camera mounted in a position whereby it obtains a good view of the seat occupancy. Sometimes several cameras are necessary to minimize the effects of blockage by a newspaper, for example. Having the photographic record of the data setup is also useful when similar results are obtained when the vehicle is subjected to road testing. During road testing, the camera is also present and the test engineer is required to initiate data collection whenever the system does not provide the correct response. The vector and the photograph of this real world test can later be compared to similar setups in the laboratory to see whether there is data that was missed in deriving the matrix of vehicle setups for training the vehicle.</p>
    <p>17. Automation</p>
    <p>When collecting data in the vehicle it is desirable to automate the motion of the vehicle seat, seatback, windows, visors etc. in this manner the positions of these items can be controlled and distributed as desired by the system designer. This minimizes the possibility of taking too much data at one configuration and thereby unbalancing the network.</p>
    <p>18. Automatic Setup Parameter Recording</p>
    <p>To achieve an accurate data set, the key parameters of the setup should be recorded automatically. These include the temperatures at various positions inside the vehicle, the position of the vehicle seat, and seatback, the position of the headrest, visor and windows and, where possible, the position of the vehicle occupants. The automatic recordation of these parameters minimizes the effects of human errors.</p>
    <p>19. Laser Pointers</p>
    <p>During the initial data collection with full horns mounted on the surface of the passenger compartment, care must the exercised so that the transducers are not accidentally moved during the data collection process. In order to check for this possibility, a small laser diode is incorporated into each transducer holder. The laser is aimed so that it illuminates some other surface of the passenger compartment at a known location. Prior to each data taking session, each of the transducer aiming points is checked.</p>
    <p>20. Multi-frequency Transducer Placement</p>
    <p>When data is collected for dynamic out-of-position, each of the ultrasonic transducers must operate at the different frequency so that all transducers can transmit simultaneously. By this method data can be collected every 10 milliseconds, which is sufficiently fast to approximately track the motion of an occupant during pre-crash braking prior to an impact. A problem arises in the spacing of the frequencies between the different transducers. If the spacing is too close, it becomes very difficult to separate the signals from different transducers and it also affects the sampling rate of the transducer data and thus the resolution of the transducers. If an ultrasonic transducer operates module below 35 kHz it can be sensed by dogs and other animals. If the transducer operates much above 70 kHz, it is very difficult to make the open type of ultrasonic transducer which produces the highest sound pressure. If the multiple frequency system is used for both the driver and passenger-side, eight separate frequencies are required. In order to find eight frequencies between 35 and 70 kHz, a frequency spacing of 5 kHz is required. In order to use conventional electronic filters and to provide sufficient spacing to permit the desired resolution at the keep out zone border, a 10 kHz spacing is desired. These incompatible requirements can be solved through a careful judicious placement of the transducers such that transducers that are within 5 kHz of each other are placed in such a manner that there is no direct path between the transducers and any indirect path is sufficiently long so that it can be filtered temporarily. An example of such an arrangement is shown on FIG. <b>11</b>. For this example the transducers operate at the following frequencies A 65 kHz, B 55 kHz, C 35 kHz, D 45 kHz, E 50 kHz, F 40 kHz, G 60 kHz, H 70 kHz. Actually other arrangements adhering to the principle described above would also work.</p>
    <p>21. Use of a PC in Data Collection</p>
    <p>When collecting data for the training, independent, and validation databases, it is frequently desirable to test the data using various screening techniques and to display the data on a monitor. Thus, during data collection the process is usually monitored using a desktop PC for data taken in the laboratory and a laptop PC for data taken on the road.</p>
    <p>22. Use of Referencing Markers and Gages</p>
    <p>In addition to and sometimes as a substitution for, the automatic recording of the positions of the seats, seatbacks, windows etc. as described above, a variety of visual markings and gages are frequently used. This includes markings to show the angular position of the seatback, the location of the seat on the seat track, the openness of the window, etc.. Also in those cases where automatic tracking of the occupant is not implemented, visual markings are placed such that a technician can observe that the test occupant remains within the required zone for the particular data taking exercise. Sometimes, a laser diode is used to create a visual line in the space that represents the boundary of the keep out zone or other desired zone boundary.</p>
    <p>It is important to realize that the adaptation process described herein applies to any combination of transducers that provide information about the vehicle occupancy. These include weight sensors, capacitive sensors, inductive sensors, moisture sensors, ultrasonic, optic, infrared, radar among others. The adaptation process begins with a selection of candidate transducers for a particular vehicle model. This selection is based on such considerations as cost, alternate uses of the system other than occupant sensing, vehicle interior passenger compartment geometry, desired accuracy and reliability, vehicle aesthetics, vehicle manufacturer preferences, and others. Once a candidate set of transducers has been chosen, these transducers are mounted in the test vehicle according to the teachings of this invention. The vehicle is then subjected to an extensive data collection process wherein various objects are placed in the vehicle at various locations as described below and an initial data set is collected. A pattern recognition system is then developed using the acquired data and an accuracy assessment is made. Further studies are made to determine which, if any, of the transducers can be eliminated from the design. In general the design process begins with a surplus of sensors plus an objective as to how many sensors are to be in the final vehicle installation. The adaptation process can determine which of the transducers are most important and which are least important and the least important transducers can be eliminated to reduce system cost and complexity.</p>
    <p>Although several preferred methods are illustrated and described above, there are other possible combinations using different sensors located at different positions within the automobile passenger compartment which measure either the same or different characteristics of an occupying object to accomplish the same or similar goals as those described herein. There are also numerous additional applications in addition to those described above including, but not limited to, monitoring the driver seat, the center seat or the rear seat of the vehicle or for controlling other vehicle systems in addition to the airbag system. This invention is not limited to the above embodiments and should be determined by the following claims.</p>
    <heading>APPENDIX 2</heading> <heading>Analysis of Neural Network Training and Data Preprocessing MethodsAn Example</heading> <p>1. Introduction</p>
    <p>The Artificial Neural Network that forms the brains of the Occupant Spatial Sensor needs to be trained to recognize airbag enable and disable patterns. The most important part of this training is the data that is collected in the vehicle, which provides the patterns corresponding to these respective configurations. Manipulation of this data (such as filtering) is appropriate if this enhances the information contained in the data. Important too, are the basic network architecture and training methods applied, as these two determine the learning and generalization capabilities of the neural network. The ultimate test for all methods and filters is their effect on the network performance against real world situations.</p>
    <p>The Occupant Spatial Sensor (OSS) uses an artificial neural network (ANN) to recognize patterns that it has been trained to identify as either airbag enable or airbag disable conditions. The pattern is obtained from four ultrasonic transducers that cover the front passenger scating area. This pattern consists of the ultrasonic echoes from the objects in the passenger seat area. The signal from each of the four transducers consists of the electrical image of the return echoes, Which is processed by the electronics. The electronic processing comprises amplification (logarithmic compression), rectification, and demodulation (band pass filtering), followed by discretization (sampling) and digitization of the signal. The only software processing required, before this signal can be fed into the artificial neural network, is normalization (i.e. mapping the input to numbers between 0 and 1). Although this is a fair amount of processing, the resulting signal is still considered raw, because all information is treated equally.</p>
    <p>It is possible to apply one or more software preprocessing filters to the raw signal before it is fed into the artificial neural network. The purpose of such filters is to enhance the useful information going into the ANN, in order to increase the system performance. This document describes several preprocessing filters that were applied to the ANN training of a particular vehicle.</p>
    <p>2. Data Description</p>
    <p>The performance of the artificial neural network is dependent on the data that is used to train the network. The amount of data and the distribution of the data within the realm of possibilities are known to have a large effect on the ability of the network to recognize patterns and to generalize. Data for the OSS is made up of vectors. Each vector is a combination of the useful parts of the signals collected from four ultrasonic transducers. A typical vector could comprise on the order of 100 data points, each representing the (time displaced) echo level as recorded by the ultrasonic transducers.</p>
    <p>Three different sets of data are collected. The first set, the training data, contains the patterns that the ANN is being trained on to recognize as either an airbag deploy or non-deploy scenario. The second set is the independent test data. This set is used during the network training to direct the optimization of the network weights. The third set is the validation (or real world) data. This set is used to quantify the success rate (or performance) of the finalized artificial neural network.</p>
    <p>Table 1 shows the main characteristics of these three data sets, as collected for the vehicle. Three numbers characterize the sets. The number of configurations characterizes how many different subjects and objects were used. The number of setups is the product of the number of configurations and the number of vehicle interior variations (seat position and recline, roof and window state, etc.) performed for each configuration. The total number of vectors is then made up of the product of the number of setups and the number of patterns collected while the subject or object moves within the passenger volume.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 1</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Characteristics of the Data Sets</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="5"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="56pt" align="left"> </colspec> <colspec colname="2" colwidth="70pt" align="center"> </colspec> <colspec colname="3" colwidth="28pt" align="center"> </colspec> <colspec colname="4" colwidth="49pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Data Set</td>
                <td class="description-td">Configurations</td>
                <td class="description-td">Setups</td>
                <td class="description-td">Vectors</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="4" align="center" rowsep="1" class="description-td" colspan="5"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Training</td>
                <td class="description-td">130</td>
                <td class="description-td">1300</td>
                <td class="description-td">650,000</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Independent Test</td>
                <td class="description-td">130</td>
                <td class="description-td">1300</td>
                <td class="description-td">195,000</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Validation</td>
                <td class="description-td">100</td>
                <td class="description-td">100</td>
                <td class="description-td">15,000</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="4" align="center" rowsep="1" class="description-td" colspan="5"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>1.1 Training Data Set Characteristics</p>
    <p>The training data set can be split up in various ways into subsets that show the distribution of the data. Table 2 shows the distribution of the training set amongst three classes of passenger seat occupancy: Empty Seat, Human Occupant, and Child Seat. All human occupants were adults of various sizes. No children were part of the training data set other then those seated in Forward Facing Child Seats. Table 3 shows a further breakup of the Child Seats into Forward Facing Child Seats, Rearward Facing Child Seats, Rearward Facing Infant Seats, and out-of-position Forward Facing Child Seats. Table 4 shows a different type of distribution; one based on the environmental conditions inside the vehicle.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 2</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Distribution of Main Training Subjects</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="35pt" align="left"> </colspec> <colspec colname="1" colwidth="56pt" align="left"> </colspec> <colspec colname="2" colwidth="126pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Occupancy</td>
                <td class="description-td">Representation</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Empty Seat</td>
                <td class="description-td">10%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Human Occupant</td>
                <td class="description-td">32%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Child Seat</td>
                <td class="description-td">58%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 3</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Child Seat Distribution</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="133pt" align="left"> </colspec> <colspec colname="2" colwidth="70pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Child Seat Configuration</td>
                <td class="description-td">Representation</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Forward Facing Child Seat</td>
                <td class="description-td">40%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Forward Facing Child Seat Out-of-Position</td>
                <td class="description-td">4%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Rearward Facing Child Seat</td>
                <td class="description-td">27%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Rearward Facing Infant Seat</td>
                <td class="description-td">29%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 4</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Distribution of Environmental Conditions</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="91pt" align="left"> </colspec> <colspec colname="2" colwidth="98pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Environmental Condition</td>
                <td class="description-td">Representation</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Ambient</td>
                <td class="description-td">56%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Static Heat (Solar Lamp)</td>
                <td class="description-td">25%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Dynamic Heat (Car Heat)</td>
                <td class="description-td">13%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Dynamic Cooling (Car A C)</td>
                <td class="description-td">6%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>1.2 Independent Test Data Characteristics</p>
    <p>The independent test data is created using the same configurations, subjects, objects, and conditions as used for the training data set. Its makeup and distributions arc therefore the same as those of the training data set.</p>
    <p>1.3 Validation Data Characteristics</p>
    <p>The distribution of the validation data set into its main subsets is shown in Table 5. This distribution is close to that of the training data set. However the human occupants comprised both children (12% of total) as well as adults (27% of total). Table 6 shows the distribution of human subjects. Contrary to the training and independent test data sets, data was collected on children ages 3 and 6 that were not seated in a child restraint of any kind. Table 7 shows the distribution of the child seats used. On the other hand, no data was collected on Forward Facing Child Seats that were out-of-position. The child and infant seats used in this data set are different from those used in the training and independent test data sets. The validation data was collected with varying environmental conditions as shown in Table 8.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 5</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Validation Data Distribution</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="35pt" align="left"> </colspec> <colspec colname="1" colwidth="56pt" align="left"> </colspec> <colspec colname="2" colwidth="126pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Occupancy</td>
                <td class="description-td">Representation</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Empty Seat</td>
                <td class="description-td">8%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Human Occupant</td>
                <td class="description-td">39%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Child Seat</td>
                <td class="description-td">53%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 6</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Human Subject Distribution</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="1" colwidth="84pt" align="left"> </colspec> <colspec colname="2" colwidth="49pt" align="center"> </colspec> <colspec colname="3" colwidth="35pt" align="center"> </colspec> <colspec colname="4" colwidth="49pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td"> </td>
                <td class="description-td">Normally</td>
                <td class="description-td"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Human Occupant</td>
                <td class="description-td">Representation</td>
                <td class="description-td">Seated</td>
                <td class="description-td">Out-of-Position</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Child age 3</td>
                <td class="description-td">15%</td>
                <td class="description-td">50%</td>
                <td class="description-td">50%</td>
              </tr> <tr class="description-tr"> <td class="description-td">Child age 6</td>
                <td class="description-td">15%</td>
                <td class="description-td">50%</td>
                <td class="description-td">50%</td>
              </tr> <tr class="description-tr"> <td class="description-td">Adult 5<sup>th </sup>percentile Female</td>
                <td class="description-td">23%</td>
                <td class="description-td">67%</td>
                <td class="description-td">33%</td>
              </tr> <tr class="description-tr"> <td class="description-td">Adult 50<sup>th </sup>percentile Male</td>
                <td class="description-td">23%</td>
                <td class="description-td">67%</td>
                <td class="description-td">33%</td>
              </tr> <tr class="description-tr"> <td class="description-td">Adult 95<sup>th </sup>percentile Male</td>
                <td class="description-td">23%</td>
                <td class="description-td">67%</td>
                <td class="description-td">33%</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 7</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Child Seat Distribution</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="91pt" align="left"> </colspec> <colspec colname="2" colwidth="98pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Child Seat Configuration</td>
                <td class="description-td">Representation</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Forward Facing Child Seat</td>
                <td class="description-td">11%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Forward Facing Booster Seat</td>
                <td class="description-td">11%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Rearward Facing Child Seat</td>
                <td class="description-td">38%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Rearward Facing Infant Seat</td>
                <td class="description-td">40%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 8</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Distribution of Environmental Conditions</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="119pt" align="left"> </colspec> <colspec colname="2" colwidth="84pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Environmental Condition</td>
                <td class="description-td">Representation</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Ambient</td>
                <td class="description-td">63%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Static Heat (Solar Lamp)</td>
                <td class="description-td">13%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Dynamic Heat (Car Heat)</td>
                <td class="description-td">12%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Dynamic Cooling (Car Air Conditioner)</td>
                <td class="description-td">12%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>3. Network Training</p>
    <p>The baseline network consisted of a four layer back-propagation network with 117 input layer nodes. 20 and 7 nodes respectively in the two hidden layers, and 1 output layer node. The input layer is made up of inputs from four ultrasonic transducers. These were located in the vehicle on the rear quarter panel (A), the A-pillar (B), and the over-head console (C, H). Table 9 shows the number of points, taken from each of these channels that make up one vector.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 9</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Transducer Volume</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="42pt" align="left"> </colspec> <colspec colname="1" colwidth="91pt" align="center"> </colspec> <colspec colname="2" colwidth="84pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Starting Point</td>
                <td class="description-td">End Point</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="7"> <colspec colname="1" colwidth="42pt" align="center"> </colspec> <colspec colname="2" colwidth="28pt" align="center"> </colspec> <colspec colname="3" colwidth="21pt" align="center"> </colspec> <colspec colname="4" colwidth="42pt" align="center"> </colspec> <colspec colname="5" colwidth="28pt" align="center"> </colspec> <colspec colname="6" colwidth="21pt" align="center"> </colspec> <colspec colname="7" colwidth="35pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td"> </td>
                <td class="description-td">Time</td>
                <td class="description-td">Distance</td>
                <td class="description-td"> </td>
                <td class="description-td">Time</td>
                <td class="description-td">Distance</td>
              </tr> <tr class="description-tr"> <td class="description-td">Transducer</td>
                <td class="description-td">Sample</td>
                <td class="description-td">(ms)</td>
                <td class="description-td">(mm)</td>
                <td class="description-td">Sample</td>
                <td class="description-td">(ms)</td>
                <td class="description-td">(mm)</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="7" align="center" rowsep="1" class="description-td" colspan="7"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="7"> <colspec colname="1" colwidth="42pt" align="center"> </colspec> <colspec colname="2" colwidth="28pt" align="center"> </colspec> <colspec colname="3" colwidth="21pt" align="center"> </colspec> <colspec colname="4" colwidth="42pt" align="char" char="."> </colspec> <colspec colname="5" colwidth="28pt" align="center"> </colspec> <colspec colname="6" colwidth="21pt" align="center"> </colspec> <colspec colname="7" colwidth="35pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">A</td>
                <td class="description-td">5</td>
                <td class="description-td">0.83</td>
                <td class="description-td">142</td>
                <td class="description-td">29</td>
                <td class="description-td">4.84</td>
                <td class="description-td">822</td>
              </tr> <tr class="description-tr"> <td class="description-td">B</td>
                <td class="description-td">3</td>
                <td class="description-td">0.50</td>
                <td class="description-td">85</td>
                <td class="description-td">35</td>
                <td class="description-td">5.84</td>
                <td class="description-td">992</td>
              </tr> <tr class="description-tr"> <td class="description-td">C</td>
                <td class="description-td">7</td>
                <td class="description-td">1.17</td>
                <td class="description-td">198</td>
                <td class="description-td">34</td>
                <td class="description-td">5.67</td>
                <td class="description-td">964</td>
              </tr> <tr class="description-tr"> <td class="description-td">H</td>
                <td class="description-td">2</td>
                <td class="description-td">0.33</td>
                <td class="description-td">57</td>
                <td class="description-td">32</td>
                <td class="description-td">5.34</td>
                <td class="description-td">907</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="7" align="center" rowsep="1" class="description-td" colspan="7"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>The artificial neural network is implemented using the NeuralWorks Professional II/Plus software. The method used for training the decision mathematical model was back-propagation with Extended Delta-Bar-Delta learning rule and sigmoid transfer function. The Extended DBD paradigm uses past values of the gradient to infer the local curvature of the error surface. This leads to a learning rule in which every connection has a different learning rate and a different momentum term, both of which are automatically calculated.</p>
    <p>The network was trained using the above-described training and independent test data sets. An optimum (against the independent test set) was found after 3,675,000 training cycles. Each training cycle uses 30 vectors (known as the epoch), randomly, chosen from the 650,000 available training set vectors. Table 10 shows the performance of the baseline network.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 10</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Baseline Network Performance</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="98pt" align="left"> </colspec> <colspec colname="2" colwidth="91pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Self Test Success Rate</td>
                <td class="description-td">95.3%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Independent Test Success Rate</td>
                <td class="description-td">94.5%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Validation Test Success Rate</td>
                <td class="description-td">92.7%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>The network performance has been further analyzed by investigating the success rates against subsets of the independent test set. The success rate against the airbag enable conditions at 94.6% is virtually equal to that against the airbag disable conditions at 94.4%. Table 11 shows the success rates for the various occupancy subsets. Table 12 shows the success rates for the environmental conditions subsets. Although the distribution of this data was not entirely balanced throughout the matrix, it can be concluded that the system performance is not significantly degraded by heat sources.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 11</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Performance per Occupancy Subset</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="21pt" align="left"> </colspec> <colspec colname="1" colwidth="105pt" align="left"> </colspec> <colspec colname="2" colwidth="91pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Occupancy</td>
                <td class="description-td">Independent Test</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Empty Seat</td>
                <td class="description-td">96.1%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Normally Seated Adult</td>
                <td class="description-td">92.1%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Rearward Facing Child/Infant Seat</td>
                <td class="description-td">94.1%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Forward Facing Child Seat</td>
                <td class="description-td">96.9%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Out-of-Position Human/FFCS</td>
                <td class="description-td">93.0%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 12</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Performance per Environmental Conditions Subset</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="112pt" align="left"> </colspec> <colspec colname="2" colwidth="91pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Environmental Condition</td>
                <td class="description-td">Independent Test</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Ambient</td>
                <td class="description-td">95.4%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Long Term Heat (Lamp Heat)</td>
                <td class="description-td">95.2%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Sort Term Heating/Cooling (HVAC)</td>
                <td class="description-td">93.5%</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="OFFSET" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>3.1 Normalization</p>
    <p>Normalization is used to scale the real world data range into a range acceptable for the network training. The NeuralWorks software requires the use of a scaling factor to bring the input data into a range of 0 to 1, inclusive. Several normalization methods have been explored for their effect on the system performance.</p>
    <p>The real world data consists of 12 bit, digitized signals with values between 0 and 4095. FIG. 12 shows a typical raw signal. A raw vector consists of combined sections of four signals.</p>
    <p>The results of the normalization study are summarized in Table 13.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 13</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Normalization Study Results</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="1" colwidth="77pt" align="left"> </colspec> <colspec colname="2" colwidth="35pt" align="center"> </colspec> <colspec colname="3" colwidth="56pt" align="center"> </colspec> <colspec colname="4" colwidth="49pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">Normalization Method</td>
                <td class="description-td">Self Test</td>
                <td class="description-td">Independent Test</td>
                <td class="description-td">Validation Test</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">a. Whole Vector (base)</td>
                <td class="description-td">95.3%</td>
                <td class="description-td">94.5%</td>
                <td class="description-td">92.7%</td>
              </tr> <tr class="description-tr"> <td class="description-td">b. Per Channel</td>
                <td class="description-td">94.9%</td>
                <td class="description-td">93.8%</td>
                <td class="description-td">90.3%</td>
              </tr> <tr class="description-tr"> <td class="description-td">c. Fixed Range [0,4095]</td>
                <td class="description-td">95.6%</td>
                <td class="description-td">90.3%</td>
                <td class="description-td">88.3%</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>A higher performance results from normalizing across the entire vector versus normalizing per channel. This can be explained from the fact that the baseline method retains the information contained in the relative strength of the signal from one transducer compared to another. This information is lost when using the second method.</p>
    <p>Normalization using a fixed range retains the information contained in the relative strength of one vector compared to the next. From this it could be expected that the performance of the network trained with fixed range normalization would increase over that of the baseline method. However, without normalization, the input range is, as a rule, not from zero to the maximum value (see FIG. <b>1</b>). The absolute value of the data at the input layer affects the network weight adjustment (see equations [1] and [2]). During network training, vectors with a smaller input range will affect the weights calculated for each processing element (neuron) differently than vectors that do span the full range.</p>
    <p>
      <maths> <formula-text><i>w</i> <sub>if</sub> <sup>[s]</sup> <i>=l</i>coef<i>e</i> <sub>j</sub> <sup>[s]</sup> <i>x</i> <sub>I</sub> <sup>[s1]</sup>[1]</formula-text> </maths> </p>
    <p>
      <maths> <formula-text> <i>e</i> <sub>j</sub> <sup>[s]</sup> <i>=x</i> <sub>j</sub> <sup>[s]</sup>(1.0<i>x</i> <sub>j</sub> <sup>[s]</sup>)<sub>k</sub>(<i>e</i> <sub>k</sub> <sup>[s+1]</sup> <i>w</i> <sub>kj</sub> <sup>[s+1]</sup>)[2]</formula-text> </maths> </p>
    <p>w<sub>ij</sub> <sup>[s] </sup>is the change in the network weights; lcoef is the learning coefficient, e<sub>j</sub> <sup>[s</sup>] is the local error at neuron j in layer s; x<sub>I</sub> <sup>[s] </sup>is the current output state of neuron j in layer s.</p>
    <p>Variations in the highest and lowest values in the input layer, therefore, have a negative effect on the training of the network. This is reflected in a lower performance against the validation data set.</p>
    <p>A secondary effect of normalization is that it increases the resolution of the signal by stretching it out over the full range of 0 to 1, inclusive. As the network predominantly learns from higher peaks in the signal, this results in better generalization capabilities and therefore in a higher performance.</p>
    <p>It must be concluded that the effects of the fixed range of input values and the increased resolution resulting from the baseline normalization method have a stronger effect on the network training than retaining the information contained in the relative vector strength.</p>
    <p>3.2 Low Threshold Filters</p>
    <p>Not all information contained in the raw signals can be considered useful for network training. Low amplitude echoes are received back from objects on the outskirts of the ultrasonic field that should not be included in the training data. Moreover, low amplitude noise, from various sources, is contained within the signal. This noise shows up strongest where the signal is weak. By using a low threshold filter, the signal to noise ratio of the vectors can be improved before they are used for network training.</p>
    <p>Three cutoff levels were used: 5%, 10%, and 20% of the signal maximum value (4095). The method used, brings the values below the threshold up to the threshold level. Subsequent vector normalization (baseline method) stretches the signal to the full range of [0,1].</p>
    <p>The results of the low threshold filter study are summarized in Table 14.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 14</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Low Threshold Filter Study Results</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="1" colwidth="56pt" align="left"> </colspec> <colspec colname="2" colwidth="42pt" align="center"> </colspec> <colspec colname="3" colwidth="63pt" align="center"> </colspec> <colspec colname="4" colwidth="56pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">Threshold Level</td>
                <td class="description-td">Self Test</td>
                <td class="description-td">Independent Test</td>
                <td class="description-td">Validation Test</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">none (base)</td>
                <td class="description-td">95.3%</td>
                <td class="description-td">94.5%</td>
                <td class="description-td">92.7%</td>
              </tr> <tr class="description-tr"> <td class="description-td">5% of 4095</td>
                <td class="description-td">95.3%</td>
                <td class="description-td">94.4%</td>
                <td class="description-td">91.9%</td>
              </tr> <tr class="description-tr"> <td class="description-td">10% of 4095</td>
                <td class="description-td">95.3%</td>
                <td class="description-td">94.3%</td>
                <td class="description-td">92.5%</td>
              </tr> <tr class="description-tr"> <td class="description-td">20% of 4095</td>
                <td class="description-td">95.1%</td>
                <td class="description-td">94.2%</td>
                <td class="description-td">86.4%</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>The performance of the networks trained with 5% and 10% threshold filter is similar to that of the baseline network. A small performance degradation is observed for the network trained with a 20% threshold filter. From this it is concluded that the noise level is sufficiently low to not affect the network training. At the same time it can be concluded that the lower 10% of the signal can be discarded without affecting the network performance. This allows the definition of demarcation lines on the outskirts of the ultrasonic field where the signal is equal to 10% of the maximum field strength.</p>
    <p>4. Network Types</p>
    <p>The baseline network is a back-propagation type network. Back-propagation is a general-purpose network paradigm that has been successfully used for prediction, classification, system modeling, and filtering as well as many other general types of problems. Back propagation learns by calculating an error between desired and actual output and propagating this error information back to each node in the network. This back-propagate error is used to drive the learning at each node. Some of the advantages of a back-propagation network are that it attempts to minimize the global error and that it can provide a very compact distributed representation of complex data sets. Some of the disadvantages are its slow learning and the irregular boundaries and unexpected classification regions due to the distributed nature of the network and the use of a transfer functions that is unbounded. Some of these disadvantages can be overcome by using a modified back-propagation method such as the Extended Delta-Bar-Delta paradigm. The EDBD algorithm automatically calculates the learning rate and momentum for each connection in the network, which facilitates optimization of the network training.</p>
    <p>Many other network architectures exist that have different characteristics than the baseline network. One of these is the Logicon Projection Network. This type of network combines the advantages of closed boundary networks with those of open boundary networks (to which the back-propagation network belongs). Closed boundary networks are fast learning because they can immediately place prototypes at the input data points and match all input data to these prototypes. Open boundary networks, on the other hand, have the capability to minimize the output error through gradient decent.</p>
    <p>Conclusions</p>
    <p>The baseline artificial neural network trained to a success rate of 92.7% against the validation data set. This network has a four-layer back-propagation architecture and uses the Extended Delta-Bar-Delta learning rule and sigmoid transfer function. Pre-processing comprised vector normalization while post-processing comprised a five consistent decision filter.</p>
    <p>The objects and subjects used for the independent test data were the same as those used for the training data. This may have negatively affected the network's classification generalization abilities.</p>
    <p>The spatial distribution of the independent test data was as wide as that of the training data. This as resulted in a network that can generalize across a large spatial volume. A lighter performance across a smaller volume, located immediately around the peak of the normal distribution, combined with a lower performance on the outskirts of the distribution curve, might be preferable.</p>
    <p>To achieve this, the distribution of the independent test set needs to be a reflection of the normal distribution for the system (a.k.a. native population).</p>
    <p>Modifying the pre-processing method or applying additional pre-processing methods did not show a significant improvement of the performance over that of the baseline network. The baseline normalization method gave the best results as it improves the learning by keeping the input values in a fixed range and increases the signal resolution. The lower threshold study showed that the network learns from the larger peaks in the echo pattern. Pre-processing techniques should be aimed at increasing the signal resolution to bring out these peaks.</p>
    <p>A further study could be performed to investigate combining a lower threshold with fixed range normalization, using a range less than full scale. This would force each vector to include at least one point at the lower threshold value and one value in saturation effectively forcing each vector into a fixed range that can be mapped between 0 and 1, inclusive. This would have the positive effects associated with the baseline normalization, while retaining the information contained in the relative vector strength. Raw vectors points that, as a result of the scaling, would fall outside the range of 0 to 1 would then be mapped to 0 and 1 respectively.</p>
    <p>Post-processing should be used to enhance the network recognition ability with a memory function. The possibilities for such are currently frustrated by the necessity, of one network performing both object classification as well as spatial locating functions. Performing the spatial locating function requires flexibility to rapidly update the system status. Object classification, on the other hand, benefits from decision rigidity to nullify the effect of an occasional pattern that is incorrectly classified by the network</p>
    <heading>APPENDIX 3</heading> <heading>Process For Training an OPS System DROOP Network For a Specific Vehicle</heading> <p>1. Define customer requirements and deliverable</p>
    <p>1.1. Number of zones</p>
    <p>1.2. Number of outputs</p>
    <p>1.3. At risk zone definition</p>
    <p>1.4. Decision definition i.e. empty seat at risk, safe seating, or not critical and undetermined</p>
    <p>1.5. Determine speed of DROOP decision</p>
    <p>2. Develop PERT chart for the program</p>
    <p>3. Determine viable locations for the transducer mounts</p>
    <p>3.1. Manufacturability</p>
    <p>3.2. Repeatability</p>
    <p>3.3. Exposure (not able to damage during vehicle life)</p>
    <p>4. Evaluate location of mount logistics</p>
    <p>4.1. Field dimensions</p>
    <p>4.2. Multipath reflections</p>
    <p>4.3. Transducer Aim</p>
    <p>4.4. Obstructions/Unwanted data</p>
    <p>4.5. Objective of view</p>
    <p>4.6. Primary DROOP transducers requirements</p>
    <p>5. Develop documentation logs for the program (vehicle books)</p>
    <p>6. Determine vehicle training variables</p>
    <p>6.1. Seat track stops</p>
    <p>6.2. Steering wheel stops</p>
    <p>6.3. Seat back angles</p>
    <p>6.4. DROOP transducer blockage during crash</p>
    <p>6.5. Etc . . .</p>
    <p>7. Determine and mark at risk zone in vehicle</p>
    <p>8. Evaluate location physical impediments</p>
    <p>8.1. Room to mount/hide transducers</p>
    <p>8.2. Sufficient hard mounting surfaces</p>
    <p>8.3. Obstructions</p>
    <p>9. Develop matrix for training, independent, validation, and DROOP data sets</p>
    <p>10. Determine necessary equipment needed for data collection</p>
    <p>10.1. Child/booster/infant seats</p>
    <p>10.2. Maps/razors/makeup</p>
    <p>10.3. Etc . . .</p>
    <p>11. Schedule sled tests for initial and final DROOP networks</p>
    <p>12. Design test buck for DROOP</p>
    <p>13. Design test dummy for DROOP testing</p>
    <p>14. Purchase any necessary variables</p>
    <p>14.1. Child/booster/infant seats</p>
    <p>14.2. Maps/razors/makeup</p>
    <p>14.3. Etc . . .</p>
    <p>15. Develop automated controls of vehicle accessories</p>
    <p>15.1. Automatic seat control for variable empty seat</p>
    <p>15.2. Automatic seat back angle control for variable empty seat</p>
    <p>15.3. Automatic window control for variable empty seat</p>
    <p>15.4. Etc . . .</p>
    <p>16. Acquire equipment to build automated controls</p>
    <p>17. Build &amp; install automated controls of vehicle variables</p>
    <p>18. Install data collection aides</p>
    <p>18.1. Thermometers</p>
    <p>18.2. Seat track gauge</p>
    <p>18.3. Seat angle gauge</p>
    <p>18.4. Etc . . .</p>
    <p>19. Install switched and fused wiring for:</p>
    <p>19.1. Transducer pairs</p>
    <p>19.2. Lasers</p>
    <p>19.3. Decision Indicator Lights</p>
    <p>19.4. System box</p>
    <p>19.5. Monitor</p>
    <p>19.6. Power automated control items</p>
    <p>19.7. Thermometers, potentiometers</p>
    <p>19.8. DROOP occupant ranging device</p>
    <p>19.9. DROOP ranging indicator</p>
    <p>19.10. Etc . . .</p>
    <p>20. Write DROOP operating software for OPS system box</p>
    <p>21. Validate DROOP operating software for OPS</p>
    <p>22. Build OPS system control box for the vehicle with special DROOP operating software</p>
    <p>23. Validate &amp; document system control box</p>
    <p>24. Write vehicle specific DROOP data collection software (pollbin)</p>
    <p>25. Write vehicle specific DROOP data evaluation program (picgraph)</p>
    <p>26. Evaluate DROOP data collection software</p>
    <p>27. Evaluate DROOP data evaluation software</p>
    <p>28. Load DROOP data collection software on OPS system box and validate</p>
    <p>29. Load DROOP data evaluation software on OPS system box and validate</p>
    <p>30. Train technicians on DROOP data collection techniques and use of data collection software</p>
    <p>31. Design prototype mounts based on known transducer variables</p>
    <p>32. Prototype mounts</p>
    <p>33. Pre-build mounts</p>
    <p>33.1. Install transducers in mounts</p>
    <p>33.2. Optimize to eliminate crosstalk</p>
    <p>33.3. Obtain desired field</p>
    <p>33.4. Validate performance of DROOP requirements for mounts</p>
    <p>34. Document mounts</p>
    <p>34.1. Polar plots of fields</p>
    <p>34.2. Drawings with all mount dimensions</p>
    <p>34.3. Drawings of transducer location in the mount</p>
    <p>35. Install mounts in the vehicle</p>
    <p>36. Map fields in the vehicle using ATI designed apparatus and specification</p>
    <p>37. Map performance in the vehicle of the DROOP transducer assembly</p>
    <p>38. Determine sensor volume</p>
    <p>39. Document vehicle mounted transducers and fields</p>
    <p>39.1. Mapping per ATI specification</p>
    <p>39.2. Photographs of all fields</p>
    <p>39.3. Drawing and dimensions of installed mounts</p>
    <p>39.4. Document sensor volume</p>
    <p>39.5. Drawing and dimensions of aim &amp; field</p>
    <p>40. Using data collection software and OPS system box collect initial 16 sheets of training, independent, and validation data</p>
    <p>41. Determine initial conditions for training the ANN</p>
    <p>41.1. Normalization method</p>
    <p>41.2. Training via back propagation or ?</p>
    <p>41.3. Weights</p>
    <p>41.4. Etc . . .</p>
    <p>42. Pre-process data</p>
    <p>43. Train an ANN on above data</p>
    <p>44. Develop post processing strategy if necessary</p>
    <p>45. Develop post processing software</p>
    <p>46. Evaluate ANN with validation data and in vehicle analysis</p>
    <p>47. Perform sled tests to confirm initial DROOP results</p>
    <p>48. Document DROOP testing results and performance</p>
    <p>49. Rework mounts and repeat steps 31 through 48 if necessary</p>
    <p>50. Meet with customer and review program</p>
    <p>51. Develop strategy for customer directed outputs</p>
    <p>51.1. Develop strategy for final ANN multiple decision networks if necessary</p>
    <p>51.2. Develop strategy for final ANN multiple layer networks if necessary</p>
    <p>51.3. Develop strategy for DROOP layer/network</p>
    <p>52. Design daily calibration jig</p>
    <p>53. Build daily calibration jig</p>
    <p>54. Develop daily calibration test</p>
    <p>55. Document daily calibration test procedure &amp; jig</p>
    <p>56. Collect daily calibration tests</p>
    <p>57. Document daily calibration test results</p>
    <p>58. Rework vehicle data collection markings for customer directed outputs</p>
    <p>58.1. Multiple zone identifiers for data collection</p>
    <p>59. Schedule subjects for all data sets</p>
    <p>60. Train subjects for data collection procedures</p>
    <p>61. Using DROOP data collection software and OPS system box collect initial 16 sheets of training, independent, and validation data</p>
    <p>62. Collect total amount of vectors deemed necessary by program directives, amount will vary as outputs and complexity of ANN varies</p>
    <p>63. Determine initial conditions for training the ANN</p>
    <p>63.1. Normalization method</p>
    <p>63.2. Training via back propagation or ?</p>
    <p>63.3. Weights</p>
    <p>63.4. Etc . . .</p>
    <p>64. Pre-process data</p>
    <p>65. Train an ANN on above data</p>
    <p>66. Develop post processing strategy</p>
    <p>66.1. Weighting</p>
    <p>66.2. Averaging</p>
    <p>66.3. Etc . . .</p>
    <p>67. Develop post processing software</p>
    <p>68. Evaluate ANN with validation data</p>
    <p>69. Perform in vehicle hole searching and analysis</p>
    <p>70. Perform in vehicle non sled mounted DROOP tests</p>
    <p>71. Determines need for further training or processing</p>
    <p>72. Repeat steps 58 through 71 if necessary</p>
    <p>73. Perform sled tests to confirm initial DROOP results</p>
    <p>74. Document DROOP testing results and performance</p>
    <p>75. Repeat steps 58 through 74 if necessary</p>
    <p>76. Write summary performance report</p>
    <p>77. Presentation of vehicle to the customer</p>
    <p>78. Delivered an OPS equipped vehicle to the customer </p> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00001.png"> <img id="EMI-00001" file="US06397136-20020528-P00001.TIF" img-format="tif" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00001.png" class="patent-full-image" alt="Figure US06397136-20020528-P00001"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00002.png"> <img id="EMI-00002" file="US06397136-20020528-P00002.TIF" img-format="tif" alt="Figure US06397136-20020528-P00002" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00002.png" class="patent-full-image"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00003.png"> <img id="EMI-00003" file="US06397136-20020528-P00003.TIF" img-format="tif" alt="Figure US06397136-20020528-P00003" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00003.png" class="patent-full-image"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00004.png"> <img id="EMI-00004" file="US06397136-20020528-P00004.TIF" img-format="tif" alt="Figure US06397136-20020528-P00004" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00004.png" class="patent-full-image"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00005.png"> <img id="EMI-00005" file="US06397136-20020528-P00005.TIF" img-format="tif" alt="Figure US06397136-20020528-P00005" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00005.png" class="patent-full-image"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00006.png"> <img id="EMI-00006" file="US06397136-20020528-P00006.TIF" img-format="tif" alt="Figure US06397136-20020528-P00006" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00006.png" class="patent-full-image"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00007.png"> <img id="EMI-00007" file="US06397136-20020528-P00007.TIF" img-format="tif" alt="Figure US06397136-20020528-P00007" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00007.png" class="patent-full-image"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00008.png"> <img id="EMI-00008" file="US06397136-20020528-P00008.TIF" img-format="tif" alt="Figure US06397136-20020528-P00008" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00008.png" class="patent-full-image"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00009.png"> <img id="EMI-00009" file="US06397136-20020528-P00009.TIF" img-format="tif" alt="Figure US06397136-20020528-P00009" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00009.png" class="patent-full-image"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00010.png"> <img id="EMI-00010" file="US06397136-20020528-P00010.TIF" img-format="tif" alt="Figure US06397136-20020528-P00010" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00010.png" class="patent-full-image"> </a> </div> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00011.png"> <img id="EMI-00011" file="US06397136-20020528-P00011.TIF" img-format="tif" alt="Figure US06397136-20020528-P00011" src="//patentimages.storage.googleapis.com/US6397136B1/US06397136-20020528-P00011.png" class="patent-full-image"> </a> </div>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3275975">US3275975</a></td><td class="patent-data-table-td patent-date-value">Dec 21, 1964</td><td class="patent-data-table-td patent-date-value">Sep 27, 1966</td><td class="patent-data-table-td ">Cleveland Technical Ct Inc</td><td class="patent-data-table-td ">Ultrasonic detecting means</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4691569">US4691569</a></td><td class="patent-data-table-td patent-date-value">Nov 24, 1986</td><td class="patent-data-table-td patent-date-value">Sep 8, 1987</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Apparatus for observing sound field of ultrasonic wave</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4881270">US4881270</a></td><td class="patent-data-table-td patent-date-value">Oct 28, 1983</td><td class="patent-data-table-td patent-date-value">Nov 14, 1989</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Navy</td><td class="patent-data-table-td ">Automatic classification of images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4906940">US4906940</a></td><td class="patent-data-table-td patent-date-value">Feb 13, 1989</td><td class="patent-data-table-td patent-date-value">Mar 6, 1990</td><td class="patent-data-table-td ">Science Applications International Corporation</td><td class="patent-data-table-td ">Process and apparatus for the automatic detection and extraction of features in images and displays</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5008946">US5008946</a></td><td class="patent-data-table-td patent-date-value">Sep 9, 1988</td><td class="patent-data-table-td patent-date-value">Apr 16, 1991</td><td class="patent-data-table-td ">Aisin Seiki K.K.</td><td class="patent-data-table-td ">System for recognizing image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5031154">US5031154</a></td><td class="patent-data-table-td patent-date-value">Aug 30, 1990</td><td class="patent-data-table-td patent-date-value">Jul 9, 1991</td><td class="patent-data-table-td ">Ricoh Company, Ltd.</td><td class="patent-data-table-td ">Three-dimensional object imaging method and system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5071160">US5071160</a></td><td class="patent-data-table-td patent-date-value">Aug 27, 1990</td><td class="patent-data-table-td patent-date-value">Dec 10, 1991</td><td class="patent-data-table-td ">Automotive Systems Laboratory, Inc.</td><td class="patent-data-table-td ">Vehicle restraint</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5074583">US5074583</a></td><td class="patent-data-table-td patent-date-value">Jul 28, 1989</td><td class="patent-data-table-td patent-date-value">Dec 24, 1991</td><td class="patent-data-table-td ">Mazda Motor Corporation</td><td class="patent-data-table-td ">Air bag system for automobile</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5118134">US5118134</a></td><td class="patent-data-table-td patent-date-value">Dec 14, 1990</td><td class="patent-data-table-td patent-date-value">Jun 2, 1992</td><td class="patent-data-table-td ">Robert Bosch Gmbh</td><td class="patent-data-table-td ">Method and apparatus for protecting motor vehicle occupants</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5181254">US5181254</a></td><td class="patent-data-table-td patent-date-value">Dec 14, 1990</td><td class="patent-data-table-td patent-date-value">Jan 19, 1993</td><td class="patent-data-table-td ">Westinghouse Electric Corp.</td><td class="patent-data-table-td ">Method for automatically identifying targets in sonar images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5214744">US5214744</a></td><td class="patent-data-table-td patent-date-value">Dec 14, 1990</td><td class="patent-data-table-td patent-date-value">May 25, 1993</td><td class="patent-data-table-td ">Westinghouse Electric Corp.</td><td class="patent-data-table-td ">Method and apparatus for automatically identifying targets in sonar images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5235339">US5235339</a></td><td class="patent-data-table-td patent-date-value">Nov 13, 1992</td><td class="patent-data-table-td patent-date-value">Aug 10, 1993</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Navy</td><td class="patent-data-table-td ">Radar target discrimination systems using artificial neural network topology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5298732">US5298732</a></td><td class="patent-data-table-td patent-date-value">Feb 18, 1993</td><td class="patent-data-table-td patent-date-value">Mar 29, 1994</td><td class="patent-data-table-td ">Emee, Inc.</td><td class="patent-data-table-td ">Automatic visor for continuously repositioning a shading object to shade a designated location from a direct radiation source</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5305012">US5305012</a></td><td class="patent-data-table-td patent-date-value">Apr 15, 1992</td><td class="patent-data-table-td patent-date-value">Apr 19, 1994</td><td class="patent-data-table-td ">Reveo, Inc.</td><td class="patent-data-table-td ">Intelligent electro-optical system and method for automatic glare reduction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5330226">US5330226</a></td><td class="patent-data-table-td patent-date-value">Dec 4, 1992</td><td class="patent-data-table-td patent-date-value">Jul 19, 1994</td><td class="patent-data-table-td ">Trw Vehicle Safety Systems Inc.</td><td class="patent-data-table-td ">Method and apparatus for detecting an out of position occupant</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5366241">US5366241</a></td><td class="patent-data-table-td patent-date-value">Sep 30, 1993</td><td class="patent-data-table-td patent-date-value">Nov 22, 1994</td><td class="patent-data-table-td ">Kithil Philip W</td><td class="patent-data-table-td ">Automobile air bag system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5390136">US5390136</a></td><td class="patent-data-table-td patent-date-value">Jun 14, 1993</td><td class="patent-data-table-td patent-date-value">Feb 14, 1995</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Artificial neuron and method of using same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5398185">US5398185</a></td><td class="patent-data-table-td patent-date-value">Jan 28, 1993</td><td class="patent-data-table-td patent-date-value">Mar 14, 1995</td><td class="patent-data-table-td ">Nissan Motor Co., Ltd.</td><td class="patent-data-table-td ">Shock absorbing interior system for vehicle passengers</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5413378">US5413378</a></td><td class="patent-data-table-td patent-date-value">Dec 2, 1993</td><td class="patent-data-table-td patent-date-value">May 9, 1995</td><td class="patent-data-table-td ">Trw Vehicle Safety Systems Inc.</td><td class="patent-data-table-td ">Method and apparatus for controlling an actuatable restraining device in response to discrete control zones</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5454591">US5454591</a></td><td class="patent-data-table-td patent-date-value">Jun 21, 1994</td><td class="patent-data-table-td patent-date-value">Oct 3, 1995</td><td class="patent-data-table-td ">Trw Vehicle Safety Systems Inc.</td><td class="patent-data-table-td ">Method and apparatus for sensing a rearward facing child restraining seat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5482314">US5482314</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 12, 1994</td><td class="patent-data-table-td patent-date-value">Jan 9, 1996</td><td class="patent-data-table-td ">Aerojet General Corporation</td><td class="patent-data-table-td ">Automotive occupant sensor system and method of operation by sensor fusion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5490069">US5490069</a></td><td class="patent-data-table-td patent-date-value">Jan 14, 1994</td><td class="patent-data-table-td patent-date-value">Feb 6, 1996</td><td class="patent-data-table-td ">Automotive Systems Laboratory, Inc.</td><td class="patent-data-table-td ">Multiple-strategy crash discrimination system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5585625">US5585625</a></td><td class="patent-data-table-td patent-date-value">Jan 11, 1995</td><td class="patent-data-table-td patent-date-value">Dec 17, 1996</td><td class="patent-data-table-td ">Temic Telefunken Microelectronic Gmbh</td><td class="patent-data-table-td ">Arrangement for detecting the occupancy of a seat in vehicles and the like</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5602734">US5602734</a></td><td class="patent-data-table-td patent-date-value">Sep 23, 1994</td><td class="patent-data-table-td patent-date-value">Feb 11, 1997</td><td class="patent-data-table-td ">Advanced Safety Concepts, Inc.</td><td class="patent-data-table-td ">Automobile air bag systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5605348">US5605348</a></td><td class="patent-data-table-td patent-date-value">Nov 3, 1993</td><td class="patent-data-table-td patent-date-value">Feb 25, 1997</td><td class="patent-data-table-td ">Trw Vehicle Safety Systems Inc.</td><td class="patent-data-table-td ">Method and apparatus for sensing a rearward facing child seat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5626359">US5626359</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 1995</td><td class="patent-data-table-td patent-date-value">May 6, 1997</td><td class="patent-data-table-td ">Trw Vehicle Safety Systems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for controlling an actuatable restraining device in response to discrete control zones</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5636864">US5636864</a></td><td class="patent-data-table-td patent-date-value">Nov 3, 1995</td><td class="patent-data-table-td patent-date-value">Jun 10, 1997</td><td class="patent-data-table-td ">Kabushiki Kaisha Tokai-Rika-Denki-Seisakusho</td><td class="patent-data-table-td ">Air bag apparatus for a passenger seat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5653462">US5653462</a></td><td class="patent-data-table-td patent-date-value">Jul 21, 1995</td><td class="patent-data-table-td patent-date-value">Aug 5, 1997</td><td class="patent-data-table-td ">Automotive Technologies International, Inc.</td><td class="patent-data-table-td ">Vehicle occupant position and velocity sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5684701">US5684701</a></td><td class="patent-data-table-td patent-date-value">Jun 7, 1995</td><td class="patent-data-table-td patent-date-value">Nov 4, 1997</td><td class="patent-data-table-td ">Automotive Technologies International, Inc.</td><td class="patent-data-table-td ">Method and apparatus for sensing a vehicle crash</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5702123">US5702123</a></td><td class="patent-data-table-td patent-date-value">Mar 7, 1996</td><td class="patent-data-table-td patent-date-value">Dec 30, 1997</td><td class="patent-data-table-td ">Toyota Jidosha Kabushiki Kaisha</td><td class="patent-data-table-td ">Air bag apparatus for passenger seat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5722686">US5722686</a></td><td class="patent-data-table-td patent-date-value">May 16, 1995</td><td class="patent-data-table-td patent-date-value">Mar 3, 1998</td><td class="patent-data-table-td ">Trw Vehicle Safety Systems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for sensing an occupant position using capacitance sensing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5782485">US5782485</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 1994</td><td class="patent-data-table-td patent-date-value">Jul 21, 1998</td><td class="patent-data-table-td ">Sensor Technology Co., Ltd.</td><td class="patent-data-table-td ">Air bag actuating system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5829782">US5829782</a></td><td class="patent-data-table-td patent-date-value">Apr 30, 1996</td><td class="patent-data-table-td patent-date-value">Nov 3, 1998</td><td class="patent-data-table-td ">Automotive Technologies International, Inc.</td><td class="patent-data-table-td ">Vehicle interior identification and monitoring system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5845000">US5845000</a></td><td class="patent-data-table-td patent-date-value">Jun 7, 1995</td><td class="patent-data-table-td patent-date-value">Dec 1, 1998</td><td class="patent-data-table-td ">Automotive Technologies International, Inc.</td><td class="patent-data-table-td ">Optical identification and monitoring system using pattern recognition for use with vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5954360">US5954360</a></td><td class="patent-data-table-td patent-date-value">Sep 18, 1997</td><td class="patent-data-table-td patent-date-value">Sep 21, 1999</td><td class="patent-data-table-td ">Breed Automotive Technology, Inc.</td><td class="patent-data-table-td ">Vehicle occupant sensing apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6007095">US6007095</a></td><td class="patent-data-table-td patent-date-value">Feb 4, 1998</td><td class="patent-data-table-td patent-date-value">Dec 28, 1999</td><td class="patent-data-table-td ">Automotive Systems Laboratory, Inc.</td><td class="patent-data-table-td ">Vehicle occupant position sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6078854">US6078854</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 4, 1998</td><td class="patent-data-table-td patent-date-value">Jun 20, 2000</td><td class="patent-data-table-td ">Automotive Technologies International, Inc.</td><td class="patent-data-table-td ">Apparatus and method for adjusting a vehicle component</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6081757">US6081757</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 14, 1997</td><td class="patent-data-table-td patent-date-value">Jun 27, 2000</td><td class="patent-data-table-td ">Automotive Technologies International, Inc.</td><td class="patent-data-table-td ">Seated-state detecting apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0669227B1?cl=en">EP0669227B1</a></td><td class="patent-data-table-td patent-date-value">Dec 22, 1994</td><td class="patent-data-table-td patent-date-value">Jul 22, 1998</td><td class="patent-data-table-td ">TEMIC TELEFUNKEN microelectronic GmbH</td><td class="patent-data-table-td ">Device for detecting the occupation of a vehicle seat</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Integrated CAE Modeling of Intelligent Restraint Systems, M. Murad et al., SAE Technical Paper Series No. 2000-01-0606, Mar. 6-9, 2000.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6539284">US6539284</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 25, 2001</td><td class="patent-data-table-td patent-date-value">Mar 25, 2003</td><td class="patent-data-table-td ">Axonn Robotics, Llc</td><td class="patent-data-table-td ">Socially interactive autonomous robot</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6542802">US6542802</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 2, 2001</td><td class="patent-data-table-td patent-date-value">Apr 1, 2003</td><td class="patent-data-table-td ">Delphi Technologies, Inc.</td><td class="patent-data-table-td ">Vehicle occupant characterization method with rough road compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6578870">US6578870</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 6, 2001</td><td class="patent-data-table-td patent-date-value">Jun 17, 2003</td><td class="patent-data-table-td ">Siemens Ag</td><td class="patent-data-table-td ">Vehicle occupant weight classification system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6588813">US6588813</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 2, 1999</td><td class="patent-data-table-td patent-date-value">Jul 8, 2003</td><td class="patent-data-table-td ">Valeo Sicurezza Abitacolo S.p.A</td><td class="patent-data-table-td ">Vehicle door handle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6685222">US6685222</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 17, 2002</td><td class="patent-data-table-td patent-date-value">Feb 3, 2004</td><td class="patent-data-table-td ">Siemens Ag</td><td class="patent-data-table-td ">Vehicle occupant weight classification system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6801662">US6801662</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 10, 2000</td><td class="patent-data-table-td patent-date-value">Oct 5, 2004</td><td class="patent-data-table-td ">Hrl Laboratories, Llc</td><td class="patent-data-table-td ">Sensor fusion architecture for vision-based occupant detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6823959">US6823959</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 17, 2002</td><td class="patent-data-table-td patent-date-value">Nov 30, 2004</td><td class="patent-data-table-td ">Siemens Ag</td><td class="patent-data-table-td ">Vehicle occupant weight classification system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6845339">US6845339</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 17, 2002</td><td class="patent-data-table-td patent-date-value">Jan 18, 2005</td><td class="patent-data-table-td ">Siemens Ag</td><td class="patent-data-table-td ">Vehicle occupant weight classification system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6901322">US6901322</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2003</td><td class="patent-data-table-td patent-date-value">May 31, 2005</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Method of predicting an empty seat condition in an occupancy sensing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6925193">US6925193</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 10, 2001</td><td class="patent-data-table-td patent-date-value">Aug 2, 2005</td><td class="patent-data-table-td ">Eaton Corporation</td><td class="patent-data-table-td ">Image processing system for dynamic suppression of airbags using multiple model likelihoods to infer three dimensional information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6975239">US6975239</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2003</td><td class="patent-data-table-td patent-date-value">Dec 13, 2005</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having circuit carrier tray</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6985077">US6985077</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2003</td><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Method of tuning a sensor array for occupancy sensing in a vehicle seat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6994397">US6994397</a></td><td class="patent-data-table-td patent-date-value">May 18, 2004</td><td class="patent-data-table-td patent-date-value">Feb 7, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having sensor assemblies with variable blasing member</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7021707">US7021707</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2003</td><td class="patent-data-table-td patent-date-value">Apr 4, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having a low profile sensor assembly</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7026946">US7026946</a></td><td class="patent-data-table-td patent-date-value">May 16, 2003</td><td class="patent-data-table-td patent-date-value">Apr 11, 2006</td><td class="patent-data-table-td ">Darrel Saunders</td><td class="patent-data-table-td ">Method and apparatus for sensing seat occupancy</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7034670">US7034670</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2003</td><td class="patent-data-table-td patent-date-value">Apr 25, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Method of occupancy classification in a vehicle seat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7034709">US7034709</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2003</td><td class="patent-data-table-td patent-date-value">Apr 25, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system and method of electrically attaching a sensor to an electrical circuit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7035432">US7035432</a></td><td class="patent-data-table-td patent-date-value">Jul 22, 2004</td><td class="patent-data-table-td patent-date-value">Apr 25, 2006</td><td class="patent-data-table-td ">Ronjo Company</td><td class="patent-data-table-td ">Method of monitoring sleeping infant</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7043997">US7043997</a></td><td class="patent-data-table-td patent-date-value">Jul 9, 2003</td><td class="patent-data-table-td patent-date-value">May 16, 2006</td><td class="patent-data-table-td ">Cherry Corporation</td><td class="patent-data-table-td ">Seat for sensing a load</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7046158">US7046158</a></td><td class="patent-data-table-td patent-date-value">Apr 16, 2003</td><td class="patent-data-table-td patent-date-value">May 16, 2006</td><td class="patent-data-table-td ">Darrel Saunders</td><td class="patent-data-table-td ">Method and apparatus for sensing seat occupancy</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7049974">US7049974</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2003</td><td class="patent-data-table-td patent-date-value">May 23, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having sensors with formed terminals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7053759">US7053759</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 2004</td><td class="patent-data-table-td patent-date-value">May 30, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Method of determining an equivalent value for a failed sensor in a vehicle seat having an occupancy sensing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7059029">US7059029</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2003</td><td class="patent-data-table-td patent-date-value">Jun 13, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Method of testing a sensor array incorporated into a vehicle seat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7063382">US7063382</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 2004</td><td class="patent-data-table-td patent-date-value">Jun 20, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle seat assembly having a vehicle occupant sensing system and a seat cushion insert</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7075450">US7075450</a></td><td class="patent-data-table-td patent-date-value">Jul 2, 2004</td><td class="patent-data-table-td patent-date-value">Jul 11, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having discrete wiring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7100980">US7100980</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 2004</td><td class="patent-data-table-td patent-date-value">Sep 5, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle seat assembly having a vehicle occupant sensing system with a biasing pad</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7128370">US7128370</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2003</td><td class="patent-data-table-td patent-date-value">Oct 31, 2006</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle seat assembly having a vehicle occupant sensing system and reinforcing inserts positioned therein</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7151452">US7151452</a></td><td class="patent-data-table-td patent-date-value">Dec 5, 2003</td><td class="patent-data-table-td patent-date-value">Dec 19, 2006</td><td class="patent-data-table-td ">Elesys North America Inc.</td><td class="patent-data-table-td ">Vehicle occupant sensing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7172244">US7172244</a></td><td class="patent-data-table-td patent-date-value">Jul 2, 2004</td><td class="patent-data-table-td patent-date-value">Feb 6, 2007</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle seat assembly having a vehicle occupant sensing system and a seat cushion insert positioned therein</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7185916">US7185916</a></td><td class="patent-data-table-td patent-date-value">Jan 14, 2004</td><td class="patent-data-table-td patent-date-value">Mar 6, 2007</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle seat assembly having a field effect sensor for detecting seat position</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7200475">US7200475</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 28, 2005</td><td class="patent-data-table-td patent-date-value">Apr 3, 2007</td><td class="patent-data-table-td ">Sartorius Ag</td><td class="patent-data-table-td ">Methods and devices for identifying the type of occupancy of a supporting surface</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7225067">US7225067</a></td><td class="patent-data-table-td patent-date-value">Jul 2, 2004</td><td class="patent-data-table-td patent-date-value">May 29, 2007</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system for a vehicle seat assembly and method of operating the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7239724">US7239724</a></td><td class="patent-data-table-td patent-date-value">Jan 31, 2006</td><td class="patent-data-table-td patent-date-value">Jul 3, 2007</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Security identification system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7258398">US7258398</a></td><td class="patent-data-table-td patent-date-value">Jul 26, 2004</td><td class="patent-data-table-td patent-date-value">Aug 21, 2007</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having an upper slide member with an emitter interference member</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7292027">US7292027</a></td><td class="patent-data-table-td patent-date-value">May 27, 2005</td><td class="patent-data-table-td patent-date-value">Nov 6, 2007</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having sensor assemblies with variable biasing member</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7365278">US7365278</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 2005</td><td class="patent-data-table-td patent-date-value">Apr 29, 2008</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having a contamination barrier member</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7402769">US7402769</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 2005</td><td class="patent-data-table-td patent-date-value">Jul 22, 2008</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having a retention member for a biasing member</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7405370">US7405370</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 2005</td><td class="patent-data-table-td patent-date-value">Jul 29, 2008</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having enclosed sensor assembly</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7428942">US7428942</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 2005</td><td class="patent-data-table-td patent-date-value">Sep 30, 2008</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having guiding ribs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7446668">US7446668</a></td><td class="patent-data-table-td patent-date-value">May 27, 2005</td><td class="patent-data-table-td patent-date-value">Nov 4, 2008</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having a low profile sensor assembly</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7464960">US7464960</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 30, 2004</td><td class="patent-data-table-td patent-date-value">Dec 16, 2008</td><td class="patent-data-table-td ">Continental Automotive Systems Us, Inc.</td><td class="patent-data-table-td ">Vehicle occupant weight classification system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7518073">US7518073</a></td><td class="patent-data-table-td patent-date-value">Jul 30, 2007</td><td class="patent-data-table-td patent-date-value">Apr 14, 2009</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Vehicle occupant sensing system having enclosed sensor assembly</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7620521">US7620521</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 26, 2007</td><td class="patent-data-table-td patent-date-value">Nov 17, 2009</td><td class="patent-data-table-td ">Automotive Technologies International, Inc.</td><td class="patent-data-table-td ">Dynamic weight sensing and classification of vehicular occupants</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7656169">US7656169</a></td><td class="patent-data-table-td patent-date-value">Feb 6, 2007</td><td class="patent-data-table-td patent-date-value">Feb 2, 2010</td><td class="patent-data-table-td ">Iee International Electronics &amp; Engineering S.A.</td><td class="patent-data-table-td ">Capacitive occupant detection system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7660437">US7660437</a></td><td class="patent-data-table-td patent-date-value">Feb 28, 2008</td><td class="patent-data-table-td patent-date-value">Feb 9, 2010</td><td class="patent-data-table-td ">Automotive Technologies International, Inc.</td><td class="patent-data-table-td ">Neural network systems for vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7995816">US7995816</a></td><td class="patent-data-table-td patent-date-value">Sep 24, 2007</td><td class="patent-data-table-td patent-date-value">Aug 9, 2011</td><td class="patent-data-table-td ">Baxter International Inc.</td><td class="patent-data-table-td ">Detecting access disconnect by pattern recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8016319">US8016319</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 30, 2008</td><td class="patent-data-table-td patent-date-value">Sep 13, 2011</td><td class="patent-data-table-td ">Siemens Ag</td><td class="patent-data-table-td ">Vehicle occupant weight classification system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8041482">US8041482</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 8, 2005</td><td class="patent-data-table-td patent-date-value">Oct 18, 2011</td><td class="patent-data-table-td ">Iee International Electronics &amp; Engineering S.A.</td><td class="patent-data-table-td ">Seat sensor system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8384399">US8384399</a></td><td class="patent-data-table-td patent-date-value">Aug 28, 2008</td><td class="patent-data-table-td patent-date-value">Feb 26, 2013</td><td class="patent-data-table-td ">Infineon Technologies Ag</td><td class="patent-data-table-td ">System including capacitively coupled electrodes and circuits in a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100191390">US20100191390</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 12, 2009</td><td class="patent-data-table-td patent-date-value">Jul 29, 2010</td><td class="patent-data-table-td ">Delphi Technologies, Inc.</td><td class="patent-data-table-td ">System and method for detecting the occupancy of a vehicle seat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110190980">US20110190980</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 4, 2010</td><td class="patent-data-table-td patent-date-value">Aug 4, 2011</td><td class="patent-data-table-td ">Delphi Technologies, Inc.</td><td class="patent-data-table-td ">Occupant detection system and method</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc701/defs701.htm&usg=AFQjCNFn25anNrI7_vY4MNK7_80zsoxwdA#C701S045000">701/45</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc180/defs180.htm&usg=AFQjCNHZg-Ul65eGSU8e-WT0LhK16OU_UA#C180S273000">180/273</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc280/defs280.htm&usg=AFQjCNGOp0FpLfQzL6wFcAzm3xewzXuCMQ#C280S735000">280/735</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01V0003080000">G01V3/08</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01V0003120000">G01V3/12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01V0001000000">G01V1/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=B60N0002440000">B60N2/44</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=B60R0021160000">B60R21/16</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01S0015080000">G01S15/08</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=B60R0021010000">B60R21/01</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01S0015040000">G01S15/04</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01S0015420000">G01S15/42</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=B60R0021015000">B60R21/015</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01S0015880000">G01S15/88</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00362">G06K9/00362</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=B60R2021/01558">B60R2021/01558</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G01S15/88">G01S15/88</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G01S15/04">G01S15/04</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=B60R2021/01554">B60R2021/01554</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=B60R21/015">B60R21/015</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=B60R2021/0157">B60R2021/0157</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=B60R2021/01529">B60R2021/01529</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=B60R2021/01537">B60R2021/01537</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=B60R2021/01516">B60R2021/01516</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=B60R2021/01533">B60R2021/01533</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=vf1ZBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G01S15/42">G01S15/42</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G01S15/04</span>, <span class="nested-value">G01S15/42</span>, <span class="nested-value">B60R21/015</span>, <span class="nested-value">G06K9/00H</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">FP</td><td class="patent-data-table-td ">Expired due to failure to pay maintenance fee</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20140528</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 28, 2014</td><td class="patent-data-table-td ">LAPS</td><td class="patent-data-table-td ">Lapse for failure to pay maintenance fees</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 3, 2014</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 24, 2012</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1-3, 6-11, 16, 17, 22-38, 42-57 AND 66-70 ARE CANCELLED. CLAIMS 4 AND 13 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 5, 12, 14, 15, 18-21, 39-41 AND 58-65 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 10, 2010</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 10, 2010</td><td class="patent-data-table-td ">SULP</td><td class="patent-data-table-td ">Surcharge for late payment</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 7, 2010</td><td class="patent-data-table-td ">PRDP</td><td class="patent-data-table-td ">Patent reinstated due to the acceptance of a late maintenance fee</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100610</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 4, 2010</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 16, 2007</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20070906</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 21, 2005</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 29, 1999</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AUTOMOTIVE TECHNOLOGIES INTERNATIONAL, INC., NEW J</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BREED, DAVID S.;JOHNSON, WENDELL;DUVALL, WILBUR E.;AND OTHERS;REEL/FRAME:010484/0588;SIGNING DATES FROM 19991028 TO 19991117</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AUTOMOTIVE TECHNOLOGIES INTERNATIONAL, INC. P.O. B</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U01wCb6Fue4SbvTuW6iL0KNG6i8_g\u0026id=vf1ZBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0evxWoonu5YBvR8SXSYKgShVw5BA\u0026id=vf1ZBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1HiaN9Q74AlrqQLGEPdoDVH7vPQA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/System_for_determining_the_occupancy_sta.pdf?id=vf1ZBAABERAJ\u0026output=pdf\u0026sig=ACfU3U0sHKSFY9SArXwU0zR2j_eQCd12Zw"},"sample_url":"http://www.google.com/patents/reader?id=vf1ZBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>