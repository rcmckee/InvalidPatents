<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6034652 - Attention manager for occupying the peripheral attention of a person in the ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Attention manager for occupying the peripheral attention of a person in the vicinity of a display device"><meta name="DC.contributor" content="Paul A. Freiberger" scheme="inventor"><meta name="DC.contributor" content="Golan Levin" scheme="inventor"><meta name="DC.contributor" content="David P. Reed" scheme="inventor"><meta name="DC.contributor" content="Marc E. Davis" scheme="inventor"><meta name="DC.contributor" content="Neal A. Bhadkamkar" scheme="inventor"><meta name="DC.contributor" content="Philippe P. Piernot" scheme="inventor"><meta name="DC.contributor" content="Todd A. Agulnick" scheme="inventor"><meta name="DC.contributor" content="Sally N. Rosenthal" scheme="inventor"><meta name="DC.contributor" content="Giles N. Goodhead" scheme="inventor"><meta name="DC.contributor" content="Interval Research Corporation" scheme="assignee"><meta name="DC.date" content="1996-3-22" scheme="dateSubmitted"><meta name="DC.description" content="An attention manager presents information to a person in the vicinity of a display device in a manner that engages at least the peripheral attention of the person. The information is embodied by one or more sets of content data (e.g., video or audio data). Each set of content data is formulated by a content provider and made available for use by content display systems. Upon appropriate activation, each content display system displays images corresponding to the sets of content data in accordance with predetermined scheduling information. The attention manager makes use of &quot;unused capacity&quot; of the display device and the person&#39;s attention, providing information to the person that the person might not otherwise expend adequate energy to obtain. The attention manager also affords an opportunity to content providers to disseminate their information to people that are interested in receiving such information, enabling the content providers to provide better directed information dissemination, as well as providing access to the previously unused attention capacity of those interested people."><meta name="DC.date" content="2000-3-7" scheme="issued"><meta name="DC.relation" content="US:4845658" scheme="references"><meta name="DC.relation" content="US:5105184" scheme="references"><meta name="DC.relation" content="US:5305195" scheme="references"><meta name="DC.relation" content="US:5347632" scheme="references"><meta name="DC.relation" content="US:5573643" scheme="references"><meta name="DC.relation" content="US:5740549" scheme="references"><meta name="DC.relation" content="US:5768528" scheme="references"><meta name="DC.relation" content="WO:1993019427:A1" scheme="references"><meta name="DC.relation" content="WO:1996030864:A1" scheme="references"><meta name="citation_reference" content="Gomes, Lee, &quot;Upstart&#39;s Internet `TV` Has Microsoft Tuned In&quot;, Wall Street Journal, Aug. 1996."><meta name="citation_reference" content="Gomes, Lee, Upstart s Internet TV Has Microsoft Tuned In , Wall Street Journal, Aug. 1996."><meta name="citation_reference" content="Joan E. Rigdon, &quot;Screen Savers Go Beyond Fish, Flying Toasters,&quot; Wall Street Journal, Feb. 13, 1996."><meta name="citation_reference" content="Joan E. Rigdon, Screen Savers Go Beyond Fish, Flying Toasters, Wall Street Journal , Feb. 13, 1996."><meta name="citation_reference" content="Staff Reporter, &quot;PointCast Inc. Is Testing New Screen-Saver Product,&quot; Wall Street Journal, May 1996."><meta name="citation_reference" content="Staff Reporter, PointCast Inc. Is Testing New Screen Saver Product, Wall Street Journal , May 1996."><meta name="citation_patent_number" content="US:6034652"><meta name="citation_patent_application_number" content="US:08/620,641"><link rel="canonical" href="http://www.google.com/patents/US6034652"/><meta property="og:url" content="http://www.google.com/patents/US6034652"/><meta name="title" content="Patent US6034652 - Attention manager for occupying the peripheral attention of a person in the vicinity of a display device"/><meta name="description" content="An attention manager presents information to a person in the vicinity of a display device in a manner that engages at least the peripheral attention of the person. The information is embodied by one or more sets of content data (e.g., video or audio data). Each set of content data is formulated by a content provider and made available for use by content display systems. Upon appropriate activation, each content display system displays images corresponding to the sets of content data in accordance with predetermined scheduling information. The attention manager makes use of &quot;unused capacity&quot; of the display device and the person&#39;s attention, providing information to the person that the person might not otherwise expend adequate energy to obtain. The attention manager also affords an opportunity to content providers to disseminate their information to people that are interested in receiving such information, enabling the content providers to provide better directed information dissemination, as well as providing access to the previously unused attention capacity of those interested people."/><meta property="og:title" content="Patent US6034652 - Attention manager for occupying the peripheral attention of a person in the vicinity of a display device"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("UlTsU77qOoa7sQTklYLgAQ"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CZE"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("UlTsU77qOoa7sQTklYLgAQ"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CZE"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6034652?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6034652"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=MLNOBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6034652&amp;usg=AFQjCNH9M-wrN308lvvSCZFaxSKVYMreuQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6034652.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6034652.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6034652" style="display:none"><span itemprop="description">An attention manager presents information to a person in the vicinity of a display device in a manner that engages at least the peripheral attention of the person. The information is embodied by one or more sets of content data (e.g., video or audio data). Each set of content data is formulated by a...</span><span itemprop="url">http://www.google.com/patents/US6034652?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6034652 - Attention manager for occupying the peripheral attention of a person in the vicinity of a display device</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6034652 - Attention manager for occupying the peripheral attention of a person in the vicinity of a display device" title="Patent US6034652 - Attention manager for occupying the peripheral attention of a person in the vicinity of a display device"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6034652 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/620,641</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Mar 7, 2000</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Mar 22, 1996</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Mar 22, 1996</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/DE69717796D1">DE69717796D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0888604A1">EP0888604A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0888604B1">EP0888604B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20020003506">US20020003506</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO1997035296A1">WO1997035296A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08620641, </span><span class="patent-bibdata-value">620641, </span><span class="patent-bibdata-value">US 6034652 A, </span><span class="patent-bibdata-value">US 6034652A, </span><span class="patent-bibdata-value">US-A-6034652, </span><span class="patent-bibdata-value">US6034652 A, </span><span class="patent-bibdata-value">US6034652A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Paul+A.+Freiberger%22">Paul A. Freiberger</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Golan+Levin%22">Golan Levin</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22David+P.+Reed%22">David P. Reed</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Marc+E.+Davis%22">Marc E. Davis</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Neal+A.+Bhadkamkar%22">Neal A. Bhadkamkar</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Philippe+P.+Piernot%22">Philippe P. Piernot</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Todd+A.+Agulnick%22">Todd A. Agulnick</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Sally+N.+Rosenthal%22">Sally N. Rosenthal</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Giles+N.+Goodhead%22">Giles N. Goodhead</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Interval+Research+Corporation%22">Interval Research Corporation</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6034652.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6034652.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6034652.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (9),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (6),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (65),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (7),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (10)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=MLNOBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6034652&usg=AFQjCNFz1R8SpZwDQlfeNnaDMyoGXDLpxA">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=MLNOBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6034652&usg=AFQjCNEKtMAXAdsxxObBPLcTL0P8NAKQzg">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=MLNOBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6034652A%26KC%3DA%26FT%3DD&usg=AFQjCNFWBBEVzHa0azLm4RQGBD_WY-0eTA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54572579" lang="EN" load-source="patent-office">Attention manager for occupying the peripheral attention of a person in the vicinity of a display device</invention-title></span><br><span class="patent-number">US 6034652 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA38041228" lang="EN" load-source="patent-office"> <div class="abstract">An attention manager presents information to a person in the vicinity of a display device in a manner that engages at least the peripheral attention of the person. The information is embodied by one or more sets of content data (e.g., video or audio data). Each set of content data is formulated by a content provider and made available for use by content display systems. Upon appropriate activation, each content display system displays images corresponding to the sets of content data in accordance with predetermined scheduling information. The attention manager makes use of "unused capacity" of the display device and the person's attention, providing information to the person that the person might not otherwise expend adequate energy to obtain. The attention manager also affords an opportunity to content providers to disseminate their information to people that are interested in receiving such information, enabling the content providers to provide better directed information dissemination, as well as providing access to the previously unused attention capacity of those interested people.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(8)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6034652-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6034652-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6034652-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6034652-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6034652-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6034652-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6034652-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6034652-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6034652-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6034652-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6034652-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6034652-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6034652-7.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6034652-7.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6034652-8.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6034652-8.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(18)</span></span></div><div class="patent-text"><div mxw-id="PCLM5532464" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>We claim:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A system for engaging the peripheral attention of a person in the vicinity of a display device of an apparatus, comprising:<div class="claim-text">a content display system associated with the display device, the content display system including means for receiving a set of content data and a set of instructions for enabling a display device to selectively display, in an unobtrusive manner that does not distract a user of the apparatus from a primary interaction with the apparatus, an image or images generated from a set of content data, the content display system further including means for using the display device to selectively display the image or images using the set of instructions;</div> <div class="claim-text">a content providing system including means for providing a set of content data to the content display system;</div> <div class="claim-text">means for providing to the content display system a set of instructions for enabling a display device to selectively display an image or images generated from a set of content data;</div> <div class="claim-text">first communication means for enabling communication between the means for providing and the content display system;</div> <div class="claim-text">second communication means for enabling communication between the content providing system and the content display system; and</div> <div class="claim-text">means for auditing the display of sets of content data by the content display system.</div> </div>
    </div>
    </div> <div class="claim"> <div num="2" class="claim">
      <div class="claim-text">2. A system for engaging the peripheral attention of a person in the vicinity of a display device of an apparatus, comprising:<div class="claim-text">means for acquiring a set of content data from a content providing system;</div> <div class="claim-text">means for selectively displaying on the display device, in an unobtrusive manner that does not distract a user of the apparatus from a primary interaction with the apparatus, an image or images generated from the set of content data; and</div> <div class="claim-text">means for detecting an idle period of predetermined duration, wherein the means for selectively displaying displays the image or images automatically after detection of the idle period.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. A system as in claim 2, further comprising means for detecting a predetermined user interaction with the apparatus subsequent to detection of the idle period, wherein occurrence of the predetermined user interaction causes the means for selectively displaying to stop displaying an image or images generated from a set of content data.</div>
    </div>
    </div> <div class="claim"> <div num="4" class="claim">
      <div class="claim-text">4. A system for engaging the peripheral attention of a person in the vicinity of a display device of an apparatus, comprising:<div class="claim-text">means for acquiring a set of content data from a content providing system;</div> <div class="claim-text">means for selectively displaying on the display device, in an unobtrusive manner that does not distract a user of the apparatus from a primary interaction with the apparatus, an image or images generated from the set of content data;</div> <div class="claim-text">means for displaying one or more control options with the display device while the means for selectively displaying is operating;</div> <div class="claim-text">means for selecting a displayed control option; and</div> <div class="claim-text">means for controlling aspects of the operation of the system in accordance with a selected control option.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. A system as in claim 4, wherein:<div class="claim-text">the control option enables the user to request termination of operation of the system; and</div> <div class="claim-text">the means for controlling terminates operation of the system.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. A system as in claim 4, wherein:<div class="claim-text">the means for selectively displaying further comprises means for scheduling the display of an image or images generated from a set of content data;</div> <div class="claim-text">the control option enables the user to request display of a next image or images generated from a next set of content data; and</div> <div class="claim-text">the means for controlling displays the next image.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. A system as in claim 4, wherein:<div class="claim-text">the means for selectively displaying further comprises means for scheduling the display of an image or images generated from a set of content data;</div> <div class="claim-text">the control option enables the user to request display of a previous image generated from a previous set of content data; and</div> <div class="claim-text">the means for controlling displays the previous image.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. A system as in claim 4, wherein:<div class="claim-text">a plurality of sets of content data are acquired by the system;</div> <div class="claim-text">the means for selectively displaying further comprises means for scheduling the display of the image or images generated from the sets of content data;</div> <div class="claim-text">the control option enables the user to remove a set of content data from the schedule; and</div> <div class="claim-text">the means for controlling removes the set of content data from the schedule.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. A system as in claim 4, wherein:<div class="claim-text">a plurality of sets of content data are acquired by the system, at least one of the sets of content data capable of being occasionally updated;</div> <div class="claim-text">the means for selectively displaying further comprises means for scheduling the display of the image or images generated from the sets of content data;</div> <div class="claim-text">the control option enables the user to prevent the display of an image generated from a designated set of content data until the designated set of content data has been updated; and</div> <div class="claim-text">the means for controlling prevents the display of the image generated from the designated set of content data until the designated set of content data has been updated.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. A system as in claim 4, wherein:<div class="claim-text">a plurality of sets of content data are acquired by the system;</div> <div class="claim-text">the means for selectively displaying further comprises means for scheduling the display of the image or images generated from the sets of content data;</div> <div class="claim-text">the control option enables the user to specify a satisfaction level for a currently displayed image from a current set of content data; and</div> <div class="claim-text">the means for controlling revises the schedule in response to the specified satisfaction level.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. A system as in claim 4, wherein:<div class="claim-text">the control option enables the user to establish a link with an information location; and</div> <div class="claim-text">the means for controlling establishes the link with the information location.</div> </div>
    </div>
    </div> <div class="claim"> <div num="12" class="claim">
      <div class="claim-text">12. A method for engaging the peripheral attention of a person in the vicinity of a display device of an apparatus, comprising the steps of:<div class="claim-text">acquiring a set of content data from a content providing system;</div> <div class="claim-text">detecting an idle period of predetermined duration; and</div> <div class="claim-text">selectively displaying on the display device, in an unobtrusive manner that does not distract a user of the apparatus from a primary interaction with the apparatus, an image or images generated from the set of content data, wherein the step of selectively displaying further comprises the step of displaying the image or images automatically after detection of the idle period.</div> </div>
    </div>
    </div> <div class="claim"> <div num="13" class="claim">
      <div class="claim-text">13. A computer readable medium encoded with one or more computer programs for enabling acquisition of a set of content data and display of an image or images generated from the set of content data on a display device during operation of an attention manager, comprising:<div class="claim-text">acquisition instructions for enabling acquisition of a set of content data from a specified information source;</div> <div class="claim-text">user interface installation instructions for enabling provision of a user interface that allows a person to request the set of content data from the specified information source;</div> <div class="claim-text">content data scheduling instructions for providing temporal constraints on the display of the image or images generated from the set of content data, the content data scheduling instructions further comprising duration instructions for enabling specification of the duration of time that the image or images generated from a set of content data can be displayed, wherein the duration instructions specify a duration of time that is dependent upon the particular time at which the image or images generated from a set of content data are displayed after the attention manager begins operating; and</div> <div class="claim-text">display instructions for enabling display of the image or images generated from the set of content data.</div> </div>
    </div>
    </div> <div class="claim"> <div num="14" class="claim">
      <div class="claim-text">14. A computer readable medium encoded with one or more computer programs for enabling acquisition of a set of content data and display of an image or images generated from the set of content data on a display device during operation of an attention manager, comprising:<div class="claim-text">acquisition instructions for enabling acquisition of a set of content data from a specified information source;</div> <div class="claim-text">user interface installation instructions for enabling provision of a user interface that allows a person to request the set of content data from the specified information source;</div> <div class="claim-text">content data scheduling instructions for providing temporal constraints on the display of the image or images generated from the set of content data, the content data scheduling instructions further comprising duration instructions for enabling specification of the duration of time that the image or images generated from a set of content data can be displayed, wherein the duration instructions specify a duration of time that is dependent upon the number of previous times that the image or images have been displayed during a continuous operation of the attention manager; and</div> <div class="claim-text">display instructions for enabling display of the image or images generated from the set of content data.</div> </div>
    </div>
    </div> <div class="claim"> <div num="15" class="claim">
      <div class="claim-text">15. A computer readable medium encoded with one or more computer programs for enabling acquisition of a set of content data and display of an image or images generated from the set of content data on a display device during operation of an attention manager, comprising:<div class="claim-text">acquisition instructions for enabling acquisition of a set of content data from a specified information source;</div> <div class="claim-text">user interface installation instructions for enabling provision of a user interface that allows a person to request the set of content data from the specified information source;</div> <div class="claim-text">content data scheduling instructions for providing temporal constraints on the display of the image or images generated from the set of content data, wherein the content data scheduling instructions further comprise sequencing instructions that specify an order in which the images generated from a set of content data are displayed; and</div> <div class="claim-text">display instructions for enabling display of the image or images generated from the set of content data.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. A computer readable medium as in claim 15, wherein the sequencing instructions further specify the duration of the display of each image or images generated from each set of content data.</div>
    </div>
    </div> <div class="claim"> <div num="17" class="claim">
      <div class="claim-text">17. A computer readable medium encoded with one or more computer programs for enabling acquisition of a set of content data and display of an image or images generated from the set of content data on a display device during operation of an attention manager, comprising:<div class="claim-text">acquisition instructions for enabling acquisition of a set of content data from a specified information source;</div> <div class="claim-text">user interface installation instructions for enabling provision of a user interface that allows a person to request the set of content data from the specified information source;</div> <div class="claim-text">content data scheduling instructions for providing temporal constraints on the display of the image or images generated from the set of content data, wherein the content data scheduling instructions further comprise saturation instructions that constrain the number of times that the image or images generated from a set of content data can be displayed; and</div> <div class="claim-text">display instructions for enabling display of the image or images generated from the set of content data.</div> </div>
    </div>
    </div> <div class="claim"> <div num="18" class="claim">
      <div class="claim-text">18. A computer readable medium, for use by a content display system, encoded with one or more computer programs for enabling acquisition of a set of content data and display of an image or images generated from the set of content data on a display device during operation of an attention manager, comprising:<div class="claim-text">acquisition instructions for enabling acquisition of a set of content data from a specified information source;</div> <div class="claim-text">user interface installation instructions for enabling provision of a user interface that allows a person to request the set of content data from the specified information source;</div> <div class="claim-text">content data scheduling instructions for providing temporal constraints on the display of the image or images generated from the set of content data;</div> <div class="claim-text">display instructions for enabling display of the image or images generated from the set of content data;</div> <div class="claim-text">content data update instructions for enabling acquisition of an updated set of content data from an information source that corresponds to a previously acquired set of content data;</div> <div class="claim-text">operating instructions for beginning, managing and terminating the display on the display device of an image generated from a set of content data;</div> <div class="claim-text">content display system scheduling instructions for scheduling the display of the image or images on the display device;</div> <div class="claim-text">installation instructions for installing the operating instructions and content display system scheduling instructions on the content display system; and</div> <div class="claim-text">audit instructions for monitoring usage of the content display system to selectively display an image or images generated from a set of content data.</div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67439446" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>This invention relates to the engagement of the peripheral attention of a person in the vicinity of a display device such as the display monitor of a computer.</p>
    <p>2. Related Art</p>
    <p>Information providers of all sorts have an interest in presenting their information to information consumers and, in particular, to information consumers who may, or do, have an interest in the particular information provided by the particular information provider. At the same time, information consumers have an interest in accessing a wide variety of information and, in particular, information in which the information consumer may, or does, have an interest. Given the extent to which computers now permeate society, and particularly in view of the escalation of networking of those computers in various ways, there is increasing recognition of the capability of using computers, and, in particular, computers (and other devices) that are interconnected in a network, as an information dissemination tool that can satisfy the interests of both information providers and information consumers.</p>
    <p>For example, information providers have used public computer networks (e.g., the Internet) and private computer networks (e.g., commercial online services such as America Online, Prodigy and CompuServe) to disseminate their information. This information can be displayed to a computer user having access to the network directly in response to a request from the user or indirectly (i.e., without request by the user) as a result of another action taken by the user. While these methods of information dissemination and acquisition can be effective, they do not exhaust the possibilities.</p>
    <p>In a different vein, historically, computers have frequently included screen saving mechanisms ("screen savers") intended to prevent the phosphors of a computer display screen from burning out when the same image remains on the screen for a long period of time, such as might occur during a long period of inactivity while the computer is operating. As computer display screen technology has progressed, the use of screen savers to preserve the display screen has become increasingly unnecessary. However, the use of screen savers has continued--even proliferated--likely due to the aesthetic or entertainment value provided by the imagery of many screen savers. Further, the use of "wallpaper" (i.e., a pattern generated in the background portions on a computer display screen) in computer display screens has also arisen, largely one would suspect because of the aesthetic or entertainment value of the wallpaper imagery. While the use of screen savers and wallpaper with computer displays appeals to many users because of the imagery they present to the user, screen savers and wallpaper have not heretofore been used as a means to convey information from information providers to computer users. Further, screen savers and wallpaper have previously been implemented as relatively simple, self-contained computer application programs that are not typically integrated with other application programs or other aspects of computer operation. In particular, screen saver and wallpaper application programs have not been constructed to enable retrieval of display content from a remote location via a computer network.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>An attention manager according to the invention presents information to a person in the vicinity of a display device in a manner that engages the peripheral attention of the person. Often, the display device is part of a broader apparatus (e.g., the display device of a computer). Generally, the attention manager makes use of "unused capacity" of the display device. For example, the information can be presented to the person while the apparatus (e.g., computer) is operating, but during inactive periods (i.e., when a user is not engaged in an intensive interaction with the apparatus). Or, the information can be presented to the person during active periods (i.e., when a user is engaged in an intensive interaction with the apparatus), but in an unobtrusive manner that does not distract the user from the primary interaction with the apparatus (e.g., the information is presented in areas of a display screen that are not used by displayed information associated with the primary interaction with the apparatus).</p>
    <p>The information is embodied as one or more sets of content data. The sets of content data represent sensory data; typically, the sensory data is either video or audio data. Each set of content data is formulated by a content provider and made available for use by an attention manager according to the invention. Each content providing system can provide more than one set of content data. The content providing systems provide user interface tools that enable a particular set of content data to be requested. Once one or more sets of content data has been acquired, a content display system integrates scheduling information for all sets of content data to produce a schedule according to which an image or images corresponding to the sets of content data are displayed on a display device associated with the content display system.</p>
    <p>A set or sets of instructions for enabling a display device to selectively display an image or images generated from a set of content data are also made available for use by the content display systems. Typically, the instructions enable images generated from content data to be displayed automatically, without user intervention, in a predetermined manner, thereby enhancing the capability of the invention to occupy the user's peripheral attention. Further, the attention manager can be implemented so that the instructions are automatically acquired (or updated, if necessary) each time a user requests acquisition of a set of content data, thereby making acquisition of the instructions transparent to the user of the attention manager and thus increasing the ease of use for the user. The instructions can include application instructions, control instructions and content data acquisition instructions. The application instructions can include operating instructions for beginning, managing, and terminating operation of the attention manager on a content display system, content display system scheduling instructions for scheduling the display of content data on a content display system, and installation instructions for installing the operating instructions and content display system scheduling instructions on a content display system. The control instructions can include display instructions for enabling generation of images from the content data on a particular type of display device or from a particular type of content data, and content data scheduling instructions for enabling temporal control of the display of the images generated from a set or sets of content data. The content data acquisition instructions can include acquisition instructions for enabling the acquisition of a set of content data, content data update instructions for enabling update of a previously acquired set of content data, and user interface installation instructions for enabling provision of a user interface that allows a person to request a set of content data from a content providing system. Each of the application, control and content data acquisition instructions could be acquired from a content provider, or any one or all of the sets of instructions could be acquired from an application manager that provides generic sets of instructions that can be tailored as necessary or desirable by a content provider. Additionally, audit instructions can be made available that enable monitoring of usage of the attention manager.</p>
    <p>According to one aspect of the invention, an attention manager engages the peripheral attention of a person in the vicinity of a display device of an apparatus by acquiring one or more sets of content data from a content providing system and selectively displaying on the display device, in an unobtrusive manner that does not distract a user of the apparatus from a primary interaction with the apparatus, an image or images generated from the set of content data. According to a further aspect of the invention, the selective display of the image or images begins automatically after detection of an idle period of predetermined duration (the "screen saver embodiment"). This aspect can be implemented, for example, using the screen saver API (application program interface) that is part of many operating systems. According to another further aspect of the invention, the selective display of an image or images occurs while the user is engaged in a primary interaction with the apparatus, which primary interaction can result in the display of an image or images in addition to the image or images generated from the set of content data (the "wallpaper embodiment"). If multitasking is allowed by the apparatus (e.g., by the computer operating system) with which the attention manager is used, the attention manager can be implemented so that, when operation of the attention manager is terminated, the user is returned to the state of the primary interaction that existed when operation of the attention manager began. The attention manager can also be implemented so that, during operation of the attention manager, the user is presented with a number of options regarding further use of the attention manager. In particular, one of the options can allow additional information to be obtained that is related to the set of content data for which an image is being displayed. Where the attention manager is implemented as part of a network, this option can enable information to be obtained from a remote information source via the network. Another option that can be implemented allows a user to specify a satisfaction level for a set of content data from which an image or images is being displayed, thereby affecting the frequency with which that set of content data is used by the attention manager in the future.</p>
    <p>According to another aspect of the invention, an attention manager that engages the peripheral attention of a person in the vicinity of a display device includes a content display system associated with the display device, a mechanism that can communicate with the content display system via a first communications mechanism to provide to the content display system a set of instructions for enabling the display device to selectively display content data, and a content providing system that can communicate with the content display device via a second communications mechanism to provide a set of content data to the content display system. The content display system uses the provided set of instructions to selectively display on the display device an image or images generated from the provided content data. The attention manager according to this aspect of the invention can further include an application management system that can communicate via a third communications mechanism to provide to either the content providing system or the content display system one or more sets of instructions for enabling a display device to selectively display an image or images generated from a set of content data. In the former case, the content providing system can, in turn, communicate with the content display system to provide the one or more sets of instructions. The attention manager according to this aspect of the invention can be implemented, for example, using existing computer networks of information sources, such as the Internet (in particular, the World Wide Web) or commercial online services, advantageously making use of pre-existing hardware and software for enabling communication over those networks. Typically, though not necessarily, an attention manager according to this aspect of the invention will include multiple content display systems and multiple content providing systems. The content providing systems will each be capable of providing one or more sets of content data, so that, overall, there will be multiple available sets of content data which can be of different types. There can also be multiple sets of instructions for enabling a display device to selectively display an image or images generated from a set of content data, which sets of instructions may be tailored to display images from particular types of content data or to display content data using a particular display device.</p>
    <p>According to yet another aspect of the invention, a computer readable medium can be encoded with one or more computer programs for enabling acquisition of a set of content data and display of an image or images generated from the set of content data on a display device during operation of an attention manager. The instructions of the computer program can include: i) acquisition instructions for enabling acquisition of a set of content data from a specified information source, ii) user interface installation instructions for enabling provision of a user interface that allows a person to request the set of content data from the specified information source, iii) content data scheduling instructions for providing temporal constraints on the display of the image or images generated from the set of content data, and iv) display instructions for enabling display of the image or images generated from the set of content data. The computer readable medium can also further include content data update instructions for enabling acquisition of an updated set of content data from an information source that corresponds to a previously acquired set of content data, the content data up date instructions specifying where and when to obtain the updated set of content data. The content data scheduling instructions can specify, for example, the duration of time that the image or images generated from a set of content data can be displayed, an order in which the images generated from a plurality of sets of content data are displayed, a time or times at which the image or images generated from a set of content data can or cannot be displayed, and/or constraint on the number of times that the image or images generated from a set of content data can be displayed. The display instructions can be tailored to enable display of the image or images generated from a set of content data on a display device of a particular type, or display of an image or images generated from a set of content data of a particular type.</p>
    <p>According to still another aspect of the invention, a computer readable medium can be encoded with one or more computer programs for enabling a content display system to selectively display on a display device, in an unobtrusive manner that does not distract a person from a primary interaction with an apparatus associated with the display device, an image generated from a set of content data. The instructions of the computer program can include: i) operating instructions for beginning, managing and terminating the selective display of the image on the display device, ii) content display system scheduling instructions for scheduling the display of the image on the display device, and iii) installation instructions for installing the operating instructions and content display system scheduling instructions on a content display system. The computer readable medium can also further include audit instructions for monitoring usage of the content display system to selectively display an image generated from a set of content data.</p>
    <p>The attention manager according to the invention is a new and useful mechanism for providing information to users of the attention manager. The attention manager provides information in which a user has expressed an interest and, importantly, information that the user might not otherwise expend adequate energy to obtain. The user can tailor the information provided by interacting with specific information sources to indicate interest in particular information provided by a specific information source while the user is perusing other information from that information source (as opposed to giving a general indication of interest in information on a particular subject or of a particular kind, from which indication information that matches the indicated interest is automatically provided from various information sources). The user can also choose information from a wide variety of information sources; in particular, when the attention manager is implemented using a network (e.g., the Internet), the user can acquire information from a wide variety of remote information sources. Additionally, the information is presented to the user in a manner that uses portions of the user's attention capacity that may otherwise be unused or filled with extraneous information.</p>
    <p>The attention manager according to the invention also provides a new and useful information dissemination tool to content providers. The attention manager affords an opportunity to content providers to disseminate their information to users that are interested in receiving such information, enabling the content providers to provide better directed information dissemination. Moreover, the attention manager provides access to the previously unused attention capacity of those interested users. Additionally, the attention manager allows content providers to tailor particular aspects of the attention manager as desired by the content provider, such as the acquisition of updated sets of the content provider's content data (e.g., the frequency of such updates), the display scheduling and manner of display of the content provider's content data, and the user interface that enables users to specify acquisition of the content provider's content data.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is a flow chart of a method that implements an attention manager according to an embodiment of the invention.</p>
    <p>FIG. 2 is a block diagram of a system for implementing an attention manager according to an embodiment of the invention.</p>
    <p>FIGS. 3A, 3B and 3C are schematic diagrams illustrating the functional components of an application manager, a content providing system and a content display system, respectively, according to an embodiment of the invention.</p>
    <p>FIG. 4 is a flow chart of a method, according to an embodiment of the invention, for acquiring and updating sets of content data.</p>
    <p>FIGS. 5 to 5C together are a flow chart of a method that implements an attention manager according to another embodiment of the invention.</p>
    <p>FIG. 6 illustrates a computer display screen including a user interface, according to one embodiment of the invention, that can be used to enable a user to specify a control option.</p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading> <p>According to the invention, an attention manager presents information to a person in the vicinity of a display device (or devices) in a manner that engages at least the peripheral attention of the person. "Display device", as used herein, encompasses any device that presents sensory stimulus to the person and includes, for example, computer video display devices, televisions and audio speakers. Further, here, "in the vicinity of" means any location with respect to the display device from which the person can perceive the information being presented. For example, if the information is being presented in a visual form, then "in the vicinity of" means any location from which the person can see the information. Or, if the information is being presented in an aural form, then "in the vicinity of" means any location from which the person can hear the information.</p>
    <p>Often, the display device is part of a broader apparatus that can be utilized by a user for a primary interaction that is unrelated to the attention manager. (However, the attention manager can also be used with a display device that is not part of a broader apparatus, the user engaging in a primary interaction with the display device.) For example, the display device can be part of a computer that can be used to implement any of a number of application programs (e.g., word processing programs, computer games, spreadsheets, etc.). The person whose attention is engaged by the attention manager can be the user or another person in the vicinity of the display device. In one embodiment of the invention, the information is presented by the attention manager while a primary interaction is ongoing, but during inactive periods (i.e., when the user is not engaged in an intensive interaction with the apparatus). In another embodiment of the invention, the information is presented by the attention manager during active periods (i.e., when the user is engaged in an intensive interaction with the apparatus), but in an unobtrusive manner that does not distract the user from the primary interaction (e.g., the information is presented in areas of a display screen that are not used by displayed information associated with the primary interaction). Generally, then, an attention manager according to the invention makes use of "unused capacity" of a display device, "unused capacity" being defined broadly to include, for example, the embodiments mentioned above, i.e., both temporal (e.g., the first-described embodiment above) and spatial (e.g., the second-described embodiment above) dimensions.</p>
    <p>The information is embodied by one or more sets of content data. Each set of content data is formulated by a content provider and made available by a corresponding content providing system for use with the attention manager. Each content providing system can provide more than one set of content data. Moreover, each set of content data can include one or more "clips", each clip being a definable portion of the set of content data that is used to generate a particular "image." The term "image" is used broadly here to mean any sensory stimulus that is produced from the set of content data, including, for example, visual imagery (e.g., moving or still pictures, text, or numerical information) and audio imagery (i.e., sounds). The content providing systems can also provide user interface tools that allow a user of the attention manager to specify that they want to obtain a particular set of content data. Once obtained, one or more images generated from the clips of one or more sets of content data are displayed by a content display system. The content display system integrates scheduling information associated with the sets of content data to produce a schedule according to which the images corresponding to the sets of content data are displayed for a particular user of the attention manager.</p>
    <p>A set or sets of instructions for enabling a display device to selectively display images generated from one or more sets of content data are also made available to users of the attention manager. The instructions include application instructions, control instructions and content data acquisition instructions. Typically, the instructions enable images generated from content data to be displayed automatically, without user intervention, in a predetermined manner, thereby enhancing the capability of the attention manager to occupy the user's peripheral attention. Different sets of instructions can be formulated, such that only images generated from sets of content data that are compatible with a particular set of instructions can be displayed using that set of instructions. Typically, an application manager establishes a standard set or sets of instructions which content providers can tailor to fit their needs or desires.</p>
    <p>As indicated above, the sets of content data represent sensory data, i.e., data that can be used to generate images as defined above. Typically, the sensory data is either video or audio data. The kinds of content data that can be used with the attention manager are virtually limitless. For example, video data that might be used as content data includes data that can be used to generate advertisements of interest to the user, moving and still video images which can be real-time or pre-recorded (e.g., nature scenes, pictures of family members, MTV music segments, or video from a camera monitoring a specified location, such as ski slopes or a traffic intersection, for conditions at that location), financial data (e.g., stock ticker information) or news summaries. Audio data that might be used as content data includes data that can be used to generate, for example, music or news programs (e.g., radio talk shows).</p>
    <p>The attention manager according to the invention is useful both to users of the attention manager and to content providers. For users, the attention manager provides information to a user in which the user has expressed an interest. In particular, the attention manager provides information to a user that the user might not otherwise expend adequate energy to obtain. Additionally, the information is presented to the user in a manner that uses portions of the user's attention capacity that may otherwise be filled with extraneous information. Further, a variety of information can be displayed (i.e., images can be generated from more than one set of content data), so that the user does not have to choose particular information to the exclusion of all other information.</p>
    <p>For content providers, the attention manager affords an opportunity to disseminate information to users that are interested in receiving such information, thus enabling the content providers to provide better directed information dissemination. Moreover, the attention manager provides access to the previously unused attention capacity of those interested users. Further, since information from more than one content provider can be displayed, content providers are more likely to have their information displayed, since their information is displayed in addition to, rather than instead of, the information of other content providers, thereby reducing the need to compete with other content providers for the attention of the user.</p>
    <p>FIG. 1 is a flow chart of a method 100 that implements an attention manager according to an embodiment of the invention. The method 100 is performed by a content display system according to the invention. The content display system can be implemented, for example, using a digital computer that includes a display device and that is programmed to perform the functions of the method 100, as described below. Below, the method 100 is described as implemented on such a digital computer, though the method 100 could be implemented on other apparatus.</p>
    <p>As shown by block 101, initially (i.e., before operation of the attention manager begins), a user is engaged in a primary user interaction, e.g., a primary user interaction with a computer. Though shown in FIG. 1, the primary user interaction of block 101 does not form part of the method 100 according to the invention. "Primary user interaction" is to be construed broadly and, generally, includes any operation of the computer (or other apparatus with which the user is engaging in an interaction) other than operation that is part of the attention manager according to the invention. When the user is interacting with a computer, the primary user interaction includes any operation of the computer that occurs to enable or to support the performance of the function or functions that provide the basis for the user's use of the computer. For example, the primary user interaction can be the use of any of a variety of conventional application programs (e.g., word processing programs, spreadsheet programs, personal finance programs, game programs, drawing programs, online services and Web browsers, among others). The primary user interaction can also be, for example, simply the operation of a conventional computer operating system, such as the Windows (e.g., Windows 3.1, Windows NT or Windows 95) or DOS operating systems produced by Microsoft Corp. of Redmond, Wash. or the MacIntosh operating system produced by Apple Computer, Inc. of Cupertino, Calif., among others. While, typically, the display device produces a display as a result of the primary user interaction, this need not necessarily be the case.</p>
    <p>The method 100 actually begins with the block 102. In the step shown in the block 102 (referred to hereinafter as step 102), a determination is made as to whether an "idle period" has occurred. Generally, as used herein, "idle period" refers to a period of time of specified duration during which a specified condition does not occur. However, typically, the specified condition is one having the characteristic that failure of the condition to occur is indicative of an extended lack of intensive (or focused) interaction with the computer by the user ("user inactivity"). For example, the specified condition could be the lack of an input from an input device of the computer, e.g., the absence of striking a key on a keyboard, clicking a mouse, pressing on a touch-sensitive area of a touchscreen or issuing a voice command. Alternatively, the attention manager could be implemented with an apparatus that can monitor the environment of the apparatus (e.g., with a video camera) and evaluate the environment to ascertain that an "idle condition" (e.g., the viewing direction of the user of the apparatus is turned away from the apparatus by a specified amount for a specified period of time) has occurred, such idle condition triggering operation of the attention manager.</p>
    <p>Theoretically, any duration of time can be specified to define the idle period. However, practically, the duration of time necessary to constitute an idle period cannot be so short that the attention manager begins operating at times that inhibit the user's primary interaction with the computer or that distract or annoy the user. Further, the duration of time chosen, as indicated above, should be sufficiently long to indicate an extended lack of interaction with the computer, suggesting that the user is not engaged in an interaction with the computer that the user would not want to have interrupted. However, the duration of time should not be so long that, for periods of user inactivity of a typical duration, the amount of time that the attention manager operates is undesirably short. In sum, choosing the duration of time that defines an idle period involves a balancing of the above considerations. Illustratively, the idle period can be defined as a period of between thirty seconds and two minutes during which the specified condition (e.g., user interaction with an input device) does not occur.</p>
    <p>While detection of the idle period can be implemented in any suitable manner, one way in which such detection can be implemented is by monitoring an idle timer that is part of a screen saver API (application program interface) that is, in turn, part of an operating system used to operate the computer. Such screen saver APIs are commonly found in current operating systems such as the Windows or MacIntosh operating systems discussed above. The idle timer could be monitored and a signal that an idle period has occurred generated when the magnitude of the idle time as indicated by the idle timer reaches a predefined threshold.</p>
    <p>Detection of an idle period as the basis for beginning operation of the attention manager is an indirect activation of the attention manager. In an alternative embodiment, step 102 of the method 100 is modified so that the attention manager is activated directly by the user. In other words, step 102 would consist of waiting for explicit direction from the user to begin operation of the attention manager. Such explicit direction could be enabled with an appropriate user interface, such as an on-screen icon or a menu selection, that is always present on the display screen of the display device as part of a standard interface that is provided by the operating system. Examples of such standard interfaces are the "Apple Menu" provided as part of the MacIntosh operating system, and the "Start Menu" or desktop icons provided as part of the Windows 95 operating system.</p>
    <p>Returning to FIG. 1, if, in step 102, an idle period has not occurred, then the primary user interaction continues (block 101). The method 100 continues executing the step 102 at predefined time intervals (typically very short time intervals), thereby continually and frequently checking for the occurrence of an idle period.</p>
    <p>If, in step 102, an idle period is detected, then, in the step shown in the block 103 (hereinafter referred to as step 103), a determination is made as to whether there are any sets of content data available for use in generating a display. (Hereinafter, reference is sometimes made to "displaying content data" or "displaying a set of content data"; it is to be understood that this means displaying images generated using the content data or set of content data.) Herein, "content data" refers to data that is used by the attention manager to generate displays (e.g., video images or sounds, or related sequences of video images or sounds). A "set of content data" refers to a related set of such data that is used to generate a particular display. A "clip" refers to a definable portion of a set of content data that is used to generate a particular image; a set of content data can include one or more clips and, therefore, can be used to generate one or more images. The acquisition of content data by the content display system is described in more detail below. Here, it is sufficient to note that, over time, an attention manager can acquire any number of sets of content data that can be displayed by the content display system.</p>
    <p>If, in step 103, no sets of content data are available for display, then the primary user interaction continues (block 101). The method 100 continues executing the steps 102 and 103 at predefined time intervals, continually checking for the occurrence of an idle period and the acquisition of at least one set of content data.</p>
    <p>If, in step 103, at least one set of content data is available for display, then, in the step shown in the block 104 (hereinafter referred to as step 104), the available sets of content data are scheduled for display by the content display system. (Alternatively, in other embodiments of the invention, scheduling of the sets of content data can occur before the method 100 begins. Such scheduling might be implemented, for example, so that each time a new set of content data is received by the content display system, the schedule is revised to include the new set of content data.) Typically, when the content display system acquires a new (or updated) set of content data, scheduling information for that set of content data is also acquired. Taken together, the scheduling information for all of the sets of content data is used to determine a schedule for display of the sets of content data by the content display system. Generally, determining a display schedule involves specifying the order in which the sets of content data are to be displayed and the duration of time for which each set of content data is to be displayed. The determination of the display schedule can also accommodate (to the extent possible) any special scheduling parameters for particular sets of content data (e.g., restrictions specifying when a particular set of content data must be displayed or cannot be displayed), mediating any conflicts between the display requirements of particular sets of content data. Often, though not necessarily, once the order and duration of display are established, the sets of content data are repetitively displayed by cycling through the display schedule repeatedly until operation of the attention manager is terminated. However, even where such iteration through the display schedule occurs, the display schedule can also accommodate scheduling parameters that delete sets of content data from the display schedule during particular iterations, thereby, for example, controlling the frequency with which particular sets of content data are displayed. The display schedule can be stored in an appropriately structured database, as known by those skilled in the art, that is stored in a memory of the computer used to implement the content display system.</p>
    <p>Any appropriate set of rules, that can, for example, be arranged in any appropriate hierarchical manner, can be used for establishing a display schedule and, in particular, mediating conflicts between conflicting scheduling parameters associated with different sets of content data. For example, one rule for mediating conflicts may give preference to displaying sets of content data so that the sets of content data are displayed inversely to the order in which they were obtained by the content display system. This rule might be further specified so that a set of content data that has never previously been displayed by the attention manager is displayed prior to display of a set of content data that has been previously displayed, even though an update of the previously displayed set of content data has been obtained at a later time than that at which the never displayed set of content data was obtained. Another rule for mediating conflicts might resolve a conflict between two sets of content data having scheduling parameters that specify display at the same sequential position in the display schedule by randomly selecting one of the sets of content data to be displayed first during each iteration through the display schedule. Still another rule for mediating conflicts might establish a hierarchy of kinds of content data, with sets of content data of kinds at the top of the hierarchy being given preference for display over those at the bottom. Yet another rule or set of rules for mediating conflicts may involve performing some sort of analysis of the characteristics of the sets of content data that have been obtained by a particular content display system to ascertain preferences indicated thereby, and giving preference to sets of content data that are evaluated to be relatively more preferred. Scheduling rules of this kind would typically be part of the scheduling parameters provided independent of the content providers (i.e., in content display system scheduling instructions, as discussed elsewhere herein and, in particular, with respect to FIGS. 3A through 3C below).</p>
    <p>Other scheduling rules, not directed to mediating conflicts between sets of content data, can also be used in determining a schedule. For example, any set of content data that has been initially obtained before a certain time and/or that has been last updated before a certain time (i.e., a set of content data that is "stale") can be automatically precluded from being inserted into the display schedule. This exclusion could further be restricted to apply only to certain sets of content data or content data of certain kinds. Similarly, the frequency with which a particular set of content data appears in a display schedule can be based upon how stale the set of content data is. Scheduling rules of this kind would typically be part of the scheduling parameters provided by a content provider for a set of content data (i.e., in tailored content data scheduling instructions, as discussed elsewhere herein and, in particular, with respect to FIGS. 3A through 3C below).</p>
    <p>The particular scheduling rules used may be influenced by the characteristics of a particular embodiment of the attention manager, such as the available kinds of content data or the characteristics of the potential users of the attention manager. The particular scheduling rules used may also be influenced by the need or desire to simplify implementation of the scheduling rules.</p>
    <p>Returning to FIG. 1, once the sets of content data have been scheduled for display, then, in the step shown in the block 105 (hereinafter referred to as step 105), a set of content data is displayed. The content display system is provided with one or more sets of display instructions to enable display of the set or sets of content data on the display device (as discussed elsewhere herein and, in particular, with respect to FIGS. 3A through 3C below).</p>
    <p>After a set of content data has been displayed, then, in the step shown in the block 106 (hereinafter referred to as step 106), a determination is made as to whether operation of the attention manager has been terminated. Generally, operation of the attention manager can be terminated either directly or indirectly. Indirect termination of operation of the attention manager can be effected by, for example, causing operation of the attention manager to terminate when the specified condition (the non-occurrence of which is used to signal an idle period) occurs. For example, the attention manager can be terminated if the user makes an input to the computer using an input device, e.g., strikes a key on a keyboard, clicks a mouse, presses on a touch-sensitive area of a touchscreen or issues a voice command. For indirect termination, it may be desirable to add a further step or steps to the method 100 that, upon an indication that indirect termination should occur (e.g., the occurrence of the specified condition), asks the user to confirm that termination of the attention manager is, in fact, desired, and, if so, terminates the attention manager upon appropriate specified user input. In contrast to indirect termination, direct termination of operation of the attention manager can be effected by, for example, causing operation of the attention manager to terminate when the user selects a control option that specifies such termination, as described in more detail below with respect to FIGS 5A, 5B and 6.</p>
    <p>If, in step 106, operation of the attention manager has been terminated, then the primary user interaction begins again (block 101). The method 100 then begins executing the step 102 again, checking for the occurrence of an idle period.</p>
    <p>If, in step 106, operation of the attention manager has not been terminated, then, in the step shown in the block 107 (hereinafter referred to as step 107), a determination is made as to whether there is an additional set of content data to be displayed. Typically, in operation of an attention manager according to the invention, there will always be another set of content data to be displayed, since, as discussed above, the sets of content data in the display schedule are iteratively displayed until operation of the attention manager is terminated. However, this need not be the case. For example, a limit can be established on the number of times that each set of content data can be displayed, or on the total number of times that any set of content data is displayed.</p>
    <p>If, in step 107, there are no additional sets of content data to be displayed, then the primary user interaction begins again (block 101). The method 100 then begins executing the step 102 again, checking for the occurrence of an idle period.</p>
    <p>If, in step 107, there are additional sets of content data to be displayed, then the method 100 returns to the step 105 and displays a set of content data in accordance with the previously determined display schedule. Steps 105, 106 and 107 are continuously performed, resulting in the continuous display of sets of content data, until either the user terminates the attention manager (step 106) or there are no more sets of content data to be displayed (step 107).</p>
    <p>In another embodiment of the invention, a step could be added to the method 100, either in place of or in addition to the step 107, or as part of the step 106, that causes operation of the attention manager to terminate after the attention manager has been operating for a specified period of time.</p>
    <p>Further, in another embodiment of the invention, an appropriate step or steps could be added to the method 100 so that, at a specified time, such as after each iteration through the display schedule, the method 100 returns to the step 104 and re-determines the display schedule.</p>
    <p>As described above, when the method 100 ends, the primary user interaction (block 101) begins again. Preferably, the primary user interaction begins again with the status existent at the time that the method 100 began. Thus, the primary user interaction must be held in abeyance while the method 100 is operating. This can be accomplished by implementing the method 100 (or any other embodiment of the attention manager) with a content display system that is implemented on a computer that operates with an operating system that allows "multi-tasking" (here used to mean either the suspension of one program while one or more other programs operate, or the execution of one program simultaneously with the execution of one or more other programs). The Windows and MacIntosh operating systems (mentioned above), among others, are operating systems having this characteristic. Where the attention manager is implemented using a screen saver API that is part of the operating system, such multitasking occurs automatically as a characteristic of the screen saver API, i.e., when operation of the attention manager ends, the user is returned to the status of the primary interaction existent at the time that the attention manager started operating. In multitasking operating systems that do not include a screen saver API, this feature of the invention can be implemented by use of an appropriately programmed device driver, as known by those skilled in the art, that monitors user interaction, suspending and restarting the primary user interaction at the beginning and end of operation of the attention manager.</p>
    <p>The method 100 (FIG. 1) described above is an embodiment of the invention in which the attention manager presents information to a person (which can be the user or another person) in the vicinity of the display device during inactive periods when a user is not engaged in an intensive interaction with the computer (as indicated by the step 102 which checks for the occurrence of an "idle period" before beginning operation of the attention manager). As indicated above, in other embodiments of the invention, the attention manager presents information to the person during active periods, but in an unobtrusive manner. In such embodiments, video content data could be presented, for example, as "wallpaper" on the display screen of a video display monitor. Audio content data according to these embodiments could be presented in the same way as for the embodiments of the method 100 described above. For implementation of such embodiments of the invention, the step 102 of the method 100 could be modified to be a determination as to whether the attention manager has been activated (typically this would require direct activation by the user). Alternatively, step 102 could be eliminated altogether and the attention manager could be implemented to operate at any time that the computer is operating and sets of content data are available for display (step 103). For these embodiments, it is, as above, necessary that the content display system be implemented on a computer operated by an operating system that allows multi-tasking as described above. In particular, simultaneous operation of programs must be allowed, since the attention manager operates while the primary user interaction is ongoing (note that the relationships between the block 101 and the method 100 shown in FIG. 1 are not present in these embodiments of the invention).</p>
    <p>Though not confined to such use, the attention manager according to the invention is envisioned as having particular use as a system implemented on, and used by, a network of computers. In such an implementation, each content providing system is implemented on a content provider computer. (It is possible to have more than one content providing system on a content provider computer.) Content display systems are implemented on user computers. The content provider computers and user computers are integrated together into a network such that each user computer can communicate with one or more of the content provider computers. The content provider computers need not (and typically would not) communicate with each other. Likewise, the user computers need not (and typically would not) communicate with each other. Further, each user computer need not communicate with all, or even more than one, of the content provider computers. For example, an attention manager according to the invention could be implemented so as to make use of a network such as the Internet. In particular, the graphical attributes of the World Wide Web would be particularly useful in enabling the provision of user interfaces that allow users to access the attention manager while visiting network sites of content providing systems.</p>
    <p>FIG. 2 is a block diagram of a system 200 for implementing an attention manager according to an embodiment of the invention. The system 200 includes an application manager 201, a multiplicity of content providing systems, shown as Content Providers 1 through n (content providing systems 202a, 202b and 202c are illustrated in FIG. 2), and a multiplicity of content display systems, shown as Users 1 through n (content display systems 203a, 203b and 203c are illustrated in FIG. 2). Hereinafter, the content providing systems and content display systems are referred to generally using the numerals 202 and 203, respectively. In FIG. 2, the solid lines indicate that communication must occur in the system 200 and the dashed lines indicate that communication may occur. However, note that, in another embodiment of the invention, the application manager 201 is not present, and communication between any particular content display system and particular content providing system need not necessarily occur.</p>
    <p>The application manager 201, content providing systems 202 and content display systems 203 can be implemented using appropriately programmed digital computers. Generally, the computers can be any conventional digital computers including an input device (such as a keyboard, mouse or touch screen), an output device (such as a conventional computer display monitor and/or one or more audio speakers), a processing device (such as a conventional microprocessor), a memory (such as a hard disk and/or random access memory), additional conventional devices necessary to interconnect and enable communication between the above-listed devices, and communications devices (e.g., a modem) for enabling communication with other computers of the system. For example, the application manager 201 and content providing systems 202 can be implemented using conventional server computers, while the content display systems 203 can be implemented using conventional client computers. The application manager 201, content providing system 202 and content display systems 203 could also themselves each be implemented by a client-server network of computers. Communication between the computers can be accomplished using any appropriate communication transmission lines, such as conventional telephone lines, or high speed data transmission systems such as T1, T3 or ISDN. The communication can be managed using any appropriate conventional networking methods (e.g., computer programs and protocols) and apparatus, as known by those skilled in the art. In particular, as described further below, the computers are programmed to enable the content display systems 203 to communicate with the content providing systems 202 and application manager 201 even without direct action by the user. In addition to being programmed to enable networking, each of the computers is also appropriately programmed, as described above and below, to perform the functions of the application manager 201, content providing systems 202 and content display systems 203, as appropriate.</p>
    <p>FIGS. 3A, 3B and 3C are schematic diagrams illustrating the functional components of the application manager 201, a content providing system 202 and a content display system 203, respectively, according to an embodiment of the invention. Each of the functional components are represented by a set of instructions and/or data. (In particular, each of the sets of instructions may include, if appropriate, data related to accomplishment of the functions associated with the set of instructions; similarly, a set of content data may include, if appropriate, instructions that enable generation of an image from the set of content data.) Each of these sets of instructions and/or data can be embodied in an appropriate computer program or set of computer instructions (the latter capable of including computer instructions and data), or an appropriate set of data configured for use by a set or sets of instructions (e.g., computer program) that must interact with the set of data in order to implement the attention manager.</p>
    <p>The application manager 201 stores a variety of instructions for use in implementing the attention manager. As shown in FIG. 3A, generally, the application manager 201 stores application instructions 310, control instructions 320, and content data acquisition instructions 330 that can be disseminated to the content display systems 203 and content providing systems 202 as necessary or appropriate. The application manager 201 can also store audit instructions 340 that can be used to enable monitoring of usage of the attention manager.</p>
    <p>The application instructions 310 include operating instructions 311 for beginning, managing and terminating operation of the attention manager on a content display system 203, and content display system scheduling instructions 312 for scheduling the display of content data on a content display system 203. The method 100 (FIG. 1) described above is one embodiment of such application instructions 310. The application instructions 310 also include installation instructions 313 that enable the other instructions used by the attention manager to be implemented using the hardware that is part of and associated with a particular content display system 203. The installation instructions 313 can be implemented as known by those skilled in the art. For example, the installation instructions 313 can be a "plug-in" or "helper" application program (such as a helper application that can be used with the Navigator and Mosaic software programs made by Netscape Communications Corp. of Mountain View, Calif.) that is used to process instructions or data of a particular type--in this case, instructions to implement the attention manager, and content data for use with the attention manager, that can be installed on the hardware of a particular content display system 203. There can be a multiplicity of such helper applications, each capable of operating on particular hardware that could be used to implement a content display system 203. The helper application enables the software program (i.e., Navigator or Mosaic) being used to access the sites of content providers to process references (e.g., Universal Resource Locators, or "URLs") to the particular type of instructions and/or data, so that sets of content data (including updated sets of content data) and the application instructions 310, control instructions 320 and content data acquisition instructions 330 (including updated versions of those instructions) can be acquired.</p>
    <p>The control instructions 320 include display instructions 321 and content data scheduling instructions 322, as described in more detail below, that are typically enhanced by content providers in a particular manner that is appropriate for the content data that the content providers provide. The application manager 201 can (and typically does) store and disseminate multiple distinct sets of control instructions 320. Generally, the display instructions 321 of a particular set of control instructions 320 enable display of content data on a particular type of display device (e.g., a particular type of computer video display or a particular type of audio speaker) or display of a particular type of content data. Display instructions 321 that can be used with a particular display device are typically already developed by third parties (e.g., the maker of the display device) and are readily available. Tailoring of the display instructions 321 to display particular types of content data (such as instructions for displaying content data that is in the GIF format or the format of AutoDesk Animator FLC files) can be done by either the application manager 201 or a content provider. The content data scheduling instructions 322 provide temporal constraints on the display of particular sets of content data. As stored by the application manager 201, the content data scheduling instructions 322 are usually the same for each set of control instructions 320 and provide a generic set of scheduling instructions that can be tailored by a content provider.</p>
    <p>The content data acquisition instructions 330 include acquisition instructions 331 for enabling the initial acquisition of a set of content data and instructions for implementing the attention manager, and content data update instructions 332 for enabling update of previously obtained sets of content data and attention manager instructions. The acquisition instructions 331 and content data update instructions 332 are generic sets of instructions that can be tailored by a content provider. The content data acquisition instructions 330 can also include user interface installation instructions 333 that enable content providers to install a user interface in the information environment (e.g., Web page) of the content provider so that users can request sets of content data from the content provider. Such user interface installation instructions are conventional and readily available for use with the attention manager of the invention.</p>
    <p>As shown in FIG. 3B, the content providing systems 202 store one or more sets of content data 350 that can be disseminated to content display systems 203 as requested. The content providing systems 202 can also store the application instructions 310, control instructions 320, and content data acquisition instructions 330 described above.</p>
    <p>As indicated above, each set of content data 350 defines a related group of data that is used to generate a particular display and includes one or more clips that each represent a definable portion of the set of content data that is used to generate a particular image. The content data 350 represents sensory data and can be, for example, video or audio data. A particular set of content data 350 can be formulated in different versions that are each compatible with content display systems 203 having particular characteristics. In particular, the characteristics of the display device of a content display system 203 can affect the formulation of a set of content data 350. For example, for computer video display monitors, the formulation of a version of a set of content data 350 can depend on the size of the display screen (e.g., horizontal length by vertical length), the display resolution (e.g., the number of horizontal pixels by the number of vertical pixels), the color depth (number, e.g., 256, of possible colors) and the characteristics of the display drivers for the display device. The formulation of a version of a set of content data 350 could also depend upon the operating system being used by the computer on which the content display system 203 is implemented or other characteristics of the computer, such as the speed with which the display device can be operated (insofar as that speed is affected by the characteristics of the computer such as processor speed). Generally, a set of content data 350 can be formatted as known by those skilled in the art in view of the above considerations.</p>
    <p>As indicated above, the control instructions 320 (as well as the content data acquisition instructions 330) are typically enhanced by content providers as appropriate for particular content data. The manner in which these instructions can be tailored by content providers is desirably required to conform to a specified format. Below, a description is given of package files that can be used for tailoring the control instructions 320 and content data acquisition instructions 330, as well identifying the location of content data. These package files can be created using an appropriate computer program (package file editor) that can be provided by, for example, the application manager 201 and that enables this tailoring to be accomplished easily and according to the specified format.</p>
    <p>The content provider can tailor the content data scheduling instructions 322 to indicate the duration of time that a particular set of content data can be displayed ("duration instructions"). Generally, the duration instructions can be arbitrarily complex and can vary in accordance with a variety of factors, including, for example, the particular time at which the set of content data 350 is displayed after the attention manager begins operating, or the number of previous times that the set of content data 350 has been displayed during a continuous operation of the attention manager. The content provider can also tailor the content data scheduling instructions 322 to indicate an order in which the clips of a set of content data 350 are displayed, as well as the duration of the display for each clip ("sequencing instructions"). The content provider can also tailor the content data scheduling instructions 322 to indicate particular times or ranges of times at which a set of content data 350 can or cannot be displayed ("timing instructions") These times can be absolute (e.g., a particular clock time on a particular day, a particular day or days during a week, after or before a specified date) or relative (e.g., not before or after a specified duration of time since the attention manager began operation, first or not first among the sets of content data 350 to be displayed, not after a particular kind or set of content data 350). The content provider can also tailor the content data scheduling instructions 322 to specify a maximum number of times that the set of content data 350 can be displayed after the attention manager begins operating or a maximum number of times that the set of content data 350 can be displayed over any number of operations of the attention manager ("saturation instructions").</p>
    <p>The content provider can also tailor the display instructions 321 to display a particular set or sets of content data. The display instructions 321 can be tailored, for example, according to the type or types of the content data. The type of content data indicates the manner in which an image or images are generated from the content data (i.e., how the bit patterns in a particular clip are transformed into an image). The type of content data is typically established as a consequence of the manner (e.g., with a particular software application program such as the Photoshop or Premiere programs produced by Adobe Systems of Mountain View, Calif.) in which a particular clip is created. The installation instructions 313, discussed above, enable content data of different types to be obtained by the attention manager. Generally, the possible types of content data can be confined to an enumerated set of standard data types, such as the Mime data types used with the World Wide Web. As will be more readily understood from the description below, the type of content data can be specified, for example, in a field of the clip part of a package file.</p>
    <p>The ability to tailor sets of content data 350 and associated control instructions 320 for particular content display systems 203, before the sets of content data 350 and control instructions 320 are provided to those content display systems 203, is advantageous because it allows the tailoring to be done once, by the content providing system 202 or the application manager 201, rather than multiple times, once by each content display system 203 that uses the set of content data 350 and associated control instructions 320.</p>
    <p>The content data acquisition instructions 330--in particular, the content data update instructions 332--are also tailored by content providers as appropriate for particular sets of content data 350. In particular, the content provider can tailor the content data acquisition instructions 330 to indicate where and when to obtain an updated set of content data 350. For example, the indication of where to obtain an updated set of content data 350 can be accomplished by specifying an appropriate network address of a content providing system 202. The network addresses can be specified by, for example, a URL used to identify, for example, an HTML file, an applet (a short application program written in Java or other suitable programming language), a script based on CGI or other suitable mechanism, or any other resource (i.e., computer program or set of data). The indication of when to obtain an updated set of content data 350 can be accomplished by specifying a time or times, either absolute time or times (i.e., particular dates and times during the day) or relative time or times (e.g., one month after the last acquisition/update of the set of content data 350). For example, the update schedule could be established to obtain updates every hour, every day or every week. Or, the update schedule could be established to obtain updates upon the occurrence of a particular event, such as a specified percentage increase or decrease in a stock market index. In general, the particular update schedule used will depend upon the character of the content data with which the update schedule is associated, e.g., content data representing stock prices would probably be updated more frequently than content data representing an advertisement.</p>
    <p>As shown in FIG. 3C, the content display systems 203 store the application instructions 310, control instructions 320, and content data acquisition instructions 330 described above. The application instructions 310 use the control instructions 320 to display sets of content data 350 that are obtained (and updated, if appropriate) by the content data acquisition instructions 330. The application instructions 310 and control instructions 320 are discussed generally, and with respect to particular embodiments, in more detail above, while an embodiment of the content data acquisition instructions 330 is described below.</p>
    <p>FIG. 4 is a flow chart of a method 400 according to the invention for acquiring and updating sets of content data, i.e., the method 400 is an embodiment, at least in part, of the acquisition instructions 331 and content data update instructions 332 of the content data acquisition instructions 330 discussed above with respect to FIGS. 3A through 3C. In the method 400, the steps shown by blocks 402 through 407 can be implemented in the acquisition instructions 331 and the steps shown by blocks 403 through 410 can be implemented in the content data update instructions 332. Generally, the steps of the method 400 can be implemented on an appropriately programmed digital computer that is programmed to perform the functions of the method 400, as described below. Below, the method 400 is described as implemented on such a digital computer, though the method 400 is not limited to such an implementation. The method 400 necessitates communication between a content display system 203 and one or more content providing systems 202. As will be understood by those skilled in the art of digital computer programming for computer network communications, when the method 400 is implemented using a programmed digital computer, particular steps of the method 400 could be implemented on either a content display system 203 or a content providing system 202.</p>
    <p>In the step shown in the block 401 (referred to hereinafter as step 401), a set of content data is selected for display by the attention manager. Initially, in step 401, particular sets of content data are obtained as a result of direct request by the user. Any appropriate user interface can be used for enabling a user to directly request a particular set of content data. For example, Web pages on the World Wide Web could include graphical buttons for enabling users that visit the Web page to request particular sets of content data. Selection of a button on a Web page results in an indication to the appropriate content providing system 202 that the requesting content display system 203 has requested the set of content data corresponding to the selected button to be transferred to the content display system 203. The user interface instructions 333 discussed above, that can be provided to each content providing system 202, can be used to create the user interface.</p>
    <p>Selection of a set of content data in step 401 causes a set of acquisition instructions 331 to be transferred to the content display system 203. The acquisition instructions 331 include information identifying the site from which the set of content data can be obtained, as well as the site or sites from which instructions (e.g., application instructions 310, control instructions 320, content data acquisition instructions 330 and audit instructions 340) for implementing the attention manager can be obtained. These sites can be the same or different sites. The sites can be identified by, for example, using URLs, as described above. The acquisition instructions 331 can also include instructions for establishing an appropriate user interface (e.g., a desktop icon) in the content display system 203 that enables a user to cause the installation instructions 313 to be executed, thereby installing the attention manager in the content display system 203.</p>
    <p>In the step shown in the block 402 (referred to hereinafter as step 402), a determination is made as to whether the requesting content display system 203 has the application instructions 310 (FIGS. 3A through 3C) that enable operation of the attention manager and scheduling of sets of content data 350. If the content display system 203 does not have the application instructions 310, then, in the step shown in the block 405 (referred to hereinafter as step 405), the content display system 203 uses the appropriate site identification provided by the content providing system 202 to obtain a version of the application instructions 310 (typically the most current version of the application instructions 310 that is compatible with the set of content data 350 requested by the user). The application instructions 310 can be provided by the content providing system 202 from which the set of content data 350 is being obtained. Alternatively, the application instructions 310 can be provided directly to the content display system 203 by the application manager 201 (or from some site other than a content provider or the application manager 201) by causing an appropriate instruction to be issued to the application manager 201 (or other site) by either the content providing system 202 or the content display system 203.</p>
    <p>If the content display system 203 does have the application instructions 310 (step 402), then, in the step shown in the block 403 (referred to hereinafter as step 403), a determination is made as to which version or versions of the application instructions 310 the content display system 203 has. As indicated elsewhere, a particular set of content data 350 can (and typically will) be updated from time to time, thereby creating different versions of the set of content data 350. Likewise, the application instructions 310 can also be updated, thereby creating different versions of the application instructions 310. In general, a set of content data 350 can be updated without regard to whether the set of content data is compatible with all versions of the application instructions 310 (though the set of content data 350 must be compatible with at least one version of the application instructions 310). Likewise, the application instructions 310 can be updated without regard to whether any particular set of content data 350 is compatible with that version of the application instructions 310. Moreover, particular versions of the application instructions 310 may be compatible only with sets of content data 350 of certain types. Consequently, a particular content display system 203, even though the content display system 203 has the application instructions 310, may not have a version of the application instructions 310 that is compatible with the type and/or version of the set of content data 350 being requested.</p>
    <p>It is necessary, therefore, to determine whether the content display system 203 has a version of the application instructions 310 that is compatible with the type and version of the set of content data 350 being requested so that, if necessary, a compatible set of application instructions 310 can be provided to the content display system 203. In the step shown in the block 404 (referred to hereinafter as step 404), this determination is made. If the content display system 203 does not have a compatible version of the application instructions 310, then, in step 405, the content providing system 202 (or, for example, the application manager 201) provides to the content display system 203 a version of the application instructions 310 (typically the most current version) that is compatible with the requested set of content data 350.</p>
    <p>Alternatively, in step 404, a determination could be made as to whether the version of the application instructions 310 that the content display system 203 has is the most current version of a set of compatible application instructions 310. If the version is not the current version, then the content providing system 202 provides the current version (step 405), even if the version that the content display system 202 already had is compatible with the newly acquired set of content data 350.</p>
    <p>Preferably, updated sets of application instructions 310 are made downwardly compatible with previous sets of application instructions 310, so that the updated application instructions 310 can be used with any previously obtained sets of content data that are compatible with a previous set of application instructions 310. If downward compatibility is not maintained, the updated set of application instructions 310 can replace a previous set of application instructions 310 and incompatible sets of content data can be removed from the schedule of sets of content data to be displayed (this can be accomplished by the use of appropriate instructions in the content display system scheduling instructions 312 that check for the compatibility of sets of content data with the existing set of application instructions 310) when the attention manager is operating. The content data update instructions 332 can also include instructions that ascertain the current version of the application instructions 310 and, for each set of content data 350 that is incompatible with the current version of the application instructions 310, seek to obtain, at the time scheduled for an update, an updated set of content data 350 that is compatible with the current version of the application instructions 310.</p>
    <p>The steps 402 through 405 are advantageous in that they result in the provision of application instructions 310 to a content display system 203 only when such instructions are needed, thus minimizing the number of sets of application instructions that are made available. The steps 402 through 405 also minimize the amount of information that must be transmitted over communication lines to the content display system 203, thereby freeing those lines for other communication and minimizing the cost (i.e., cost of using the communication lines) associated with using the attention manager of the invention.</p>
    <p>Returning to FIG. 4, in the step shown in the block 406 (referred to hereinafter as step 406), the content providing system 202 provides the current set of content data 350 to the content display system 203. (In practice, the set of content data 350 can be provided before, after or simultaneously with provision of the application instructions 310.) Further, as described above, a particular set of content data 350 can exist in different versions that are each compatible with the content display system 203 to which the version of the set of content data 350 is being provided. The step 406 can include a determination as to the version or versions of the set of content data 350 that can be used by the requesting content display system 203, so that a properly formulated set of content data 350 is acquired.</p>
    <p>A set of control instructions 320 and content data acquisition instructions 330 (FIGS. 3A through 3C) associated with the set of content data 350 can also be provided, as shown by the step of block 407 (referred to hereinafter as step 407). Typically, a check is made (like that for the application instructions 310 and providing similar benefits) to determine whether the content display system 203 already has a compatible (and/or current) version of the control instructions 320 and/or the content data acquisition instructions 330 associated with the set of content data 350 being obtained.</p>
    <p>Each set of content obtained by a content display system 203 can be stored in a database (having any suitable structure) that is stored in a memory of the computer used to implement the content display system 203. The database can also store other information associated with each set of content data 350. This information is discussed in more detail below in the discussion of package files which can be used to convey such information from the content providing systems 202 to the content display systems 203. The package file editor mentioned above can be provided to each content providing system 202 to enable the content provider to easily create a package file for each set of content data 350 provided by that content provider.</p>
    <p>Each package file includes a reference to the set of content data 350 (e.g., a network address) to which that package file corresponds. As mentioned above, each package file can also include a variety of other information. For example, the package file can include a specification of the format of the content data 350 (i.e., an indication of the types of content display systems 203 with which the set of content data 350 is compatible) and the type of the content data (e.g., an identification of a particular graphical format, as discussed above). (This information might be specified explicitly or implicitly; alternatively, this information may be passed to the content display system 203 separately from the package file.) The package file can additionally include a text description of the contents of the package file (this could be used, for example, in a user interface that lists descriptions of all of the sets of content data available to a content display system 203 or provided by a content providing system 202). The package file can also include information governing the presentation of the set of content data, such as screen position, special animation effects and display duration (the latter is shown by the View-Time attribute in the Example below). The update information (location and schedule) is also included in the package file. The package file can also include linking information (e.g., network address of an information source) used to implement a link option discussed in more detail below. The content data scheduling information discussed above can also be included in the package file. The package file can also include data structures that can be used to store auditing information, as discussed in more detail below. The package file can also include reference to one or more sets of control instructions 320, each set of control instructions 320 enabling display of the set of content data 350 by a content display system 203 having a particular architecture, or enabling display of clips of particular types.</p>
    <p>The following Example illustrates how a package file for use with the invention could be constructed. The package file of this Example does not include all types of information that could be included in a package file; it is to be understood that other types of information (as discussed above, for example) could be included in such a package file, expressed in a similar manner to that shown in the Example. In this illustration, the package file is constructed in an object-oriented manner. Generally, each statement in the package file conforms to the following syntax:</p>
    <p>keyword{attribute:value (1) . . . attribute:value(n)}</p>
    <p>where "keyword" can be either PACKAGE or CLIP, "attribute" identifies one of the types of information discussed immediately above, and "value" is an identification of particular content for the type of information. There can be any number of "attribute:value" pairs in a statement. In the Example, each attribute:value pair is designated at right by a numeral enclosed in parentheses to aid in the description; this numeral does not form part of the package file shown in the Example.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Example______________________________________PACKAGE {    Object-Id: 1             (1)               Object-Type: 1                                                              (2)                  Source: http://iwww.interval.com/.sup.    freiberg/                (3)                    Netscreen/Bookreviews/reviews.nss              Name: Book Reviews: Day 1                                                   (4)              Description:                                      (5)              Update Frequency: 720                                                       (6)CLIP {       Object-Id: 16919316                              (7)              Object-Type: 2                                  (8)              Source: http://iwww.interval.com/.sup. freiberg/                             (9)                    Netscreen/Bookreviews/1%20Day%20Book/                    bookreview-1-a1.gif              Name: Anger                             (10)              Description: Book Review                                                    (11)              Update-Frequency: 0                                                         (12)              View-Time: 15                                    (13)              Followup-URL: http://www.randomhouse.com/                                   (14)                    knopf/            Linked-To-Following: 1                                 (15)}CLIP {       Object-Id: 16919384                              (16)              Object-Type: 2                                  (17)              Source: http://iwww.interva1.com/.sup. freiberg/                             (18)                    Netscreen/Bookreviews/1%20Day%20Book/                    bookreview-1-a2.gif              Name: Emotional Intelligence                                                (19)              Description:                             (20)              Update-Frequency: 0                                                         (21)              View-Time: 15                                    (22)              Followup-URL: http://www.randomhouse.com/                                   (23)                    knopf/              Linked-To-Following: 0                                                      (24)}______________________________________</pre>
    
    <p>The first part of line 1 indicates that the following describes a package file. The remainder of line 1 and line 2 are used in debugging and are not relevant to the invention. Line 3 specifies a network address that identifies the location of the package file. (Note that the type of the package file is suggested in line 3 by the file extension .nss, though this extension is not necessary to specify the type. This extension can be used to implicitly specify the type of the package file to the content display system 203.) Lines 4 and 5 each give a description of the contents of the package file that can be used, for example, in a user interface to identify the package file. Line 6 specifies the frequency of acquisition of updates to the set of content data 350 and related instructions that are described by the package file. (In this Example, the frequency is specified in minutes.) The first part of line 7 indicates that the following describes a clip in the package file. The remainder of line 7 and line 8 are similar to lines 1 and 2. Line 9 specifies a network address that identifies the location of the clip. (Similarly to line 3, the type of the clip is suggested in line 9 by the file extension .gif, though, again, this extension is not necessary to specify the type.) Lines 10, 11 and 12 are similar to lines 4, 5 and 6. (Note that, in line 12, the specification of "0" for the update frequency indicates that the clip is never updated.) Line 13 specifies the duration of display for this clip. (In this Example, the duration is specified in seconds.) Line 14 specifies a network address of an information source to which a link can be established during display of this clip. (This aspect of the invention is described in more detail below with respect to the "more" option 602d of FIG. 6.) Line 15 specifies the number of additional clips that are part of this package file. Lines 16 through 24 are similar to lines 7 through 15.</p>
    <p>When a content display system 203 receives a new package file from a content providing system 202, the content display system 203 first determines whether the contents of a corresponding package file (i.e., either the same package file or an earlier version of the package file) already exist as part of the database. This can be done by scanning a list of entries in the database that each indicate the presence of the contents of a particular package file. If the contents of a corresponding package file are not present, then a new entry is created in the list and the contents of the new package file are stored as part of the database (in accordance with the structure of the database). As part of the process of storing the contents of the package file, the contents are transformed into a form that is compatible with the architecture of the content display system 203 (this is enabled by the installation instructions 313 discussed above.</p>
    <p>As described above, the database of content data and related information is constructed from a package file that can have a particular format, as illustrated in the Example above. However, generally, such a database can be constructed from files having any format (e.g., an ASCII file) that enables specification of the information described above that a package file includes.</p>
    <p>Returning to FIG. 4, as indicated above, when a set of content data 350 is obtained (step 406), corresponding control instructions 320 and content data acquisition instructions 330 are also obtained (step 407) if such instructions have not already been acquired by the content display system 203. In particular, content data update instructions 332 can be obtained, so that updates to the set of content data 350 and/or the associated control instructions 320 and content data acquisition instructions 330 can be obtained in the future. As mentioned above, the content data update instructions 332 include a description of the location of the content providing system 202 from which the updates can be obtained as well a schedule of times at which such updates should be obtained.</p>
    <p>In the step shown in the block 408 (referred to hereinafter as step 408), a determination is made as to whether it is time to update the set of content data 350. The update schedule discussed above is used for this purpose. As long as the schedule indicates that no update need be obtained, the method 400 continues executing the step 408, thereby continuously monitoring whether an update need be obtained. The monitoring of step 408 could be implemented, for example, by a procedure that monitors the content display system computer clock and indicates that an update should be obtained when the clock time is equal to a time in the update schedule.</p>
    <p>The update schedule can be established according to any desired criteria. For example, preferably, though not necessarily, the step 408 (and the steps 409 and 410 discussed below and, as necessary, the steps 403 through 407 discussed above) of the method 400 operates at any time that the computer (or computers) with which the content display system 203 is implemented is on, even when the attention manager is not operating. Thus, the update schedule could be established so that updates are obtained during the middle of the night, when charges for communication with content providing systems 202 are cheaper. Preferably, then, at least this part of the content display system 203 is implemented on a computer that is always on, so that such cheap communications time can be utilized for obtaining updates. This can be particularly feasible if the content display system 203 is implemented on a client-server network in which at least the content data update instructions 332 are executed by a server computer which remains on at all times. If, however, the computer on which the content data update instructions 332 are executed is turned off at a time when an update is scheduled to be retrieved, then the update can occur immediately after the next time that the computer is turned on.</p>
    <p>This aspect of the content data acquisition instructions 332 can be implemented, for example, using a communications daemon that is part of the content data update instructions 332. When the content data update instructions 332 are acquired by a content display system 203, the daemon is inserted into a startup file that is executed at the beginning of operation of the operating system of the computer with which the content display system 203 is associated. The daemon causes a connection to be made to each location from which the content data update instructions 332 indicate that an update is to be acquired. For example, if the computer uses a Windows operating system, the daemon initiates a WinSock TCP/IP connection to enable connection to be made to the locations of the updated sets of content data 350.</p>
    <p>Returning to FIG. 4, once it is determined that an update of the set of content data 350 should be obtained, then, in the step shown in the block 409 (referred to hereinafter as step 409), the location of the appropriate content providing system 202 is ascertained from the scheduling information, and that location is accessed.</p>
    <p>In the step shown in the block 410 (referred to hereinafter as step 410), a determination is made as to whether an updated set of content data 350 is available on the content providing system 202. If an updated set of content data 350 is not available, then the step 408 begins executing again, continuing until the update schedule indicates that it is again time to check for an updated set of content data 350. If an updated set of content data 350 is available, then the method 400 returns to the step 403, and an updated set of content data 350 and, if necessary, related control instructions 320 and content data acquisition instructions 330 are provided to the content display system 203 (i.e., an appropriate package file is provided to the content display system 203). As discussed above, the content display system 203 compares the version of the package file contents stored in the database to the contents of the version of the package file being newly provided, and makes changes to the database as necessary.</p>
    <p>FIGS. 5A and 5B together are a flow chart of a method 500 that implements an attention manager according to another embodiment of the invention. Like the method 100 (FIG. 1), the method 500 is performed by a content display system 203 according to the invention which can be implemented, for example, using a digital computer that includes a display device and that is programmed to perform the functions of the method 500, as described below. Below, the method 500 is described as implemented on such a digital computer, though the method 500 could be implemented on other apparatus. Steps in the method 500 that are the same as steps in the method 100 are shown by like-numbered blocks. Generally, the method 500 differs from the method 100 in that the method 500 provides a number of control options that enable the user to effect particular types of control of the attention manager. While the method 500 and the associated description below illustrate several control options that can be used with an attention manager according to the invention, it is to be understood that an attention manager according to the invention could include any of a number of other options not shown in FIGS. 5A and 5B, or described specifically herein.</p>
    <p>The attention manager according to this embodiment of the invention can include any suitable user interface to enable the user to specify a control option. FIG. 6 illustrates a computer display screen 600 including one embodiment of such a user interface. The screen 600 displays, in addition to an image generated from a set of content data 350, a dialog box 601 that includes a list of available control options 602a through 602e. The dialog box 601 can remain on the screen 600 during the entire time that the attention manager is operating. The available control options 602a through 602e shown in the dialog box 601--as well as additional control options that could be, but are not, included in the dialog box 601--are discussed in more detail below.</p>
    <p>The manner of selecting an option depends upon the available user input device(s). For example, a keyboard could be used to move a cursor to a desired option, which is then selected using the Enter key. Or, a mouse could be used to move a cursor to a desired option, then clicked to select the option. Or, a touch pen could be used to contact the screen 600 (if the screen 600 is a touch-sensitive screen) at an appropriate location to cause a desired option to be selected. Or, an audio command could be issued to a voice recognition system which causes the desired option to be selected.</p>
    <p>One control option that can be used with an attention manager according to the invention enables the user to directly terminate operation of the attention manager. In FIG. 6, this is shown as the "exit" option 602a. In the method 500, this option is implemented using the step 107. As discussed above, selection of the "exit" option 602a causes the primary user interaction to begin again (block 101).</p>
    <p>Another control option that can be used with an attention manager according to the invention enables the user to terminate display of the currently displayed set of content data and begin display of the next scheduled set of content data. In FIG. 6, this is shown as the "next" option 602b. In the method 500, this option is implemented by the step shown in the block 501.</p>
    <p>Yet another control option that can be used with an attention manager according to the invention enables the user to terminate display of the currently displayed set of content data and begin display of the set of content data displayed immediately prior to the terminated set. In FIG. 6, this is shown as the "back" option 602c. In the method 500, this option is implemented by the steps shown in the blocks 502 and 511.</p>
    <p>Still another control option that can be used with an attention manager according to the invention enables the user to terminate display of the currently displayed set of content data and remove that set of content data from the schedule so that the set will not be displayed in the future. This option is not shown in FIG. 6. In the method 500, this option is implemented by the steps shown in the blocks 503 and 512. In a particular embodiment, this option can be implemented so that the set of content data is precluded from being displayed only during the current operation of the attention manager. In another particular embodiment, this option can be implemented so that the set of content data is removed from the content display system 203 entirely, i.e., the set of content data is no longer available for display. In this embodiment, the set of content data could only become available for display again if the user takes affirmative steps to re-obtain the set of content data, as described above with respect to step 401 of the method 400 (FIG. 4).</p>
    <p>Another control option that can be used with an attention manager according to the invention enables the user to prevent future display of the currently displayed set of content data until that set of content data has been updated. This option is not shown in FIG. 6. In the method 500, this option is implemented by the steps shown in the blocks 504, 513, 521, 522 and 523 (referred to hereinafter as steps 504, 513, 521, 522 and 523, respectively). If this option is selected in step 504, then an update flag is activated. The update flag can be a designated field associated with a particular set of content data in the database that contains all of the available sets of content data. As shown by step 521, the method 500 identifies, before display of a next set of content data in the schedule, the identity of that next set, and determines (step 522) whether the update flag has been activated for that set of content data. If the update flag has not been activated, then, in step 105, the set of content data is displayed. However, if the update flag has been activated, then, in step 523, a determination is made as to whether the set of content data has been updated since the last time that the set of content data was displayed. This step can be accomplished by checking an update monitor flag that can be a designated field of the database that is associated with the set of content data. If the update monitor flag indicates that the set of content data has been updated since the last time that the set of content data was displayed, then the set of content data is displayed (step 105). Otherwise, the method 500 returns to the step 521 to identify the next set of content data in the schedule.</p>
    <p>Yet another control option that can be used with an attention manager according to the invention enables the user to specify a level of satisfaction with the currently displayed content data. This option is not shown in FIG. 6. In the method 500, this option is implemented by the steps shown in the blocks 505, 514 and 515. Depending upon the level of satisfaction indicated in the step 514, the schedule can be modified (step 515) to show the set of content data more, less or at different times than was previously the case. This option can be implemented in any appropriate manner; one way is described immediately below.</p>
    <p>The content display system scheduling instructions 312 can include instructions that evaluate a probability function each time that a set of content data in the schedule is presented for display, and either display or not display the set of content data dependent upon the evaluation of the probability function. The probability function can include consideration of a variety of factors (e.g., the amount of time that has passed since a particular set of content data has been updated), but for implementation of the instant option, the probability function includes a term n<sup>p</sup>, where n is a constant between 1 and 2, and p is a variable that represents a user's preference for a particular set of content data. Initially, the value of p is 0. Each time that a user indicates a like or dislike for a set of content data (by, for example, selecting an appropriate option in a dialog box such as the dialog box 601), the variable p is incremented or decremented, respectively, by a predetermined amount. The content display system scheduling instructions 312 evaluate a stochastic probability function (e.g., a Gaussian probability function) using the evaluated probability function as an argument. If the result of evaluation of the stochastic probability function is "true", then the set of content data is displayed; if "false", then the set of content data is not displayed. As can be seen, then, initially (i.e., when p=0), the user has expressed no like or dislike of a set of content data and the set of content data is displayed or not according to other criteria. Incrementing or decrementing p (i.e., expressing like or dislike for a set of content data) causes the term n<sup>p</sup> to increase or decrease exponentially, thereby increasing or decreasing the likelihood that the set of content data will be displayed.</p>
    <p>Still another control option that can be used with an attention manager according to the invention enables the user to establish a link with another information source. In FIG. 6, this is shown as the "more" option 602d. (In "wallpaper" embodiments of the invention, this option can be implemented so that any time the user clicks a mouse--or presses the "Enter" key on a keyboard--when the cursor is within the wallpaper, the link is made to the other information source.) In the method 500, this option is implemented by the steps shown in the blocks 506, 516 and 517. Links can be established to any of a variety of information sources and types of information sources. Typically, the link will be made to an information source that provides information that is related to the content data which was being displayed when the link was established. Upon selection by the user of this control option, the information source is accessed and additional information retrieved for presentation to the user. A link can be made, for example, to any information source that is part of a network which can be accessed by the computer with which the attention manager is being used (though it is not necessary that the link be made through a network). For example, the attention manager can be implemented so that links can be established to locations on the World Wide Web using the appropriate URLs. Such links can be established using any of a variety of Web browser software programs, such as the Navigator software program made by Netscape Communications Corp. Links are enabled by appropriately specifying the location (e.g., a network address) of the information source. The location of an information source (or locations of information sources) can be specified by associating the location with the set of content data, for example, in a package file as described and illustrated above.</p>
    <p>As shown in the method 500, the attention manager continues to operate during the time that the link is established and the link is established to an information source from which it is possible to return to the attention manager (see step 517). The presentation of the new information to the user can include an appropriate user interface mechanism that allows the user to request such a return to the attention manager. However, the capacity to return to operation of the attention manager may not always exist. In that event, the step 517 is not part of the method 500; rather, the method 500 terminates after the step 516 and the user operates in the environment of the information source from that point forward. Such termination of the attention manager will frequently be the case where the link is made via a network to an information source.</p>
    <p>Another control option that can be used with an attention manager according to the invention enables the user to obtain an overview of all of the content data available for display by the attention manager. This option is not shown in FIG. 6, nor is it implemented in the method 500 of FIGS. 5A and 5B. The overview could be presented textually, pictorially or aurally. The overview information can be obtained either via a link to another information location (e.g, the location of the application manager 201) as described above or from a memory associated with the content display system 203, the overview information having been communicated to the content display system 203 when a set of content data was obtained.</p>
    <p>Still another control option that can be used with an attention manager according to the invention enables the user to maintain display of the currently displayed set of content data 350 until such display is terminated by the user. This option is not shown in FIG. 6, nor is it implemented in the method 500 of FIGS. 5A and 5B. Upon selection of this option, an appropriate user interface could be made to appear that allows the user to specify termination of the display. After termination of the display, the attention manager resumes normal operation, i.e., the next set of content data 350 is displayed.</p>
    <p>The dialog box 601 also includes an additional option, the "cancel" option 602e. Selection of the "cancel" option 602e causes the dialog box 601 to be removed from the screen 600. The dialog box 601 can be made to reappear again using any appropriate technique. For example, the application instructions 310 can include appropriate instructions to cause the dialog box 601 to reappear when the user makes an input to the computer using an input device.</p>
    <p>As discussed above (see FIG. 2), usage of the attention manager can be audited using audit instructions 340 (FIGS. 3A and 3C) that can be supplied by the application manager 201 to the content display systems 203, either directly or via the content providing systems 202. The audit instructions 340 can include instructions that cause a content display system 203 to record, as the attention manager is used, particular information (audit information) regarding use of the attention manager (or compute such information from other, more basic information recorded by the attention manager). The audit information can be stored by the content display system 203 in an appropriately structured database. The audit information can include, for example, the identity of each set of content data 350 displayed by the attention manager, the number of times that a set of content data 350 was displayed by the attention manager, the frequency (e.g., number of times per week) that a set of content data 350 was displayed by the attention manager, the times at which a set of content data 350 was displayed by the attention manager, a user-expressed satisfaction level for a particular set of content data 350, and the last set of content data 350 displayed to a user before the user either "passively" (i.e., by making an input to the computer with an input device) or "actively" (i.e., by selecting a control option) terminated operation of the attention manager (of interest, since the user presumably was viewing the display screen when such interaction occurred). The audit instructions can also include instructions that compile and/or analyze the audit information in a desired manner. The audit instructions 340 can also include instructions that cause audit information to be transmitted to a remote site (e.g., the application manager 201 or a content providing system 202). These instructions can include scheduling instructions that govern when the audit information is so communicated (e.g., after periodic time intervals), as well as instructions that identify the location (e.g., network address) of the remote site. The transfer of audit information can be accomplished, for example, using a conventional electronic mail mechanism, as known to those skilled in the art. The audit instructions 340 can also include instructions that enable the content display system 203 to display audit information. Additionally, the audit instructions 340 can include instructions that enable the user to disable the audit function entirely, or that enable the user to prevent audit information from being transmitted to the application manager 201 and/or to content providing systems 202. These last instructions could also be accompanied by operating instructions that provide a control option or options to the user, in a manner similar to that described above with respect to FIGS. 5A, 5B and 6, that enable the user to select disablement of the audit function. The audit instructions 340 can also include instructions that cause the database of audit information to be erased at an appropriate time, such as after the audit information has been communicated to a remote site.</p>
    <p>Auditing of use of the attention manager can be useful to both users of the attention manager and content providers for a variety of reasons. Such auditing can be used, for example, to illustrate to content providers the value of the attention manager as a tool for disseminating the content provider's information, by showing the content providers how many content data display systems 203 are displaying the content provider's content data. The auditing can also give content providers insight into the interests of computer users, enabling the content providers to better target the information that the content providers provide. The auditing can also indicate to a user the amount and types of the information that the user has been receiving.</p>
    <p>Various embodiments of the invention have been described. The descriptions are intended to be illustrative, not limitative. Thus, it will be apparent to one skilled in the art that certain modifications may be made to the invention as described without departing from the scope of the claims set out below. For example, though it is contemplated that an attention manager according to the invention will typically be used to occupy the peripheral attention of a human computer user, generally the attention manager can be used to occupy the attention of any sentient being. For example, the attention manager may be useful in occupying the attention of domesticated animals such as dogs or cats, or providing training (i.e., audio that can be repeated) for a "talking" bird such as a parrot.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4845658">US4845658</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 1, 1986</td><td class="patent-data-table-td patent-date-value">Jul 4, 1989</td><td class="patent-data-table-td ">Massachusetts Institute Of Technology</td><td class="patent-data-table-td ">Information method and apparatus using simplex and duplex communications</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5105184">US5105184</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 9, 1989</td><td class="patent-data-table-td patent-date-value">Apr 14, 1992</td><td class="patent-data-table-td ">Noorali Pirani</td><td class="patent-data-table-td ">Methods for displaying and integrating commercial advertisements with computer software</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5305195">US5305195</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 25, 1992</td><td class="patent-data-table-td patent-date-value">Apr 19, 1994</td><td class="patent-data-table-td ">Gerald Singer</td><td class="patent-data-table-td ">Interactive advertising system for on-line terminals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5347632">US5347632</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 28, 1989</td><td class="patent-data-table-td patent-date-value">Sep 13, 1994</td><td class="patent-data-table-td ">Prodigy Services Company</td><td class="patent-data-table-td ">Reception system for an interactive computer network and method of operation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5573643">US5573643</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 18, 1994</td><td class="patent-data-table-td patent-date-value">Nov 12, 1996</td><td class="patent-data-table-td ">Valmet Corporation</td><td class="patent-data-table-td ">Twin wire web former in a paper machine</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5740549">US5740549</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 12, 1995</td><td class="patent-data-table-td patent-date-value">Apr 14, 1998</td><td class="patent-data-table-td ">Pointcast, Inc.</td><td class="patent-data-table-td ">Information and advertising distribution system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5768528">US5768528</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 24, 1996</td><td class="patent-data-table-td patent-date-value">Jun 16, 1998</td><td class="patent-data-table-td ">V-Cast, Inc.</td><td class="patent-data-table-td ">Client-server system for delivery of online information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1993019427A1?cl=en">WO1993019427A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 24, 1993</td><td class="patent-data-table-td patent-date-value">Sep 30, 1993</td><td class="patent-data-table-td ">Arthur J Murphy</td><td class="patent-data-table-td ">Interactive advertising system for on-line terminals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1996030864A1?cl=en">WO1996030864A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 29, 1995</td><td class="patent-data-table-td patent-date-value">Oct 3, 1996</td><td class="patent-data-table-td ">Futurevision Of America Corp</td><td class="patent-data-table-td ">Interactive advertising system and device</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Gomes, Lee, "<a href='http://scholar.google.com/scholar?q="Upstart%27s+Internet+%60TV%60+Has+Microsoft+Tuned+In"'>Upstart's Internet `TV` Has Microsoft Tuned In</a>", Wall Street Journal, Aug. 1996.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Gomes, Lee, Upstart s Internet TV Has Microsoft Tuned In , Wall Street Journal, Aug. 1996.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Joan E. Rigdon, "<a href='http://scholar.google.com/scholar?q="Screen+Savers+Go+Beyond+Fish%2C+Flying+Toasters%2C"'>Screen Savers Go Beyond Fish, Flying Toasters,</a>" Wall Street Journal, Feb. 13, 1996.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Joan E. Rigdon, Screen Savers Go Beyond Fish, Flying Toasters, Wall Street Journal , Feb. 13, 1996.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Staff Reporter, "<a href='http://scholar.google.com/scholar?q="PointCast+Inc.+Is+Testing+New+Screen-Saver+Product%2C"'>PointCast Inc. Is Testing New Screen-Saver Product,</a>" Wall Street Journal, May 1996.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Staff Reporter, PointCast Inc. Is Testing New Screen Saver Product, Wall Street Journal , May 1996.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6286029">US6286029</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 28, 1997</td><td class="patent-data-table-td patent-date-value">Sep 4, 2001</td><td class="patent-data-table-td ">Sabre Inc.</td><td class="patent-data-table-td ">Kiosk controller that retrieves content from servers and then pushes the retrieved content to a kiosk in the order specified in a run list</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6317780">US6317780</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 8, 1998</td><td class="patent-data-table-td patent-date-value">Nov 13, 2001</td><td class="patent-data-table-td ">Webtv Networks, Inc.</td><td class="patent-data-table-td ">System and method for distributing data over a communications network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6317791">US6317791</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 8, 1998</td><td class="patent-data-table-td patent-date-value">Nov 13, 2001</td><td class="patent-data-table-td ">Webtv Networks, Inc.</td><td class="patent-data-table-td ">System and method for distributing data over a communications network for display during start-up</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6338094">US6338094</a></td><td class="patent-data-table-td patent-date-value">Dec 9, 1999</td><td class="patent-data-table-td patent-date-value">Jan 8, 2002</td><td class="patent-data-table-td ">Webtv Networks, Inc.</td><td class="patent-data-table-td ">Method, device and system for playing a video file in response to selecting a web page link</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6356934">US6356934</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 28, 1997</td><td class="patent-data-table-td patent-date-value">Mar 12, 2002</td><td class="patent-data-table-td ">Sabre Inc.</td><td class="patent-data-table-td ">Intermediate server having control program for storing content accessed during browsing sessions and playback program for asynchronously replaying browsing sessions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6446056">US6446056</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 10, 1999</td><td class="patent-data-table-td patent-date-value">Sep 3, 2002</td><td class="patent-data-table-td ">Yamaha Hatsudoki Kabushiki Kaisha</td><td class="patent-data-table-td ">Interactive artificial intelligence</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6484148">US6484148</a></td><td class="patent-data-table-td patent-date-value">Feb 19, 2000</td><td class="patent-data-table-td patent-date-value">Nov 19, 2002</td><td class="patent-data-table-td ">John E. Boyd</td><td class="patent-data-table-td ">Electronic advertising device and method of using the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6563523">US6563523</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 28, 1999</td><td class="patent-data-table-td patent-date-value">May 13, 2003</td><td class="patent-data-table-td ">Midway Amusement Games Llc</td><td class="patent-data-table-td ">Graphical control of a time-based set-up feature for a video game</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6594649">US6594649</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 1999</td><td class="patent-data-table-td patent-date-value">Jul 15, 2003</td><td class="patent-data-table-td ">Yamaha Hatsudoki Kabushiki Kaisha</td><td class="patent-data-table-td ">Interactive artificial intelligence</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6604091">US6604091</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 1999</td><td class="patent-data-table-td patent-date-value">Aug 5, 2003</td><td class="patent-data-table-td ">Yamaha Hatsudoki Kabushiki Kaisha</td><td class="patent-data-table-td ">Interactive artificial intelligence</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6606652">US6606652</a></td><td class="patent-data-table-td patent-date-value">Oct 16, 2001</td><td class="patent-data-table-td patent-date-value">Aug 12, 2003</td><td class="patent-data-table-td ">Webtv Networks, Inc.</td><td class="patent-data-table-td ">System for targeting information to specific users on a computer network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6704773">US6704773</a></td><td class="patent-data-table-td patent-date-value">Nov 13, 2001</td><td class="patent-data-table-td patent-date-value">Mar 9, 2004</td><td class="patent-data-table-td ">Webtv Networks, Inc.</td><td class="patent-data-table-td ">Distributing data over a communications network for display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6714172">US6714172</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 10, 1998</td><td class="patent-data-table-td patent-date-value">Mar 30, 2004</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Display control system and its control method, switching device, connection device, peripheral device, peripheral device system, and their control method, and computer readable memory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6750880">US6750880</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 20, 2002</td><td class="patent-data-table-td patent-date-value">Jun 15, 2004</td><td class="patent-data-table-td ">Interval Research</td><td class="patent-data-table-td ">Attention manager for occupying the peripheral attention of a person in the vicinity of a display device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6788314">US6788314</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 20, 2000</td><td class="patent-data-table-td patent-date-value">Sep 7, 2004</td><td class="patent-data-table-td ">Interval Research Corporation</td><td class="patent-data-table-td ">Attention manager for occupying the peripheral attention of a person in the vicinity of a display device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6964022">US6964022</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 22, 2000</td><td class="patent-data-table-td patent-date-value">Nov 8, 2005</td><td class="patent-data-table-td ">Xerox Corporation</td><td class="patent-data-table-td ">Electronic board system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7015949">US7015949</a></td><td class="patent-data-table-td patent-date-value">Apr 12, 2001</td><td class="patent-data-table-td patent-date-value">Mar 21, 2006</td><td class="patent-data-table-td ">Ipix Corporation</td><td class="patent-data-table-td ">Method and apparatus for hosting a network camera with refresh degradation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7024488">US7024488</a></td><td class="patent-data-table-td patent-date-value">Apr 12, 2001</td><td class="patent-data-table-td patent-date-value">Apr 4, 2006</td><td class="patent-data-table-td ">Ipix Corporation</td><td class="patent-data-table-td ">Method and apparatus for hosting a network camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7076085">US7076085</a></td><td class="patent-data-table-td patent-date-value">Apr 12, 2001</td><td class="patent-data-table-td patent-date-value">Jul 11, 2006</td><td class="patent-data-table-td ">Ipix Corp.</td><td class="patent-data-table-td ">Method and apparatus for hosting a network camera including a heartbeat mechanism</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7167255">US7167255</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 30, 1999</td><td class="patent-data-table-td patent-date-value">Jan 23, 2007</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Method for displaying desired message in display unit of data processing apparatus for various processes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7177448">US7177448</a></td><td class="patent-data-table-td patent-date-value">Apr 12, 2001</td><td class="patent-data-table-td patent-date-value">Feb 13, 2007</td><td class="patent-data-table-td ">Ipix Corporation</td><td class="patent-data-table-td ">System and method for selecting and transmitting images of interest to a user</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7348935">US7348935</a></td><td class="patent-data-table-td patent-date-value">May 5, 2004</td><td class="patent-data-table-td patent-date-value">Mar 25, 2008</td><td class="patent-data-table-td ">Vulcan Patents Llc</td><td class="patent-data-table-td ">Attention manager for occupying the peripheral attention of a person in the vicinity of a display device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7538790">US7538790</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 21, 2003</td><td class="patent-data-table-td patent-date-value">May 26, 2009</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Method and apparatus for controlling a video signal processing apparatus to prevent screen aging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7599520">US7599520</a></td><td class="patent-data-table-td patent-date-value">Nov 18, 2005</td><td class="patent-data-table-td patent-date-value">Oct 6, 2009</td><td class="patent-data-table-td ">Accenture Global Services Gmbh</td><td class="patent-data-table-td ">Detection of multiple targets on a plane of interest</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7912915">US7912915</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 30, 2001</td><td class="patent-data-table-td patent-date-value">Mar 22, 2011</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Systems and methods for enticing users to access a web site</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7983977">US7983977</a></td><td class="patent-data-table-td patent-date-value">Dec 10, 2002</td><td class="patent-data-table-td patent-date-value">Jul 19, 2011</td><td class="patent-data-table-td ">Ebay Inc.</td><td class="patent-data-table-td ">Method and system for performing a progressive auction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8015103">US8015103</a></td><td class="patent-data-table-td patent-date-value">Feb 22, 2010</td><td class="patent-data-table-td patent-date-value">Sep 6, 2011</td><td class="patent-data-table-td ">Ebay Inc.</td><td class="patent-data-table-td ">Auction with interest rate bidding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8019656">US8019656</a></td><td class="patent-data-table-td patent-date-value">Jul 17, 2007</td><td class="patent-data-table-td patent-date-value">Sep 13, 2011</td><td class="patent-data-table-td ">Cbs Interactive Inc.</td><td class="patent-data-table-td ">System and method for generating an alternative product recommendation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8026944">US8026944</a></td><td class="patent-data-table-td patent-date-value">Apr 12, 2001</td><td class="patent-data-table-td patent-date-value">Sep 27, 2011</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Method and apparatus for hosting a network camera with image degradation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8209620">US8209620</a></td><td class="patent-data-table-td patent-date-value">Apr 21, 2006</td><td class="patent-data-table-td patent-date-value">Jun 26, 2012</td><td class="patent-data-table-td ">Accenture Global Services Limited</td><td class="patent-data-table-td ">System for storage and navigation of application states and interactions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8271351">US8271351</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2010</td><td class="patent-data-table-td patent-date-value">Sep 18, 2012</td><td class="patent-data-table-td ">Cbs Interactive Inc.</td><td class="patent-data-table-td ">System and method for generating an alternative product recommendation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8348675">US8348675</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 18, 2001</td><td class="patent-data-table-td patent-date-value">Jan 8, 2013</td><td class="patent-data-table-td ">Life Success Academy</td><td class="patent-data-table-td ">Apparatus and method for delivery of instructional information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8374948">US8374948</a></td><td class="patent-data-table-td patent-date-value">Dec 21, 2007</td><td class="patent-data-table-td patent-date-value">Feb 12, 2013</td><td class="patent-data-table-td ">Ebay Inc.</td><td class="patent-data-table-td ">System and method for receiving a bid</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8386366">US8386366</a></td><td class="patent-data-table-td patent-date-value">Dec 21, 2007</td><td class="patent-data-table-td patent-date-value">Feb 26, 2013</td><td class="patent-data-table-td ">Ebay Inc.</td><td class="patent-data-table-td ">System and method for creating a customer account</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8392284">US8392284</a></td><td class="patent-data-table-td patent-date-value">Aug 6, 2012</td><td class="patent-data-table-td patent-date-value">Mar 5, 2013</td><td class="patent-data-table-td ">Cbs Interactive Inc.</td><td class="patent-data-table-td ">System and method for generating an alternative product recommendation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8398407">US8398407</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 28, 2003</td><td class="patent-data-table-td patent-date-value">Mar 19, 2013</td><td class="patent-data-table-td ">Iplearn, Llc</td><td class="patent-data-table-td ">Learning method and system in a window environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8429244">US8429244</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 26, 2009</td><td class="patent-data-table-td patent-date-value">Apr 23, 2013</td><td class="patent-data-table-td ">Interval Licensing Llc</td><td class="patent-data-table-td ">Alerting users to items of current interest</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8433643">US8433643</a></td><td class="patent-data-table-td patent-date-value">Jul 13, 2011</td><td class="patent-data-table-td patent-date-value">Apr 30, 2013</td><td class="patent-data-table-td ">Ebay Inc.</td><td class="patent-data-table-td ">Auction with interest rate bidding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8475174">US8475174</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 26, 2012</td><td class="patent-data-table-td patent-date-value">Jul 2, 2013</td><td class="patent-data-table-td ">Iplearn-Focus, Llc</td><td class="patent-data-table-td ">Learning method and system using detached sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8504436">US8504436</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 2012</td><td class="patent-data-table-td patent-date-value">Aug 6, 2013</td><td class="patent-data-table-td ">Cbs Interactive Inc.</td><td class="patent-data-table-td ">Systems and methods for generating a manufacturer tier product rollup</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8510406">US8510406</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Aug 13, 2013</td><td class="patent-data-table-td ">Mainstream Scientific, Llc</td><td class="patent-data-table-td ">Component for accessing and displaying internet content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8510407">US8510407</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Aug 13, 2013</td><td class="patent-data-table-td ">Mainstream Scientific, Llc</td><td class="patent-data-table-td ">Displaying time-varying internet based data using application media packages</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8521833">US8521833</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Aug 27, 2013</td><td class="patent-data-table-td ">Mainstream Scientific, Llc</td><td class="patent-data-table-td ">System and method for accessing and displaying internet content via an integrated application media package</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8527910">US8527910</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 31, 2003</td><td class="patent-data-table-td patent-date-value">Sep 3, 2013</td><td class="patent-data-table-td ">Lg Electronics Inc.</td><td class="patent-data-table-td ">Method and display apparatus of providing advance screen saver warning</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8538320">US8538320</a></td><td class="patent-data-table-td patent-date-value">Mar 14, 2013</td><td class="patent-data-table-td patent-date-value">Sep 17, 2013</td><td class="patent-data-table-td ">Iplearn-Focus, Llc</td><td class="patent-data-table-td ">Learning method and system using detached sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8538321">US8538321</a></td><td class="patent-data-table-td patent-date-value">Mar 14, 2013</td><td class="patent-data-table-td patent-date-value">Sep 17, 2013</td><td class="patent-data-table-td ">Iplearn-Focus, Llc</td><td class="patent-data-table-td ">Computing method and system using detached sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8540520">US8540520</a></td><td class="patent-data-table-td patent-date-value">Dec 2, 2009</td><td class="patent-data-table-td patent-date-value">Sep 24, 2013</td><td class="patent-data-table-td ">Life Success Academy</td><td class="patent-data-table-td ">Apparatus and method for instructional information delivery</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8606819">US8606819</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 18, 2012</td><td class="patent-data-table-td patent-date-value">Dec 10, 2013</td><td class="patent-data-table-td ">Robocast, Inc.</td><td class="patent-data-table-td ">Automated content scheduler and displayer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8606820">US8606820</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 13, 2012</td><td class="patent-data-table-td patent-date-value">Dec 10, 2013</td><td class="patent-data-table-td ">Robocast, Inc.</td><td class="patent-data-table-td ">Automated content scheduler and displayer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8621034">US8621034</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Dec 31, 2013</td><td class="patent-data-table-td ">John Albert Kembel</td><td class="patent-data-table-td ">Indexing, sorting, and categorizing application media packages</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8630919">US8630919</a></td><td class="patent-data-table-td patent-date-value">Nov 30, 2012</td><td class="patent-data-table-td patent-date-value">Jan 14, 2014</td><td class="patent-data-table-td ">Cbs Interactive Inc.</td><td class="patent-data-table-td ">System and method for generating a narrative summary</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8666876">US8666876</a></td><td class="patent-data-table-td patent-date-value">Dec 11, 2012</td><td class="patent-data-table-td patent-date-value">Mar 4, 2014</td><td class="patent-data-table-td ">Ebay, Inc.</td><td class="patent-data-table-td ">System and method for creating a customer account</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8682740">US8682740</a></td><td class="patent-data-table-td patent-date-value">Oct 26, 2010</td><td class="patent-data-table-td patent-date-value">Mar 25, 2014</td><td class="patent-data-table-td ">Cbs Interactive Inc.</td><td class="patent-data-table-td ">Systems and methods using a manufacturer line, series, model hierarchy</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8700495">US8700495</a></td><td class="patent-data-table-td patent-date-value">Sep 16, 2011</td><td class="patent-data-table-td patent-date-value">Apr 15, 2014</td><td class="patent-data-table-td ">Cbs Interactive Inc.</td><td class="patent-data-table-td ">Systems and methods for mapping records in a manufacturer line, series, model hierarchy</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8738655">US8738655</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 6, 2011</td><td class="patent-data-table-td patent-date-value">May 27, 2014</td><td class="patent-data-table-td ">Robocast, Inc.</td><td class="patent-data-table-td ">Automated content scheduler and displayer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060218479">US20060218479</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 21, 2005</td><td class="patent-data-table-td patent-date-value">Sep 28, 2006</td><td class="patent-data-table-td ">Damon Torres</td><td class="patent-data-table-td ">Automated content scheduler and displayer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090198774">US20090198774</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 26, 2009</td><td class="patent-data-table-td patent-date-value">Aug 6, 2009</td><td class="patent-data-table-td ">Michael Naimark</td><td class="patent-data-table-td ">Alerting users to items of current interest</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110265007">US20110265007</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 6, 2011</td><td class="patent-data-table-td patent-date-value">Oct 27, 2011</td><td class="patent-data-table-td ">Damon Torres</td><td class="patent-data-table-td ">Automated content scheduler and displayer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120216182">US20120216182</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 27, 2012</td><td class="patent-data-table-td patent-date-value">Aug 23, 2012</td><td class="patent-data-table-td ">Digital River, Inc.</td><td class="patent-data-table-td ">Scheduling of a File Download and Search for Updates</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120226553">US20120226553</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 18, 2012</td><td class="patent-data-table-td patent-date-value">Sep 6, 2012</td><td class="patent-data-table-td ">Damon Torres</td><td class="patent-data-table-td ">Automated content scheduler and displayer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120237920">US20120237920</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 26, 2012</td><td class="patent-data-table-td patent-date-value">Sep 20, 2012</td><td class="patent-data-table-td ">Chi Fai Ho</td><td class="patent-data-table-td ">Learning Method and System Using Detached Sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120259699">US20120259699</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 13, 2012</td><td class="patent-data-table-td patent-date-value">Oct 11, 2012</td><td class="patent-data-table-td ">Damon Torres</td><td class="patent-data-table-td ">Automated content scheduler and displayer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000062145A1?cl=en">WO2000062145A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 7, 2000</td><td class="patent-data-table-td patent-date-value">Oct 19, 2000</td><td class="patent-data-table-td ">Tiburon Technology Inc</td><td class="patent-data-table-td ">System and method for signaling receipt of data on a display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2002019134A1?cl=en">WO2002019134A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 28, 2001</td><td class="patent-data-table-td patent-date-value">Mar 7, 2002</td><td class="patent-data-table-td ">Digitalowl Com Inc</td><td class="patent-data-table-td ">System and methods for the flexible usage of electronic content in heterogeneous distributed environments</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2005111988A2?cl=en">WO2005111988A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 9, 2005</td><td class="patent-data-table-td patent-date-value">Nov 24, 2005</td><td class="patent-data-table-td ">Dotphoto</td><td class="patent-data-table-td ">Internet presentation system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=MLNOBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc715/defs715.htm&usg=AFQjCNEsvPOacMHcG92b6Esmd6a_S2NVkg#C715S730000">715/730</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=MLNOBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc709/defs709.htm&usg=AFQjCNFBXWYqUOVuuxerz7B8cqt9daJk7Q#C709S218000">709/218</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=MLNOBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0013000000">G06F13/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=MLNOBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09F0027000000">G09F27/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=MLNOBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09G0005000000">G09G5/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=MLNOBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G09F27/00">G09F27/00</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G09F27/00</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jun 5, 2012</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 4-8, 11 AND 15-18 IS CONFIRMED. NEW CLAIMS 34-67 ARE ADDED AND DETERMINED TO BE PATENTABLE. CLAIMS 1-3, 9-10, 12-14 AND 19-33 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 24, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110316</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 28, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 24, 2010</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">MERGER;ASSIGNOR:VULCAN PATENTS LLC;REEL/FRAME:024140/0339</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20091223</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">INTERVAL LICENSING LLC,WASHINGTON</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 17, 2007</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 7, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 15, 2005</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">VULCAN PATENTS LLC, WASHINGTON</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INTERVAL RESEARCH CORPORATION;REEL/FRAME:016334/0387</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20041229</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 8, 2003</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 13, 2001</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 29, 1996</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">INTERVAL RESEARCH CORPORATION, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:FREIBERGER, PAUL A.;LEVIN, GOLAN;REED, DAVID P.;AND OTHERS;REEL/FRAME:008009/0238;SIGNING DATES FROM 19960510 TO 19960618</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U37JAHnDwG_QIC2wXUrKbqDBATZ8A\u0026id=MLNOBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U2Z38Pfapu545gZrtu-HwBIHPyNqA\u0026id=MLNOBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2QP7KCIn-Xf7-c0l_gqFoxONiTkA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Attention_manager_for_occupying_the_peri.pdf?id=MLNOBAABERAJ\u0026output=pdf\u0026sig=ACfU3U2YvNNCTdwPrCBinalf-nX8FpqaIA"},"sample_url":"http://www.google.com/patents/reader?id=MLNOBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>