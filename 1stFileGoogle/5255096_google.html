<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5255096 - Video time code synchronized robot control apparatus - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Video time code synchronized robot control apparatus"><meta name="DC.contributor" content="William M. Boyle" scheme="inventor"><meta name="DC.contributor" content="Boyle William M" scheme="assignee"><meta name="DC.date" content="1992-4-10" scheme="dateSubmitted"><meta name="DC.description" content="The stored robot control program defining the path of movement of a robot arm carrying a video camera is synchronized to time code information recorded on a video tape. Video signals from the video camera are recorded on the video tape by a video tape recorder along with time code information from a time code generator. A time code reader decodes the time code information from the video tape or from the video tape recorder and supplies the decoded time code information to a robot controller. The time code information specifying the address of each frame of video signal is synchronized with the robot control program to enable the robot arm to be positioned in the same identical positional coordinates corresponding to the position of the robot arm when a particular frame of video signal was originally generated."><meta name="DC.date" content="1993-10-19" scheme="issued"><meta name="DC.relation" content="US:4503470" scheme="references"><meta name="DC.relation" content="US:4532557" scheme="references"><meta name="DC.relation" content="US:4651203" scheme="references"><meta name="DC.relation" content="US:4789961" scheme="references"><meta name="DC.relation" content="US:4802023" scheme="references"><meta name="DC.relation" content="US:4831316" scheme="references"><meta name="DC.relation" content="US:4837487" scheme="references"><meta name="DC.relation" content="US:4837638" scheme="references"><meta name="DC.relation" content="US:4858033" scheme="references"><meta name="DC.relation" content="US:4939594" scheme="references"><meta name="DC.relation" content="US:5018009" scheme="references"><meta name="DC.relation" content="US:5046022" scheme="references"><meta name="DC.relation" content="US:5063456" scheme="references"><meta name="DC.relation" content="US:5066902" scheme="references"><meta name="citation_patent_number" content="US:5255096"><meta name="citation_patent_application_number" content="US:07/866,446"><link rel="canonical" href="http://www.google.com/patents/US5255096"/><meta property="og:url" content="http://www.google.com/patents/US5255096"/><meta name="title" content="Patent US5255096 - Video time code synchronized robot control apparatus"/><meta name="description" content="The stored robot control program defining the path of movement of a robot arm carrying a video camera is synchronized to time code information recorded on a video tape. Video signals from the video camera are recorded on the video tape by a video tape recorder along with time code information from a time code generator. A time code reader decodes the time code information from the video tape or from the video tape recorder and supplies the decoded time code information to a robot controller. The time code information specifying the address of each frame of video signal is synchronized with the robot control program to enable the robot arm to be positioned in the same identical positional coordinates corresponding to the position of the robot arm when a particular frame of video signal was originally generated."/><meta property="og:title" content="Patent US5255096 - Video time code synchronized robot control apparatus"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("NSfuU-mkDYS7sQSM0YCgDw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("POL"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("NSfuU-mkDYS7sQSM0YCgDw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("POL"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5255096?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5255096"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=Beg2BAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5255096&amp;usg=AFQjCNF8l6MNpN-H2qQK61tm5wsEuQGfhA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5255096.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5255096.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5255096" style="display:none"><span itemprop="description">The stored robot control program defining the path of movement of a robot arm carrying a video camera is synchronized to time code information recorded on a video tape. Video signals from the video camera are recorded on the video tape by a video tape recorder along with time code information from a...</span><span itemprop="url">http://www.google.com/patents/US5255096?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5255096 - Video time code synchronized robot control apparatus</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5255096 - Video time code synchronized robot control apparatus" title="Patent US5255096 - Video time code synchronized robot control apparatus"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5255096 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 07/866,446</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Oct 19, 1993</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Apr 10, 1992</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Apr 10, 1992</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2133552A1">CA2133552A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2133552C">CA2133552C</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE69315997D1">DE69315997D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE69315997T2">DE69315997T2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0635190A1">EP0635190A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0635190A4">EP0635190A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0635190B1">EP0635190B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO1993021735A1">WO1993021735A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">07866446, </span><span class="patent-bibdata-value">866446, </span><span class="patent-bibdata-value">US 5255096 A, </span><span class="patent-bibdata-value">US 5255096A, </span><span class="patent-bibdata-value">US-A-5255096, </span><span class="patent-bibdata-value">US5255096 A, </span><span class="patent-bibdata-value">US5255096A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22William+M.+Boyle%22">William M. Boyle</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Boyle+William+M%22">Boyle William M</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5255096.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5255096.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5255096.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (14),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (17),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (28),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (8)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5255096&usg=AFQjCNHVqW63D9jJIUL7MUyh5GrOZ399XA">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5255096&usg=AFQjCNERBgXCQc3VZxLlyp8HUF3OaC_pzQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5255096A%26KC%3DA%26FT%3DD&usg=AFQjCNHvNCR9teo9OHtq5_tbSlmaOASD6A">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT53782748" lang="EN" load-source="patent-office">Video time code synchronized robot control apparatus</invention-title></span><br><span class="patent-number">US 5255096 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37264645" lang="EN" load-source="patent-office"> <div class="abstract">The stored robot control program defining the path of movement of a robot arm carrying a video camera is synchronized to time code information recorded on a video tape. Video signals from the video camera are recorded on the video tape by a video tape recorder along with time code information from a time code generator. A time code reader decodes the time code information from the video tape or from the video tape recorder and supplies the decoded time code information to a robot controller. The time code information specifying the address of each frame of video signal is synchronized with the robot control program to enable the robot arm to be positioned in the same identical positional coordinates corresponding to the position of the robot arm when a particular frame of video signal was originally generated.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(4)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5255096-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5255096-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5255096-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5255096-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5255096-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5255096-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5255096-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5255096-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(14)</span></span></div><div class="patent-text"><div mxw-id="PCLM4675241" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A video time code synchronized robot control apparatus comprising:<div class="claim-text">a robot including an arm movable through a path of movement;</div> <div class="claim-text">a video camera, mounted on the arm of the robot, for generating video signals during operation of the video camera;</div> <div class="claim-text">time code generator means for generating time code information;</div> <div class="claim-text">video image storing means, responsive to the video signals from the video camera and the time code information from the time code generator means for storing a composite signal formed of the video signals and the time code information on a storage medium;</div> <div class="claim-text">time code reader means, responsive to the composite video signal from the video image storing means, for decoding the time code information for each frame of the composite signal; and</div> <div class="claim-text">robot controller means for controlling the path of movement of the robot arm in accordance with a stored control program, the robot controller means being responsive to the time code information for storing the position coordinates of the robot arm along the path of movement for each distinct time code associated with the video signal on a video signal frame by frame basis and for synchronizing the movement of the robot arm along its predetermined path of movement with the time code information during the generation of video signals and time code information from the storage medium on a frame-by-frame basis.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The apparatus of claim 1 further comprising:<div class="claim-text">monitor means, connected to the video image storing means, for displaying video images from one of the video camera and the composite image recorded on the storage medium.</div> </div>
    </div>
    </div> <div class="claim"> <div num="3" class="claim">
      <div class="claim-text">3. A video time code synchronized robot control apparatus comprising:<div class="claim-text">a robot including an arm movable through a path of movement;</div> <div class="claim-text">a video camera, mounted on the arm of the robot, for generating video signals during movement of the video camera;</div> <div class="claim-text">time code generator means for generating time code information;</div> <div class="claim-text">the video signals from the video camera being output to the time code generator means;</div> <div class="claim-text">video recorder means, responsive to the video signals from the video camera and the time code information from the time code generator means, for recording a composite signal formed of the video signals and the time code information on a recording medium;</div> <div class="claim-text">the time code generator means outputting the video signals and the time code information to the video recorder means;</div> <div class="claim-text">time code reader means, responsive to the composite video signal from the video recorder means, for decoding the time code information for each frame of the composite signal; and</div> <div class="claim-text">robot controller means for controlling the path of movement of the robot arm in accordance with a stored control program, the robot controller means being responsive to the decoded time code information from the time code reader for synchronizing the movement of the robot arm along its predetermined path of movement with the time code information from the time code reader on a frame-by-frame basis.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The apparatus of claim 3 wherein the composite signal from the video tape recorder is input to the time code reader means.</div>
    </div>
    </div> <div class="claim"> <div num="5" class="claim">
      <div class="claim-text">5. A video time code synchronized robot control apparatus comprising:<div class="claim-text">a robot including an arm movable through a path of movement;</div> <div class="claim-text">a video camera, mounted on the arm of the robot, for generating video signals during movement of the video camera;</div> <div class="claim-text">time code generator means for generating time code information;</div> <div class="claim-text">video recorder means, responsive to the video signals from the video camera and the time code information from the time code generator means, for recording a composite signal formed of the video signals and the time code information on a recording medium;</div> <div class="claim-text">the video signals from the video camera being output to the video recorder means;</div> <div class="claim-text">the time code information from the time code generator means being output to the video recorder means;</div> <div class="claim-text">time code reader means, responsive to the composite video signal from the video recorder means, for decoding the time code information for each frame of the composite signal; and</div> <div class="claim-text">robot controller means for controlling the path of movement of the robot arm in accordance with a stored control program, the robot controller means being responsive to the decoded time code information from the time code reader for synchronizing the movement of the robot arm along its predetermined path of movement with the time code information from the time code reader on a frame-by-frame basis.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The apparatus of claim 5 wherein:<div class="claim-text">the composite signal from the video tape recorder is input to the time code reader means.</div> </div>
    </div>
    </div> <div class="claim"> <div num="7" class="claim">
      <div class="claim-text">7. A video time code synchronized robot control apparatus comprising:<div class="claim-text">a robot including an arm movable through a path of movement;</div> <div class="claim-text">a video camera, mounted on the arm of the robot, for generating video signals during movement of the video camera;</div> <div class="claim-text">combined video time code generator and reader means for separately generating time code information and for decoding time code information,</div> <div class="claim-text">video recorder means, responsive to the video signals and the time code information from the combined time code generator and reader means, for recording a composite signal formed of the video signals and the time code information on a recording medium;</div> <div class="claim-text">the time code information being output from the video recorder means to the reader portion of the combined time code generator and reader means; and</div> <div class="claim-text">robot controller means for controlling the path of movement of the robot arm in accordance with a stored control program, the robot controller means being responsive to the decoded time code information from the combined time code generator and reader means for synchronizing the movement of the robot arm along its predetermined path of movement with the time code information from the combined time code generator and reader means on a frame-by-frame basis.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The apparatus of claim 7 wherein the composite signal from the video tape recorder is input to the combined time code generator and reader means for decoding the time code information and for outputting the decoded time code information to the robot controller.</div>
    </div>
    </div> <div class="claim"> <div num="9" class="claim">
      <div class="claim-text">9. A video time code synchronized robot control apparatus comprising:<div class="claim-text">a robot including an arm movable through a path of movement;</div> <div class="claim-text">a video camera, mounted on the arm of the robot, for generating video signals during movement of the video camera;</div> <div class="claim-text">time code generator means for generating time code information;</div> <div class="claim-text">video recorder means, responsive to the video signals from the video camera and the time code information from the time code generator means, for recording a composite signal formed of the video signals and the time code information on a recording medium;</div> <div class="claim-text">time code reader means, responsive to the composite video signal from the video recorder means, for decoding the time code information for each frame of the composite signal; and</div> <div class="claim-text">robot controller means for controlling the path of movement of the robot arm in accordance with a stored control program, the robot controller means being responsive to the decoded time code information from the time code reader for synchronizing the movement of the robot arm along its predetermined path of movement with the time code information from the time code reader on a frame-by-frame basis the robot controller means including:<div class="claim-text">means for identifying the positional coordinate of the robot arm corresponding in time with each frame of video signals generated by the video camera; and</div> <div class="claim-text">the robot controller means further including means for moving the robot arm to the identified positional coordinates corresponding to any frame of video signals as the time code information identifying the any frame of video signals is input thereto from the time code reader means.</div> </div> </div>
    </div>
    </div> <div class="claim"> <div num="10" class="claim">
      <div class="claim-text">10. A method of generating video images comprising:<div class="claim-text">programming a robot to repeatedly move a video camera mounted on the end of a movable arm of the robot through a predetermined path of movement;</div> <div class="claim-text">operating the video camera to generate video signals from the camera during movement of the arm of the robot along the predetermined path of movement;</div> <div class="claim-text">generating video signal frame identification information in conjunction with the generation of video signals on a frame-by-frame basis of the generated video signals;<div class="claim-text">storing the position coordinates of the robot arm along the predetermined path of movement for each distinct one of the video signal frame identification information on a video signal frame-by-frame basis;</div> </div> <div class="claim-text">storing the video signals and the video signal frame identification information as a composite signal on a storage medium on a frame-by-frame basis; and</div> <div class="claim-text">synchronizing the movement of the robot arm along the predetermined path of movement with the video signal frame identification information during the generation of video signals from the storage medium such that the arm of the robot is position by the robot controller in the same position for each frame of video signal from the storage medium as when each frame of video signal was initially generated by the video camera.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The method of claim 10 wherein the step of generating video signal frame identification information comprises the step of:<div class="claim-text">generating time code information for each frame of video signal generated by the video camera.</div> </div>
    </div>
    </div> <div class="claim"> <div num="12" class="claim">
      <div class="claim-text">12. A method of generating video images comprising:<div class="claim-text">programming a robot to repeatedly move an end of a movable arm of the robot through a predetermined path of movement;</div> <div class="claim-text">operating a video camera to generate video signals of visual images along the predetermined path of movement from the camera during movement of the arm of the robot along the predetermined path of movement;</div> <div class="claim-text">storing the position coordinates of the robot arm along the predetermined path of movement for each distinct frame of the video signal generated by the video camera on a video signal frame-by-frame basis;</div> <div class="claim-text">storing the video signals on a storage medium on a video signal frame-by-frame basis; and</div> <div class="claim-text">synchronizing the movement of the robot arm along the predetermined path of movement with each frame of video signal during the generation of stored video signals from the storage medium such that the arm of the robot is positioned by the robot controller in the same position for each frame of video signal operated from the storage medium as when each frame of video signal was initially generated by the video camera.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The method of claim 12 wherein the step of storing the position coordinates of the robot arm further comprises the step of:<div class="claim-text">storing the position coordinates of the robot arm in a memory; and</div> <div class="claim-text">storing with each position coordinate a unique video signal frame identification data.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The method of claim 13 wherein the step of synchronizing further comprises the steps of:<div class="claim-text">generating video signals from the storage medium on a frame-by-frame basis;</div> <div class="claim-text">generating the video frame identification data for each frame of video signal generated from the storage medium;</div> <div class="claim-text">accessing the memory to identify the position coordinates of the robot arm associated with each generated video signal identification data; and</div> <div class="claim-text">moving the robot arm to the identified position coordinates on a video signal frame-by-frame basis as the video signals are generated from the storage medium.</div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES66348651" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p>The present invention relates to robots and, also, to apparatus for composing video source material.</p>
    <p>In the production of audiovisual films, videos, television commercials, movies, and the like, a video camera is used to record video images and/or audio signals on a video tape. The video tape may be carried directly by the camera, as in a video camcorder, or the video images from a video camera may be output to a video tape recorder (VTR) which records the video images on a video tape. The video tape can then be played back to review the recorded images.</p>
    <p>As frequently occurs during the production of audiovisual materials, it is oftentimes necessary to re-shoot some portion of the recorded sequence of images. When this occurs, the video tape must be rewound to the desired position or frame to enable new video images to be recorded over old images or new video images are recorded on a separate tape. After the new and old images are recorded on different tapes, the two video tapes are then edited by merging the desired portions of the two tapes into a single tape to form the desired sequence of video images. A number of video tape editing devices are available to perform such editing operations.</p>
    <p>Time code generators are also well known and are used to generate standardized time codes. Such time codes are developed according to standards set by the SMPTE (Society of Motion Picture and Television Engineers) and the EBU (European Broadcasting Union). The time codes are formed of a binary code corresponding to hours, minutes, seconds and frame number of each frame of a video signal starting from a zero point and continuing during the entire video image running time. The time code information is encoded onto a recording medium by a video tape recorder on a separate track from the tracks containing the video information for each frame of the video signal. The recorded time code information acts as an address to identify each frame to permit electronic editing of video tapes.</p>
    <p>During editing, time code readers are employed to locate a particular frame on a video tape. However, such editing is a time consuming process requiring a considerable amount of skill and costly time code generators, time code readers and tape synchronizers which result in high post production costs to form a complete audiovisual tape.</p>
    <p>As described above, it is often necessary during the production of audiovisual material to re-shoot the same sequence of images many times before a final sequence is obtained. The camera and/or the object(s) being filmed must be moved through the same path of movement with only the desired variations being introduced in each separate re-shoot. Various devices have been employed to repeatedly move an object and/or camera through a predetermined path.</p>
    <p>Robots have been developed, primarily for industrial applications, to move a tool, etc., mounted at the end of an end effector on a robot arm in a predetermined multi-axis path of movement according to a stored program executed by a robot controller.</p>
    <p>It is known to mount a camera on the movable arm of a robot so as to be able to repeatedly move the camera through a predetermined path of movement while the camera is operated to record a sequence of video images. However, heretofore, there has been no known attempt to synchronize the movement of the robot as it executes its stored control program with the advance or reverse movement of a video recording medium storing video images in a predetermined sequence to enable the robot and the recording medium to be moved in synchronization to a predetermined position corresponding to a particular frame on the video tape with the robot being positioned in the same position as it was while the image was shot. The different speeds of the film transport in the video camera and/or video tape recorder and the motors controlling the position and speed of movement of the robot arm have made such synchronization difficult and have resulted in hit or miss efforts to position a robot in a particular position in multiple axes corresponding to a particular robot position in a particular frame on a video tape.</p>
    <p>Thus, it would be desirable to provide an apparatus for synchronizing robot or machine movement with a video recording medium such that the robot or machine can be positioned in the same position as recorded on each frame of the video tape. It would also be desirable to provide an apparatus for use with a robot or machine and a video recording apparatus which enables the robot arm to be moved to any position corresponding to a particular frame of a recorded video image while remaining synchronized in time with the video recording.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention is a video time code synchronized robot control apparatus which synchronizes the position of a robot or other automated machine having a camera mounted on a movable robot arm with the frame-by-frame images on a video recording medium.</p>
    <p>The apparatus includes a robot or machine having an arm movable through a path of movement. A video camera is mounted on the arm and generates video signals during movement of the camera along the path of movement of the arm. A time code generator means generates time code information for use with the video signals from the video camera. A video tape recorder in response to the video signals from the video camera and the time code information from the time code generator means records a composite video signal formed of the video signal from the video camera and the time code information from the time code generator onto a video recording medium.</p>
    <p>A time code reader means is responsive to the composite video signal output from the video tape recorder and decodes the time code information. The decoded time code information is input to a robot controller means which controls the path of movement of the robot arm in accordance with a taught and/or stored program. The robot controller, in response to the decoded time code information from the time code reader, synchronizes the movement of the robot arm along its programmed path of movement with the time code information on a video image frame-by-frame basis.</p>
    <p>In one embodiment, the video signals from the video camera are input to a time code generator which generates time code information for each frame of video signals. The video signals and the time code information are then output to a video tape recorder which records a composite signal of the video signal and the time code information onto a video tape recording medium. A video monitor may also be provided and controlled by the video tape recorder for displaying the video images. On a real time basis or during playback of the video tape in the video tape recorder, the time code information on the video tape is decoded by a time code reader which outputs the decoded time code information to the robot controller. In another embodiment, the output of the video camera and the time code information from the time code generator are separately input to a video tape recorder which records the composite signal formed of the video images and the time code information onto separate tracks of a video recording medium or tape. The output from the video tape recorder is decoded by the time code reader and input to the robot controller as in the first embodiment.</p>
    <p>In yet another embodiment, the video signals from the video camera are input to a combined time code qenerator/reader. The time code generator portion of the combined time code generator/reader generates time code information and outputs the video images and the generated time codes to a video tape recorder which stores the video images and the time code information on a video tape. The output of the video tape recorder is input to the combined time code generator/reader which decodes the time code information and outputs the decoded time code information to the robot controller.</p>
    <p>The decoded time code information from the time code reader is synchronized with the multi-axis positional coordinates of the robot control program by any of a number of different means. In an exemplary embodiment, the robot controller, upon receiving the decoded time code information, generates and stores in memory the time code information for each frame of the video signal and the multi-axis robot arm positional coordinates corresponding to each frame. In this manner, upon receipt of a particular time code defining a particular frame of the video signal, the robot controller can position the robot arm in the positional coordinates corresponding to those at which the particular video image was originally taken.</p>
    <p>The unique video time code synchronized robot control apparatus of the present invention simplifies the production of audiovisual materials by enabling the video images stored frame-by-frame on a video tape to be coordinated in time with the positional coordinates of a multi-axis robot controller. This enables the robot controller to move its arm carrying the video camera to the same position in which a particular frame of video signals was generated. This simplifies the editing of video tapes by enabling the robot to be moved to any desired position in synchronization with the video images and new video images generated and recorded onto the same tape. This also simplifies post production editing of multiple video tapes and insures that the robot, the robot arm and the video camera carried by the robot arm are in the same identical position corresponding to each frame of the video signals.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWING</heading> <p>The various features, advantages and other uses of the present invention will become more apparent by referring to the following detailed description and drawing in which:</p>
    <p>FIG. 1 is a perspective view of a robot apparatus designed to move a video camera through a predetermined, programmed path of movement;</p>
    <p>FIG. 2 is a perspective view of another embodiment of a robot apparatus usable with the present invention;</p>
    <p>FIG. 3 is a block diagram of one embodiment of the apparatus of the present invention;</p>
    <p>FIG. 4 is a block diagram of another embodiment of the apparatus of the present invention; and</p>
    <p>FIG. 5 is a block diagram of yet another embodiment of the apparatus of the present invention.</p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>Referring now to FIG. 1, there is depicted one embodiment of a robot control apparatus usable with the present invention. It will be understood that any type of robot, such as a gantry-type robot 10 shown in FIG. 1, as well as pedestal robots may also be used. Further, the term "robot" is also meant to include any machine which is capable of repeatedly moving an arm or member thereof along a predetermined path of movement.</p>
    <p>By way of example only, the robot 10 is an AEG 8000 Series gantry-type robot. This robot I0 includes four frame members, only two of which 12 and 14 are shown in FIG. 1. The frame members 12 and 14 are supported above a floor by a plurality of upright legs 16.</p>
    <p>The frame members 12 and 14 are disposed in parallel and spaced apart. The frame members 12 and 14 are formed as channel-like members which slidably support horizontal sliders 18 and 20, respectively. The horizontal sliders 18 and 20 are slidably disposed in the frame members 12 and 14, respectively, and are movable along an axis, hereafter denoted as the X axis. A horizontal slider drive means is provided for driving the horizontal sliders 18 and 20 in a bi-directional manner along the frame members 12 and 14. By way of example only, the drive means comprises an electric motor 22 mounted at one end of the frame member 14. The output shaft of the motor 22 is mounted in a bearing and engages a drive pulley, not shown. A similar drive pulley is mounted in the frame member 12 and is connected to the output shaft of the motor by a coupling shaft 24. A timing belt, not shown, is mounted in each of the frame members 12 and 14 and is operably coupled to the drive pulleys associated with the motor 22. Rotation of the output shaft and drive pulleys by the motor 22 results in movement of the timing belt which drives the horizontal sliders 18 and 20 reciprocatingly along the frame members 12 and 14.</p>
    <p>A pair of spaced, channel-like cross members 28 and 30 are mounted at opposite ends to the horizontal sliders 18 and 20 and span the horizontal sliders 18 and 20. The cross members 28 and 30 extend along a Y axis perpendicular to the X axis defined by the frame members 12 and 14. A carriage 32 is slidably mounted on the cross members 28 and 30 and is reciprocatingly driven along the cross members 28 and 30 by a Y axis drive motor 34 mounted on one end of the cross members 28 and 30. A timing belt extends through the cross member 28 and is reciprocatingly driven through a pulley by the Y axis drive motor 34. The timing belt is coupled to the carriage 32 and drives the carriage 32 reciprocatingly along the Y axis upon activation of the Y axis drive motor 34.</p>
    <p>A third or Z axis drive motor 40 is mounted on the carriage 32 and reciprocatingly moves a Z axis channel 42 substantially vertically through the carriage 32.</p>
    <p>An end effector 50 is slidably mounted on the Z axis channel 42 and is vertically movable along with the channel 42 in response to bi-directional rotation of the output shaft of the Z axis motor 40. A conventional video camera 52 is mounted on the end effector and is moved by the robot apparatus 10 along a programmed multi-axis path of movement.</p>
    <p>The electrical control signals to the various drive motors 22, 34 and 40 as well as feedback signals, etc., pass through a junction box 54 and are supplied by electrical conductors, cables, etc., mounted in cable carriers 26 and 36 to a robot controller means 56. Any conventional robot controller 56 may be employed, such as a Modicon 3240/3220 Flexible Automation Controller, for example only. Such a robot controller includes a central processing unit or computer which executes a control program stored in a memory. A keyboard and a display, not shown, are also provided with the robot controller 56. As is conventional, such robot controllers 56 are adapted for learning a particular path of movement of the end effector 50. In such a learning or teach mode, the end effector 50 is manually moved or jogged through a predetermined multi-axis path of movement and each step or sequence of steps are input to the robot controller which stores the multi-axis positional coordinates of the robot arm, i.e., the Z axis channel 42, at each step. The sequence of steps thus defines the predetermined path of movement of the end effector 50 and the camera 52 mounted on the arm or Z axis channel 42.</p>
    <p>FIG. 2 depicts another embodiment of a robot 60 usable with the present invention. The robot 60 includes the same gantry-type robot described above and shown in FIG. 1. However, in this embodiment the Z axis channel 42 is replaced by a second robot 62. The second robot 62 is mounted to the Y axis carriage 32 and thus is movable by the gantry robot 10 along the X and Z axes under the control of the robot controller 56.</p>
    <p>The second robot 62 may be any type of pedestal-type robot, such as a Motoman K10 robot sold by Yaskawa Electric Mfg. Co., Ltd. The robot 62 includes a movable arm 64 to which a video camera 52 is mounted by means of a bracket 66. The robot 62 and the movable arm 64, which are controlled by the same robot controller 56 controlling the gantry robot 10, provides a greater freedom of movement for the camera 52 in conjunction with the X and Y axis movements provided by the gantry robot. In both of the robots 10 and 62, a rotatable end effector may be mounted on the robot arm to support the video camera 52 and provide an additional axis of movement to the video camera 52.</p>
    <p>Referring now to FIG. 3, there is depicted one embodiment of a video time code synchronization control apparatus which coordinates video image time codes with the positional coordinates stored in the robot controller 56 to coordinate the multi-axis position of the robot 56 with the video images recorded by the video camera 52. As shown in FIG. 3, the video signals output from the video camera 52 during movement of the camera 52 are input to a conventional time code generator means 70, such as a time code generator Model No. CDI-716A sold by Cipher Digital. As is well known, the time code generator means 70 generates a binary time code for each frame of video signals from the camera 52. The time code signal is in a standardized format as established by SMPTE (Society of Motion Picture and Television Engineers) or the EBU (European Broadcasting Union). The binary time code acts as an address for each frame of the video image or signals and specifies in encoded form the hour, minutes, seconds and frame number of running time of each frame of the sequence of video images from a zero or start frame. In the SMPTE time code format, a new frame of video signals is generated every 1/30th of a second. In the EBU format, each video signal frame is generated every 1/24th of a second. Other formats, such as 24 frame per second motion picture film formats, are also possible with the present invention.</p>
    <p>In the embodiment shown in FIG. 3, the video signals from the video camera 52 and the time code generated by the time code generator means 70 are separately output from the time code generator means 70 to a conventional video tape recorder (VTR) 72. The video tape recorder 72 may be any suitable type of video tape recorder, such as a broadcasting-type video tape recorder. Such a video tape recorder 72 records a composite signal on a suitable video image recording medium, such as a video tape, which is formed of the video images and the associated time code on a frame-by-frame basis on separate tracks.</p>
    <p>A monitor 74 may optionally be connected to the video tape recorder 72 to display the video images from the camera 52 in real time or the video images recorded on the video tape during playback.</p>
    <p>A time code reader means 76 is connected to the video tape recorder 72 and receives time code information from the video tape recorder 72 on a frame-by-frame basis. The time code reader means 76, as is conventional, decodes the time code information and outputs, according to the present invention, the decoded time code information to the robot controller 56. The output signals from the time code reader means 76, denoted generally by reference number 78, may be in RS232 serial or RS422 parallel format. Further, such output signals from the time code reader means 76 may be in the specified form of a serial digital interface standard for communicating video equipment with digital equipment.</p>
    <p>An alternate embodiment of the present invention is shown in FIG. 4 in which the same components as shown in FIG. 3 are connected in a different configuration, but provide the same result. As shown in FIG. 4, the video signals from the video camera 52 and the time code information from the time code generator means 70 are separately input to the video tape recorder 72. The video tape recorder 72 forms a composite signal of the video images and the time code information on a frame-by-frame basis and records the video signals and the time code information on separate tracks on a video tape recording medium in a normal manner. The recorded time codes are then decoded on a frame-by-frame basis by the time code reader means 76 and output to the robot controller 56.</p>
    <p>Another embodiment is shown in FIG. 5 in which the video signals from the video camera 52 are input to a combined time code generator/reader 80. The time code generator/reader 80 may be, by way of example only, a time code reader/generator event controller, Model No. CDI-750, sold by Cipher Digital. In the time code generator portion of the time code generator/reader 80, time code information is generated for each frame of video signals received from the video camera 52. The video signals and the time code information are output to the video tape recorder 72 on a frame-by-frame basis. The video tape recorder 72 records both signals on a video tape recording medium. Time code information on a frame-by-frame basis is output from the video tape recorder 72 to the reader portion of the combined time code generator/reader 80 the time code information and outputs the decoded time code signals to the robot controller 56.</p>
    <p>An alternate embodiment of the apparatus shown in FIG. 5 may also be provided. In the alternate embodiment, as shown in FIG. 4, the outputs of the video camera 52 and time code information from the combined time code generator/reader 80 may be separate input to the video tape recorder 72 to form the composite signal which is recorded on the video tape by the video tape recorder 72.</p>
    <p>In a preferred sequence of operations, it will be assumed that the robot 10 or 60 has been moved through a teach mode to learn a desired multi-axis path of movement, which path of movement is stored by positional coordinates in the memory of the robot controller 56. With the robots 10 or 10 and 60 positioned at their respective start positions, execution of the control program by the robot controller 56 will cause the robots 10 or 10 and 60 to move the robot arm through its predetermined path of movement thereby moving the video camera 52 along the same predetermined path of movement. Activation of the video camera 52 during such movement will cause a series of video signals on a frame-by-frame basis to be generated and output from the video camera 52.</p>
    <p>Using the apparatus shown in FIG. 3, the video signals from the video camera 56 will be input to the time code generator means 70 which will generate time code information for each frame of video signal. The video signals and the time code information from the time code generator 70 are output to the video tape recorder 72 which records a composite signal containing the video signals and the time code information on a suitable video tape recording medium on a frame-by-frame basis.</p>
    <p>In real time, while the video camera 52 is being moved through its predetermined path of movement or during playback, the time code information recorded by the video tape recorder 72 on the video tape is output to the time code reader means 76 which decodes the time code information and supplies the decoded time code information to the robot controller 56.</p>
    <p>According to the present invention, the robot controller 56 via a suitable software control program, circuitry or via an external unit communicating with the robot controller 56, coordinates the positional coordinates of the robot control program with each frame of video signal as defined by the time code information received from the time code reader means 76. This may be implemented, by example only, by the robot controller 56 which divides each step or path of movement between two points into a number of increments, each at a time period corresponding to the time interval of each frame of video images or signals, i.e., every 1/30th or 1/24th second. The robot controller 56 learns and stores in memory the multi-axis positional coordinates of the robot arm at each 1/30th or 1/24th of a second. This links the multi-axis positional coordinates of the robot with the time code defining each frame of video signal.</p>
    <p>After the robot controller 56 has completed the control program and moved the robot 10 or 60 through its predetermined path of movement, the synchronizing information synchronizing the time code with the positional coordinates of the robot corresponding to each frame of video signal may then be utilized to move the robot controller to any desired position in its predetermined path of movement during advance or rewind of the video tape on which the video signals have been recorded by the video tape recorder 72. As each frame of video signal on the video tape has a specific time code associated therewith, the robot controller 56 via the learned positional coordinates in memory can determine the multi-axis coordinates of the robot 10 or 60 corresponding to each time code of video information and thereby move the robot 10 or 60 to such coordinates as each frame of video information advances through the video tape recorder 72. The video tape recorder 72 may be stopped at any frame at which time the robot 10 or 60 will be precisely positioned in the same positional coordinates as it was when the video image recorded on the particular frame on the video tape was first taken. This simplifies editing since any portion of the video image on the video tape may be re-shot starting with the position of the robot at any position along its predetermined path of movement.</p>
    <p>In summary, there has been disclosed a video time code synchronized robot control apparatus which coordinates time code information associated with each frame of a video image recorded on a video tape with the stored positional coordinates of a robot apparatus to enable the robot apparatus to be moved to a position corresponding to the position of its components when a particular frame of video image was first taken. Editing of the video tape as required to re-shoot a particular portion of an overall image sequence may easily be done on the same tape by moving the robot to any predetermined position along its path of movement corresponding to a particular frame of video image. The succeeding portion of the robot movement and/or the object being imaged may then be varied and new video images generated as the robot moves through its existing path of movement or a revised path of movement.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4503470">US4503470</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 20, 1982</td><td class="patent-data-table-td patent-date-value">Mar 5, 1985</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">For a tape recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4532557">US4532557</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 8, 1983</td><td class="patent-data-table-td patent-date-value">Jul 30, 1985</td><td class="patent-data-table-td ">Ampex Corporation</td><td class="patent-data-table-td ">Synchronous programmable parallel-to-serial data converter and a programmable longitudinal time code generator utilizing the converter</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4651203">US4651203</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 29, 1985</td><td class="patent-data-table-td patent-date-value">Mar 17, 1987</td><td class="patent-data-table-td ">At&amp;T Technologies, Inc.</td><td class="patent-data-table-td ">Video controlled article positioning system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4789961">US4789961</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 22, 1986</td><td class="patent-data-table-td patent-date-value">Dec 6, 1988</td><td class="patent-data-table-td ">Kirsch Technologies, Inc.</td><td class="patent-data-table-td ">Computer memory back-up with automatic tape positioning</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4802023">US4802023</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 21, 1986</td><td class="patent-data-table-td patent-date-value">Jan 31, 1989</td><td class="patent-data-table-td ">Ampex Corporation</td><td class="patent-data-table-td ">System for reading and writing vertical interval time code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4831316">US4831316</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 1, 1987</td><td class="patent-data-table-td patent-date-value">May 16, 1989</td><td class="patent-data-table-td ">Toyota Jidosha Kabushiki Kaisha</td><td class="patent-data-table-td ">Control system for an industrial robot with a foresight function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4837487">US4837487</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 26, 1987</td><td class="patent-data-table-td patent-date-value">Jun 6, 1989</td><td class="patent-data-table-td ">Fanuc Ltd.</td><td class="patent-data-table-td ">System for coupling a visual sensor processor and a robot controller</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4837638">US4837638</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 6, 1987</td><td class="patent-data-table-td patent-date-value">Jun 6, 1989</td><td class="patent-data-table-td ">Fullwood John W</td><td class="patent-data-table-td ">Video tape editing system with vertical interval time code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4858033">US4858033</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 18, 1987</td><td class="patent-data-table-td patent-date-value">Aug 15, 1989</td><td class="patent-data-table-td ">Chippendale Arthur J</td><td class="patent-data-table-td ">Apparatus for pacing, queing and equipment control in audiovisual work</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4939594">US4939594</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 16, 1989</td><td class="patent-data-table-td patent-date-value">Jul 3, 1990</td><td class="patent-data-table-td ">Lex Computer And Management Corporation</td><td class="patent-data-table-td ">Method and apparatus for improved storage addressing of video source material</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5018009">US5018009</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 25, 1990</td><td class="patent-data-table-td patent-date-value">May 21, 1991</td><td class="patent-data-table-td ">Messerschmitt-Bolkow-Blohm Gmbh</td><td class="patent-data-table-td ">Arrangement for a remote-controlled track-guided picture transmission</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5046022">US5046022</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 10, 1988</td><td class="patent-data-table-td patent-date-value">Sep 3, 1991</td><td class="patent-data-table-td ">The Regents Of The University Of Michigan</td><td class="patent-data-table-td ">Tele-autonomous system and method employing time/position synchrony/desynchrony</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5063456">US5063456</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 3, 1989</td><td class="patent-data-table-td patent-date-value">Nov 5, 1991</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Video signal processor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5066902">US5066902</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 30, 1989</td><td class="patent-data-table-td patent-date-value">Nov 19, 1991</td><td class="patent-data-table-td ">Fanuc Ltd</td><td class="patent-data-table-td ">Automatic nominal data setting method in a visual sensor system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5403140">US5403140</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 13, 1993</td><td class="patent-data-table-td patent-date-value">Apr 4, 1995</td><td class="patent-data-table-td ">Storage Technology Corporation</td><td class="patent-data-table-td ">Dynamic sweeping mechanism for a line scan camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5528514">US5528514</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 7, 1995</td><td class="patent-data-table-td patent-date-value">Jun 18, 1996</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Luminance transition coding method for software motion video compression/decompression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5784282">US5784282</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 10, 1994</td><td class="patent-data-table-td patent-date-value">Jul 21, 1998</td><td class="patent-data-table-td ">Bertin &amp; Cie</td><td class="patent-data-table-td ">Method and apparatus for identifying the position in three dimensions of a movable object such as a sensor or a tool carried by a robot</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6611617">US6611617</a></td><td class="patent-data-table-td patent-date-value">Jul 25, 1996</td><td class="patent-data-table-td patent-date-value">Aug 26, 2003</td><td class="patent-data-table-td ">Stephen James Crampton</td><td class="patent-data-table-td ">Scanning apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7310439">US7310439</a></td><td class="patent-data-table-td patent-date-value">Jul 29, 2002</td><td class="patent-data-table-td patent-date-value">Dec 18, 2007</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">Robot having an imaging capability</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7313264">US7313264</a></td><td class="patent-data-table-td patent-date-value">Jun 20, 2003</td><td class="patent-data-table-td patent-date-value">Dec 25, 2007</td><td class="patent-data-table-td ">3D Scanners Limited</td><td class="patent-data-table-td ">Scanning apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7814037">US7814037</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 4, 2006</td><td class="patent-data-table-td patent-date-value">Oct 12, 2010</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Information processing apparatus and method, and program for teaching an action to a device in a time-series pattern</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8010233">US8010233</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 2, 2010</td><td class="patent-data-table-td patent-date-value">Aug 30, 2011</td><td class="patent-data-table-td ">Fanuc Ltd.</td><td class="patent-data-table-td ">Image processor for robot system and robot system including the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8326460">US8326460</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 27, 2011</td><td class="patent-data-table-td patent-date-value">Dec 4, 2012</td><td class="patent-data-table-td ">Fanuc Corporation</td><td class="patent-data-table-td ">Robot system comprising visual sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8421870">US8421870</a></td><td class="patent-data-table-td patent-date-value">Aug 25, 2010</td><td class="patent-data-table-td patent-date-value">Apr 16, 2013</td><td class="patent-data-table-td ">Electronics And Telecommunications Research Institute</td><td class="patent-data-table-td ">Method and apparatus for automatic control of multiple cameras</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8520999">US8520999</a></td><td class="patent-data-table-td patent-date-value">Nov 24, 2009</td><td class="patent-data-table-td patent-date-value">Aug 27, 2013</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Camera event logger</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080316368">US20080316368</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 7, 2006</td><td class="patent-data-table-td patent-date-value">Dec 25, 2008</td><td class="patent-data-table-td ">Kuka Roboter Gmbh</td><td class="patent-data-table-td ">Method and Device For Moving a Camera Disposed on a Pan/Tilt Head Long a Given Trajectory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110218675">US20110218675</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 27, 2011</td><td class="patent-data-table-td patent-date-value">Sep 8, 2011</td><td class="patent-data-table-td ">Fanuc Corporation</td><td class="patent-data-table-td ">Robot system comprising visual sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE43895">USRE43895</a></td><td class="patent-data-table-td patent-date-value">Dec 24, 2009</td><td class="patent-data-table-td patent-date-value">Jan 1, 2013</td><td class="patent-data-table-td ">3D Scanners Limited</td><td class="patent-data-table-td ">Scanning apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1202572A2?cl=en">EP1202572A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 22, 2001</td><td class="patent-data-table-td patent-date-value">May 2, 2002</td><td class="patent-data-table-td ">Alcatel</td><td class="patent-data-table-td ">Picture monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1219380A2?cl=en">EP1219380A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 21, 2001</td><td class="patent-data-table-td patent-date-value">Jul 3, 2002</td><td class="patent-data-table-td ">Kawasaki Jukogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">Laser welding method and laser welding apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1997022918A1?cl=en">WO1997022918A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 20, 1996</td><td class="patent-data-table-td patent-date-value">Jun 26, 1997</td><td class="patent-data-table-td ">Mediamaxx Inc</td><td class="patent-data-table-td ">Computer-controlled system for producing three-dimensional navigable photographs of areas and method thereof</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S095000">348/95</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348SE07088">348/E07.088</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspcG9B/defsG9B.htm&usg=AFQjCNE1uzWUMUoBoyPG8UViGilZBwVzaQ#CG9BS027044">G9B/27.044</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspcG9B/defsG9B.htm&usg=AFQjCNE1uzWUMUoBoyPG8UViGilZBwVzaQ#CG9BS027017">G9B/27.017</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspcG9B/defsG9B.htm&usg=AFQjCNE1uzWUMUoBoyPG8UViGilZBwVzaQ#CG9BS027009">G9B/27.009</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc700/defs700.htm&usg=AFQjCNHrBgWJUqFreK-ZW80HFPO-10C3Kw#C700S259000">700/259</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S119000">348/119</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspcG9B/defsG9B.htm&usg=AFQjCNE1uzWUMUoBoyPG8UViGilZBwVzaQ#CG9BS027006">G9B/27.006</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc386/defs386.htm&usg=AFQjCNHoCRy3A8wUXs-nnWGWsV5S8kt9nQ#C386S241000">386/241</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G11B0027320000">G11B27/32</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G05D0003120000">G05D3/12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=B25J0013080000">B25J13/08</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=B25J0009100000">B25J9/10</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G11B0027029000">G11B27/029</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G11B0027024000">G11B27/024</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007180000">H04N7/18</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G11B0027100000">G11B27/10</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/10">G11B27/10</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/029">G11B27/029</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/024">G11B27/024</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/323">G11B27/323</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N7/185">H04N7/185</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Beg2BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B2220/90">G11B2220/90</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G11B27/029</span>, <span class="nested-value">G11B27/024</span>, <span class="nested-value">G11B27/32B1</span>, <span class="nested-value">H04N7/18D2</span>, <span class="nested-value">G11B27/10</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jan 1, 2008</td><td class="patent-data-table-td ">B2</td><td class="patent-data-table-td ">Reexamination certificate second reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-14 IS CONFIRMED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 24, 2005</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20050404</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 30, 2005</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 15, 2001</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 12, 2001</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 23, 1997</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 14, 1997</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 11, 1997</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19970203</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1pDzYWFC8s4tW46bgVt_yHFZ5dmA\u0026id=Beg2BAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3xYnJbdfqr_CchAxpwb5uuuV9l0Q\u0026id=Beg2BAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1l8QdWYpvBf-Ndbj_lns2zvrZwLw","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Video_time_code_synchronized_robot_contr.pdf?id=Beg2BAABERAJ\u0026output=pdf\u0026sig=ACfU3U0IhajOo7R_ZN-CpZQdswjhjtqu-A"},"sample_url":"http://www.google.com/patents/reader?id=Beg2BAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>