<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7551172 - Sending three-dimensional images over a network - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Sending three-dimensional images over a network"><meta name="DC.contributor" content="Ronnie Yaron" scheme="inventor"><meta name="DC.contributor" content="Ofer Shor" scheme="inventor"><meta name="DC.contributor" content="Skyline Software Systems, Inc." scheme="assignee"><meta name="DC.date" content="2006-6-2" scheme="dateSubmitted"><meta name="DC.description" content="A benefit is obtained for sending digital information over a network. The digital information is representative of three-dimensional images which include photographic images. The receiving computer renders the images from the received digital information, and a viewer at the receiving computer can interactively choose a viewpoint or perspective to view the images on a display of the receiving computer. The benefit to the sender can be monetary compensation and/or increased recognition of the sender, for example."><meta name="DC.date" content="2009-6-23" scheme="issued"><meta name="DC.relation" content="DE:19549306:A1" scheme="references"><meta name="DC.relation" content="US:3757037" scheme="references"><meta name="DC.relation" content="US:3984671" scheme="references"><meta name="DC.relation" content="US:4055004" scheme="references"><meta name="DC.relation" content="US:4070705" scheme="references"><meta name="DC.relation" content="US:4177579" scheme="references"><meta name="DC.relation" content="US:4205341" scheme="references"><meta name="DC.relation" content="US:4213252" scheme="references"><meta name="DC.relation" content="US:4225850" scheme="references"><meta name="DC.relation" content="US:4240108" scheme="references"><meta name="DC.relation" content="US:4281344" scheme="references"><meta name="DC.relation" content="US:4319267" scheme="references"><meta name="DC.relation" content="US:4343037" scheme="references"><meta name="DC.relation" content="US:4359733" scheme="references"><meta name="DC.relation" content="US:4360876" scheme="references"><meta name="DC.relation" content="US:4366475" scheme="references"><meta name="DC.relation" content="US:4384338" scheme="references"><meta name="DC.relation" content="US:4398171" scheme="references"><meta name="DC.relation" content="US:4414628" scheme="references"><meta name="DC.relation" content="US:4481584" scheme="references"><meta name="DC.relation" content="US:4484192" scheme="references"><meta name="DC.relation" content="US:4489389" scheme="references"><meta name="DC.relation" content="US:4504913" scheme="references"><meta name="DC.relation" content="US:4513377" scheme="references"><meta name="DC.relation" content="US:4514810" scheme="references"><meta name="DC.relation" content="US:4520506" scheme="references"><meta name="DC.relation" content="US:4527155" scheme="references"><meta name="DC.relation" content="US:4532514" scheme="references"><meta name="DC.relation" content="US:4543572" scheme="references"><meta name="DC.relation" content="US:4550317" scheme="references"><meta name="DC.relation" content="US:4615013" scheme="references"><meta name="DC.relation" content="US:4766556" scheme="references"><meta name="DC.relation" content="US:4821212" scheme="references"><meta name="DC.relation" content="US:4855934" scheme="references"><meta name="DC.relation" content="US:4888713" scheme="references"><meta name="DC.relation" content="US:4931954" scheme="references"><meta name="DC.relation" content="US:4935879" scheme="references"><meta name="DC.relation" content="US:4974176" scheme="references"><meta name="DC.relation" content="US:4994989" scheme="references"><meta name="DC.relation" content="US:5051929" scheme="references"><meta name="DC.relation" content="US:5128870" scheme="references"><meta name="DC.relation" content="US:5153936" scheme="references"><meta name="DC.relation" content="US:5261041" scheme="references"><meta name="DC.relation" content="US:5265176" scheme="references"><meta name="DC.relation" content="US:5299300" scheme="references"><meta name="DC.relation" content="US:5325472" scheme="references"><meta name="DC.relation" content="US:5327509" scheme="references"><meta name="DC.relation" content="US:5394516" scheme="references"><meta name="DC.relation" content="US:5420969" scheme="references"><meta name="DC.relation" content="US:5428715" scheme="references"><meta name="DC.relation" content="US:5434966" scheme="references"><meta name="DC.relation" content="US:5467444" scheme="references"><meta name="DC.relation" content="US:5471563" scheme="references"><meta name="DC.relation" content="US:5499194" scheme="references"><meta name="DC.relation" content="US:5502798" scheme="references"><meta name="DC.relation" content="US:5515482" scheme="references"><meta name="DC.relation" content="US:5550960" scheme="references"><meta name="DC.relation" content="US:5555354" scheme="references"><meta name="DC.relation" content="US:5559860" scheme="references"><meta name="DC.relation" content="US:5561746" scheme="references"><meta name="DC.relation" content="US:5577174" scheme="references"><meta name="DC.relation" content="US:5579456" scheme="references"><meta name="DC.relation" content="US:5586233" scheme="references"><meta name="DC.relation" content="US:5586246" scheme="references"><meta name="DC.relation" content="US:5594846" scheme="references"><meta name="DC.relation" content="US:5608410" scheme="references"><meta name="DC.relation" content="US:5636334" scheme="references"><meta name="DC.relation" content="US:5657432" scheme="references"><meta name="DC.relation" content="US:5675720" scheme="references"><meta name="DC.relation" content="US:5680474" scheme="references"><meta name="DC.relation" content="US:5687307" scheme="references"><meta name="DC.relation" content="US:5694530" scheme="references"><meta name="DC.relation" content="US:5701403" scheme="references"><meta name="DC.relation" content="US:5726689" scheme="references"><meta name="DC.relation" content="US:5745665" scheme="references"><meta name="DC.relation" content="US:5764233" scheme="references"><meta name="DC.relation" content="US:5774132" scheme="references"><meta name="DC.relation" content="US:5782762" scheme="references"><meta name="DC.relation" content="US:5784301" scheme="references"><meta name="DC.relation" content="US:5828382" scheme="references"><meta name="DC.relation" content="US:5831875" scheme="references"><meta name="DC.relation" content="US:5847712" scheme="references"><meta name="DC.relation" content="US:5847717" scheme="references"><meta name="DC.relation" content="US:5850226" scheme="references"><meta name="DC.relation" content="US:5856829" scheme="references"><meta name="DC.relation" content="US:5860077" scheme="references"><meta name="DC.relation" content="US:5864640" scheme="references"><meta name="DC.relation" content="US:5867166" scheme="references"><meta name="DC.relation" content="US:5870105" scheme="references"><meta name="DC.relation" content="US:5870307" scheme="references"><meta name="DC.relation" content="US:6058397" scheme="references"><meta name="DC.relation" content="US:6321158" scheme="references"><meta name="citation_reference" content="Andrews, Matthews, et al., Improved Methods for Hiding Latency in High Bandwidth Networks (Extended Abstract), ACM Press, Jun. 1996, p. 53-61."><meta name="citation_reference" content="Astheimer, Peter, et al., &quot;Level-of-Detail Generation and Its Application in Virtual Reality,&quot; Virtual Reality Software &amp; Technology, Aug. 1994, p. 299-309."><meta name="citation_reference" content="B. Watson et al, &quot;Effects of Variation in System Responsiveness on User Performance in Virtual Environments,&quot; The Journal of the Human Factors &amp; Ergonomics Society, p. 405-413."><meta name="citation_reference" content="B. Watson, et al., &quot;Evaluation of the Effects of Frame Time Variation on VR Task Performance,&quot; IEEE 1997 Virtual Reality Annual International Symposium, Mar. 1-May 1997, p. 38-44."><meta name="citation_reference" content="B. Watson, et al., &quot;Managing Level of Detail Through Head-Tracked Peripheral Degradation: A Model and Resulting Design Principles,&quot; ACM VRST &#39;97, 1997, p. 59-63."><meta name="citation_reference" content="B.L. Tierney, et al., &quot;Using High Speed Networks to Enable Distributed parallel Image server Systems,&quot; IEEE, 1994, p. 610-619."><meta name="citation_reference" content="Bajaj, C. L., et al., &quot;Reconstructing Surfaces and Functions on Surfaces from Unoriganized Three-Dimensional Data,&quot; Algorithmica, Sep./Oct. 1997, vol. 19, No. 1/2, p. 243-261."><meta name="citation_reference" content="Beasley, Graham, &quot;Mission Rehearsal Meets Distributed Interactive Simulation (DIS),&quot; p. 1-7."><meta name="citation_reference" content="Bernard Chazaelle, &quot;An Optimal Algorithm for Intersecting Three-Dimensional Convex Polyhedra,&quot; Siam Journal on Computing, Aug. 1992, p. 671-696, vol. 21, No. 4."><meta name="citation_reference" content="Birkel, Paul A.(Dr.), &quot;SECRIS Geospatial Reference Model,&quot; The MITRE Corporation."><meta name="citation_reference" content="Bolin, Mark R. and Meyer, Gary W., &quot;A Frequency Based Ray Tracer,&quot; ACM Press-Computer Graphics, Aug. 6-11, 1995, p. 409-418."><meta name="citation_reference" content="Bolin, Mark R. and Meyer, Gary W., &quot;A Perceptually Based Adaptive Sampling Algorithms,&quot; ACM Press-Computer Graphics, Jul. 1998, p. 299-309."><meta name="citation_reference" content="Bricken, William and Coco, Geoffrey, &quot;The VEOS Project,&quot; Presence, 1994, vol. 3, No. 2., p. 111-129."><meta name="citation_reference" content="Burdea, Grigore, &quot;Effect of Frame Rate and Force Feedback on Virtual Object Manipulation,&quot; Presence, 1996, vol. 5, No. 1, p. 95-108, MIT Press."><meta name="citation_reference" content="C.L. Bajaj, V. Pascucci, &quot;Visualization of Scalar Topology for Structural Enhancement,&quot; IEEE, Oct. 1998, p. 51-58."><meta name="citation_reference" content="Carlson, Deborah A., et al., &quot;Simulation Levels of Detail for Real-time Animation,&quot; Graphics Interface, 1997, p. 1-8."><meta name="citation_reference" content="Chandrajit L. Bajaj and Daniel R. Schikore, &quot;Error-bounded Reduction of Triangle Meshes with Multivariate Data,&quot; SPIE, 1996, vol. 2656, p. 34-45."><meta name="citation_reference" content="Chen, M., Townsend, P. and Vince, J.A., &quot;High Performance Computing for Computer Graphics and Visualization,&quot; Swansea, Jul. 3-4, 1995, pp. 216-237."><meta name="citation_reference" content="Christopher Allen Chrislip and James Frederick Ehlert, Jr., &quot;Level of Detail Models For Dismounted Infantry in NPSNET-IV.8.1,&quot; Sep. 1995, p. i-xii and p. 1-85."><meta name="citation_reference" content="Cohen, Jonathan, &quot;Simplification Envelopes,&quot; Computer Graphics, 1996, p. 119-128."><meta name="citation_reference" content="Cohen, Jonathan, et al., &quot;Appearance-Preserving Simplification,&quot; ACM Press-Computer Graphics, Jul. 19-24, 1998, p. 115-122."><meta name="citation_reference" content="Cohen-Or, Daniel, et al., &quot;Conservative Visibility and Strong Occlusion for Viewspace Partitioning of Densely Occluded Scenes,&quot; Computer Graphics Forum, 1998, V.17, No. 3."><meta name="citation_reference" content="Cohen-Or, David and Levanoni, Yishay, &quot;Temporal Continuity of Levels of Detail in Delaunay Triangulated Terrain,&quot; IEEE, Oct. 27-Nov. 1996."><meta name="citation_reference" content="Coorg, Satya and Teller, Seth, &quot;Real-Time Occlusion Culling for Models with Large Occluders,&quot; 1997 Symposium on Interactive 3D Graphics, Apr. 27-30, 1997, p. 83-90 and 189."><meta name="citation_reference" content="Coorg, Satya and Teller, Seth, &quot;Temporally Coherent Conservative Visibility (Extended Abstract),&quot; ACM Press, May 24-26, 1996."><meta name="citation_reference" content="Cosman, Michael A., &quot;A New Visual System to Support Advanced Requirement Requirements,&quot; Evans &amp; Sutherland, p. 371-380."><meta name="citation_reference" content="Cosman, Michael A., &quot;Mission Rehearsal Modeling,&quot; Image VI Conference, 1992, p. 413-425."><meta name="citation_reference" content="Cosman, Michael, et al., &quot;Global Terrain Texture: Lowering the Cost,&quot;."><meta name="citation_reference" content="Cruz-Neira, Carolina, et al., &quot;Surround-Screen Projection-based Virtual reality: The Design and Implementation of the CAVE,&quot; Computer Graphics, Aug. 1993, p. 135-143."><meta name="citation_reference" content="David R. Cheriton, et al., &quot;Effective Remote Modeling in Large-Scale Distributed Simulation and Visualization Environments,&quot; Sandeep Kishan Singhal, Aug. 1996, p. ix-156."><meta name="citation_reference" content="De Floriani, et al., &quot;Multiresolution Models for Topographic Surface Description,&quot; The Visual Computer, 1996, vol. 12, p. 317-345."><meta name="citation_reference" content="De Floriani, L, et al., &quot;A Delaunay-Based Method for Surface Approximation,&quot; Eurographics &#39;83, Aug. 31-Sep. 2, 1983, pp. 333-350."><meta name="citation_reference" content="De Floriani, Leila, &quot;A Pyramidal Data Structure for Triangle-Based Surface Description,&quot; IEEE Computer Graphics and Applications, Mar. 1989, V. 9, No. 2, p. 67-88."><meta name="citation_reference" content="De Floriani, Leila, et al., &quot;Hierarchical Triangulation for Multiresolution Surface Description,&quot; ACM Transactions on Graphics, p. 363-411."><meta name="citation_reference" content="DeHaemer, Jr. Michael J. and Zyda, Michael J., &quot;Simplification of Objects Rendered by Polygonal Approximations,&quot; 1991, vol. 15, No. 2, p. 175-184."><meta name="citation_reference" content="Deussen, Oliver, et al., &quot;Realistic Modeling and Rendering of Plant Ecosystems,,&quot; ACM Press-Computer Graphics, Jul. 1998, p. 275-286."><meta name="citation_reference" content="Dirk Bartz, Michael Meibner, Tobias Huttner, &quot;Extending Graphics Hardware for Occlusion Queries in OpenGL,&quot; Computer Graphics Lab, University of Tubingen."><meta name="citation_reference" content="Eck, Matthias, et al. &quot;Multiresolution Analysis of Arbitrary Meshes,&quot; Computer Graphics, 1995, p. 173-182."><meta name="citation_reference" content="Edwin Ear Catmull, &quot;A Subdivision Algorithm for Computer Disply of Curved Surfaces,&quot; Department of Computer Science, University of Utah, Dec. 1974."><meta name="citation_reference" content="El-Sana, Jihad, et al., &quot;Topololgy Simplification for Polygonal Virtual Environments,&quot; IEEE Trans. on Visualization and Computer Graphics, &#39;98, vol. 4, No. 2, p. 133-144."><meta name="citation_reference" content="F. C. Crow, &quot;A More Flexible Image Generation Environment,&quot; Computer Graphics, siggraph &#39;82 Conference Proceedings, Jul. 1982, vol. 16, No. 3, p. 9-18."><meta name="citation_reference" content="Falby, John, S., et al., &quot;NPSNET: Hierarchical Data Structures for Real-Time Three-Dimensional Visual Simulation,&quot; In Computer &amp; Graphics, vol. 1, No. 1, p. 65-69."><meta name="citation_reference" content="Ferguson, R.L., et al., &quot;Continuous Terrain Level of Detail for Visual Simulation,&quot; p. 145-151."><meta name="citation_reference" content="Ferwerda, James, et al., &quot;A Model of Visual Masking for Computer Graphics,&quot; Computer Graphics Proceedings, 1997, pp. 143-152."><meta name="citation_reference" content="Fowler, Robert J. and Little, James J., &quot;Automatice Extraction of Irregular Network Digital Terrain Models,&quot; Computer Graphics, Aug. 1979, vol. 13, No. 2, p. 198-207."><meta name="citation_reference" content="G. Wheless, et al., &quot;Virtual Chesapeake Bay: Interacting with a Coupled Physical/Biological Model,&quot; IEEE, Jul. 1996, p. 52-57."><meta name="citation_reference" content="Greene, Ned, K, and Miller, Gavin, &quot;Hierarchical Z-Buffer Visisbility,&quot; Computer Graphics Proceedings, Annual Conference Series, 1993, p. 231-238."><meta name="citation_reference" content="Gueziec, A., Taubin, G., Lazarus, F., and Horn, W., &quot;Simplicial Maps for Progressive Transmission of Polygonal Surfaces,&quot; ACM Siggraph."><meta name="citation_reference" content="Hamann, Bernd, &quot;A Data Reduction Scheme for Triangulated Surfaces,&quot; Computer Aided Geometric Design, Apr. 1994, vol. 11, No. 2, p. 197-198."><meta name="citation_reference" content="He, Taosong, Hong, Lichan, Varshney, Amitabh and Wang Sidney W., &quot;Controlled Topology Simiplification,&quot; IEEE Trans., Jun. 1996, vol. 2, No. 2, p. 171-184."><meta name="citation_reference" content="Holloway, Richard, &quot;Viper: A Quasi-Real-time Virtual-Environment Application,&quot;p. 1-10."><meta name="citation_reference" content="Hoppe, H., DeRose, T., Duchamp, T., McDonald, J., Stuetzle, W., &quot;Mesh Optimization,&quot; Computer Graphics, 1993, pp. 19-26."><meta name="citation_reference" content="Hoppe, Hugues, &quot;Efficient Implementation of Progressive Meshes,&quot; Computer and Graphics, 1998, vol. 22, No. 1, pp. 27-36."><meta name="citation_reference" content="Hoppe, Hugues, &quot;Progressive Meshes,&quot; Computer Graphics, Aug. 4-9, 1996, pp. 99-108."><meta name="citation_reference" content="Hoppe, Hugues, &quot;Smooth View-Dependent Level-of-Detail Control and its Application to Terrain Rendering,&quot; IEEE, Oct. 18-23, 1998, pp. 35-42 and p. 516."><meta name="citation_reference" content="Hoppe, Hugues, &quot;View-Dependent Refinement of Progressive Meshes,&quot; Computer Graphics, Aug. 3-8, 1997."><meta name="citation_reference" content="Hubbard, Philip M., &quot;Approximately Polyhedra with Spheres for Time-Critical Collision Detection,&quot; ACM Transactions on Graphics."><meta name="citation_reference" content="Hugh R. Wilson and James R. Bergen, &quot;A Four Mechanism Model for Threshold Spatial Vision,&quot; 1979, vol. 19, No. 1, p. 19-31."><meta name="citation_reference" content="James H. Clark, &quot;Hierarchical Geometric Models for Visible Surface Algorithms,&quot; Communication of the ACM, Oct. 1976, vol. 19, No. 10, p. 547-554."><meta name="citation_reference" content="Jarvis, Kevin M., &quot;Visual Performances Requirement Below the Skyline, A Cost Effective Solution to Low Level Flight,&quot; p. 231-235."><meta name="citation_reference" content="John Dill and Nahum Gershon, &quot;IEEE Symposium on Information Visualization,&quot; IEEE Computer Society, Oct. 20-21, 1997, p. 395-402."><meta name="citation_reference" content="Johnson K. Yan, &quot;Advances in Computer-Generated Imagery for Flight Simulation,&quot; IEEE Computer Graphics and Applications, Aug. 1985, p. 37-51."><meta name="citation_reference" content="Johnston, William, et al., &quot;Distributed Large Data-Object Environments: End-to-End Performance Analysis of High Speed Distributed Storage System in Wide Area ATM Networks,&quot;."><meta name="citation_reference" content="Jonathan Blow, &quot;Implementing a Texture Caching System,&quot; Game Developer, Apr. 1998."><meta name="citation_reference" content="Jonathan David Cohen, &quot;Appearance-Preserving Simplification of Polygonal Models,&quot; Chapel Hill, 1999, p. i-xvii and p. 1-130."><meta name="citation_reference" content="Jose, Cecil, Delfinado, A. and Edelsbrunner, Herbert, &quot;An Incremental Algorithm for Betti Numbers of Simplicial Complexes on the 3-sphere,&quot;."><meta name="citation_reference" content="Julie C. Xia and Amitabh Varshney, &quot;Dynamic view-Dependent Simplification for Polygonal Models,&quot; Proceedings Visualization &#39;96, Oct. 27-Nov. 1, 1996, p. 327-498."><meta name="citation_reference" content="Julie C. Xia et al., &quot;Adaptive Real-time Level-of-Detail-Based Rendering for Polygonal Model,&quot; IEEE Trans., Apr.-Jun. 1997, vol. 3, No. 2, p. 171-183."><meta name="citation_reference" content="Kaplan, Lance M., et al., &quot;Fast Texture Database Retrieval Using Extended Fractal Features,&quot; SPIE, Jan. 1998, vol. 3312, p. 162-173."><meta name="citation_reference" content="Korp, P. A., Lurie, G.R., and Christiansen, J., &quot;A Smalltalk-based Extension to Traditional Geographic Information Systems,&quot;."><meta name="citation_reference" content="Lance Williams, &quot;Pyramidal Parametrics,&quot; Computer Graphics, Jul. 1983, vol. 17, No. 3, p. i-11."><meta name="citation_reference" content="Leclerc, Yvan G. and Lau, Jr., Steven Q., &quot;TerraVision: A Terrain Visualization System,&quot; SRI International, Jan. 26, 1995, pp. 1-20."><meta name="citation_reference" content="Leigh, Jason, et al., &quot;CAVERN: A Distributed Architecture for Supporting Scalable Persistence and Interoperability in Collaborative Virtual Environments,&quot;."><meta name="citation_reference" content="Liang, Jiandong, Shaw, Chris and Green, Mark, &quot;On Temporal-Spatial Realism in the Virtual REality Environment,&quot; Nov. 11-13, 1991, pp. 19-25."><meta name="citation_reference" content="Lindstrom, P. et al., &quot;Real-Time, Continuous Level of Detail Rendering of Height Fields,&quot; Computer Graphics, Siggraph 96, Aug. 4-9, 1996, pp. 109-118."><meta name="citation_reference" content="Lindstrom, Peter, et al., &quot;Level-of-Detail Management for Real-Time rendereing of Phototextured Terrain,&quot; p. 1-110."><meta name="citation_reference" content="Lindstron, Peter, Koller, David, Ribarsky, William, Hodges, Larry. F., Op den Bosch, Augusto, Faust, Nick, &quot;An Integrated Global GIS and Visual Simulation System,&quot; pp. 1-9."><meta name="citation_reference" content="Luebke, David and Erikson, Carl, &quot;View-Dependent Simplification of Arbitrary Polygonal Environments,&quot; Computer Graphics, Siggraph 97, Aug. 3-8, 1997, pp. 199-208."><meta name="citation_reference" content="Niblack, W., et al., &quot;The QBIC Project: Querying Images By Content Using Color, Texture, and Shape,&quot; SPIE, vol. 1908, p. 173-187."><meta name="citation_reference" content="Palmer, Stephen, Rosch, and Chase, Paul, &quot;8 Canonical Perspective and the Perception of Objects,&quot; LEA, 1981, p. 135-151."><meta name="citation_reference" content="Pugh, William, &quot;Skip Lists: A Probabilistic Alternative to Balanced Trees,&quot; Communications of the ACM, Jun. 1990, vol. 22, No. 6, p. 668-675."><meta name="citation_reference" content="Reddy, Martin, &quot;A Survey of Level of Detail Support in Current Virtual Reality Solutions,&quot; Virtual Reality, 1995, vol. 1, No. 2, p. 95-98."><meta name="citation_reference" content="Robert Weibel and C. B. Jones, &quot;Computational Perspectives on Map Generalization,&quot; GeoInformation, 1998, vol. 2, No. 4, p. 307-314."><meta name="citation_reference" content="Roger D. Smith, &quot;Vertical Interface Methodology for Connecting Constructive and Virtual Level Simulations,&quot; Central University, Sep. 15, 1994, p. i-122."><meta name="citation_reference" content="Rossignac, Jarek and Borrel, Paul, &quot;Multi-resolution 3D Approximations for Rendering Complex Scenes,&quot; p. 455-465."><meta name="citation_reference" content="Scarlatos, Lori L., et al., &quot;A Refined Triangulation Hierarchy For Multiple Levels of Terrain Detail,&quot; p. 115-122."><meta name="citation_reference" content="Schachter, Bruce J., &quot;Computer Image Generation for Flight Simulation,&quot; IEEE Computer Graphics and Applications, Oct. 1981, p. 5-68."><meta name="citation_reference" content="Sidney W. Wang and Arie E. Kaufman, &quot;Volume Sampled voxelization of Geometric Primitives,&quot; Visualization &#39;93, Oct. 25-29, 1993, p. 77-84 and CP-9."><meta name="citation_reference" content="Tanner, Christopher C., et al., &quot;The Clipmap: A Virtual Mipmap,&quot; Silicon Graphics Computer Systems."><meta name="citation_reference" content="Terry Caelli and Giampaolo Moraglia, &quot;On the Detection of Gabor Signals and Discrimination of Gabor Texture,&quot; Journal in Visual Science, 1985, p. 671-684, vol. 25 No. 5."><meta name="citation_reference" content="Tonkin, Maine H. and Moerdyk, David M., &quot;Testing Missile Seeker Systems with Computer Generated Images,&quot; p. 221-228."><meta name="citation_reference" content="V.E. Taylor, et al., &quot;Identifying and Reducing Critical Lag in finite Element Simulations&quot; IEEE Computer Graphics and Applications, 1996, p. 67-71."><meta name="citation_reference" content="Vince, John, &quot;10 Virtual Reality Techniques in Flight Simulation,&quot; Virtual Reality Systems, 1993, p. 135-157."><meta name="citation_reference" content="Watson, Benjamin Allen, &quot;Level of Detail Management,&quot; Georgia Institute of Technology, Sep. 1997, p. i-140."><meta name="citation_reference" content="Wei-Ying Ma, &quot;Netra: A Toolbox For Navigating Large Image Databases,&quot; Doctor of Philosophy in Electrical and Computer Engineering, Jun. 1997, p. 1-158."><meta name="citation_reference" content="Westervelt, James D., &quot;Simulating Mobile Objects in Dynamic Processes,&quot; USACERL Technical Report, 98/94, Jul. 1998."><meta name="citation_reference" content="Yan, Johnson K., &quot;Advances in Computer-Generated Imagery for Flight Simulation,&quot; IEEE Computer Society, Aug. 1985, pp. 2-51."><meta name="citation_reference" content="Zhang, Hansong, &quot;Effective Occlusion Culling for the Interactive Display of Arbitrary Models,&quot; p. i-98."><meta name="citation_reference" content="Zimmerman, stephen A., &quot;Applying Frequency Domain Constructs to a Broad Spectrum or Visual Simulation Problems,&quot; Image IV Conference, Jun. 23-26, 1987, p. 209-216."><meta name="citation_patent_number" content="US:7551172"><meta name="citation_patent_application_number" content="US:11/445,165"><link rel="canonical" href="http://www.google.com/patents/US7551172"/><meta property="og:url" content="http://www.google.com/patents/US7551172"/><meta name="title" content="Patent US7551172 - Sending three-dimensional images over a network"/><meta name="description" content="A benefit is obtained for sending digital information over a network. The digital information is representative of three-dimensional images which include photographic images. The receiving computer renders the images from the received digital information, and a viewer at the receiving computer can interactively choose a viewpoint or perspective to view the images on a display of the receiving computer. The benefit to the sender can be monetary compensation and/or increased recognition of the sender, for example."/><meta property="og:title" content="Patent US7551172 - Sending three-dimensional images over a network"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("H0_sU4mxO9KOogT0zoHIAQ"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CRI"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("H0_sU4mxO9KOogT0zoHIAQ"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CRI"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7551172?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7551172"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=pXDIBQABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7551172&amp;usg=AFQjCNHLp75kwL2Prgqc4ppqf5wLJkOosw" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7551172.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7551172.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20070094094"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US7551172"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7551172" style="display:none"><span itemprop="description">A benefit is obtained for sending digital information over a network. The digital information is representative of three-dimensional images which include photographic images. The receiving computer renders the images from the received digital information, and a viewer at the receiving computer can interactively...</span><span itemprop="url">http://www.google.com/patents/US7551172?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7551172 - Sending three-dimensional images over a network</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7551172 - Sending three-dimensional images over a network" title="Patent US7551172 - Sending three-dimensional images over a network"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7551172 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 11/445,165</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Jun 23, 2009</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jun 2, 2006</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Feb 26, 1999</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US8237713">US8237713</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8462151">US8462151</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20030158786">US20030158786</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070094094">US20070094094</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20090231333">US20090231333</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130038604">US20130038604</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20140160112">US20140160112</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">11445165, </span><span class="patent-bibdata-value">445165, </span><span class="patent-bibdata-value">US 7551172 B2, </span><span class="patent-bibdata-value">US 7551172B2, </span><span class="patent-bibdata-value">US-B2-7551172, </span><span class="patent-bibdata-value">US7551172 B2, </span><span class="patent-bibdata-value">US7551172B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Ronnie+Yaron%22">Ronnie Yaron</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Ofer+Shor%22">Ofer Shor</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Skyline+Software+Systems,+Inc.%22">Skyline Software Systems, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7551172.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7551172.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7551172.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (92),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (99),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (2),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (27),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7551172&usg=AFQjCNGbFfMrY8kvKHN0ULtCeQHBmZ7yrA">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7551172&usg=AFQjCNGs7LqkK7tZLh-QkS-knfoR5FA0nw">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7551172B2%26KC%3DB2%26FT%3DD&usg=AFQjCNELdpP-T_uRgVhSZGPdokJywFJpAQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT75573257" lang="EN" load-source="patent-office">Sending three-dimensional images over a network</invention-title></span><br><span class="patent-number">US 7551172 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA53259731" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">A benefit is obtained for sending digital information over a network. The digital information is representative of three-dimensional images which include photographic images. The receiving computer renders the images from the received digital information, and a viewer at the receiving computer can interactively choose a viewpoint or perspective to view the images on a display of the receiving computer. The benefit to the sender can be monetary compensation and/or increased recognition of the sender, for example.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(11)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7551172B2/US07551172-20090623-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7551172B2/US07551172-20090623-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(77)</span></span></div><div class="patent-text"><div mxw-id="PCLM13164833" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A method of providing information representing physical features of a portion of a three-dimensional surface, the information having a hierarchical structure which includes sets of information at a plurality of different resolution levels, the method comprising:
<div class="claim-text">generating a request associated with the portion of the three dimensional surface including a resolution level parameter;</div>
<div class="claim-text">receiving a first set of information from a memory of a local computer, the first set of information including data corresponding to at least some of the portion of the three dimensional surface associated with the request; and</div>
<div class="claim-text">downloading from a remote server one or more additional sets of information at a resolution level higher than the resolution level of the first set of information when the provided first set of information from the memory is at a resolution level lower than a desired resolution level, the one or more additional sets of information including data corresponding to the portion of the three dimensional surface associated with the request.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the information comprises elevation attributes.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the information comprises color attributes.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more additional sets of information includes compressed data corresponding to the portion of the three dimensional surface associated with the request.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the one or more additional sets of information is downloaded over the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more additional sets of information is downloaded over the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">downloading from the remote server one or more further sets of information at a resolution level higher than the resolution level of the one or more additional sets of information, the one or more further sets of information including data corresponding to the portion of the three dimensional surface, when the downloaded one or more additional sets of information is at a resolution level lower than the desired-resolution level.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein each successive one or more further sets of information are at a next higher resolution level than the resolution level of the preceding sets of information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the sets of information include a description of pixels required to produce a display of the portion of the three dimensional surface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein downloading the one or more additional sets of information comprises downloading the sets of information from a succession of resolution levels, beginning from a level immediately higher than the resolution level of the first set of information up to the maximal existent resolution level on the remote server not above the desired resolution level.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">downloading from a remote server excess sets of information not currently needed, to store in the local memory when not downloading the one or more additional sets of information.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the excess sets of information relates to a location on a predetermined course of a path of a vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein downloading the sets of information comprises downloading the sets of information over the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<div class="claim-text">displaying a view from a current viewpoint, wherein downloading the excess sets of information comprises storing in the memory substantially all of the sets of information surrounding a point on the surface seen from the current viewpoint within a predetermined distance range.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein storing in the memory comprises storing in the memory substantially all of the sets of information within the range from a lower resolution level before downloading sets of information of higher resolution levels.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein generating the request includes generating a plurality of requests associated with the portion of the three dimensional surface, an identification of each of the plurality of requests being included in respective distinct sets of information, and wherein the one or more additional sets of information includes information corresponding to the respective distinct sets of information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein sets of information of lower resolution levels are downloaded before sets of information of higher resolution levels.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the desired resolution is the resolution level associated with the resolution level parameter.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text">19. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the sets of information are downloaded according to the order in which the plurality of requests were generated.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text">20. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the desired resolution level is the resolution level associated with an equipment capacity.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
      <div class="claim-text">21. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the desired resolution level is predetermined resolution level.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
      <div class="claim-text">22. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the desired resolution level is a function of the available resolution levels.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
      <div class="claim-text">23. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the desired resolution level is a function of the rate of transmission of information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00024" num="00024" class="claim">
      <div class="claim-text">24. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the desired resolution level is a function of the selected portion of a three-dimensional surface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00025" num="00025" class="claim">
      <div class="claim-text">25. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the desired resolution level is a function of user perspective.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00026" num="00026" class="claim">
      <div class="claim-text">26. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the desired resolution level is a function of perceived distance.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00027" num="00027" class="claim">
      <div class="claim-text">27. The method of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein the equipment capacity comprises performance characteristics.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00028" num="00028" class="claim">
      <div class="claim-text">28. An apparatus for providing information representing physical features of a portion of a three dimensional surface, the information having a hierarchical structure which includes sets of information at a plurality of different resolution levels, the apparatus comprising:
<div class="claim-text">a memory of a local computer which stores sets of information representing physical features of the portion of the three dimensional surface associated with a current viewpoint;</div>
<div class="claim-text">a communication link through which the memory receives the information from a remote server; and</div>
<div class="claim-text">a processor which generates a request associated with the portion of the three dimensional surface and a resolution level parameter, retrieves a first set of information from a memory of a local computer, the first set of information including data corresponding to at least some of the portion of the three dimensional surface, and downloads over the communication link one or more additional sets of information at a resolution level higher than the resolution level of the first set of information when the provided first set of information is at a resolution level lower than a desired resolution level, the one or more additional sets of information including data corresponding to the portion of the three dimensional surface associated with the request.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00029" num="00029" class="claim">
      <div class="claim-text">29. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the information comprises elevation attributes.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00030" num="00030" class="claim">
      <div class="claim-text">30. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the information comprises color attributes.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00031" num="00031" class="claim">
      <div class="claim-text">31. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the sets of information include a description of pixels required to produce a display of the portion of the three dimensional surface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00032" num="00032" class="claim">
      <div class="claim-text">32. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein generating includes generating a plurality of requests associated with the portion of the three dimensional surface, an identification of each of the plurality of requests being included in respective distinct sets of information, the one or more additional sets of information including information corresponding to the distinct sets of information, and the one or more additional sets of information being downloaded according to the order in which the plurality of requests were generated.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00033" num="00033" class="claim">
      <div class="claim-text">33. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein excess sets of information not currently needed are downloaded when the processor is not downloading sets of required information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00034" num="00034" class="claim">
      <div class="claim-text">34. The apparatus of <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein the communication link comprises a connection to the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00035" num="00035" class="claim">
      <div class="claim-text">35. The apparatus of <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein the excess sets of information relate to a location on a course of vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00036" num="00036" class="claim">
      <div class="claim-text">36. The apparatus of <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein the processor stores in the memory substantially all the sets of information surrounding a point in the terrain seen from a current viewpoint in a predetermined range.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00037" num="00037" class="claim">
      <div class="claim-text">37. The apparatus of <claim-ref idref="CLM-00036">claim 36</claim-ref>, wherein the processor stores in the memory substantially all the sets of information from a lower level before downloading sets of information of higher resolution levels.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00038" num="00038" class="claim">
      <div class="claim-text">38. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the one or more additional sets of information includes compressed data corresponding to the portion of the three dimensional surface associated with the request.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00039" num="00039" class="claim">
      <div class="claim-text">39. The apparatus of <claim-ref idref="CLM-00038">claim 38</claim-ref>, wherein the one or more additional sets of information is downloaded over the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00040" num="00040" class="claim">
      <div class="claim-text">40. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the one or more additional sets of information is downloaded over the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00041" num="00041" class="claim">
      <div class="claim-text">41. The apparatus of <claim-ref idref="CLM-00040">claim 40</claim-ref>, wherein the one or more additional sets of information includes compressed data corresponding to the portion of the three dimensional surface associated with the request.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00042" num="00042" class="claim">
      <div class="claim-text">42. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the processor downloads one or more further sets of information at a resolution level higher than the resolution level of the one or more additional sets of information when the downloaded one or more additional sets of information is at a resolution level lower than the desired resolution level, the one or more further sets of information including data corresponding to the portion of the three dimensional surface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00043" num="00043" class="claim">
      <div class="claim-text">43. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the desired resolution is the resolution level associated with the resolution level parameter.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00044" num="00044" class="claim">
      <div class="claim-text">44. The apparatus of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the processor comprises a cache manager.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00045" num="00045" class="claim">
      <div class="claim-text">45. A method of obtaining data representing physical features of a portion of a three-dimensional surface, the data arranged according to a hierarchical structure at a plurality of resolution levels, the method comprising:
<div class="claim-text">retrieving locally stored data corresponding to the portion of the three-dimensional surface from a local memory;</div>
<div class="claim-text">determining whether the stored data is at a resolution level lower than a desired resolution; and when the stored data is at a resolution level lower than the desired resolution, requesting data corresponding to the portion of the three-dimensional surface at a requested resolution over a network, wherein the requested resolution is less than or equal to the desired resolution.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00046" num="00046" class="claim">
      <div class="claim-text">46. The method of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein requesting data comprises providing one or more coordinates corresponding to the portion of the three-dimensional surface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00047" num="00047" class="claim">
      <div class="claim-text">47. The method of <claim-ref idref="CLM-00046">claim 46</claim-ref>, wherein the stored data comprises a first set of information including data corresponding to the one or more coordinates.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00048" num="00048" class="claim">
      <div class="claim-text">48. The method of <claim-ref idref="CLM-00047">claim 47</claim-ref>, wherein the stored data comprises one or more additional sets of information at a resolution level higher than the resolution level of the first set of information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00049" num="00049" class="claim">
      <div class="claim-text">49. The method of <claim-ref idref="CLM-00045">claim 45</claim-ref>, further comprising:
<div class="claim-text">downloading over the Internet excess data not currently needed, to store in the local memory when not downloading additional data.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00050" num="00050" class="claim">
      <div class="claim-text">50. The method of <claim-ref idref="CLM-00049">claim 49</claim-ref>, further comprising:
<div class="claim-text">displaying a view from a current viewpoint, wherein downloading the excess data includes storing in the local memory with substantially all data surrounding a point on the surface seen from the current viewpoint within a predetermined distance range.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00051" num="00051" class="claim">
      <div class="claim-text">51. The method of <claim-ref idref="CLM-00050">claim 50</claim-ref>, wherein storing in the local memory includes storing in the local memory substantially all data within the predetermined distance range of a lower resolution level before downloading data of higher resolution levels.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00052" num="00052" class="claim">
      <div class="claim-text">52. The method of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein the network is the Internet and the additional data includes compressed data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00053" num="00053" class="claim">
      <div class="claim-text">53. The method of <claim-ref idref="CLM-00045">claim 45</claim-ref>, further comprising the step of iteratively requesting, over the network, additional data at a resolution level higher than the resolution level of the locally stored data until the resolution of the additional data is higher than the desired resolution.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00054" num="00054" class="claim">
      <div class="claim-text">54. The method of <claim-ref idref="CLM-00053">claim 53</claim-ref>, wherein the requested resolution indicates the desired resolution.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00055" num="00055" class="claim">
      <div class="claim-text">55. The method of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein the step of requesting data consists of a single request.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00056" num="00056" class="claim">
      <div class="claim-text">56. A method of providing information representing physical features of a portion of a three-dimensional surface, the information having a hierarchical structure which includes sets of information at a plurality of different resolution levels, the method comprising:
<div class="claim-text">generating a request associated with the portion of the three dimensional surface including a resolution level parameter;</div>
<div class="claim-text">receiving a first set of information from a memory of a local computer, the first set of information including data corresponding to at least some of the portion of the three dimensional surface associated with the request; and,</div>
<div class="claim-text">downloading from the remote server one or more additional sets of information at a resolution level higher than the resolution level of the first set of information when the provided first set of information from the memory is at a resolution level lower than or equal to a desired resolution level.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00057" num="00057" class="claim">
      <div class="claim-text">57. The method of <claim-ref idref="CLM-00056">claim 56</claim-ref>, wherein the one or more additional sets of information is downloaded over the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00058" num="00058" class="claim">
      <div class="claim-text">58. The method of <claim-ref idref="CLM-00056">claim 56</claim-ref>, wherein the one or more additional sets of information includes compressed data corresponding to the portion of the three dimensional surface associated with the request.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00059" num="00059" class="claim">
      <div class="claim-text">59. The method of <claim-ref idref="CLM-00056">claim 56</claim-ref>, wherein the sets of information include description of pixels required to produce a display of the portion of the three dimensional surface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00060" num="00060" class="claim">
      <div class="claim-text">60. The method of <claim-ref idref="CLM-00056">claim 56</claim-ref>, further comprising: downloading from the remote server one or more further sets of information at a resolution level higher than the resolution level of the one or more additional sets of information, the one or more further sets of information including data corresponding to the portion of the three dimensional surface, when the downloaded one or more additional sets of information is at a resolution level lower than or equal to the desired-resolution level.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00061" num="00061" class="claim">
      <div class="claim-text">61. An apparatus for providing information representing physical features of a portion of a three dimensional surface, the information having a hierarchical structure which includes sets of information at a plurality of different resolution levels, the apparatus comprising:
<div class="claim-text">a memory of a local computer which stores sets of information representing physical features of the portion of the three dimensional surface associated with a current viewpoint;</div>
<div class="claim-text">a communication link through which the memory receives the information from a remote server; and</div>
<div class="claim-text">a processor which generates a request associated with the portion of the three dimensional surface and a resolution level parameter, retrieves a first set of information from a memory of a local computer, the first set of information including data corresponding to at least some of the portion of the three dimensional surface, and downloads over the communication link one or more additional sets of information at a resolution level higher than the resolution level of the first set of information when the provided first set of information is at a resolution level lower than or equal to a desired resolution level, the one or more additional sets of information including data corresponding to the portion of the three dimensional surface associated with the request.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00062" num="00062" class="claim">
      <div class="claim-text">62. The apparatus of <claim-ref idref="CLM-00061">claim 61</claim-ref>, wherein the processor downloads one or more further sets of information at a resolution level higher than the resolution level of the one or more additional sets of information when the downloaded one or more additional sets of information is at a resolution level lower than or equal to the desired resolution level, the one or more further sets of information including data corresponding to the portion of the three dimensional surface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00063" num="00063" class="claim">
      <div class="claim-text">63. The apparatus of <claim-ref idref="CLM-00061">claim 61</claim-ref>, wherein the communication link over which one or more additional sets of information is downloaded comprises the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00064" num="00064" class="claim">
      <div class="claim-text">64. The apparatus of <claim-ref idref="CLM-00061">claim 61</claim-ref>, wherein the one or more additional sets of information includes compressed data corresponding to the portion of the three dimensional surface associated with the request.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00065" num="00065" class="claim">
      <div class="claim-text">65. The apparatus of <claim-ref idref="CLM-00061">claim 61</claim-ref>, wherein the sets of information include description of pixels required to produce a display of the portion of the three dimensional surface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00066" num="00066" class="claim">
      <div class="claim-text">66. The apparatus of <claim-ref idref="CLM-00061">claim 61</claim-ref>, wherein the processor comprises a cache manager.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00067" num="00067" class="claim">
      <div class="claim-text">67. A method of obtaining data representing physical features of a portion of a three-dimensional surface, the data arranged according to a hierarchical structure at a plurality of resolution levels, the method comprising:
<div class="claim-text">retrieving locally stored data corresponding to the portion of the three-dimensional surface from a memory;</div>
<div class="claim-text">determining whether the stored data is at a resolution level lower than a desired resolution; and when the stored data is at a resolution level lower than or equal to the desired resolution; requesting data corresponding to the portion of the three-dimensional surface at a requested resolution from a server, wherein the requested resolution is less than or equal to the desired resolution.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00068" num="00068" class="claim">
      <div class="claim-text">68. The method of <claim-ref idref="CLM-00067">claim 67</claim-ref>, comprising the step of receiving over the network additional data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00069" num="00069" class="claim">
      <div class="claim-text">69. The method of <claim-ref idref="CLM-00068">claim 68</claim-ref>, wherein the requested additional data is received over the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00070" num="00070" class="claim">
      <div class="claim-text">70. The method of <claim-ref idref="CLM-00068">claim 68</claim-ref>, wherein the additional data includes compressed data corresponding to the portion of the three dimensional surface associated with the request.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00071" num="00071" class="claim">
      <div class="claim-text">71. The method of <claim-ref idref="CLM-00067">claim 67</claim-ref>, wherein the additional data include description of pixels required to produce a display of the portion of the three dimensional surface.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00072" num="00072" class="claim">
      <div class="claim-text">72. A method of providing information representing physical features of a portion of a three-dimensional surface, the information having a hierarchical structure which includes sets of information at a plurality of different resolution levels, the method comprising:
<div class="claim-text">generating a request associated with the portion of the three dimensional surface including a resolution level parameter;</div>
<div class="claim-text">receiving a first set of information from a memory of a local computer, the first set of information including data corresponding to at least some of the portion of the three dimensional surface associated with the request; and</div>
<div class="claim-text">downloading from a remote server one or more additional sets of information at a resolution level higher than the resolution level of the first set of information based on a test performed upon the first set of information, the one or more additional sets of information including data corresponding to the portion of the three dimensional surface associated with the request.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00073" num="00073" class="claim">
      <div class="claim-text">73. The method of <claim-ref idref="CLM-00072">claim 72</claim-ref>, wherein the test is whether the first set of information is at a resolution level less than or equal to a desired resolution level.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00074" num="00074" class="claim">
      <div class="claim-text">74. The method of <claim-ref idref="CLM-00073">claim 73</claim-ref>, wherein the desired resolution is indicated by the resolution level parameter.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00075" num="00075" class="claim">
      <div class="claim-text">75. The method of <claim-ref idref="CLM-00072">claim 72</claim-ref>, wherein the test is whether the first set of information is at a resolution level less than a desired resolution level.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00076" num="00076" class="claim">
      <div class="claim-text">76. The method of <claim-ref idref="CLM-00075">claim 75</claim-ref>, wherein the desired resolution is indicated by the resolution level parameter.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00077" num="00077" class="claim">
      <div class="claim-text">77. The method of <claim-ref idref="CLM-00072">claim 72</claim-ref>, wherein the test is whether a desired resolution level is greater than the resolution level of the first set of information.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES18551871" lang="EN" load-source="patent-office" class="description">
    <heading>CROSS REFERENCE TO RELATED CASE</heading> <p num="p-0002">This application is a divisional application of and claims priority to and the benefit of U.S. patent application Ser. No. 10/330,181, filed Dec. 30, 2002, now abandoned, which is a continuation-in-part and claims priority to and the benefit of U.S. patent application Ser. No. 09/258,663, filed Feb. 26, 1999, now U.S. Pat. No. 6,496,189, and is a continuation of and claims priority to and the benefit of U.S. patent application Ser. No. 09/494,979, filed Jan. 31, 2000, now abandoned, the entirety of which is hereby incorporated herein by reference.</p>
    <heading>TECHNICAL FIELD</heading> <p num="p-0003">The present invention relates generally to obtaining a benefit for sending digital information over a communication network.</p>
    <heading>BACKGROUND INFORMATION</heading> <p num="p-0004">U.S. Pat. No. 4,940,972, describes displaying to a pilot of an aircraft a synthetic image of the ground terrain over which the pilot is flying. U.S. Pat. No. 5,566,073 describes allowing a pilot to preview a route either in flight or on the ground. The '073 patent also describes allowing the pilot to take over and try out different flight strategies. The data volume required to display flight routes in accordance with the above-mentioned patents is very large. The '073 patent describes representing the terrain as polygons in order to save computer storage space, but even so, the amount of storage on most home computers allows only a limited area and/or resolution level to be displayed. The '073 patent describes using a CD-ROM to store the required data, but the delivery of the CD-ROM to home users requires time and changes in the terrain (such as seasonal changes) can require frequent updates of the data on the CD-ROM.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p num="p-0005">It is an object of some aspects of the present invention to provide methods and apparatus for displaying on a remote computer actual images of an area as seen from a viewpoint which is chosen interactively.</p>
    <p num="p-0006">It is still another object of some aspects of the present invention to provide methods and apparatus for displaying on a client computer three-dimensional images stored in a remote server, which are conveyed to the client via a network, preferably the Internet.</p>
    <p num="p-0007">It is still another object of some aspects of the present invention to provide methods and apparatus for streaming data required for rendering three-dimensional images on a remote computer.</p>
    <p num="p-0008">In some embodiments of the present invention, a processor simulates traveling along a selected route. At substantially any viewpoint along the route, the processor displays the view seen from the viewpoint in three-dimensional real-life images. A user may select at substantially each point along the route the direction of view and may change the direction dynamically. Preferably, the user controls the speed of progress along the route and may stop the progress and/or reverse direction along the course.</p>
    <p num="p-0009">Preferably, the user views the three-dimensional images without having to store a large database of images on the user's processor, and without requiring that the processor have an unusually large memory capacity. Rather, the user connects to a server, which stores all the required data, and the user's processor downloads the data dynamically according to the data required to display each specific scene. Preferably, the processor connects to the server via a communication link, such as the Internet. Preferably, the data is conveyed by a standard modem at sufficient speed for relatively smooth display of the images.</p>
    <p num="p-0010">Alternatively or additionally, the required data is downloaded prior to the displaying of the scene, or the data is retrieved from a CD or other memory or storage apparatus associated with the processor.</p>
    <p num="p-0011">U.S. patent application Ser. No. 08/939,948, which is assigned to the assignee of the present application and is incorporated herein by reference, describes a method of rendering three-dimensional terrain images. The method allows fast rendering of images by comparison with other methods known in the art. The method of U.S. patent application Ser. No. 08/939,948 uses a hierarchical database in which substantially each image is described in a plurality of blocks at different resolution levels. The blocks at lower resolution levels include less detail per unit area, while the blocks of higher resolution levels include more detail per unit area. The additional storage space required in order to store the additional data required due to the hierarchical structure is “paid back” in improved time performance of the rendering.</p>
    <p num="p-0012">There is further provided in accordance with an embodiment of the present invention, a method of displaying three dimensional images, including establishing a communication link between a local processor and a server, transferring data blocks describing three-dimensional images over the communication link from the server to the local processor; and rendering a three-dimensional image at the local processor responsive to the data blocks.</p>
    <p num="p-0013">There is further provided in accordance with an embodiment of the present invention, an apparatus for displaying three dimensional images, including a processor, a communication link between the processor and a server over which data blocks describing terrain are transferred, and a display on which the processor renders three-dimensional terrain images responsive to the data blocks.</p>
    <p num="p-0014">In general, the invention relates to obtaining a benefit for sending digital information over a network. The digital information is representative of three-dimensional images which include photographic images. The receiving computer renders the images from the received digital information, and a viewer at the receiving computer can interactively choose a viewpoint or perspective to view the images on a display of the receiving computer. The benefit to the sender can be monetary compensation or increased recognition of the sender, for example.</p>
    <p num="p-0015">In one aspect, the invention relates to a method of obtaining a benefit for sending digital information over a communication network. The steps of this method comprise: (A) providing at least one first database that includes digital information representative of three-dimensional images including photographic images, (B) receiving requests over the communication network for at least some of the digital information in the database, (C) sending the requested digital information over the communication network, and (D) receiving a benefit for sending the requested digital information.</p>
    <p num="p-0016">In one embodiment, step (C) further comprises providing the digital information which is associated with at least one of a plurality of travel courses stored in a second database.</p>
    <p num="p-0017">In some embodiments, the benefit includes monetary compensation possibly derived from advertising) and/or increased recognition of an entity that performs steps (A), (B), and/or (C).</p>
    <p num="p-0018">In some embodiments, the method further comprises providing at least one second database that includes digital information representative of a plurality of travel courses and each travel course is associated with at least some of the digital information stored in the first databases.</p>
    <p num="p-0019">In one embodiment, step (C) further includes sending software to convert the requested digital information into the images.</p>
    <p num="p-0020">In another aspect, the invention features a system for providing three-dimensional images. The system comprises at least one first database comprising digital information representing three-dimensional images including photographic images, an input module configured to receive requests over a communication network for at least some of the digital information in the first database, and an output module configured to send the requested digital information over the communication network. A benefit is received for using the system to send the requested digital information over the communication network using the system.</p>
    <p num="p-0021">The system can further comprise at least one second database that includes digital information representative of a plurality of travel courses where each travel course is associated with at least some of the digital information stored in the first database. The output module can be configured to send software to convert the requested digital information into the three-dimensional images. The digital information included in the first database can be associated with at least one of a plurality of travel courses stored in a second database. The input module can comprise a software program running on a computer server, and the output module can comprise a software program running on a computer server.</p>
    <p num="p-0022">In still another aspect, the invention relates to a system for sending digital information over a communication network. The system comprises a first database including digital information representative of three-dimensional images including photographs. The system also comprises a computer server in communication with the first and with the communication network and a client computer for allowing an end user to send requests over the communication network for at least some of the three-dimensional images and for allowing the end user to receive the digital information representing the requested three-dimensional images. The system also comprises an e-commerce business for receiving the end user's requests over the communication network and redirecting the end user's requests to the computer server so the computer server can send the digital information representing the requested three-dimensional images to the end user's client computer. The computer server comprises an input module configured to receive requests over the communication network for at least some of the digital information in the first database, and an output module configured to send the requested digital information over the communication network. An operator of the system receives a benefit for sending the requested digital information.</p>
    <p num="p-0023">In all aspects and embodiments of the invention the benefit that is received for sending the requested digital information can include monetary compensation and/or increased recognition of the operator or other entity involved with sending the requested digital information over the communication network.</p>
    <p num="p-0024">The present invention will be more fully understood from the following detailed description, including</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a schematic illustration of a system for obtaining compensation for sending information over a communication network in accordance with the present invention;</p>
      <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a schematic block diagram illustrating the data structure of images stored in a database on a pilot training server, in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a flow chart illustrating a method for preparation of a pilot training database, in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a schematic block diagram illustrating a flight course database on a pilot training server, in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0029"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a schematic block diagram illustrating a processor for viewing three-dimensional real-life terrain images, in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a schematic view of a viewpoint and a scene viewed therefrom, useful in understanding a method of displaying the selected route, in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0031"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a flow chart illustrating the actions of a cache manager while the processor of <figref idrefs="DRAWINGS">FIG. 4</figref> displays a selected route, in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0032"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a schematic illustration of an image block from the data structure of <figref idrefs="DRAWINGS">FIG. 2</figref>, along with its ancestors, useful in understanding the flow chart of <figref idrefs="DRAWINGS">FIG. 8</figref>; and</p>
      <p num="p-0033"> <figref idrefs="DRAWINGS">FIGS. 9</figref> <i>a </i>and <b>9</b> <i>b </i>are flow diagrams illustrating obtaining a benefit for sending digital information over a communication network, in accordance with the present invention.</p>
    </description-of-drawings> <heading>DESCRIPTION</heading> <p num="p-0034"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a schematic illustration of a system <b>300</b> for obtaining compensation for sending information over a communication network in accordance with the present invention. In <figref idrefs="DRAWINGS">FIG. 1</figref>, the disclosed embodiment of the system <b>300</b> includes one or more computer servers <b>26</b> (one server <b>26</b> is shown), a communication network <b>306</b> such as the Internet or other computer network, at least one image database <b>40</b>, at least one course database <b>60</b>, at least one third-party electronic-commerce business or entity (e-commerce business) <b>304</b>, and at least one client computer <b>310</b>. Each client computer <b>310</b> typically will include at least a processor <b>20</b>, a visual display <b>22</b>, and a communication network interface <b>24</b>. The e-commerce business <b>304</b> includes one or more server computers for communication with the server(s) <b>26</b> and the client computer(s) <b>310</b>, generally via the network <b>306</b>. The network <b>306</b> can include a variety of different and/or similar links including wireless links.</p>
    <p num="p-0035">Digital information representing real-life three-dimensional images is stored in at least one of the image databases <b>40</b>, and digital information representing a travel course or route is stored in at least one of the course databases <b>60</b>. Real-life three-dimensional images are created by taking two-dimensional photographic images and, through the use of the rendering method described in U.S. patent application Ser. No. 08/939,948 or other software and/or rendering schemes/devices, rendering three-dimensional images such that the images include the photographic images. The computer server <b>26</b> is in communication with the image database(s) <b>40</b>, the course database(s) <b>60</b>, and the communication network <b>306</b>. The client computer <b>310</b> is also in communication with the communication network <b>306</b> via the communication network interface <b>24</b>. In one embodiment, the communication network interface <b>24</b> is a standard 33,600 kilobyte per second modem. Other modems, faster or slower, may also be used. Additionally, other connections may be used for the communication interface <b>24</b>, such as ISDN connections or direct routers.</p>
    <p num="p-0036">An end user uses the client computer <b>310</b> to request real-life three-dimensional images which depict views of a user defined virtual travel course or which depict views of preset guided tour. The request is made by contacting an e-commerce business <b>304</b> that is in communication with the communication network <b>306</b>. The e-commerce business <b>304</b> redirects the end user's request to the computer server <b>26</b>, typically in a way that is transparent to the end user. In response to the end user's request, the computer server <b>26</b> retrieves the digital information representing the requested real-life three-dimensional images from the image database <b>40</b> that depict views of the user defined virtual travel course or which depict views of a preset guided tour. The computer server <b>26</b> transmits the requested digital information to the computer client <b>310</b> via the communication network <b>306</b>. The processor <b>20</b> in the computer client <b>310</b> receives the requested digital information and reconstructs the real-life three-dimensional images and displays them on the visual display <b>22</b>.</p>
    <p num="p-0037">Alternatively or additionally, the processor <b>20</b> communicates with the computer server <b>26</b> through a direct communication line. Further alternatively or additionally, the processor <b>20</b> receives a storage disk <b>28</b>, such as a CD, from those who supply the real-life three-dimensional images or from any other distribution source.</p>
    <p num="p-0038">The e-commerce business <b>304</b> is also in communication with the computer server <b>26</b>, either directly or via the communication network <b>306</b>. In response to the computer server <b>26</b> transmitting the user requested digital information to the end user, the entity that controls, operates, and/or owns the computer server <b>26</b> and/or the data in the databases <b>40</b>, <b>60</b> receives some benefit. The benefit may include, but is not limited to, monetary compensation, and/or increased recognition of the entity by the public or some group (including increased traffic to the entity's website).</p>
    <p num="p-0039"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a schematic illustration of the data structure of images stored in an image database <b>40</b> residing on, or in communication with the computer server <b>26</b>, in accordance with a preferred embodiment of the present invention. Image database <b>40</b> comprises a plurality of image blocks <b>42</b>, labeled <b>42</b>A, <b>42</b>B, etc., which contain data representing terrain in various areas as would be perceived from different heights. Preferably, substantially all of blocks <b>42</b> are of the same data size. Preferably, the size of the blocks is determined according to the expected rate of transmission of data via modem <b>24</b>, so that a block <b>42</b> may be transmitted on the average within a predetermined amount of time, for example, half a second. In a preferred embodiment of the present invention, the blocks comprise 256×256 pixels, although the blocks may be of any other suitable size. Preferably, the blocks are divided into sub-blocks <b>43</b> of smaller sizes, such that processors which work with slow modems may download small sub-blocks in case the entire block is not required. In a preferred embodiment of the present invention, each block <b>42</b> is divided into sixteen sub-blocks <b>43</b> of 64×64 pixels. Each pixel is preferably represented by a color and an elevation attribute, as is known in the art. Blocks <b>42</b> are preferably real-life images of terrain areas received from airborne or satellite cameras.</p>
    <p num="p-0040">Preferably, each sub-block <b>43</b> includes an attachment field in which additional optional data objects associated with the area covered by the sub-block are described. These objects preferably include, but are not limited to, labels, annotations, lines and 3D objects. Each object is preferably accompanied by coordinates which state the position of the object within sub-block <b>43</b>. Preferably, the labels are stored in text format, the lines are stored as vectors, and the 3D objects are stored as polygons, although any suitable storage format may be used.</p>
    <p num="p-0041">The objects may be used to represent existing structures which are not viewed sufficiently well when shown as part of the image. Alternatively or additionally, the structures may be used to overlay virtual structures on the terrain. For example, it is possible to add planned buildings to the terrain and thus see the effect of the buildings on the view. Further alternatively or additionally, the objects may be used to overlay map symbols and other markings on the terrain. The markings are preferably overlaid on the view at a constant size regardless of the resolution level of the terrain displayed.</p>
    <p num="p-0042">Blocks <b>42</b> are preferably stored in the image database <b>40</b> in a compressed form using any suitable compression method, such as JPEG. Blocks <b>42</b> are classified in successive resolution levels <b>44</b> labeled <b>44</b>A, <b>44</b>B, etc., according to the height from which they view the terrain and, therefore, the level of detail which they include. A plurality of blocks <b>42</b>A which belong to the lowest resolution level <b>44</b>A, labeled “level <b>1</b>,” cover the largest area per block and therefore have the least detail per area unit. It is noted that the size of the geographical area covered by blocks <b>42</b>A of “level <b>1</b>” is dependent on the specific application of the image database <b>40</b> and may be very diverse. For example, in some flight applications, a single block <b>42</b>A includes an image of the entire Planet Earth, while in an atom-simulation application, which shows the terrain of an atom, block <b>42</b>A shows the entire atom. Blocks <b>42</b>B of the next level <b>44</b>B, labeled “level <b>2</b>,” preferably cover a quarter of the area of blocks <b>42</b>A of “level <b>1</b>”. Thus, for substantially each block <b>42</b>A, there exist four blocks <b>42</b>B which cover the same area. In a similar manner, each successive level <b>44</b> comprises blocks <b>42</b> which cover a quarter of the area of the blocks <b>42</b> of the lower resolution level.</p>
    <p num="p-0043">Four blocks <b>55</b> of a certain level <b>44</b>C, which cover the same area as a block <b>57</b> of the preceding level <b>44</b>B, are referred to as descendants of block <b>57</b>. Conversely, block <b>57</b> is referred to herein as the parent of blocks <b>55</b>. The parent block <b>59</b> of block <b>57</b> is referred to herein as an “ancestor” of blocks <b>55</b>, and is said to be of a lower resolution level than its descendants. It is noted that in <figref idrefs="DRAWINGS">FIG. 2</figref>, the lower resolution levels appear higher on the page.</p>
    <p num="p-0044">Preferably, each block <b>42</b> in the image database <b>40</b> includes pointers <b>52</b> to the four descendants of the block. If one or more of the descendants does not exist, a null pointer <b>56</b> is preferably used. Preferably, a header record <b>54</b> comprises an index to blocks <b>42</b>A of “level <b>1</b>” such that the processor <b>20</b> can easily find the block <b>42</b>A which covers a desired area.</p>
    <p num="p-0045">The number of levels <b>44</b> is dependent on the images input to the computer server <b>26</b> and may differ for different areas of terrain. Thus, one block <b>42</b>A may have descendants up to level <b>12</b>, for example, while another block <b>42</b>A may have no descendants. It is also noted that the number of descendants of each block <b>42</b> may have a value different from four, for example nine, and may differ for different levels <b>44</b>.</p>
    <p num="p-0046">Preferably, each block <b>42</b> is referenced using longitudinal and latitudinal (x,y) coordinates of one of the points in the block, such as the top right corner pixel, together with the resolution level <b>44</b> of the block.</p>
    <p num="p-0047"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a flow chart illustrating a method for preparation of the image database <b>40</b>, in accordance with a preferred embodiment of the present invention. Preferably, all the steps described in <figref idrefs="DRAWINGS">FIG. 3</figref> are performed automatically by a processor (referred to herein as a Terra builder). The Terra Builder may prepare the images online provided the images are supplied at a sufficient rate. Alternatively or additionally, the Terra Builder operates together with a human operator to achieve better accuracy in the preparation of the image database <b>40</b>.</p>
    <p num="p-0048">Preferably, the Terra builder receives one or more images of a terrain area covered by the database <b>40</b> (step <b>200</b>). The images are preferably received in a standard format, such as TIFF or bitmap. The images preferably cover adjacent areas or are partially overlapping. Some of the images may cover the same area at different levels of resolution.</p>
    <p num="p-0049">The processor cuts the image up into blocks <b>42</b> and assigns these blocks temporarily to the highest resolution level (step <b>202</b>). Blocks of lower levels of resolution are prepared by eliminating data from the original blocks (step <b>204</b>). Preferably, the blocks of lower resolution levels are prepared by decimation, for example, by eliminating odd (or even) rows and columns from the higher level blocks. Further preferably, the blocks are filtered using a low pass filter, most preferably before the decimation.</p>
    <p num="p-0050">Thereafter, the blocks from different images are aligned relative to each other, based on the coordinates of the images and the meter-per-pixel resolution values of the images (step <b>206</b>). Preferably, the coordinates and meter-per-pixel values are received together with the images. Alternatively, an operator determines and inputs the coordinate correspondences and meter-per-pixel values by viewing the images. Further alternatively or additionally, the operator inputs the heights of the terrain for some or all of the pixels.</p>
    <p num="p-0051">Blocks <b>42</b> are then compressed, for example, using the JPEG compression method (step <b>208</b>). The operator may add labels, lines, virtual structures and other objects, before or after the compression (step <b>210</b>). Alternatively or additionally, the processor automatically derives such objects from the images. For example, the processor may identify roads and/or runways in the images and represent them as objects so that they appear more clearly in substantially any resolution of display.</p>
    <p num="p-0052">It is noted that although the hierarchical structure of the image database <b>40</b> requires extra storage space, relative to a non-hierarchical record of the terrain, the advantages of the hierarchical structure justify the extra storage space required. The use of the hierarchical structure allows faster rendering of the images on the visual display <b>22</b> and allows fast download of required images at low resolution levels. Optionally, in order to reduce storage requirements, some of blocks <b>42</b> are stored only in some of resolution levels <b>44</b>, and when non-existent resolution levels are required, computer server <b>26</b> generates the required block from a descendant block of a higher resolution level.</p>
    <p num="p-0053">Preferably, the user of the processor <b>20</b> on the client computer <b>310</b> is able to add virtual structures and/or other objects to the terrain described by database <b>40</b>, while viewing the terrain. Preferably, a file stored locally on the processor <b>20</b> stores descriptions of the virtual structures added by the user of the processor <b>20</b>.</p>
    <p num="p-0054"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a schematic block diagram illustrating an example of a course stored on a course database <b>60</b> residing on or in communication with the computer server <b>26</b>, in accordance with a preferred embodiment of the present invention. Preferably, the course database <b>60</b> includes a catalog file <b>62</b>, which lists all the available routes stored in the course database <b>60</b>. For each route, the course database <b>60</b> preferably includes a list <b>64</b> of three-coordinate points <b>66</b> which describe the route. The three coordinates preferably represent longitudinal, latitudinal, and height coordinates of the points along the course, as are known in the art of terrain mapping. Preferably, list <b>64</b> also includes speed settings <b>68</b>, and/or other flight-relevant data.</p>
    <p num="p-0055">The routes in the course database <b>60</b> preferably include routes terminating in landings at various airports. Using these routes, pilots may become familiar with airports to which they are scheduled to fly. Alternatively or additionally, the course database <b>60</b> includes routes of flight through difficult access areas, such as deep canyons in which helicopters need to fly. Further alternatively or additionally, the course database <b>60</b> may include routes for training military pilots in approaching a required target. Further alternatively or additionally, the course database <b>60</b> may include land routes through buildings, town, cities, and/or countries</p>
    <p num="p-0056">It is noted that other scenarios may be included in the course database <b>60</b>, such as online images from an area of interest For example, a route may be used to display a car race, and the points <b>66</b> describing the route may be received online using a GPS from one of the cars in the race. The cars are preferably superimposed on the images, using methods known in the art. A user watching the race on a home computer may select any viewpoint of interest and is not limited to pre-chosen viewpoints selected by others. The user requested real-life three-dimensional images received by the client computer <b>310</b> arrive in the form of a stream of digital data. In order for the images to be viewable on the visual display <b>22</b>, they must be reconstructed from the stream of digital data by the processor <b>20</b> on the client computer <b>310</b>.</p>
    <p num="p-0057"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a schematic block diagram of the processor <b>20</b> on the client computer <b>310</b>, in accordance with a preferred embodiment of the present invention. The blocks are preferably realized as software processes running on a general-purpose microcomputer, although dedicated hardware realizations are also possible. Preferably, the processor <b>20</b> comprises a navigator <b>70</b>, which keeps track of a viewpoint of a virtual viewer. The viewpoint preferably follows a predetermined course which a user of processor <b>20</b> is supposed to follow. Preferably, the course is received from course database <b>60</b>.</p>
    <p num="p-0058">Preferably, the navigator <b>70</b> sets a default view direction of the viewpoint in the direction of movement along the course. Alternatively, the default view direction is set directly down towards the terrain. The user may change the view direction of the viewpoint without moving out of the course. Therefore, there is no compulsory correlation between the flight direction and the view direction. Preferably, the user may change the speed of motion along the course. Further preferably, the user may move the viewpoint out of the course in order to view the area around the predetermined course, or to try to find a better course. Preferably, the user controls the direction, speed, altitude and/or any other parameter of the viewpoint. Specifically, the user may freeze the viewpoint in order to have a better look at the view from a certain point or angle.</p>
    <p num="p-0059">The processor <b>20</b> preferably further comprises a renderer <b>72</b>, which calculates the view from the viewpoint and continuously renders the view on the visual display <b>22</b>. The renderer <b>72</b> determines the coordinates of the pixels it needs in order to render the view and requests the descriptions of these pixels from a cache manager <b>74</b>. Preferably, the renderer <b>72</b> determines which blocks <b>42</b> and/or sub-blocks <b>43</b> include the required pixels. Alternatively, the cache manager <b>74</b> determines the identity of the required blocks <b>42</b> and/or sub-blocks <b>43</b>. Along with each required pixel, block <b>42</b>, or sub-block <b>43</b>, renderer <b>72</b> preferably states the resolution level <b>44</b> at which the block is required. The resolution level is preferably determined based on the distance between the viewpoint and the desired pixel or block <b>42</b>. Further preferably, the resolution level is also dependent on the number of pixels in the image displayed on the visual display <b>22</b>. Preferably, the resolution levels are chosen so that an approximate 1:1 ratio is achieved between the number of displayed pixels and the number of data pixels. Preferably, the renderer <b>72</b> also overlays the objects associated with the rendered sub-blocks <b>43</b>.</p>
    <p num="p-0060">Preferably, cache manager <b>74</b> manages a group of blocks <b>42</b> and/or sub-blocks <b>43</b> in a cache memory <b>32</b> of the processor <b>20</b>, for example in the main memory of the processor <b>20</b>, in accordance with a method described hereinbelow. Alternatively or additionally, the cache memory <b>32</b> is defined in a local hard disk associated with the processor <b>20</b>. Thus, even if the processor <b>20</b> is shut down, the renderer can immediately resume operation when the processor <b>20</b> is turned on again, at the point it left off, without downloading the data again from the computer server <b>26</b>. Further alternatively or additionally, the processor <b>20</b> determines areas which are most commonly visited by the user of the processor <b>20</b>, and blocks <b>42</b> from these areas are permanently stored in the local hard disk of the client computer <b>310</b>. One such preferred application involves positioning the processor <b>20</b> within a ground vehicle in order to view the surroundings of the vehicle. Since the vehicle is usually located in the same area, the required download time may be reduced substantially.</p>
    <p num="p-0061">It is noted that the term cache memory is used herein generally to refer to any relatively small memory which can be accessed rapidly by the processor <b>20</b> and is used to save data which is most likely to be used by the processor <b>20</b>.</p>
    <p num="p-0062">The cache manager <b>74</b> downloads from the computer server <b>26</b> the blocks <b>42</b> and/or sub-blocks <b>43</b> required by renderer <b>72</b>, if they are not already stored in cache memory <b>32</b>, and meanwhile provides replacement blocks from the cache memory. Preferably, the cache manager <b>74</b> references blocks <b>42</b> on the computer server <b>26</b> by providing pointers to the required blocks. The cache manager <b>74</b> has the pointers for the lowest resolution level blocks <b>42</b>A from header record <b>54</b>. The pointer to a desired block <b>42</b> of any other level <b>44</b> is preferably taken from the parent block of the desired block, as described above. Therefore, as described hereinbelow, the cache manager <b>74</b> preferably always requests that the computer server <b>26</b> send a block <b>42</b> after the cache manager has received its parent block.</p>
    <p num="p-0063">As previously stated, after the end user requests a real-life three-dimensional image from an e-commerce business <b>304</b> via the client computer <b>310</b>, the request is redirected by the e-commerce business <b>304</b> to the computer server <b>26</b>. Preferably, the processor <b>20</b> on the client computer <b>310</b> establishes one or more communication connections <b>76</b> with the computer server <b>26</b> through which blocks <b>42</b> are sent to the processor <b>20</b>. Connections <b>76</b> are preferably standard TCP connections as are known in the art, although any other protocol may be used to form the connection. Preferably, when connections <b>76</b> are not in use bringing blocks <b>42</b> required by the renderer <b>72</b>, the cache manager <b>74</b> downloads blocks in the area of the viewpoint to fill cache memory <b>32</b>. Preferably, the cache manager <b>74</b> attempts to fill cache memory <b>32</b> with a sufficient number of blocks, such that for any view direction of the current viewpoint, all blocks <b>42</b> required by the renderer <b>72</b> are stored in cache memory <b>32</b>. Preferably, the cache manager <b>74</b> stores in cache memory <b>32</b> the same number of blocks <b>42</b> in each resolution level <b>44</b>. Preferably, cache memory <b>32</b> stores, for each resolution level <b>44</b>, between 9 and 36 blocks, which are most preferably organized in a square centered directly below the location of the viewpoint. In a preferred embodiment of the present invention, cache memory <b>32</b> stores sixteen blocks <b>42</b> organized in a square for each resolution level <b>44</b>. Blocks <b>42</b> are preferably chosen such that the viewpoint is closest to the center of the square, most preferably, as described in the above-mentioned U.S. patent application Ser. No. 08/939,948.</p>
    <p num="p-0064">Preferably, blocks <b>42</b> are stored in cache memory <b>32</b> in the compressed form in which they are received from the computer server <b>26</b>. Further preferably, the cache manager <b>74</b> decompresses the blocks before they are provided to the renderer <b>72</b>. Preferably, the cache manager <b>74</b> manages, in addition to cache memory <b>32</b>, an open cache memory <b>34</b> in which blocks <b>42</b> and/or sub-blocks <b>43</b> which were decompressed are stored. Preferably, open cache memory <b>34</b> is of a size determined according to the amount of available empty storage space on the memory associated with the processor <b>20</b> and/or the size of the image rendered on the visual display <b>22</b>. Preferably, the user of the processor <b>20</b> may adjust the size of open cache memory <b>34</b> in order to achieve maximal rendering speed by saving the time required for decompression. In a preferred embodiment of the present invention, open cache memory <b>34</b> has a default size sufficient to store a few hundred decompressed sub-blocks <b>43</b>.</p>
    <p num="p-0065">Preferably, when open cache memory <b>34</b> is full, a least recently used (LRU) method is used to determine which sub-block <b>43</b> is to be discarded to make room for a new sub-block. A preferred LRU method is described in the above-mentioned Ser. No. 08/939,948 patent application. Alternatively or additionally, any other suitable method of memory management may be used to manage cache memory <b>32</b> and/or open cache memory <b>34</b>.</p>
    <p num="p-0066">The renderer <b>72</b> uses blocks <b>42</b> from cache manager <b>74</b> to render the required view on display <b>22</b>. Preferably, when the cache manager <b>74</b> provides a block <b>42</b> of a lower resolution level than that requested by the renderer <b>72</b>, the renderer <b>72</b> uses the provided block to interpolate a higher resolution-level block. Preferably, the higher resolution-level block is interpolated using any method known in the art, such as bilinear, fractal, or texture blending.</p>
    <p num="p-0067">When the cache manager <b>74</b> finishes downloading an additional block of a higher resolution level from the computer server <b>26</b>, the block is provided to the renderer <b>72</b>, which updates the rendered view accordingly. Preferably, when the viewpoint is in motion, the renderer <b>72</b> updates the view at least ten times per second so that the user has a perception of constant movement, although other rates of update may also be used. Preferably, the renderer <b>72</b> renders the view each time from scratch without using previously-rendered views.</p>
    <p num="p-0068">Preferably, the renderer <b>72</b> is as described in the above mentioned U.S. patent application Ser. No. 08/939,948. Alternatively or additionally, the renderer <b>72</b> may operate in accordance with any other method known in the art. The renderer <b>72</b> is preferably implemented entirely in software. Alternatively, the renderer <b>72</b> includes a dedicated hardware processor, such as a 3D graphic accelerator, along with a software package running on general purpose processor <b>20</b> which provides blocks <b>42</b> to the dedicated hardware processor.</p>
    <p num="p-0069"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a schematic view of a viewpoint <b>80</b> and a scene <b>82</b> viewed therefrom, used to explain the operation of the renderer <b>72</b>, in accordance with a preferred embodiment of the present invention. Scene <b>82</b> includes areas <b>84</b> close to viewpoint <b>80</b>, for example 1 kilometer from the viewpoint. Other areas <b>86</b> of scene <b>82</b> are far away from viewpoint <b>80</b>, for example, 50-100 kilometers away. Still other areas <b>85</b> of scene <b>82</b> may be at other distances from viewpoint <b>80</b>. In order to build a real life image of the view from viewpoint <b>80</b>, the renderer <b>72</b> needs blocks <b>42</b> from a high resolution level <b>44</b> of area <b>84</b>, such that a group of buildings <b>88</b> in area <b>84</b> are seen in the image as they would be seen from 1 kilometer away. However, for area <b>86</b>, the renderer <b>72</b> needs only a low resolution level block <b>42</b> since a group of buildings <b>90</b> in area <b>86</b> would not be seen from viewpoint <b>80</b>.</p>
    <p num="p-0070">Preferably, the renderer <b>72</b> determines the exact blocks needed and calls for them using their (x,y) coordinates and their resolution level <b>44</b>. Alternatively or additionally, the renderer <b>72</b> specifies, for each resolution level <b>44</b>, the coordinates of the boundaries of the necessary areas, and the cache manager <b>74</b> determines the identities of the required blocks <b>42</b>. Preferably, when only a small part of a block <b>42</b> is required, the cache manager <b>74</b> orders only the required sub-blocks <b>43</b> in order to save transmission time. On the average, rendering a view image requires between about 20 and 200 sub-blocks <b>43</b> of various resolution levels <b>44</b>.</p>
    <p num="p-0071"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a flow chart illustrating the actions of the cache manager <b>74</b> in displaying a selected route by the processor <b>20</b>, in accordance with a preferred embodiment of the present invention. After downloading the first batch of level <b>1</b> blocks, as indicated in block <b>102</b>, the cache manager <b>74</b> moves into a wait state, as indicated by block <b>100</b>.</p>
    <p num="p-0072">Reference is also made to <figref idrefs="DRAWINGS">FIG. 8</figref>, which is a schematic illustration of a block <b>150</b> (corresponding either to one of blocks <b>42</b> or one of sub-blocks <b>43</b>) requested by the renderer <b>72</b>, and ancestors <b>152</b>, <b>154</b> and <b>158</b> of the requested block. When a request for block <b>150</b>, identified as “x,” and having resolution level N, is received from the renderer <b>72</b>, the cache manager <b>74</b> determines, as indicated in block <b>104</b> (<figref idrefs="DRAWINGS">FIG. 7</figref>), the level j of the highest resolution-level ancestor of block x stored in cache memory <b>32</b>. If the block <b>42</b> itself is stored in cache memory <b>32</b> (i.e., j=N), the block is provided to renderer <b>72</b>. Otherwise, the highest resolution level ancestor <b>152</b> of block x which is stored in cache memory <b>32</b> is provided to the renderer <b>72</b>, as indicated in block <b>106</b>. As described hereinbelow, the cache manager <b>74</b> downloads the rest of the ancestors <b>158</b> of block x from the computer server <b>26</b> in order of increasing resolution levels, as indicated by an arrow <b>156</b> in <figref idrefs="DRAWINGS">FIG. 8</figref>. As the blocks are received from the computer server <b>26</b>, they are supplied to the renderer <b>72</b> so that the user sees an image whose resolution increases with time.</p>
    <p num="p-0073">Thus, if viewpoint <b>80</b> is not changed, or is changed relatively slowly, the resolution level of the images displayed by the renderer <b>72</b> is slowly increased until the maximal desired resolution is reached. Naturally, if the image database <b>40</b> does not include blocks at a desired level of resolution for a certain area, the last block supplied is of the highest existing level of resolution for that certain area.</p>
    <p num="p-0074">If no ancestor of block x is found in memory <b>32</b> (an eventuality not shown in the figure), the level <b>1</b> ancestor <b>154</b> of the block is ordered from the computer server <b>26</b>, based on the pointer to the level <b>1</b> ancestor block in header record <b>54</b>. While waiting for the ordered block, renderer <b>72</b> preferably renders a blank block to the display. Alternatively, renderer <b>72</b> waits until level <b>1</b> ancestor <b>154</b> is received. However, it is noted that such cases are very rare, since blocks <b>42</b>A of level <b>1</b> cover very large areas, and usually, blocks <b>42</b>A adjacent to the block in use are also downloaded and stored in cache memory <b>32</b>.</p>
    <p num="p-0075">If block x itself was not found in memory <b>32</b>, the cache manager <b>74</b> adds to a download queue the block x and all its ancestors <b>158</b> of resolution levels higher than level j, as indicated by block <b>108</b>. If all TCP connections <b>76</b> available to processor <b>20</b> are in use, the cache manager <b>74</b> returns to wait state <b>100</b> until one of connections <b>76</b> is available. If one of connections <b>76</b> is available the newly added blocks to the queue are immediately ordered. Preferably, the cache manager <b>74</b> proceeds to send a download order to the computer server <b>26</b> for the lowest resolution-level block in the download queue, as indicated by blocks <b>112</b>, <b>114</b>, <b>116</b> and <b>118</b>. Alternatively or additionally, the download queue is managed by the computer server <b>26</b>.</p>
    <p num="p-0076">Preferably, if more than one block of the lowest resolution level is in the queue, the last entered block is downloaded (so long as the block is still within range, as described hereinbelow). The downloaded block is thereafter removed from the queue, either when the download order is sent as indicated in block <b>120</b>, or when the block has been completely received. The cache manager <b>74</b> preferably moves back to wait state <b>100</b> to wait for the completion of the downloading of the block.</p>
    <p num="p-0077">Preferably, before a download order for block x is sent to the computer server <b>26</b>, the cache manager <b>74</b> checks whether the block is still needed, as indicated by block <b>116</b>. Most preferably, the cache manager <b>74</b> checks whether the block is within a range of the current viewpoint such that it would meet the criteria for the cache manager <b>74</b> to order it for download to cache memory <b>32</b>. If block x is not within the range of the current viewpoint, the block is not useful for the renderer <b>72</b> and is therefore not downloaded. This situation may occur when the viewpoint has changed substantially since block x was put into the download queue. Alternatively or additionally, the cache manager <b>74</b> scans the download queue periodically for block orders which are not currently useful and must be erased from the queue.</p>
    <p num="p-0078">When one of TCP connections <b>76</b> notifies the cache manager <b>74</b> that the transfer of a block Y has been completed, the cache manager <b>74</b> checks whether the block is currently needed by the renderer <b>72</b>, as indicated by block <b>122</b>. Preferably, the cache manager <b>74</b> queries the renderer <b>72</b> regarding each received block as to whether the renderer <b>72</b> currently needs the block. Alternatively or additionally, the cache manager <b>74</b> maintains a list of blocks for which download orders were sent, and therefore are needed by the renderer <b>72</b>. Preferably, the renderer <b>72</b> notifies the cache manager <b>74</b> of blocks it requested and did not receive and which it does not need any more. Alternatively, each order from the renderer <b>72</b> to the cache manager <b>74</b> includes all the blocks it needs, and any blocks not in the order are not needed.</p>
    <p num="p-0079">If renderer <b>72</b> needs the downloaded block (i.e., it was not ordered solely to fill cache memory <b>32</b>, as described hereinbelow), it is passed to the renderer <b>72</b>, as indicated by block <b>124</b>. Preferably, all the received blocks are stored in cache memory <b>32</b> for later use, as indicated by block <b>126</b>. If cache memory <b>32</b> is full, a block beyond the predetermined range from the current viewpoint is discarded, as indicated by block <b>128</b>. Preferably, the discarded block is the least recently used block which is beyond the predetermined range. Alternatively, the discarded block is chosen from the highest resolution level for which there are blocks beyond the predetermined range.</p>
    <p num="p-0080">After downloading of a block has been completed, one of connections <b>76</b> is necessarily not in use. If the download queue is not empty, a block from the queue is downloaded as described hereinabove and indicated in blocks <b>112</b>, <b>114</b>, <b>116</b> and <b>118</b>. However, if the queue is empty, the cache manager <b>74</b> fills cache memory <b>32</b> with the blocks within the range of the current viewpoint, so that, for any direction of view from the current viewpoint, there is no need to download further blocks from the computer server <b>26</b>.</p>
    <p num="p-0081">Preferably, the next block downloaded for filling cache memory <b>32</b> is from the lowest resolution level for which all the blocks in the range of the viewpoint are not already in the cache memory, as indicated in block <b>130</b>. Further preferably, the cache manager <b>74</b> first downloads the eight blocks surrounding the block which is directly below the current viewpoint. Alternatively or additionally, the blocks are ordered according to the current view direction of the viewpoint.</p>
    <p num="p-0082"> <figref idrefs="DRAWINGS">FIGS. 9</figref> <i>a </i>and <b>9</b> <i>b </i>are flow diagrams illustrating a method for obtaining a benefit for sending information over a communication network, in accordance with an embodiment of the invention. Referring to <figref idrefs="DRAWINGS">FIGS. 9</figref> <i>a </i>and <b>9</b> <i>b</i>, the end user first uses the client computer <b>310</b> containing the processor <b>20</b> to connect to the communication network <b>306</b> via the communication network interface <b>24</b> (step <b>400</b>). After this connection is established, the end user establishes communication with an e-commerce business <b>304</b> that is also in communication with the communication network <b>306</b> (step <b>402</b>). The connection with the e-commerce business <b>304</b> can be established through the use of a communication network browser program that is executed by the processor <b>20</b> on the client computer <b>310</b>. Examples of satisfactory communication network browser programs include, but are not limited to, Netscape Navigator and Internet Explorer.</p>
    <p num="p-0083">After the connection with an e-commerce business <b>304</b> is established, the end user either makes a request for real-life three-dimensional images that depict views of a user defined virtual travel course (step <b>404</b>) or the user makes a request for real-life three-dimensional images that depict views of a preset guided tour (step <b>420</b>). If the end user's request is for the real-life three-dimensional images that depict views of a user defined travel course, the request is redirected by the e-commerce business <b>304</b> to the computer server <b>26</b> (step <b>406</b>). When the e-commerce business <b>304</b> redirects the user's request, it sends digital information representing the user defined travel course and overlay data to the computer server <b>26</b>. The overlay data can include, but is not limited to, digital information representing things such as labels, three-dimensional objects, and billboards. This overlay data can be inserted into the views along the user defined travel course. The user defined travel course information and the overlay data, once received by the computer server <b>26</b>, are converted by the computer server <b>26</b> into a format that is compatible with the navigator <b>70</b> running on the client computer <b>310</b>.</p>
    <p num="p-0084">Upon redirection, the processor <b>20</b> on the client computer <b>310</b> established communication with the computer server <b>26</b> (step <b>408</b>). Preferably, if the processor <b>20</b> is accessing the computer server <b>26</b> for the first time, the computer server <b>26</b> sends the processor <b>20</b> a software package which includes the navigator <b>70</b>, the renderer <b>72</b> and the cache manager <b>74</b> (step <b>410</b>). The software package can be in the form of an ActiveX plug-in sent to the communication network browser running on the processor <b>20</b>. Alternatively or additionally, the user of the processor <b>20</b> may receive the software package on a compact disk (CD) or on any other storage media. Preferably, the software package is stored on the client computer <b>310</b> so that the package need be sent only once.</p>
    <p num="p-0085">Thereafter, the computer server <b>26</b> sends the user defined virtual travel course information and overlay data to the navigator <b>70</b>, preferably using one or more of TCP connections <b>76</b> (step <b>412</b>).</p>
    <p num="p-0086">Alternatively, if the end user's request is for a preset virtual guided tour from the e-commerce business <b>304</b> (step <b>420</b>), the e-commerce business determines if the proper software (navigator <b>70</b>, renderer <b>72</b> and cache manager <b>74</b>) is running on the processor <b>20</b> (step <b>422</b>). If this software is not present on processor <b>20</b> the e-commerce business <b>304</b> redirects the client computer <b>310</b> to the server <b>26</b> to download the software (step <b>424</b>). If the software is already present on processor <b>20</b> or after the software is downloaded to processor <b>20</b>, the e-commerce business sends the properly formatted preset virtual guided tour course information and overlay data directly to the client computer <b>310</b> (step <b>426</b>). In a preset virtual guided tour, the user has the option of following the downloaded preset tour course or navigating freely along any alternate user defined travel course.</p>
    <p num="p-0087">After the user defined travel course information or the virtual guided tour information is received by the processor <b>20</b>, the navigator <b>70</b> begins to run on the downloaded course. Concurrently, the cache manager <b>74</b> is ordered to download one or more, preferably four, level <b>1</b> blocks <b>42</b>A surrounding the starting point of the route from the image database <b>40</b> that is in communication with the computer server <b>26</b> (step <b>414</b>). Thus, the cache manager <b>74</b> will have in local cache memory <b>32</b> images of a very large area surrounding the starting point. The cache manager <b>74</b> can therefore provide to the renderer <b>72</b> images which cover substantially any area, even if only at a low resolution level initially. The renderer <b>72</b> then reconstructs the images and sends them to the visual display <b>22</b> (step <b>416</b>). Alternatively or additionally, the user may choose to begin a tour at a specific location, without referring to a specific route.</p>
    <p num="p-0088">The user is able to decide whether to display some or all of the objects associated with the database. Thus, the user may request to view only the images without any of the objects, or to see only objects which represent existing structures. The user is able to request to view the images with or without labels. Thus, on a first visit to a new area, the user may view the area with labels which allow easy acquaintance with the area, while at a second visit, the user may omit the labels in order to test whether he/she has properly memorized the important labeled landmarks. Preferably, the user is able to switch between viewing the terrain with and without the objects, so that, for example, the user may easily compare the view of a desired area with and without a group of planned structures.</p>
    <p num="p-0089">In response to the computer server <b>26</b> transmitting the digital information representing real-life three-dimensional images to an end user, the entity that controls, operates, and/or owns the server <b>26</b> and/or the data in the databases <b>40</b>, <b>60</b> receives some benefit (step <b>418</b>). The benefit can include, but is not limited to, monetary compensation and/or increased recognition of the entity by the public or some group (including increased “traffic” or “hits” to the entity's web site). The monetary compensation can be provided to the entity by the e-commerce business <b>304</b> or by some other company such as an advertiser associated with the entity, in that the entity includes the advertiser's advertisements within the images sent by the entity to the end user.</p>
    <p num="p-0090">Alternatively, an end user can connect to the computer server <b>26</b> to request real-life three-dimensional image depicting views of preset virtual guided tours. The end user uses the client computer <b>310</b> to establish a connection with the computer server <b>26</b>. The computer server <b>26</b> sends the catalog <b>62</b> and/or the header record <b>54</b> to the processor <b>20</b>. The end user of the processor <b>20</b> chooses a desired route from the catalog <b>62</b>, and the navigator <b>70</b> downloads the route from the course database <b>60</b> that is in communication with the computer server <b>26</b>. The navigator <b>70</b> then begins to run on the downloaded course as describe hereinabove.</p>
    <p num="p-0091">It will be appreciated that the above-described embodiments relate to displaying three dimensional real-life images. A variety of embodiments and uses are within the scope of the invention including, but are not limited to, displaying of terrain for purposes of real estate trading, travel, education and amusement uses, in which the terrain may be shown at various levels of detail. Furthermore, the terrain is not limited to the Earth or parts thereof, and may cover other planets (real or virtual) and/or 3D views of surfaces of real or imaginary objects, such as views showing the atomic structure of a material, and the like. In addition, the data streaming methods of the present invention may be used to convey large databases of data which are to be displayed graphically, such as in graphic displays of stock values. It also will be appreciated that the embodiments described above are cited by way of example, and the full scope of the invention is limited only by the claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3757037">US3757037</a></td><td class="patent-data-table-td patent-date-value">Feb 2, 1972</td><td class="patent-data-table-td patent-date-value">Sep 4, 1973</td><td class="patent-data-table-td ">N Bialek</td><td class="patent-data-table-td ">Video image retrieval catalog system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3984671">US3984671</a></td><td class="patent-data-table-td patent-date-value">Aug 30, 1974</td><td class="patent-data-table-td patent-date-value">Oct 5, 1976</td><td class="patent-data-table-td ">Nasa</td><td class="patent-data-table-td ">Optical process for producing classification maps from multispectral data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4055004">US4055004</a></td><td class="patent-data-table-td patent-date-value">Oct 17, 1975</td><td class="patent-data-table-td patent-date-value">Oct 25, 1977</td><td class="patent-data-table-td ">The United States Of America As Represented By The Administrator Of The National Aeronautics And Space Administration</td><td class="patent-data-table-td ">Full color hybrid display for aircraft simulators</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4070705">US4070705</a></td><td class="patent-data-table-td patent-date-value">Nov 20, 1975</td><td class="patent-data-table-td patent-date-value">Jan 24, 1978</td><td class="patent-data-table-td ">The Singer Company</td><td class="patent-data-table-td ">Simulation apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4177579">US4177579</a></td><td class="patent-data-table-td patent-date-value">Mar 24, 1978</td><td class="patent-data-table-td patent-date-value">Dec 11, 1979</td><td class="patent-data-table-td ">The Singer Company</td><td class="patent-data-table-td ">Simulation technique for generating a visual representation of an illuminated area</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4205341">US4205341</a></td><td class="patent-data-table-td patent-date-value">Nov 14, 1978</td><td class="patent-data-table-td patent-date-value">May 27, 1980</td><td class="patent-data-table-td ">Nippon Telegraph And Telephone Public Corporation</td><td class="patent-data-table-td ">Picture signal coding apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4213252">US4213252</a></td><td class="patent-data-table-td patent-date-value">May 8, 1978</td><td class="patent-data-table-td patent-date-value">Jul 22, 1980</td><td class="patent-data-table-td ">The Singer Company</td><td class="patent-data-table-td ">Repeating pattern simulation of a polygon face object system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4225850">US4225850</a></td><td class="patent-data-table-td patent-date-value">Nov 15, 1978</td><td class="patent-data-table-td patent-date-value">Sep 30, 1980</td><td class="patent-data-table-td ">Rockwell International Corporation</td><td class="patent-data-table-td ">Non-fingerprint region indicator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4240108">US4240108</a></td><td class="patent-data-table-td patent-date-value">Oct 3, 1977</td><td class="patent-data-table-td patent-date-value">Dec 16, 1980</td><td class="patent-data-table-td ">Grumman Aerospace Corporation</td><td class="patent-data-table-td ">Vehicle controlled raster display system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4281344">US4281344</a></td><td class="patent-data-table-td patent-date-value">May 2, 1980</td><td class="patent-data-table-td patent-date-value">Jul 28, 1981</td><td class="patent-data-table-td ">Bell Telephone Laboratories, Incorporated</td><td class="patent-data-table-td ">Video interframe transform coding technique</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4319267">US4319267</a></td><td class="patent-data-table-td patent-date-value">Jan 30, 1980</td><td class="patent-data-table-td patent-date-value">Mar 9, 1982</td><td class="patent-data-table-td ">Nippon Telegraph And Telephone Public Corporation</td><td class="patent-data-table-td ">Picture coding and/or decoding equipment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4343037">US4343037</a></td><td class="patent-data-table-td patent-date-value">Jun 13, 1980</td><td class="patent-data-table-td patent-date-value">Aug 3, 1982</td><td class="patent-data-table-td ">Redifon Simulation Limited</td><td class="patent-data-table-td ">Visual display systems of the computer generated image type</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4359733">US4359733</a></td><td class="patent-data-table-td patent-date-value">Sep 23, 1980</td><td class="patent-data-table-td patent-date-value">Nov 16, 1982</td><td class="patent-data-table-td ">Neill Gerard K O</td><td class="patent-data-table-td ">Satellite-based vehicle position determining system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4360876">US4360876</a></td><td class="patent-data-table-td patent-date-value">Jul 2, 1980</td><td class="patent-data-table-td patent-date-value">Nov 23, 1982</td><td class="patent-data-table-td ">Thomson-Csf</td><td class="patent-data-table-td ">Cartographic indicator system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4366475">US4366475</a></td><td class="patent-data-table-td patent-date-value">Feb 20, 1981</td><td class="patent-data-table-td patent-date-value">Dec 28, 1982</td><td class="patent-data-table-td ">Fujitsu Fanuc Limited</td><td class="patent-data-table-td ">Image display system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4384338">US4384338</a></td><td class="patent-data-table-td patent-date-value">Dec 24, 1980</td><td class="patent-data-table-td patent-date-value">May 17, 1983</td><td class="patent-data-table-td ">The Singer Company</td><td class="patent-data-table-td ">Methods and apparatus for blending computer image generated features</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4398171">US4398171</a></td><td class="patent-data-table-td patent-date-value">Feb 23, 1981</td><td class="patent-data-table-td patent-date-value">Aug 9, 1983</td><td class="patent-data-table-td ">Dahan Pierre Louis</td><td class="patent-data-table-td ">Video system for plotting and transmitting video traffic information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4414628">US4414628</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 1981</td><td class="patent-data-table-td patent-date-value">Nov 8, 1983</td><td class="patent-data-table-td ">Bell Telephone Laboratories, Incorporated</td><td class="patent-data-table-td ">System for displaying overlapping pages of information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4481584">US4481584</a></td><td class="patent-data-table-td patent-date-value">Jul 30, 1981</td><td class="patent-data-table-td patent-date-value">Nov 6, 1984</td><td class="patent-data-table-td ">Holland Bobby H</td><td class="patent-data-table-td ">Highway information system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4484192">US4484192</a></td><td class="patent-data-table-td patent-date-value">Dec 17, 1981</td><td class="patent-data-table-td patent-date-value">Nov 20, 1984</td><td class="patent-data-table-td ">The Bendix Corporation</td><td class="patent-data-table-td ">Moving map display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4489389">US4489389</a></td><td class="patent-data-table-td patent-date-value">Oct 2, 1981</td><td class="patent-data-table-td patent-date-value">Dec 18, 1984</td><td class="patent-data-table-td ">Harris Corporation</td><td class="patent-data-table-td ">Real time video perspective digital map display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4504913">US4504913</a></td><td class="patent-data-table-td patent-date-value">Jun 7, 1982</td><td class="patent-data-table-td patent-date-value">Mar 12, 1985</td><td class="patent-data-table-td ">Nippondenso Co., Ltd.</td><td class="patent-data-table-td ">Electronic navigator for automotive vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4513377">US4513377</a></td><td class="patent-data-table-td patent-date-value">Jun 8, 1982</td><td class="patent-data-table-td patent-date-value">Apr 23, 1985</td><td class="patent-data-table-td ">Nippondenso Co., Ltd.</td><td class="patent-data-table-td ">Vehicle-mounted navigator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4514810">US4514810</a></td><td class="patent-data-table-td patent-date-value">Sep 15, 1982</td><td class="patent-data-table-td patent-date-value">Apr 30, 1985</td><td class="patent-data-table-td ">Nippondenso Co., Ltd.</td><td class="patent-data-table-td ">Navigator for vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4520506">US4520506</a></td><td class="patent-data-table-td patent-date-value">Oct 20, 1981</td><td class="patent-data-table-td patent-date-value">May 28, 1985</td><td class="patent-data-table-td ">Harris Corporation</td><td class="patent-data-table-td ">Method and system for compression and reconstruction of cultural data for use in a digital moving map display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4527155">US4527155</a></td><td class="patent-data-table-td patent-date-value">Mar 2, 1982</td><td class="patent-data-table-td patent-date-value">Jul 2, 1985</td><td class="patent-data-table-td ">Nissan Motor Company, Limited</td><td class="patent-data-table-td ">System for maintaining an orientation of characters displayed with a rotatable image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4532514">US4532514</a></td><td class="patent-data-table-td patent-date-value">Aug 13, 1982</td><td class="patent-data-table-td patent-date-value">Jul 30, 1985</td><td class="patent-data-table-td ">Alps Electric Co., Ltd.</td><td class="patent-data-table-td ">Course guidance system with speeded-up display function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4543572">US4543572</a></td><td class="patent-data-table-td patent-date-value">Apr 29, 1982</td><td class="patent-data-table-td patent-date-value">Sep 24, 1985</td><td class="patent-data-table-td ">Nissan Motor Company, Limited</td><td class="patent-data-table-td ">Road map display system with indications of a vehicle position and destination</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4550317">US4550317</a></td><td class="patent-data-table-td patent-date-value">Sep 29, 1982</td><td class="patent-data-table-td patent-date-value">Oct 29, 1985</td><td class="patent-data-table-td ">Toyota Jidosha Kabushiki Kaisha</td><td class="patent-data-table-td ">Drive guide display system for motor vehicle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4615013">US4615013</a></td><td class="patent-data-table-td patent-date-value">Aug 2, 1983</td><td class="patent-data-table-td patent-date-value">Sep 30, 1986</td><td class="patent-data-table-td ">The Singer Company</td><td class="patent-data-table-td ">Method and apparatus for texture generation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4766556">US4766556</a></td><td class="patent-data-table-td patent-date-value">Nov 19, 1985</td><td class="patent-data-table-td patent-date-value">Aug 23, 1988</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Three-dimensional solid object manipulating apparatus and method therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4821212">US4821212</a></td><td class="patent-data-table-td patent-date-value">Aug 8, 1984</td><td class="patent-data-table-td patent-date-value">Apr 11, 1989</td><td class="patent-data-table-td ">General Electric Company</td><td class="patent-data-table-td ">Three dimensional texture generator for computed terrain images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4855934">US4855934</a></td><td class="patent-data-table-td patent-date-value">Oct 3, 1986</td><td class="patent-data-table-td patent-date-value">Aug 8, 1989</td><td class="patent-data-table-td ">Evans &amp; Sutherland Computer Corporation</td><td class="patent-data-table-td ">System for texturing computer graphics images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4888713">US4888713</a></td><td class="patent-data-table-td patent-date-value">Sep 5, 1986</td><td class="patent-data-table-td patent-date-value">Dec 19, 1989</td><td class="patent-data-table-td ">Cdi Technologies, Inc.</td><td class="patent-data-table-td ">Fishing lure apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4931954">US4931954</a></td><td class="patent-data-table-td patent-date-value">Jun 29, 1987</td><td class="patent-data-table-td patent-date-value">Jun 5, 1990</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Image storage system and method of storing images such that they are displayed with gradually increasing resolution</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4935879">US4935879</a></td><td class="patent-data-table-td patent-date-value">Aug 5, 1988</td><td class="patent-data-table-td patent-date-value">Jun 19, 1990</td><td class="patent-data-table-td ">Daikin Industries, Ltd.</td><td class="patent-data-table-td ">Texture mapping apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4974176">US4974176</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 1987</td><td class="patent-data-table-td patent-date-value">Nov 27, 1990</td><td class="patent-data-table-td ">General Electric Company</td><td class="patent-data-table-td ">Computer image generation system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4994989">US4994989</a></td><td class="patent-data-table-td patent-date-value">Oct 7, 1988</td><td class="patent-data-table-td patent-date-value">Feb 19, 1991</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Displaying method and apparatus for three-dimensional computer graphics</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5051929">US5051929</a></td><td class="patent-data-table-td patent-date-value">Oct 19, 1987</td><td class="patent-data-table-td patent-date-value">Sep 24, 1991</td><td class="patent-data-table-td ">Interand Corporation</td><td class="patent-data-table-td ">Electronic memory state reallocation system for improving the resolution of color coding video systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5128870">US5128870</a></td><td class="patent-data-table-td patent-date-value">Jun 9, 1989</td><td class="patent-data-table-td patent-date-value">Jul 7, 1992</td><td class="patent-data-table-td ">Regents Of The University Of Minnesota</td><td class="patent-data-table-td ">Automated high-precision fabrication of objects of complex and unique geometry</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5153936">US5153936</a></td><td class="patent-data-table-td patent-date-value">Jul 19, 1990</td><td class="patent-data-table-td patent-date-value">Oct 6, 1992</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Dual density digital image system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5261041">US5261041</a></td><td class="patent-data-table-td patent-date-value">Dec 28, 1990</td><td class="patent-data-table-td patent-date-value">Nov 9, 1993</td><td class="patent-data-table-td ">Apple Computer, Inc.</td><td class="patent-data-table-td ">Computer controlled animation system based on definitional animated objects and methods of manipulating same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5265176">US5265176</a></td><td class="patent-data-table-td patent-date-value">Apr 17, 1991</td><td class="patent-data-table-td patent-date-value">Nov 23, 1993</td><td class="patent-data-table-td ">Hewlett-Packard Company</td><td class="patent-data-table-td ">Method and apparatus for mapping printer resolution using lock-up-tables</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5299300">US5299300</a></td><td class="patent-data-table-td patent-date-value">Jun 8, 1993</td><td class="patent-data-table-td patent-date-value">Mar 29, 1994</td><td class="patent-data-table-td ">Harris Corporation</td><td class="patent-data-table-td ">Interpolation processing of digital map imagery data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5325472">US5325472</a></td><td class="patent-data-table-td patent-date-value">Apr 12, 1991</td><td class="patent-data-table-td patent-date-value">Jun 28, 1994</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Image displaying system for interactively changing the positions of a view vector and a viewpoint in a 3-dimensional space</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5327509">US5327509</a></td><td class="patent-data-table-td patent-date-value">Apr 27, 1992</td><td class="patent-data-table-td patent-date-value">Jul 5, 1994</td><td class="patent-data-table-td ">Star Technologies, Inc.</td><td class="patent-data-table-td ">Compressed image system for texture patterns</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5394516">US5394516</a></td><td class="patent-data-table-td patent-date-value">Jun 28, 1991</td><td class="patent-data-table-td patent-date-value">Feb 28, 1995</td><td class="patent-data-table-td ">U.S. Philips Corporation</td><td class="patent-data-table-td ">Generating an image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5420969">US5420969</a></td><td class="patent-data-table-td patent-date-value">Oct 14, 1993</td><td class="patent-data-table-td patent-date-value">May 30, 1995</td><td class="patent-data-table-td ">Winbond Electronic Corp.</td><td class="patent-data-table-td ">Apparatus using mean value image smoothing for a two-dimensional image signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5428715">US5428715</a></td><td class="patent-data-table-td patent-date-value">Mar 13, 1992</td><td class="patent-data-table-td patent-date-value">Jun 27, 1995</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Three-dimensional figure data generator device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5434966">US5434966</a></td><td class="patent-data-table-td patent-date-value">Jun 1, 1992</td><td class="patent-data-table-td patent-date-value">Jul 18, 1995</td><td class="patent-data-table-td ">Kao Corporation</td><td class="patent-data-table-td ">System and method for storing and retrieving three dimensional shapes using two dimensional contrast images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5467444">US5467444</a></td><td class="patent-data-table-td patent-date-value">Nov 7, 1991</td><td class="patent-data-table-td patent-date-value">Nov 14, 1995</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Method of three-dimensional display of object-oriented figure information and system thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5471563">US5471563</a></td><td class="patent-data-table-td patent-date-value">Nov 16, 1992</td><td class="patent-data-table-td patent-date-value">Nov 28, 1995</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">System and method for automatic resolution reduction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5499194">US5499194</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 1994</td><td class="patent-data-table-td patent-date-value">Mar 12, 1996</td><td class="patent-data-table-td ">Renishaw Plc</td><td class="patent-data-table-td ">Method for scanning the surface of an object</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5502798">US5502798</a></td><td class="patent-data-table-td patent-date-value">Sep 26, 1994</td><td class="patent-data-table-td patent-date-value">Mar 26, 1996</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image processing apparatus for synthesizing Z-axis coordinate data using X- and Y-direction increments</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5515482">US5515482</a></td><td class="patent-data-table-td patent-date-value">May 6, 1992</td><td class="patent-data-table-td patent-date-value">May 7, 1996</td><td class="patent-data-table-td ">Ricoh Co., Ltd.</td><td class="patent-data-table-td ">Sorting apparatus and method for sorting data in sequence of reference levels indicated by the data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5550960">US5550960</a></td><td class="patent-data-table-td patent-date-value">Aug 2, 1993</td><td class="patent-data-table-td patent-date-value">Aug 27, 1996</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">In a computer system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5555354">US5555354</a></td><td class="patent-data-table-td patent-date-value">Mar 23, 1993</td><td class="patent-data-table-td patent-date-value">Sep 10, 1996</td><td class="patent-data-table-td ">Silicon Graphics Inc.</td><td class="patent-data-table-td ">Method and apparatus for navigation within three-dimensional information landscape</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5559860">US5559860</a></td><td class="patent-data-table-td patent-date-value">Jun 11, 1992</td><td class="patent-data-table-td patent-date-value">Sep 24, 1996</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">User selectable response to an incoming call at a mobile station</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5561746">US5561746</a></td><td class="patent-data-table-td patent-date-value">Aug 26, 1993</td><td class="patent-data-table-td patent-date-value">Oct 1, 1996</td><td class="patent-data-table-td ">Namco Ltd.</td><td class="patent-data-table-td ">Image synthesizing system with surface data perspective transformation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5577174">US5577174</a></td><td class="patent-data-table-td patent-date-value">Mar 19, 1992</td><td class="patent-data-table-td patent-date-value">Nov 19, 1996</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Video data processing apparatus and method for smoothly intersecting images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5579456">US5579456</a></td><td class="patent-data-table-td patent-date-value">Nov 29, 1995</td><td class="patent-data-table-td patent-date-value">Nov 26, 1996</td><td class="patent-data-table-td ">Evans &amp; Sutherland Computer Corp.</td><td class="patent-data-table-td ">Direct rendering of textured height fields</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5586233">US5586233</a></td><td class="patent-data-table-td patent-date-value">Apr 17, 1996</td><td class="patent-data-table-td patent-date-value">Dec 17, 1996</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Method and apparatus for creating multi-gradation data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5586246">US5586246</a></td><td class="patent-data-table-td patent-date-value">Dec 23, 1994</td><td class="patent-data-table-td patent-date-value">Dec 17, 1996</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Image synthesis apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5594846">US5594846</a></td><td class="patent-data-table-td patent-date-value">Dec 19, 1994</td><td class="patent-data-table-td patent-date-value">Jan 14, 1997</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">In a computer graphics system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5608410">US5608410</a></td><td class="patent-data-table-td patent-date-value">Mar 11, 1994</td><td class="patent-data-table-td patent-date-value">Mar 4, 1997</td><td class="patent-data-table-td ">Associated Rt, Inc.</td><td class="patent-data-table-td ">System for locating a source of bursty transmissions cross reference to related applications</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5636334">US5636334</a></td><td class="patent-data-table-td patent-date-value">Jan 23, 1995</td><td class="patent-data-table-td patent-date-value">Jun 3, 1997</td><td class="patent-data-table-td ">Casio Computer Co., Ltd.</td><td class="patent-data-table-td ">Three-dimensional image creation devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5657432">US5657432</a></td><td class="patent-data-table-td patent-date-value">Sep 14, 1994</td><td class="patent-data-table-td patent-date-value">Aug 12, 1997</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Texture mapping method for placing texture pieces successively on object</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5675720">US5675720</a></td><td class="patent-data-table-td patent-date-value">Sep 19, 1996</td><td class="patent-data-table-td patent-date-value">Oct 7, 1997</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Method of searching for points of closest approach, and preprocessing method therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5680474">US5680474</a></td><td class="patent-data-table-td patent-date-value">Oct 26, 1993</td><td class="patent-data-table-td patent-date-value">Oct 21, 1997</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Corresponding point extraction method for a plurality of images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5687307">US5687307</a></td><td class="patent-data-table-td patent-date-value">Sep 16, 1994</td><td class="patent-data-table-td patent-date-value">Nov 11, 1997</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5694530">US5694530</a></td><td class="patent-data-table-td patent-date-value">Jan 18, 1995</td><td class="patent-data-table-td patent-date-value">Dec 2, 1997</td><td class="patent-data-table-td ">Hitachi Medical Corporation</td><td class="patent-data-table-td ">Method of constructing three-dimensional image according to central projection method and apparatus for same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5701403">US5701403</a></td><td class="patent-data-table-td patent-date-value">May 23, 1995</td><td class="patent-data-table-td patent-date-value">Dec 23, 1997</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Cad system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5726689">US5726689</a></td><td class="patent-data-table-td patent-date-value">Jul 11, 1995</td><td class="patent-data-table-td patent-date-value">Mar 10, 1998</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Mapping apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5745665">US5745665</a></td><td class="patent-data-table-td patent-date-value">Sep 25, 1996</td><td class="patent-data-table-td patent-date-value">Apr 28, 1998</td><td class="patent-data-table-td ">Douglas F. Winnek</td><td class="patent-data-table-td ">Method for processing a three-dimensional data set into a composite two-dimensional image viewable as a three-dimensional image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5764233">US5764233</a></td><td class="patent-data-table-td patent-date-value">Jan 2, 1996</td><td class="patent-data-table-td patent-date-value">Jun 9, 1998</td><td class="patent-data-table-td ">Silicon Graphics, Inc.</td><td class="patent-data-table-td ">Method for generating hair using textured fuzzy segments in a computer graphics system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5774132">US5774132</a></td><td class="patent-data-table-td patent-date-value">Oct 26, 1995</td><td class="patent-data-table-td patent-date-value">Jun 30, 1998</td><td class="patent-data-table-td ">Yamaha Corporation</td><td class="patent-data-table-td ">Video capture computer system using local memory for texture mapping</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5782762">US5782762</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 1994</td><td class="patent-data-table-td patent-date-value">Jul 21, 1998</td><td class="patent-data-table-td ">Wake Forest University</td><td class="patent-data-table-td ">Method and system for producing interactive, three-dimensional renderings of selected body organs having hollow lumens to enable simulated movement through the lumen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5784301">US5784301</a></td><td class="patent-data-table-td patent-date-value">Jan 26, 1996</td><td class="patent-data-table-td patent-date-value">Jul 21, 1998</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Method and apparatus for producing paper fiber structure data, and method and apparatus for drawing bled figure</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5828382">US5828382</a></td><td class="patent-data-table-td patent-date-value">Aug 2, 1996</td><td class="patent-data-table-td patent-date-value">Oct 27, 1998</td><td class="patent-data-table-td ">Cirrus Logic, Inc.</td><td class="patent-data-table-td ">Apparatus for dynamic XY tiled texture caching</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5831875">US5831875</a></td><td class="patent-data-table-td patent-date-value">Jun 3, 1996</td><td class="patent-data-table-td patent-date-value">Nov 3, 1998</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Link mechanism analyzer and link mechanism joint data arithmetic apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5847712">US5847712</a></td><td class="patent-data-table-td patent-date-value">Jan 3, 1995</td><td class="patent-data-table-td patent-date-value">Dec 8, 1998</td><td class="patent-data-table-td ">University Of Washington</td><td class="patent-data-table-td ">Method and system for generating graphic illustrations according to a stroke texture and a tone</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5847717">US5847717</a></td><td class="patent-data-table-td patent-date-value">Aug 28, 1997</td><td class="patent-data-table-td patent-date-value">Dec 8, 1998</td><td class="patent-data-table-td ">Hewlett Packard Company</td><td class="patent-data-table-td ">Data synchronization between a plurality of asynchronous data renderers</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5850226">US5850226</a></td><td class="patent-data-table-td patent-date-value">Sep 9, 1996</td><td class="patent-data-table-td patent-date-value">Dec 15, 1998</td><td class="patent-data-table-td ">Ultra-High Speed Network And Computer Technology Laboratories</td><td class="patent-data-table-td ">Method of transferring and displaying 3-D shape data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5856829">US5856829</a></td><td class="patent-data-table-td patent-date-value">May 10, 1996</td><td class="patent-data-table-td patent-date-value">Jan 5, 1999</td><td class="patent-data-table-td ">Cagent Technologies, Inc.</td><td class="patent-data-table-td ">Inverse Z-buffer and video display system having list-based control mechanism for time-deferred instructing of 3D rendering engine that also responds to supervisory immediate commands</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5860077">US5860077</a></td><td class="patent-data-table-td patent-date-value">Dec 10, 1996</td><td class="patent-data-table-td patent-date-value">Jan 12, 1999</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Three-dimensional data storing method for parallel access of vertex data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5864640">US5864640</a></td><td class="patent-data-table-td patent-date-value">Oct 25, 1996</td><td class="patent-data-table-td patent-date-value">Jan 26, 1999</td><td class="patent-data-table-td ">Wavework, Inc.</td><td class="patent-data-table-td ">Method and apparatus for optically scanning three dimensional objects using color information in trackable patches</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5867166">US5867166</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 1996</td><td class="patent-data-table-td patent-date-value">Feb 2, 1999</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method and system for generating images using Gsprites</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5870105">US5870105</a></td><td class="patent-data-table-td patent-date-value">May 31, 1996</td><td class="patent-data-table-td patent-date-value">Feb 9, 1999</td><td class="patent-data-table-td ">Hewlett-Packard Company</td><td class="patent-data-table-td ">System and method for local storage of image data during object to image mapping</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5870307">US5870307</a></td><td class="patent-data-table-td patent-date-value">Jun 7, 1995</td><td class="patent-data-table-td patent-date-value">Feb 9, 1999</td><td class="patent-data-table-td ">3D Systems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for production of high resolution three-dimensional objects by stereolithography</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6058397">US6058397</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 8, 1997</td><td class="patent-data-table-td patent-date-value">May 2, 2000</td><td class="patent-data-table-td ">Mitsubishi Electric Information Technology Center America, Inc.</td><td class="patent-data-table-td ">3D virtual environment creation management and delivery system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6321158">US6321158</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 31, 1998</td><td class="patent-data-table-td patent-date-value">Nov 20, 2001</td><td class="patent-data-table-td ">Delorme Publishing Company</td><td class="patent-data-table-td ">Integrated routing/mapping information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/DE19549306A1?cl=en">DE19549306A1</a></td><td class="patent-data-table-td patent-date-value">Dec 22, 1995</td><td class="patent-data-table-td patent-date-value">Jul 3, 1997</td><td class="patent-data-table-td ">Art &amp; Com Medientechnologie Un</td><td class="patent-data-table-td ">Verfahren und Vorrichtung zur bildlichen Darstellung raumbezogener Daten</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Andrews, Matthews, et al., Improved Methods for Hiding Latency in High Bandwidth Networks (Extended Abstract), ACM Press, Jun. 1996, p. 53-61.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Astheimer, Peter, et al., "<a href='http://scholar.google.com/scholar?q="Level-of-Detail+Generation+and+Its+Application+in+Virtual+Reality%2C"'>Level-of-Detail Generation and Its Application in Virtual Reality,</a>" Virtual Reality Software &amp; Technology, Aug. 1994, p. 299-309.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">B. Watson et al, "<a href='http://scholar.google.com/scholar?q="Effects+of+Variation+in+System+Responsiveness+on+User+Performance+in+Virtual+Environments%2C"'>Effects of Variation in System Responsiveness on User Performance in Virtual Environments,</a>" The Journal of the Human Factors &amp; Ergonomics Society, p. 405-413.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">B. Watson, et al., "<a href='http://scholar.google.com/scholar?q="Evaluation+of+the+Effects+of+Frame+Time+Variation+on+VR+Task+Performance%2C"'>Evaluation of the Effects of Frame Time Variation on VR Task Performance,</a>" IEEE 1997 Virtual Reality Annual International Symposium, Mar. 1-May 1997, p. 38-44.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">B. Watson, et al., "<a href='http://scholar.google.com/scholar?q="Managing+Level+of+Detail+Through+Head-Tracked+Peripheral+Degradation%3A+A+Model+and+Resulting+Design+Principles%2C"'>Managing Level of Detail Through Head-Tracked Peripheral Degradation: A Model and Resulting Design Principles,</a>" ACM VRST '97, 1997, p. 59-63.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">B.L. Tierney, et al., "<a href='http://scholar.google.com/scholar?q="Using+High+Speed+Networks+to+Enable+Distributed+parallel+Image+server+Systems%2C"'>Using High Speed Networks to Enable Distributed parallel Image server Systems,</a>" IEEE, 1994, p. 610-619.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Bajaj, C. L., et al., "<a href='http://scholar.google.com/scholar?q="Reconstructing+Surfaces+and+Functions+on+Surfaces+from+Unoriganized+Three-Dimensional+Data%2C"'>Reconstructing Surfaces and Functions on Surfaces from Unoriganized Three-Dimensional Data,</a>" Algorithmica, Sep./Oct. 1997, vol. 19, No. 1/2, p. 243-261.</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Beasley, Graham, "<a href='http://scholar.google.com/scholar?q="Mission+Rehearsal+Meets+Distributed+Interactive+Simulation+%28DIS%29%2C"'>Mission Rehearsal Meets Distributed Interactive Simulation (DIS),</a>" p. 1-7.</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Bernard Chazaelle, "<a href='http://scholar.google.com/scholar?q="An+Optimal+Algorithm+for+Intersecting+Three-Dimensional+Convex+Polyhedra%2C"'>An Optimal Algorithm for Intersecting Three-Dimensional Convex Polyhedra,</a>" Siam Journal on Computing, Aug. 1992, p. 671-696, vol. 21, No. 4.</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Birkel, Paul A.(Dr.), "<a href='http://scholar.google.com/scholar?q="SECRIS+Geospatial+Reference+Model%2C"'>SECRIS Geospatial Reference Model,</a>" The MITRE Corporation.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Bolin, Mark R. and Meyer, Gary W., "<a href='http://scholar.google.com/scholar?q="A+Frequency+Based+Ray+Tracer%2C"'>A Frequency Based Ray Tracer,</a>" ACM Press-Computer Graphics, Aug. 6-11, 1995, p. 409-418.</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Bolin, Mark R. and Meyer, Gary W., "<a href='http://scholar.google.com/scholar?q="A+Perceptually+Based+Adaptive+Sampling+Algorithms%2C"'>A Perceptually Based Adaptive Sampling Algorithms,</a>" ACM Press-Computer Graphics, Jul. 1998, p. 299-309.</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Bricken, William and Coco, Geoffrey, "<a href='http://scholar.google.com/scholar?q="The+VEOS+Project%2C"'>The VEOS Project,</a>" Presence, 1994, vol. 3, No. 2., p. 111-129.</td></tr><tr><td class="patent-data-table-td ">14</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Burdea, Grigore, "<a href='http://scholar.google.com/scholar?q="Effect+of+Frame+Rate+and+Force+Feedback+on+Virtual+Object+Manipulation%2C"'>Effect of Frame Rate and Force Feedback on Virtual Object Manipulation,</a>" Presence, 1996, vol. 5, No. 1, p. 95-108, MIT Press.</td></tr><tr><td class="patent-data-table-td ">15</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">C.L. Bajaj, V. Pascucci, "<a href='http://scholar.google.com/scholar?q="Visualization+of+Scalar+Topology+for+Structural+Enhancement%2C"'>Visualization of Scalar Topology for Structural Enhancement,</a>" IEEE, Oct. 1998, p. 51-58.</td></tr><tr><td class="patent-data-table-td ">16</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Carlson, Deborah A., et al., "<a href='http://scholar.google.com/scholar?q="Simulation+Levels+of+Detail+for+Real-time+Animation%2C"'>Simulation Levels of Detail for Real-time Animation,</a>" Graphics Interface, 1997, p. 1-8.</td></tr><tr><td class="patent-data-table-td ">17</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Chandrajit L. Bajaj and Daniel R. Schikore, "<a href='http://scholar.google.com/scholar?q="Error-bounded+Reduction+of+Triangle+Meshes+with+Multivariate+Data%2C"'>Error-bounded Reduction of Triangle Meshes with Multivariate Data,</a>" SPIE, 1996, vol. 2656, p. 34-45.</td></tr><tr><td class="patent-data-table-td ">18</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Chen, M., Townsend, P. and Vince, J.A., "<a href='http://scholar.google.com/scholar?q="High+Performance+Computing+for+Computer+Graphics+and+Visualization%2C"'>High Performance Computing for Computer Graphics and Visualization,</a>" Swansea, Jul. 3-4, 1995, pp. 216-237.</td></tr><tr><td class="patent-data-table-td ">19</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Christopher Allen Chrislip and James Frederick Ehlert, Jr., "<a href='http://scholar.google.com/scholar?q="Level+of+Detail+Models+For+Dismounted+Infantry+in+NPSNET-IV.8.1%2C"'>Level of Detail Models For Dismounted Infantry in NPSNET-IV.8.1,</a>" Sep. 1995, p. i-xii and p. 1-85.</td></tr><tr><td class="patent-data-table-td ">20</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Cohen, Jonathan, "<a href='http://scholar.google.com/scholar?q="Simplification+Envelopes%2C"'>Simplification Envelopes,</a>" Computer Graphics, 1996, p. 119-128.</td></tr><tr><td class="patent-data-table-td ">21</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Cohen, Jonathan, et al., "<a href='http://scholar.google.com/scholar?q="Appearance-Preserving+Simplification%2C"'>Appearance-Preserving Simplification,</a>" ACM Press-Computer Graphics, Jul. 19-24, 1998, p. 115-122.</td></tr><tr><td class="patent-data-table-td ">22</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Cohen-Or, Daniel, et al., "<a href='http://scholar.google.com/scholar?q="Conservative+Visibility+and+Strong+Occlusion+for+Viewspace+Partitioning+of+Densely+Occluded+Scenes%2C"'>Conservative Visibility and Strong Occlusion for Viewspace Partitioning of Densely Occluded Scenes,</a>" Computer Graphics Forum, 1998, V.17, No. 3.</td></tr><tr><td class="patent-data-table-td ">23</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Cohen-Or, David and Levanoni, Yishay, "<a href='http://scholar.google.com/scholar?q="Temporal+Continuity+of+Levels+of+Detail+in+Delaunay+Triangulated+Terrain%2C"'>Temporal Continuity of Levels of Detail in Delaunay Triangulated Terrain,</a>" IEEE, Oct. 27-Nov. 1996.</td></tr><tr><td class="patent-data-table-td ">24</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Coorg, Satya and Teller, Seth, "<a href='http://scholar.google.com/scholar?q="Real-Time+Occlusion+Culling+for+Models+with+Large+Occluders%2C"'>Real-Time Occlusion Culling for Models with Large Occluders,</a>" 1997 Symposium on Interactive 3D Graphics, Apr. 27-30, 1997, p. 83-90 and 189.</td></tr><tr><td class="patent-data-table-td ">25</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Coorg, Satya and Teller, Seth, "<a href='http://scholar.google.com/scholar?q="Temporally+Coherent+Conservative+Visibility+%28Extended+Abstract%29%2C"'>Temporally Coherent Conservative Visibility (Extended Abstract),</a>" ACM Press, May 24-26, 1996.</td></tr><tr><td class="patent-data-table-td ">26</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Cosman, Michael A., "<a href='http://scholar.google.com/scholar?q="A+New+Visual+System+to+Support+Advanced+Requirement+Requirements%2C"'>A New Visual System to Support Advanced Requirement Requirements,</a>" Evans &amp; Sutherland, p. 371-380.</td></tr><tr><td class="patent-data-table-td ">27</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Cosman, Michael A., "<a href='http://scholar.google.com/scholar?q="Mission+Rehearsal+Modeling%2C"'>Mission Rehearsal Modeling,</a>" Image VI Conference, 1992, p. 413-425.</td></tr><tr><td class="patent-data-table-td ">28</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Cosman, Michael, et al., "<a href='http://scholar.google.com/scholar?q="Global+Terrain+Texture%3A+Lowering+the+Cost%2C"'>Global Terrain Texture: Lowering the Cost,</a>".</td></tr><tr><td class="patent-data-table-td ">29</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Cruz-Neira, Carolina, et al., "<a href='http://scholar.google.com/scholar?q="Surround-Screen+Projection-based+Virtual+reality%3A+The+Design+and+Implementation+of+the+CAVE%2C"'>Surround-Screen Projection-based Virtual reality: The Design and Implementation of the CAVE,</a>" Computer Graphics, Aug. 1993, p. 135-143.</td></tr><tr><td class="patent-data-table-td ">30</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">David R. Cheriton, et al., "<a href='http://scholar.google.com/scholar?q="Effective+Remote+Modeling+in+Large-Scale+Distributed+Simulation+and+Visualization+Environments%2C"'>Effective Remote Modeling in Large-Scale Distributed Simulation and Visualization Environments,</a>" Sandeep Kishan Singhal, Aug. 1996, p. ix-156.</td></tr><tr><td class="patent-data-table-td ">31</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">De Floriani, et al., "<a href='http://scholar.google.com/scholar?q="Multiresolution+Models+for+Topographic+Surface+Description%2C"'>Multiresolution Models for Topographic Surface Description,</a>" The Visual Computer, 1996, vol. 12, p. 317-345.</td></tr><tr><td class="patent-data-table-td ">32</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">De Floriani, L, et al., "<a href='http://scholar.google.com/scholar?q="A+Delaunay-Based+Method+for+Surface+Approximation%2C"'>A Delaunay-Based Method for Surface Approximation,</a>" Eurographics '83, Aug. 31-Sep. 2, 1983, pp. 333-350.</td></tr><tr><td class="patent-data-table-td ">33</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">De Floriani, Leila, "<a href='http://scholar.google.com/scholar?q="A+Pyramidal+Data+Structure+for+Triangle-Based+Surface+Description%2C"'>A Pyramidal Data Structure for Triangle-Based Surface Description,</a>" IEEE Computer Graphics and Applications, Mar. 1989, V. 9, No. 2, p. 67-88.</td></tr><tr><td class="patent-data-table-td ">34</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">De Floriani, Leila, et al., "<a href='http://scholar.google.com/scholar?q="Hierarchical+Triangulation+for+Multiresolution+Surface+Description%2C"'>Hierarchical Triangulation for Multiresolution Surface Description,</a>" ACM Transactions on Graphics, p. 363-411.</td></tr><tr><td class="patent-data-table-td ">35</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">DeHaemer, Jr. Michael J. and Zyda, Michael J., "<a href='http://scholar.google.com/scholar?q="Simplification+of+Objects+Rendered+by+Polygonal+Approximations%2C"'>Simplification of Objects Rendered by Polygonal Approximations,</a>" 1991, vol. 15, No. 2, p. 175-184.</td></tr><tr><td class="patent-data-table-td ">36</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Deussen, Oliver, et al., "<a href='http://scholar.google.com/scholar?q="Realistic+Modeling+and+Rendering+of+Plant+Ecosystems%2C%2C"'>Realistic Modeling and Rendering of Plant Ecosystems,,</a>" ACM Press-Computer Graphics, Jul. 1998, p. 275-286.</td></tr><tr><td class="patent-data-table-td ">37</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Dirk Bartz, Michael Meibner, Tobias Huttner, "<a href='http://scholar.google.com/scholar?q="Extending+Graphics+Hardware+for+Occlusion+Queries+in+OpenGL%2C"'>Extending Graphics Hardware for Occlusion Queries in OpenGL,</a>" Computer Graphics Lab, University of Tubingen.</td></tr><tr><td class="patent-data-table-td ">38</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Eck, Matthias, et al. "<a href='http://scholar.google.com/scholar?q="Multiresolution+Analysis+of+Arbitrary+Meshes%2C"'>Multiresolution Analysis of Arbitrary Meshes,</a>" Computer Graphics, 1995, p. 173-182.</td></tr><tr><td class="patent-data-table-td ">39</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Edwin Ear Catmull, "<a href='http://scholar.google.com/scholar?q="A+Subdivision+Algorithm+for+Computer+Disply+of+Curved+Surfaces%2C"'>A Subdivision Algorithm for Computer Disply of Curved Surfaces,</a>" Department of Computer Science, University of Utah, Dec. 1974.</td></tr><tr><td class="patent-data-table-td ">40</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">El-Sana, Jihad, et al., "<a href='http://scholar.google.com/scholar?q="Topololgy+Simplification+for+Polygonal+Virtual+Environments%2C"'>Topololgy Simplification for Polygonal Virtual Environments,</a>" IEEE Trans. on Visualization and Computer Graphics, '98, vol. 4, No. 2, p. 133-144.</td></tr><tr><td class="patent-data-table-td ">41</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">F. C. Crow, "<a href='http://scholar.google.com/scholar?q="A+More+Flexible+Image+Generation+Environment%2C"'>A More Flexible Image Generation Environment,</a>" Computer Graphics, siggraph '82 Conference Proceedings, Jul. 1982, vol. 16, No. 3, p. 9-18.</td></tr><tr><td class="patent-data-table-td ">42</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Falby, John, S., et al., "<a href='http://scholar.google.com/scholar?q="NPSNET%3A+Hierarchical+Data+Structures+for+Real-Time+Three-Dimensional+Visual+Simulation%2C"'>NPSNET: Hierarchical Data Structures for Real-Time Three-Dimensional Visual Simulation,</a>" In Computer &amp; Graphics, vol. 1, No. 1, p. 65-69.</td></tr><tr><td class="patent-data-table-td ">43</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Ferguson, R.L., et al., "<a href='http://scholar.google.com/scholar?q="Continuous+Terrain+Level+of+Detail+for+Visual+Simulation%2C"'>Continuous Terrain Level of Detail for Visual Simulation,</a>" p. 145-151.</td></tr><tr><td class="patent-data-table-td ">44</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Ferwerda, James, et al., "<a href='http://scholar.google.com/scholar?q="A+Model+of+Visual+Masking+for+Computer+Graphics%2C"'>A Model of Visual Masking for Computer Graphics,</a>" Computer Graphics Proceedings, 1997, pp. 143-152.</td></tr><tr><td class="patent-data-table-td ">45</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Fowler, Robert J. and Little, James J., "<a href='http://scholar.google.com/scholar?q="Automatice+Extraction+of+Irregular+Network+Digital+Terrain+Models%2C"'>Automatice Extraction of Irregular Network Digital Terrain Models,</a>" Computer Graphics, Aug. 1979, vol. 13, No. 2, p. 198-207.</td></tr><tr><td class="patent-data-table-td ">46</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">G. Wheless, et al., "<a href='http://scholar.google.com/scholar?q="Virtual+Chesapeake+Bay%3A+Interacting+with+a+Coupled+Physical%2FBiological+Model%2C"'>Virtual Chesapeake Bay: Interacting with a Coupled Physical/Biological Model,</a>" IEEE, Jul. 1996, p. 52-57.</td></tr><tr><td class="patent-data-table-td ">47</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Greene, Ned, K, and Miller, Gavin, "<a href='http://scholar.google.com/scholar?q="Hierarchical+Z-Buffer+Visisbility%2C"'>Hierarchical Z-Buffer Visisbility,</a>" Computer Graphics Proceedings, Annual Conference Series, 1993, p. 231-238.</td></tr><tr><td class="patent-data-table-td ">48</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Gueziec, A., Taubin, G., Lazarus, F., and Horn, W., "<a href='http://scholar.google.com/scholar?q="Simplicial+Maps+for+Progressive+Transmission+of+Polygonal+Surfaces%2C"'>Simplicial Maps for Progressive Transmission of Polygonal Surfaces,</a>" ACM Siggraph.</td></tr><tr><td class="patent-data-table-td ">49</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Hamann, Bernd, "<a href='http://scholar.google.com/scholar?q="A+Data+Reduction+Scheme+for+Triangulated+Surfaces%2C"'>A Data Reduction Scheme for Triangulated Surfaces,</a>" Computer Aided Geometric Design, Apr. 1994, vol. 11, No. 2, p. 197-198.</td></tr><tr><td class="patent-data-table-td ">50</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">He, Taosong, Hong, Lichan, Varshney, Amitabh and Wang Sidney W., "<a href='http://scholar.google.com/scholar?q="Controlled+Topology+Simiplification%2C"'>Controlled Topology Simiplification,</a>" IEEE Trans., Jun. 1996, vol. 2, No. 2, p. 171-184.</td></tr><tr><td class="patent-data-table-td ">51</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Holloway, Richard, "<a href='http://scholar.google.com/scholar?q="Viper%3A+A+Quasi-Real-time+Virtual-Environment+Application%2C"'>Viper: A Quasi-Real-time Virtual-Environment Application,</a>"p. 1-10.</td></tr><tr><td class="patent-data-table-td ">52</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Hoppe, H., DeRose, T., Duchamp, T., McDonald, J., Stuetzle, W., "<a href='http://scholar.google.com/scholar?q="Mesh+Optimization%2C"'>Mesh Optimization,</a>" Computer Graphics, 1993, pp. 19-26.</td></tr><tr><td class="patent-data-table-td ">53</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Hoppe, Hugues, "<a href='http://scholar.google.com/scholar?q="Efficient+Implementation+of+Progressive+Meshes%2C"'>Efficient Implementation of Progressive Meshes,</a>" Computer and Graphics, 1998, vol. 22, No. 1, pp. 27-36.</td></tr><tr><td class="patent-data-table-td ">54</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Hoppe, Hugues, "<a href='http://scholar.google.com/scholar?q="Progressive+Meshes%2C"'>Progressive Meshes,</a>" Computer Graphics, Aug. 4-9, 1996, pp. 99-108.</td></tr><tr><td class="patent-data-table-td ">55</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Hoppe, Hugues, "<a href='http://scholar.google.com/scholar?q="Smooth+View-Dependent+Level-of-Detail+Control+and+its+Application+to+Terrain+Rendering%2C"'>Smooth View-Dependent Level-of-Detail Control and its Application to Terrain Rendering,</a>" IEEE, Oct. 18-23, 1998, pp. 35-42 and p. 516.</td></tr><tr><td class="patent-data-table-td ">56</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Hoppe, Hugues, "<a href='http://scholar.google.com/scholar?q="View-Dependent+Refinement+of+Progressive+Meshes%2C"'>View-Dependent Refinement of Progressive Meshes,</a>" Computer Graphics, Aug. 3-8, 1997.</td></tr><tr><td class="patent-data-table-td ">57</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Hubbard, Philip M., "<a href='http://scholar.google.com/scholar?q="Approximately+Polyhedra+with+Spheres+for+Time-Critical+Collision+Detection%2C"'>Approximately Polyhedra with Spheres for Time-Critical Collision Detection,</a>" ACM Transactions on Graphics.</td></tr><tr><td class="patent-data-table-td ">58</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Hugh R. Wilson and James R. Bergen, "<a href='http://scholar.google.com/scholar?q="A+Four+Mechanism+Model+for+Threshold+Spatial+Vision%2C"'>A Four Mechanism Model for Threshold Spatial Vision,</a>" 1979, vol. 19, No. 1, p. 19-31.</td></tr><tr><td class="patent-data-table-td ">59</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">James H. Clark, "<a href='http://scholar.google.com/scholar?q="Hierarchical+Geometric+Models+for+Visible+Surface+Algorithms%2C"'>Hierarchical Geometric Models for Visible Surface Algorithms,</a>" Communication of the ACM, Oct. 1976, vol. 19, No. 10, p. 547-554.</td></tr><tr><td class="patent-data-table-td ">60</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Jarvis, Kevin M., "<a href='http://scholar.google.com/scholar?q="Visual+Performances+Requirement+Below+the+Skyline%2C+A+Cost+Effective+Solution+to+Low+Level+Flight%2C"'>Visual Performances Requirement Below the Skyline, A Cost Effective Solution to Low Level Flight,</a>" p. 231-235.</td></tr><tr><td class="patent-data-table-td ">61</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">John Dill and Nahum Gershon, "<a href='http://scholar.google.com/scholar?q="IEEE+Symposium+on+Information+Visualization%2C"'>IEEE Symposium on Information Visualization,</a>" IEEE Computer Society, Oct. 20-21, 1997, p. 395-402.</td></tr><tr><td class="patent-data-table-td ">62</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Johnson K. Yan, "<a href='http://scholar.google.com/scholar?q="Advances+in+Computer-Generated+Imagery+for+Flight+Simulation%2C"'>Advances in Computer-Generated Imagery for Flight Simulation,</a>" IEEE Computer Graphics and Applications, Aug. 1985, p. 37-51.</td></tr><tr><td class="patent-data-table-td ">63</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Johnston, William, et al., "<a href='http://scholar.google.com/scholar?q="Distributed+Large+Data-Object+Environments%3A+End-to-End+Performance+Analysis+of+High+Speed+Distributed+Storage+System+in+Wide+Area+ATM+Networks%2C"'>Distributed Large Data-Object Environments: End-to-End Performance Analysis of High Speed Distributed Storage System in Wide Area ATM Networks,</a>".</td></tr><tr><td class="patent-data-table-td ">64</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Jonathan Blow, "<a href='http://scholar.google.com/scholar?q="Implementing+a+Texture+Caching+System%2C"'>Implementing a Texture Caching System,</a>" Game Developer, Apr. 1998.</td></tr><tr><td class="patent-data-table-td ">65</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Jonathan David Cohen, "<a href='http://scholar.google.com/scholar?q="Appearance-Preserving+Simplification+of+Polygonal+Models%2C"'>Appearance-Preserving Simplification of Polygonal Models,</a>" Chapel Hill, 1999, p. i-xvii and p. 1-130.</td></tr><tr><td class="patent-data-table-td ">66</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Jose, Cecil, Delfinado, A. and Edelsbrunner, Herbert, "<a href='http://scholar.google.com/scholar?q="An+Incremental+Algorithm+for+Betti+Numbers+of+Simplicial+Complexes+on+the+3-sphere%2C"'>An Incremental Algorithm for Betti Numbers of Simplicial Complexes on the 3-sphere,</a>".</td></tr><tr><td class="patent-data-table-td ">67</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Julie C. Xia and Amitabh Varshney, "<a href='http://scholar.google.com/scholar?q="Dynamic+view-Dependent+Simplification+for+Polygonal+Models%2C"'>Dynamic view-Dependent Simplification for Polygonal Models,</a>" Proceedings Visualization '96, Oct. 27-Nov. 1, 1996, p. 327-498.</td></tr><tr><td class="patent-data-table-td ">68</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Julie C. Xia et al., "<a href='http://scholar.google.com/scholar?q="Adaptive+Real-time+Level-of-Detail-Based+Rendering+for+Polygonal+Model%2C"'>Adaptive Real-time Level-of-Detail-Based Rendering for Polygonal Model,</a>" IEEE Trans., Apr.-Jun. 1997, vol. 3, No. 2, p. 171-183.</td></tr><tr><td class="patent-data-table-td ">69</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Kaplan, Lance M., et al., "<a href='http://scholar.google.com/scholar?q="Fast+Texture+Database+Retrieval+Using+Extended+Fractal+Features%2C"'>Fast Texture Database Retrieval Using Extended Fractal Features,</a>" SPIE, Jan. 1998, vol. 3312, p. 162-173.</td></tr><tr><td class="patent-data-table-td ">70</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Korp, P. A., Lurie, G.R., and Christiansen, J., "<a href='http://scholar.google.com/scholar?q="A+Smalltalk-based+Extension+to+Traditional+Geographic+Information+Systems%2C"'>A Smalltalk-based Extension to Traditional Geographic Information Systems,</a>".</td></tr><tr><td class="patent-data-table-td ">71</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Lance Williams, "<a href='http://scholar.google.com/scholar?q="Pyramidal+Parametrics%2C"'>Pyramidal Parametrics,</a>" Computer Graphics, Jul. 1983, vol. 17, No. 3, p. i-11.</td></tr><tr><td class="patent-data-table-td ">72</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Leclerc, Yvan G. and Lau, Jr., Steven Q., "<a href='http://scholar.google.com/scholar?q="TerraVision%3A+A+Terrain+Visualization+System%2C"'>TerraVision: A Terrain Visualization System,</a>" SRI International, Jan. 26, 1995, pp. 1-20.</td></tr><tr><td class="patent-data-table-td ">73</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Leigh, Jason, et al., "<a href='http://scholar.google.com/scholar?q="CAVERN%3A+A+Distributed+Architecture+for+Supporting+Scalable+Persistence+and+Interoperability+in+Collaborative+Virtual+Environments%2C"'>CAVERN: A Distributed Architecture for Supporting Scalable Persistence and Interoperability in Collaborative Virtual Environments,</a>".</td></tr><tr><td class="patent-data-table-td ">74</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Liang, Jiandong, Shaw, Chris and Green, Mark, "<a href='http://scholar.google.com/scholar?q="On+Temporal-Spatial+Realism+in+the+Virtual+REality+Environment%2C"'>On Temporal-Spatial Realism in the Virtual REality Environment,</a>" Nov. 11-13, 1991, pp. 19-25.</td></tr><tr><td class="patent-data-table-td ">75</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Lindstrom, P. et al., "<a href='http://scholar.google.com/scholar?q="Real-Time%2C+Continuous+Level+of+Detail+Rendering+of+Height+Fields%2C"'>Real-Time, Continuous Level of Detail Rendering of Height Fields,</a>" Computer Graphics, Siggraph 96, Aug. 4-9, 1996, pp. 109-118.</td></tr><tr><td class="patent-data-table-td ">76</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Lindstrom, Peter, et al., "<a href='http://scholar.google.com/scholar?q="Level-of-Detail+Management+for+Real-Time+rendereing+of+Phototextured+Terrain%2C"'>Level-of-Detail Management for Real-Time rendereing of Phototextured Terrain,</a>" p. 1-110.</td></tr><tr><td class="patent-data-table-td ">77</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Lindstron, Peter, Koller, David, Ribarsky, William, Hodges, Larry. F., Op den Bosch, Augusto, Faust, Nick, "<a href='http://scholar.google.com/scholar?q="An+Integrated+Global+GIS+and+Visual+Simulation+System%2C"'>An Integrated Global GIS and Visual Simulation System,</a>" pp. 1-9.</td></tr><tr><td class="patent-data-table-td ">78</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Luebke, David and Erikson, Carl, "<a href='http://scholar.google.com/scholar?q="View-Dependent+Simplification+of+Arbitrary+Polygonal+Environments%2C"'>View-Dependent Simplification of Arbitrary Polygonal Environments,</a>" Computer Graphics, Siggraph 97, Aug. 3-8, 1997, pp. 199-208.</td></tr><tr><td class="patent-data-table-td ">79</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Niblack, W., et al., "<a href='http://scholar.google.com/scholar?q="The+QBIC+Project%3A+Querying+Images+By+Content+Using+Color%2C+Texture%2C+and+Shape%2C"'>The QBIC Project: Querying Images By Content Using Color, Texture, and Shape,</a>" SPIE, vol. 1908, p. 173-187.</td></tr><tr><td class="patent-data-table-td ">80</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Palmer, Stephen, Rosch, and Chase, Paul, "<a href='http://scholar.google.com/scholar?q="8+Canonical+Perspective+and+the+Perception+of+Objects%2C"'>8 Canonical Perspective and the Perception of Objects,</a>" LEA, 1981, p. 135-151.</td></tr><tr><td class="patent-data-table-td ">81</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Pugh, William, "<a href='http://scholar.google.com/scholar?q="Skip+Lists%3A+A+Probabilistic+Alternative+to+Balanced+Trees%2C"'>Skip Lists: A Probabilistic Alternative to Balanced Trees,</a>" Communications of the ACM, Jun. 1990, vol. 22, No. 6, p. 668-675.</td></tr><tr><td class="patent-data-table-td ">82</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Reddy, Martin, "<a href='http://scholar.google.com/scholar?q="A+Survey+of+Level+of+Detail+Support+in+Current+Virtual+Reality+Solutions%2C"'>A Survey of Level of Detail Support in Current Virtual Reality Solutions,</a>" Virtual Reality, 1995, vol. 1, No. 2, p. 95-98.</td></tr><tr><td class="patent-data-table-td ">83</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Robert Weibel and C. B. Jones, "<a href='http://scholar.google.com/scholar?q="Computational+Perspectives+on+Map+Generalization%2C"'>Computational Perspectives on Map Generalization,</a>" GeoInformation, 1998, vol. 2, No. 4, p. 307-314.</td></tr><tr><td class="patent-data-table-td ">84</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Roger D. Smith, "<a href='http://scholar.google.com/scholar?q="Vertical+Interface+Methodology+for+Connecting+Constructive+and+Virtual+Level+Simulations%2C"'>Vertical Interface Methodology for Connecting Constructive and Virtual Level Simulations,</a>" Central University, Sep. 15, 1994, p. i-122.</td></tr><tr><td class="patent-data-table-td ">85</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Rossignac, Jarek and Borrel, Paul, "<a href='http://scholar.google.com/scholar?q="Multi-resolution+3D+Approximations+for+Rendering+Complex+Scenes%2C"'>Multi-resolution 3D Approximations for Rendering Complex Scenes,</a>" p. 455-465.</td></tr><tr><td class="patent-data-table-td ">86</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Scarlatos, Lori L., et al., "<a href='http://scholar.google.com/scholar?q="A+Refined+Triangulation+Hierarchy+For+Multiple+Levels+of+Terrain+Detail%2C"'>A Refined Triangulation Hierarchy For Multiple Levels of Terrain Detail,</a>" p. 115-122.</td></tr><tr><td class="patent-data-table-td ">87</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Schachter, Bruce J., "<a href='http://scholar.google.com/scholar?q="Computer+Image+Generation+for+Flight+Simulation%2C"'>Computer Image Generation for Flight Simulation,</a>" IEEE Computer Graphics and Applications, Oct. 1981, p. 5-68.</td></tr><tr><td class="patent-data-table-td ">88</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Sidney W. Wang and Arie E. Kaufman, "<a href='http://scholar.google.com/scholar?q="Volume+Sampled+voxelization+of+Geometric+Primitives%2C"'>Volume Sampled voxelization of Geometric Primitives,</a>" Visualization '93, Oct. 25-29, 1993, p. 77-84 and CP-9.</td></tr><tr><td class="patent-data-table-td ">89</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Tanner, Christopher C., et al., "<a href='http://scholar.google.com/scholar?q="The+Clipmap%3A+A+Virtual+Mipmap%2C"'>The Clipmap: A Virtual Mipmap,</a>" Silicon Graphics Computer Systems.</td></tr><tr><td class="patent-data-table-td ">90</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Terry Caelli and Giampaolo Moraglia, "<a href='http://scholar.google.com/scholar?q="On+the+Detection+of+Gabor+Signals+and+Discrimination+of+Gabor+Texture%2C"'>On the Detection of Gabor Signals and Discrimination of Gabor Texture,</a>" Journal in Visual Science, 1985, p. 671-684, vol. 25 No. 5.</td></tr><tr><td class="patent-data-table-td ">91</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Tonkin, Maine H. and Moerdyk, David M., "<a href='http://scholar.google.com/scholar?q="Testing+Missile+Seeker+Systems+with+Computer+Generated+Images%2C"'>Testing Missile Seeker Systems with Computer Generated Images,</a>" p. 221-228.</td></tr><tr><td class="patent-data-table-td ">92</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">V.E. Taylor, et al., "<a href='http://scholar.google.com/scholar?q="Identifying+and+Reducing+Critical+Lag+in+finite+Element+Simulations"'>Identifying and Reducing Critical Lag in finite Element Simulations</a>" IEEE Computer Graphics and Applications, 1996, p. 67-71.</td></tr><tr><td class="patent-data-table-td ">93</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Vince, John, "<a href='http://scholar.google.com/scholar?q="10+Virtual+Reality+Techniques+in+Flight+Simulation%2C"'>10 Virtual Reality Techniques in Flight Simulation,</a>" Virtual Reality Systems, 1993, p. 135-157.</td></tr><tr><td class="patent-data-table-td ">94</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Watson, Benjamin Allen, "<a href='http://scholar.google.com/scholar?q="Level+of+Detail+Management%2C"'>Level of Detail Management,</a>" Georgia Institute of Technology, Sep. 1997, p. i-140.</td></tr><tr><td class="patent-data-table-td ">95</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Wei-Ying Ma, "<a href='http://scholar.google.com/scholar?q="Netra%3A+A+Toolbox+For+Navigating+Large+Image+Databases%2C"'>Netra: A Toolbox For Navigating Large Image Databases,</a>" Doctor of Philosophy in Electrical and Computer Engineering, Jun. 1997, p. 1-158.</td></tr><tr><td class="patent-data-table-td ">96</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Westervelt, James D., "<a href='http://scholar.google.com/scholar?q="Simulating+Mobile+Objects+in+Dynamic+Processes%2C"'>Simulating Mobile Objects in Dynamic Processes,</a>" USACERL Technical Report, 98/94, Jul. 1998.</td></tr><tr><td class="patent-data-table-td ">97</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Yan, Johnson K., "<a href='http://scholar.google.com/scholar?q="Advances+in+Computer-Generated+Imagery+for+Flight+Simulation%2C"'>Advances in Computer-Generated Imagery for Flight Simulation,</a>" IEEE Computer Society, Aug. 1985, pp. 2-51.</td></tr><tr><td class="patent-data-table-td ">98</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Zhang, Hansong, "<a href='http://scholar.google.com/scholar?q="Effective+Occlusion+Culling+for+the+Interactive+Display+of+Arbitrary+Models%2C"'>Effective Occlusion Culling for the Interactive Display of Arbitrary Models,</a>" p. i-98.</td></tr><tr><td class="patent-data-table-td ">99</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Zimmerman, stephen A., "<a href='http://scholar.google.com/scholar?q="Applying+Frequency+Domain+Constructs+to+a+Broad+Spectrum+or+Visual+Simulation+Problems%2C"'>Applying Frequency Domain Constructs to a Broad Spectrum or Visual Simulation Problems,</a>" Image IV Conference, Jun. 23-26, 1987, p. 209-216.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8184069">US8184069</a></td><td class="patent-data-table-td patent-date-value">Jun 20, 2011</td><td class="patent-data-table-td patent-date-value">May 22, 2012</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Systems and methods for adaptive transmission of data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8471783">US8471783</a></td><td class="patent-data-table-td patent-date-value">Apr 23, 2012</td><td class="patent-data-table-td patent-date-value">Jun 25, 2013</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Systems and methods for adaptive transmission of data</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S428000">345/428</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc715/defs715.htm&usg=AFQjCNEsvPOacMHcG92b6Esmd6a_S2NVkg#C715S760000">715/760</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S419000">345/419</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S421000">345/421</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S597000">345/597</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc715/defs715.htm&usg=AFQjCNEsvPOacMHcG92b6Esmd6a_S2NVkg#C715S848000">715/848</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S645000">345/645</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S190000">382/190</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc705/defs705.htm&usg=AFQjCNFzs2esjESm-KHynrEapHJvKhyIeA#C705S027200">705/27.2</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0017000000">G06T17/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0017400000">G06T17/40</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q30/0277">G06Q30/0277</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T19/003">G06T19/003</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q30/0623">G06Q30/0623</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q30/0643">G06Q30/0643</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T2200/16">G06T2200/16</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q30/0247">G06Q30/0247</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q30/0242">G06Q30/0242</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T19/20">G06T19/20</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=pXDIBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q30/02">G06Q30/02</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06T19/00</span>, <span class="nested-value">G06Q30/02</span>, <span class="nested-value">G06Q30/0643</span>, <span class="nested-value">G06Q30/0242</span>, <span class="nested-value">G06Q30/0247</span>, <span class="nested-value">G06Q30/0277</span>, <span class="nested-value">G06Q30/0623</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Mar 11, 2013</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 11, 2013</td><td class="patent-data-table-td ">SULP</td><td class="patent-data-table-td ">Surcharge for late payment</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 4, 2013</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 10, 2012</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1, 28, 45, 56, 61, 67 AND 72 ARE CANCELLED. CLAIMS 2-27, 29-44, 46-55, 57-60, 62-66, 68-71 AND 73-77 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 5, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110215</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1n3wv3Jh0EyidUNPcxJMQVwuuQ1A\u0026id=pXDIBQABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0gKZNt5PdTteyHd78xMnsHk8q4oA\u0026id=pXDIBQABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U33avG41sGFnBxfb9NLQ9I3tv1rBA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Sending_three_dimensional_images_over_a.pdf?id=pXDIBQABERAJ\u0026output=pdf\u0026sig=ACfU3U26wEVG6FfkemY_Sleaa5HDKtiKLw"},"sample_url":"http://www.google.com/patents/reader?id=pXDIBQABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>