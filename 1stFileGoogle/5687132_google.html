<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5687132 - Multiple-bank memory architecture and systems and methods using the same - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4ff636b3d23669b7103f3b3a3a18b4cd/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4ff636b3d23669b7103f3b3a3a18b4cd__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Multiple-bank memory architecture and systems and methods using the same"><meta name="DC.contributor" content="G. R. Mohan Rao" scheme="inventor"><meta name="DC.contributor" content="Cirrus Logic, Inc." scheme="assignee"><meta name="DC.date" content="1995-10-26" scheme="dateSubmitted"><meta name="DC.description" content="A memory 20 is disclosed including a first column of memory cells including a conductive bitline 202 and a second column of memory cells also including a conductive bitline 202. A gate 203 is provided for selectively coupling the bitline 202 of the first column with the bitline 202 of the second column for transferring a bit of data from a selected cell of the first column to a selected cell of the second column."><meta name="DC.date" content="1997-11-11" scheme="issued"><meta name="DC.relation" content="US:4893281" scheme="references"><meta name="DC.relation" content="US:4987559" scheme="references"><meta name="DC.relation" content="US:5121360" scheme="references"><meta name="DC.relation" content="US:5305284" scheme="references"><meta name="DC.relation" content="US:5319603" scheme="references"><meta name="DC.relation" content="US:5377154" scheme="references"><meta name="DC.relation" content="US:5390139" scheme="references"><meta name="citation_patent_number" content="US:5687132"><meta name="citation_patent_application_number" content="US:08/548,752"><link rel="canonical" href="http://www.google.com/patents/US5687132"/><meta property="og:url" content="http://www.google.com/patents/US5687132"/><meta name="title" content="Patent US5687132 - Multiple-bank memory architecture and systems and methods using the same"/><meta name="description" content="A memory 20 is disclosed including a first column of memory cells including a conductive bitline 202 and a second column of memory cells also including a conductive bitline 202. A gate 203 is provided for selectively coupling the bitline 202 of the first column with the bitline 202 of the second column for transferring a bit of data from a selected cell of the first column to a selected cell of the second column."/><meta property="og:title" content="Patent US5687132 - Multiple-bank memory architecture and systems and methods using the same"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("WmroU7m5GtCssASWuICIAQ"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407291699.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("NLD"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("WmroU7m5GtCssASWuICIAQ"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407291699.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("NLD"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5687132?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5687132"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=XANEBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5687132&amp;usg=AFQjCNGzcwenjcBElqZVEn_ELSEfPhssOw" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5687132.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5687132.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5687132" style="display:none"><span itemprop="description">A memory 20 is disclosed including a first column of memory cells including a conductive bitline 202 and a second column of memory cells also including a conductive bitline 202. A gate 203 is provided for selectively coupling the bitline 202 of the first column with the bitline 202 of the second column...</span><span itemprop="url">http://www.google.com/patents/US5687132?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5687132 - Multiple-bank memory architecture and systems and methods using the same</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5687132 - Multiple-bank memory architecture and systems and methods using the same" title="Patent US5687132 - Multiple-bank memory architecture and systems and methods using the same"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5687132 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/548,752</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Nov 11, 1997</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Oct 26, 1995</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Oct 26, 1995</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/DE69618319D1">DE69618319D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0771008A2">EP0771008A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0771008A3">EP0771008A3</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0771008B1">EP0771008B1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08548752, </span><span class="patent-bibdata-value">548752, </span><span class="patent-bibdata-value">US 5687132 A, </span><span class="patent-bibdata-value">US 5687132A, </span><span class="patent-bibdata-value">US-A-5687132, </span><span class="patent-bibdata-value">US5687132 A, </span><span class="patent-bibdata-value">US5687132A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22G.+R.+Mohan+Rao%22">G. R. Mohan Rao</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Cirrus+Logic,+Inc.%22">Cirrus Logic, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5687132.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5687132.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5687132.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (7),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (14),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (9),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (10)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5687132&usg=AFQjCNGqgb-Ji8YSWu1n83gLeRbmrc6_dQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5687132&usg=AFQjCNFyp4uT_ve7bBOlED5UFv3o4XbWyg">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5687132A%26KC%3DA%26FT%3DD&usg=AFQjCNGO8sjJNo990DuQloe82gq8QUxw5Q">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54212818" lang="EN" load-source="patent-office">Multiple-bank memory architecture and systems and methods using the same</invention-title></span><br><span class="patent-number">US 5687132 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37695487" lang="EN" load-source="patent-office"> <div class="abstract">A memory 20 is disclosed including a first column of memory cells including a conductive bitline 202 and a second column of memory cells also including a conductive bitline 202. A gate 203 is provided for selectively coupling the bitline 202 of the first column with the bitline 202 of the second column for transferring a bit of data from a selected cell of the first column to a selected cell of the second column.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(4)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5687132-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5687132-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5687132-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5687132-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5687132-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5687132-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5687132-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5687132-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(30)</span></span></div><div class="patent-text"><div mxw-id="PCLM5151586" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A memory comprising:<div class="claim-text">a first plurality of columns of memory cells each including at least one conductive bitline;</div> <div class="claim-text">a second plurality of columns of memory cells each including at least one conductive bitline; and</div> <div class="claim-text">a plurality of gates organized in independently controlled groups for selectively coupling said bitlines of a selected group of said first plurality of columns with a group of said bitlines of said second plurality of columns for transferring a at least one bit of data from a selected cell of said first plurality of columns of cells to a selected cell of said second plurality of columns of cells.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The memory of claim 1 wherein each said gate comprises a field effect transistor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The memory of claim 1 wherein said memory cells comprises dynamic random access memory cells.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The memory of claim 1 wherein said first column of cells comprises one of a plurality of columns of memory cells forming a first subarray and said second column of cells comprises one of a plurality of columns of cells forming a second subarray.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The memory of claim 4 wherein said first and second subarrays each comprise a plurality of rows of cells, each said row including a conductive wordline, a wordline of a said row of said first subarray controlled by a first row decoder and a wordline of a said row of said second subarray controlled by a second row decoder.</div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6. A memory subsystem comprising:<div class="claim-text">a first subarray of memory cells arranged in rows and columns, each said column associated with a conductive bitline and each said row associated with a conductive wordline;</div> <div class="claim-text">a second subarray of memory cells arranged in rows and columns, each said column associated with a conductive bitline and each said row associated with a conductive wordline;</div> <div class="claim-text">circuitry for independently coupling selected groups of said bitlines of said first subarray with corresponding groups of said bitlines of said second subarray;</div> <div class="claim-text">a first column decoder coupled to said bitlines of said first subarray for randomly accessing selected cells along a selected row in said first subarray; and</div> <div class="claim-text">a second column decoder coupled to said bitlines of said second subarray for randomly accessing selected cells along a selected row in said second subarray.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The memory subsystem of claim 6 and further comprising column control circuitry operable to cause said circuitry for gating to coupled selected ones of said bitlines in response to a received control signal.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The memory of claim 6 wherein said bitlines of each of said first and second subarrays comprise folded bitlines.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The memory of claim 6 wherein said circuitry for coupling comprises a plurality of gates.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The memory of claim 9 wherein said plurality of gates comprises a plurality of field effect transistors.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The memory of claim 8 and further comprising control circuitry for causing said circuitry for coupling to couple a said bitline and a complementary said bitline of said first subarray with a said bitline and a complementary said bitline of said second subarray in response to a received control signal.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The memory of claim 6 and further comprising a first row decoder coupled to said wordlines of said first subarray and a second row decoder coupled to said wordlines of said second subarray.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The memory of claim 12 wherein said first and second row decoders respond to different address sets respectively.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The memory of claim 1 wherein said first and second column decoders respond to different address sets respectively.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. The memory of claim 14 and further comprising a first first-in-first-out memory coupled to said first column decoder and a second first-in-first-out memory coupled to said second column decoder.</div>
    </div>
    </div> <div class="claim"> <div num="16" class="claim">
      <div class="claim-text">16. A memory device comprising:<div class="claim-text">a first subarray of rows and columns of dynamic random access memory cells, each said column including a bitline and each said row including a wordline;</div> <div class="claim-text">a second subarray of rows and columns of dynamic random access memory cells, each said column including a bitline and each said row including a wordline;</div> <div class="claim-text">a first row decoder for selecting a said wordline in said first subarray in response to a first set of row addresses;</div> <div class="claim-text">a second row decoder for selecting a said wordline in said second subarray in response to a second set of row addresses;</div> <div class="claim-text">a first column decoder for selecting at least one bitline in said first subarray for random access in response to a first set of column addresses;</div> <div class="claim-text">a second column decoder for selecting at least one bitline in said second subarray for random access in response to a second set of column addresses;</div> <div class="claim-text">a first plurality of gates for selectively coupling at least one bitline of a corresponding group of bitlines in said first subarray with at least one bitline of a corresponding group of bitlines in said second subarray, said first plurality of gates controlled by a first control signal; and</div> <div class="claim-text">a second plurality of gates for selectively coupling at least one bitline in a corresponding group of bitlines in said first subarray with at least one bitline of a corresponding group of bitlines in said second subarray.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The memory device of claim 16 wherein first set of row addresses is equivalent to said second set of row addresses.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. The memory device of claim 16 wherein said first set of column addresses is equivalent to said second set of column addresses.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The memory device of claim 16 wherein said bitlines of said first and second subarrays comprise folded bitlines arranged in pairs of complementary bitlines, a sense amplifier shared by said complementary bitlines of a selected said pair.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The memory device of claim 16 and further comprising latching circuitry associated with said first subarray for temporarily latching data read from at least one cell in said first subarray during a transfer through at least one of said gates to a cell in said second subarray.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. The memory device of claim 16 wherein said plurality of gates comprises a plurality of field effect transistors each having a current path coupling a said bitline in said first subarray with a said bitline in said second subarray.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22. The memory device of claim 16 wherein said plurality of gates are controlled by at least one control signal received from a source external to said memory device.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. The memory device of claim 16 and further comprising a first FIFO coupled to said first column decoder and a second FIFO coupled to said second column decoder.</div>
    </div>
    </div> <div class="claim"> <div num="24" class="claim">
      <div class="claim-text">24. A processing system comprising:<div class="claim-text">a memory device including:<div class="claim-text">a first subarray of memory cells arranged in rows and columns, each said column associated with a conductive bitline and each said row associated with a conductive wordline;</div> <div class="claim-text">a second subarray of memory cells arranged in rows and columns, each said column associated with a conductive bitline and each said row associated with a conductive wordline;</div> <div class="claim-text">circuitry for randomly accessing at least one selected cell in said first subarray;</div> <div class="claim-text">circuitry for randomly accessing at least one selected cell in said second subarray;</div> <div class="claim-text">circuitry for coupling a selected one of said bitlines of said first subarray with a selected one of said bitlines of said second subarray for transferring data from an accessed cell of said first subarray to an accessed cell of said second subarray;</div> </div> <div class="claim-text">a first display device for displaying data received from said first subarray; and</div> <div class="claim-text">a second display device for displaying data received from said second subarray.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25. The processing system of claim 24 wherein said first and second display devices operate at different refresh rates.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" class="claim">
      <div class="claim-text">26. The processing system of claim 24 wherein said circuitry for accessing a said cell in said first subarray and said circuitry for accessing a said cell in said second subarray are coupled to a single display controller.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27. The processing system of claim 24 wherein said circuitry for accessing a said cell in said first subarray and said circuitry for accessing a said cell in said second subarray are coupled to a single core logic chip set.</div>
    </div>
    </div> <div class="claim"> <div num="28" class="claim">
      <div class="claim-text">28. A method for performing a data transfer in a memory subsystem including a first subarray of memory cells arranged in rows and columns, each column associated with a conductive bitline and each row associated with a conductive wordline, a second subarray of memory cells arranged in rows and columns, each column associated with a conductive bitline and each row associated with a conductive wordline, and a plurality gates partitioned into at least two independently controllable groups, each group of gates for coupling selected ones of the bitlines of the first subarray with corresponding ones of the bitlines of said second subarray, the method comprising the steps of:<div class="claim-text">activating a selected wordline in the first subarray;</div> <div class="claim-text">sensing data at the bitlines of the first subarray from the cells of the selected row;</div> <div class="claim-text">activating a selected group of the gates to couple the sensed data from ones of the bitlines of the first subarray to selected ones of the bitlines of the second subarray; and</div> <div class="claim-text">activating a selected wordline of the second subarray to write the data from the first subarray into cells of a selected row and the columns associated with the selected bitlines of the second subarray.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" class="claim">
      <div class="claim-text">29. The method of claim 28 and further comprising the step of latching the data at the bitlines of the first subarray after said step of sensing.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" class="claim">
      <div class="claim-text">30. The method of claim 28 and further comprising the step of deactivating the selected wordline in the first subarray prior to said step of activating the selected wordline in the second subarray.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67040001" lang="EN" load-source="patent-office" class="description">
    <heading>TECHNICAL FIELD OF THE INVENTION</heading> <p>The present invention relates in general to electronic memories and in particular to multiple-bank memories and systems and methods using the same.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>A typical processing system with video/graphics display capability includes a central processing unit (CPU), a display controller coupled to the CPU by a CPU local bus (directly and/or through core logic), a system memory coupled to the CPU local bus through core logic, a frame buffer memory coupled to the display controller via a peripheral local bus (e.g., PCI bus), peripheral circuitry (e.g., clock drivers and signal converters, display driver circuitry), and a display unit.</p>
    <p>The CPU is the system master and generally provides overall system control in con, unction with the software operating system. Among other things, the CPU communicates with the system memory, holding instructions and data necessary for program execution, normally through core logic. Typically, the core logic is two to seven chips, with one or more chips being "address intensive" and one or more other chips being "data path intensive." The CPU also, in response to user commands and program instructions, controls the contents of the graphics images to be displayed on the display unit by the display controller.</p>
    <p>The display controller, which may be, for example, a video graphics architecture (VGA) controller, generally interfaces the CPU and the display driver circuitry, manages the exchange of graphics and/or video data between the frame buffer and the CPU and the display during display data update and screen refresh operations, controls frame buffer memory operations, and performs additional basic processing on the subject graphics or video data. For example, the display controller may also include the capability of performing basic operations such as line draws and polygon fills. The display controller is for the most part a slave to the CPU.</p>
    <p>In current information processing systems, a number of key operations, such as data block transfers and display updates, are inefficiently performed because of limitations on the available system architectures and memory devices. As a result, system performance and pricing cannot be optimized. This is especially true in the case of state of the art systems operating at high clock rates and/or with high definition displays.</p>
    <p>During a block transfer, an entire block of data is either moved or copied from a source area in memory to a destination area in memory. The transfer may be between the system memory and the frame buffer, within the system memory, or within the frame buffer. Block transfers operations can be performed by a "BLT (bit-block transfer) engine" within either the display controller or the CPU, or even by the CPU itself. Typically, the data is read from the source area of memory a word or byte at a time, and then written into the destination block of memory a word or byte at a time. This use of two operations (a read and a write) results in substantial inefficiencies, especially when the transfer crosses chip boundaries; not only are the number of required clock cycles doubled, but the bandwidth of the device interfaces and the interconnecting bus are diverted from other critical operations.</p>
    <p>A similar problem occurs during display update operations. Generally, the CPU itself generates the display (graphics) data necessary to update the display screen when a display image change is required by user or the application software being run. Due to overhead constraints on the CPU, (as well as bandwidth limitations on PCI local bus and other buses within the system) and limits on the size of the display controller write buffer, the updated display data generated by the CPU is first stored in the system memory. When the display controller write buffer has capacity and CPU time is available, the CPU then reads back the required update information (typically both addresses to the frame buffer and pixel data) from the system memory via the core logic and the CPU local bus and then writes that data via the core logic and PCI local bus into the write buffer of the display controller. In other words, multiple CPU cycles (i.e., a read and a write cycle) are required to write each word of data to the display controller during a display update. This creates serious disadvantages when the efficient use of CPU cycles is critical to higher processing speeds and expanded performance and available bus bandwidth is constrained.</p>
    <p>Another instance where transferring data can be problematic is during the operation of multiple asynchronous displays using a single display subsystem. This may occur for example when a single display controller and/or frame buffer are used to drive a CRT display requiring data at a first refresh rate and simultaneously an LCD display screen at a second refresh rate. The problem becomes even more difficult when the respective displays differ in size (number of pixels to be displayed).</p>
    <p>Most currently available display subsystems, and in particular graphics subsystems, can simultaneously display the same information on both a CRT display and an LCD display. One instance where this situation occurs is when a portable PC with an LCD display is inserted into a "docking station" with a CRT display. Such systems are practical as long as: (1) the resolution of the displays is the same (i.e. 640Ã—480 pixels) and (2) the refresh rates for both displays are the same. When the displays differ in size, some vertical or horizontal interpolation may be employed to expand or contract the images, as required, to fit the display screens. However, interpolation usually distorts the images, especially when graphics and text are mixed.</p>
    <p>In an asynchronous system, the refresh rates for the two display devices differ. For example, the system CRT display might have a 72 Hz refresh rate and the LCD display might have a 60 Hz refresh rate. In this case a contention problem arises if the display controller attempts to drive both displays from the same frame buffer. Two frame buffers may be used to solve the contention problem and in addition allow the display controller to simultaneously generate different images on the respective displays. The two frame buffer approach however is more complex and expensive, since not only is additional memory required but also independent display data controls (e.g. FIFOs and DACs). Further, the use of two different frame buffers is inefficient since often data use overlaps; in current two display systems, the data is simply stored twice, once in each frame buffer.</p>
    <p>Thus, the need has arisen for memory devices and systems and methods using the same which addresses each of the problems discussed above. In particular, such a memory devices, systems and methods should allow for efficient block transfers of data. Increased efficiency of display operations, such as display data updates, should also be addressed. Additionally, such memory devices, systems and methods should allow for the efficient generation of images on multiple displays.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>In general, the principles of the present invention provide for the construction and operation of multiple bank memories. These memories include dynamic random access memory (DRAM) devices, static random access memory (SRAM) devices, and other types of memory devices. Generally, each memory includes multiple subarrays of columns of memory cells, the bitlines of which may be selectively coupled together by gating circuitry. This allows, among other things, for a bit of data to be transferred from one column of memory cells to another with only one gate delay. Further, the principles of the present invention allow for the two banks of memory to be operated asynchronously and independently.</p>
    <p>According to a first embodiment of the principles of the present invention, a memory device is provided which includes a first column of memory cells having at least one conductive bitline and a second column of memory cells, also having at least one conductive bit line. A gate is provided for selectively coupling the bitline of the first column with the bitline of the second column for transferring a bit of data from a selected cell of the first column of cells to a selected cell of the second column of cells.</p>
    <p>According to a second embodiment of the present invention, a memory subsystem is provided which includes first and second subarrays of memory cells. The memory cells of the first subarray are arranged in rows and columns, with each column associated with a conductive bitline and each row associated with a conductive word line. The second subarray is also arranged as rows and columns of cells, with each column of the second subarray associated with a conductive bitline and each row of the second subarray associated with a conductive word line. The memory subsystem also includes circuitry for coupling selected ones of the bit lines of the first subarray with corresponding ones of the bit lines of the second subarray.</p>
    <p>According to a further embodiment of the principles of the present invention, a memory device is provided which includes a first subarray of rows and columns of dynamic random access memory cells, each column including a bitline and each row including a word line. A second subarray of rows and columns of dynamic random access memory cells is also provided, with each column including a bitline and each row including a word line. A first row decoder is provided for selecting a wordline in the first subarray in response to a first set of row addresses. A second row decoder is provided for selecting a wordline in the second subarray in response to a second set of row addresses. A first column decoder is provided for selecting at least one bitline in the first array in response to a first set of column addresses and a second column decoder is provided for selecting at least one bitline in the second subarray in response to a second set of column addresses. Finally, a plurality of gates is included for selectively coupling at least one bitline in the first subarray with at least one bitline in the second subarray.</p>
    <p>The principles of the present invention are further embodied in processing systems. Once such processing system includes a memory device including a first array of memory cells arranged in rows and columns, each column associated with a conductive bitline and each row associated with a conductive word line. The memory device also includes a second subarray of memory cells arranged in rows and columns, each column associated with a conductive bitline and each row associated with a conductive word line. The memory device further includes circuitry for accessing at least one selected cell in the first subarray and circuitry for accessing at least one selected cell in the second subarray. Circuitry is provided for coupling a selected one of the bit lines of the first subarray with a selected one of the bit lines of the second subarray for transferring data from an accessed cell of the first subarray to an accessed cell of the second subarray. The processing system further includes a first display device for displaying data received from the first subarray and a second display device for displaying data from the second subarray.</p>
    <p>The principles of the present invention are also embodied in methods for performing a block transfer in a memory subsystem, the memory subsystem including first and second subarrays of memory cells, each arranged in rows and columns, with each column associated with a conductive bitline and each row associated with a conductive word line, the memory further including a plurality of gates for coupling selected ones of the bitline of the first subarray with corresponding ones of the bitline for the second subarray. According to one method, a selected wordline in the first subarray is activated. Data at the bit lines of the first subarray from the cells of the selected row are sensed. Selected ones of the gates are activated to couple the sensed data from the corresponding bit lines of the first subarray to selected ones of the bit lines of the second subarray. A selected wordline of the second subarray is activated to write the data from the first subarray into the cells of a selected row of the second subarray.</p>
    <p>Memory devices and systems and methods embodying the principles of the present invention have substantial advantages over the prior art. Among other things, the principles of the present invention provide for the efficient block transfer of data within a memory subsystem. Efficient block transfers in turn allow for optimization various display operations, such as display data updates, and block moves/copies. Additionally, the principles of the present invention allow for the efficient generation of images on multiple displays, especially if such displays are being asynchronously refreshed a differing refresh rated.</p>
    <p>The foregoing has outlined rather broadly the features and technical advantages of the present invention in order that the detailed description of the invention that follows may be better understood. Additional features and advantages of the invention will be described hereinafter which form the subject of the claims of the invention. It should be appreciated by those skilled in the art that the conception and the specific embodiment disclosed may be readily utilized as a basis for modifying or designing other structures for carrying out the same purposes of the present invention. It should also be realized by those skilled in the art that such equivalent constructions do not depart from the spirit and scope of the invention as set forth in the appended claims.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>For a more complete understanding of the present invention, and the advantages thereof, reference is now made to the following descriptions taken in conjunction with the accompanying drawings, in which:</p>
    <p>FIGS. 1A and 1B are high level functional block diagrams of exemplary information processing systems in which one or more memories embodying the principles of the present invention may be employed;</p>
    <p>FIG. 2A is a functional block diagram of a first memory device embodying the principles of the present invention;</p>
    <p>FIG. 2B is an enlarged portion of FIG. 2A showing selected circuitry of the embodiment of FIG. 2A in additional detail; and</p>
    <p>FIG. 3 is a functional block diagram of a second memory device embodying the principles of the present invention.</p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading> <p>The principles of the present invention and their advantages are best understood by referring to the illustrated embodiment depicted in FIGS. 1-3 of the drawings, in which like numbers designate like parts. While memory devices embodying the principles of the present invention are useful in a wide number of applications, for purposes of illustration, such memory devices will be described in conjunction with a basic processing system architecture typically employed in personal computers.</p>
    <p>FIG. 1 is a high level functional block diagram of the portion of a processing system 100. System 100 includes a central processing unit 101, a CPU local bus 102, core logic 103, a display controller 104, a system memory 105, a digital to analog converter (DAC) 106, frame buffer 108, a display device 107a and an optional display device 107b.</p>
    <p>CPU 101 is the "master" which controls the overall operation of system 100. Among other things, CPU 101 performs various data processing functions and determines the content of the graphics data to be displayed on display unit 107 in response to user commands and/or the execution of application software. CPU 101 may be for example a general purpose microprocessor, such as an Intel Pentium class microprocessor or the like, used in commercial personal computers. CPU 101 communicates with the remainder of system 100 via CPU local bus 102, which may be for example a special bus, or a general bus (common in the industry).</p>
    <p>Core logic 103, under the direction of CPU 101, controls the exchange of data, addresses, control signals and instructions between CPU 101, display controller 104, and system memory 105. Core logic 103 may be any one of a number of commercially available core logic chip sets designed for compatibility with the remainder of the system, and in particular with CPU 101. One or more core logic chips, such as chip 112 in the illustrated system, are typically "address and system controller intensive" while one or more core logic chips, such as chip 114 in FIG. 1, are "data intensive." Address intensive core logic chip 112 generally: interfaces CPU 101 with the address path of CPU bus 102; maintains cache memory, including the cache tags, set associative cache tags and other data necessary to insure cache coherency; performs cache "bus snooping"; generates the control signals required for DRAMs in the system memory or cache; and controls general management transactions. Data intensive chip 114 generally: interfaces CPU 101 with the data path of CPU bus 102; issues cycle completion responses to address chip 112 or CPU 101; may abort operations if their cycles are incomplete; and arbitrates for the data path of bus 102.</p>
    <p>CPU 101 can directly communicate with core logic 103 or through an external (L2) cache 115. L2 cache 115 may be for example a 256 KByte fast SRAM device(s). It should be noted that CPU 101 can also include on-board (L1) cache, typically up to 16 kilobytes.</p>
    <p>Display controller 104 may be any one of a number of commercially available VGA display controllers. For example, display controller 104 may be one of the Cirrus Logic CL-GD754x series of display controllers. The structure and operation of such controllers is described in CL-GD754x Application Book, Rev 1.0, Nov. 22, 1994, and CL-GD7542 LCD VGA Controller Preliminary Data Book, Rev. 1.0.2, June 1994, both available from Cirrus Logic, Inc., Fremont, Calif., and incorporated herein by reference. Display controller 104 may receive data, instructions and/or addresses from CPU 101 either through core logic 103 or directly from CPU 101 through CPU local bus 102. Data, instructions, and addresses are exchanged between display controller 104 and system memory 105 through core logic 103. Further, addresses and instructions may be exchanged between core logic 103 and display controller 104 via a local bus which may be for example a PCI local bus. Generally, display controller 104 controls screen refresh, executes a limited number of graphics functions such as line draws, polygon fills, color space conversion, display data interpolation and zooming, and video streaming and handles other ministerial chores such as power management. Most importantly, display controller 104 controls the raster of pixel data from frame buffer 108 to display unit 107 during screen refresh and interfaces CPU 101 and frame buffer 108 during display data update. Video data may be directly input into display controller 104.</p>
    <p>Digital to analog converter 106 receives digital data from controller 104 and outputs the analog data to drive displays 107a and 107b (when used) in response. In the illustrated embodiment, DAC 106 is integrated with display controller 104 onto a single chip. Depending on the specific implementation of system 100, DAC 106 may also include a color palette, YUV to RGB format conversion circuitry, and/or X- and Y- zooming circuitry, to name a few options. Displays 107 may be for example a CRT unit, a liquid crystal display, electroluminescent display, plasma display, or other type of display device which displays images on a screen as a plurality of pixels. It should also be noted that in alternate embodiments, "display" 107 may be another type of output device such as a laser printer or similar document view/print appliance.</p>
    <p>As discussed further below, the principles of the present invention allow for two displays 107a and 107b to operate simultaneously even though their respective sizes and refresh rates differ. For example, display 107a may be an LCD portable PC display operating at a 60 Hz refresh rate and display 107b may be the CRT display of a docking system operating at 70 or 72 Hz.</p>
    <p>The data paths in system 100 will vary with each design. For example, system 100 may be a "64-bit" or "72-bit" system. Assume for discussion purposes that a 64-bit system is chosen. Then, each of the data connections, including the data paths of CPU bus 102 and PCI bus 116, the data paths through core logic 103 to system memory 109 and display controller 104, and the data interconnection between display controller 104 and frame buffer 108, are all 64 bits wide. It should be noted that the address interconnections will vary depending on the size of the memory and such factors as the need to support data byte select, error detection correction, and virtual memory operations. In a typical CPU processor system today, the address portions of CPU bus 102 and PCI bus 116 are typically on the order of 30 bits wide.</p>
    <p>FIG. 1B is an alternate system architecture to which the principles of the present invention may advantageously applied. In this example, memory 105 is a "unified" memory system since the system memory 109 and frame buffer 108 are collocated in a single integrated circuit or bank of integrated circuits. This is in contrast to those systems in which the frame buffer is separate and apart from the system memory and interfaces with the remainder of the system through the display controller. System memory 109 again is preferably a traditional system memory which stores data, addresses, and instructions under the command of CPU 101 as required for executing various processing functions and applications programs. As in traditional systems, the frame buffer 108 stores the pixel data required to generate the required images on the screen of display unit 107.</p>
    <p>FIG. 2 is a functional block diagram of a memory 20 embodying the principles of the present invention. In the preferred embodiment, memory 20 is fabricated on single integrated circuit chip, although the present invention is not limited to single chip embodiments.</p>
    <p>Memory 20 includes an array of n number of rows and m number of columns of memory cells partition into an upper bank or subarray 200a and a lower bank or subarray 200b. In the preferred embodiment, the memory cells are dynamic random access memory (DRAM) cells, although in alternate embodiments other memory devices, such as static random access memory (SRAM) cells, may be used.</p>
    <p>Some of the fundamental principles of DRAM operation are described in: "A 64-k Dynamic RAM Needs Only One 5-volt Supply to Outstrip 16 k Parts", G. R. Mohan Rao and John Hewkin, Electronics, Sep. 28, 1978, pp. 109-116; "A 5-volt Only 64 k DRAM", L. S. White, N. H. Hong, D. J. Redwine, and G. R. Mohan Rao, International Solid State Circuit Conference 1980, Digest of Technical Papers, pp. 230-231; "A 1 Mb DRAM With Design-For-Test Functions," J. Neal, B. Holland, S. Inoue, W. K. Loh, H. McAdams and K. Poteet, International Solid State Circuit Conference 1986, Digest of Technical Papers, pp. 264-265; "A 4 Mb DRAM With Half Internal-Voltage Bitline Precharge", International Solid State Circuit Conference 1986, Digest of Technical Papers, pp. 270-271; "A Full Bit Prefetch Architecture For Synchronous DRAMs", T. Sunaga, K. Hosokawa, Y. Nakamura, M. Ichinose, A Moriwaki, S. Kakimi and N. Kato, IEEE Journal of Solid State Circuits, Vol 30., No. 9, September 1995, pp. 994-1005; and "DRAM Macros For ASIC Chips", IEEE Journal of Solid State Circuits, Vol 30., No. 9, September 1995, pp. 1006-1014, each incorporated herein by reference.</p>
    <p>In the illustrated embodiment, subarray 200a includes rows 0 through n/2 and subarray 200b contains rows n/2+1 to n, although alternate row arrangements may be used. Each row is associated with a conductive wordline 201. The wordlines 201 of subarray 200a are coupled to and controlled by row decoder circuitry 204a and the wordlines 201 of subarray 200b are coupled to and controlled by row decoder circuitry 204b.</p>
    <p>In the preferred embodiment, the columns of cells are arranged as pairs of folded bitlines 202, one for carrying "true logic" data from a selected cell and the other for carrying the complement of that data. In FIG. 2A, bitlines pairs BLA0/BLA0 to BLAm/BLAm are contained within subarray 200a and bitline pairs BLB0/BLB0 to BLBm/BLBm are contained with subarray 200b. The bitlines 202 of subarrays 200a and 200b are coupled to and controlled by corresponding column decoder/sense amplifier circuitry 205a and 205b. According to the principles of the present invention each block of circuitry 205 further includes at least one latch per bitline 202 for selectively latching data passed by the column decoders in response to column addresses.</p>
    <p>FIG. 2B is a schematic diagram depicting in further detail representative pairs of the folded bitlines 202 of the preferred embodiment shown in FIG. 2A. A similar bitline/cell arrangement is applicable to the remainder of subarray 200a, as well as subarray 200b. In this case, the memory cells 220 are assumed to be DRAM cells. It should be noted that because of the sensing advantages of this configuration, discussed further below, folded bitlines are employed in the preferred embodiment, although in alternate embodiments other arrangements, such as open bitlines, may be used.</p>
    <p>In the folded bitline configuration, the memory cells 220 of each bitline BLAx are coupled to a corresponding even numbered wordline 201 while each cell 220 of a "complementary" bitline BLAx is coupled a corresponding odd numbered wordline. As shown in FIG. 2B, a pair of exemplary cells 220 along even Row 0 are coupled to bitlines BLA0 and BLA and a pair of exemplary cells 220 along odd ROW 1 are coupled to bitlines BLAO and BLA1 This pattern repeats itself throughout subarrays 200a and 200b.</p>
    <p>Each bitline pair, such as bitlines BLA0 and BLAO and bitlines BLA1 and BLA1 shown in FIG. 2B, are coupled to a sense amplifier 221. Sense amplifiers 221 sense difference the voltage between the bitlines BLAx and BLAx of the corresponding bitline pair. It should also be recognized that while the configuration of FIG. 2B does not employ a voltage reference for sensing, in alternate embodiments appropriate voltage reference circuitry known in the art (referenced previously) may also be included. The sense amplifiers then latch to either a full logic one or full a logic zero, depending on the sensed voltage swing. For example, assume that the cell 220 (cell A) at Row 0 and bitline BLA0 is be read (a write operation is similar, but instead data is impressed onto the bitlines and the cell capacitator). Bitlines BLA0 and BLA0 are precharged to Vcc. (In alternate embodiments the bitlines may be precharged to Vss, with the voltages during accesses appropriately reversed.) The wordline 201 for Row 0 is set to an active (logic high) state by row decoder 204a. If cell A is storing a logic zero (i.e zero charge on the cell capacitor), the charge on the voltage on the bitline BLA0 capacitance is discharged relative to the charge on the capacitance of bitline BLA0, which is at the precharge state of Vcc. The voltage swing is sensed by sense amplifier 221, which then latches BLA0 to a full logic 0 voltage and bitline BLA0 to the complement, a full logic 1. On the other hand, if cell A is storing a logic 1, the cell capacitor charges up bitline BLA0 relative to bitline BLA0; sense amplifier 221 latches bitline BLA0 to a logic 1 and bitline BLA0 to the complement, a logic 0. It should be recognized that if a cell along Row 1 is being accessed, such as cell B, bitlines BLA0 and BLA0 reverse roles. In this case, bitline BLA0 is latched to the "true data value" and BLA0 latched to the complement.</p>
    <p>According to the principles of the present invention, corresponding bitlines in arrays 200a and 200b can be selectively coupled together by gates 203 under the control of column control circuitry 206. As will be discussed in detail below, this configuration advantageously allows for the transfer of data from subarray 200a to subarray 200b with only a single gate delay per bit. In the preferred embodiment, gates 203 are field effect transistors having a source-drain path coupling the respective bitlines 202 and a gate coupled to control circuitry 206. While n-channel devices are shown in FIG. 2A, p-channel devices or more complex logic gates may be employed, depending on the desired logic and voltage polarities being implemented.</p>
    <p>In the illustrated embodiment, bitline BLA0 of subarray 200a can be coupled to bitline BLB0 of subarray 200b, bitline BLA0 to bitline BLB0, and so on. At the opposite end of the array, bitline BLAm can be coupled to bitline BLBm and bitline BLam to bitline BLBm. Preferably, bitlines 202 are controlled in pairs, such that when bitline BLA0 is coupled to bitline BLB0, bitline BLA0 is simultaneously coupled to bitline BLB0. Therefore, as illustrated in FIG. 2A, the gates of the corresponding gates 203 for each pair are coupled in common to column control circuitry 206 via the same control line 207. Column control circuitry 206 couples bitlines in subarray 200a with the corresponding bitlines in subarray 200b in response to control signals Colsel0-Colselx received through input/output and control circuitry 208.</p>
    <p>Circuitry 208 also includes conventional data and address buffers and latches, clock generation circuitry, and page mode column address incrementation circuitry. Preferably, circuitry 208 latches in row addresses and column addresses address-serial from a multiplexed address bus in response to a row address strobe (RAS) and a column address strobe (CAS). In synchronous DRAM designs, a master clock dictates the basic DRAM operation.</p>
    <p>The number of column control signals Colselx, as well as the number of control lines 207 between column control circuitry 206 and gates 203, required will depend on the control resolution required and the size of the cell array. For example, if subarrays 200a and 200b each have 512 pairs of columns of cells (a total of 1024 bitlines 202) and the ability to couple corresponding pairs of bitlines (i.e BLAx/BLAx to BLBx/BLBx) on an individual basis is desired, 512 control lines 207 are needed between each pair of gates 203 and control circuitry 206 and the number of control signals Colselx will be 10 (2<sup>10</sup> =1,024).</p>
    <p>In the preferred embodiment, multiple pairs of bitlines BLAx/BLAx can be simultaneously coupled as a block to corresponding bitline pairs BLBx/BLBx. This reduces the number of external control signals Colselx and reduces the number of control lines 207 on-chip. For example, assume that data is to be exchanged between subarrays in 64-bit blocks (64 bitline pairs or 128 bitlines) and that each subarray 200 includes 512 column pairs. In this case, only eight control lines 207 are required, each coupled to a corresponding 128 gates 203. The number of external control signals Colselx needed to select one of eight 64-bit block of columns correspondingly will be 3.</p>
    <p>During conventional accesses (reads, writes, read-modify-writes, refreshes) all gates 203 are turned off. Row and column addresses are input word (address)--serial from an external source with RAS and CAS (memory 20 may also be a synchronous DRAM operating to a master clock). In one embodiment of memory 20, row decoders 204 operate in response to separate sets of row addresses and column decoders 205 operate in response to separate sets of column addresses. In this embodiment, address pins Add0-AddQ and data pins DQ0-DQR can be organized in either of two ways. First, separate subsets of address pins Add0-AddQ and separate subsets of data pins DQ0-DQR can be dedicated to the row decoder 204 and column decoder 205 associated with each subarray 200. Preferably, two sets of address and data latches would be provided in input/output circuitry 208, one per each subset of address and data pins. In this configuration, both arrays can be addressed and accessed simultaneously and independently through the corresponding address and data pin subsets, although address and data pin count would increase. Second, the address pins Add0-AddQ and data pins DQ0-DQR may be shared between subarrays 200a and 200b. Preferably, two sets of address and data latches would also be employed. In this case the address/data pin count is reduced, and accesses to the subarrays are "interleaved." During a given RAS cycle, row and column addresses to a first subarray 200 are latched-in circuitry 208 with RAS and CAS through address pins Add0-AddQ and the desired access made through data pins DQ0-DQR. Subsequently, an access to a second subarray 200 would be made by latching in the appropriate row and column addresses with RAS and CAS through address pins Add0-AddQ and the access made through data pins DQ0-DQR.</p>
    <p>In a second embodiment, row decoders 204a and 204b lie in the same address space and respond to the same set of addresses received from an external source (e.g. core logic 103) In this case, a bank select signal is used to select to which subarray 200a or 200b the desired access is to be made. Preferably, the column decoders 205a and 205b also lie within the same column address space and thus respond to the same set of column addresses, although this is not a requirement of the present invention.</p>
    <p>According to the principles of the present invention block transfers can optionally be performed in memory 20 as follows. Assume for discussion purposes that exchanges from one subarray 200 to another are made by 64-bit blocks. Also assume that the shared (multiplexed) address and data pins embodiment discussed above is used and that row decoders 204 are in separate address spaces, also as discussed above.</p>
    <p>A first row and a first column address to a source block in the source subarray 200, assume for discussion the first 64 even bitlines BLA0-BLA64 of Row 0 of subarray 2000a, are received and latched by input/output circuitry 208 with RAS and CAS in a conventional fashion. Additionally, when RAS goes low, memory 20 transitions from the precharge to active cycle. All the cells of Row 0 are turned on and the data stored therein sensed latched by sense amplifiers 221.</p>
    <p>In the present example, column decoder 205a responds to the first column address to source subarray 200a and selects the first 64 bitlines 202. The data on these 64 bitlines held by the corresponding sense amplifiers is passed by the column decoder and latched into the latches within column decoder/sense amplifiers 205a. RAS then returns to the precharge (logic high) state.</p>
    <p>Next, a new RAS cycle is initiated and a second Row address is latched-in with the falling edge of RAS and a second column address latched-in with the falling edge of CAS. In the present example these addresses are to a location in destination subarray 200b. It should be noted that in the illustrated embodiment, the columns addressed in the source subarray correspond in row position to the columns addressed in the destination subarray such that data can be appropriately transferred therebetween when gates 203 are turned-on. For example, if the first 64 columns in the source subarray 200a are addressed in the first RAS then the first 64 columns in destination subarray 200b are addressed in the second RAS cycle.</p>
    <p>Control signals Colselx are then received to couple together corresponding pairs of bitlines in subarrays 200a and 200b through gates 203. In this example, the selected gates 203 allow the 64 bits of latched data read from the addressed block in source subarray 200a during the first RAS cycle to be coupled through the corresponding bitlines 202 to the addressed block in destination subarray 200b during the second RAS cycle. The data is passed through in response to the destination column address to the latches in decoder/sense amplifier circuitry 200b. The wordline 201 of the addressed destination row is then activated. The voltages representing the latched data become impressed in the cells along the destination row for the selected columns to complete the block copy/move.</p>
    <p>A second method of performing block transfers is possible in those embodiments where dedicated subsets of address pins are provided for each row decoder 204/subarray 200. In this case, row addresses to both subarrays 200a and 200b are simultaneously presented to address pins ADD0-ADDQ and latched-in with RAS. Subsequently, column addresses to both subarrays 200a and 200b are simultaneously received at address pins ADD0-ADDQ and latched-in with CAS.</p>
    <p>Assuming again that subarray 200a is the source subarray and subarray 200b is the destination subarray, the block of data to be transferred is read from the addressed cells and latched in the latches of decoder/sense amplifier 205a, as discussed immediately above.</p>
    <p>The wordline 201 of the selected row (Row 0) in the source subarray 200a is deactivated (pulled low). The gates 203 coupling the addressed columns in the source subarray 200a and the addressed columns in the destination subarray 200b are turned-on. The data from the cells in subarray 200a are transferred to the bitlines of subarray 200b and latched by the latches in column decoder/sense amplifiers 205b. The wordline 201 of the destination row is then activated (pulled high) and the data in the latches impressed into the capacitors of destination cells.</p>
    <p>It should be noted that alternatively, the latching of data within the source and destination sense amplifiers/column decoder block 205 by latches may be foregone. In this case the sense amplifiers may maintain the voltage on the bitlines during wordline switching. Further, column decoding may be foregone and the gates 203 alone used to select bits for transfer.</p>
    <p>To insure smooth operation, the physical structure of subarrays 200 should be substantially identical. Among other things, the cell density, row/column pitch, bitline length (hence bitline capacitance) and number of cells per row and column should be substantially the same. Smooth operation is also insured in embodiments using the folded bitline arrangement described above. In particular, folded bitlines allow better differential sensing and noise imunity between the complementary bitlines of each bitline pair even when voltage drops occur when a bitline in one subarray is coupled to a bitline to the other subarray during a block transfer. For example, assume that all bitlines are precharged to Vss. If logic one is read from a source cell, the associated bitline in latched by the associated sense amplifier to approximately Vcc. When the corresponding gate 203 couples the sourcing bitline to the destination bitline the voltage on the two bitlines is reduced to Vcc/2, assuming the capacitance for both bitlines is the same. After differential sensing between the destination bitline and the complementary bitline of its pair, the sense amplifiers of the destination subarray 200 pulls the voltage on the destination bitline, still at the precharge voltage Vss, back to Vcc. The problem becomes much simpler when the source bitline is carrying a logic zero since the precharge value Vss on the destination bitline is essentially the same. Similarly, if the bitlines 201 are precharged to Vcc or an intermediate voltage such as Vcc/2, the differential sensing insures that the transferred data is not impacted.</p>
    <p>Memories embodying the principles of the present invention, such as memory 20, may advantageously be used in a number of systems applications. For example, memory 200 may be used as a display memory or frame buffer in a traditional architecture as shown in FIG. 1A. In this case, a block move of display data, such as when a display object is dragged across the screen with a mouse, can be implemented using the methods described above.</p>
    <p>In the unified memory system of FIG. 1B, memory 20 can be employed to construct at least part of the unified memory at the boundary between the system memory and the frame buffer. For example, one subarray 200 would constitute a portion of the system memory to which display data would be written during an update. The other subarray would constitute some or all of the frame buffer. Hence, during an update, instead of reading the data out of the system memory and then writing the data to the frame buffer, that data is simply transferred across the system memory/frame buffer memory boundary through gates 203.</p>
    <p>Memory 20, and in particular those embodiments discussed above which allow independent accessing to each subarray 200, is especially advantageous for use in systems employing multiple asynchronous displays. In this case, one subarray 200 services one display and the other subarray 200. FIG. 3 depicts a further embodiment, system 30, in which a pair of first-in-first-out memories (registers) 301 are provided for independently driving a pair of display devices. It should be noted that these FIFOs may also be used for queuing (pipelining) data during writes to the corresponding subarrays 200.</p>
    <p>In each application of memory 20, not only can data transfer speed be optimized, but also memory space usage. For example, assume that the same data is required by two different associated devices, such as two asynchronous displays, then the data need only be stored in a single subarray and "shared" through gates 203. The share data may be for example stored in selected rows of subarray 200a and moved or copied into rows in subarray 200b as needed. In this fashion, wasted memory space can be substantially reduced or even eliminated.</p>
    <p>Although the present invention and its advantages have been described in detail, it should be understood that various changes, substitutions and alterations can be made herein without departing from the spirit and scope of the invention as defined by the appended claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4893281">US4893281</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 25, 1986</td><td class="patent-data-table-td patent-date-value">Jan 9, 1990</td><td class="patent-data-table-td ">Texas Instruments Incorporated</td><td class="patent-data-table-td ">Semiconductor memory system with programmable address decoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4987559">US4987559</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 6, 1989</td><td class="patent-data-table-td patent-date-value">Jan 22, 1991</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Semiconductor memory device having a plurality of access ports</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5121360">US5121360</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 9, 1991</td><td class="patent-data-table-td patent-date-value">Jun 9, 1992</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Video random access memory serial port access</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5305284">US5305284</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 19, 1992</td><td class="patent-data-table-td patent-date-value">Apr 19, 1994</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Semiconductor memory device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5319603">US5319603</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 30, 1991</td><td class="patent-data-table-td patent-date-value">Jun 7, 1994</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Multiport semiconductor memory device having RAM blocks and SAM blocks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5377154">US5377154</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 28, 1993</td><td class="patent-data-table-td patent-date-value">Dec 27, 1994</td><td class="patent-data-table-td ">Oki Electric Industry Co., Ltd.</td><td class="patent-data-table-td ">Multiple serial-access memory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5390139">US5390139</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 28, 1993</td><td class="patent-data-table-td patent-date-value">Feb 14, 1995</td><td class="patent-data-table-td ">Texas Instruments Incorporated</td><td class="patent-data-table-td ">Devices, systems and methods for implementing a Kanerva memory</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5844856">US5844856</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 19, 1996</td><td class="patent-data-table-td patent-date-value">Dec 1, 1998</td><td class="patent-data-table-td ">Cirrus Logic, Inc.</td><td class="patent-data-table-td ">Dual port memories and systems and methods using the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6046958">US6046958</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 14, 1999</td><td class="patent-data-table-td patent-date-value">Apr 4, 2000</td><td class="patent-data-table-td ">Micron Technology, Inc.</td><td class="patent-data-table-td ">Latching wordline driver for multi-bank memory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6125432">US6125432</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 30, 1997</td><td class="patent-data-table-td patent-date-value">Sep 26, 2000</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Image process apparatus having a storage device with a plurality of banks storing pixel data, and capable of precharging one bank while writing to another bank</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6163496">US6163496</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 14, 1999</td><td class="patent-data-table-td patent-date-value">Dec 19, 2000</td><td class="patent-data-table-td ">Oki Electric Industry Co., Ltd.</td><td class="patent-data-table-td ">Semiconductor memory device having a common column decoder shared by plurality of banks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6445638">US6445638</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 19, 2000</td><td class="patent-data-table-td patent-date-value">Sep 3, 2002</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Folded-bitline dual-port DRAM architecture system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6510098">US6510098</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 28, 1997</td><td class="patent-data-table-td patent-date-value">Jan 21, 2003</td><td class="patent-data-table-td ">Cirrus Logic, Inc.</td><td class="patent-data-table-td ">Method and apparatus for transferring data in a dual port memory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6519174">US6519174</a></td><td class="patent-data-table-td patent-date-value">May 16, 2001</td><td class="patent-data-table-td patent-date-value">Feb 11, 2003</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Early write DRAM architecture with vertically folded bitlines</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6687146">US6687146</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 31, 2002</td><td class="patent-data-table-td patent-date-value">Feb 3, 2004</td><td class="patent-data-table-td ">Atmos Corporation</td><td class="patent-data-table-td ">Interleaved wordline architecture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6826069">US6826069</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 18, 2003</td><td class="patent-data-table-td patent-date-value">Nov 30, 2004</td><td class="patent-data-table-td ">Atmos Corporation</td><td class="patent-data-table-td ">Interleaved wordline architecture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7295485">US7295485</a></td><td class="patent-data-table-td patent-date-value">Jul 12, 2005</td><td class="patent-data-table-td patent-date-value">Nov 13, 2007</td><td class="patent-data-table-td ">Atmel Corporation</td><td class="patent-data-table-td ">Memory architecture with advanced main-bitline partitioning circuitry for enhanced erase/program/verify operations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7649575">US7649575</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 22, 2005</td><td class="patent-data-table-td patent-date-value">Jan 19, 2010</td><td class="patent-data-table-td ">Hitachi Displays, Ltd.</td><td class="patent-data-table-td ">Liquid crystal display device with improved response speed</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7656708">US7656708</a></td><td class="patent-data-table-td patent-date-value">Oct 12, 2007</td><td class="patent-data-table-td patent-date-value">Feb 2, 2010</td><td class="patent-data-table-td ">Atmel Corporation</td><td class="patent-data-table-td ">Memory architecture with advanced main-bitline partitioning circuitry for enhanced erase/program/verify operations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8015389">US8015389</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 19, 2007</td><td class="patent-data-table-td patent-date-value">Sep 6, 2011</td><td class="patent-data-table-td ">Fujitsu Semiconductor Limited</td><td class="patent-data-table-td ">Memory device, memory controller and memory system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8120613">US8120613</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 15, 2007</td><td class="patent-data-table-td patent-date-value">Feb 21, 2012</td><td class="patent-data-table-td ">Siemens Medical Solutions Usa, Inc.</td><td class="patent-data-table-td ">Method and apparatus for real-time digital image acquisition, storage, and retrieval</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc365/defs365.htm&usg=AFQjCNEzHaQGuetTtzY59oDtginiG6P-0A#C365S230030">365/230.03</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc365/defs365.htm&usg=AFQjCNEzHaQGuetTtzY59oDtginiG6P-0A#C365S221000">365/221</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc365/defs365.htm&usg=AFQjCNEzHaQGuetTtzY59oDtginiG6P-0A#C365S230040">365/230.04</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09G0003360000">G09G3/36</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G11C0007180000">G11C7/18</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G11C0011401000">G11C11/401</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09G0005000000">G09G5/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=XANEBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11C7/18">G11C7/18</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G11C7/18</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Mar 4, 2014</td><td class="patent-data-table-td ">IPR</td><td class="patent-data-table-td ">Aia trial proceeding filed before the patent and appeal board: inter partes review</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">TRIAL NO: IPR2014-00317</span></div><div class="nested-key-value"><span class="nested-key">Opponent name: </span><span class="nested-value">TOSHIBA CORPORATION</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20131231</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 3, 2013</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19990217</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CIRRUS LOGIC., INC., A DELAWARE CORPORATION, CALIF</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">MERGER;ASSIGNOR:CIRRUS LOGIC., INC., A CALIFORNIA CORPORATION;REEL/FRAME:030735/0574</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 18, 2012</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120914</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 7, 2010</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20101207</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">INTELLECTUAL VENTURES II LLC, DELAWARE</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">MERGER;ASSIGNOR:HUAI TECHNOLOGIES, LLC;REEL/FRAME:025446/0029</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 26, 2010</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:CIRRUS LOGIC, INC.;REEL/FRAME:025039/0292</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100824</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">HUAI TECHNOLOGIES, LLC, DELAWARE</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 11, 2009</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 26, 2005</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 26, 2005</td><td class="patent-data-table-td ">SULP</td><td class="patent-data-table-td ">Surcharge for late payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">7</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 15, 2001</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 26, 1995</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CIRRUS LOGIC, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOHAN RAO, G.R.;REEL/FRAME:007738/0175</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19951024</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4ff636b3d23669b7103f3b3a3a18b4cd.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1dlsOr9KTs-qfCNDrdahEYQik1fw\u0026id=XANEBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U2OSGrR1bihmtscgf3o5pPMeUVYCw\u0026id=XANEBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U0ryXBfWyEoBn5U0ixZ2SzNPQ74QA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Multiple_bank_memory_architecture_and_sy.pdf?id=XANEBAABERAJ\u0026output=pdf\u0026sig=ACfU3U1qxqdzSiWgmJrWXhgMJ1t65NpgYQ"},"sample_url":"http://www.google.com/patents/reader?id=XANEBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>