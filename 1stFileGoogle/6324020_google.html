<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6324020 - Method and apparatus for reduction of trapezoidal distortion and improvement ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method and apparatus for reduction of trapezoidal distortion and improvement of image sharpness in an optical image capturing system"><meta name="DC.contributor" content="Harry H. Teng" scheme="inventor"><meta name="DC.contributor" content="Sung-Chan Jo" scheme="inventor"><meta name="DC.contributor" content="Secugen Corporation" scheme="assignee"><meta name="DC.date" content="1999-8-4" scheme="dateSubmitted"><meta name="DC.description" content="An apparatus and method for acquiring an image of a patterned object such as a fingerprint including a light refracting device, a focusing lens, and a light source. The light refracting device can, for example, be a prism and includes an imaging surface, a light receiving surface and a viewing surface. Incident light from the light source is projected through the light receiving surface and reflected off a surface other than the imaging surface. This reflected light is then projected onto the imaging surface to create an image of the patterned object from substantially all scattered light through the viewing surface. The lens is placed adjacent to the viewing surface to focus the light on an image sensor. The apparatus is configured to reduce or substantially eliminate trapezoidal distortion and improve overall image sharpness in an image of an object created by the apparatus."><meta name="DC.date" content="2001-11-27" scheme="issued"><meta name="DC.relation" content="CA:1286032" scheme="references"><meta name="DC.relation" content="DE:19509751:A1" scheme="references"><meta name="DC.relation" content="EP:0308162:A2" scheme="references"><meta name="DC.relation" content="EP:0617919:A2" scheme="references"><meta name="DC.relation" content="EP:0847024:A2" scheme="references"><meta name="DC.relation" content="EP:0867828:A2" scheme="references"><meta name="DC.relation" content="EP:0867829:A2" scheme="references"><meta name="DC.relation" content="JP:H02133892" scheme="references"><meta name="DC.relation" content="JP:H02188888" scheme="references"><meta name="DC.relation" content="JP:H03246693" scheme="references"><meta name="DC.relation" content="JP:H03292578" scheme="references"><meta name="DC.relation" content="JP:H0395693" scheme="references"><meta name="DC.relation" content="JP:H05216981" scheme="references"><meta name="DC.relation" content="JP:H07131322" scheme="references"><meta name="DC.relation" content="JP:H11102432" scheme="references"><meta name="DC.relation" content="JP:S61145686" scheme="references"><meta name="DC.relation" content="JP:S61221883" scheme="references"><meta name="DC.relation" content="JP:S6274177" scheme="references"><meta name="DC.relation" content="KR:940007344" scheme="references"><meta name="DC.relation" content="US:3527535" scheme="references"><meta name="DC.relation" content="US:3864042" scheme="references"><meta name="DC.relation" content="US:3975711" scheme="references"><meta name="DC.relation" content="US:4120585" scheme="references"><meta name="DC.relation" content="US:4135147" scheme="references"><meta name="DC.relation" content="US:4210899" scheme="references"><meta name="DC.relation" content="US:4340300" scheme="references"><meta name="DC.relation" content="US:4414684" scheme="references"><meta name="DC.relation" content="US:4668995" scheme="references"><meta name="DC.relation" content="US:4681435" scheme="references"><meta name="DC.relation" content="US:4832485" scheme="references"><meta name="DC.relation" content="US:4872203" scheme="references"><meta name="DC.relation" content="US:4983415" scheme="references"><meta name="DC.relation" content="US:5051576" scheme="references"><meta name="DC.relation" content="US:5096290" scheme="references"><meta name="DC.relation" content="US:5177435" scheme="references"><meta name="DC.relation" content="US:5177802" scheme="references"><meta name="DC.relation" content="US:5189482" scheme="references"><meta name="DC.relation" content="US:5210588" scheme="references"><meta name="DC.relation" content="US:5222153" scheme="references"><meta name="DC.relation" content="US:5233404" scheme="references"><meta name="DC.relation" content="US:5416573" scheme="references"><meta name="DC.relation" content="US:5548394" scheme="references"><meta name="DC.relation" content="US:5623553" scheme="references"><meta name="DC.relation" content="US:5635723" scheme="references"><meta name="DC.relation" content="US:5680205" scheme="references"><meta name="DC.relation" content="US:5732148" scheme="references"><meta name="DC.relation" content="US:5737071" scheme="references"><meta name="DC.relation" content="US:5740276" scheme="references"><meta name="DC.relation" content="US:5796858" scheme="references"><meta name="DC.relation" content="US:5812252" scheme="references"><meta name="DC.relation" content="US:5822445" scheme="references"><meta name="DC.relation" content="US:5875025" scheme="references"><meta name="DC.relation" content="US:5963657" scheme="references"><meta name="DC.relation" content="US:6154285" scheme="references"><meta name="DC.relation" content="WO:1997014111:A1" scheme="references"><meta name="DC.relation" content="WO:1998011478:A2" scheme="references"><meta name="DC.relation" content="WO:1998011501:A2" scheme="references"><meta name="DC.relation" content="WO:1998011750:A2" scheme="references"><meta name="DC.relation" content="WO:1998035118:A1" scheme="references"><meta name="citation_reference" content="Seigo Igaki et al. (Jan. 1990). &quot;Holographic Fingerprint Sensor,&quot; Fujitsu Sci.Tech. J., JP, Fujitsu Limited. Kawasaki, 25(4): 287-296."><meta name="citation_patent_number" content="US:6324020"><meta name="citation_patent_application_number" content="US:09/368,442"><link rel="canonical" href="http://www.google.com/patents/US6324020"/><meta property="og:url" content="http://www.google.com/patents/US6324020"/><meta name="title" content="Patent US6324020 - Method and apparatus for reduction of trapezoidal distortion and improvement of image sharpness in an optical image capturing system"/><meta name="description" content="An apparatus and method for acquiring an image of a patterned object such as a fingerprint including a light refracting device, a focusing lens, and a light source. The light refracting device can, for example, be a prism and includes an imaging surface, a light receiving surface and a viewing surface. Incident light from the light source is projected through the light receiving surface and reflected off a surface other than the imaging surface. This reflected light is then projected onto the imaging surface to create an image of the patterned object from substantially all scattered light through the viewing surface. The lens is placed adjacent to the viewing surface to focus the light on an image sensor. The apparatus is configured to reduce or substantially eliminate trapezoidal distortion and improve overall image sharpness in an image of an object created by the apparatus."/><meta property="og:title" content="Patent US6324020 - Method and apparatus for reduction of trapezoidal distortion and improvement of image sharpness in an optical image capturing system"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("2Z3tU-KHBeWssASp6ID4Aw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("LUX"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("2Z3tU-KHBeWssASp6ID4Aw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("LUX"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6324020?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6324020"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6324020&amp;usg=AFQjCNEolrW_zzKQomMZ5evymY3uHBBtrA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6324020.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6324020.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6324020" style="display:none"><span itemprop="description">An apparatus and method for acquiring an image of a patterned object such as a fingerprint including a light refracting device, a focusing lens, and a light source. The light refracting device can, for example, be a prism and includes an imaging surface, a light receiving surface and a viewing surface....</span><span itemprop="url">http://www.google.com/patents/US6324020?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6324020 - Method and apparatus for reduction of trapezoidal distortion and improvement of image sharpness in an optical image capturing system</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6324020 - Method and apparatus for reduction of trapezoidal distortion and improvement of image sharpness in an optical image capturing system" title="Patent US6324020 - Method and apparatus for reduction of trapezoidal distortion and improvement of image sharpness in an optical image capturing system"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6324020 B1</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/368,442</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Nov 27, 2001</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Aug 4, 1999</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Aug 4, 1999</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2381300A1">CA2381300A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2381300C">CA2381300C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN1178154C">CN1178154C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN1369077A">CN1369077A</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE60023156D1">DE60023156D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE60023156T2">DE60023156T2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1210686A2">EP1210686A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1210686B1">EP1210686B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2001011549A2">WO2001011549A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2001011549A3">WO2001011549A3</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2001011549A9">WO2001011549A9</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09368442, </span><span class="patent-bibdata-value">368442, </span><span class="patent-bibdata-value">US 6324020 B1, </span><span class="patent-bibdata-value">US 6324020B1, </span><span class="patent-bibdata-value">US-B1-6324020, </span><span class="patent-bibdata-value">US6324020 B1, </span><span class="patent-bibdata-value">US6324020B1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Harry+H.+Teng%22">Harry H. Teng</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Sung-Chan+Jo%22">Sung-Chan Jo</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Secugen+Corporation%22">Secugen Corporation</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6324020.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6324020.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6324020.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (59),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (1),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (15),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (10),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (9)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6324020&usg=AFQjCNFp9JOfkw9vGeBqy4QLk1xS78_qNg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6324020&usg=AFQjCNGUH8TAvTMGPUbtvMf6tKTS5sqTfQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6324020B1%26KC%3DB1%26FT%3DD&usg=AFQjCNHgV5OM5yuOEZhAXtN6dx8makPMHw">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54857419" lang="EN" load-source="patent-office">Method and apparatus for reduction of trapezoidal distortion and improvement of image sharpness in an optical image capturing system</invention-title></span><br><span class="patent-number">US 6324020 B1</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA72647931" lang="EN" load-source="patent-office"> <div class="abstract">An apparatus and method for acquiring an image of a patterned object such as a fingerprint including a light refracting device, a focusing lens, and a light source. The light refracting device can, for example, be a prism and includes an imaging surface, a light receiving surface and a viewing surface. Incident light from the light source is projected through the light receiving surface and reflected off a surface other than the imaging surface. This reflected light is then projected onto the imaging surface to create an image of the patterned object from substantially all scattered light through the viewing surface. The lens is placed adjacent to the viewing surface to focus the light on an image sensor. The apparatus is configured to reduce or substantially eliminate trapezoidal distortion and improve overall image sharpness in an image of an object created by the apparatus.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(8)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6324020B1/US06324020-20011127-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6324020B1/US06324020-20011127-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6324020B1/US06324020-20011127-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6324020B1/US06324020-20011127-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6324020B1/US06324020-20011127-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6324020B1/US06324020-20011127-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6324020B1/US06324020-20011127-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6324020B1/US06324020-20011127-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6324020B1/US06324020-20011127-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6324020B1/US06324020-20011127-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6324020B1/US06324020-20011127-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6324020B1/US06324020-20011127-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6324020B1/US06324020-20011127-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6324020B1/US06324020-20011127-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6324020B1/US06324020-20011127-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6324020B1/US06324020-20011127-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(19)</span></span></div><div class="patent-text"><div mxw-id="PCLM28739060" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is: </claim-statement> <div class="claim"> <div num="1" id="US-6324020-B1-CLM-00001" class="claim">
      <div class="claim-text">1. A compact apparatus for forming a high contrast, low distortion image of a patterned object including:</div>
      <div class="claim-text">a light refractor for reflecting and refracting light, the light refractor including: </div>
      <div class="claim-text">an imaging surface against which a patterned object to be imaged is to be placed to form an apparent image of the patterned object in the light refractor; </div>
      <div class="claim-text">a viewing surface adjacent to the imaging surface and through which an image of the object to be imaged is projected, the viewing surface forming an angle γ with the imaging surface; and </div>
      <div class="claim-text">a further surface adjacent to the imaging surface </div>
      <div class="claim-text">at least one lens adjacent to the viewing surface and for receiving and focusing an image of a patterned object projected through the viewing surface, the lens having a lens plane which is perpendicular to an optical axis of the lens, the lens plane forming an angle δ with the viewing surface; </div>
      <div class="claim-text">wherein the angles γ and δ are formed to substantially equalize a path length of a first light ray traveling from one part of the apparent image of the patterned object to the lens plane with a path length of any other light ray substantially parallel to the first light ray and traveling from another part of the apparent image of the patterned object to the lens plane. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6324020-B1-CLM-00002" class="claim">
      <div class="claim-text">2. The apparatus of claim <b>1</b> wherein the angles γ and δ are related by the equation:</div>
      <div class="claim-text">
        <maths> <formula-text>0.7≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.3. </formula-text> </maths> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6324020-B1-CLM-00003" class="claim">
      <div class="claim-text">3. The apparatus of claim <b>1</b> wherein the angles γ and δ are related by the equation:</div>
      <div class="claim-text">
        <maths> <formula-text>0.85≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.15. </formula-text> </maths> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6324020-B1-CLM-00004" class="claim">
      <div class="claim-text">4. The apparatus of claim <b>1</b> wherein the angles γ and δ are related by the equation:</div>
      <div class="claim-text">
        <maths> <formula-text>0.925≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.075. </formula-text> </maths> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6324020-B1-CLM-00005" class="claim">
      <div class="claim-text">5. The apparatus of claim <b>1</b> wherein the part of the imaging surface against which an object to be imaged is to be placed is able to have at least one light ray scattered from each portion thereof such that the intersection of the at least one light ray and the viewing surface form a first angle, the first angle being interior to a triangular area formed by the viewing surface, the imaging surface and the at least one light ray, which is less than 90 degrees.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6324020-B1-CLM-00006" class="claim">
      <div class="claim-text">6. The apparatus of claim <b>1</b> further including at least one light source located adjacent to the light refractor and for emitting incident light which enters the light refractor to create an image of the patterned object at the viewing surface.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" id="US-6324020-B1-CLM-00007" class="claim">
      <div class="claim-text">7. The apparatus of claim <b>6</b> wherein:</div>
      <div class="claim-text">the light refractor includes: </div>
      <div class="claim-text">a first edge opposite the imaging surface and adjacent to the viewing surface; and </div>
      <div class="claim-text">the light source is a strip of light emitting diodes (LEDs) oriented towards and parallel with the viewing surface and adjacent to the first edge. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" id="US-6324020-B1-CLM-00008" class="claim">
      <div class="claim-text">8. The apparatus of claim <b>1</b> wherein:</div>
      <div class="claim-text">the at least one lens has a diameter; the object to be imaged has a length dimension; and </div>
      <div class="claim-text">the diameter of the at least one lens is smaller than the length dimension of the object to be imaged. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" id="US-6324020-B1-CLM-00009" class="claim">
      <div class="claim-text">9. The apparatus of claim <b>2</b> wherein the part of the imaging surface against which an object to be imaged is to be placed is able to have at least one light ray scattered from each portion thereof such that the intersection of the at least one light ray and the viewing surface form a first angle, the first being interior to a triangle area formed by the viewing surface, the imaging surface and the at least one light ray which is less than 90 degrees.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" id="US-6324020-B1-CLM-00010" class="claim">
      <div class="claim-text">10. The apparatus of claim <b>3</b> wherein the part of the imaging surface against which an object to be imaged is to be placed is able to have at least one light ray scattered from each portion thereof such that the intersection of the at least one light ray and the viewing surface form a first angle, the first being interior to a triangle area formed by the viewing surface, the imaging surface and the at least one light ray which is less than 90 degrees.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" id="US-6324020-B1-CLM-00011" class="claim">
      <div class="claim-text">11. The apparatus of claim <b>4</b> wherein the part of the imaging surface against which an object to be imaged is to be placed is able to have at least one light ray scattered from each portion thereof such that the intersection of the at least one light ray and the viewing surface form a first angle, the first angle being interior to a triangular area formed by the viewing surface, the imaging surface and the at least one light ray, which is less than 90 degrees.</div>
    </div>
    </div> <div class="claim"> <div num="12" id="US-6324020-B1-CLM-00012" class="claim">
      <div class="claim-text">12. A method of imaging a patterned object comprising:</div>
      <div class="claim-text">providing a light refractor having an imaging surface, a viewing surface and a further surface; </div>
      <div class="claim-text">forming an angle γ between a plane defined by the viewing surface and a plane defined by the imaging surface; </div>
      <div class="claim-text">placing the patterned object against the imaging surface of the light refractor; </div>
      <div class="claim-text">projecting incident light into the light refractor; </div>
      <div class="claim-text">scattering the incident light off the imaging surface and patterned object and through the viewing surface; </div>
      <div class="claim-text">providing a lens adjacent to the viewing surface; </div>
      <div class="claim-text">forming an angle δ between the plane defined by the viewing surface and a lens plane of the lens; </div>
      <div class="claim-text">fixing angles δ and angle γ to equalize a path length of a first light ray traveling from one part of an apparent image of the patterned object in the light refractor to the lens plane with a path length of any other light ray substantially parallel to the first light ray and traveling from another part of the apparent image of the patterned object to the lens plane. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" id="US-6324020-B1-CLM-00013" class="claim">
      <div class="claim-text">13. The method of claim <b>12</b> wherein the step of fixing angle δ and angle γ includes relating angle δ and angle γ according to the equation:</div>
      <div class="claim-text">
        <maths> <formula-text>0.7≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.3. </formula-text> </maths> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" id="US-6324020-B1-CLM-00014" class="claim">
      <div class="claim-text">14. The method of claim <b>13</b> wherein the step of fixing angle δ and angle γ includes relating angle δ and angle γ according to the equation:</div>
      <div class="claim-text">
        <maths> <formula-text>0.85≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.15. </formula-text> </maths> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" id="US-6324020-B1-CLM-00015" class="claim">
      <div class="claim-text">15. The method of claim <b>12</b> wherein the step of fixing angle δ and angle γ includes relating angle δ and angle γ according to the equation:</div>
      <div class="claim-text">
        <maths> <formula-text>0.925≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.075. </formula-text> </maths> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" id="US-6324020-B1-CLM-00016" class="claim">
      <div class="claim-text">16. The method of claim <b>12</b> wherein the step of placing the patterned object against the imaging surface includes placing the patterned object against portions of the imaging surface which are able to have at least one light ray scattered therefrom such that the intersection of the at least one light ray and the viewing surface form a first angle, the first angle being interior to a triangular area formed by the viewing surface, the imaging surface and the at least one light ray, which is less than 90 degrees.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" id="US-6324020-B1-CLM-00017" class="claim">
      <div class="claim-text">17. The method of claim <b>13</b> wherein the step of placing the patterned object against the imaging surface includes placing the patterned object against portions of the imaging surface which are able to have at least one light ray scattered therefrom such that the intersection of the at least one light ray and the viewing surface form a first angle, the first angle being interior to a triangular area formed by the viewing surface, the imaging surface and the at least one light ray, which is less than 90 degrees.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" id="US-6324020-B1-CLM-00018" class="claim">
      <div class="claim-text">18. The method of claim <b>14</b> wherein the step of placing the patterned object against the imaging surface includes placing the patterned object against portions of the imaging surface which are able to have at least one light ray scattered therefrom such that the intersection of the at least one light ray and the viewing surface form a first angle, the first angle being interior to a triangular area formed by the viewing surface, the imaging surface and the at least one light ray, which is less than 90 degrees.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" id="US-6324020-B1-CLM-00019" class="claim">
      <div class="claim-text">19. The method of claim <b>15</b> wherein the step of placing the patterned object against the imaging surface includes placing the patterned object against portions of the imaging surface which are able to have at least one light ray scattered therefrom such that the intersection of the at least one light ray and the viewing surface form a first angle, the first angle being interior to a triangular area formed by the viewing surface, the imaging surface and the at least one light ray, which is less than 90 degrees.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES54762709" lang="EN" load-source="patent-office" class="description">
    <heading>FIELD OF THE INVENTION</heading> <p>The present invention relates to an optical acquisition apparatus for use with an image capturing and recognition system. In particular, the present invention includes an optical acquisition apparatus for reducing or substantially eliminating trapezoidal distortion in images of patterned objects and allowing such images to be more sharply focused.</p>
    <heading>BACKGROUND</heading> <p>Patterned object recognition systems are becoming common in industrial and commercial settings and have a variety of uses. For example, such systems can be used in scanners for the scanning of text, drawings, and photographs. Recently, manufacturers have been attempting to reduce costs associated with pattern recognition systems to make them more viable for consumer use. One such consumer application for pattern recognition systems includes fingerprint acquisition and recognition. Such a system is useful, for example, to enhance computer security by reading a potential user's fingerprint to compare with the fingerprints of users authorized to use the computer or access certain files or functions of the computer. Such a system could, for example, take the place of a security system that uses a login name and password.</p>
    <p>The first thing such a fingerprint recognition system, or any pattern recognition system, must be able to do is to accurately acquire the fingerprint, or other pattern, for analysis. A number of mechanisms exist for such acquisition of pattern data. For example, U.S. Pat. Nos. 3,975,711; 4,681,435; 5,051,576; 5,177,435 and 5,233,404 all disclose apparatuses for acquiring an image of a patterned object.</p>
    <p>FIG. 1 shows a schematic diagram of one such prior art optical fingerprint capturing and recognition system. In FIG. 1, an optical recognition system <b>108</b> includes a light source <b>112</b>, an optical triangular prism <b>110</b>, a lens assembly <b>114</b>, an image sensor <b>116</b>, and a storage and processing unit <b>125</b>. The prism <b>110</b> includes an imaging surface <b>118</b>, a light receiving surface <b>120</b>, and a viewing surface <b>122</b>. Imaging surface <b>118</b> is the surface against which a patterned object, such as a fingerprint, is placed for imaging. The light source <b>112</b>, which may, for example, be a light emitting diode (LED), is placed adjacent to light receiving surface <b>120</b> and generates incident light <b>124</b> that is transmitted to the optical prism <b>110</b>. The optical prism <b>110</b> is an isosceles right triangle, with the angle opposite the imaging surface <b>118</b> being approximately 90 degrees and the other two “base” angles (that is, the two angles of an isosceles prism that are equal) each being approximately 45 degrees.</p>
    <p>Generally, incident light <b>124</b> strikes imaging surface <b>118</b> at an angle <b>126</b> with the incident surface normal line <b>115</b>. Angle <b>126</b> is greater than the critical angle <b>128</b>. In general, a critical angle is measured between an incident light ray and a normal line to a surface. If incident light strikes a surface at an angle greater than the critical angle, the incident light will undergo total internal reflection off the surface, if the incident light strikes the surface at an angle less than the critical angle, the incident light will substantially pass through the surface. Accordingly, critical angle <b>128</b> is the angle with the normal line to the imaging surface <b>118</b> above which incident light will totally internally reflect from imaging surface <b>118</b> and pass out of prism <b>110</b> as reflected light <b>130</b> through viewing surface <b>122</b>.</p>
    <p>Reflected light <b>130</b> passes through lens assembly <b>114</b> located adjacent to viewing surface <b>122</b>. Lens assembly <b>114</b> may contain one or more optical lenses. Thereafter, light from lens assembly <b>114</b> is captured by image sensor <b>116</b>. Image sensor <b>116</b>, which may, for example, be a charge coupled device (CCD) or a complementary metal oxide semiconductor (CMOS) device, captures optical light images and converts them to electrical signals. Such image sensors are well known to those skilled in the art. The electrical signals are then transmitted to the storage and processing unit <b>125</b>.</p>
    <p>Storage and processing unit <b>125</b> may include a memory unit, a processor and an analog to digital converter (not shown). The analog to digital converter converts the analog electrical signals from the image sensor <b>116</b> into digital data. The memory is used to store the digital data and algorithms for comparing a captured fingerprint image with a stored fingerprint image. The processor compares the captured digital data with data previously stored in memory based on an algorithm for comparing such data. The processor may also analyze the captured digital data for purposes different from comparison with stored data. Such storage and processing units are known to those skilled in the art and can include standard personal computers equipped with appropriate software. Algorithms for processing and comparison of image data are disclosed, for example, in U.S. Pat. Ser. Nos. 4,135,147 and 4,668,995 each of which is incorporated in its entirety by reference.</p>
    <p>When a fingerprint is placed on the optical prism's imaging surface <b>118</b>, ridges <b>111</b> of the fingerprint contact imaging surface <b>118</b>, and valleys <b>109</b> of the fingerprint remain out of contact with imaging surface <b>118</b>. Thus, in fingerprint valleys <b>109</b> incident light <b>124</b> entering optical prism <b>110</b> from light source <b>112</b> undergoes total internal reflection at imaging surface <b>118</b> if the incidence angle of the incoming light exceeds the critical angle of the optical prism <b>110</b>. However, at ridges <b>111</b> of a fingerprint some of incident light <b>124</b> is absorbed and scattered off the fingerprint ridge. As used herein, the term “scattered” indicates light which, after striking an irregular surface, is radiated or irregularly reflected off the irregular surface in multiple directions.</p>
    <p>As a result of this scattering and/or absorption, there is less than total internal reflection of incident light <b>124</b> at fingerprint ridges <b>111</b>. Thus, the intensity of reflected light <b>130</b> leaving prism <b>110</b> from the valleys <b>109</b> of a fingerprint is of greater intensity than reflected light <b>130</b> leaving prism <b>110</b> from ridges <b>111</b>. The lower intensity reflected light <b>130</b> from ridges <b>111</b> translate into darker regions to indicate the presence of an object at the point of incidence between the light beam and the fingerprinting surface. Conversely, higher intensity reflected light <b>130</b>, such as that which undergoes total internal reflection, translates into brighter regions to indicate the absence of an object at the point of incidence between the incident light <b>124</b> and the imaging surface <b>118</b>. This allows distinguishing the darker fingerprint ridges <b>111</b> from the relatively brighter fingerprint valleys <b>109</b>. Because absorption of incident light at fingerprint ridges <b>111</b> is primarily responsible for creating a fingerprint image, system <b>108</b> is referred to as an “absorption” imaging system.</p>
    <p>The above described system allows capturing an optical fingerprint image and processing the electrical representation of the optical fingerprint image. However, in regions of fingerprint ridges <b>111</b>, incident light <b>124</b> still undergoes some total internal reflection and some scattering in a direction parallel to reflected light <b>130</b>. Thus, the difference in intensity between reflected light <b>130</b> from fingerprint valleys <b>109</b> and fingerprint ridges <b>111</b> can be relatively low. That is, the contrast between fingerprint ridges <b>111</b> and valleys <b>109</b> in the fingerprint image can be relatively low. This can make image acquisition, processing, and comparison relatively difficult.</p>
    <p>Additionally, in optical recognition system such as optical recognition system <b>108</b> it can be desirable that the diameter of the first lens in lens assembly <b>114</b> be smaller than the image of a fingerprint on viewing surface <b>122</b>. This both allows optical recognition system <b>108</b> to be relatively small and can be less expensive to manufacture.</p>
    <p>However, as shown in FIG. 2, in an absorption type system such as system <b>108</b>, if the diameter of the first lens of lens assembly <b>114</b> is smaller than the fingerprint on imaging surface <b>118</b>, then the lens assembly <b>114</b> must generally be placed relatively far from viewing surface <b>122</b>. This allows the image of a fingerprint captured by system <b>108</b> to be relatively sharp all the way to the edges of the fingerprint image. That is, if lens assembly <b>114</b> is placed too close to viewing surface <b>122</b>, the edges of a fingerprint image could be lost or distorted near the edges of the image. This is because in an absorption system such as system <b>108</b>, the light rays which generate the image of the fingerprint must be substantially parallel for the image to be in focus. And, if the first lens in lens assembly <b>114</b> is smaller than the fingerprint in imaging surface <b>118</b>, then the light rays from the edges of the fingerprint image that are parallel to light rays from areas closer to the center of a fingerprint image may not be able to enter lens assembly <b>114</b>. This can cause the edges of a fingerprint image to be out of focus or lost.</p>
    <p>Thus, as shown in FIG. 2, if the lens assembly for optical recognition system <b>108</b> were placed where lens assembly <b>114</b>′ is shown (in phantom), then substantially parallel rays of reflected light <b>130</b> and <b>130</b>′ would not enter lens assembly <b>114</b>′. For this reason, system <b>108</b> would not produce a sharp image of a fingerprint placed on imaging surface <b>118</b> at points A and B if the lens assembly were placed at the location of lens assembly <b>114</b>′.</p>
    <p>Thus, as shown in FIG. 2, in an absorption system, the reduction in size gained by manufacturing a relatively small first lens of lens assembly <b>114</b> can be lost because lens assembly <b>114</b> must be placed at a relatively large distance from viewing surface <b>122</b> in order to capture the entire fingerprint image using light rays that are substantially parallel. For this reason, making optical recognition system <b>108</b> relatively compact can be problematic. Additionally, a relatively large distance between viewing surface <b>122</b> and lens assembly <b>114</b> can cause loss of contrast in the fingerprint image due to light interference.</p>
    <p>Further, when the first lens in lens assembly <b>114</b> is smaller than an image of a fingerprint at viewing surface <b>122</b>, a phenomenon known as trapezoidal distortion can occur in optical recognition system <b>108</b>. Trapezoidal distortion in an imaging system has the effect of making the image of a square created by the system appear as a trapezoid.</p>
    <p>FIG. 2 is a schematic illustration showing why trapezoidal distortion arises in optical recognition system <b>108</b>. Incident light <b>124</b> from light source <b>112</b> enters prism <b>110</b> and reflects off imaging surface <b>118</b>, imaging object AB. Reflected light <b>130</b> then passes out of viewing surface <b>122</b> and to lens assembly <b>114</b> at points A′ and B′ to form object A′B′. Viewing object AB through viewing surface <b>122</b>, object AB would appear to be located at an “apparent image” object ab. Specifically, point A appears to be at point a, a distance aa′ from viewing surface <b>122</b> and point B appears to be at point b, a distance bb′ from viewing surface <b>122</b>. The distance that an apparent image of an object appears from viewing surface <b>122</b> is given by the actual distance the object is from viewing surface <b>122</b> divided by the index of refraction n of prism <b>110</b>. Specifically, the distance aa′ is given by:</p>
    <p>aa′=Aa′/n,</p>
    <p>where n is the index of refraction of prism <b>110</b>. Similarly,</p>
    <p>bb′=Bb′/n.</p>
    <p>Trapezoidal distortion occurs when the light path length from the apparent image of an object to the lens plane <b>107</b> of lens assembly <b>114</b> is different for different parts of the imaged object and the object lens of the lens assembly <b>114</b> is smaller than the image of the fingerprint through viewing surface <b>122</b>. Specifically, trapezoidal distortion occurs in system <b>108</b> because the distance aA′ is longer than the distance bB′ and lens assembly <b>114</b> has a smaller diameter than the distance a′b′ on viewing surface <b>122</b>.</p>
    <p>Another consequence of distance aA′ being larger than distance bB′ is that an image of an object which is sharply focused at each part of the image can be difficult to obtain. More generally, whenever the light path length from the apparent image of an object to the lens plane, and ultimately image sensor, of a lens assembly is different for different parts of the imaged object, parts of the image of the object at the lens plane may be in relatively sharp focus and parts of the image may be out of focus.</p>
    <p>To correct both the problems of trapezoidal distortion and having a portion of an image of an object which is out of focus, prior art manufacturers have tilted the lens plane <b>107</b> of lens assembly <b>114</b> and image sensor <b>116</b> to increase the distance bB′ and decrease the distance aA′ to a point where the two distances are approximately equal. However, it is a property of an isosceles right prism (that is, a triangular prism in which the base angles measure approximately 45 degrees and the non-base angle, or apex angle, measures approximately 90 degrees), that reflected light <b>130</b> exits prism <b>110</b> substantially normal to viewing surface <b>122</b>. That is, no refraction of reflected light <b>130</b> occurs as it exits viewing surface <b>122</b>. Further, generally, the larger the angle of incidence on a surface of a transparent object, the greater the portion of incident light that is reflected from the surface. Thus, while tilting lens assembly <b>114</b> and the sensor can reduce trapezoidal distortion and increase image sharpness, it also causes greater reflection of reflected light <b>130</b> off the surface of lens assembly <b>114</b>, and the surface of image sensor <b>116</b>, because reflected light <b>130</b> strikes lens assembly <b>114</b> at a greater angle of incidence. This reduces the intensity of light entering image sensor <b>116</b>, making image processing and comparison more difficult.</p>
    <p>Additionally, the relative placement of light source <b>112</b> and lens assembly <b>114</b> make it possible for stray light <b>113</b> emitted by light source <b>112</b> to enter lens assembly <b>114</b>. This can generate additional background “noise” light which can further reduce the quality of a captured image and make image processing more difficult.</p>
    <p>To overcome some of the difficulties associated with the type of absorption image acquisition system described above, acquisition systems have been designed which are based primarily on “scattering” mechanisms rather than absorption mechanisms. One such acquisition system is disclosed by U.S. Pat. No. 5,233,404 issued to J. Lougheed et al. on Aug. 3, 1993 (Lougheed et al.). FIG. 3 is a schematic diagram illustrating the image acquisition portion of the apparatus disclosed by Lougheed et al. As shown in FIG. 3, a prior art image acquisition system <b>208</b> includes a trapezoidal prism <b>210</b>, a light source <b>212</b>, a lens assembly <b>214</b> and an image sensor <b>216</b>. The trapezoidal prism <b>210</b> includes at least an imaging surface <b>218</b>, a light receiving surface <b>220</b>, and a viewing surface <b>222</b>.</p>
    <p>The imaging surface <b>218</b> is the surface against which an object to be imaged, such as a fingerprint, is placed. The light source <b>212</b> is located adjacent to and facing the light receiving surface <b>220</b> which is substantially parallel to imaging surface <b>218</b>. Thus, incident light <b>224</b> emitted by light source <b>212</b> projects light through prism <b>210</b> and onto imaging surface <b>218</b> at an angle which is generally less than the critical angle <b>228</b> of prism <b>210</b>. Therefore, in the valleys <b>209</b> of a fingerprint placed against imaging surface <b>218</b> where the fingerprint is not in contact with imaging surface, total internal reflection does not occur and incident light <b>224</b> passes through imaging surface <b>218</b>. At points where fingerprint ridges <b>211</b> are in contact with imaging surface <b>218</b>, incident light <b>224</b> strikes the fingerprint ridge to generate scattered (or equivalently, irregularly reflected) light <b>230</b>. Scattered light <b>230</b> propagates back into prism <b>210</b> in substantially all directions including the direction of lens assembly <b>214</b>, located adjacent to viewing surface <b>222</b>. Scattered light passes through viewing surface <b>222</b> and into lens assembly <b>214</b> to be detected by image sensor <b>216</b>, which, as above, can be a CCD, CMOS or other type of detector.</p>
    <p>In the region of a fingerprint valley <b>209</b>, incident light <b>224</b> passes through imaging surface <b>218</b>. And, in the area of a fingerprint ridge <b>211</b>, incident light <b>224</b> scatters off imaging surface <b>218</b> to be picked up by lens assembly <b>214</b> and image sensor <b>216</b>. Accordingly, the image of the fingerprint is relatively bright at fingerprint ridges <b>211</b> and relatively dark at fingerprint valleys <b>209</b>. Because scattered light <b>230</b> is picked up by the image sensor <b>216</b>, this type of system is referred to as a “scattering” system.</p>
    <p>The difference in intensity, or ratio of intensity, between the ridges and valleys in a fingerprint image created by such a scattering system can be greater than the difference in intensity, or ratio of intensity, between the ridges and valleys of a fingerprint image created in an absorption system as shown in FIG. <b>1</b>. As a result, the fingerprint image created by such a scattering system can display higher contrast between fingerprint ridges and valleys than an image created by an absorption system. Thus, the image can be more accurately acquired by the image sensor <b>216</b>. This can reduce errors in subsequent fingerprint comparisons performed by the system.</p>
    <p>Additionally, it is a property of a scattering system that the rays of light which enter lens assembly <b>214</b> to produce an image of a fingerprint in a scattering system do not need to be parallel to produce a sharp image. Thus, if the first lens in lens assembly <b>214</b> is smaller than the image of the fingerprint in viewing surface <b>222</b>, lens assembly <b>214</b> can still be placed relatively close to viewing surface <b>222</b> without loss of image sharpness near the edges of the image.</p>
    <p>However, a trapezoidal prism such as prism <b>210</b> can be more expensive to manufacture than a triangular prism such as prism <b>110</b>, shown in FIG. <b>1</b>. This is because, among other reasons, there is an extra surface to polish. This can increase the price of an imaging system such as imaging system <b>208</b>, making it less viable for consumer use.</p>
    <p>Additionally, because of differences in scattered light path lengths from different portions of the apparent image of the fingerprint in prism <b>210</b> to lens assembly <b>214</b>, image acquisition system <b>208</b> can cause portions of a fingerprint image to be out of focus in a manner similar to that of optical recognition system <b>108</b>. Additionally, though not shown in FIG. 3, if the first lens in lens assembly <b>214</b> of image acquisition system <b>208</b> is smaller than a fingerprint image on viewing surface <b>222</b> the differences in scattered light path lengths from different portions of the apparent image of the fingerprint in prism <b>210</b> to lens assembly <b>214</b> and image sensor <b>216</b> can also cause trapezoidal distortion.</p>
    <p>As the above discussion makes clear, there is a need for improved image acquisition apparatus for use with patterned object recognition systems. Specifically, an image acquisition apparatus which produces an image having reduced or substantially eliminated trapezoidal distortion would be desirable. Additionally, an image acquisition system which generates an image in which substantially the entire image is in focus is also desirable. The image acquisition system should also be relatively compact and inexpensive to manufacture.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention includes a compact image acquisition apparatus which produces a high contrast, low distortion image which has reduced or substantially no trapezoidal distortion. Additionally, the image acquisition system of the present invention can be relatively low cost to manufacture. The apparatus includes a light refractor having an imaging surface against which a patterned object is to be placed to form an apparent image of the patterned object in the light refractor, a further surface, and a viewing surface. The viewing surface is adjacent to the imaging surface and forms an angle y therewith. An image of the patterned object is projected through the viewing surface. The apparatus also includes a lens adjacent to the viewing surface for receiving and focusing an image of a patterned object. The lens has a lens plane which is perpendicular to an optical axis of the lens and which forms an angle δ with the viewing surface. The angles γ and δ are formed to substantially equalize a path length of a first light ray traveling from one part of the apparent image of the patterned object to the lens plane, and ultimately, to the image sensor, with a path length of any other light ray substantially parallel to the first light ray and traveling from another part of the apparent image of the patterned object to the lens plane, and ultimately, the image sensor. Preferably, this is achieved by fixing angles γ and δ to conform to the equation:</p>
    <p>
      <maths> <formula-text>0.7≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.30.</formula-text> </maths> </p>
    <p>In another aspect of the present invention, preferably, every point of the portion of the imaging surface against which an object to be imaged is to be placed is able to have at least one light ray scattered therefrom such that the intersection of the light ray and the viewing surface form an angle, adjacent to the intersection of the viewing surface and the imaging surface, which is less than 90 degrees.</p>
    <p>In yet another aspect of the present invention, a method of generating an image of a patterned object includes providing a light refractor having an imaging surface, a viewing surface, and a further surface. An angle γ is formed between a plane defined by the viewing surface and a plane defined by the imaging surface. A patterned object is placed against the imaging surface and incident light is projected into the light refractor. The incident light is scattered off the imaging surface and patterned object and through the viewing surface. A lens is provided adjacent to the viewing surface and an angle δ is formed between the focal plane of the lens and the plane defined by the viewing surface. The angles γ and δ are fixed to substantially equalize a path length of a first light ray traveling from one part of an apparent image of the patterned object formed in the light refractor to the lens plane, and ultimately the image sensor, with a path length of any other light ray substantially parallel to the first light ray and traveling from another part of the apparent image of the patterned object to the lens plane and image sensor. Preferably, the angles γ and δ are fixed so that they are related by the equation:</p>
    <p>
      <maths> <formula-text>0.7≦(n<sup>2</sup>sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.30</formula-text> </maths> </p>
    <p>Additionally, it is preferable that the portions of the imaging surface to be used for imaging are each able to have at least one light ray scattered therefrom such that the intersection of the light ray and the viewing surface form a first angle, adjacent to the intersection of the viewing surface and the imaging surface, which is less than 90 degrees.</p>
    <p>The apparatus and method discussed above allow forming an image of a patterned object which has reduced, or is substantially free of, trapezoidal distortion and which can generate an image the entirety of which is in relatively sharp focus. This advantageously facilitates more accurate processing and comparison of patterned object images.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is a schematic of a prior art image acquisition apparatus which utilizes an absorption image acquisition technique.</p>
    <p>FIG. 2 is a schematic of the image acquisition apparatus of FIG. 1 illustrating trapezoidal distortion.</p>
    <p>FIG. 3 is a schematic of a second prior art image acquisition apparatus which utilizes a scattering image acquisition technique.</p>
    <p>FIG. 4 is a schematic diagram of an image acquisition system including a prism, light source, lens assembly, and image sensor, in accordance with the present invention.</p>
    <p>FIG. 5 is a perspective view of the prism and light source shown in FIG. <b>4</b>.</p>
    <p>FIG. 6 is a schematic diagram of the image acquisition system shown in FIG. 4 illustrating how trapezoidal distortion is reduced.</p>
    <p>FIG. 7 is a schematic diagram showing a lens assembly which can be used with the image acquisition system shown in FIG. <b>4</b>.</p>
    <p>FIG. 8 is a schematic diagram of the image acquisition system shown in FIG. 4 illustrating preferred prism and lens assembly configuration.</p>
    <p>FIG. 9 is a schematic diagram showing an alternate embodiment of a prism which can be used with the image acquisition system of the present invention illustrating a scattered light ray path.</p>
    <p>FIG. 10 is a schematic diagram of the prism shown in FIG. 9 illustrating an alternate scattered light ray path.</p>
    <heading>DETAILED DESCRIPTION</heading> <p>FIGS. 4 and 5 show a patterned object image acquisition system <b>308</b> in accordance with the present invention. Acquisition system <b>308</b> preferably includes a triangular prism <b>310</b>, a light source <b>312</b>, a lens assembly <b>314</b>, and an image sensor <b>316</b>. Prism <b>310</b> is a five faced triangular prism the length of which extends into the plane of FIG. <b>4</b>. Prism <b>310</b> includes a rectangular, planar, imaging surface <b>318</b> against which an object to be imaged, such as a fingerprint <b>335</b>, is placed. Prism <b>310</b> also includes a rectangular, planar, viewing surface <b>320</b> through which an image of a fingerprint <b>335</b> placed against imaging surface <b>318</b> passes out of prism <b>310</b>. In the embodiment of FIGS. 4 and 5, viewing surface <b>320</b> also serves as a light receiving surface for allowing light to pass into prism <b>310</b>. A light scattering surface <b>322</b> comprises a third, or further, rectangular, planar, surface of prism <b>310</b>. For reasons detailed below, light scattering surface <b>322</b> is preferably a diffusive.</p>
    <p>Light source <b>312</b> is preferably an elongated LED array consisting of a single row of light emitting diodes (LEDs) extending the length (into the plane of FIG. 4) of prism <b>310</b>. If such LEDs are used as light source <b>312</b>, a diffusive cover can be placed between the LEDs and viewing surface <b>320</b> to provide more even illumination of imaging surface <b>318</b>. It is also within the ambit of the present invention, however, for light source <b>312</b> to be any other type of light source to provide incident light into prism <b>310</b>. Preferably, light source <b>312</b> is placed along an edge <b>338</b> of prism <b>310</b> which is opposite imaging surface <b>318</b>. However, it is also within the ambit of the present invention to configure and locate a light source for acquisition system <b>308</b> in any other way. For example, other configurations for light sources which can be used with the present invention are disclosed in commonly assigned, co-pending U.S. patent application Ser. No. 09/191,428 for “High Contrast, Low Distortion Optical Acquisition System for Image Capturing” filed Nov. 12, 1998, still pending, which is hereby incorporated by reference in its entirety. This includes placing light source <b>312</b> against viewing surface <b>320</b> anywhere between edge <b>338</b> and the line <b>360</b> along viewing surface <b>320</b> formed by the intersection of viewing surface <b>320</b> and a perpendicular line to viewing surface <b>320</b> which intersects edge <b>365</b>.</p>
    <p>Lens assembly <b>314</b> is for receiving scattered light <b>330</b> from fingerprint <b>335</b> and focusing scattered light <b>330</b> onto image sensor <b>316</b>. Lens assembly <b>314</b> can be a single lens or, preferably, can consist of multiple lenses. Most preferably, lens assembly <b>314</b> has a focal length of approximately 13.48 mm and is located approximately 13.5 mm from viewing surface <b>320</b>. Additionally, as shown in FIG. 7 which is a schematic diagram of one embodiment of lens assembly <b>314</b>, lens assembly most preferably consists of three lenses <b>904</b>, <b>906</b>, and <b>908</b> whose respective optical axes are aligned on a common optical axis <b>902</b>. Lens <b>904</b> most preferably has a diameter of approximately 17.8 mm, and both lenses <b>906</b> and <b>908</b> most preferably have a diameter of approximately 6 mm. It is considered that any number of lenses be included in lens assembly <b>314</b>.</p>
    <p>Image sensor <b>316</b> captures optical light images from lens assembly <b>314</b> and converts them to electrical signals. Image sensor <b>316</b> can be a charge couple device (“CCD”) or any other means of converting a light signal into either an analog or digital electrical signal. Preferably, image sensor <b>316</b> is a complementary metal oxide semiconductor device. CCD and CMOS image sensors are well known by those skilled in the art. The electrical signals generated by image sensor <b>316</b> can be processed using known means and used to compare input patterns, such as fingerprints. As noted in the Background section, such signal processing means are disclosed, for example, in U.S. Pat. Nos. 4,135,147 and 4,668,995, which have been incorporated by reference.</p>
    <p>To create an optical image of fingerprint <b>335</b> on image sensor <b>316</b>, fingerprint <b>335</b> is placed against imaging surface <b>318</b>. Incident light <b>324</b> from light source <b>312</b> passes through viewing surface <b>320</b> and into prism <b>310</b>. Because light source <b>312</b> is located adjacent to edge <b>338</b>, incident light <b>324</b> strikes scattering surface <b>322</b>. As noted above, scattering surface <b>322</b> is preferably diffusive. As such, a relatively high portion of incident light <b>334</b> striking scattering surface <b>322</b> is internally scattered in prism <b>310</b>. This scattered light then strikes imaging surface <b>318</b>. Even if light scattering surface <b>322</b> is not diffusive, substantially all of incident light <b>324</b> will strike scattering surface <b>322</b> at an angle <b>323</b> which is greater than the critical angle for scattering surface <b>322</b>. Thus, incident light will reflect off scattering surface <b>322</b> and strike imaging surface <b>318</b>. To enhance reflection of incident light off scattering surface <b>322</b> it is contemplated to place a mirrored face of a reflecting surface <b>381</b> towards scattering surface <b>322</b>.</p>
    <p>Because incident light <b>324</b> has been scattered or directly reflected off scattering surface <b>322</b>, a relatively large percentage of incident light <b>324</b> will strike imaging surface <b>318</b> at an angle <b>327</b> less than the critical angle <b>328</b> of prism <b>310</b>. Accordingly, incident light <b>324</b> which strikes imaging surface <b>318</b> at a region thereof where there is a fingerprint valley <b>309</b> will not undergo total internal reflection and will substantially pass through imaging surface <b>318</b>. Thus, substantially no light hitting an area of imaging surface <b>318</b> where there is a fingerprint valley <b>309</b> will be directed into the sensor <b>316</b>. However, incident light <b>324</b> that strikes a region of imaging surface <b>318</b> where there is a fingerprint ridge <b>311</b> touching imaging surface <b>318</b> will substantially scatter, producing scattered light <b>330</b>. A portion of scattered light <b>330</b> will exit prism <b>310</b> via viewing surface <b>320</b>. Upon exiting prism <b>310</b>, scattered light <b>330</b> will refract into lens assembly <b>314</b> which will focus scattered light <b>330</b> into image sensor <b>316</b>.</p>
    <p>Because incident light <b>324</b> can be scattered by scattering surface <b>322</b>, incident light <b>324</b> provides relatively uniform illumination over imaging surface <b>318</b> which produces a relatively uniform image. Such a uniform image is desirable because it is easier to process and compare with other stored fingerprint data. To further increase the uniformity of illumination over imaging surface <b>318</b>, the portion of viewing surface <b>320</b> facing light source <b>312</b> can be streaked by etching lines <b>370</b>, shown in FIG. 5, on viewing surface <b>320</b>. Lines <b>370</b> run the length of prism <b>310</b> and parallel to apex <b>338</b>. Lines <b>370</b> act to diffuse light emitted from light source <b>312</b> as it passes through viewing surface <b>320</b>.</p>
    <p>In addition to the components discussed above, image acquisition system <b>308</b> preferably also includes a light blocking shield <b>350</b> on a portion of light receiving surface adjacent to light source <b>312</b>. Preferably, light blocking shield runs the entire length of prism <b>310</b> (into the plane of FIG. <b>4</b>). Light blocking shield <b>350</b> is to reduce the amount of stray light from light source <b>312</b> which might enter lens assembly <b>314</b> and interfere with or cloud a fingerprint image. It is also considered that the surface of light blocking shield <b>350</b> facing the interior of prism <b>310</b> be mirrored. This mirroring can act to desirably increase the intensity of scattered light incident on imaging surface <b>318</b>. In addition to, or instead of, light blocking surface <b>350</b>, a second light blocking surface <b>352</b> can be placed between light source <b>312</b> and lens assembly <b>314</b>. Light shield <b>352</b> preferably extends from viewing surface <b>320</b> at an angle to block stray light from light source <b>312</b> from entering lens assembly <b>314</b>.</p>
    <p>Because light source <b>312</b> is relatively narrow and located adjacent to edge <b>338</b> opposite imaging surface <b>318</b>, substantially all incident light <b>324</b> reaching imaging surface <b>318</b> is reflected or scattered into the lens assembly <b>314</b>. That is, almost no incident light <b>324</b> can be captured by the image sensor <b>316</b> without scattering off the imaging surface <b>318</b> at the points of contact with fingerprint ridges <b>311</b>. To further reduce the likelihood of incident light <b>324</b> which falls into the fingerprint valleys <b>309</b> reaching image sensor <b>316</b> through lens assembly <b>314</b>, light source <b>312</b> is preferably configured not to extend past a line <b>360</b>, shown in FIG. 5, extending the length of prism <b>310</b> and defined by the intersection of a plane normal to viewing surface <b>320</b> and intersecting with edge <b>365</b>, adjacent to imaging surface <b>318</b>. If light source <b>312</b> is kept on the same side of this line as apex <b>338</b>, then substantially no incident light <b>324</b> emitted perpendicularly from light source <b>312</b> will reach image sensor <b>316</b> without scattering off of the fingerprint ridges <b>311</b>.</p>
    <p>By minimizing the incident light <b>324</b> from light source <b>312</b> that is directly incident on imaging surface, there is substantially no total internal reflection of incident light <b>324</b> from regions of imaging surface <b>318</b> where there are fingerprint valleys <b>309</b>. This means that substantially no light from these valley regions passes through viewing surface <b>320</b> and into lens assembly <b>314</b>. Rather, substantially all the light passing into lens assembly <b>314</b> from imaging surface <b>318</b> is scattered from fingerprint ridges <b>311</b> on imaging surface <b>318</b>. This provides a fingerprint image having relatively high contrast between fingerprint ridges <b>311</b> and valleys <b>309</b>. Such a high contrast fingerprint image is relatively easy to process and compare with other fingerprint images and can, therefore, advantageously increase processing accuracy.</p>
    <p>Further, use of this scattering technique for image acquisition is achieved with a triangular prism, as opposed to a trapezoidal prism as disclosed in Lougheed, discussed in the Background section. Because triangular prisms can be more efficient to manufacture than trapezoidal prisms, image acquisition system <b>308</b> can advantageously be relatively less expensive to manufacture.</p>
    <p>Moreover, scattered light generally scatters from an object in many directions, as opposed to substantially one direction. And, as noted in the Background, nonparallel scattered light can be used by a lens assembly to form a focused image of an object. Thus, as shown in optical recognition system <b>318</b> in FIG. 6, if the first lens of lens assembly <b>314</b> has a smaller diameter than the diagonal of fingerprint <b>335</b> in viewing surface <b>320</b>, non-parallel scattered light rays can be used to produce a focused image of fingerprint <b>335</b>. Accordingly, lens assembly <b>314</b> can be, but does not necessarily need to be, placed relatively close to viewing surface <b>320</b> without loss of image quality near the edges of a fingerprint image generated by system <b>308</b>. This advantageously allows the image acquisition system <b>308</b> to be relatively compact and allows lens assembly <b>314</b> to be relatively low cost to manufacture.</p>
    <p>Because, as shown in FIG. 6, the diameter of a first lens of lens assembly <b>314</b> is smaller than the size of the fingerprint on imaging surface <b>318</b>, trapezoidal distortion could result in a generated image. However, the image acquisition system of the current invention can reduce trapezoidal distortion in, and increase the overall sharpness of, a produced image. As discussed in the Background section, trapezoidal distortion is manifested in an image having dimensions distorted from those of the actual object being imaged. Both trapezoidal distortion and portions of an image being out of focus can be caused by variation in path length of light from the apparent image of an object to lens assembly <b>314</b>, and ultimately image sensor <b>316</b>, from one part of the imaged object to another. As shown in FIG. 6, however, in image acquisition system <b>308</b>, the path length of scattered light <b>330</b> from different points on the apparent image <b>335</b>′ of fingerprint <b>335</b> to lens assembly <b>314</b> and image sensor <b>316</b> is substantially the same. Specifically, path AA′ is substantially equal to path BB′ and path CC′. Thus, trapezoidal distortion can advantageously be reduced and overall image sharpness can be increased. As shown in FIG. 6, substantial equalization of paths AA′, BB′ and CC′ is facilitated by tilting lens assembly <b>314</b> with respect to viewing surface <b>320</b>.</p>
    <p>However, unlike optical recognition system <b>108</b>, shown in FIG. 1, such tilting of lens assembly <b>314</b> does not severely reduce the intensity of the image reaching image sensor <b>316</b>. As noted in the background section with respect to optical recognition system <b>108</b>, tilting lens assembly <b>114</b> causes reflected light <b>130</b> to strike the first element of lens assembly <b>314</b> at an angle to normal line thereof. This causes greater reflection of reflected light <b>130</b> from the surface of lens assembly <b>114</b>, thereby undesirably reducing image intensity at image sensor <b>116</b>.</p>
    <p>However, prism <b>310</b> preferably has an index of refraction higher than <b>1</b>. Thus, scattered light <b>330</b> which strikes viewing surface <b>320</b> refracts away from the normal to viewing surface <b>320</b> as it exits prism <b>310</b>. As such, by tilting the lens plane <b>307</b> of lens assembly <b>314</b>, scattered light <b>330</b> strikes lens assembly <b>314</b> at substantially 90 degrees. Thus, there is little or no loss in image intensity due to undue reflection of scattered light at the surface of lens assembly <b>314</b>, and trapezoidal distortion can be reduced, and overall image sharpness can be increased, without losing image intensity at image sensor <b>316</b>.</p>
    <p>Referring to FIG. 8, the appropriate angle at which to tilt lens assembly <b>314</b> can be determined. In FIG. 8, light rays <b>410</b> and <b>412</b> are scattered from imaging surface edge <b>414</b> and opposite imaging surface edge <b>416</b>, respectively. Lens plane <b>307</b> is a theoretical representation of lens assembly <b>314</b> as the thickness of the lens assembly goes to zero. Distance Aa is the distance from the apparent image of an object in prism <b>310</b> to lens plane <b>307</b> along light ray <b>410</b> and distance B′b is the distance from the apparent image of an object in prism <b>310</b> along light ray <b>412</b>. In order to substantially eliminate trapezoidal distortion, distance Aa must be substantially equal to distance B′b. Because B′b is the apparent depth of an object at edge B in prism <b>310</b>, then, as discussed in the Background section:</p>
    <p>B′b=Bb/n</p>
    <p>where Bb is the distance from point B, at edge <b>416</b>, to point b on prism <b>310</b>. The requirement for substantial elimination of trapezoidal distortion and improvement in overall image sharpness can be expressed as:</p>
    <p>
      <maths> <formula-text>Aa=Bb/n  (Eq. 1)</formula-text> </maths> </p>
    <p>The angle of incidence of light ray <b>412</b> on viewing surface <b>320</b>, that is, the angle between a normal line to viewing surface <b>320</b> and light ray <b>412</b> inside prism <b>310</b>, is shown in FIG. 8 as θ<sub>1</sub>. The angle of refraction of light ray <b>412</b> after it passes out of prism <b>310</b> is shown as θ<sub>2</sub>. Thus, by Snell's law:</p>
    <p>
      <maths> <formula-text>n=sinθ<sub>2</sub>/sinθ<sub>1</sub>  (Eq. 2)</formula-text> </maths> </p>
    <p>Also, using fundamental trigonometric relationships, it can be shown that:</p>
    <p>
      <maths> <formula-text>ABcosγ+Bbcosα′=Ab  (Eq. 3)</formula-text> </maths> </p>
    <p>where AB is the length of the imaging surface of prism <b>310</b> from point A to point B; Ab is the length of segment Ab on viewing surface <b>320</b>; α′ is the angle between light ray <b>412</b> and viewing surface <b>320</b>, which equals 90°−θ<sub>1</sub>; and γ is the angle between imaging surface <b>318</b> and viewing surface <b>320</b> (also shown as angle <b>342</b> in FIG. <b>8</b>).</p>
    <p>Finally, using the law of sines, it can be shown that:</p>
    <p>
      <maths> <formula-text>AB/Bb=cosθ<sub>1</sub>/sinγ  (Eq. 4)</formula-text> </maths> </p>
    <p>Using equations 1, 2, 3, and 4 above, it can be shown that in order for trapezoidal distortion to be substantially eliminated, and overall image sharpness increased, the following condition relating the angles of prism <b>310</b> with the angle which lens plane <b>307</b> forms with viewing surface <b>320</b> must be met:</p>
    <p>
      <maths> <formula-text>(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ=1  (Eq. 5)</formula-text> </maths> </p>
    <p>Where, as shown in FIG. 8, δ is the angle that lens plane <b>307</b> of lens assembly <b>314</b> forms with viewing surface <b>320</b>. Thus, imaging system <b>308</b>, in accordance with the present invention, is preferably configured in accordance with equation 5 to substantially eliminate trapezoidal distortion and improve overall image sharpness.</p>
    <p>However, in manufacturing imaging system <b>308</b>, achieving precise tolerances for angles γ and δ can be difficult and expensive. Therefore, an imaging system in accordance with the present invention and allowing for a 30% manufacturing tolerance is preferably configured in accordance with the equation 6 below:</p>
    <p>
      <maths> <formula-text>0.7≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.3  (Eq. 6)</formula-text> </maths> </p>
    <p>More preferably, an imaging system in accordance with the present invention and allowing for a 15% manufacturing tolerance is configured in accordance with equation 7 below:</p>
    <p>
      <maths> <formula-text>0.85≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.15  (Eq. 7)</formula-text> </maths> </p>
    <p>Most preferably, an imaging system in accordance with the present invention and allowing for a 7.5% manufacturing tolerance is configured in accordance with equation 8 below:</p>
    <p>
      <maths> <formula-text>0.925≦(n<sup>2</sup>−sin<sup>2</sup>δ)<sup>½</sup>(cotγ)(sinδ)+sin<sup>2</sup>δ≦1.075  (Eq. 8)</formula-text> </maths> </p>
    <p>As noted above, by configuring imaging system <b>308</b> in accordance with one of equations 5-8 above, trapezoidal distortion can be substantially reduced or eliminated and overall image sharpness can be improved. This advantageously facilitates more accurate image processing and comparison by an image acquisition system.</p>
    <p>Prism <b>310</b> can be made of glass, acrylic or any other transparent material having an index of refraction higher than 1 (that of air). Prisms having the preferred index of refraction and angles are commercially available from Shinkwang Ltd. of Seoul, Korea and are fabricated of glass having the designation LaK-<b>7</b> or LaK-<b>8</b>.</p>
    <p>Lens assemblies such as lens assembly <b>314</b> are commercially available from Woorim Optical Systems Ltd. of Seoul, Korea and are preferably fabricated from a glass having the commercial designation of BK<b>7</b>. If more than one element is used in lens assembly <b>314</b>, as shown in FIG. 6, the individual elements can be aligned and spaced by placing them in a frame fabricated by plastic molding or any other fabrication means as is known in the art.</p>
    <p>Light source <b>312</b> preferably consists of four standard LEDs positioned in a straight array on a circuit board. Powering of LEDs is well known by those skilled in the art. Image sensor <b>316</b> is preferably a CMOS type sensor and is commercially available from Hyundai Electronics of Seoul, Korea, VLSI Vision, Ltd. of San Jose, Calif., or Omnivision Technologies Inc. of Sunnyvale, Calif.</p>
    <p>To secure the components of image acquisition into the relative positions as shown in FIG. 4, a frame having holding slots for each component can be plastic molded or otherwise fabricated. Light source <b>312</b> can be either placed in a holding slot adjacent to viewing surface <b>320</b> or attached directly to viewing surface <b>320</b> using adhesive as known in the art.</p>
    <p>Equations 5-8 were derived assuming that the entire width AB of imaging surface <b>318</b> would be used in capturing an image. However, less than the entire imaging surface of a prism can be used to capture an image. This may be the case, for example, if a triangular prism having an angle greater than or equal to 90 degrees is used as a light refractor. However, if the entire imaging surface of a prism is not used to image an object, a requirement in addition to being configured according to equations 5-8 above is preferably met by the configuration of such an imaging system. To illustrate this additional requirement, FIG. 9 shows a triangular prism <b>510</b> having an obtuse angle <b>541</b>. Triangular prism <b>510</b> includes a planar imaging surface <b>518</b>, a planar viewing surface <b>520</b> and a planar further surface <b>522</b>. FIG. 9 also shows a light source <b>512</b> which can be substantially the same as light source <b>312</b>, and lens plane <b>507</b> of a lens assembly (not shown). A lens assembly used with prism <b>510</b> can be substantially the same as lens assembly <b>314</b>.</p>
    <p>As shown in FIG. 9, a light ray <b>612</b> is scattered from point D on imaging surface <b>518</b> and a light ray <b>610</b> is scattered from imaging surface <b>518</b> at point A. Prism <b>510</b> and lens plane <b>507</b> are configured in accordance with equation 5 above. Additionally, segment a′d′ is parallel to lens plane <b>507</b>. And, length D′d′ is the apparent depth in prism <b>510</b> of the image of an object at point D on imaging surface <b>518</b>. Thus, the length of segments Aa′ and D′d′ are the equal. Because the index of refraction of prism <b>510</b> is greater than 1, as light ray <b>612</b> leaves prism <b>510</b> at point d′, it will refract away from a normal line <b>620</b> to viewing surface <b>520</b>.</p>
    <p>Angle <b>545</b>, labeled as α′ in FIG. 9, which is the angle formed by the intersection of light ray <b>612</b> and viewing surface <b>520</b>, and is adjacent to the intersection of the viewing surface and the imaging surface, is less than 90 degrees. Thus, as light ray <b>612</b> passes out of prism <b>510</b> and refracts away from normal line <b>620</b>, it will travel in a path parallel to that of light ray <b>610</b> outside of prism <b>510</b>. Therefore, the lengths of segments a′a and d′d are also equal. Accordingly, the total path lengths from the apparent image in prism <b>510</b> to the lens plane <b>507</b>, and ultimately the an image sensor (not shown) will be the same for an object on imaging surface <b>518</b> at both point A and point D. In this way overall image sharpness can be increased.</p>
    <p>Referring now to FIG. 10, which also shows prism <b>510</b>, the path length from the apparent image in prism <b>510</b> of an object placed at point E on imaging surface <b>518</b> will not be equal to the path length from the apparent image in prism <b>510</b> of an object placed at point A on prism <b>510</b>. Light ray <b>612</b> is a scattered light ray from an object placed at point E on imaging surface <b>518</b>. As above, because prism <b>510</b> has an index of refraction which is greater than 1, as light ray <b>612</b> exits prism <b>510</b> at point e′, it will refract away from normal line <b>620</b> to viewing surface <b>520</b>. Therefore, because angle <b>545</b>, labeled α′, is greater than 90 degrees, the path of light ray <b>612</b> outside of prism <b>510</b> is not parallel to the path of light ray <b>610</b> outside of prism <b>510</b>. Because light rays <b>610</b> and <b>612</b> are not parallel, the length of segment e′e will be different from the length of segment a′a. This means that the total path length from the apparent image in prism <b>510</b> to lens plane <b>507</b> will be different for an object at point E on imaging surface <b>318</b> than for an object at point A thereon. Thus, relatively large trapezoidal distortion and/or a relatively out of focus image will result.</p>
    <p>As noted above, in order to avoid this, when a prism having a 90 degree or greater angle is used in an imaging system in accordance with the present invention, preferably, less than the entire width of the imaging surface is used to image an object. As shown above, when α′ is less than 90 degrees, and the image capturing system is configured according to equations (5) through (8) above, trapezoidal distortion can be substantially eliminated. And, when α′ is greater or equal to 90 degrees trapezoidal distortion can result. Thus, if less than the entire width of the imaging surface <b>518</b> of a prism is to be used to place an object to be imaged against, each portion of the imaging surface <b>518</b> to be used for imaging must be able to have at least one light ray scattered therefrom such that the intersection of the one light ray and the viewing surface <b>520</b> form an angle, α′ in FIGS. 9 and 10, adjacent to the intersection of the viewing surface and the imaging surface, which is less than 90 degrees. This criteria advantageously facilitates reduction or substantial elimination of trapezoidal distortion and increase in overall image sharpness in an imaging system configured in accordance with one of equations 5-8 above.</p>
    <p>Prism <b>510</b>, and light source <b>512</b> can be manufactured in substantially the same way and of the same materials as discussed above with respect to prism <b>310</b> and light source <b>312</b>.</p>
    <p>Many widely different embodiments of the present invention may be constructed without departing from the spirit and scope of the present invention. It should be understood that the present invention is not limited to the specific embodiments described in the specification. For example, though the above disclosed embodiment of the present invention are described with reference to imaging a fingerprint, any other type of patterned object is contemplated to be imaged with the present invention.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3527535">US3527535</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 15, 1968</td><td class="patent-data-table-td patent-date-value">Sep 8, 1970</td><td class="patent-data-table-td ">Eg &amp; G Inc</td><td class="patent-data-table-td ">Fingerprint observation and recording apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3864042">US3864042</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 10, 1973</td><td class="patent-data-table-td patent-date-value">Feb 4, 1975</td><td class="patent-data-table-td ">Leventhal Stephen Richard</td><td class="patent-data-table-td ">Fingerprint scanning system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3975711">US3975711</a></td><td class="patent-data-table-td patent-date-value">Aug 30, 1974</td><td class="patent-data-table-td patent-date-value">Aug 17, 1976</td><td class="patent-data-table-td ">Sperry Rand Corporation</td><td class="patent-data-table-td ">Real time fingerprint recording terminal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4120585">US4120585</a></td><td class="patent-data-table-td patent-date-value">Nov 19, 1976</td><td class="patent-data-table-td patent-date-value">Oct 17, 1978</td><td class="patent-data-table-td ">Calspan Corporation</td><td class="patent-data-table-td ">Fingerprint identification system using a pliable optical prism</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4135147">US4135147</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 1976</td><td class="patent-data-table-td patent-date-value">Jan 16, 1979</td><td class="patent-data-table-td ">Rockwell International Corporation</td><td class="patent-data-table-td ">Minutiae pattern matcher</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4210899">US4210899</a></td><td class="patent-data-table-td patent-date-value">Nov 25, 1977</td><td class="patent-data-table-td patent-date-value">Jul 1, 1980</td><td class="patent-data-table-td ">Fingermatrix, Inc.</td><td class="patent-data-table-td ">Fingerprint-based access control and identification apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4340300">US4340300</a></td><td class="patent-data-table-td patent-date-value">Aug 11, 1980</td><td class="patent-data-table-td patent-date-value">Jul 20, 1982</td><td class="patent-data-table-td ">Siemens Corporation</td><td class="patent-data-table-td ">Input sensor unit for a fingerprint identification system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4414684">US4414684</a></td><td class="patent-data-table-td patent-date-value">Dec 24, 1980</td><td class="patent-data-table-td patent-date-value">Nov 8, 1983</td><td class="patent-data-table-td ">Interlock Sicherheitssysteme Gmbh</td><td class="patent-data-table-td ">Method and apparatus for performing a comparison of given patterns, in particular fingerprints</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4668995">US4668995</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 12, 1985</td><td class="patent-data-table-td patent-date-value">May 26, 1987</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System for reproducing mixed images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4681435">US4681435</a></td><td class="patent-data-table-td patent-date-value">Mar 30, 1984</td><td class="patent-data-table-td patent-date-value">Jul 21, 1987</td><td class="patent-data-table-td ">Kabushiki Kaisha Tokai Rika Denki Seisakusho</td><td class="patent-data-table-td ">Contact pattern observation apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4832485">US4832485</a></td><td class="patent-data-table-td patent-date-value">Sep 3, 1982</td><td class="patent-data-table-td patent-date-value">May 23, 1989</td><td class="patent-data-table-td ">Commonwealth Technology, Inc.</td><td class="patent-data-table-td ">Image enhancer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4872203">US4872203</a></td><td class="patent-data-table-td patent-date-value">Mar 25, 1988</td><td class="patent-data-table-td patent-date-value">Oct 3, 1989</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Image input device for processing a fingerprint prior to identification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4983415">US4983415</a></td><td class="patent-data-table-td patent-date-value">Jul 21, 1989</td><td class="patent-data-table-td patent-date-value">Jan 8, 1991</td><td class="patent-data-table-td ">Identicator Corporation</td><td class="patent-data-table-td ">Method of making permanent images on recording surface having a thermosensitive color-developing layer thereon</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5051576">US5051576</a></td><td class="patent-data-table-td patent-date-value">Jul 31, 1990</td><td class="patent-data-table-td patent-date-value">Sep 24, 1991</td><td class="patent-data-table-td ">Michael Schiller</td><td class="patent-data-table-td ">Finger surface image enhancement having a liquid layer on the finger touching surface of the platen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5096290">US5096290</a></td><td class="patent-data-table-td patent-date-value">Aug 27, 1990</td><td class="patent-data-table-td patent-date-value">Mar 17, 1992</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Apparatus for imaging fingerprint using transparent optical means having elastic material layer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5177435">US5177435</a></td><td class="patent-data-table-td patent-date-value">Oct 11, 1991</td><td class="patent-data-table-td patent-date-value">Jan 5, 1993</td><td class="patent-data-table-td ">Advantest Corporation</td><td class="patent-data-table-td ">IC test equipment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5177802">US5177802</a></td><td class="patent-data-table-td patent-date-value">Mar 4, 1991</td><td class="patent-data-table-td patent-date-value">Jan 5, 1993</td><td class="patent-data-table-td ">Sharp Kabushiki Kaisha</td><td class="patent-data-table-td ">Fingerprint input apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5189482">US5189482</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 22, 1991</td><td class="patent-data-table-td patent-date-value">Feb 23, 1993</td><td class="patent-data-table-td ">Goldstar Co., Ltd.</td><td class="patent-data-table-td ">Optical apparatus for fingerprint recognition system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5210588">US5210588</a></td><td class="patent-data-table-td patent-date-value">Nov 15, 1991</td><td class="patent-data-table-td patent-date-value">May 11, 1993</td><td class="patent-data-table-td ">Goldstar Co., Ltd.</td><td class="patent-data-table-td ">Fingerprint identification apparatus for enhancing identification performance by forming an illumination source and a light conducting panel in a single body</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5222153">US5222153</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 1991</td><td class="patent-data-table-td patent-date-value">Jun 22, 1993</td><td class="patent-data-table-td ">Thumbscan, Inc.</td><td class="patent-data-table-td ">Apparatus for matching a fingerprint using a tacky finger platen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5233404">US5233404</a></td><td class="patent-data-table-td patent-date-value">Sep 26, 1990</td><td class="patent-data-table-td patent-date-value">Aug 3, 1993</td><td class="patent-data-table-td ">Oscan Electro Optics Inc.</td><td class="patent-data-table-td ">Optical scanning and recording apparatus for fingerprints</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5416573">US5416573</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 1993</td><td class="patent-data-table-td patent-date-value">May 16, 1995</td><td class="patent-data-table-td ">Indentix Incorporated</td><td class="patent-data-table-td ">Apparatus for producing fingerprint images which are substantially free of artifacts attributable to moisture on the finger being imaged</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5548394">US5548394</a></td><td class="patent-data-table-td patent-date-value">Mar 16, 1995</td><td class="patent-data-table-td patent-date-value">Aug 20, 1996</td><td class="patent-data-table-td ">Printrak International Inc.</td><td class="patent-data-table-td ">Scanning fingerprint reading</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5623553">US5623553</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 8, 1995</td><td class="patent-data-table-td patent-date-value">Apr 22, 1997</td><td class="patent-data-table-td ">Asahi Kogaku Kogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">High contrast fingerprint image detector</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5635723">US5635723</a></td><td class="patent-data-table-td patent-date-value">Dec 26, 1995</td><td class="patent-data-table-td patent-date-value">Jun 3, 1997</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Fingerprint image input apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5680205">US5680205</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 1996</td><td class="patent-data-table-td patent-date-value">Oct 21, 1997</td><td class="patent-data-table-td ">Dew Engineering And Development Ltd.</td><td class="patent-data-table-td ">Fingerprint imaging apparatus with auxiliary lens</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5732148">US5732148</a></td><td class="patent-data-table-td patent-date-value">Sep 16, 1994</td><td class="patent-data-table-td patent-date-value">Mar 24, 1998</td><td class="patent-data-table-td ">Keagy; John Martin</td><td class="patent-data-table-td ">Apparatus and method for electronically acquiring fingerprint images with low cost removable platen and separate imaging device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5737071">US5737071</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 1996</td><td class="patent-data-table-td patent-date-value">Apr 7, 1998</td><td class="patent-data-table-td ">Identicator Corporation</td><td class="patent-data-table-td ">Method and apparatus for enhancing live-scan fingerprint reader images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5740276">US5740276</a></td><td class="patent-data-table-td patent-date-value">Jul 27, 1995</td><td class="patent-data-table-td patent-date-value">Apr 14, 1998</td><td class="patent-data-table-td ">Mytec Technologies Inc.</td><td class="patent-data-table-td ">Holographic method for encrypting and decrypting information using a fingerprint</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5796858">US5796858</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 10, 1996</td><td class="patent-data-table-td patent-date-value">Aug 18, 1998</td><td class="patent-data-table-td ">Digital Persona, Inc.</td><td class="patent-data-table-td ">Fingerprint sensing system using a sheet prism</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5812252">US5812252</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 31, 1995</td><td class="patent-data-table-td patent-date-value">Sep 22, 1998</td><td class="patent-data-table-td ">Arete Associates</td><td class="patent-data-table-td ">Fingerprint--Acquisition apparatus for access control; personal weapon and other systems controlled thereby</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5822445">US5822445</a></td><td class="patent-data-table-td patent-date-value">Jul 8, 1997</td><td class="patent-data-table-td patent-date-value">Oct 13, 1998</td><td class="patent-data-table-td ">Dew Engineering And Development Limited</td><td class="patent-data-table-td ">Apparatus for identifying fingerprints</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5875025">US5875025</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 14, 1997</td><td class="patent-data-table-td patent-date-value">Feb 23, 1999</td><td class="patent-data-table-td ">Hamamatsu Photonics K.K.</td><td class="patent-data-table-td ">Image input apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5963657">US5963657</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 9, 1996</td><td class="patent-data-table-td patent-date-value">Oct 5, 1999</td><td class="patent-data-table-td ">Arete Associates</td><td class="patent-data-table-td ">Economical skin-pattern-acquisition and analysis apparatus for access control; systems controlled thereby</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6154285">US6154285</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 21, 1998</td><td class="patent-data-table-td patent-date-value">Nov 28, 2000</td><td class="patent-data-table-td ">Secugen Corporation</td><td class="patent-data-table-td ">Surface treatment for optical image capturing system</td></tr><tr><td class="patent-data-table-td citation-patent"></td><td class="patent-data-table-td ">CA1286032A</td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/DE19509751A1?cl=en">DE19509751A1</a></td><td class="patent-data-table-td patent-date-value">Mar 17, 1995</td><td class="patent-data-table-td patent-date-value">Sep 19, 1996</td><td class="patent-data-table-td ">Hans J Dr Einighammer</td><td class="patent-data-table-td ">Optical imaging system for representing papillary ridge pattern</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0308162A2?cl=en">EP0308162A2</a></td><td class="patent-data-table-td patent-date-value">Sep 12, 1988</td><td class="patent-data-table-td patent-date-value">Mar 22, 1989</td><td class="patent-data-table-td ">Identix Incorporated</td><td class="patent-data-table-td ">Optical system for fingerprint imaging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0617919A2?cl=en">EP0617919A2</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 1994</td><td class="patent-data-table-td patent-date-value">Oct 5, 1994</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Apparatus for obtaining ridge line pattern image on a curved surface</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0847024A2?cl=en">EP0847024A2</a></td><td class="patent-data-table-td patent-date-value">Dec 5, 1997</td><td class="patent-data-table-td patent-date-value">Jun 10, 1998</td><td class="patent-data-table-td ">Yamatake-Honeywell Co. Ltd.</td><td class="patent-data-table-td ">Fingerprint input apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0867828A2?cl=en">EP0867828A2</a></td><td class="patent-data-table-td patent-date-value">Mar 26, 1998</td><td class="patent-data-table-td patent-date-value">Sep 30, 1998</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Fingerprint detecting device and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0867829A2?cl=en">EP0867829A2</a></td><td class="patent-data-table-td patent-date-value">Mar 26, 1998</td><td class="patent-data-table-td patent-date-value">Sep 30, 1998</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Fingerprint detecting device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH0395693A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHQCI3_ktX-t4uuZ9buOhGhIlZ4jA">JPH0395693A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH02133892A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEAALCiYVTEDkp394cofXK3SIM8Pg">JPH02133892A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH02188888A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGz3_FTfuDpemn4lC12kerh4pl-og">JPH02188888A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH03246693A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNG0GQefNMnhx-yVylQmg_5d0dmxLw">JPH03246693A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH03292578A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFKi8CAHPa5CMz9esoUIIRU3Ts1rQ">JPH03292578A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH05216981A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEmW8BJ_9dXQ4YqQZ3IGdM6szQq3Q">JPH05216981A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH07131322A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNE_9soJJRmvTxr4FyyUatxcpvEvwg">JPH07131322A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH11102432A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHNJUzNNYlDkvP-nqysIe7wMH_nNg">JPH11102432A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DS6274177A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNH7oDtUhlYAxKHtdD0XlKj5FWyJnw">JPS6274177A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DS61145686A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEZ-PH8GwobSF2x0ek8lKejilC1YQ">JPS61145686A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DS61221883A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHOLORQiTeQX2WzEzgDkHymeG8VsA">JPS61221883A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=PuJXBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DKR%26NR%3D940007344A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEnsgVE94wvKFqRQAF_iu4LkG-hTA">KR940007344A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1997014111A1?cl=en">WO1997014111A1</a></td><td class="patent-data-table-td patent-date-value">Oct 4, 1996</td><td class="patent-data-table-td patent-date-value">Apr 17, 1997</td><td class="patent-data-table-td ">Kallo Peter</td><td class="patent-data-table-td ">In a fingerprint recognizing apparatus detector for recognizing the living character of a finger</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1998011478A2?cl=en">WO1998011478A2</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 1997</td><td class="patent-data-table-td patent-date-value">Mar 19, 1998</td><td class="patent-data-table-td ">Yang Li</td><td class="patent-data-table-td ">A biometric based method for software distribution</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1998011501A2?cl=en">WO1998011501A2</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 1997</td><td class="patent-data-table-td patent-date-value">Mar 19, 1998</td><td class="patent-data-table-td ">D Ramesh K Rao</td><td class="patent-data-table-td ">Embeddable module for fingerprint capture and matching</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1998011750A2?cl=en">WO1998011750A2</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 1997</td><td class="patent-data-table-td patent-date-value">Mar 19, 1998</td><td class="patent-data-table-td ">Yang Li</td><td class="patent-data-table-td ">Method of using fingerprints to authenticate wireless communications</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1998035118A1?cl=en">WO1998035118A1</a></td><td class="patent-data-table-td patent-date-value">Jan 28, 1998</td><td class="patent-data-table-td patent-date-value">Aug 13, 1998</td><td class="patent-data-table-td ">Schelter Wolfgang</td><td class="patent-data-table-td ">Identification device</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Seigo Igaki et al. (Jan. 1990). "<a href='http://scholar.google.com/scholar?q="Holographic+Fingerprint+Sensor%2C"'>Holographic Fingerprint Sensor,</a>" Fujitsu Sci.Tech. J., JP, Fujitsu Limited. Kawasaki, 25(4): 287-296.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6954261">US6954261</a></td><td class="patent-data-table-td patent-date-value">Jun 17, 2003</td><td class="patent-data-table-td patent-date-value">Oct 11, 2005</td><td class="patent-data-table-td ">Cross Match Technologies, Inc.</td><td class="patent-data-table-td ">System and method for illuminating a platen in a live scanner and producing high-contrast print images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7035442">US7035442</a></td><td class="patent-data-table-td patent-date-value">Jun 1, 2001</td><td class="patent-data-table-td patent-date-value">Apr 25, 2006</td><td class="patent-data-table-td ">Secugen Corporation</td><td class="patent-data-table-td ">User authenticating system and method using one-time fingerprint template</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7050158">US7050158</a></td><td class="patent-data-table-td patent-date-value">Dec 24, 2002</td><td class="patent-data-table-td patent-date-value">May 23, 2006</td><td class="patent-data-table-td ">Guolin Ma</td><td class="patent-data-table-td ">Compact image pickup module</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7119890">US7119890</a></td><td class="patent-data-table-td patent-date-value">Oct 11, 2005</td><td class="patent-data-table-td patent-date-value">Oct 10, 2006</td><td class="patent-data-table-td ">Cross Match Technologies, Inc.</td><td class="patent-data-table-td ">System and method for illuminating a platen in a live scanner and producing high-contrast print images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7426020">US7426020</a></td><td class="patent-data-table-td patent-date-value">Aug 1, 2005</td><td class="patent-data-table-td patent-date-value">Sep 16, 2008</td><td class="patent-data-table-td ">Cross Match Technologies, Inc.</td><td class="patent-data-table-td ">System for print imaging with prism illumination optics</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7580550">US7580550</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 13, 2004</td><td class="patent-data-table-td patent-date-value">Aug 25, 2009</td><td class="patent-data-table-td ">Sagem Defense Securite</td><td class="patent-data-table-td ">Fingerprint-image-forming optical device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7834988">US7834988</a></td><td class="patent-data-table-td patent-date-value">Jun 2, 2008</td><td class="patent-data-table-td patent-date-value">Nov 16, 2010</td><td class="patent-data-table-td ">Ramendra Deo Bahuguna</td><td class="patent-data-table-td ">Fingerprint sensor using a spectral filter and a holographic optical element</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8131477">US8131477</a></td><td class="patent-data-table-td patent-date-value">Aug 8, 2006</td><td class="patent-data-table-td patent-date-value">Mar 6, 2012</td><td class="patent-data-table-td ">3M Cogent, Inc.</td><td class="patent-data-table-td ">Method and device for image-based biological data quantification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8254728">US8254728</a></td><td class="patent-data-table-td patent-date-value">Jul 9, 2009</td><td class="patent-data-table-td patent-date-value">Aug 28, 2012</td><td class="patent-data-table-td ">3M Cogent, Inc.</td><td class="patent-data-table-td ">Method and apparatus for two dimensional image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8275179">US8275179</a></td><td class="patent-data-table-td patent-date-value">Apr 17, 2008</td><td class="patent-data-table-td patent-date-value">Sep 25, 2012</td><td class="patent-data-table-td ">3M Cogent, Inc.</td><td class="patent-data-table-td ">Apparatus for capturing a high quality image of a moist finger</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8379982">US8379982</a></td><td class="patent-data-table-td patent-date-value">Oct 13, 2009</td><td class="patent-data-table-td patent-date-value">Feb 19, 2013</td><td class="patent-data-table-td ">3M Cogent, Inc.</td><td class="patent-data-table-td ">System and method for fast biometric pattern matching</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8405757">US8405757</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 27, 2011</td><td class="patent-data-table-td patent-date-value">Mar 26, 2013</td><td class="patent-data-table-td ">Optical Logic Inc.</td><td class="patent-data-table-td ">Imaging device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8411916">US8411916</a></td><td class="patent-data-table-td patent-date-value">Mar 28, 2008</td><td class="patent-data-table-td patent-date-value">Apr 2, 2013</td><td class="patent-data-table-td ">3M Cogent, Inc.</td><td class="patent-data-table-td ">Bio-reader device with ticket identification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8583379">US8583379</a></td><td class="patent-data-table-td patent-date-value">Jan 25, 2012</td><td class="patent-data-table-td patent-date-value">Nov 12, 2013</td><td class="patent-data-table-td ">3M Innovative Properties Company</td><td class="patent-data-table-td ">Method and device for image-based biological data quantification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120105705">US20120105705</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 27, 2011</td><td class="patent-data-table-td patent-date-value">May 3, 2012</td><td class="patent-data-table-td ">Yoji Kubota</td><td class="patent-data-table-td ">Imaging device</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc359/defs359.htm&usg=AFQjCNF5eQz9hOHtK1nQva4sjr3LkAoZzw#C359S726000">359/726</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc359/defs359.htm&usg=AFQjCNF5eQz9hOHtK1nQva4sjr3LkAoZzw#C359S737000">359/737</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S127000">382/127</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc359/defs359.htm&usg=AFQjCNF5eQz9hOHtK1nQva4sjr3LkAoZzw#C359S798000">359/798</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc359/defs359.htm&usg=AFQjCNF5eQz9hOHtK1nQva4sjr3LkAoZzw#C359S831000">359/831</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc356/defs356.htm&usg=AFQjCNGiEVb0PD41nDL-c_Hc6_cJvkgI_Q#C356S071000">356/71</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0001000000">G06T1/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=PuJXBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00046">G06K9/00046</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06K9/00A1G</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Mar 19, 2013</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 15, 2009</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1-6 AND 8-11 ARE CANCELLED. CLAIMS 7 AND 12 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 13-19, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. NEW CLAIMS 20-28 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 16, 2009</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 23, 2008</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20080806</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 22, 2008</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">UNION COMMUNITY CO., LTD., KOREA, REPUBLIC OF</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">LICENSE;ASSIGNOR:SECUGEN CORPORATION;REEL/FRAME:021561/0541</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20080909</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 12, 2005</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 8, 2003</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">MORRISON &amp; FOERSTER LLP, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY INTEREST;ASSIGNOR:SECUGEN CORPORATION;REEL/FRAME:013645/0449</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20021220</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">MORRISON &amp; FOERSTER LLP 425 MARKET STREETSAN FRANC</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY INTEREST;ASSIGNOR:SECUGEN CORPORATION /AR;REEL/FRAME:013645/0449</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 6, 1999</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SECUGEN CORPORATION, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:TENG, HARRY H.;JO, SUNG-CHAN;REEL/FRAME:010464/0099;SIGNING DATES FROM 19991015 TO 19991021</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SECUGEN CORPORATION 1740 TECHNOLOGY DRIVE, SUITE 5</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 7, 1999</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SECUGEN CORPORATION, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:TENG, HARRY H.;JO, SUNG-CHAN;REEL/FRAME:010219/0312</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19990728</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U2-fFVdZHAf-7_p5ZlyUuRGV7c0kg\u0026id=PuJXBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U21PDQle-DoZA3WjyuRqhzmRJCK5A\u0026id=PuJXBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2eQfaLqS4eBwPGRHrpxW3ZR3tHvg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_and_apparatus_for_reduction_of_tr.pdf?id=PuJXBAABERAJ\u0026output=pdf\u0026sig=ACfU3U2vZSTYf5H9aiIZX7T1Hq_ijrPWRg"},"sample_url":"http://www.google.com/patents/reader?id=PuJXBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>