<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US8174560 - Video camera - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4ff636b3d23669b7103f3b3a3a18b4cd/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4ff636b3d23669b7103f3b3a3a18b4cd__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Video camera"><meta name="DC.contributor" content="James Jannard" scheme="inventor"><meta name="DC.contributor" content="Thomas Graeme Nattress" scheme="inventor"><meta name="DC.contributor" content="Red.Com, Inc." scheme="assignee"><meta name="DC.date" content="2008-4-11" scheme="dateSubmitted"><meta name="DC.description" content="A video camera can be configured to highly compress video data in a visually lossless manner. The camera can be configured to transform blue and red image data in a manner that enhances the compressibility of the data. The data can then be compressed and stored in this form. This allows a user to reconstruct the red and blue data to obtain the original raw data for a modified version of the original raw data that is visually lossless when demosaiced. Additionally, the data can be processed in a manner in which the green image elements are demosaiced first and then the red and blue elements are reconstructed based on values of the demosaiced green image elements."><meta name="DC.date" content="2012-5-8" scheme="issued"><meta name="DC.relation" content="US:20020041707:A1" scheme="references"><meta name="DC.relation" content="US:20020196354:A1" scheme="references"><meta name="DC.relation" content="US:20030007567:A1" scheme="references"><meta name="DC.relation" content="US:20030011747:A1" scheme="references"><meta name="DC.relation" content="US:20030038885:A1" scheme="references"><meta name="DC.relation" content="US:20030156188:A1" scheme="references"><meta name="DC.relation" content="US:20030185302:A1" scheme="references"><meta name="DC.relation" content="US:20030202106:A1" scheme="references"><meta name="DC.relation" content="US:20040051793:A1" scheme="references"><meta name="DC.relation" content="US:20040095477:A1" scheme="references"><meta name="DC.relation" content="US:20040196389:A1" scheme="references"><meta name="DC.relation" content="US:20040201701:A1" scheme="references"><meta name="DC.relation" content="US:20040246346:A1" scheme="references"><meta name="DC.relation" content="US:20050276496:A1" scheme="references"><meta name="DC.relation" content="US:20060007324:A1" scheme="references"><meta name="DC.relation" content="US:20060012694:A1" scheme="references"><meta name="DC.relation" content="US:20060061659:A1" scheme="references"><meta name="DC.relation" content="US:20060114987:A1" scheme="references"><meta name="DC.relation" content="US:20060165179:A1" scheme="references"><meta name="DC.relation" content="US:20060170786:A1" scheme="references"><meta name="DC.relation" content="US:20060221199:A1" scheme="references"><meta name="DC.relation" content="US:20060221203:A1" scheme="references"><meta name="DC.relation" content="US:20060221230:A1" scheme="references"><meta name="DC.relation" content="US:20070035636:A1" scheme="references"><meta name="DC.relation" content="US:20070041634:A1" scheme="references"><meta name="DC.relation" content="US:20070127095:A1" scheme="references"><meta name="DC.relation" content="US:20070153093:A1" scheme="references"><meta name="DC.relation" content="US:20070160142:A1" scheme="references"><meta name="DC.relation" content="US:20070216782:A1" scheme="references"><meta name="DC.relation" content="US:20070285517:A1" scheme="references"><meta name="DC.relation" content="US:20080002035:A1" scheme="references"><meta name="DC.relation" content="US:20080012953:A1" scheme="references"><meta name="DC.relation" content="US:20080018746:A1" scheme="references"><meta name="DC.relation" content="US:3972010" scheme="references"><meta name="DC.relation" content="US:4200889" scheme="references"><meta name="DC.relation" content="US:4316213" scheme="references"><meta name="DC.relation" content="US:4561012" scheme="references"><meta name="DC.relation" content="US:5016107" scheme="references"><meta name="DC.relation" content="US:5040063" scheme="references"><meta name="DC.relation" content="US:5049983" scheme="references"><meta name="DC.relation" content="US:5249053" scheme="references"><meta name="DC.relation" content="US:5255083" scheme="references"><meta name="DC.relation" content="US:5303062" scheme="references"><meta name="DC.relation" content="US:5343243" scheme="references"><meta name="DC.relation" content="US:5526047" scheme="references"><meta name="DC.relation" content="US:5535246" scheme="references"><meta name="DC.relation" content="US:5537157" scheme="references"><meta name="DC.relation" content="US:5563655" scheme="references"><meta name="DC.relation" content="US:5592224" scheme="references"><meta name="DC.relation" content="US:5592237" scheme="references"><meta name="DC.relation" content="US:5818524" scheme="references"><meta name="DC.relation" content="US:5949468" scheme="references"><meta name="DC.relation" content="US:5991515" scheme="references"><meta name="DC.relation" content="US:5999220" scheme="references"><meta name="DC.relation" content="US:6009201" scheme="references"><meta name="DC.relation" content="US:6154493" scheme="references"><meta name="DC.relation" content="US:6192086" scheme="references"><meta name="DC.relation" content="US:6198505" scheme="references"><meta name="DC.relation" content="US:6262763" scheme="references"><meta name="DC.relation" content="US:6269217" scheme="references"><meta name="DC.relation" content="US:6275263" scheme="references"><meta name="DC.relation" content="US:6285794" scheme="references"><meta name="DC.relation" content="US:6314206" scheme="references"><meta name="DC.relation" content="US:6466699" scheme="references"><meta name="DC.relation" content="US:6567988" scheme="references"><meta name="DC.relation" content="US:6597860" scheme="references"><meta name="DC.relation" content="US:6697106" scheme="references"><meta name="DC.relation" content="US:6825876" scheme="references"><meta name="DC.relation" content="US:6859226" scheme="references"><meta name="DC.relation" content="US:6867717" scheme="references"><meta name="DC.relation" content="US:6937276" scheme="references"><meta name="DC.relation" content="US:6958774" scheme="references"><meta name="DC.relation" content="US:6983074" scheme="references"><meta name="DC.relation" content="US:6990240" scheme="references"><meta name="DC.relation" content="US:6995793" scheme="references"><meta name="DC.relation" content="US:6995794" scheme="references"><meta name="DC.relation" content="US:7038719" scheme="references"><meta name="DC.relation" content="US:7050642" scheme="references"><meta name="DC.relation" content="US:7095899" scheme="references"><meta name="DC.relation" content="US:7126634" scheme="references"><meta name="DC.relation" content="US:7127116" scheme="references"><meta name="DC.relation" content="US:7155066" scheme="references"><meta name="DC.relation" content="US:7174045" scheme="references"><meta name="DC.relation" content="US:7212313" scheme="references"><meta name="DC.relation" content="US:7312821" scheme="references"><meta name="DC.relation" content="US:7313286" scheme="references"><meta name="DC.relation" content="US:7324141" scheme="references"><meta name="DC.relation" content="US:7343043" scheme="references"><meta name="DC.relation" content="US:7365658" scheme="references"><meta name="DC.relation" content="US:7369161" scheme="references"><meta name="DC.relation" content="US:7385647" scheme="references"><meta name="DC.relation" content="US:7388992" scheme="references"><meta name="DC.relation" content="US:7394485" scheme="references"><meta name="DC.relation" content="US:7477781" scheme="references"><meta name="DC.relation" content="US:7483909" scheme="references"><meta name="DC.relation" content="US:7512283" scheme="references"><meta name="DC.relation" content="US:7577689" scheme="references"><meta name="DC.relation" content="US:7590301" scheme="references"><meta name="DC.relation" content="US:7609300" scheme="references"><meta name="DC.relation" content="US:7796186" scheme="references"><meta name="DC.relation" content="US:7830967" scheme="references"><meta name="DC.relation" content="US:7937919" scheme="references"><meta name="DC.relation" content="US:RE37342" scheme="references"><meta name="DC.relation" content="US:RE38079" scheme="references"><meta name="citation_reference" content="ARRFLEX D-21: The Film Style Didial Camera, Jan. 4, 2008, www.arri.de, [online] http://www.arri.de/press/press/press-release.html?tx-ttnews[tt-news]=32&amp;tx-ttnews[backPid]=1781&amp;cHash=e89c9b0855."><meta name="citation_reference" content="ARRFLEX D-21: The Film Style Didial Camera, Jan. 4, 2008, www.arri.de, [online] http://www.arri.de/press/press/press—release.html?tx—ttnews[tt—news]=32&amp;tx—ttnews[backPid]=1781&amp;cHash=e89c9b0855."><meta name="citation_reference" content="ARRIFLEX D-20 Preliminary Specifications, May 31. 2005, www.arri.com, [online], http://web.archive.org/web/20050531010626/www.arri.com/entry/products.htm, pp. 1-2."><meta name="citation_reference" content="CineForm Insider-Nov. 13, 2007."><meta name="citation_reference" content="CineForm Insider—Nov. 13, 2007."><meta name="citation_reference" content="CineForm Online Workflow Solutions for Film and Video-Nov. 1, 2006."><meta name="citation_reference" content="CineForm Online Workflow Solutions for Film and Video—Nov. 1, 2006."><meta name="citation_reference" content="CineForm Raw-Dalsa and Vision Research Raw File Converters, Jul. 22, 2008, www.cineform.com, [online], http://web.archive.org/web/20080411 213717/www.cineform.com/products/TechNotes/RawConvert.htm, in 4 pages."><meta name="citation_reference" content="CineForm Raw—Dalsa and Vision Research Raw File Converters, Jul. 22, 2008, www.cineform.com, [online], http://web.archive.org/web/20080411 213717/www.cineform.com/products/TechNotes/RawConvert.htm, in 4 pages."><meta name="citation_reference" content="CineForm RAW-Technology Overview and Workflow, Apr. 13, 2006."><meta name="citation_reference" content="CineForm RAW—Technology Overview and Workflow, Apr. 13, 2006."><meta name="citation_reference" content="CinemaTechnic Camera Profiles | ARRI 16SR, 2001."><meta name="citation_reference" content="Dalsa Technology with Vision, Mar. 2003."><meta name="citation_reference" content="Digital Negative (DNG) Specification, Apr. 2008."><meta name="citation_reference" content="European Communication pursuant to Rule 114(2) EPC, issued on Mar. 30, 2010 in Application No. 08745686.9, in 5 pages."><meta name="citation_reference" content="Examination Report from Australian Patent Office in Australian Patent Application No. 2008240144."><meta name="citation_reference" content="Extended European Search Report in Application No. 08745686.9 dated Aug. 4, 2011 in 7 pages."><meta name="citation_reference" content="Gamma Correction, www.broadcastengineering.com [online], dated Jan. 1, 2005 in 5 pages."><meta name="citation_reference" content="International Search Report and Written Opinion for PCT/US2010/028808, dated Aug. 3, 2010 in 12 pages."><meta name="citation_reference" content="International Search Report of PCT Application No. PCT/US08/60126 dated Jul. 7, 2008."><meta name="citation_reference" content="JPEG 2000 still image coding versus other standards, Jul. 2000."><meta name="citation_reference" content="Mitani, K; Shimamoto, H; Fujita, Y; A 4 K×2 K-pixel color image pickup system; IEICE Transactions on Information and Systems; E82D (8): 1219-1227; Aug. 1999."><meta name="citation_reference" content="Mitani, K; Sugawara, M; Shimamoto, H; Yamashita, T; Okano, F; Ultrahigh-definition color video camera system with 4K-scanning lines; Sensors and Camera Systems for Scientific, Industrial, and Digital Photography Applications IV, 5017: 159-166, 2003."><meta name="citation_reference" content="New Zealand Examination Report in Application No. 580171 dated Feb. 22, 2011 in 2 pages."><meta name="citation_reference" content="Non-Patent Literature (NPL), datedJan. 29, 2007, by Michael D. Smith and John Villasenor, titled &quot;Constant Quality JPEG2000 Rate Control for Digital Cinema&quot;, SPIE-IS&amp;T/vol. 6508 65081B-1."><meta name="citation_reference" content="PHANTOM 65 the world&#39;s first 65mm digital cinema, Nov. 22, 2006."><meta name="citation_reference" content="PHANTOM 65, Feb. 4, 2007, www.visionresearch.com, [online], http://web.archive.org/web/20070204110551/www.visionresearch.com/index.cfm?sector=htm/files&amp;page=camera-65-new, pp. 1-2."><meta name="citation_reference" content="PHANTOM 65, Feb. 4, 2007, www.visionresearch.com, [online], http://web.archive.org/web/20070204110551/www.visionresearch.com/index.cfm?sector=htm/files&amp;page=camera—65—new, pp. 1-2."><meta name="citation_reference" content="Silicon Imaging SI-2K MINI Full Specifications, May 23, 2007, www.siliconimaging.com, [online], http://web.archive.org/web/20070523223217/www.siliconimaging.com/DigitalCinema/SI-2K-full-specifications.html, pp. 1-2."><meta name="citation_reference" content="Silicon Imaging SI-2K MINI Full Specifications, May 23, 2007, www.siliconimaging.com, [online], http://web.archive.org/web/20070523223217/www.siliconimaging.com/DigitalCinema/SI—2K—full—specifications.html, pp. 1-2."><meta name="citation_reference" content="Silicon Imaging Support: Frequently-Asked-Questions, Dec. 17, 2008, www.siliconimaging.com, [online], http://web.archive.org/web/20071212165310/www.siliconimaging.com/DigitalCinema/SiliconImaging-faq.html, in 12 pages."><meta name="citation_reference" content="Silicon Imaging Support: Frequently-Asked-Questions, Dec. 17, 2008, www.siliconimaging.com, [online], http://web.archive.org/web/20071212165310/www.siliconimaging.com/DigitalCinema/SiliconImaging—faq.html, in 12 pages."><meta name="citation_reference" content="Smith, Michael D; Villasenor, John; Constant quality JPEG2000 rate control for digital cinema; Source: Proceedings of SPIE-The International Society for Optical Engineering, v 6508, n Part 1, 2007, Conference: Visual Communications and Image Processing 2007, Jan. 30, 2007-Feb. 1, 2007."><meta name="citation_reference" content="Smith, Michael D; Villasenor, John; Constant quality JPEG2000 rate control for digital cinema; Source: Proceedings of SPIE—The International Society for Optical Engineering, v 6508, n Part 1, 2007, Conference: Visual Communications and Image Processing 2007, Jan. 30, 2007-Feb. 1, 2007."><meta name="citation_reference" content="Title: Silicon Imaging Support: Frequently-Asked-Questions, Aug. 13, 2008, www.siliconimaging.com, [online], http://web.archive.org/web/20080610162715/www.siliconimaging.com/DigitalCinema/SiliconImaging-faq.html, in 14 pages."><meta name="citation_reference" content="Title: Silicon Imaging Support: Frequently-Asked-Questions, Aug. 13, 2008, www.siliconimaging.com, [online], http://web.archive.org/web/20080610162715/www.siliconimaging.com/DigitalCinema/SiliconImaging—faq.html, in 14 pages."><meta name="citation_patent_number" content="US:8174560"><meta name="citation_patent_application_number" content="US:12/101,882"><link rel="canonical" href="http://www.google.com/patents/US8174560"/><meta property="og:url" content="http://www.google.com/patents/US8174560"/><meta name="title" content="Patent US8174560 - Video camera"/><meta name="description" content="A video camera can be configured to highly compress video data in a visually lossless manner. The camera can be configured to transform blue and red image data in a manner that enhances the compressibility of the data. The data can then be compressed and stored in this form. This allows a user to reconstruct the red and blue data to obtain the original raw data for a modified version of the original raw data that is visually lossless when demosaiced. Additionally, the data can be processed in a manner in which the green image elements are demosaiced first and then the red and blue elements are reconstructed based on values of the demosaiced green image elements."/><meta property="og:title" content="Patent US8174560 - Video camera"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("fGvoU46oA6LTsQSxq4FQ"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407291699.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("NLD"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("fGvoU46oA6LTsQSxq4FQ"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407291699.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("NLD"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us8174560?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US8174560"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=IqE_BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS8174560&amp;usg=AFQjCNHUyC0T8PlzeGJv9eXNXweNVDB2SA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US8174560.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US8174560.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20080291319"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US8174560"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US8174560" style="display:none"><span itemprop="description">A video camera can be configured to highly compress video data in a visually lossless manner. The camera can be configured to transform blue and red image data in a manner that enhances the compressibility of the data. The data can then be compressed and stored in this form. This allows a user to reconstruct...</span><span itemprop="url">http://www.google.com/patents/US8174560?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US8174560 - Video camera</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US8174560 - Video camera" title="Patent US8174560 - Video camera"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US8174560 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 12/101,882</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">May 8, 2012</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Apr 11, 2008</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Apr 11, 2007</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2683636A1">CA2683636A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2683636C">CA2683636C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2831698A1">CA2831698A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101689357A">CN101689357A</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2145330A1">EP2145330A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2145330A4">EP2145330A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2145330B1">EP2145330B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8358357">US8358357</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20080291319">US20080291319</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120294582">US20120294582</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120301102">US20120301102</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2008128112A1">WO2008128112A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">101882, </span><span class="patent-bibdata-value">12101882, </span><span class="patent-bibdata-value">US 8174560 B2, </span><span class="patent-bibdata-value">US 8174560B2, </span><span class="patent-bibdata-value">US-B2-8174560, </span><span class="patent-bibdata-value">US8174560 B2, </span><span class="patent-bibdata-value">US8174560B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22James+Jannard%22">James Jannard</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Thomas+Graeme+Nattress%22">Thomas Graeme Nattress</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Red.Com,+Inc.%22">Red.Com, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US8174560.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8174560.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8174560.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (104),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (36),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (6),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (13),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (4)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/8174560&usg=AFQjCNH1hsxciWKFZet-z1ztvLndhjvCCQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D8174560&usg=AFQjCNEkhHe1eOjqL6QD4q3ToeKi1OOZNQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D8174560B2%26KC%3DB2%26FT%3DD&usg=AFQjCNFy-luqn-hCrDk8vxeWnIBCOfFCbA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT111775540" lang="EN" load-source="patent-office">Video camera</invention-title></span><br><span class="patent-number">US 8174560 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA95250515" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">A video camera can be configured to highly compress video data in a visually lossless manner. The camera can be configured to transform blue and red image data in a manner that enhances the compressibility of the data. The data can then be compressed and stored in this form. This allows a user to reconstruct the red and blue data to obtain the original raw data for a modified version of the original raw data that is visually lossless when demosaiced. Additionally, the data can be processed in a manner in which the green image elements are demosaiced first and then the red and blue elements are reconstructed based on values of the demosaiced green image elements.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(19)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00014.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00014.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00015.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00015.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00016.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00016.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00017.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00017.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8174560B2/US08174560-20120508-D00018.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8174560B2/US08174560-20120508-D00018.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(12)</span></span></div><div class="patent-text"><div mxw-id="PCLM40657434" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A video camera comprising:
<div class="claim-text">a portable housing;</div>
<div class="claim-text">a lens assembly supported by the housing and configured to focus light;</div>
<div class="claim-text">a light sensitive device configured to convert the focused light into raw image data with a resolution of at least 2 k at a frame rate of at least about twenty-three frames per second;</div>
<div class="claim-text">a memory device; and</div>
<div class="claim-text">an image processing system configured to compress and store in the memory device the raw image data at a compression ratio of at least six to one and remain substantially visually lossless, and at a rate of at least about 23 frames per second.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. A video camera according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the light sensitive device includes a first group of sensor cells configured to detect a first color, a second group of sensor cells configured to detect a second color, and a third group of sensor cells configured to detect a third color, the third group of sensor cells comprising twice as many sensor cells as the second group of sensor cells.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. A video camera according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the memory device is disposed within the housing.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. A video camera according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the memory device is supported on the outside of the housing.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. A video camera according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the memory device is connected to the housing with a flexible cable.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. A method of recording a motion video with a camera, the method comprising:
<div class="claim-text">guiding light onto a light sensitive device of a camera;</div>
<div class="claim-text">converting the light received by the light sensitive device into raw digital image data having a horizontal resolution of at least 2 k at a rate of at least greater than twenty three frames per second;</div>
<div class="claim-text">compressing the raw digital image data into compressed digital image data such that the data remains substantially visually lossless upon decompression; and</div>
<div class="claim-text">recording the compressed digital image data at a rate of at least about 23 frames per second onto a storage device of the camera.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the step of compressing the raw digital image data comprises compressing the raw digital image data to an effective compression ratio of at least 6 to 1.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the step of compressing the raw digital image data comprises compressing the raw digital image data with an effective compression ratio of at least about 12:1.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the step of recording comprises storing the compressed digital image data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the step of recording comprises recording the compressed digital image data at a rate of at least about 23.976 frames per second onto the storage device.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. A video camera comprising:
<div class="claim-text">a lens assembly supported by the housing and configured to focus light;</div>
<div class="claim-text">a light sensitive device configured to convert the focused light into a signal of raw image data representing the focused light and having a resolution of at least 2 k;</div>
<div class="claim-text">a memory device; and</div>
<div class="claim-text">means for compressing and recording the raw image data in the memory device at a frame rate of at least about 23 frames per second such that the image data remains substantially visually lossless upon decompression.</div>
</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. A video camera comprising:
<div class="claim-text">a portable housing having at least one handle configured to allow a user to manipulate the orientation with respect to at least one degree of movement of the housing during a video recording operation of the camera;</div>
<div class="claim-text">a lens assembly comprising at least one lens supported by the housing and configured to focus light at a plane disposed inside the housing;</div>
<div class="claim-text">a light sensitive device configured to convert the focused light into raw image data with a horizontal resolution of at least 2 k and at a frame rate of at least about twenty three frames per second;</div>
<div class="claim-text">a memory device configured to store video image data;</div>
<div class="claim-text">an image processing system configured to compress and store in the memory device the raw image data at a compression ratio of at least six to one and remain substantially visually lossless, and at a rate of at least about 23 frames per second. </div>
</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES46125058" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND</heading> <p num="p-0002">1. Field of the Inventions</p>
    <p num="p-0003">The present inventions are directed to digital cameras, such as those for capturing still or moving pictures, and more particularly, to digital cameras that compress image data.</p>
    <p num="p-0004">2. Description of the Related Art</p>
    <p num="p-0005">Despite the availability of digital video cameras, the producers of major motion pictures and some television broadcast media continue to rely film cameras. The film used for such provides video editors with very high resolution images that can be edited by conventional means. More recently, however, such film is often scanned, digitized and digitally edited.</p>
    <heading>SUMMARY OF THE INVENTIONS</heading> <p num="p-0006">Although some currently available digital video cameras include high resolution image sensors, and thus output high resolution video, the image processing and compression techniques used on board such cameras are too lossy and thus eliminate too much raw image data to be acceptable in the high end portions of the market noted above. An aspect of at least one of the embodiments disclosed herein includes the realization that video quality that is acceptable for the higher end portions of the markets noted above, such as the major motion picture market, can be satisfied by cameras that can capture and store raw or substantially raw video data having a resolution of at least about 2 k and at a frame rate of at least about 23 frames per second.</p>
    <p num="p-0007">Thus, in accordance with an embodiment, a video camera can comprise a portable housing, and a lens assembly supported by the housing and configured to focus light. A light sensitive device can be configured to convert the focused light into raw image data with a resolution of at least 2 k at a frame rate of at least about twenty-three frames per second. The camera can also include a memory device and an image processing system configured to compress and store in the memory device the raw image data at a compression ratio of at least six to one and remain substantially visually lossless, and at a rate of at least about 23 frames per second.</p>
    <p num="p-0008">In accordance with another embodiment, a method of recording a motion video with a camera can comprise guiding light onto a light sensitive device. The method can also include converting the light received by the light sensitive device into raw digital image data at a rate of at least greater than twenty three frames per second, compressing the raw digital image data, and recording the raw image data at a rate of at least about 23 frames per second onto a storage device.</p>
    <p num="p-0009">In accordance with yet another embodiment, a video camera can comprise a lens assembly supported by the housing and configured to focus light and a light sensitive device configured to convert the focused light into a signal of raw image data representing the focused light. The camera can also include a memory device and means for compressing and recording the raw image data at a frame rate of at least about 23 frames per second.</p>
    <p num="p-0010">In accordance with yet another embodiment, a video camera can comprise a portable housing having at least one handle configured to allow a user to manipulate the orientation with respect to at least one degree of movement of the housing during a video recording operation of the camera. A lens assembly can comprise at least one lens supported by the housing and configured to focus light at a plane disposed inside the housing. A light sensitive device can be configured to convert the focused light into raw image data with a horizontal resolution of at least 2 k and at a frame rate of at least about twenty three frames per second. A memory device can also be configured to store video image data. An image processing system can be configured to compress and store in the memory device the raw image data at a compression ratio of at least six to one and remain substantially visually lossless, and at a rate of at least about 23 frames per second.</p>
    <p num="p-0011">Another aspect of at least one of the inventions disclosed herein includes the realization that because the human eye is more sensitive to green wavelengths than any other color, green image data based modification of image data output from an image sensor can be used to enhance compressibility of the data, yet provide a higher quality video image. One such technique can include subtracting the magnitude of green light detected from the magnitudes of red and/or blue light detected prior to compressing the data. This can convert the red and/or blue image data into a more compressible form. For example, in the known processes for converting gamma corrected RGB data to Y′CbCr, the image is “decorrelated”, leaving most of the image data in the Y′ (a.k.a. “luma”), and as such, the remaining chroma components are more compressible. However, the known techniques for converting to the Y′CbCr format cannot be applied directly to Bayer pattern data because the individual color data is not spatially correlated and Bayer pattern data includes twice as much green image data as blue or red image data. The processes of green image data subtraction, in accordance with some of the embodiments disclosed herein, can be similar to the Y′CbCr conversion noted above in that most of the image data is left in the green image data, leaving the remaining data in a more compressible form.</p>
    <p num="p-0012">Further, the process of green image data subtraction can be reversed, preserving all the original raw data. Thus, the resulting system and method incorporating such a technique can provide lossless or visually lossless and enhanced compressibility of such video image data.</p>
    <p num="p-0013">Thus, in accordance with an embodiment, a video camera can comprise a lens assembly supported by the housing and configured to focus light and a light sensitive device configured to convert the focused light into a raw signal of image data representing at least first, second, and third colors of the focused light. An image processing module can be configured to modify image data of at least one of the first and second colors based on the image data of the third color. Additionally, the video camera can include a memory device and a compression device configured to compress the image data of the first, second, and third colors and to store the compressed image data on the memory device.</p>
    <p num="p-0014">In accordance with another embodiment, a method of processing an image can be provided. The method can include converting an image and into first image data representing a first color, second image data representing a second color, and third image data representing a third color, modifying at least the first image data and the second image data based on the third image data, compressing the third image data and the modified first and second image data, and storing the compressed data.</p>
    <p num="p-0015">In accordance with yet another embodiment, a video camera can comprise a lens assembly supported by the housing and configured to focus light. A light sensitive device can be configured to convert the focused light into a raw signal of image data representing at least first, second, and third colors of the focused light. The camera can also include means for modifying image data of at least one of the first and second colors based on the image data of the third color, a memory device, and a compression device configured to compress the image data of the first, second, and third colors and to store the compressed image data on the memory device.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0016"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a system that can include hardware and/or can be configured to perform methods for processing video image data in accordance with an embodiment.</p>
      <p num="p-0017"> <figref idrefs="DRAWINGS">FIG. 2</figref> is an optional embodiment of a housing for the camera schematically illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
      <p num="p-0018"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a schematic layout of an image sensor having a Bayer Pattern Filter that can be used with the system illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
      <p num="p-0019"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a schematic block diagram of an image processing module that can be used in the system illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
      <p num="p-0020"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a schematic layout of the green image data from the green sensor cells of the image sensor of <figref idrefs="DRAWINGS">FIG. 3</figref>.</p>
      <p num="p-0021"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a schematic layout of the remaining green image data of <figref idrefs="DRAWINGS">FIG. 5</figref> after an optional process of deleting some of the original green image data.</p>
      <p num="p-0022"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a schematic layout of the red, blue, and green image data of <figref idrefs="DRAWINGS">FIG. 5</figref> organized for processing in the image processing module of <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
      <p num="p-0023"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a flowchart illustrating an image data transformation technique that can be used with the system illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
      <p num="p-0024"> <figref idrefs="DRAWINGS">FIG. 8A</figref> is a flowchart illustrating a modification of the image data transformation technique of <figref idrefs="DRAWINGS">FIG. 8</figref> that can also be used with the system illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
      <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a schematic layout of blue image data resulting from an image transformation process of <figref idrefs="DRAWINGS">FIG. 8</figref>.</p>
      <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a schematic layout of red image data resulting from an image transformation process of <figref idrefs="DRAWINGS">FIG. 8</figref>.</p>
      <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates an exemplary optional transform that can be applied to the image data for gamma correction.</p>
      <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 12</figref> is a flowchart of a control routine that can be used with the system of <figref idrefs="DRAWINGS">FIG. 1</figref> to decompress and demosaic image data.</p>
      <p num="p-0029"> <figref idrefs="DRAWINGS">FIG. 12A</figref> is a flowchart illustrating a modification of the control routine of <figref idrefs="DRAWINGS">FIG. 12</figref> that can also be used with the system illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
      <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a schematic layout of green image data having been decompressed and demosaiced according to the flowchart of <figref idrefs="DRAWINGS">FIG. 12</figref>.</p>
      <p num="p-0031"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a schematic layout of half of the original green image data from <figref idrefs="DRAWINGS">FIG. 13</figref>, having been decompressed and demosaiced according to the flowchart of <figref idrefs="DRAWINGS">FIG. 12</figref>.</p>
      <p num="p-0032"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a schematic layout of blue image data having been decompressed according to the flowchart of <figref idrefs="DRAWINGS">FIG. 12</figref>.</p>
      <p num="p-0033"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a schematic layout of blue image data of <figref idrefs="DRAWINGS">FIG. 15</figref> having been demosaiced according to the flowchart of <figref idrefs="DRAWINGS">FIG. 12</figref>.</p>
    </description-of-drawings> <heading>DETAILED DESCRIPTION OF EMBODIMENTS</heading> <p num="p-0034"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a schematic diagram of a camera having image sensing, processing, and compression modules, described in the context of a video camera for moving pictures. The embodiments disclosed herein are described in the context of a video camera having a single sensor device with a Bayer pattern filter because these embodiments have particular utility in this context. However, the embodiments and inventions herein can also be applied to cameras having other types of image sensors (e.g., CMY Bayer as well as other non-Bayer patterns), other numbers of image sensors, operating on different image format types, and being configured for still and/or moving pictures. Thus, it is to be understood that the embodiments disclosed herein are exemplary but nonlimiting embodiments, and thus, the inventions disclosed herein are not limited to the disclosed exemplary embodiments.</p>
    <p num="p-0035">With continued reference to <figref idrefs="DRAWINGS">FIG. 1</figref>, a camera <b>10</b> can include a body or housing <b>12</b> configured to support a system <b>14</b> configured to detect, process, and optionally store and/or replay video image data. For example, the system <b>14</b> can include optics hardware <b>16</b>, an image sensor <b>18</b>, an image processing module <b>20</b>, a compression module <b>22</b>, and a storage device <b>24</b>. Optionally, the camera <b>10</b> can also include a monitor module <b>26</b>, a playback module <b>28</b>, and a display <b>30</b>.</p>
    <p num="p-0036"> <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates a nonlimiting exemplary embodiment of the camera <b>10</b>. As shown in <figref idrefs="DRAWINGS">FIG. 2</figref>, the optics hardware <b>16</b> can be supported by the housing <b>12</b> in a manner that leaves it exposed at its outer surface. In some embodiments, the system <b>14</b> is supported within the housing <b>12</b>. For example, the image sensor <b>18</b>, image processing module <b>20</b>, and the compression module <b>22</b> can be housed within the housing <b>12</b>. The storage device <b>24</b> can be mounted in the housing <b>12</b>. Additionally, in some embodiments, the storage device <b>24</b> can be mounted to an exterior of the housing <b>12</b> and connected to the remaining portions of the system <b>14</b> through any type of known connector or cable. Additionally, the storage device <b>24</b> can be connected to the housing <b>12</b> with a flexible cable, thus allowing the storage device <b>24</b> to be moved somewhat independently from the housing <b>12</b>. For example, with such a flexible cable connection, the storage device <b>24</b> can be worn on a belt of a user, allowing the total weight of the housing <b>12</b> to be reduced. Further, in some embodiments, the housing can include one or more storage devices <b>24</b> inside and mounted to its exterior. Additionally, the housing <b>12</b> can also support the monitor module <b>26</b>, and playbook module <b>28</b>. Additionally, in some embodiments, the display <b>30</b> can be configured to be mounted to an exterior of the housing <b>12</b>.</p>
    <p num="p-0037">The optics hardware <b>16</b> can be in the form of a lens system having at least one lens configured to focus an incoming image onto the image sensor <b>18</b>. The optics hardware <b>16</b>, optionally, can be in the form of a multi-lens system providing variable zoom, aperture, and focus. Additionally, the optics hardware <b>16</b> can be in the form of a lens socket supported by the housing <b>12</b> and configured to receive a plurality of different types of lens systems for example, but without limitation, the optics hardware <b>16</b> include a socket configured to receive various sizes of lens systems including a 50-100 millimeter (F2.8) zoom lens, an 18-50 millimeter (F2.8) zoom lens, a 300 millimeter (F2.8) lens, 15 millimeter (F2.8) lens, 25 millimeter (F1.9) lens, 35 millimeter (F1.9) lens, 50 millimeter (F1.9) lens, 85 millimeter (F1.9) lens, and/or any other lens. As noted above, the optics hardware <b>16</b> can be configured such that despite which lens is attached thereto, images can be focused upon a light-sensitive surface of the image sensor <b>18</b>.</p>
    <p num="p-0038">The image sensor <b>18</b> can be any type of video sensing device, including, for example, but without limitation, CCD, CMOS, vertically-stacked CMOS devices such as the Foveon® sensor, or a multi-sensor array using a prism to divide light between the sensors. In some embodiments, the image sensor <b>18</b> can include a CMOS device having about 12 million photocells. However, other size sensors can also be used. In some configurations, camera <b>10</b> can be configured to output video at “2 k” (e.g., 2048×1152 pixels), “4 k” (e.g., 4,096×2,540 pixels), “4.5 k” horizontal resolution or greater resolutions. As used herein, in the terms expressed in the format of xk (such as 2 k and 4 k noted above), the “x” quantity refers to the approximate horizontal resolution. As such, “4 k” resolution corresponds to about 4000 or more horizontal pixels and “2 k” corresponds to about 2000 or more pixels. Using currently commercially available hardware, the sensor can be as small as about 0.5 inches (8 mm), but it can be about 1.0 inches, or larger. Additionally, the image sensor <b>18</b> can be configured to provide variable resolution by selectively outputting only a predetermined portion of the sensor <b>18</b>. For example, the sensor <b>18</b> and/or the image processing module can be configured to allow a user to identify the resolution of the image data output.</p>
    <p num="p-0039">The camera <b>10</b> can also be configured to downsample and subsequently process the output of the sensor <b>18</b> to yield video output at 2K, 1080 p, 720 p, or any other resolution. For example, the image data from the sensor <b>18</b> can be “windowed”, thereby reducing the size of the output image and allowing for higher readout speeds. However, other size sensors can also be used. Additionally, the camera <b>10</b> can be configured to upsample the output of the sensor <b>18</b> to yield video output at higher resolutions.</p>
    <p num="p-0040">With reference to <figref idrefs="DRAWINGS">FIGS. 1 and 3</figref>, in some embodiments, the sensor <b>18</b> can include a Bayer pattern filter. As such, the sensor <b>18</b>, by way of its chipset (not shown) outputs data representing magnitudes of red, green, or blue light detected by individual photocells of the image sensor <b>18</b>. <figref idrefs="DRAWINGS">FIG. 3</figref> schematically illustrates the Bayer pattern output of the sensor <b>18</b>. In some embodiments, for example, as shown in <figref idrefs="DRAWINGS">FIG. 3</figref>, the Bayer pattern filter has twice as many green elements as the number of red elements and the number of blue elements. The chipset of the image sensor <b>18</b> can be used to read the charge on each element of the image sensor and thus output a stream of values in the well-known RGB format output.</p>
    <p num="p-0041">With continued reference to <figref idrefs="DRAWINGS">FIG. 4</figref>, the image processing module <b>20</b> optionally can be configured to format the data stream from the image sensor <b>18</b> in any known manner. In some embodiments, the image processing module <b>20</b> can be configured to separate the green, red, and blue image data into three or four separate data compilations. For example, the image processing module <b>20</b> can be configured to separate the red data into one data element, the blue data into one blue data element, and the green data into one green data element. For example, with reference to <figref idrefs="DRAWINGS">FIG. 4</figref>, the image processing module <b>20</b> can include a red data processing module <b>32</b>, a blue data image processing module <b>34</b>, and a first green image data processing module <b>36</b>.</p>
    <p num="p-0042">As noted above, however, the Bayer pattern data illustrated in <figref idrefs="DRAWINGS">FIG. 3</figref>, has twice as many green pixels as the other two colors. <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates a data component with the blue and red data removed, leaving only the original green image data.</p>
    <p num="p-0043">In some embodiments, the camera <b>10</b> can be configured to delete or omit some of the green image data. For example, in some embodiments, the image processing module <b>20</b> can be configured to delete ½ of the green image data so that the total amount of green image data is the same as the amounts of blue and red image data. For example, <figref idrefs="DRAWINGS">FIG. 6</figref> illustrates the remaining data after the image processing module <b>20</b> deletes ½ of the green image data. In the illustrated embodiment of <figref idrefs="DRAWINGS">FIG. 6</figref>, the rows n−3, n−1, n+1, and n+3 have been deleted. This is merely one example of the pattern of green image data that can be deleted. Other patterns and other amounts of green image data can also be deleted.</p>
    <p num="p-0044">In some alternatives, the camera <b>10</b> can be configured to delete ½ of the green image data after the red and blue image data has been transformed based on the green image data. This optional technique is described below following the description of the subtraction of green image data values from the other color image data.</p>
    <p num="p-0045">Optionally, the image processing module <b>20</b> can be configured to selectively delete green image data. For example, the image processing module <b>20</b> can include a deletion analysis module (not shown) configured to selectively determine which green image data to delete. For example, such a deletion module can be configured to determine if deleting a pattern of rows from the green image data would result in aliasing artifacts, such as Moiré lines, or other visually perceptible artifacts. The deletion module can be further configured to choose a pattern of green image data to delete that would present less risk of creating such artifacts. For example, the deletion module can be configured to choose a green image data deletion pattern of alternating vertical columns if it determines that the image captured by the image sensor <b>18</b> includes an image feature characterized by a plurality of parallel horizontal lines. This deletion pattern can reduce or eliminate artifacts, such as Moiré lines, that might have resulted from a deletion pattern of alternating lines of image data parallel to the horizontal lines detected in the image.</p>
    <p num="p-0046">However, this merely one exemplary, non-limiting example of the types of image features and deletion patterns that can be used by the deletion module. The deletion module can also be configured to detect other image features and to use other image data deletion patterns, such as for example, but without limitation, deletion of alternating rows, alternating diagonal lines, or other patterns. Additionally, the deletion module can be configured to delete portions of the other image data, such as the red and blue image data, or other image data depending on the type of sensor used.</p>
    <p num="p-0047">Additionally, the camera <b>10</b> can be configured to insert a data field into the image data indicating what image data has been deleted. For example, but without limitation, the camera <b>10</b> can be configured to insert a data field into the beginning of any video clip stored into the storage device <b>24</b>, indicating what data has been deleted in each of the “frames” of the video clip. In some embodiments, the camera can be configured to insert a data field into each frame captured by the sensor <b>18</b>, indicating what image data has been deleted. For example, in some embodiments, where the image processing module <b>20</b> is configured to delete ½ of the green image data in one deletion pattern, the data field can be as small as a single bit data field, indicating whether or not image data has been deleted. Since the image processing module <b>20</b> is configured to delete data in only one pattern, a single bit is sufficient to indicate what data has been deleted.</p>
    <p num="p-0048">In some embodiments, as noted above, the image processing module <b>20</b> can be configured to selectively delete image data in more than one pattern. Thus, the image data deletion field can be larger, including a sufficient number of values to provide an indication of which of the plurality of different image data deletion patterns was used. This data field can be used by downstream components and or processes to determine to which special positions the remaining image data corresponds.</p>
    <p num="p-0049">In some embodiments, the image processing module can be configured to retain all of the raw green image data, e.g., the data shown in <figref idrefs="DRAWINGS">FIG. 5</figref>. In such embodiments, the image processing module can include one or more green image data processing modules.</p>
    <p num="p-0050">As noted above, in known Bayer pattern filters, there are twice as many green elements as the number of red elements and the number of blue elements. In other words, the red elements comprise 25% of the total Bayer pattern array, the blue elements corresponded 25% of the Bayer pattern array and the green elements comprise 50% of the elements of the Bayer pattern array. Thus, in some embodiments, where all of the green image data is retained, the image processing module <b>20</b> can include a second green data image processing module <b>38</b>. As such, the first green data image processing module <b>36</b> can process half of the green elements and the second green image data processing module <b>38</b> can process the remaining green elements. However, the present inventions can be used in conjunction with other types of patterns, such as for example, but without limitation, CMY and RGBW.</p>
    <p num="p-0051"> <figref idrefs="DRAWINGS">FIG. 7</figref> includes schematic illustrations of the red, blue and two green data components processed by modules <b>32</b>, <b>34</b>, <b>36</b>, and <b>38</b> (<figref idrefs="DRAWINGS">FIG. 4</figref>). This can provide further advantages because the size and configuration of each of these modules can be about the same since they are handling about the same amount of data. Additionally, the image processing module <b>20</b> can be selectively switched between modes in which is processes all of the green image data (by using both modules <b>36</b> and <b>38</b>) and modes where ½ of the green image data is deleted (in which it utilizes only one of modules <b>36</b> and <b>38</b>). However, other configurations can also be used.</p>
    <p num="p-0052">Additionally, in some embodiments, the image processing module <b>20</b> can include other modules and/or can be configured to perform other processes, such as, for example, but without limitation, gamma correction processes, noise filtering processes, etc.</p>
    <p num="p-0053">Additionally, in some embodiments, the image processing module <b>20</b> can be configured to subtract a value of a green element from a value of a blue element and/or red element. As such, in some embodiments, when certain colors are detected by the image sensor <b>18</b>, the corresponding red or blue element can be reduced to zero. For example, in many photographs, there can be large areas of black, white, or gray, or a color shifted from gray toward the red or blue colors. Thus, if the corresponding pixels of the image sensor <b>18</b> have sensed an area of gray, the magnitude of the green, red, and blue, would be about equal. Thus, if the green value is subtracted from the red and blue values, the red and blue values will drop to zero or near zero. Thus, in a subsequent compression process, there will be more zeros generated in pixels that sense a black, white, or gray area and thus the resulting data will be more compressible. Additionally, the subtraction of green from one or both of the other colors can make the resulting image data more compressible for other reasons.</p>
    <p num="p-0054">Such a technique can help achieve a higher effective compression ratio and yet remain visually lossless due to its relationship to the entropy of the original image data. For example, the entropy of an image is related to the amount of randomness in the image. The subtraction of image data of one color, for example, from image data of the other colors can reduce the randomness, and thus reduce the entropy of the image data of those colors, thereby allowing the data to be compressed at higher compression ratios with less loss. Typically, an image is not a collection of random color values. Rather, there is often a certain degree of correlation between surrounding picture elements. Thus, such a subtraction technique can use the correlation of picture elements to achieve better compression. The amount of compression will depend, at least in part, on the entropy of the original information in the image.</p>
    <p num="p-0055">In some embodiments, the magnitudes subtracted from a red or blue pixel can be the magnitude of the value output from a green pixel adjacent to the subject red or blue pixel. Further, in some embodiments, the green magnitude subtracted from the red or blue elements can be derived from an average of the surrounding green elements. Such techniques are described in greater detail below. However, other techniques can also be used.</p>
    <p num="p-0056">Optionally, the image processing module <b>20</b> can also be configured to selectively subtract green image data from the other colors. For example, the image processing module <b>20</b> can be configured to determine if subtracting green image data from a portion of the image data of either of the other colors would provide better compressibility or not. In this mode, the image processing module <b>20</b> can be configured to insert flags into the image data indicating what portions of the image data has been modified (by e.g., green image data subtraction) and which portions have not been so modified. With such flags, a downstream demosaicing/reconstruction component can selectively add green image values back into the image data of the other colors, based on the status of such data flags.</p>
    <p num="p-0057">Optionally, image processing module <b>20</b> can also include a further data reduction module (not shown) configured to round values of the red and blue data. For example, if, after the subtraction of green magnitudes, the red or blue data is near zero (e.g., within one or two on an 8-bit scale ranging from 0-255 or higher magnitudes for a higher resolution system). For example, the sensor <b>18</b> can be a 12-bit sensor outputting red, blue, and green data on a scale of 0-4095. Any rounding or filtering of the data performed the rounding module can be adjusted to achieve the desired effect. For example, rounding can be performed to a lesser extent if it is desired to have lossless output and to a greater extent if some loss or lossy output is acceptable. Some rounding can be performed and still result in a visually lossless output. For example, on a 8-bit scale, red or blue data having absolute value of up to 2 or 3 can be rounded to 0 and still provide a visually lossless output. Additionally, on a 12-bit scale, red or blue data having an absolute value of up to 10 to 20 can be rounded to 0 and still provide visually lossless output.</p>
    <p num="p-0058">Additionally, the magnitudes of values that can be rounded to zero, or rounded to other values, and still provide a visually lossless output depends on the configuration of the system, including the optics hardware <b>16</b>, the image sensor <b>18</b>, the resolution of the image sensor, the color resolution (bit) of the image sensor <b>18</b>, the types of filtering, anti-aliasing techniques or other techniques performed by the image processing module <b>20</b>, the compression techniques performed by the compression module <b>22</b>, and/or other parameters or characteristics of the camera <b>10</b>.</p>
    <p num="p-0059">As noted above, in some embodiments, the camera <b>10</b> can be configured to delete ½ of the green image data after the red and blue image data has been transformed based on the green image data. For example, but without limitation, the processor module <b>20</b> can be configured to delete ½ of the green image data after the average of the magnitudes of the surrounding green data values have been subtracted from the red and blue data values. This reduction in the green data can reduce throughput requirements on the associated hardware. Additionally, the remaining green image data can be used to reconstruct the red and blue image data, described in greater detail below with reference to <figref idrefs="DRAWINGS">FIGS. 14 and 16</figref>.</p>
    <p num="p-0060">As noted above, the camera <b>10</b> can also include a compression module <b>22</b>. The compression module <b>22</b> can be in the form of a separate chip or it can be implemented with software and another processor. For example, the compression module <b>22</b> can be in the form of a commercially available compression chip that performs a compression technique in accordance with the JPEG 2000 standard, or other compression techniques.</p>
    <p num="p-0061">The compression module can be configured to perform any type of compression process on the data from the image processing module <b>20</b>. In some embodiments, the compression module <b>22</b> performs a compression technique that takes advantage of the techniques performed by the image processing module <b>20</b>. For example, as noted above, the image processing module <b>20</b> can be configured to reduce the magnitude of the values of the red and blue data by subtracting the magnitudes of green image data, thereby resulting in a greater number of zero values, as well as other effects. Additionally, the image processing module <b>20</b> can perform a manipulation of raw data that uses the entropy of the image data. Thus, the compression technique performed by the compression module <b>22</b> can be of a type that benefits from the presence of larger strings of zeros to reduce the size of the compressed data output therefrom.</p>
    <p num="p-0062">Further, the compression module <b>22</b> can be configured to compress the image data from the image processing module <b>20</b> to result in a visually lossless output. For example, firstly, the compression module can be configured to apply any known compression technique, such as, but without limitation, JPEG 2000, MotionJPEG, any DCT based codec, any codec designed for compressing RGB image data, H.264, MPEG4, Huffman, or other techniques.</p>
    <p num="p-0063">Depending on the type of compression technique used, the various parameters of the compression technique can be set to provide a visually lossless output. For example, many of the compression techniques noted above can be adjusted to different compression rates, wherein when decompressed, the resulting image is better quality for lower compression rates and lower quality for higher compression rates. Thus, the compression module can be configured to compress the image data in a way that provides a visually lossless output, or can be configured to allow a user to adjust various parameters to obtain a visually lossless output. For example, the compression module <b>22</b> can be configured to compress the image data at a compression ratio of about 6:1, 7:1, 8:1 or greater. In some embodiments, the compression module <b>22</b> can be configured to compress the image data to a ratio of 12:1 or higher.</p>
    <p num="p-0064">Additionally, the compression module <b>22</b> can be configured to allow a user to adjust the compression ratio achieved by the compression module <b>22</b>. For example, the camera <b>10</b> can include a user interface that allows a user to input commands that cause the compression module <b>22</b> to change the compression ratio. Thus, in some embodiments, the camera <b>10</b> can provide for variable compression.</p>
    <p num="p-0065">As used herein, the term “visually lossless” is intended to include output that, when compared side by side with original (never compressed) image data on the same display device, one of ordinary skill in the art would not be able to determine which image is the original with a reasonable degree of accuracy, based only on a visual inspection of the images.</p>
    <p num="p-0066">With continued reference to <figref idrefs="DRAWINGS">FIG. 1</figref>, the camera <b>10</b> can also include a storage device <b>24</b>. The storage device can be in the form of any type of digital storage, such as, for example, but without limitation, hard disks, flash memory, or any other type of memory device. In some embodiments, the size of the storage device <b>24</b> can be sufficiently large to store image data from the compression module <b>22</b> corresponding to at least about 30 minutes of video at 12 mega pixel resolution, 12-bit color resolution, and at 60 frames per second. However, the storage device <b>24</b> can have any size.</p>
    <p num="p-0067">In some embodiments, the storage device <b>24</b> can be mounted on an exterior of the housing <b>12</b>. Further, in some embodiments, the storage device <b>24</b> can be connected to the other components of the system <b>14</b> through standard communication ports, including, for example, but without limitation, IEEE 1394, USB 2.0, IDE, SATA, etc. Further, in some embodiments, the storage device <b>24</b> can comprise a plurality of hard drives operating under a RAID protocol. However, any type of storage device can be used.</p>
    <p num="p-0068">With continued reference to <figref idrefs="DRAWINGS">FIG. 1</figref>, as noted above, in some embodiments, the system can include a monitor module <b>26</b> and a display device <b>30</b> configured to allow a user to view video images captured by the image sensor <b>18</b> during operation. In some embodiments, the image processing module <b>20</b> can include a subsampling system configured to output reduced resolution image data to the monitor module <b>26</b>. For example, such a subsampling system can be configured to output video image data to support 2K, 1080 p, 720 p, or any other resolution. In some embodiments, filters used for demosaicing can be adapted to also perform downsampling filtering, such that downsampling and filtering can be performed at the same time. The monitor module <b>26</b> can be configured to perform any type of demosaicing process to the data from the image processing module <b>20</b>. Thereafter, the monitor module <b>26</b> can output a demosaiced image data to the display <b>30</b>.</p>
    <p num="p-0069">The display <b>30</b> can be any type of monitoring device. For example, but without limitation, the display <b>30</b> can be a four-inch LCD panel supported by the housing <b>12</b>. For example, in some embodiments, the display <b>30</b> can be connected to an infinitely adjustable mount configured to allow the display <b>30</b> to be adjusted to any position relative to the housing <b>12</b> so that a user can view the display <b>30</b> at any angle relative to the housing <b>12</b>. In some embodiments, the display <b>30</b> can be connected to the monitor module through any type of video cables such as, for example, an RGB or YCC format video cable.</p>
    <p num="p-0070">Optionally, the playback module <b>28</b> can be configured to receive data from the storage device <b>24</b>, decompressed and demosaic the image data and then output the image data to the display <b>30</b>. In some embodiments, the monitor module <b>26</b> and the playback module <b>28</b> can be connected to the display through an intermediary display controller (not shown). As such, the display <b>30</b> can be connected with a single connector to the display controller. The display controller can be configured to transfer data from either the monitor module <b>26</b> or the playback module <b>28</b> to the display <b>30</b>.</p>
    <p num="p-0071"> <figref idrefs="DRAWINGS">FIG. 8</figref> includes a flowchart <b>50</b> illustrating the processing of image data by the camera <b>10</b>. In some embodiments, the flowchart <b>50</b> can represent a control routine stored in a memory device, such as the storage device <b>24</b>, or another storage device (not shown) within the camera <b>10</b>. Additionally, a central processing unit (CPU) (not shown) can be configured to execute the control routine. The below description of the methods corresponding to the flow chart <b>50</b> are described in the context of the processing of a single frame of video image data. Thus, the techniques can be applied to the processing of a single still image. These processes can also be applied to the processing of continuous video, e.g., frame rates of greater than 12, as well as frame rates of 20, 23.976, 24, 30, 60, and 120, or other frame rates between these frame rates or greater.</p>
    <p num="p-0072">With continued reference to <figref idrefs="DRAWINGS">FIG. 8</figref>, control routine can begin at operation block <b>52</b>. In the operation block <b>52</b>, the camera <b>10</b> can obtain sensor data. For example, with reference to <figref idrefs="DRAWINGS">FIG. 1</figref>, the image sensor <b>18</b>, which can include a Bayer Sensor and chipset, can output image data.</p>
    <p num="p-0073">For example, but without limitation, with reference to <figref idrefs="DRAWINGS">FIG. 3</figref>, the image sensor can comprise a CMOS device having a Bayer pattern filter on its light receiving surface. Thus, the focused image from the optics hardware <b>16</b> is focused on the Bayer pattern filter on the CMOS device of the image sensor <b>18</b>. <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates an example of the Bayer pattern created by the arrangement of Bayer pattern filter on the CMOS device.</p>
    <p num="p-0074">In <figref idrefs="DRAWINGS">FIG. 3</figref>, column m is the fourth column from the left edge of the Bayer pattern and row n is the fourth row from the top of the pattern. The remaining columns and rows are labeled relative to column m and row n. However, this layout is merely chosen arbitrarily for purposes of illustration, and does not limit any of the embodiments or inventions disclosed herein.</p>
    <p num="p-0075">As noted above, known Bayer pattern filters often include twice as many green elements as blue and red elements. In the pattern of <figref idrefs="DRAWINGS">FIG. 5</figref>, blue elements only appear in rows n−3, n−1, n+1, and n+3. Red elements only appear in rows n−2, n, n+2, and n+4. However, green elements appear in all rows and columns, interspersed with the red and blue elements.</p>
    <p num="p-0076">Thus, in the operation block <b>52</b>, the red, blue, and green image data output from the image sensor <b>18</b> can be received by the image processing module <b>20</b> and organized into separate color data components, such as those illustrated in <figref idrefs="DRAWINGS">FIG. 7</figref>. As shown in <figref idrefs="DRAWINGS">FIG. 7</figref>, and as described above with reference to <figref idrefs="DRAWINGS">FIG. 4</figref>, the image processing module <b>20</b> can separate the red, blue, and green image data into four separate components. <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates two green components (Green <b>1</b> and Green <b>2</b>), a blue component, and a red component. However, this is merely one exemplary way of processing image data from the image sensor <b>18</b>. Additionally, as noted above, the image processing module <b>20</b>, optionally, can arbitrarily or selectively delete ½ of the green image data.</p>
    <p num="p-0077">After the operation block <b>52</b>, the flowchart <b>50</b> can move on to operation block <b>54</b>. In the operation block <b>56</b>, the image data can be further processed. For example, optionally, any one or all of the resulting data (e.g., green <b>1</b>, green <b>2</b>, the blue image data from <figref idrefs="DRAWINGS">FIG. 9</figref>, and the red image data from <figref idrefs="DRAWINGS">FIG. 10</figref>) can be further processed.</p>
    <p num="p-0078">For example, the image data can be pre-emphasized or processed in other ways. In some embodiments, the image data can be processed to be more (mathematically) non-linear. Some compression algorithms benefit from performing such a linearization on the picture elements prior to compression. However, other techniques can also be used. For example, the image data can be processed with a linear curve, which provides essentially no emphasis.</p>
    <p num="p-0079">In some embodiments, the operation block <b>54</b> can process the image data using curve defined by the function y=x^0.5. In some embodiments, this curve can be used where the image data was, for example but without limitation, floating point data in the normalized 0-1 range. In other embodiments, for example, where the image data is 12-bit data, the image can be processed with the curve y=(x/4095)^0.5. Additionally, the image data can be processed with other curves, such as y=(x+c)^g where 0.01&lt;g&lt;1 and c is an offset, which can be 0 in some embodiments. Additionally, log curves can also be used. For example, curves in the form y=A*log(B*x+C) where A, B, and C are constants chosen to provide the desired results. Additionally, the above curves and processes can be modified to provide more linear areas in the vicinity of black, similar to those techniques utilized in the well-known Rec709 gamma curve. In applying these processes to the image data, the same processes can be applied to all of the image data, or different processes can be applied to the different colors of image data. However, these are merely exemplary curves that can be used to process the image data, or curves or transforms can also be used. Additionally, these processing techniques can be applied using mathematical functions such as those noted above, or with Look Up Tables (LUTs). Additionally, different processes, techniques, or transforms can be used for different types of image data, different ISO settings used during recording of the image data, temperature (which can affect noise levels), etc.</p>
    <p num="p-0080">After the operation block <b>54</b>, the flowchart <b>50</b> can move to an operation block <b>56</b>. In the operation block <b>56</b>, the red and blue picture elements can be transformed. For example, as noted above, green image data can be subtracted from each of the blue and red image data components. In some embodiments, a red or blue image data value can be transformed by subtracting a green image data value of at least one of the green picture elements adjacent to the red or blue picture element. In some embodiments, an average value of the data values of a plurality of adjacent green picture elements can be subtracted from the red or blue image data value. For example, but without limitation, average values of 2, 3, 4, or more green image data values can be calculated and subtracted from red or blue picture elements in the vicinity of the green picture elements.</p>
    <p num="p-0081">For example, but without limitation, with reference to <figref idrefs="DRAWINGS">FIG. 3</figref>, the raw output for the red element R<sub>m−2,n−2 </sub>is surrounded by four green picture elements G<sub>m−2,n−3</sub>, G<sub>m−1,n−2</sub>, G<sub>m−3,n−2</sub>, and G<sub>m−2,n−1</sub>. Thus, the red element R<sub>m−2,n−2 </sub>can be transformed by subtracting the average of the values of the surrounding green element as follows:
<br> <i>R</i> <sub>m,n</sub> <i>=R</i> <sub>m,n</sub>−(<i>G</i> <sub>m,n−1</sub> <i>+G</i> <sub>m+1,n</sub> <i>+G</i> <sub>m,n+1</sub> <i>+G</i> <sub>m−1,n</sub>)/4  (1)</p>
    <p num="p-0082">Similarly, the blue elements can be transformed in a similar manner by subtracting the average of the surrounding green elements as follows:
<br> <i>B</i> <sub>m+1,n+1</sub> <i>=B</i> <sub>m+1,n+1</sub>−(<i>G</i> <sub>m+1,n</sub> <i>+G</i> <sub>m+2,n+1</sub> <i>+G</i> <sub>m+1,n+2</sub> <i>+G</i> <sub>m,n+1</sub>)/4  (2)</p>
    <p num="p-0083"> <figref idrefs="DRAWINGS">FIG. 9</figref> illustrates a resulting blue data component where the original blue raw data B<sub>m−1,n−1 </sub>is transformed, the new value labeled as B′<sub>m−1,n−1 </sub>(only one value in the component is filled in and the same technique can be used for all the blue elements). Similarly, <figref idrefs="DRAWINGS">FIG. 10</figref> illustrates the red data component having been transformed in which the transformed red element R<sub>m−2,n−2 </sub>is identified as R′<sub>m−2,n−2</sub>. In this state, the image data can still be considered “raw” data. For example, the mathematical process performed on the data are entirely reversible such that all of the original values can be obtained by reversing those processes.</p>
    <p num="p-0084">With continued reference to <figref idrefs="DRAWINGS">FIG. 8</figref>, after the operation block <b>56</b>, the flowchart <b>50</b> can move on to an operation block <b>58</b>. In the operation block <b>58</b>, the resulting data, which is raw or can be substantially raw, can be further compressed to using any known compression algorithm. For example, the compression module <b>22</b> (<figref idrefs="DRAWINGS">FIG. 1</figref>) can be configured to perform such a compression algorithm. After compression, the compressed raw data can be stored in the storage device <b>24</b> (<figref idrefs="DRAWINGS">FIG. 1</figref>).</p>
    <p num="p-0085"> <figref idrefs="DRAWINGS">FIG. 8A</figref> illustrates a modification of the flowchart <b>50</b>, identified by the reference numeral <b>50</b>′. Some of the steps described above with reference to the flowchart <b>50</b> can be similar or the same as some of the corresponding steps of the flowchart <b>50</b>′ and thus are identified with the same reference numerals.</p>
    <p num="p-0086">As shown in <figref idrefs="DRAWINGS">FIG. 8A</figref>, the flowchart <b>50</b>′, in some embodiments, can optionally omit operation block <b>54</b>. In some embodiments, the flowchart <b>50</b>′ can also include an operation block <b>57</b> in which a look up table can be applied to the image data. For example, an optional look-up table, represented by the curve of <figref idrefs="DRAWINGS">FIG. 11</figref>, can be used to enhance further compression. In some embodiments, the look-up table of <figref idrefs="DRAWINGS">FIG. 11</figref> is only used for the green picture elements. In other embodiments, the look-up table can also be used for red and blue picture elements. The same look-up table may be used for the three different colors, or each color may have its own look-up table. Additionally, processes other than that represented by the curve of <figref idrefs="DRAWINGS">FIG. 11</figref> can also be applied.</p>
    <p num="p-0087">By processing the image data in the manner described above with reference to <figref idrefs="DRAWINGS">FIGS. 8 and 8A</figref>, it has been discovered that the image data from the image sensor <b>18</b> can be compressed by a compression ratio of 6 to 1 or greater and remain visually lossless. Additionally, although the image data has been transformed (e.g., by the subtraction of green image data) all of the raw image data is still available to an end user. For example, by reversing certain of the processes, all or substantially all of the original raw data can be extracted and thus further processed, filtered, and/or demosaiced using any process the user desires.</p>
    <p num="p-0088">For example, with reference to <figref idrefs="DRAWINGS">FIG. 12</figref>, the data stored in the storage device <b>24</b> can be decompressed and demosaiced. Optionally, the camera <b>10</b> can be configured to perform the method illustrated by flowchart <b>60</b>. For example, but without limitation, the playback module <b>28</b> can be configured to perform the method illustrated by flowchart <b>60</b>. However, a user can also transfer the data from the storage device <b>24</b> into a separate workstation and apply any or all of the steps and/or operations of the flowchart <b>60</b>.</p>
    <p num="p-0089">With continued reference to <figref idrefs="DRAWINGS">FIG. 12</figref>, the flowchart <b>60</b> can begin with the operation block <b>62</b>, in which the data from the storage device <b>24</b> is decompressed. For example, the decompression of the data in operation block <b>62</b> can be the reverse of the compression algorithm performed in operational block <b>58</b> (<figref idrefs="DRAWINGS">FIG. 8</figref>). After the operation block <b>62</b>, the flowchart <b>60</b> can move on to an operation block <b>64</b>.</p>
    <p num="p-0090">In the operation block <b>64</b>, a process performed in operation block <b>56</b> (<figref idrefs="DRAWINGS">FIG. 8</figref>) can be reversed. For example, the inverse of the curve of <figref idrefs="DRAWINGS">FIG. 11</figref> or the inverse of any of the other functions described above with reference to operation block <b>56</b> of <figref idrefs="DRAWINGS">FIGS. 8 and 8A</figref>, can be applied to the image data. After the operation block <b>64</b>, the flowchart <b>60</b> can move on to a step <b>66</b>.</p>
    <p num="p-0091">In the operation block <b>66</b>, the green picture elements can be demosaiced. For example, as noted above, all the values from the data components Green <b>1</b> and/or Green <b>2</b> (<figref idrefs="DRAWINGS">FIG. 7</figref>) can be stored in the storage device <b>24</b>. For example, with reference to <figref idrefs="DRAWINGS">FIG. 5</figref>, the green image data from the data components Green <b>1</b>, Green <b>2</b> can be arranged according to the original Bayer pattern applied by the image sensor <b>18</b>. The green data can then be further demosaiced by any known technique, such as, for example, linear interpolation, bilinear, etc.</p>
    <p num="p-0092"> <figref idrefs="DRAWINGS">FIG. 13</figref> illustrates an exemplary layout of green image data demosaiced from all of the raw green image data. The green image elements identified with the letter G<sub>x </sub>represent original raw (decompressed) image data and the elements identified with “DG<sub>x</sub>” represent elements that were derived from the original data through the demosaic process. This nomenclature is used with regard to the below descriptions of the demosaicing process for the other colors. <figref idrefs="DRAWINGS">FIG. 14</figref> illustrates an exemplary image data layout for green image data demosaiced from ½ of the original green image data.</p>
    <p num="p-0093">With continued reference to <figref idrefs="DRAWINGS">FIG. 12</figref>, the flowchart <b>60</b> can, after the operation block <b>66</b>, move on to an operation block <b>68</b>. In the operation block <b>68</b>, the demosaiced green image data can be further processed. For example, but without limitation, noise reduction techniques can be applied to the green image data. However, any other image processing technique, such as anti-aliasing techniques, can also be applied to the green image data. After the operation block <b>68</b>, the flowchart <b>60</b> can move on to an operation block <b>70</b>.</p>
    <p num="p-0094">In the operation block <b>70</b>, the red and blue image data can be demosaiced. For example, firstly, the blue image data of <figref idrefs="DRAWINGS">FIG. 9</figref> can be rearranged according to the original Bayer pattern (<figref idrefs="DRAWINGS">FIG. 15</figref>). The surrounding elements, as shown in <figref idrefs="DRAWINGS">FIG. 16</figref>, can be demosaiced from the existing blue image data using any known demosaicing technique, including linear interpolation, bilinear, etc. As a result of demosaicing step, there will be blue image data for every pixel as shown in <figref idrefs="DRAWINGS">FIG. 16</figref>. However, this blue image data was demosaiced based on the modified blue image data of <figref idrefs="DRAWINGS">FIG. 9</figref>, i.e., blue image data values from which green image data values were subtracted.</p>
    <p num="p-0095">The operation block <b>70</b> can also include a demosaicing process of the red image data. For example, the red image data from <figref idrefs="DRAWINGS">FIG. 10</figref> can be rearranged according to the original Bayer pattern and further demosaiced by any known demosaicing process such as linear interpolation, bilinear, etc.</p>
    <p num="p-0096">After the operation block <b>70</b>, the flowchart can move on to an operation block <b>72</b>. In the operation block <b>72</b>, the demosaiced red and blue image data can be reconstructed from the demosaiced green image data.</p>
    <p num="p-0097">In some embodiments, each of the red and blue image data elements can be reconstructed by adding in the green value from co-sited green image element (the green image element in the same column “m” and row “n” position). For example, after demosaicing, the blue image data includes a blue element value DB<sub>m−2,n−2</sub>. Because the original Bayer pattern of <figref idrefs="DRAWINGS">FIG. 3</figref> did not include a blue element at this position, this blue value DB<sub>m−2,n−2 </sub>was derived through the demosaicing process noted above, based on, for example, blue values from any one of the elements B<sub>m−3,n−3</sub>, B<sub>m−1,n−3</sub>, B<sub>m−3,n−1</sub>, and B<sub>m−1,n−1 </sub>or by any other technique or other blue image elements. As noted above, these values were modified in operation block <b>54</b> (<figref idrefs="DRAWINGS">FIG. 8</figref>) and thus do not correspond to the original blue image data detected by the image sensor <b>18</b>. Rather, an average green value had been subtracted from each of these values. Thus, the resulting blue image data DB<sub>m−2,n−2 </sub>also represents blue data from which green image data has been subtracted. Thus, in one embodiment, the demosaiced green image data for element DG<sub>m−2,n−2 </sub>can be added to the blue image value DB<sub>m−2,n−2 </sub>thereby resulting in a reconstructed blue image data value.</p>
    <p num="p-0098">In some embodiments, optionally, the blue and/or red image data can first be reconstructed before demosaicing. For example, the transformed blue image data B′<sub>m−1,n−1 </sub>can be first reconstructed by adding the average value of the surrounding green elements. This would result in obtaining or recalculating the original blue image data B<sub>m−1,n−1</sub>. This process can be performed on all of the blue image data. Subsequently, the blue image data can be further demosaiced by any known demosaicing technique. The red image data can also be processed in the same or similar manners.</p>
    <p num="p-0099"> <figref idrefs="DRAWINGS">FIG. 12A</figref> illustrates a modification of the flowchart <b>60</b>, identified by the reference numeral <b>60</b>′. Some of the steps described above with reference to the flowchart <b>60</b> can be similar or the same as some of the corresponding steps of the flowchart <b>60</b>′ and thus are identified with the same reference numerals.</p>
    <p num="p-0100">As shown in <figref idrefs="DRAWINGS">FIG. 12A</figref>, the flow chart <b>60</b>′ can include the operation block <b>68</b>′ following operation block <b>62</b>. In operation block <b>68</b>′, a noise reduction technique can be performed on the image data. For example, but without limitation, noise reduction techniques can be applied to the green image data. However, any other image processing technique, such as anti-aliasing techniques, can also be applied to the green image data. After operation block <b>68</b>′, the flow chart can move on to operation block <b>70</b>′</p>
    <p num="p-0101">In operation block <b>70</b>′, the image data can be demosaiced. In the description set forth above with reference to operation blocks <b>66</b> and <b>70</b>, the green, red, and blue image data can be demosaiced in two steps. However, in the present flow chart <b>60</b>′, the demosaicing of all three colors of image data is represented in a single step, although the same demosaicing techniques described above can be used for this demosaicing process. After the operation block <b>70</b>′, the flow chart can move on to operation block <b>72</b>, in which the red and blue image data can be reconstructed, and operation block <b>64</b> in which an inverse look-up table can be applied.</p>
    <p num="p-0102">After the image data has been decompressed and processed according to either of the flow charts <b>70</b> or <b>70</b>′, or any other suitable process, the image data can be further processed as demosaiced image data.</p>
    <p num="p-0103">By demosaicing the green image data before reconstructing the red and blue image data, certain further advantages can be achieved. For example, as noted above, the human eye is more sensitive to green light. Demosaicing and processing the green image data optimize the green image values, to which the human eye is more sensitive. Thus, the subsequent reconstruction of the red and blue image data will be affected by the processing of the green image data.</p>
    <p num="p-0104">Additionally, Bayer patterns have twice as many green elements as red and blue elements. Thus, in embodiments where all of the green data is retained, there is twice as much image data for the green elements as compared to either the red or blue image data elements. Thus, the demosaicing techniques, filters, and other image processing techniques result in a better demosaiced, sharpened, or otherwise filtered image. Using these demosaiced values to reconstruct and demosaic the red and blue image data transfers the benefits associated with the higher resolution of the original green data to the process, reconstruction, and demosaicing of the red and blue elements. As such, the resulting image is further enhanced.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3972010">US3972010</a></td><td class="patent-data-table-td patent-date-value">Dec 20, 1974</td><td class="patent-data-table-td patent-date-value">Jul 27, 1976</td><td class="patent-data-table-td ">Ray Milton Dolby</td><td class="patent-data-table-td ">Compressors, expanders and noise reduction systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4200889">US4200889</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 1976</td><td class="patent-data-table-td patent-date-value">Apr 29, 1980</td><td class="patent-data-table-td ">Basf Aktiengesellschaft</td><td class="patent-data-table-td ">Complementary pre-emphasis and de-emphasis circuits for a video signal transfer channel</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4316213">US4316213</a></td><td class="patent-data-table-td patent-date-value">Sep 23, 1980</td><td class="patent-data-table-td patent-date-value">Feb 16, 1982</td><td class="patent-data-table-td ">Rca Corporation</td><td class="patent-data-table-td ">Video processor employing variable amplitude compression of the chrominance component</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4561012">US4561012</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 1983</td><td class="patent-data-table-td patent-date-value">Dec 24, 1985</td><td class="patent-data-table-td ">Rca Corporation</td><td class="patent-data-table-td ">Pre-emphasis and de-emphasis filters for a composite NTSC format video signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5016107">US5016107</a></td><td class="patent-data-table-td patent-date-value">May 9, 1989</td><td class="patent-data-table-td patent-date-value">May 14, 1991</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Electronic still camera utilizing image compression and digital storage</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5040063">US5040063</a></td><td class="patent-data-table-td patent-date-value">Oct 23, 1989</td><td class="patent-data-table-td patent-date-value">Aug 13, 1991</td><td class="patent-data-table-td ">Zenith Electronics Corporation</td><td class="patent-data-table-td ">TV signal transmission systems and methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5049983">US5049983</a></td><td class="patent-data-table-td patent-date-value">Oct 9, 1990</td><td class="patent-data-table-td patent-date-value">Sep 17, 1991</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Digital camera apparatus having an analog emphasis circuitry</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5249053">US5249053</a></td><td class="patent-data-table-td patent-date-value">Aug 7, 1992</td><td class="patent-data-table-td patent-date-value">Sep 28, 1993</td><td class="patent-data-table-td ">Dycam Inc.</td><td class="patent-data-table-td ">Filmless digital camera with selective image compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5255083">US5255083</a></td><td class="patent-data-table-td patent-date-value">Jun 5, 1991</td><td class="patent-data-table-td patent-date-value">Oct 19, 1993</td><td class="patent-data-table-td ">Sony Corporation Of America</td><td class="patent-data-table-td ">Digital color correction system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5303062">US5303062</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 1990</td><td class="patent-data-table-td patent-date-value">Apr 12, 1994</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Folding camcorder for compact storage</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5343243">US5343243</a></td><td class="patent-data-table-td patent-date-value">Dec 28, 1992</td><td class="patent-data-table-td patent-date-value">Aug 30, 1994</td><td class="patent-data-table-td ">Ricoh Company, Ltd.</td><td class="patent-data-table-td ">Digital video camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5526047">US5526047</a></td><td class="patent-data-table-td patent-date-value">Sep 23, 1994</td><td class="patent-data-table-td patent-date-value">Jun 11, 1996</td><td class="patent-data-table-td ">Asahi Kogaku Kogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">Scheme camera employing compression recording</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5535246">US5535246</a></td><td class="patent-data-table-td patent-date-value">Jun 4, 1992</td><td class="patent-data-table-td patent-date-value">Jul 9, 1996</td><td class="patent-data-table-td ">National Transcommunications Limited</td><td class="patent-data-table-td ">Method of video noise reduction using non-linear pre/de-emphasis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5537157">US5537157</a></td><td class="patent-data-table-td patent-date-value">Aug 30, 1994</td><td class="patent-data-table-td patent-date-value">Jul 16, 1996</td><td class="patent-data-table-td ">Kinya Washino</td><td class="patent-data-table-td ">For use with a display device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5563655">US5563655</a></td><td class="patent-data-table-td patent-date-value">Feb 28, 1994</td><td class="patent-data-table-td patent-date-value">Oct 8, 1996</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Intelligent digital image storage for an electronic camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5592224">US5592224</a></td><td class="patent-data-table-td patent-date-value">Apr 12, 1995</td><td class="patent-data-table-td patent-date-value">Jan 7, 1997</td><td class="patent-data-table-td ">Lg Electronics Inc.</td><td class="patent-data-table-td ">Device for rotating liquid crystal display coupled to camcorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5592237">US5592237</a></td><td class="patent-data-table-td patent-date-value">Nov 4, 1994</td><td class="patent-data-table-td patent-date-value">Jan 7, 1997</td><td class="patent-data-table-td ">Infimed, Inc.</td><td class="patent-data-table-td ">High resolution image processor with multiple bus architecture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5818524">US5818524</a></td><td class="patent-data-table-td patent-date-value">Mar 11, 1996</td><td class="patent-data-table-td patent-date-value">Oct 6, 1998</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Digital still camera having an image data compression function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5949468">US5949468</a></td><td class="patent-data-table-td patent-date-value">Jul 10, 1996</td><td class="patent-data-table-td patent-date-value">Sep 7, 1999</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Light quantity measuring system and exposure apparatus using the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5991515">US5991515</a></td><td class="patent-data-table-td patent-date-value">Jul 15, 1997</td><td class="patent-data-table-td patent-date-value">Nov 23, 1999</td><td class="patent-data-table-td ">Adobe Systems Incorporated</td><td class="patent-data-table-td ">Method and apparatus for compressing and decompressing data prior to display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5999220">US5999220</a></td><td class="patent-data-table-td patent-date-value">Apr 7, 1997</td><td class="patent-data-table-td patent-date-value">Dec 7, 1999</td><td class="patent-data-table-td ">Washino; Kinya</td><td class="patent-data-table-td ">Multi-format audio/video production system with frame-rate conversion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6009201">US6009201</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 1997</td><td class="patent-data-table-td patent-date-value">Dec 28, 1999</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Efficient table-lookup based visually-lossless image compression scheme</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6154493">US6154493</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 21, 1998</td><td class="patent-data-table-td patent-date-value">Nov 28, 2000</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Compression of color images based on a 2-dimensional discrete wavelet transform yielding a perceptually lossless image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6192086">US6192086</a></td><td class="patent-data-table-td patent-date-value">Jan 14, 2000</td><td class="patent-data-table-td patent-date-value">Feb 20, 2001</td><td class="patent-data-table-td ">Antec Corporation</td><td class="patent-data-table-td ">Digital sub-systems and building blocks for a mostly digital low-cost BTSC compatible encoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6198505">US6198505</a></td><td class="patent-data-table-td patent-date-value">Jul 19, 1999</td><td class="patent-data-table-td patent-date-value">Mar 6, 2001</td><td class="patent-data-table-td ">Lockheed Martin Corp.</td><td class="patent-data-table-td ">High resolution, high speed digital camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6262763">US6262763</a></td><td class="patent-data-table-td patent-date-value">Jul 1, 1999</td><td class="patent-data-table-td patent-date-value">Jul 17, 2001</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Actual size image display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6269217">US6269217</a></td><td class="patent-data-table-td patent-date-value">May 21, 1998</td><td class="patent-data-table-td patent-date-value">Jul 31, 2001</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Multi-stage electronic motion image capture and processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6275263">US6275263</a></td><td class="patent-data-table-td patent-date-value">Jun 28, 2000</td><td class="patent-data-table-td patent-date-value">Aug 14, 2001</td><td class="patent-data-table-td ">Sigma Designs, Inc.</td><td class="patent-data-table-td ">Multi-function USB video capture chip using bufferless data compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6285794">US6285794</a></td><td class="patent-data-table-td patent-date-value">Apr 17, 1998</td><td class="patent-data-table-td patent-date-value">Sep 4, 2001</td><td class="patent-data-table-td ">Adobe Systems Incorporated</td><td class="patent-data-table-td ">Compression and editing of movies by multi-image morphing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6314206">US6314206</a></td><td class="patent-data-table-td patent-date-value">Apr 2, 1998</td><td class="patent-data-table-td patent-date-value">Nov 6, 2001</td><td class="patent-data-table-td ">Asahi Kogaku Kogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">Compression ratio setting device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6466699">US6466699</a></td><td class="patent-data-table-td patent-date-value">Aug 20, 1999</td><td class="patent-data-table-td patent-date-value">Oct 15, 2002</td><td class="patent-data-table-td ">Ricoh Company, Ltd</td><td class="patent-data-table-td ">Reversible DCT for lossless—lossy compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6567988">US6567988</a></td><td class="patent-data-table-td patent-date-value">May 1, 1998</td><td class="patent-data-table-td patent-date-value">May 20, 2003</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Video signal transmission apparatus and video signal transmission method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6597860">US6597860</a></td><td class="patent-data-table-td patent-date-value">Aug 11, 1998</td><td class="patent-data-table-td patent-date-value">Jul 22, 2003</td><td class="patent-data-table-td ">Samsung Electronics</td><td class="patent-data-table-td ">Digital camcorder apparatus with MPEG-2 compatible video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6697106">US6697106</a></td><td class="patent-data-table-td patent-date-value">Mar 23, 2000</td><td class="patent-data-table-td patent-date-value">Feb 24, 2004</td><td class="patent-data-table-td ">Fuji Photo Film Co., Ltd.</td><td class="patent-data-table-td ">Apparatus for processing image signals representative of a still picture and moving pictures picked up</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6825876">US6825876</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Nov 30, 2004</td><td class="patent-data-table-td ">Lightsurf Technologies, Inc.</td><td class="patent-data-table-td ">Digital camera device with methodology for efficient color conversion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6859226">US6859226</a></td><td class="patent-data-table-td patent-date-value">Feb 20, 1998</td><td class="patent-data-table-td patent-date-value">Feb 22, 2005</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Camera with first and second compression units and with a digital capture unit providing an output to the first or second compression unit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6867717">US6867717</a></td><td class="patent-data-table-td patent-date-value">Apr 4, 2003</td><td class="patent-data-table-td patent-date-value">Mar 15, 2005</td><td class="patent-data-table-td ">Dalsa, Inc.</td><td class="patent-data-table-td ">Digital encoder and method of encoding high dynamic range video images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6937276">US6937276</a></td><td class="patent-data-table-td patent-date-value">Aug 22, 2001</td><td class="patent-data-table-td patent-date-value">Aug 30, 2005</td><td class="patent-data-table-td ">Benq Corporation</td><td class="patent-data-table-td ">Digital camera with low memory usage</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6958774">US6958774</a></td><td class="patent-data-table-td patent-date-value">Jan 15, 2002</td><td class="patent-data-table-td patent-date-value">Oct 25, 2005</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Electronic camera capable of storing lossless compressed data based on a threshold value</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6983074">US6983074</a></td><td class="patent-data-table-td patent-date-value">Jun 14, 2001</td><td class="patent-data-table-td patent-date-value">Jan 3, 2006</td><td class="patent-data-table-td ">Adobe Systems Incorporated</td><td class="patent-data-table-td ">Data compression system and technique</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6990240">US6990240</a></td><td class="patent-data-table-td patent-date-value">Jun 22, 2001</td><td class="patent-data-table-td patent-date-value">Jan 24, 2006</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6995793">US6995793</a></td><td class="patent-data-table-td patent-date-value">Nov 14, 2000</td><td class="patent-data-table-td patent-date-value">Feb 7, 2006</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Video tap for a digital motion camera that simulates the look of post processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6995794">US6995794</a></td><td class="patent-data-table-td patent-date-value">May 18, 2001</td><td class="patent-data-table-td patent-date-value">Feb 7, 2006</td><td class="patent-data-table-td ">Logitech Europe S.A.</td><td class="patent-data-table-td ">Video camera with major functions implemented in host software</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7038719">US7038719</a></td><td class="patent-data-table-td patent-date-value">Sep 16, 2002</td><td class="patent-data-table-td patent-date-value">May 2, 2006</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image sensing apparatus, image processing method, recording medium, and program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7050642">US7050642</a></td><td class="patent-data-table-td patent-date-value">May 27, 2004</td><td class="patent-data-table-td patent-date-value">May 23, 2006</td><td class="patent-data-table-td ">Next Software, Inc.</td><td class="patent-data-table-td ">Method and apparatus for video compression using microwavelets</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7095899">US7095899</a></td><td class="patent-data-table-td patent-date-value">Aug 18, 2005</td><td class="patent-data-table-td patent-date-value">Aug 22, 2006</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">System and method for progressively transforming and coding digital data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7126634">US7126634</a></td><td class="patent-data-table-td patent-date-value">Jul 23, 2002</td><td class="patent-data-table-td patent-date-value">Oct 24, 2006</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Image processing system, image pickup apparatus and image processing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7127116">US7127116</a></td><td class="patent-data-table-td patent-date-value">Dec 16, 2003</td><td class="patent-data-table-td patent-date-value">Oct 24, 2006</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Image data compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7155066">US7155066</a></td><td class="patent-data-table-td patent-date-value">May 31, 2001</td><td class="patent-data-table-td patent-date-value">Dec 26, 2006</td><td class="patent-data-table-td ">Agilent Technologies, Inc.</td><td class="patent-data-table-td ">System and method for demosaicing raw data images with compression considerations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7174045">US7174045</a></td><td class="patent-data-table-td patent-date-value">Mar 26, 2003</td><td class="patent-data-table-td patent-date-value">Feb 6, 2007</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Image compression apparatus, method and recording medium storing an image compression program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7212313">US7212313</a></td><td class="patent-data-table-td patent-date-value">Dec 16, 2003</td><td class="patent-data-table-td patent-date-value">May 1, 2007</td><td class="patent-data-table-td ">Adobe Systems Incorporated</td><td class="patent-data-table-td ">Reducing storage requirements for display data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7312821">US7312821</a></td><td class="patent-data-table-td patent-date-value">Jun 3, 2003</td><td class="patent-data-table-td patent-date-value">Dec 25, 2007</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">Time-sliced still image generation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7313286">US7313286</a></td><td class="patent-data-table-td patent-date-value">Apr 6, 2004</td><td class="patent-data-table-td patent-date-value">Dec 25, 2007</td><td class="patent-data-table-td ">Ricoh Company, Ltd.</td><td class="patent-data-table-td ">Reversible DCT for lossless-lossy compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7324141">US7324141</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 2003</td><td class="patent-data-table-td patent-date-value">Jan 29, 2008</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image sensing apparatus and data processing method used therein</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7343043">US7343043</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2006</td><td class="patent-data-table-td patent-date-value">Mar 11, 2008</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Image compression apparatus, method and recording medium storing an image compression program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7365658">US7365658</a></td><td class="patent-data-table-td patent-date-value">Jun 6, 2006</td><td class="patent-data-table-td patent-date-value">Apr 29, 2008</td><td class="patent-data-table-td ">The Board Of Trustees Of The University Of Arkansas</td><td class="patent-data-table-td ">Method and apparatus for lossless run-length data encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7369161">US7369161</a></td><td class="patent-data-table-td patent-date-value">Feb 7, 2001</td><td class="patent-data-table-td patent-date-value">May 6, 2008</td><td class="patent-data-table-td ">Lightsurf Technologies, Inc.</td><td class="patent-data-table-td ">Digital camera device providing improved methodology for rapidly taking successive pictures</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7385647">US7385647</a></td><td class="patent-data-table-td patent-date-value">Feb 16, 2005</td><td class="patent-data-table-td patent-date-value">Jun 10, 2008</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Housing cover for image photographing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7388992">US7388992</a></td><td class="patent-data-table-td patent-date-value">Dec 20, 2005</td><td class="patent-data-table-td patent-date-value">Jun 17, 2008</td><td class="patent-data-table-td ">Nokia Corporation</td><td class="patent-data-table-td ">Digital photographic device for controlling compression parameter of image data and method of deciding compression parameter value of image data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7394485">US7394485</a></td><td class="patent-data-table-td patent-date-value">May 19, 2004</td><td class="patent-data-table-td patent-date-value">Jul 1, 2008</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Combination image-capturing apparatus and method for efficiently combining a digital still camera with a digital video camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7477781">US7477781</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 2003</td><td class="patent-data-table-td patent-date-value">Jan 13, 2009</td><td class="patent-data-table-td ">Dalsa Corporation</td><td class="patent-data-table-td ">Method and apparatus for adaptive pixel correction of multi-color matrix</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7483909">US7483909</a></td><td class="patent-data-table-td patent-date-value">May 1, 2006</td><td class="patent-data-table-td patent-date-value">Jan 27, 2009</td><td class="patent-data-table-td ">Adobe Systems Incorporated</td><td class="patent-data-table-td ">System, method and apparatus for converting and integrating media files</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7512283">US7512283</a></td><td class="patent-data-table-td patent-date-value">Jun 12, 2006</td><td class="patent-data-table-td patent-date-value">Mar 31, 2009</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Method of transmitting selected regions of interest of digital video data at selected resolutions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7577689">US7577689</a></td><td class="patent-data-table-td patent-date-value">Jun 15, 2005</td><td class="patent-data-table-td patent-date-value">Aug 18, 2009</td><td class="patent-data-table-td ">Adobe Systems Incorporated</td><td class="patent-data-table-td ">Method and system to archive data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7590301">US7590301</a></td><td class="patent-data-table-td patent-date-value">Feb 2, 2006</td><td class="patent-data-table-td patent-date-value">Sep 15, 2009</td><td class="patent-data-table-td ">Sunplus Technology Co., Ltd.</td><td class="patent-data-table-td ">Method and system for correcting defective pixels of a color image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7609300">US7609300</a></td><td class="patent-data-table-td patent-date-value">Apr 24, 2006</td><td class="patent-data-table-td patent-date-value">Oct 27, 2009</td><td class="patent-data-table-td ">Sunplus Technology Co., Ltd.</td><td class="patent-data-table-td ">Method and system of eliminating color noises caused by an interpolation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7796186">US7796186</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 9, 2007</td><td class="patent-data-table-td patent-date-value">Sep 14, 2010</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Imaging apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7830967">US7830967</a></td><td class="patent-data-table-td patent-date-value">Jul 12, 2010</td><td class="patent-data-table-td patent-date-value">Nov 9, 2010</td><td class="patent-data-table-td ">Red.Com, Inc.</td><td class="patent-data-table-td ">Video camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7937919">US7937919</a></td><td class="patent-data-table-td patent-date-value">Jun 9, 2006</td><td class="patent-data-table-td patent-date-value">May 10, 2011</td><td class="patent-data-table-td ">Deere &amp; Company</td><td class="patent-data-table-td ">Flexible cutting platform with passive float arm stop in an agricultural harvesting machine</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020041707">US20020041707</a></td><td class="patent-data-table-td patent-date-value">Apr 5, 2001</td><td class="patent-data-table-td patent-date-value">Apr 11, 2002</td><td class="patent-data-table-td ">Newman David A.</td><td class="patent-data-table-td ">Real-time color correction of digitally recorded video</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020196354">US20020196354</a></td><td class="patent-data-table-td patent-date-value">Jun 19, 2001</td><td class="patent-data-table-td patent-date-value">Dec 26, 2002</td><td class="patent-data-table-td ">Michael Chang</td><td class="patent-data-table-td ">Intelligent blemish control algorithm and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030007567">US20030007567</a></td><td class="patent-data-table-td patent-date-value">Jun 26, 2002</td><td class="patent-data-table-td patent-date-value">Jan 9, 2003</td><td class="patent-data-table-td ">Newman David A.</td><td class="patent-data-table-td ">Method and apparatus for real-time editing of plural content streams</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030011747">US20030011747</a></td><td class="patent-data-table-td patent-date-value">Jul 12, 2001</td><td class="patent-data-table-td patent-date-value">Jan 16, 2003</td><td class="patent-data-table-td ">Reimar Lenz</td><td class="patent-data-table-td ">Digital, high-resolution motion-picture camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030038885">US20030038885</a></td><td class="patent-data-table-td patent-date-value">May 21, 1998</td><td class="patent-data-table-td patent-date-value">Feb 27, 2003</td><td class="patent-data-table-td ">Nestor M. Rodriguez</td><td class="patent-data-table-td ">Wide gamut motion image capture process for post production applications</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030156188">US20030156188</a></td><td class="patent-data-table-td patent-date-value">Jan 28, 2002</td><td class="patent-data-table-td patent-date-value">Aug 21, 2003</td><td class="patent-data-table-td ">Abrams Thomas Algie</td><td class="patent-data-table-td ">Stereoscopic video</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030185302">US20030185302</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 2, 2002</td><td class="patent-data-table-td patent-date-value">Oct 2, 2003</td><td class="patent-data-table-td ">Abrams Thomas Algie</td><td class="patent-data-table-td ">Camera and/or camera converter</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030202106">US20030202106</a></td><td class="patent-data-table-td patent-date-value">Jan 31, 2003</td><td class="patent-data-table-td patent-date-value">Oct 30, 2003</td><td class="patent-data-table-td ">Robert Kandleinsberger</td><td class="patent-data-table-td ">Digital camera with overscan sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040051793">US20040051793</a></td><td class="patent-data-table-td patent-date-value">Sep 18, 2002</td><td class="patent-data-table-td patent-date-value">Mar 18, 2004</td><td class="patent-data-table-td ">Tecu Kirk S.</td><td class="patent-data-table-td ">Imaging device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040095477">US20040095477</a></td><td class="patent-data-table-td patent-date-value">Aug 8, 2003</td><td class="patent-data-table-td patent-date-value">May 20, 2004</td><td class="patent-data-table-td ">Takashi Maki</td><td class="patent-data-table-td ">ROI setting method and apparatus, electronic camera apparatus, program, and recording medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040196389">US20040196389</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 2004</td><td class="patent-data-table-td patent-date-value">Oct 7, 2004</td><td class="patent-data-table-td ">Yoshiaki Honda</td><td class="patent-data-table-td ">Image pickup apparatus and method thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040201701">US20040201701</a></td><td class="patent-data-table-td patent-date-value">Sep 6, 2001</td><td class="patent-data-table-td patent-date-value">Oct 14, 2004</td><td class="patent-data-table-td ">Shuichi Takagi</td><td class="patent-data-table-td ">Camera with wireless virtual storage</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040246346">US20040246346</a></td><td class="patent-data-table-td patent-date-value">May 28, 2004</td><td class="patent-data-table-td patent-date-value">Dec 9, 2004</td><td class="patent-data-table-td ">Kim Yong-Ho</td><td class="patent-data-table-td ">Photographing apparatus for automatically setting compression format and method thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20050276496">US20050276496</a></td><td class="patent-data-table-td patent-date-value">Jun 14, 2004</td><td class="patent-data-table-td patent-date-value">Dec 15, 2005</td><td class="patent-data-table-td ">Claus Molgaard</td><td class="patent-data-table-td ">Image compression for rapid high-quality imaging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060007324">US20060007324</a></td><td class="patent-data-table-td patent-date-value">Sep 8, 2005</td><td class="patent-data-table-td patent-date-value">Jan 12, 2006</td><td class="patent-data-table-td ">Hirofumi Takei</td><td class="patent-data-table-td ">White balance correcting device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060012694">US20060012694</a></td><td class="patent-data-table-td patent-date-value">Dec 11, 2003</td><td class="patent-data-table-td patent-date-value">Jan 19, 2006</td><td class="patent-data-table-td ">Yutaka Yoneda</td><td class="patent-data-table-td ">Pixel defect detecting/correcting device and pixel defect detecting/correcting method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060061659">US20060061659</a></td><td class="patent-data-table-td patent-date-value">Sep 14, 2005</td><td class="patent-data-table-td patent-date-value">Mar 23, 2006</td><td class="patent-data-table-td ">Chiyumi Niwa</td><td class="patent-data-table-td ">Image capturing apparatus and control method thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060114987">US20060114987</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 2005</td><td class="patent-data-table-td patent-date-value">Jun 1, 2006</td><td class="patent-data-table-td ">Roman Kendyl A</td><td class="patent-data-table-td ">Handheld video transmission and display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060165179">US20060165179</a></td><td class="patent-data-table-td patent-date-value">Jan 27, 2005</td><td class="patent-data-table-td patent-date-value">Jul 27, 2006</td><td class="patent-data-table-td ">Technion Research &amp; Development Foundation Ltd.</td><td class="patent-data-table-td ">Acquisition of image sequences with enhanced resolution</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060170786">US20060170786</a></td><td class="patent-data-table-td patent-date-value">Jan 31, 2005</td><td class="patent-data-table-td patent-date-value">Aug 3, 2006</td><td class="patent-data-table-td ">Nara Won</td><td class="patent-data-table-td ">Digital camera and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060221199">US20060221199</a></td><td class="patent-data-table-td patent-date-value">Sep 30, 2005</td><td class="patent-data-table-td patent-date-value">Oct 5, 2006</td><td class="patent-data-table-td ">Seiko Epson Corporation</td><td class="patent-data-table-td ">Digital camera and image processing method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060221203">US20060221203</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 2006</td><td class="patent-data-table-td patent-date-value">Oct 5, 2006</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Camera apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060221230">US20060221230</a></td><td class="patent-data-table-td patent-date-value">Apr 17, 2003</td><td class="patent-data-table-td patent-date-value">Oct 5, 2006</td><td class="patent-data-table-td ">Nokia Corporation</td><td class="patent-data-table-td ">Mobile camera telephone</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070035636">US20070035636</a></td><td class="patent-data-table-td patent-date-value">Apr 24, 2006</td><td class="patent-data-table-td patent-date-value">Feb 15, 2007</td><td class="patent-data-table-td ">Sunplus Technology Co., Ltd.</td><td class="patent-data-table-td ">Method and system of eliminating color noises caused by an interpolation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070041634">US20070041634</a></td><td class="patent-data-table-td patent-date-value">Aug 8, 2006</td><td class="patent-data-table-td patent-date-value">Feb 22, 2007</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image capturing apparatus, image processing apparatus and image processing method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070127095">US20070127095</a></td><td class="patent-data-table-td patent-date-value">Nov 30, 2006</td><td class="patent-data-table-td patent-date-value">Jun 7, 2007</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image capturing apparatus, image processing method, program, and storage medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070153093">US20070153093</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2005</td><td class="patent-data-table-td patent-date-value">Jul 5, 2007</td><td class="patent-data-table-td ">Mediatek Incorporation</td><td class="patent-data-table-td ">Apparatus and method for image capturing with an image scaling unit to scale a portion of an image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070160142">US20070160142</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 20, 2007</td><td class="patent-data-table-td patent-date-value">Jul 12, 2007</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Camera and/or Camera Converter</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070216782">US20070216782</a></td><td class="patent-data-table-td patent-date-value">Feb 12, 2007</td><td class="patent-data-table-td patent-date-value">Sep 20, 2007</td><td class="patent-data-table-td ">Donald Lee Chernoff</td><td class="patent-data-table-td ">Method of processing and storing files in a digital camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070285517">US20070285517</a></td><td class="patent-data-table-td patent-date-value">Jan 26, 2007</td><td class="patent-data-table-td patent-date-value">Dec 13, 2007</td><td class="patent-data-table-td ">Shinichi Ishikuro</td><td class="patent-data-table-td ">Imaging apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080002035">US20080002035</a></td><td class="patent-data-table-td patent-date-value">Jun 20, 2007</td><td class="patent-data-table-td patent-date-value">Jan 3, 2008</td><td class="patent-data-table-td ">Akimitsu Yoshida</td><td class="patent-data-table-td ">Information processing apparatus and image processing parameter editing method, and image sensing apparatus and its control method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080012953">US20080012953</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 13, 2006</td><td class="patent-data-table-td patent-date-value">Jan 17, 2008</td><td class="patent-data-table-td ">Vimicro Corporation</td><td class="patent-data-table-td ">Image Sensors</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080018746">US20080018746</a></td><td class="patent-data-table-td patent-date-value">Jul 17, 2007</td><td class="patent-data-table-td patent-date-value">Jan 24, 2008</td><td class="patent-data-table-td ">Pentax Corporation</td><td class="patent-data-table-td ">Method and apparatus for recording image data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE37342">USRE37342</a></td><td class="patent-data-table-td patent-date-value">Jan 30, 1998</td><td class="patent-data-table-td patent-date-value">Aug 28, 2001</td><td class="patent-data-table-td ">Multi-Format, Inc.</td><td class="patent-data-table-td ">Dual format digital video production system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE38079">USRE38079</a></td><td class="patent-data-table-td patent-date-value">Jul 10, 1998</td><td class="patent-data-table-td patent-date-value">Apr 15, 2003</td><td class="patent-data-table-td ">Muti-Format, Inc.</td><td class="patent-data-table-td ">Multi-format audio/video production system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">ARRFLEX D-21: The Film Style Didial Camera, Jan. 4, 2008, www.arri.de, [online] http://www.arri.de/press/press/press-release.html?tx-ttnews[tt-news]=32&amp;tx-ttnews[backPid]=1781&amp;cHash=e89c9b0855.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">ARRFLEX D-21: The Film Style Didial Camera, Jan. 4, 2008, www.arri.de, [online] http://www.arri.de/press/press/press—release.html?tx—ttnews[tt—news]=32&amp;tx—ttnews[backPid]=1781&amp;cHash=e89c9b0855.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">ARRIFLEX D-20 Preliminary Specifications, May 31. 2005, www.arri.com, [online], http://web.archive.org/web/20050531010626/www.arri.com/entry/products.htm, pp. 1-2.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CineForm Insider-Nov. 13, 2007.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CineForm Insider—Nov. 13, 2007.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CineForm Online Workflow Solutions for Film and Video-Nov. 1, 2006.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CineForm Online Workflow Solutions for Film and Video—Nov. 1, 2006.</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CineForm Raw-Dalsa and Vision Research Raw File Converters, Jul. 22, 2008, www.cineform.com, [online], http://web.archive.org/web/20080411 213717/www.cineform.com/products/TechNotes/RawConvert.htm, in 4 pages.</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CineForm Raw—Dalsa and Vision Research Raw File Converters, Jul. 22, 2008, www.cineform.com, [online], http://web.archive.org/web/20080411 213717/www.cineform.com/products/TechNotes/RawConvert.htm, in 4 pages.</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CineForm RAW-Technology Overview and Workflow, Apr. 13, 2006.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CineForm RAW—Technology Overview and Workflow, Apr. 13, 2006.</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CinemaTechnic Camera Profiles | ARRI 16SR, 2001.</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Dalsa Technology with Vision, Mar. 2003.</td></tr><tr><td class="patent-data-table-td ">14</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Digital Negative (DNG) Specification, Apr. 2008.</td></tr><tr><td class="patent-data-table-td ">15</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">European Communication pursuant to Rule 114(2) EPC, issued on Mar. 30, 2010 in Application No. 08745686.9, in 5 pages.</td></tr><tr><td class="patent-data-table-td ">16</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Examination Report from Australian Patent Office in Australian Patent Application No. 2008240144.</td></tr><tr><td class="patent-data-table-td ">17</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Extended European Search Report in Application No. 08745686.9 dated Aug. 4, 2011 in 7 pages.</td></tr><tr><td class="patent-data-table-td ">18</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Gamma Correction, www.broadcastengineering.com [online], dated Jan. 1, 2005 in 5 pages.</td></tr><tr><td class="patent-data-table-td ">19</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">International Search Report and Written Opinion for PCT/US2010/028808, dated Aug. 3, 2010 in 12 pages.</td></tr><tr><td class="patent-data-table-td ">20</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">International Search Report of PCT Application No. PCT/US08/60126 dated Jul. 7, 2008.</td></tr><tr><td class="patent-data-table-td ">21</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">JPEG 2000 still image coding versus other standards, Jul. 2000.</td></tr><tr><td class="patent-data-table-td ">22</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Mitani, K; Shimamoto, H; Fujita, Y; A 4 K×2 K-pixel color image pickup system; IEICE Transactions on Information and Systems; E82D (8): 1219-1227; Aug. 1999.</td></tr><tr><td class="patent-data-table-td ">23</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Mitani, K; Sugawara, M; Shimamoto, H; Yamashita, T; Okano, F; Ultrahigh-definition color video camera system with 4K-scanning lines; Sensors and Camera Systems for Scientific, Industrial, and Digital Photography Applications IV, 5017: 159-166, 2003.</td></tr><tr><td class="patent-data-table-td ">24</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">New Zealand Examination Report in Application No. 580171 dated Feb. 22, 2011 in 2 pages.</td></tr><tr><td class="patent-data-table-td ">25</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Non-Patent Literature (NPL), datedJan. 29, 2007, by Michael D. Smith and John Villasenor, titled "<a href='http://scholar.google.com/scholar?q="Constant+Quality+JPEG2000+Rate+Control+for+Digital+Cinema"'>Constant Quality JPEG2000 Rate Control for Digital Cinema</a>", SPIE-IS&amp;T/vol. 6508 65081B-1.</td></tr><tr><td class="patent-data-table-td ">26</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">PHANTOM 65 the world's first 65mm digital cinema, Nov. 22, 2006.</td></tr><tr><td class="patent-data-table-td ">27</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">PHANTOM 65, Feb. 4, 2007, www.visionresearch.com, [online], http://web.archive.org/web/20070204110551/www.visionresearch.com/index.cfm?sector=htm/files&amp;page=camera-65-new, pp. 1-2.</td></tr><tr><td class="patent-data-table-td ">28</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">PHANTOM 65, Feb. 4, 2007, www.visionresearch.com, [online], http://web.archive.org/web/20070204110551/www.visionresearch.com/index.cfm?sector=htm/files&amp;page=camera—65—new, pp. 1-2.</td></tr><tr><td class="patent-data-table-td ">29</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Silicon Imaging SI-2K MINI Full Specifications, May 23, 2007, www.siliconimaging.com, [online], http://web.archive.org/web/20070523223217/www.siliconimaging.com/DigitalCinema/SI-2K-full-specifications.html, pp. 1-2.</td></tr><tr><td class="patent-data-table-td ">30</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Silicon Imaging SI-2K MINI Full Specifications, May 23, 2007, www.siliconimaging.com, [online], http://web.archive.org/web/20070523223217/www.siliconimaging.com/DigitalCinema/SI—2K—full—specifications.html, pp. 1-2.</td></tr><tr><td class="patent-data-table-td ">31</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Silicon Imaging Support: Frequently-Asked-Questions, Dec. 17, 2008, www.siliconimaging.com, [online], http://web.archive.org/web/20071212165310/www.siliconimaging.com/DigitalCinema/SiliconImaging-faq.html, in 12 pages.</td></tr><tr><td class="patent-data-table-td ">32</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Silicon Imaging Support: Frequently-Asked-Questions, Dec. 17, 2008, www.siliconimaging.com, [online], http://web.archive.org/web/20071212165310/www.siliconimaging.com/DigitalCinema/SiliconImaging—faq.html, in 12 pages.</td></tr><tr><td class="patent-data-table-td ">33</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Smith, Michael D; Villasenor, John; Constant quality JPEG2000 rate control for digital cinema; Source: Proceedings of SPIE-The International Society for Optical Engineering, v 6508, n Part 1, 2007, Conference: Visual Communications and Image Processing 2007, Jan. 30, 2007-Feb. 1, 2007.</td></tr><tr><td class="patent-data-table-td ">34</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Smith, Michael D; Villasenor, John; Constant quality JPEG2000 rate control for digital cinema; Source: Proceedings of SPIE—The International Society for Optical Engineering, v 6508, n Part 1, 2007, Conference: Visual Communications and Image Processing 2007, Jan. 30, 2007-Feb. 1, 2007.</td></tr><tr><td class="patent-data-table-td ">35</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Title: Silicon Imaging Support: Frequently-Asked-Questions, Aug. 13, 2008, www.siliconimaging.com, [online], http://web.archive.org/web/20080610162715/www.siliconimaging.com/DigitalCinema/SiliconImaging-faq.html, in 14 pages.</td></tr><tr><td class="patent-data-table-td ">36</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Title: Silicon Imaging Support: Frequently-Asked-Questions, Aug. 13, 2008, www.siliconimaging.com, [online], http://web.archive.org/web/20080610162715/www.siliconimaging.com/DigitalCinema/SiliconImaging—faq.html, in 14 pages.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8358357">US8358357</a></td><td class="patent-data-table-td patent-date-value">Aug 3, 2012</td><td class="patent-data-table-td patent-date-value">Jan 22, 2013</td><td class="patent-data-table-td ">Red.Com, Inc.</td><td class="patent-data-table-td ">Video camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8477238">US8477238</a></td><td class="patent-data-table-td patent-date-value">Jan 4, 2013</td><td class="patent-data-table-td patent-date-value">Jul 2, 2013</td><td class="patent-data-table-td ">Red.Com, Inc.</td><td class="patent-data-table-td ">Modular digital camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8525924">US8525924</a></td><td class="patent-data-table-td patent-date-value">Dec 29, 2008</td><td class="patent-data-table-td patent-date-value">Sep 3, 2013</td><td class="patent-data-table-td ">Red.Com, Inc.</td><td class="patent-data-table-td ">Modular motion camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8525925">US8525925</a></td><td class="patent-data-table-td patent-date-value">Dec 22, 2009</td><td class="patent-data-table-td patent-date-value">Sep 3, 2013</td><td class="patent-data-table-td ">Red.Com, Inc.</td><td class="patent-data-table-td ">Modular digital camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8595756">US8595756</a></td><td class="patent-data-table-td patent-date-value">Jul 15, 2011</td><td class="patent-data-table-td patent-date-value">Nov 26, 2013</td><td class="patent-data-table-td ">Voxlibertum S.A.</td><td class="patent-data-table-td ">System and method for selling or licensing image files</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110221901">US20110221901</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 11, 2010</td><td class="patent-data-table-td patent-date-value">Sep 15, 2011</td><td class="patent-data-table-td ">Gm Global Technology Operations, Inc.</td><td class="patent-data-table-td ">Adaptive Scene Rendering and V2X Video/Image Sharing</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S014130">348/14.13</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375S240200">375/240.2</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009340000">G06K9/34</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007140000">H04N7/14</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0011020000">H04N11/02</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00903">H04N19/00903</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N9/045">H04N9/045</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T3/4015">G06T3/4015</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/648">H04N1/648</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=IqE_BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00315">H04N19/00315</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06T3/40C</span>, <span class="nested-value">H04N9/04B</span>, <span class="nested-value">H04N1/64E</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">May 20, 2014</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1 AND 6-12 ARE DETERMINED TO BE PATENTABLE AS AMENDED.CLAIMS 2-5, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE.NEW CLAIMS 13-36 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 27, 2013</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 11, 2012</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120913</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 7, 2008</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">RED.COM, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:JANNARD, JAMES;NATTRESS, THOMAS GRAEME;REEL/FRAME:021366/0478;SIGNING DATES FROM 20080716 TO 20080721</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:JANNARD, JAMES;NATTRESS, THOMAS GRAEME;SIGNING DATES FROM 20080716 TO 20080721;REEL/FRAME:021366/0478</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4ff636b3d23669b7103f3b3a3a18b4cd.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0tHQHvDdwO526XeaqwTai6LswRbg\u0026id=IqE_BwABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U2PeooKtAjqmKBk7QWmAXQ5PiofUA\u0026id=IqE_BwABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U3nyIyfk9ZT2sU9oL-fAenrxz7JHg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Video_camera.pdf?id=IqE_BwABERAJ\u0026output=pdf\u0026sig=ACfU3U0dhiFiXgfwIwc-3VNS88h3Y8x0jw"},"sample_url":"http://www.google.com/patents/reader?id=IqE_BwABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>