<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5754976 - Algebraic codebook with signal-selected pulse amplitude/position ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Algebraic codebook with signal-selected pulse amplitude/position combinations for fast coding of speech"><meta name="DC.contributor" content="Jean-Pierre Adoul" scheme="inventor"><meta name="DC.contributor" content="Claude Laflamme" scheme="inventor"><meta name="DC.contributor" content="Universite De Sherbrooke" scheme="assignee"><meta name="DC.date" content="1995-7-28" scheme="dateSubmitted"><meta name="DC.description" content="A codebook is searched in view of encoding a sound signal. This codebook consists of a set of pulse amplitude/position combinations each defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, wherein each non-zero-amplitude pulse assumes at least one of q possible amplitudes. To reduce the search complexity, a subset of pulse amplitude/position combinations from the codebook is pre-selected in relation to the sound signal, and only this subset of combinations is searched. The pre-selection of the subset of combinations consists of pre-establishing, in relation to the sound signal, a function Sp between the respective positions p=1, 2, . . . L and the q possible amplitudes, the search being limited to the combinations of the codebook having non-zero-amplitude pulses which respect the pre-established function. The function can be pre-established by pre-assigning one of the q possible amplitudes to each position p, the pre-established function being respected when the non-zero-amplitude pulses of a combination each have an amplitude equal to the amplitude Sp pre-assigned to the position p of that pulse."><meta name="DC.date" content="1998-5-19" scheme="issued"><meta name="DC.relation" content="EP:0138061:A1" scheme="references"><meta name="DC.relation" content="EP:0149724:A1" scheme="references"><meta name="DC.relation" content="EP:0342687:A2" scheme="references"><meta name="DC.relation" content="EP:0446817:A2" scheme="references"><meta name="DC.relation" content="EP:0514912:A2" scheme="references"><meta name="DC.relation" content="EP:0532225:A2" scheme="references"><meta name="DC.relation" content="EP:0545386:A2" scheme="references"><meta name="DC.relation" content="US:4401855" scheme="references"><meta name="DC.relation" content="US:4486899" scheme="references"><meta name="DC.relation" content="US:4520499" scheme="references"><meta name="DC.relation" content="US:4594687" scheme="references"><meta name="DC.relation" content="US:4625286" scheme="references"><meta name="DC.relation" content="US:4667340" scheme="references"><meta name="DC.relation" content="US:4669120" scheme="references"><meta name="DC.relation" content="US:4677671" scheme="references"><meta name="DC.relation" content="US:4680797" scheme="references"><meta name="DC.relation" content="US:4710959" scheme="references"><meta name="DC.relation" content="US:4720861" scheme="references"><meta name="DC.relation" content="US:4724535" scheme="references"><meta name="DC.relation" content="US:4742550" scheme="references"><meta name="DC.relation" content="US:4764963" scheme="references"><meta name="DC.relation" content="US:4771465" scheme="references"><meta name="DC.relation" content="US:4797925" scheme="references"><meta name="DC.relation" content="US:4797926" scheme="references"><meta name="DC.relation" content="US:4799261" scheme="references"><meta name="DC.relation" content="US:4811398" scheme="references"><meta name="DC.relation" content="US:4815134" scheme="references"><meta name="DC.relation" content="US:4817157" scheme="references"><meta name="DC.relation" content="US:4821324" scheme="references"><meta name="DC.relation" content="US:4858115" scheme="references"><meta name="DC.relation" content="US:4860355" scheme="references"><meta name="DC.relation" content="US:4864620" scheme="references"><meta name="DC.relation" content="US:4868867" scheme="references"><meta name="DC.relation" content="US:4873723" scheme="references"><meta name="DC.relation" content="US:4964169" scheme="references"><meta name="DC.relation" content="US:4991214" scheme="references"><meta name="DC.relation" content="US:5097508" scheme="references"><meta name="DC.relation" content="US:5193140" scheme="references"><meta name="DC.relation" content="US:5293449" scheme="references"><meta name="DC.relation" content="US:5307441" scheme="references"><meta name="DC.relation" content="US:5457783" scheme="references"><meta name="DC.relation" content="WO:1990000381:A1" scheme="references"><meta name="DC.relation" content="WO:1991013432:A1" scheme="references"><meta name="citation_reference" content="&quot;8 kbits/s Speech Coder with Pitch Adaptive Vector Quantizer&quot; S. Iai and K. Irie, ICASSP 1986, Tokyo, vol. 3, Apr. 1986, pp. 1697-1700."><meta name="citation_reference" content="&quot;A comparision of some alegbraic structures for CELP coding of speech&quot; J-P. Adoul et al. ICASSP 87 Proceedings, Apr. 6-9, 1987, Dallas, Texas pp. 1953-1956."><meta name="citation_reference" content="&quot;A robust 16 Kbits/s vector adaptive predictive coder for mobile communications&quot; A. Le Guyader et al. ICASSP 86 Prooceedings, Apr. 7-11, Tokyo, Japan pp. 857-860."><meta name="citation_reference" content="&quot;Algorithme de quantification vectorielle spherique a partir du reseau de Gosset d&#39;ordre 8&quot; C. Lamblin et J.P. Adoul, Annales es Telecommunications, 1988, vol. 43, No. 1-2, pp. 172-186."><meta name="citation_reference" content="&quot;Coding of Speech at 8 kbit/s using Conjugate-structure Algebraic-code-excited Linear-Predictive (CS-ACELP) Coding&quot; Study Group 15 contrib., Int. Telecom. Union Jun. 1995, pp. 1-43."><meta name="citation_reference" content="&quot;Fast CELP coding based on algebraic codes&quot; J-P. Adoul et al. ICASSP 87 Proceedings Apr. 6-9, 1987, Dallas Texas pp. 1957-1960."><meta name="citation_reference" content="&quot;Fast Methods for Code Search in CELP&quot; M.E. Ahmed and M.I. Al-Suwaiyel, IEEE Transactions on Speech and Audio Processing, 1993, vol. 1, No. 3, New York, pp. 315-325."><meta name="citation_reference" content="&quot;Multipulse excitation codebook design and fast search methods for CELP speech coding&quot; F.F. Tzeng IEEE Glob. Telcom. Conf. &amp; Exhib., Nov. 28-Dec. 1, 1988 Hollywood Fla, pp. 0590-0594."><meta name="citation_reference" content="8 kbits/s Speech Coder with Pitch Adaptive Vector Quantizer S. Iai and K. Irie, ICASSP 1986, Tokyo, vol. 3, Apr. 1986, pp. 1697 1700."><meta name="citation_reference" content="A comparision of some alegbraic structures for CELP coding of speech J P. Adoul et al. ICASSP 87 Proceedings, Apr. 6 9, 1987, Dallas, Texas pp. 1953 1956."><meta name="citation_reference" content="A robust 16 Kbits/s vector adaptive predictive coder for mobile communications A. Le Guyader et al. ICASSP 86 Prooceedings, Apr. 7 11, Tokyo, Japan pp. 857 860."><meta name="citation_reference" content="Abstract of &quot;Low delay speech coding&quot;, Cuperman, et al., Journal Speech Communication, vol. 12, No. 2, Netherlands, Jun. 1993, pp. 193-204."><meta name="citation_reference" content="Abstract of Low delay speech coding , Cuperman, et al., Journal Speech Communication, vol. 12, No. 2, Netherlands, Jun. 1993, pp. 193 204."><meta name="citation_reference" content="Algorithme de quantification vectorielle sph e rique a partir du r e seau de Gosset d ordre 8 C. Lamblin et J.P. Adoul, Annales es T e l e communications, 1988, vol. 43, No. 1 2, pp. 172 186."><meta name="citation_reference" content="Claude Laflamme, Jean Pierre Adoul, R. Salami, S. Morisette, and P. Mabilleau, 16 Kbps Wideband Speech Coding Technique Based on Algebraic CELP , Proceeding of IEEE ICASSP 91, session S1.4, pp. 13 16, May 1991."><meta name="citation_reference" content="Claude Laflamme, Jean-Pierre Adoul, R. Salami, S. Morisette, and P. Mabilleau, &quot;16 Kbps Wideband Speech Coding Technique Based on Algebraic CELP&quot;, Proceeding of IEEE ICASSP 91, session S1.4, pp. 13-16, May 1991."><meta name="citation_reference" content="Coding of Speech at 8 kbit/s using Conjugate structure Algebraic code excited Linear Predictive (CS ACELP) Coding Study Group 15 contrib., Int. Telecom. Union Jun. 1995, pp. 1 43."><meta name="citation_reference" content="Fast CELP coding based on algebraic codes J P. Adoul et al. ICASSP 87 Proceedings Apr. 6 9, 1987, Dallas Texas pp. 1957 1960."><meta name="citation_reference" content="Fast Methods for Code Search in CELP M.E. Ahmed and M.I. Al Suwaiyel, IEEE Transactions on Speech and Audio Processing, 1993, vol. 1, No. 3, New York, pp. 315 325."><meta name="citation_reference" content="Laflamme, et al., &quot;On Reducing Computational Complexity of Codebook Search in CELP Coder Through the Use of Algebraic Codes&quot;, Proceeding of the IEEE ICASSP 1990, pp. 177-180."><meta name="citation_reference" content="Laflamme, et al., On Reducing Computational Complexity of Codebook Search in CELP Coder Through the Use of Algebraic Codes , Proceeding of the IEEE ICASSP 1990, pp. 177 180."><meta name="citation_reference" content="Multipulse excitation codebook design and fast search methods for CELP speech coding F.F. Tzeng IEEE Glob. Telcom. Conf. &amp; Exhib., Nov. 28 Dec. 1, 1988 Hollywood Fla, pp. 0590 0594."><meta name="citation_patent_number" content="US:5754976"><meta name="citation_patent_application_number" content="US:08/508,801"><link rel="canonical" href="http://www.google.com/patents/US5754976"/><meta property="og:url" content="http://www.google.com/patents/US5754976"/><meta name="title" content="Patent US5754976 - Algebraic codebook with signal-selected pulse amplitude/position combinations for fast coding of speech"/><meta name="description" content="A codebook is searched in view of encoding a sound signal. This codebook consists of a set of pulse amplitude/position combinations each defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, wherein each non-zero-amplitude pulse assumes at least one of q possible amplitudes. To reduce the search complexity, a subset of pulse amplitude/position combinations from the codebook is pre-selected in relation to the sound signal, and only this subset of combinations is searched. The pre-selection of the subset of combinations consists of pre-establishing, in relation to the sound signal, a function Sp between the respective positions p=1, 2, . . . L and the q possible amplitudes, the search being limited to the combinations of the codebook having non-zero-amplitude pulses which respect the pre-established function. The function can be pre-established by pre-assigning one of the q possible amplitudes to each position p, the pre-established function being respected when the non-zero-amplitude pulses of a combination each have an amplitude equal to the amplitude Sp pre-assigned to the position p of that pulse."/><meta property="og:title" content="Patent US5754976 - Algebraic codebook with signal-selected pulse amplitude/position combinations for fast coding of speech"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("CCruU4buAqXZsQTPpYCQAg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("PRT"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("CCruU4buAqXZsQTPpYCQAg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("PRT"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5754976?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5754976"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=0RRGBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5754976&amp;usg=AFQjCNF0tiLck-YhptkcHjgAeuzvc24pIg" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5754976.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5754976.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5754976" style="display:none"><span itemprop="description">A codebook is searched in view of encoding a sound signal. This codebook consists of a set of pulse amplitude/position combinations each defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination,...</span><span itemprop="url">http://www.google.com/patents/US5754976?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5754976 - Algebraic codebook with signal-selected pulse amplitude/position combinations for fast coding of speech</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5754976 - Algebraic codebook with signal-selected pulse amplitude/position combinations for fast coding of speech" title="Patent US5754976 - Algebraic codebook with signal-selected pulse amplitude/position combinations for fast coding of speech"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5754976 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/508,801</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">May 19, 1998</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jul 28, 1995</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Feb 23, 1990</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2210765A1">CA2210765A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2210765C">CA2210765C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN1181150A">CN1181150A</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN1198262C">CN1198262C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN1220178C">CN1220178C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN1410970A">CN1410970A</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE19604273A1">DE19604273A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE19604273C2">DE19604273C2</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE19604273C5">DE19604273C5</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0808496A1">EP0808496A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0808496B1">EP0808496B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1225568A1">EP1225568A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1225568B1">EP1225568B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO1996024925A1">WO1996024925A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08508801, </span><span class="patent-bibdata-value">508801, </span><span class="patent-bibdata-value">US 5754976 A, </span><span class="patent-bibdata-value">US 5754976A, </span><span class="patent-bibdata-value">US-A-5754976, </span><span class="patent-bibdata-value">US5754976 A, </span><span class="patent-bibdata-value">US5754976A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jean-Pierre+Adoul%22">Jean-Pierre Adoul</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Claude+Laflamme%22">Claude Laflamme</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Universite+De+Sherbrooke%22">Universite De Sherbrooke</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5754976.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5754976.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5754976.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (43),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (22),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (50),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (23),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (6)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5754976&usg=AFQjCNE2wFf5CKyDoWLSrl1c-OPwtaaYsQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5754976&usg=AFQjCNHl4FbV8FlLu3rCHPBN2M4_xEDRew">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5754976A%26KC%3DA%26FT%3DD&usg=AFQjCNGh8pBe0QkvJgELqaDKz8wXzBAC6Q">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54281966" lang="EN" load-source="patent-office">Algebraic codebook with signal-selected pulse amplitude/position combinations for fast coding of speech</invention-title></span><br><span class="patent-number">US 5754976 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA131518412" lang="EN" load-source="patent-office"> <div class="abstract">A codebook is searched in view of encoding a sound signal. This codebook consists of a set of pulse amplitude/position combinations each defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, wherein each non-zero-amplitude pulse assumes at least one of q possible amplitudes. To reduce the search complexity, a subset of pulse amplitude/position combinations from the codebook is pre-selected in relation to the sound signal, and only this subset of combinations is searched. The pre-selection of the subset of combinations consists of pre-establishing, in relation to the sound signal, a function S<sub>p</sub> between the respective positions p=1, 2, . . . L and the q possible amplitudes, the search being limited to the combinations of the codebook having non-zero-amplitude pulses which respect the pre-established function. The function can be pre-established by pre-assigning one of the q possible amplitudes to each position p, the pre-established function being respected when the non-zero-amplitude pulses of a combination each have an amplitude equal to the amplitude S<sub>p</sub> pre-assigned to the position p of that pulse.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(6)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5754976-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5754976-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5754976-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5754976-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5754976-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5754976-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5754976-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5754976-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5754976-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5754976-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5754976-7.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5754976-7.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(27)</span></span></div><div class="patent-text"><div mxw-id="PCLM59471339" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A method of conducting a search in a codebook in view of encoding a sound signal, said codebook consisting of a set of pulse amplitude/position combinations, each pulse amplitude/position combination defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, and each non-zero-amplitude pulse assuming at least one of q possible amplitudes, said method comprising the steps of:<div class="claim-text">pre-selecting from said codebook a subset of pulse amplitude/position combinations in relation to the sound signal;</div> <div class="claim-text">searching only said subset of pulse amplitude/position combinations in view of encoding the sound signal whereby complexity of the search is reduced as only a subset of the pulse amplitude/position combinations of the codebook is searched; and</div> <div class="claim-text">wherein the pre-selecting step comprises pre-establishing, in relation to the sound signal, a function S<sub>p</sub> pre-assigning to the positions p=1, 2, . . . L valid amplitudes out of said q possible amplitudes, and wherein the searching step comprises searching only the pulse amplitude/position combinations of said codebook having non-zero-amplitude pulses which respect the pre-established function.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The method of claim 1, wherein the function pre-establishing step comprises the step of pre-assigning, by means of the function S<sub>p</sub>, one of the q possible amplitudes as valid amplitude to each position p, and wherein the pre-established function is respected when the non-zero-amplitude pulses of a pulse amplitude/position combination each have an amplitude equal to the amplitude pre-assigned by the function S<sub>p</sub> to the position p of said non-zero-amplitude pulse.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The method of claim 2, wherein the step of pre-assigning one of the q possible amplitudes to each position p comprises the steps of:<div class="claim-text">processing the sound signal to produce a backward-filtered target signal D and a pitch-removed residual signal R';</div> <div class="claim-text">calculating an amplitude estimate vector B in response to the backward-filtered target signal D and to the pitch-removed residual signal R'; and</div> <div class="claim-text">for each of said positions p, quantizing an amplitude estimate B<sub>p</sub> of said vector B to obtain the amplitude to be selected for said position p.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The method of claim 3, in which the step of calculating an amplitude estimate vector B comprises the step of summing the backward-filtered target signal D in normalized form: ##EQU26## to the pitch-removed residual signal R' in normalized form: ##EQU27## to thereby obtain an amplitude estimate vector B of the form: ##EQU28## where β is a fixed constant.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The method of claim 4, wherein β is a fixed constant having a value situated between 0 and 1.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The method of claim 3, in which for each of said positions p, the quantizing step comprises quantizing a peak-normalized amplitude estimate B<sub>p</sub> of said vector B using the following expression: ##EQU29## wherein the denominator ##EQU30## is a normalizing factor representing a peak amplitude of the non-zero-amplitude pulses.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The method of claim 3, wherein said pulse amplitude/position combinations each comprise a number N of non-zero-amplitude pulses, and wherein the searching step comprises the step of maximizing a given ratio having a denominator α<sub>k</sub> <sup>2</sup> computed by means of N nested loops in accordance with the following relation: ##EQU31## where computation for each loop is written in a separate line from an outermost loop to an innermost loop of the N nested loops, where p<sub>n</sub> is the position of the n<sup>th</sup> non-zero-amplitude pulse of the combination, and where U'(p<sub>x</sub>, p<sub>y</sub>) is a function dependent on the amplitude S<sub>p</sub>.sbsb.x pre-assigned to a position p<sub>x</sub> amongst the positions p and the amplitude S<sub>p</sub>.sbsb.y pre-assigned to a position p<sub>y</sub> amongst the positions p.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The method of claim 7, wherein the step of maximizing said given ratio comprises the step of skipping at least the innermost loop of the N nested loops whenever the following inequality is true ##EQU32## where S<sub>p</sub>.sbsb.n is the amplitude pre-assigned to position p<sub>n</sub>, D<sub>p</sub>.sbsb.n is the p<sub>n</sub> <sup>th</sup> component of the target signal D, and T<sub>D</sub> is a threshold related to the backward-filtered target signal D.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The method of claim 1, wherein said pulse amplitude/position combinations each comprise a number N of non-zero-amplitude pulses, said method further comprising the step of restraining the positions p of the non-zero-amplitude pulses in accordance with at least one N-interleaved single-pulse permutation code.</div>
    </div>
    </div> <div class="claim"> <div num="10" class="claim">
      <div class="claim-text">10. A device for conducting a search in a codebook in view of encoding a sound signal, said codebook consisting of a set of pulse amplitude/position combinations, each pulse amplitude/position combination defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, and each non-zero-amplitude pulse assuming at least one of q possible amplitudes, said device comprising:<div class="claim-text">means for pre-selecting from said codebook a subset of pulse amplitude/position combinations in relation to the sound signal; and</div> <div class="claim-text">means for searching only said subset of pulse amplitude/position combinations in view of encoding the sound signal whereby complexity of the search is reduced as only a subset of the pulse amplitude/position combinations of the codebook is searched;</div> <div class="claim-text">wherein the pre-selecting means comprises means for pre-establishing, in relation to the sound signal, a function S<sub>p</sub> pre-assigning to the positions p=1, 2, . . . L valid amplitudes out of said q possible amplitudes, and wherein the searching means comprises means for limiting the search to the pulse amplitude/position combinations of said codebook having non-zero-amplitude pulses which respect the pre-established function.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The device of claim 10, wherein the function pre-establishing means comprises means for pre-assigning, by means of the function S<sub>p</sub>, one of the q possible amplitudes as valid amplitude to each position p, and wherein the pre-established function is respected when the non-zero-amplitude pulses of a pulse amplitude/position combination each have an amplitude equal to the amplitude pre-assigned by the function S<sub>p</sub> to the position p of said non-zero-amplitude pulse.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The device of claim 11, wherein the means for pre-assigning one of the q possible amplitudes to each position p comprises:<div class="claim-text">means for processing the sound signal to produce a backward-filtered target signal D and a pitch-removed residual signal R';</div> <div class="claim-text">means for calculating an amplitude estimate vector B in response to the backward-filtered target signal D and to the pitch-removed residual signal R'; and</div> <div class="claim-text">means for quantizing, for each of said positions p, an amplitude estimate B<sub>p</sub> of said vector B to obtain the amplitude to be selected for said position p.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The device of claim 12, in which said means for calculating an amplitude estimate vector B comprises means for summing the backward-filtered target signal D in normalized form: ##EQU33## to the pitch-removed residual signal R' in normalized form: ##EQU34## to thereby obtain an amplitude estimate vector B of the form: ##EQU35## where β is a fixed constant.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The device of claim 13, wherein β is a fixed constant having a value situated between 0 and 1.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. The device of claim 12, in which said quantizing means comprises means for quantizing, for each of said positions p, a peak-normalized amplitude estimate B<sub>p</sub> of said vector B using the following expression: ##EQU36## wherein the denominator ##EQU37## is a normalizing factor representing a peak amplitude of the non-zero-amplitude pulses.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The device of claim 12, wherein said pulse amplitude/position combinations each comprise a number N of non-zero-amplitude pulses, and wherein the searching means comprises means for maximizing a given ratio having a denominator α<sub>k</sub> <sup>2</sup> and means for computing said denominator α<sub>k</sub> <sup>2</sup> by means of N nested loops in accordance with the following relation: ##EQU38## where computation for each loop is written in a separate line from an outermost loop to an innermost loop of the N nested loops, where p<sub>n</sub> is the position of the n<sup>th</sup> non-zero-amplitude pulse of the combination, and where U'(p<sub>x</sub>,p<sub>y</sub>) is a function dependent on the amplitude S<sub>p</sub>.sbsb.x pre-assigned to a position p<sub>x</sub> amongst the positions p and the amplitude S<sub>p</sub>.sbsb.y, pre-assigned to a position p<sub>y</sub> amongst the positions p.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The device of claim 16, wherein said means for computing the denominator ∝<sub>k</sub> <sup>2</sup> comprises means for skipping at least the innermost loop of the N nested loops whenever the following inequality is true ##EQU39## where S<sub>p</sub>.sbsb.n is the amplitude pre-assigned to position p<sub>n</sub>, D<sub>p</sub>.sbsb.n is the p<sub>n</sub> <sup>th</sup> component of the target signal D, and T<sub>D</sub> is a threshold related to the backward-filtered target signal D.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. The device of claim 10, wherein said pulse amplitude/position combinations each comprise a number N of non-zero-amplitude pulses, said device further comprising means for restraining the positions p of the non-zero-amplitude pulses in accordance with at least one N-interleaved single-pulse permutation code.</div>
    </div>
    </div> <div class="claim"> <div num="19" class="claim">
      <div class="claim-text">19. A cellular communication system for servicing a large geographical area divided into a plurality of cells, comprising:<div class="claim-text">mobile transmitter/receiver units;</div> <div class="claim-text">cellular base stations respectively situated in said cells;</div> <div class="claim-text">means for controlling communication between the cellular base stations;</div> <div class="claim-text">a bidirectional wireless communication sub-system between each mobile unit situated in one cell and the cellular base station of said one cell, said bidirectional wireless communication sub-system comprising in both the mobile unit and the cellular base station (a) a transmitter including means for encoding a speech signal and means for transmitting the encoded speech signal, and (b) a receiver including means for receiving a transmitted encoded speech signal and means for decoding the received encoded speech signal;<div class="claim-text">wherein said speech signal encoding means comprises a device for conducting a search in a codebook in view of encoding the speech signal, said codebook consisting of a set of pulse amplitude/position combinations, each pulse amplitude/position combination defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, and each non-zero-amplitude pulse assuming at least one of q possible amplitudes, said search conducting device comprising:<div class="claim-text">means for pre-selecting from said codebook a subset of pulse amplitude/position combinations in relation to the speech signal; and</div> <div class="claim-text">means for searching only said subset of pulse amplitude/position combinations in view of encoding the speech signal whereby complexity of the search is reduced as only a subset of the pulse amplitude/position combinations of the codebook is searched;</div> </div> </div> <div class="claim-text">wherein the pre-selecting means comprises means for pre-establishing, in relation to the sound signal, a function S<sub>p</sub> pre-assigning to the positions p=1, 2, . . . L valid amplitudes out of said q possible amplitudes, and wherein the searching means comprises means for limiting the search to the pulse amplitude/position combinations of said codebook having non-zero-amplitude pulses which respect the pre-established function.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The system of claim 19, wherein the function pre-establishing means comprises means for pre-assigning, by means of the function S<sub>p</sub>, one of the q possible amplitudes as valid amplitude to each position p, and wherein the pre-established function is respected when the non-zero-amplitude pulses of a pulse amplitude/position combination each have an amplitude equal to the amplitude pre-assigned by the function S<sub>p</sub> to the position p of said non-zero-amplitude pulse.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. The system of claim 20, wherein the means for pre-assigning one of the q possible amplitudes to each position p comprises:<div class="claim-text">means for processing the speech signal to produce a backward-filtered target signal D and a pitch-removed residual signal R';</div> <div class="claim-text">means for calculating an amplitude estimate vector B in response to the backward-filtered target signal D and to the pitch-removed residual signal R'; and</div> <div class="claim-text">means for quantizing, for each of said positions p, an amplitude estimate B<sub>p</sub> of said vector B to obtain the amplitude to be selected for said position p.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22. The system of claim 21, in which said means for calculating an amplitude estimate vector B comprises means for summing the backward-filtered target signal D in normalized form: ##EQU40## to the pitch-removed residual signal R' in normalized form: ##EQU41## to thereby obtain an amplitude estimate vector B of the form: ##EQU42## where β is a fixed constant.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. The system of claim 22, wherein β is a fixed constant having a value situated between 0 and 1.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" class="claim">
      <div class="claim-text">24. The system of claim 21, in which said quantizing means comprises means for quantizing, for each of said positions p, a peak-normalized amplitude estimate B<sub>p</sub> of said vector B using the following expression: ##EQU43## wherein the denominator ##EQU44## is a normalizing factor representing a peak amplitude of the non-zero-amplitude pulses.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25. The system of claim 21, wherein said pulse amplitude/position combinations each comprise a number N of non-zero-amplitude pulses, and wherein the searching means comprises means for maximizing a given ratio having a denominator α<sub>k</sub> <sup>2</sup> and means for computing said denominator α<sub>k</sub> <sup>2</sup> by means of N nested loops in accordance with the following relation: ##EQU45## where computation for each loop is written in a separate line from an outermost loop to an innermost loop of the N nested loops, where p<sub>n</sub> is the position of the n<sup>th</sup> non-zero-amplitude pulse of the combination, and where U'(p<sub>x</sub>, p<sub>y</sub>) is a function dependent on the amplitude S<sub>p</sub>.sbsb.x pre-assigned to a position p<sub>x</sub> amongst the positions p and the amplitude S<sub>p</sub>.sbsb.y pre-assigned to a position p<sub>y</sub> amongst the positions p.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" class="claim">
      <div class="claim-text">26. The system of claim 25, wherein said means for computing the denominator ∝<sub>k</sub> <sup>2</sup> comprises means for skipping at least the innermost loop of the N nested loops whenever the following inequality is true ##EQU46## where S<sub>p</sub>.sbsb.n is the amplitude pre-assigned to position p<sub>n</sub>, D<sub>p</sub>.sbsb.n is the p<sub>n</sub> <sup>th</sup> component of the target signal D, and T<sub>D</sub> is a threshold related to the backward-filtered target signal D.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27. The system of claim 19, wherein said pulse amplitude/position combinations each comprise a number N of non-zero-amplitude pulses, said device further comprising means for restraining the positions p of the non-zero-amplitude pulses in accordance with at least one N-interleaved single-pulse permutation code.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67115115" lang="EN" load-source="patent-office" class="description">
    <heading>RELATED U.S. PATENT APPLICATION</heading> <p>This is a Continuation-In-Part of U.S. patent application Ser. No. 08/383,968 filed on Feb. 6, 1995, now abandoned, which is a continuation-in part application of a patent application, Ser. No. 07/927,528, filed as PCT/CA90/00381, Nov. 6, 1990, published as WO91/13432, Sep. 5, 1991, now issued as U.S. Pat. No. 5,444,816, issued Aug. 22, 1995 for an invention entitled "ALGEBRAIC CODEBOOK WITH SIGNAL-SELECTED PULSE AMPLITUDES FOR FAST CODING OF SPEECH".</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>The present invention relates to an improved technique for digitally encoding a sound signal, in particular but not exclusively a speech signal, in view of transmitting and synthesizing this sound signal.</p>
    <p>2. Brief Description of the Prior Art</p>
    <p>The demand for efficient digital speech encoding techniques with a good subjective quality/bit rate tradeoff is increasing for numerous applications such as voice transmission over satellites, land mobile, digital radio or packed network, voice storage, voice response and wireless telephony.</p>
    <p>One of the best prior art techniques capable of achieving a good quality/bit rate tradeoff is the so called Code Excited Linear Prediction (CELP) technique. According to this technique, the speech signal is sampled and processed in blocks of L samples (i.e. vectors), where L is some predetermined number. The CELP technique makes use of a codebook.</p>
    <p>A codebook, in the CELP context, is an indexed set of L-sample-long sequences which will be referred to as L-dimensional codevectors (pulse combinations defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination). The codebook comprises an index k ranging from 1 to M, where M represents the size of the codebook sometimes expressed as a number of bits b:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">M=2<sup>b</sup> </pre>
    
    <p>A codebook can be stored in a physical memory (e.g. a look-up table), or can refer to a mechanism for relating the index to a corresponding codevector (e.g. a formula).</p>
    <p>To synthesize speech according to the CELP technique, each block of speech samples is synthesized by filtering the appropriate codevector from the codebook through time varying filters modelling the spectral characteristics of the speech signal. At the encoder end, the synthetic output is computed for all or a subset of the candidate codevectors from the codebook (codebook search). The retained codevector is the one producing the synthetic output which is the closest to the original speech signal according to a perceptually weighted distortion measure.</p>
    <p>A first type of codebooks are the so called "stochastic" codebooks. A drawback of these codebooks is that they often involve substantial physical storage. They are stochastic, i.e. random in the sense that the path from the index to the associated codevector involves look-up tables which are the result of randomly generated numbers or statistical techniques applied to large speech training sets. The size of stochastic codebooks tends to be limited by storage and/or search complexity.</p>
    <p>A second type of codebooks are the algebraic codebooks. By contrast with the stochastic codebooks, algebraic codebooks are not random and require no storage. An algebraic codebook is a set of indexed codevectors in which the amplitudes and positions of the pulses of the k<sup>th</sup> codevector can be derived from its index k through a rule requiring no, or minimal, physical storage. Therefore, the size of an algebraic codebook is not limited by storage requirements. Algebraic codebooks can also be designed for efficient search.</p>
    <heading>OBJECTS OF THE INVENTION</heading> <p>An object of the present invention is therefore to provide a method and device for drastically reducing the complexity of the codebook search upon encoding an sound signal, these method and device being applicable to a large class of codebooks.</p>
    <p>Another object of the present invention is a method and device capable of selecting a-priori a subset of the codebook pulse combinations and restraining the combinations to be searched to this subset in view of reducing the codebook search complexity.</p>
    <p>A further object of the present invention is to increase the size of a codebook by allowing the individual non-zero-amplitude pulses of the codevectors to assume at least one of q possible amplitudes without increasing the search complexity.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>More particularly, in accordance with the present invention, there is provided a method of conducting a search in a codebook in view of encoding a sound signal, the codebook consisting of a set of pulse combinations and each pulse combination defining a plurality of different positions and comprising pulses assigned to respective positions of the combination, this method comprising the steps of:</p>
    <p>pre-selecting from the codebook a subset of pulse combinations in relation to the sound signal; and</p>
    <p>searching only the subset of pulse combinations in view of encoding the sound signal;</p>
    <p>whereby, in operation, complexity of the search is reduced as only a subset of the pulse combinations of the codebook is searched.</p>
    <p>The present invention also relates to a method of conducting a search in a codebook in view of encoding a sound signal, in which the codebook consists of a set of pulse amplitude/position combinations, each pulse amplitude/position combination defines L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, and each non-zero-amplitude pulses assumes at least one of q possible amplitudes. This method comprises the steps of:</p>
    <p>pre-selecting from the codebook a subset of pulse amplitude/position combinations in relation to the sound signal; and</p>
    <p>searching only the subset of pulse amplitude/position combinations in view of encoding the sound signal.</p>
    <p>Again, complexity of the search is reduced as only a subset of the pulse amplitude/position combinations of the codebook is searched.</p>
    <p>Still in accordance with the present invention, there is provided a device for conducting a search in a codebook in view of encoding a sound signal, the codebook consisting of a set of pulse combinations and each pulse combination defining a plurality of different positions and comprising pulses assigned to respective positions of the combination, the device comprising:</p>
    <p>means for pre-selecting from the codebook a subset of pulse combinations in relation to the sound signal; and</p>
    <p>means for searching only the subset of pulse combinations in view of encoding the sound signal.</p>
    <p>In operation, complexity of the search is reduced as only a subset of the pulse combinations of the codebook is searched.</p>
    <p>The subject invention further relates to a device for conducting a search in a codebook in view of encoding a sound signal, the codebook consisting of a set of pulse amplitude/position combinations, each pulse amplitude/position combination defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, and each non-zero-amplitude pulses assuming at least one of q possible amplitudes. This device comprises means for pre-selecting from the codebook a subset of pulse amplitude/position combinations in relation to the sound signal, and means for searching only the subset of pulse amplitude/position combinations in view of encoding the sound signal, whereby complexity of the search is reduced as only a subset of the pulse amplitude/position combinations of the codebook is searched.</p>
    <p>Still further in accordance with the present invention, there is provided a cellular communication system for servicing a large geographical area divided into a plurality of cells, comprising:</p>
    <p>mobile portable transmitter/receiver units;</p>
    <p>cellular base stations respectively situated in the cells;</p>
    <p>means for controlling communication between the cellular base stations;</p>
    <p>a bidirectional wireless communication sub-system between each mobile unit situated in one cell and the cellular base station of the one cell, the bidirectional wireless communication sub-system comprising in both the mobile unit and the cellular base station (a) a transmitter including means for encoding a speech signal and means for transmitting the encoded speech signal, and (b) a receiver including means for receiving a transmitted encoded speech signal and means for decoding the received encoded speech signal;</p>
    <p>wherein the speech signal encoding means comprises a device for conducting a search in a codebook in view of encoding the speech signal, the codebook consisting of a set of pulse combinations and each pulse combination defining a plurality of different positions and comprising pulses assigned to respective positions of the combination, the search conducting device comprising:</p>
    <p>means for pre-selecting from the codebook a subset of pulse combinations in relation to the speech signal; and</p>
    <p>means for searching only the subset of pulse combinations in view of encoding the speech signal;</p>
    <p>In operation, complexity of the search is still reduced as only a subset of the pulse combinations of the codebook is searched.</p>
    <p>Finally, the present invention is concerned with a cellular communication system for servicing a large geographical area divided into a plurality of cells, comprising:</p>
    <p>mobile portable transmitter/receiver units;</p>
    <p>cellular base stations respectively situated in the cells;</p>
    <p>means for controlling communication between the cellular base stations;</p>
    <p>a bidirectional wireless communication sub-system between each mobile unit situated in one cell and the cellular base station of the one cell, the bidirectional wireless communication sub-system comprising in both the mobile unit and the cellular base station (a) a transmitter including means for encoding a speech signal and means for transmitting the encoded speech signal, and (b) a receiver including means for receiving a transmitted encoded speech signal and means for decoding the received encoded speech signal;</p>
    <p>wherein the speech signal encoding means comprises a device for conducting a search in a codebook in view of encoding the speech signal, the codebook consisting of a set of pulse amplitude/position combinations, each pulse amplitude/position combination defining L different positions and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, and each non-zero-amplitude pulses assuming at least one of q possible amplitudes, the search conducting device comprising:</p>
    <p>means for pre-selecting from the codebook a subset of pulse amplitude/position combinations in relation to the speech signal; and</p>
    <p>means for searching only the subset of pulse amplitude/position combinations in view of encoding the speech signal.</p>
    <p>In operation, complexity of the search is reduced as only a subset of the pulse amplitude/position combinations of the codebook is searched.</p>
    <p>In accordance with a preferred embodiment of the invention, (a) the subset of pulse amplitude/position combinations is pre-selecting by pre-establishing, in relation to the sound signal, a function S<sub>p</sub> between the respective positions p=1, 2, . . . L and the q possible amplitudes, and (b) only the pulse amplitude/position combinations of the codebook having non-zero-amplitude pulses which respect the pre-established function are searched.</p>
    <p>Advantageously, the function S<sub>p</sub> is pre-established by pre-assigning, in relation to the sound signal, one of the q possible amplitudes to each position p, and the pre-established function is respected when the non-zero-amplitude pulses of a pulse amplitude/position combination each have an amplitude equal to the amplitude S<sub>p</sub> pre-assigned to the position p of the non-zero-amplitude pulse.</p>
    <p>Preferably, pre-assigning one of the q possible amplitudes to each position p comprises the steps of:</p>
    <p>processing the sound signal to produce a backward-filtered target signal D and a pitch-removed residual signal R';</p>
    <p>calculating an amplitude estimate vector B in response to the backward-filtered target signal D and to the pitch-removed residual signal R'; and</p>
    <p>for each of the positions p, quantizing an amplitude estimate B<sub>p</sub> of the vector B to obtain the amplitude to be selected for the position p.</p>
    <p>Calculation of the amplitude estimate vector B advantageously comprises the step of summing the backward-filtered target signal D in normalized form: ##EQU1## to the pitch-removed residual signal R' in normalized form: ##EQU2## to thereby obtain an amplitude estimate vector B of the form: ##EQU3## where β is a fixed constant preferably having a value situated between 0 and 1.</p>
    <p>According to a further preferred embodiment of the subject invention, quantizing is performed on a peak-normalized amplitude estimate B<sub>p</sub> of the vector B using the following expression: ##EQU4## wherein the denominator ##EQU5## is a normalizing factor representing a peak amplitude of the non-zero-amplitude pulses.</p>
    <p>The pulse combinations may each comprise a number N of non-zero-amplitude pulses, and the positions p of the non-zero-amplitude pulses are advantageously restrained in accordance with at least one N-interleaved single-pulse permutation code.</p>
    <p>Searching the codebook preferably comprises maximizing a given ratio having a denominator α<sub>k</sub> <sup>2</sup> computed by means of N nested loops in accordance with the following relation: ##EQU6## where computation for each loop is written in a separate line from an outermost loop to an innermost loop of the N nested loops, where p<sub>n</sub> is the position of the n<sup>th</sup> non-zero-amplitude pulse of the combination, and where U' (p<sub>x</sub>, p<sub>y</sub>) is a function dependent on the amplitude S<sub>p</sub>.sbsb.x pre-assigned to a position p<sub>x</sub> amongst the positions p and the amplitude S<sub>p</sub>.sbsb.y pre-assigned to a position p<sub>y</sub> amongst the positions p. In the above calculation, at least the innermost loop of the N nested loops may be skipped whenever the following inequality is true ##EQU7## where S<sub>p</sub>.sbsb.n is the amplitude pre-assigned to position p<sub>n</sub>, D<sub>p</sub>.sbsb.n is the p<sub>n</sub> <sup>th</sup> component of the target vector D, and T<sub>D</sub> is a threshold related to the backward-filtered target vector D.</p>
    <p>The objects, advantages and other features of the present invention will become more apparent upon reading of the following non restrictive description of a preferred embodiment thereof, given by way of example only with reference to the accompanying drawings.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>In the appended drawings:</p>
    <p>FIG. 1 is a schematic block diagram of a sound signal encoding device comprising an amplitude selector and an optimizing controller in accordance with the present invention;</p>
    <p>FIG. 2 is a schematic block diagram of a decoding device associated with the encoding device of FIG. 1;</p>
    <p>FIG. 3a is a sequence of basic operations for the fast codebook search in accordance with the present invention, based on signal-selected pulse amplitudes;</p>
    <p>FIG. 3b is a sequence of operations for pre-assigning one of the q amplitudes to each position p of the pulse amplitude/position combinations;</p>
    <p>FIG. 3c is a sequence of operations involved in the N-embedded loop search in which the innermost loop is skipped whenever the contribution of the first N-1 pulses to the numerator DA<sub>k</sub> <sup>T</sup> is deemed insufficient;</p>
    <p>FIG. 4 is a schematic representation of the N-nested loops used in the codebook search; and</p>
    <p>FIG. 5 is a schematic block diagram illustrating the infrastructure of a typical cellular communication system.</p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading> <p>FIG. 5 illustrates the infrastructure of a typical cellular communication system 1.</p>
    <p>Although application of the search conducting method and device according to the invention to a cellular communication system is disclosed as a non limitative example in the present specification, it should be kept in mind that these method and device can be used with the same advantages in many other types of communication systems in which sound signal encoding is required.</p>
    <p>In a cellular communication system such as 1, a telecommunications service is provided over a large geographic area by dividing that large area into a number of smaller cells. Each cell has a cellular base station 2 (FIG. 5) for providing radio signalling channels, and audio and data channels.</p>
    <p>The radio signalling channels are utilized to page mobile radio telephones (mobile transmitter/receiver units) such as 3 within the limits of the cellular base station's coverage area (cell), and to place calls to other radio telephones either inside or outside the base station's cell, or onto another network such as the Public Switched Telephone Network (PSTN) 4.</p>
    <p>Once a radio telephone 3 has successfully placed or received a call, an audio or data channel is set up with the cellular base station 2 corresponding to the cell in which the radio telephone 3 is situated, and communication between the base station 2 and radio telephone 3 occurs over that audio or data channel. The radio telephone 3 may also receive control or timing information over the signalling channel whilst a call is in progress.</p>
    <p>If a radio telephone 3 leaves a cell during a call and enters another cell, the radio telephone hands over the call to an available audio or data channel in the new cell. Similarly, if no call is in progress a control message is sent over the signalling channel such that the radio telephone logs onto the base station 2 associated with the new cell. In this manner mobile communication over a wide geographical area is possible.</p>
    <p>The cellular communication system 1 further comprises a terminal 5 to control communication between the cellular base stations 2 and the Public Switched Telephone Network 4, for example during a communication between a radio telephone 3 and the PSTN 4, or between a radio telephone 3 in a first cell and a radio telephone 3 in a second cell.</p>
    <p>Of course, a bidirectional wireless radio communication sub-system is required to establish communication between each radio telephone 3 situated in one cell and the cellular base station 2 of that cell. Such a bidirectional wireless radio communication system typically comprises in both the radio telephone 3 and the cellular base station 2 (a) a transmitter for encoding the speech signal and for transmitting the encoded speech signal through an antenna such as 6 or 7, and (b) a receiver for receiving a transmitted encoded speech signal through the same antenna 6 or 7 and for decoding the received encoded speech signal. As well known to those of ordinary skill in the art, voice encoding is required in order to reduce the bandwidth necessary to transmit speech across the bidirectional wireless radio communication system, i.e. between a radio telephone 3 and a base station 2.</p>
    <p>The aim of the present invention is to provide an efficient digital speech encoding technique with a good subjective quality/bit rate tradeoff for example for bidirectional transmission of speech signals between a cellular base station 2 and a radio telephone 3 through an audio or data channel. FIG. 1 is a schematic block diagram of a digital speech encoding device suitable for carrying out this efficient technique.</p>
    <p>The speech encoding device of FIG. 1 is the same encoding device as illustrated in FIG. 1 of U.S. parent patent application Ser. No. 07/927,528 to which an amplitude selector 112 in accordance with the present invention has been added. U.S. parent patent application Ser. No. 07/927,528 was filed on Sep. 10, 1992 for an invention entitled "DYNAMIC CODEBOOK FOR EFFICIENT SPEECH CODING BASED ON ALGEBRAIC CODES".</p>
    <p>The analog speech signal is sampled and block processed. It should be understood that the present invention is not limited to an application to speech signal. Encoding of other types of sound signal can also be contemplated.</p>
    <p>In the illustrated example, the block of input sampled speech S (FIG. 1) comprises L consecutive samples. In the CELP literature, L is designated as the "subframe" length and is typically situated between 20 and 80. Also, the blocks of L samples are referred to as L-dimensional vectors. Various L-dimensional vectors are produced in the course of the encoding procedure. A list of these vectors which appear in FIGS. 1 and 2, as well as a list of transmitted parameters is given hereinbelow:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________List of the main L-dimensional vectors:S             Input speech vector;R'            Pitch-removed residual vector;X             Target vector;D             Backward-filtered target vector;A<sub>k</sub>       Codevector of index k from the         algebraic codebook; andC<sub>k</sub>       Innovation vector (filtered         codevector).List of transmitted parameters:k             Codevector index (input of the         algebraic codebook);g             Gain;STP           Short term prediction parameters         (defining A(z)); andLTP           Long term prediction parameters         (defining a pitch gain b and a         pitch delay T).______________________________________</pre>
    
    <heading>DECODING PRINCIPLE</heading> <p>It is believed preferable to describe first the speech decoding device of FIG. 2 illustrating the various steps carried out between the digital input (input of demultiplexer 205) and the output sampled speech (output of synthesis filter 204).</p>
    <p>The demultiplexer 205 extracts four different parameters from the binary information received from a digital input channel, namely the index k, the gain g, the short term prediction parameters STP, and the long term prediction parameters LTP. The current L-dimensional vector S of speech signal is synthesized on the basis of these four parameters as will be explained in the following description.</p>
    <p>The speech decoding device of FIG. 2 comprises a dynamic codebook 208 composed of an algebraic code generator 201 and an adaptive prefilter 202, an amplifier 206, an adder 207, a long term predictor 203, and a synthesis filter 204.</p>
    <p>In a first step, the algebraic code generator 201 produces a codevector A<sub>k</sub> in response to the index k.</p>
    <p>In a second step, the codevector A<sub>k</sub> is processed by an adaptive prefilter 202 supplied with the long term prediction parameters LTP to produce an output innovation vector C<sub>k</sub>. The purpose of the adaptive prefilter 202 is to dynamically control the frequency content of the output innovation vector C<sub>k</sub> so as to enhance speech quality, i.e. to reduce the audible distortion caused by frequencies annoying the human ear. Typical transfer functions F(z) for the adaptive prefilter 202 are given below: ##EQU8##</p>
    <p>F<sub>a</sub> (z) is a formant prefilter in which 0&lt;γ<sub>1</sub> &lt;γ<sub>2</sub> &lt;1 are constants. This prefilter enhances the formant regions and works very effectively specially at coding rate below 5 kbit/s.</p>
    <p>F<sub>b</sub> (z) is a pitch prefilter where T is the time varying pitch delay and b<sub>0</sub> is either constant or equal to the quantized long term pitch prediction parameter from the current or previous subframes. F<sub>b</sub> (z) is very effective to enhance pitch harmonic frequencies at all rates. Therefore, F(z) typically includes a pitch prefilter sometimes combined with a formant prefilter, namely:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">F(z)=F<sub>a</sub> (z) F<sub>b</sub> (z)</pre>
    
    <p>In accordance with the CELP technique, the output sampled speech signal S is obtained by first scaling the innovation vector C<sub>k</sub> from the codebook 208 by the gain g through the amplifier 206. The adder 207 then adds the scaled waveform gC<sub>k</sub> to the output E (the long term prediction component of the signal excitation of the synthesis filter 204) of a long term predictor 203 supplied with the LTP parameters, placed in a feedback loop and having a transfer function B(z) defined as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">B(z)=bz<sup>-T</sup> </pre>
    
    <p>where b and T are the above defined pitch gain and delay, respectively.</p>
    <p>The predictor 203 is a filter having a transfer function being in accordance with the last received LTP parameters b and T to model the pitch periodicity of speech. It introduces the appropriate pitch gain b and delay T of samples. The composite signal E+gC<sub>k</sub> constitutes the signal excitation of the synthesis filter 204 which has a transfer function 1/A(z) (A(z) being defined in the following description) . The filter 204 provides the correct spectrum shaping in accordance with the last received STP parameters. More specifically, the filter 204 models the resonant frequencies (formants) of speech. The output block S is the synthesized sampled speech signal which can be converted into an analog signal with proper anti-aliasing filtering in accordance with a technique well known in the art.</p>
    <p>There are many ways to design an algebraic code generator 201. An advantageous method, disclosed in the above mentioned U.S. patent application Ser. No. 07/927,528, consists of using at least one N-interleaved single-pulse permutation code.</p>
    <p>This concept will be illustrated by way of a simple algebraic code generator 201. In this example, L=40 and the set of 40-dimensional codevectors contains only N=5 non-zero-amplitude pulses that will be called S<sub>p</sub>.sbsb.1, S<sub>p</sub>.sbsb.2, S<sub>p</sub>.sbsb.3, S<sub>p</sub>.sbsb.4, S<sub>p</sub>.sbsb.5. In this more thorough notation, p<sub>i</sub> stands for the location of the i<sup>th</sup> pulse within the subframe (i.e., p<sub>i</sub> ranges from 0 to L-1). Suppose that pulse S<sub>p</sub>.sbsb.1 is constrained to eight possible positions p<sub>1</sub> as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>1</sub> =0,5,10,15,20,25,30,35=0+8m<sub>1</sub> ; m<sub>1</sub> =0,1 . . . 7</pre>
    
    <p>Within these eight positions, which can be called "track"#1, S<sub>p</sub>.sbsb.1 and seven zero-amplitude pulses can freely permute. This is a "single-pulse permutation code". Let us now interleave five such "single pulse permutation codes" by also constraining the positions of the remaining pulses in a similar fashion (i.e. track #2, track #3, track #4, and track #5).</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>1</sub> =0,5,10,15,20,25,30,35=0+8m<sub>1</sub> </pre>
    
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>2</sub> =1,6,11,16,21,26,31,36=1+8m<sub>2</sub> </pre>
    
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>3</sub> =2,7,12,17,22,27,32,37=2+8m<sub>3</sub> </pre>
    
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>4</sub> =3,8,13,18,23,28,33,38=3+8m<sub>4</sub> </pre>
    
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>5</sub> =4,9,14,19,24,29,34,39=4+8m<sub>5</sub> </pre>
    
    <p>Note that the integers m<sub>i</sub> =0, 1, . . ., 7 fully define the position p<sub>i</sub> of each pulse S<sub>p</sub>.sbsb.i. Thus, a simple position index k<sub>p</sub> can be derived through straightforward multiplexing of the m<sub>i</sub> 's using the following relation:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">k<sub>p</sub> =4096 m<sub>1</sub> +512 m<sub>2</sub> +64 m<sub>3</sub> +8 m<sub>4</sub> +m<sub>5</sub> </pre>
    
    <p>It should be pointed out that other codebooks can be derived using the above pulse tracks. For instance, only 4 pulses can be used, where the first three pulses occupy the positions in the first three tracks, respectively, while the fourth pulse occupies either the fourth or the fifth track with one bit to specify which track. This design gives rise to a 13 bit position codebook.</p>
    <p>In the prior art, the non-zero-amplitude pulses were assumed to have a fixed amplitude for all practical purposes for reasons of codevector search complexity. Indeed, if pulse S<sub>p</sub>.sbsb.i may assume one of q possible amplitudes, as many as q<sup>N</sup> pulse-amplitude combinations will have to be considered in the search. For instance, if the five pulses of the first example are allowed to take one of q=4 possible amplitudes, for example S<sub>p</sub>.sbsb.i =+1, -1, +2, -2 instead of a fixed amplitude, the algebraic codebook size jumps from 15 to 15+(5×2) bits=25 bits; that is, a search a thousand time more complex.</p>
    <p>It is the purpose of the present invention to disclose the surprising fact that very good performance can be achieved with q-amplitude pulses without paying a heavy price. The solution consists of limiting the search to a restrained subset of codevectors. The method of selecting the codevectors is related to the input speech signal as will be described in the following description.</p>
    <p>The practical benefit of the present invention is to enable an increase of the size of the dynamic algebraic codebook 208 by allowing individual pulses to assume different possible amplitudes without increasing the codevector search complexity.</p>
    <heading>ENCODING PRINCIPLE</heading> <p>The sampled speech signal S is encoded on a block by block basis by the encoding system of FIG. 1 which is broken down into 11 modules numbered from 102 to 112. The function and operation of most of these modules are unchanged with respect to the description of U.S. parent patent application Ser. No. 07/927,528. Therefore, although the following description will at least briefly explain the function and operation of each module, it will concentrate on the matter which is new with respect to the disclosure of U.S. parent patent application Ser. No. 07/927,528.</p>
    <p>For each block of L samples of speech signal, a set of Linear Predictive Coding (LPC) parameters, called short term prediction (STP) parameters, is produced in accordance with a prior art technique through an LPC spectrum analyser 102. More specifically, the analyser 102 models the spectral characteristics of each block S of L samples.</p>
    <p>The input block S of L-sample is whitened by a whitening filter 103 having the following transfer function based on the current values of the STP parameters: ##EQU9## where a<sub>0</sub> =1, and z is the usual variable of the so-called z-transform. As illustrated in FIG. 1, the whitening filter 103 produces a residual vector R.</p>
    <p>A pitch extractor 104 is used to compute and quantize the LTP parameters, namely the pitch delay T and the pitch gain g. The initial state of the extractor 104 is also set to a value FS from an initial state extractor 110. A detailed procedure for computing and quantizing the LTP parameters is described in U.S. parent patent application Ser. No. 07/927,528 and is believed to be well known to those of ordinary skill in the art. Accordingly, it will not be further described in the present disclosure.</p>
    <p>A filter responses characterizer 105 (FIG. 1) is supplied with the STP and LTP parameters to compute a filter responses characterization FRC for use in the later steps. The FRC information consists of the following three components where n=1, 2, . . . L. ##EQU10##</p>
    <p>The long term predictor 106 is supplied with the past excitation signal (i.e. E+gC<sub>k</sub> of the previous subframe) for form the new E component using proper pitch delay T and gain b.</p>
    <p>The initial state of the perceptual filter 107 is set to the value FS supplied from the initial state extractor 110. The pitch removed residual vector R'=R-E calculated by a subtractor 121 (FIG. 1) is then supplied to the perceptual filter 107 to obtain at the output of the latter filter a target vector X. As illustrated in FIG. 1, the STP parameters are applied to the filter 107 to vary its transfer function in relation to these parameters. Basically, X=R'-P where P represents the contribution of the long term prediction (LTP) including "ringing" from the past excitations. The MSE criterion which applies to Δ can now be stated in the following matrix notations: ##EQU11## where H is an L×L lower-triangular Toeplitz matrix formed from the h(n) response as follows. The term h(0) occupies the matrix diagonal and h(1), h(2), . . . h(L-1) occupy the respective lower diagonals.</p>
    <p>A backward filtering step is performed by the filter 108 of FIG. 1. Setting to zero the derivative of the above equation with respect to the gain g yields to the optimum gain as follows: ##EQU12## With this value for g, the minimization becomes: ##EQU13## The objective is to find the particular index k for which the minimization is achieved. Note that because ∥X∥<sup>2</sup> is a fixed quantity, the same index can be found by maximizing the following quantity: ##EQU14##  where D=(XH) and α<sub>k</sub> <sup>2</sup> =∥A<sub>k</sub> H<sup>T</sup> ∥<sup>2</sup>.</p>
    <p>In the backward filter 108, a backward filtered target vector D=(XH) is computed. The term "backward filtering" for this operation comes from the interpretation of (XH) as the filtering of time-reversed X.</p>
    <p>Only an amplitude selector 112 has been added to FIG. 1 of the above mentioned U.S. parent patent application Ser. No. 07/927,528. The function of the amplitude selector 112 is to restrain the codevectors A<sub>k</sub> being searched by the optimizing controller 109 to the most promising codevectors A<sub>k</sub> to thereby reduce the codevector search complexity. As described in the foregoing description, each codevector A<sub>k</sub> is a pulse amplitude/position combination waveform defining L different positions p and comprising both zero-amplitude pulses and non-zero-amplitude pulses assigned to respective positions p=1, 2, . . . L of the combination, wherein each non-zero-amplitude pulse assumes at least one of q different possible amplitudes.</p>
    <p>Referring now to FIG. 3a, 3b and 3c, the purpose of the amplitude selector 112 is to pre-establish a function S<sub>p</sub> between the positions p of the codevector waveform and the q possible values of the pulse amplitudes. The pre-established function S<sub>p</sub> is derived in relation to the speech signal prior to the codebook search. More specifically, pre-establishing this function consists of pre-assigning, in relation to the speech signal, at least one of the q possible amplitudes to each position p of the waveform (step 301 of FIG. 3a).</p>
    <p>To pre-assign one of the q amplitudes to each position p of the waveform, an amplitude estimate vector B is calculated in response to the backward-filtered target vector D and to the pitch-removed residual vector R'. More specifically, the amplitude estimate vector B is calculated by summing (substep 301-1 of FIG. 3b) the backward-filtered target vector D in normalized form: ##EQU15## and the pitch-removed residual vector R' in normalized form: ##EQU16## to thereby obtain an amplitude estimate vector B of the form: ##EQU17## where β is a fixed constant having a typical value of 1/2 (the value of β is chosen between 0 and 1 depending on the percentage of non-zero-amplitude pulses used in the algebraic code).</p>
    <p>For each position p of the waveform, the amplitude S<sub>p</sub> to be pre-assigned to that position p is obtained by quantizing a corresponding amplitude estimate B<sub>p</sub> of vector B. More specifically, for each position p of the waveform, a peak-normalized amplitude estimate B<sub>p</sub> of the vector B is quantized (substep 301-2 of FIG. 3b) using the following expression: ##EQU18## wherein Q (.) is the quantization function and ##EQU19## is a normalisation factor representing a peak amplitude of the non-zero-amplitude pulses.</p>
    <p>In the important special case in which:</p>
    <p>- q=2, that is the pulse amplitudes can assume only two values (i.e. S<sub>p</sub>.sbsb.i =±1); and</p>
    <p>- the non-zero-amplitude pulse density N/L is lower than or equal to 15%;</p>
    <p>the value of β can be equal to zero; then the amplitude estimate vector B reduces simply to the backward-filtered target vector D and consequently S<sub>p=sign</sub>(D<sub>p</sub>).</p>
    <p>The purpose of the optimizing controller 109 is to select the best codevector A<sub>k</sub> from the algebraic codebook. The selection criterion is given in the form of a ration to be calculated for each codevector A<sub>k</sub> and to be maximized over all codevectors (step 303) ##EQU20## where D=(XH) and α<sub>k</sub> <sup>2</sup> =∥A<sub>k</sub> H<sup>T</sup> ∥<sup>2</sup>.</p>
    <p>Since A<sub>k</sub> is an algebraic codevector having N non-zero-amplitude pulses of respective amplitudes S<sub>p</sub>.sbsb.i, the numerator is the square of ##EQU21## and the denominator is an energy term which can be expressed as: ##EQU22## where U(p<sub>i</sub>,p<sub>j</sub>) is the correlation associated with two unit-amplitude pulses, one at position p<sub>i</sub> and the other at position p<sub>j</sub>. This matrix is computed in accordance with the above equation in the filter response characterizer 105 and included in the set of parameters referred to as FRC in the block diagram of FIG. 1.</p>
    <p>A fast method for computing this denominator (step 304) involves the N-nested loops illustrated in FIG. 4 in which the trim lined notation S(i) and SS(i,j) is used in the place of the respective quantities "S<sub>p</sub>.sbsb.i " and "S<sub>p</sub>.sbsb.i S<sub>p</sub>.sbsb.j ". Computation of the denominator α<sub>k</sub> <sup>2</sup> is the most time consuming process. The computations contributing to α<sub>k</sub> <sup>2</sup> which are performed in each loop of FIG. 4 can be written on separate lines from the outermost loop to the innermost loop as follows: ##EQU23## where p<sub>i</sub> is the position of the i<sup>th</sup> non-zero-amplitude pulse. Note that the N-nested loops of FIG. 4 enables constraining the non-zero-amplitude pulses of codevectors A<sub>k</sub> in accordance with N interleaved single-pulse permutation codes.</p>
    <p>In the present invention search complexity is drastically reduced by restraining the subset of codevectors A<sub>k</sub> being searched to codevectors of which the N non-zero-amplitude pulses respect the function pre-established in step 301 of FIG. 3a. The pre-established function is respected when the N non-zero-amplitude pulses of a codevector A<sub>k</sub> each have an amplitude equal to the amplitude pre-assigned to the position p of the non-zero-amplitude pulse.</p>
    <p>Said restraining the subset of codevectors is preformed by first combining the pre-established function S<sub>p</sub> with the entries of matrix U(i,j) (step 302 of FIG. 3a) then, by using the N-nested loops of FIG. 4 with all pulses S(i) assumed to be fixed, positive and of unit amplitude (step 303). Thus, even though the amplitude of non-zero pulses can take any of q possible values in the algebraic codebook, the search complexity is reduced to the case of fixed pulse amplitudes. More precisely, the matrix U(i,j) which is supplied by the filter response characterizer 105 is combined with the pre-established function in accordance with the following relation (step 302):</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">U'(i,j)=S<sub>i</sub> S<sub>j</sub> U(i,j)</pre>
    
    <p>where S<sub>i</sub> results from the selecting method of amplitude selector 112, namely S<sub>i</sub> is the amplitude selected for an individual position i following quantization of the corresponding amplitude estimate.</p>
    <p>With this new matrix, the computation for each loop of the fast algorithm can be written on a separate line, from the outermost to the innermost loop, as follows: ##EQU24## where p<sub>x</sub> is the position of the x<sup>th</sup> non-zero-amplitude pulse of the waveform, and where U'(p<sub>x</sub>,p<sub>y</sub>) is a function dependent on the amplitude S<sub>p</sub>.sbsb.x pre-assigned to a position p<sub>x</sub> amongst the positions p and the amplitude S<sub>p</sub>.sbsb.y pre-assigned to a position p<sub>y</sub> amongst the positions p.</p>
    <p>To still further reduce the search complexity, one may skip (cf FIG. 3c) in particular, but not exclusively, the innermost loop whenever the following inequality is true: ##EQU25## where S<sub>p</sub>.sbsb.n is the amplitude pre-assigned to position p<sub>n</sub>, D<sub>p</sub>.sbsb.n is the p<sub>n</sub> <sup>th</sup> component of the target vector D, and T<sub>D</sub> is a threshold related to the backward-filtered target vector D.</p>
    <p>The global signal excitation signal E+gCk is computed by an adder 120 (FIG. 1) from the signal gCk from the controller 109 and the output E from the predictor 106. The initial state extractor module 110, constituted by a perceptual filter with a transfer function 1/A(zγ<sup>-1</sup>) varying in relation to the STP parameters, subtracts from the residual signal R the signal excitation signal E+gCk for the sole purpose of obtaining the final filter state FS for use as initial state in filter 107 and pitch extractor 104.</p>
    <p>The set of four parameters k, g, LTP and STP are converted into the proper digital channel format by a multiplexer 111 completing the procedure for encoding a block S of samples of speech signal.</p>
    <p>Although the present invention has been described hereinabove with reference to preferred embodiments thereof, these embodiments can be modified at will, within the scope of the appended claims, without departing from the spirit and nature of the subject invention.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4401855">US4401855</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 28, 1980</td><td class="patent-data-table-td patent-date-value">Aug 30, 1983</td><td class="patent-data-table-td ">The Regents Of The University Of California</td><td class="patent-data-table-td ">Apparatus for the linear predictive coding of human speech</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4486899">US4486899</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 16, 1982</td><td class="patent-data-table-td patent-date-value">Dec 4, 1984</td><td class="patent-data-table-td ">Nippon Electric Co., Ltd.</td><td class="patent-data-table-td ">System for extraction of pole parameter values</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4520499">US4520499</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 25, 1982</td><td class="patent-data-table-td patent-date-value">May 28, 1985</td><td class="patent-data-table-td ">Milton Bradley Company</td><td class="patent-data-table-td ">Combination speech synthesis and recognition apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4594687">US4594687</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 26, 1983</td><td class="patent-data-table-td patent-date-value">Jun 10, 1986</td><td class="patent-data-table-td ">Nippon Telegraph &amp; Telephone Corporation</td><td class="patent-data-table-td ">Address arithmetic circuit of a memory unit utilized in a processing system of digitalized analogue signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4625286">US4625286</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 3, 1982</td><td class="patent-data-table-td patent-date-value">Nov 25, 1986</td><td class="patent-data-table-td ">Texas Instruments Incorporated</td><td class="patent-data-table-td ">Time encoding of LPC roots</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4667340">US4667340</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 13, 1983</td><td class="patent-data-table-td patent-date-value">May 19, 1987</td><td class="patent-data-table-td ">Texas Instruments Incorporated</td><td class="patent-data-table-td ">Voice messaging system with pitch-congruent baseband coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4669120">US4669120</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 2, 1984</td><td class="patent-data-table-td patent-date-value">May 26, 1987</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Low bit-rate speech coding with decision of a location of each exciting pulse of a train concurrently with optimum amplitudes of pulses</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4677671">US4677671</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 18, 1983</td><td class="patent-data-table-td patent-date-value">Jun 30, 1987</td><td class="patent-data-table-td ">International Business Machines Corp.</td><td class="patent-data-table-td ">Method and device for coding a voice signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4680797">US4680797</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 26, 1984</td><td class="patent-data-table-td patent-date-value">Jul 14, 1987</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Air Force</td><td class="patent-data-table-td ">Secure digital speech communication</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4710959">US4710959</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 29, 1982</td><td class="patent-data-table-td patent-date-value">Dec 1, 1987</td><td class="patent-data-table-td ">Massachusetts Institute Of Technology</td><td class="patent-data-table-td ">Voice encoder and synthesizer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4720861">US4720861</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 24, 1985</td><td class="patent-data-table-td patent-date-value">Jan 19, 1988</td><td class="patent-data-table-td ">Itt Defense Communications A Division Of Itt Corporation</td><td class="patent-data-table-td ">Digital speech coding circuit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4724535">US4724535</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 16, 1985</td><td class="patent-data-table-td patent-date-value">Feb 9, 1988</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Low bit-rate pattern coding with recursive orthogonal decision of parameters</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4742550">US4742550</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 17, 1984</td><td class="patent-data-table-td patent-date-value">May 3, 1988</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Residual excited linear predictive coder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4764963">US4764963</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 12, 1987</td><td class="patent-data-table-td patent-date-value">Aug 16, 1988</td><td class="patent-data-table-td ">American Telephone And Telegraph Company, At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Speech pattern compression arrangement utilizing speech event identification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4771465">US4771465</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 11, 1986</td><td class="patent-data-table-td patent-date-value">Sep 13, 1988</td><td class="patent-data-table-td ">American Telephone And Telegraph Company, At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Processing system for synthesizing voice from encoded information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4797925">US4797925</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 26, 1986</td><td class="patent-data-table-td patent-date-value">Jan 10, 1989</td><td class="patent-data-table-td ">Bell Communications Research, Inc.</td><td class="patent-data-table-td ">Method for coding speech at low bit rates</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4797926">US4797926</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 11, 1986</td><td class="patent-data-table-td patent-date-value">Jan 10, 1989</td><td class="patent-data-table-td ">American Telephone And Telegraph Company, At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Digital speech vocoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4799261">US4799261</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 8, 1987</td><td class="patent-data-table-td patent-date-value">Jan 17, 1989</td><td class="patent-data-table-td ">Texas Instruments Incorporated</td><td class="patent-data-table-td ">Low data rate speech encoding employing syllable duration patterns</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4811398">US4811398</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 24, 1986</td><td class="patent-data-table-td patent-date-value">Mar 7, 1989</td><td class="patent-data-table-td ">Cselt-Centro Studi E Laboratori Telecomunicazioni S.P.A.</td><td class="patent-data-table-td ">Method of and device for speech signal coding and decoding by subband analysis and vector quantization with dynamic bit allocation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4815134">US4815134</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 8, 1987</td><td class="patent-data-table-td patent-date-value">Mar 21, 1989</td><td class="patent-data-table-td ">Texas Instruments Incorporated</td><td class="patent-data-table-td ">Very low rate speech encoder and decoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4817157">US4817157</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 7, 1988</td><td class="patent-data-table-td patent-date-value">Mar 28, 1989</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Digital speech coder having improved vector excitation source</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4821324">US4821324</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 24, 1985</td><td class="patent-data-table-td patent-date-value">Apr 11, 1989</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Low bit-rate pattern encoding and decoding capable of reducing an information transmission rate</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4858115">US4858115</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 31, 1985</td><td class="patent-data-table-td patent-date-value">Aug 15, 1989</td><td class="patent-data-table-td ">Unisys Corporation</td><td class="patent-data-table-td ">Loop control mechanism for scientific processor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4860355">US4860355</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 15, 1987</td><td class="patent-data-table-td patent-date-value">Aug 22, 1989</td><td class="patent-data-table-td ">Cselt Centro Studi E Laboratori Telecomunicazioni S.P.A.</td><td class="patent-data-table-td ">Method of and device for speech signal coding and decoding by parameter extraction and vector quantization techniques</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4864620">US4864620</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 3, 1988</td><td class="patent-data-table-td patent-date-value">Sep 5, 1989</td><td class="patent-data-table-td ">The Dsp Group, Inc.</td><td class="patent-data-table-td ">Method for performing time-scale modification of speech information or speech signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4868867">US4868867</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 6, 1987</td><td class="patent-data-table-td patent-date-value">Sep 19, 1989</td><td class="patent-data-table-td ">Voicecraft Inc.</td><td class="patent-data-table-td ">Vector excitation speech or audio coder for transmission or storage</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4873723">US4873723</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 16, 1987</td><td class="patent-data-table-td patent-date-value">Oct 10, 1989</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Method and apparatus for multi-pulse speech coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4964169">US4964169</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 15, 1989</td><td class="patent-data-table-td patent-date-value">Oct 16, 1990</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Method and apparatus for speech coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4991214">US4991214</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 26, 1988</td><td class="patent-data-table-td patent-date-value">Feb 5, 1991</td><td class="patent-data-table-td ">British Telecommunications Public Limited Company</td><td class="patent-data-table-td ">Speech coding using sparse vector codebook and cyclic shift techniques</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5097508">US5097508</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 31, 1989</td><td class="patent-data-table-td patent-date-value">Mar 17, 1992</td><td class="patent-data-table-td ">Codex Corporation</td><td class="patent-data-table-td ">Digital speech coder having improved long term lag parameter determination</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5193140">US5193140</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 30, 1990</td><td class="patent-data-table-td patent-date-value">Mar 9, 1993</td><td class="patent-data-table-td ">Telefonaktiebolaget L M Ericsson</td><td class="patent-data-table-td ">Excitation pulse positioning method in a linear predictive speech coder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5293449">US5293449</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 29, 1992</td><td class="patent-data-table-td patent-date-value">Mar 8, 1994</td><td class="patent-data-table-td ">Comsat Corporation</td><td class="patent-data-table-td ">Analysis-by-synthesis 2,4 kbps linear predictive speech codec</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5307441">US5307441</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 29, 1989</td><td class="patent-data-table-td patent-date-value">Apr 26, 1994</td><td class="patent-data-table-td ">Comsat Corporation</td><td class="patent-data-table-td ">Wear-toll quality 4.8 kbps speech codec</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5457783">US5457783</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 7, 1992</td><td class="patent-data-table-td patent-date-value">Oct 10, 1995</td><td class="patent-data-table-td ">Pacific Communication Sciences, Inc.</td><td class="patent-data-table-td ">Adaptive speech coder having code excited linear prediction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0138061A1?cl=en">EP0138061A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 12, 1984</td><td class="patent-data-table-td patent-date-value">Apr 24, 1985</td><td class="patent-data-table-td ">Siemens Aktiengesellschaft</td><td class="patent-data-table-td ">Method of determining speech spectra with an application to automatic speech recognition and speech coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0149724A1?cl=en">EP0149724A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 8, 1984</td><td class="patent-data-table-td patent-date-value">Jul 31, 1985</td><td class="patent-data-table-td ">Northern Telecom Limited</td><td class="patent-data-table-td ">Method and apparatus for coding digital signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0342687A2?cl=en">EP0342687A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 19, 1989</td><td class="patent-data-table-td patent-date-value">Nov 23, 1989</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Coded speech communication system having code books for synthesizing small-amplitude components</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0446817A2?cl=en">EP0446817A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 8, 1991</td><td class="patent-data-table-td patent-date-value">Sep 18, 1991</td><td class="patent-data-table-td ">Gte Laboratories Incorporated</td><td class="patent-data-table-td ">Method for reducing the search complexity in analysis-by-synthesis coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0514912A2?cl=en">EP0514912A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 21, 1992</td><td class="patent-data-table-td patent-date-value">Nov 25, 1992</td><td class="patent-data-table-td ">Nippon Telegraph And Telephone Corporation</td><td class="patent-data-table-td ">Speech coding and decoding methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0532225A2?cl=en">EP0532225A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 3, 1992</td><td class="patent-data-table-td patent-date-value">Mar 17, 1993</td><td class="patent-data-table-td ">AT&amp;amp;T Corp.</td><td class="patent-data-table-td ">Method and apparatus for speech coding and decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0545386A2?cl=en">EP0545386A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 2, 1992</td><td class="patent-data-table-td patent-date-value">Jun 9, 1993</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Method for speech coding and voice-coder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1990000381A1?cl=en">WO1990000381A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 10, 1989</td><td class="patent-data-table-td patent-date-value">Jan 25, 1990</td><td class="patent-data-table-td ">Kci Medical United Kingdom Lim</td><td class="patent-data-table-td ">Improved fluidized bead bed</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1991013432A1?cl=en">WO1991013432A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 6, 1990</td><td class="patent-data-table-td patent-date-value">Sep 5, 1991</td><td class="patent-data-table-td ">Univ Sherbrooke</td><td class="patent-data-table-td ">Dynamic codebook for efficient speech coding based on algebraic codes</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="8+kbits%2Fs+Speech+Coder+with+Pitch+Adaptive+Vector+Quantizer"'>8 kbits/s Speech Coder with Pitch Adaptive Vector Quantizer</a>" S. Iai and K. Irie, ICASSP 1986, Tokyo, vol. 3, Apr. 1986, pp. 1697-1700.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="A+comparision+of+some+alegbraic+structures+for+CELP+coding+of+speech"'>A comparision of some alegbraic structures for CELP coding of speech</a>" J-P. Adoul et al. ICASSP 87 Proceedings, Apr. 6-9, 1987, Dallas, Texas pp. 1953-1956.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="A+robust+16+Kbits%2Fs+vector+adaptive+predictive+coder+for+mobile+communications"'>A robust 16 Kbits/s vector adaptive predictive coder for mobile communications</a>" A. Le Guyader et al. ICASSP 86 Prooceedings, Apr. 7-11, Tokyo, Japan pp. 857-860.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Algorithme+de+quantification+vectorielle+spherique+a+partir+du+reseau+de+Gosset+d%27ordre+8"'>Algorithme de quantification vectorielle spherique a partir du reseau de Gosset d'ordre 8</a>" C. Lamblin et J.P. Adoul, Annales es Telecommunications, 1988, vol. 43, No. 1-2, pp. 172-186.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Coding+of+Speech+at+8+kbit%2Fs+using+Conjugate-structure+Algebraic-code-excited+Linear-Predictive+%28CS-ACELP%29+Coding"'>Coding of Speech at 8 kbit/s using Conjugate-structure Algebraic-code-excited Linear-Predictive (CS-ACELP) Coding</a>" Study Group 15 contrib., Int. Telecom. Union Jun. 1995, pp. 1-43.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Fast+CELP+coding+based+on+algebraic+codes"'>Fast CELP coding based on algebraic codes</a>" J-P. Adoul et al. ICASSP 87 Proceedings Apr. 6-9, 1987, Dallas Texas pp. 1957-1960.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Fast+Methods+for+Code+Search+in+CELP"'>Fast Methods for Code Search in CELP</a>" M.E. Ahmed and M.I. Al-Suwaiyel, IEEE Transactions on Speech and Audio Processing, 1993, vol. 1, No. 3, New York, pp. 315-325.</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Multipulse+excitation+codebook+design+and+fast+search+methods+for+CELP+speech+coding"'>Multipulse excitation codebook design and fast search methods for CELP speech coding</a>" F.F. Tzeng IEEE Glob. Telcom. Conf. &amp; Exhib., Nov. 28-Dec. 1, 1988 Hollywood Fla, pp. 0590-0594.</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">8 kbits/s Speech Coder with Pitch Adaptive Vector Quantizer S. Iai and K. Irie, ICASSP 1986, Tokyo, vol. 3, Apr. 1986, pp. 1697 1700.</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">A comparision of some alegbraic structures for CELP coding of speech J P. Adoul et al. ICASSP 87 Proceedings, Apr. 6 9, 1987, Dallas, Texas pp. 1953 1956.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">A robust 16 Kbits/s vector adaptive predictive coder for mobile communications A. Le Guyader et al. ICASSP 86 Prooceedings, Apr. 7 11, Tokyo, Japan pp. 857 860.</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Abstract of "<a href='http://scholar.google.com/scholar?q="Low+delay+speech+coding"'>Low delay speech coding</a>", Cuperman, et al., Journal Speech Communication, vol. 12, No. 2, Netherlands, Jun. 1993, pp. 193-204.</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Abstract of Low delay speech coding , Cuperman, et al., Journal Speech Communication, vol. 12, No. 2, Netherlands, Jun. 1993, pp. 193 204.</td></tr><tr><td class="patent-data-table-td ">14</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Algorithme de quantification vectorielle sph e rique a partir du r e seau de Gosset d ordre 8 C. Lamblin et J.P. Adoul, Annales es T e l e communications, 1988, vol. 43, No. 1 2, pp. 172 186.</td></tr><tr><td class="patent-data-table-td ">15</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Claude Laflamme, Jean Pierre Adoul, R. Salami, S. Morisette, and P. Mabilleau, 16 Kbps Wideband Speech Coding Technique Based on Algebraic CELP , Proceeding of IEEE ICASSP 91, session S1.4, pp. 13 16, May 1991.</td></tr><tr><td class="patent-data-table-td ">16</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Claude Laflamme, Jean-Pierre Adoul, R. Salami, S. Morisette, and P. Mabilleau, "<a href='http://scholar.google.com/scholar?q="16+Kbps+Wideband+Speech+Coding+Technique+Based+on+Algebraic+CELP"'>16 Kbps Wideband Speech Coding Technique Based on Algebraic CELP</a>", Proceeding of IEEE ICASSP 91, session S1.4, pp. 13-16, May 1991.</td></tr><tr><td class="patent-data-table-td ">17</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Coding of Speech at 8 kbit/s using Conjugate structure Algebraic code excited Linear Predictive (CS ACELP) Coding Study Group 15 contrib., Int. Telecom. Union Jun. 1995, pp. 1 43.</td></tr><tr><td class="patent-data-table-td ">18</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Fast CELP coding based on algebraic codes J P. Adoul et al. ICASSP 87 Proceedings Apr. 6 9, 1987, Dallas Texas pp. 1957 1960.</td></tr><tr><td class="patent-data-table-td ">19</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Fast Methods for Code Search in CELP M.E. Ahmed and M.I. Al Suwaiyel, IEEE Transactions on Speech and Audio Processing, 1993, vol. 1, No. 3, New York, pp. 315 325.</td></tr><tr><td class="patent-data-table-td ">20</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Laflamme, et al., "<a href='http://scholar.google.com/scholar?q="On+Reducing+Computational+Complexity+of+Codebook+Search+in+CELP+Coder+Through+the+Use+of+Algebraic+Codes"'>On Reducing Computational Complexity of Codebook Search in CELP Coder Through the Use of Algebraic Codes</a>", Proceeding of the IEEE ICASSP 1990, pp. 177-180.</td></tr><tr><td class="patent-data-table-td ">21</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Laflamme, et al., On Reducing Computational Complexity of Codebook Search in CELP Coder Through the Use of Algebraic Codes , Proceeding of the IEEE ICASSP 1990, pp. 177 180.</td></tr><tr><td class="patent-data-table-td ">22</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Multipulse excitation codebook design and fast search methods for CELP speech coding F.F. Tzeng IEEE Glob. Telcom. Conf. &amp; Exhib., Nov. 28 Dec. 1, 1988 Hollywood Fla, pp. 0590 0594.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5822724">US5822724</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 14, 1995</td><td class="patent-data-table-td patent-date-value">Oct 13, 1998</td><td class="patent-data-table-td ">Nahumi; Dror</td><td class="patent-data-table-td ">Optimized pulse location in codebook searching techniques for speech processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5963897">US5963897</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 27, 1998</td><td class="patent-data-table-td patent-date-value">Oct 5, 1999</td><td class="patent-data-table-td ">Lernout &amp; Hauspie Speech Products N.V.</td><td class="patent-data-table-td ">Apparatus and method for hybrid excited linear prediction speech encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6064956">US6064956</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 10, 1996</td><td class="patent-data-table-td patent-date-value">May 16, 2000</td><td class="patent-data-table-td ">Telefonaktiebolaget Lm Ericsson</td><td class="patent-data-table-td ">Method to determine the excitation pulse positions within a speech frame</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6295520">US6295520</a></td><td class="patent-data-table-td patent-date-value">Mar 15, 1999</td><td class="patent-data-table-td patent-date-value">Sep 25, 2001</td><td class="patent-data-table-td ">Tritech Microelectronics Ltd.</td><td class="patent-data-table-td ">Multi-pulse synthesis simplification in analysis-by-synthesis coders</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6385576">US6385576</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 23, 1998</td><td class="patent-data-table-td patent-date-value">May 7, 2002</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Speech encoding/decoding method using reduced subframe pulse positions having density related to pitch</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6393391">US6393391</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 15, 1998</td><td class="patent-data-table-td patent-date-value">May 21, 2002</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Speech coder for high quality at low bit rates</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6594626">US6594626</a></td><td class="patent-data-table-td patent-date-value">Jan 8, 2002</td><td class="patent-data-table-td patent-date-value">Jul 15, 2003</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Voice encoding and voice decoding using an adaptive codebook and an algebraic codebook</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6714907">US6714907</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 15, 2001</td><td class="patent-data-table-td patent-date-value">Mar 30, 2004</td><td class="patent-data-table-td ">Mindspeed Technologies, Inc.</td><td class="patent-data-table-td ">Codebook structure and search for speech coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6728669">US6728669</a></td><td class="patent-data-table-td patent-date-value">Aug 7, 2000</td><td class="patent-data-table-td patent-date-value">Apr 27, 2004</td><td class="patent-data-table-td ">Lucent Technologies Inc.</td><td class="patent-data-table-td ">Relative pulse position in celp vocoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6751585">US6751585</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 7, 2001</td><td class="patent-data-table-td patent-date-value">Jun 15, 2004</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Speech coder for high quality at low bit rates</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6795805">US6795805</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 1999</td><td class="patent-data-table-td patent-date-value">Sep 21, 2004</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">Periodicity enhancement in decoding wideband signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6807524">US6807524</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 1999</td><td class="patent-data-table-td patent-date-value">Oct 19, 2004</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">Perceptual weighting device and method for efficient coding of wideband signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6928406">US6928406</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 2, 2000</td><td class="patent-data-table-td patent-date-value">Aug 9, 2005</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Excitation vector generating apparatus and speech coding/decoding apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6978235">US6978235</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 30, 1999</td><td class="patent-data-table-td patent-date-value">Dec 20, 2005</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Speech coding apparatus and speech decoding apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7054807">US7054807</a></td><td class="patent-data-table-td patent-date-value">Nov 8, 2002</td><td class="patent-data-table-td patent-date-value">May 30, 2006</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Optimizing encoder for efficiently determining analysis-by-synthesis codebook-related parameters</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7146311">US7146311</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 14, 1999</td><td class="patent-data-table-td patent-date-value">Dec 5, 2006</td><td class="patent-data-table-td ">Telefonaktiebolaget Lm Ericsson (Publ)</td><td class="patent-data-table-td ">CELP encoding/decoding method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7151802">US7151802</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 1999</td><td class="patent-data-table-td patent-date-value">Dec 19, 2006</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">High frequency content recovering method and device for over-sampled synthesized wideband signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7191123">US7191123</a></td><td class="patent-data-table-td patent-date-value">Nov 17, 2000</td><td class="patent-data-table-td patent-date-value">Mar 13, 2007</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">Gain-smoothing in wideband speech and audio signal decoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7194408">US7194408</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 8, 2004</td><td class="patent-data-table-td patent-date-value">Mar 20, 2007</td><td class="patent-data-table-td ">Telefonaktiebolaget Lm Ericsson (Publ)</td><td class="patent-data-table-td ">CELP encoding/decoding method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7206740">US7206740</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 12, 2002</td><td class="patent-data-table-td patent-date-value">Apr 17, 2007</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Efficient excitation quantization in noise feedback coding with general noise shaping</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7236928">US7236928</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 19, 2001</td><td class="patent-data-table-td patent-date-value">Jun 26, 2007</td><td class="patent-data-table-td ">Ntt Docomo, Inc.</td><td class="patent-data-table-td ">Joint optimization of speech excitation and filter parameters</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7249014">US7249014</a></td><td class="patent-data-table-td patent-date-value">Mar 13, 2003</td><td class="patent-data-table-td patent-date-value">Jul 24, 2007</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Apparatus, methods and articles incorporating a fast algebraic codebook search technique</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7260521">US7260521</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 27, 1999</td><td class="patent-data-table-td patent-date-value">Aug 21, 2007</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">Method and device for adaptive bandwidth pitch search in coding wideband signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7272553">US7272553</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 8, 1999</td><td class="patent-data-table-td patent-date-value">Sep 18, 2007</td><td class="patent-data-table-td ">8X8, Inc.</td><td class="patent-data-table-td ">Varying pulse amplitude multi-pulse analysis speech processor and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7280959">US7280959</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 22, 2001</td><td class="patent-data-table-td patent-date-value">Oct 9, 2007</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">Indexing pulse positions and signs in algebraic codebooks for coding of wideband signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7363219">US7363219</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 30, 2004</td><td class="patent-data-table-td patent-date-value">Apr 22, 2008</td><td class="patent-data-table-td ">Texas Instruments Incorporated</td><td class="patent-data-table-td ">Hybrid speech coding and system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7519533">US7519533</a></td><td class="patent-data-table-td patent-date-value">Mar 8, 2007</td><td class="patent-data-table-td patent-date-value">Apr 14, 2009</td><td class="patent-data-table-td ">Panasonic Corporation</td><td class="patent-data-table-td ">Fixed codebook searching apparatus and fixed codebook searching method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7672837">US7672837</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 4, 2006</td><td class="patent-data-table-td patent-date-value">Mar 2, 2010</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">Method and device for adaptive bandwidth pitch search in coding wideband signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7693710">US7693710</a></td><td class="patent-data-table-td patent-date-value">May 30, 2003</td><td class="patent-data-table-td patent-date-value">Apr 6, 2010</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">Method and device for efficient frame erasure concealment in linear predictive based speech codecs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7698132">US7698132</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 17, 2002</td><td class="patent-data-table-td patent-date-value">Apr 13, 2010</td><td class="patent-data-table-td ">Qualcomm Incorporated</td><td class="patent-data-table-td ">Sub-sampled excitation waveform codebooks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7949521">US7949521</a></td><td class="patent-data-table-td patent-date-value">Feb 25, 2009</td><td class="patent-data-table-td patent-date-value">May 24, 2011</td><td class="patent-data-table-td ">Panasonic Corporation</td><td class="patent-data-table-td ">Fixed codebook searching apparatus and fixed codebook searching method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7957962">US7957962</a></td><td class="patent-data-table-td patent-date-value">Feb 25, 2009</td><td class="patent-data-table-td patent-date-value">Jun 7, 2011</td><td class="patent-data-table-td ">Panasonic Corporation</td><td class="patent-data-table-td ">Fixed codebook searching apparatus and fixed codebook searching method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8036885">US8036885</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 17, 2009</td><td class="patent-data-table-td patent-date-value">Oct 11, 2011</td><td class="patent-data-table-td ">Voiceage Corp.</td><td class="patent-data-table-td ">Method and device for adaptive bandwidth pitch search in coding wideband signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8160871">US8160871</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 31, 2010</td><td class="patent-data-table-td patent-date-value">Apr 17, 2012</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Speech coding method and apparatus which codes spectrum parameters and an excitation signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8224657">US8224657</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 2003</td><td class="patent-data-table-td patent-date-value">Jul 17, 2012</td><td class="patent-data-table-td ">Nokia Corporation</td><td class="patent-data-table-td ">Method and device for efficient in-band dim-and-burst signaling and half-rate max operation in variable bit-rate wideband speech coding for CDMA wireless systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8249866">US8249866</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 2010</td><td class="patent-data-table-td patent-date-value">Aug 21, 2012</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Speech decoding method and apparatus which generates an excitation signal and a synthesis filter</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8255207">US8255207</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 2006</td><td class="patent-data-table-td patent-date-value">Aug 28, 2012</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">Method and device for efficient frame erasure concealment in speech codecs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8260621">US8260621</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 2010</td><td class="patent-data-table-td patent-date-value">Sep 4, 2012</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Speech coding method and apparatus for coding an input speech signal based on whether the input speech signal is wideband or narrowband</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8280729">US8280729</a></td><td class="patent-data-table-td patent-date-value">Jan 22, 2010</td><td class="patent-data-table-td patent-date-value">Oct 2, 2012</td><td class="patent-data-table-td ">Research In Motion Limited</td><td class="patent-data-table-td ">System and method for encoding and decoding pulse indices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8315861">US8315861</a></td><td class="patent-data-table-td patent-date-value">Mar 12, 2012</td><td class="patent-data-table-td patent-date-value">Nov 20, 2012</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Wideband speech decoding apparatus for producing excitation signal, synthesis filter, lower-band speech signal, and higher-band speech signal, and for decoding coded narrowband speech</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8352254">US8352254</a></td><td class="patent-data-table-td patent-date-value">Dec 8, 2006</td><td class="patent-data-table-td patent-date-value">Jan 8, 2013</td><td class="patent-data-table-td ">Panasonic Corporation</td><td class="patent-data-table-td ">Fixed code book search device and fixed code book search method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8452590">US8452590</a></td><td class="patent-data-table-td patent-date-value">Apr 25, 2011</td><td class="patent-data-table-td patent-date-value">May 28, 2013</td><td class="patent-data-table-td ">Panasonic Corporation</td><td class="patent-data-table-td ">Fixed codebook searching apparatus and fixed codebook searching method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8515743">US8515743</a></td><td class="patent-data-table-td patent-date-value">Jun 4, 2009</td><td class="patent-data-table-td patent-date-value">Aug 20, 2013</td><td class="patent-data-table-td ">Huawei Technologies Co., Ltd</td><td class="patent-data-table-td ">Method and apparatus for searching fixed codebook</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8566106">US8566106</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 2008</td><td class="patent-data-table-td patent-date-value">Oct 22, 2013</td><td class="patent-data-table-td ">Voiceage Corporation</td><td class="patent-data-table-td ">Method and device for fast algebraic codebook search in speech and audio coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8600739">US8600739</a></td><td class="patent-data-table-td patent-date-value">Jun 9, 2009</td><td class="patent-data-table-td patent-date-value">Dec 3, 2013</td><td class="patent-data-table-td ">Huawei Technologies Co., Ltd.</td><td class="patent-data-table-td ">Coding method, encoder, and computer readable medium that uses one of multiple codebooks based on a type of input signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1083546A2?cl=en">EP1083546A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 20, 2000</td><td class="patent-data-table-td patent-date-value">Mar 14, 2001</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Speech coding method using linear prediction and algebraic code excitation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1184842A2?cl=en">EP1184842A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 2, 2001</td><td class="patent-data-table-td patent-date-value">Mar 6, 2002</td><td class="patent-data-table-td ">Lucent Technologies Inc.</td><td class="patent-data-table-td ">Relative pulse position in CELP vocoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1513137A1?cl=en">EP1513137A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 22, 2003</td><td class="patent-data-table-td patent-date-value">Mar 9, 2005</td><td class="patent-data-table-td ">MicronasNIT LCC, Novi Sad Institute of Information Technologies</td><td class="patent-data-table-td ">Speech processing system and method with multi-pulse excitation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2648184A1?cl=en">EP2648184A1</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 2013</td><td class="patent-data-table-td patent-date-value">Oct 9, 2013</td><td class="patent-data-table-td ">Motorola Mobility LLC</td><td class="patent-data-table-td ">Method and apparatus for generating a candidate code-vector to code an informational signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2001020595A1?cl=en">WO2001020595A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 14, 1999</td><td class="patent-data-table-td patent-date-value">Mar 22, 2001</td><td class="patent-data-table-td ">Fujitsu Ltd</td><td class="patent-data-table-td ">Voice encoder/decoder</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc704/defs704.htm&usg=AFQjCNFXKBc0Q4Cbl6DXC_PCjlN_Rft8Xg#C704S223000">704/223</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc704/defs704.htm&usg=AFQjCNFXKBc0Q4Cbl6DXC_PCjlN_Rft8Xg#C704SE19032">704/E19.032</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc704/defs704.htm&usg=AFQjCNFXKBc0Q4Cbl6DXC_PCjlN_Rft8Xg#C704SE19035">704/E19.035</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc704/defs704.htm&usg=AFQjCNFXKBc0Q4Cbl6DXC_PCjlN_Rft8Xg#C704S219000">704/219</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc704/defs704.htm&usg=AFQjCNFXKBc0Q4Cbl6DXC_PCjlN_Rft8Xg#C704S230000">704/230</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc704/defs704.htm&usg=AFQjCNFXKBc0Q4Cbl6DXC_PCjlN_Rft8Xg#C704S262000">704/262</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0019120000">G10L19/12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04W0088020000">H04W88/02</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L">G10L</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0019000000">G10L19/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0013000000">G10L13/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0019080000">G10L19/08</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0019040000">G10L19/04</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H03M0007300000">H03M7/30</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04B0007260000">H04B7/26</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H03M0007360000">H03M7/36</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0019100000">G10L19/10</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L25/06">G10L25/06</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L19/12">G10L19/12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L19/10">G10L19/10</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0RRGBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L19/00">G10L19/00</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G10L19/10</span>, <span class="nested-value">G10L19/12</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Nov 10, 2009</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 30, 2007</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-27 IS CONFIRMED. NEW CLAIMS 28-34 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 20, 2005</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 26, 2004</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20040913</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 8, 2001</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 2, 1995</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">UNIVERSITE DE SHERBROOKE, CANADA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ADOUL, JEAN-PIERRE;LAFLAMME, CLAUDE;REEL/FRAME:007859/0417</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19951003</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U3qAHT5w7HzhDsPa_iYscQJ7zzpvg\u0026id=0RRGBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0Sqi8I-Q788rflx7MQTx33M1IKog\u0026id=0RRGBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U3yQOjrkNYbXGT8r34brgMa3L3KdA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Algebraic_codebook_with_signal_selected.pdf?id=0RRGBAABERAJ\u0026output=pdf\u0026sig=ACfU3U2BBLoM5o3tGMYb8PvOrX_xP_NOlA"},"sample_url":"http://www.google.com/patents/reader?id=0RRGBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>