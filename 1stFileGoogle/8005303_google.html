<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US8005303 - Method and apparatus for encoding/decoding image data - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4ff636b3d23669b7103f3b3a3a18b4cd/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4ff636b3d23669b7103f3b3a3a18b4cd__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method and apparatus for encoding/decoding image data"><meta name="DC.contributor" content="Pierre Cote" scheme="inventor"><meta name="DC.contributor" content="Iq Biometrix, Inc." scheme="assignee"><meta name="DC.date" content="2009-12-11" scheme="dateSubmitted"><meta name="DC.description" content="The invention relates to a method and an apparatus for encoding images, more particularly to an encoding unit in conjunction with a library of pictorial entities and image qualifiers. The method and apparatus provide encoding an image by using a code factor table in conjunction with a set of element codes. The resulting image code allows the set pictorial elements of an image and their associated image qualifiers to be represented by a compact code uniquely representing a given configuration of pictorial elements. The use of the resulting image code facilitates the transmission and storage of images requiring only the code to be sent or stored. The invention further provides a computer readable medium comprising a program element that direct a computer to implement the encoding process."><meta name="DC.date" content="2011-8-23" scheme="issued"><meta name="DC.relation" content="US:5572656" scheme="references"><meta name="DC.relation" content="US:5588096" scheme="references"><meta name="DC.relation" content="US:5600767" scheme="references"><meta name="DC.relation" content="US:5808624" scheme="references"><meta name="DC.relation" content="US:6381346" scheme="references"><meta name="citation_patent_number" content="US:8005303"><meta name="citation_patent_application_number" content="US:12/636,302"><link rel="canonical" href="http://www.google.com/patents/US8005303"/><meta property="og:url" content="http://www.google.com/patents/US8005303"/><meta name="title" content="Patent US8005303 - Method and apparatus for encoding/decoding image data"/><meta name="description" content="The invention relates to a method and an apparatus for encoding images, more particularly to an encoding unit in conjunction with a library of pictorial entities and image qualifiers. The method and apparatus provide encoding an image by using a code factor table in conjunction with a set of element codes. The resulting image code allows the set pictorial elements of an image and their associated image qualifiers to be represented by a compact code uniquely representing a given configuration of pictorial elements. The use of the resulting image code facilitates the transmission and storage of images requiring only the code to be sent or stored. The invention further provides a computer readable medium comprising a program element that direct a computer to implement the encoding process."/><meta property="og:title" content="Patent US8005303 - Method and apparatus for encoding/decoding image data"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("J-HoU4WaMsOlsAS-hoDQCw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407291699.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CZE"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("J-HoU4WaMsOlsAS-hoDQCw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407291699.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CZE"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us8005303?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US8005303"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=0rH4BgABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS8005303&amp;usg=AFQjCNH2DWoyWkk3wU8R9ceQI8NegUoJBw" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US8005303.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US8005303.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20100142834"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US8005303"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US8005303" style="display:none"><span itemprop="description">The invention relates to a method and an apparatus for encoding images, more particularly to an encoding unit in conjunction with a library of pictorial entities and image qualifiers. The method and apparatus provide encoding an image by using a code factor table in conjunction with a set of element...</span><span itemprop="url">http://www.google.com/patents/US8005303?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US8005303 - Method and apparatus for encoding/decoding image data</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US8005303 - Method and apparatus for encoding/decoding image data" title="Patent US8005303 - Method and apparatus for encoding/decoding image data"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US8005303 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 12/636,302</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Aug 23, 2011</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Dec 11, 2009</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Apr 29, 1998</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7113642">US7113642</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7139413">US7139413</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7146061">US7146061</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7289647">US7289647</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7471835">US7471835</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20040091154">US20040091154</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20040091155">US20040091155</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20040091156">US20040091156</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20040207645">US20040207645</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20040207646">US20040207646</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20090074309">US20090074309</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20100142834">US20100142834</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120045138">US20120045138</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130278630">US20130278630</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">12636302, </span><span class="patent-bibdata-value">636302, </span><span class="patent-bibdata-value">US 8005303 B2, </span><span class="patent-bibdata-value">US 8005303B2, </span><span class="patent-bibdata-value">US-B2-8005303, </span><span class="patent-bibdata-value">US8005303 B2, </span><span class="patent-bibdata-value">US8005303B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Pierre+Cote%22">Pierre Cote</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Iq+Biometrix,+Inc.%22">Iq Biometrix, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US8005303.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8005303.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8005303.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (5),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (7),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/8005303&usg=AFQjCNHvvlb211tYdl-jTKqVv4eYNnEjwQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D8005303&usg=AFQjCNHVaBhMT31E4r_NfxVkCFBQWG0vag">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D8005303B2%26KC%3DB2%26FT%3DD&usg=AFQjCNGP02Qw0rJ7AcB2GBT4tTPG_ZoECg">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT106222096" lang="EN" load-source="patent-office">Method and apparatus for encoding/decoding image data</invention-title></span><br><span class="patent-number">US 8005303 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA88005435" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">The invention relates to a method and an apparatus for encoding images, more particularly to an encoding unit in conjunction with a library of pictorial entities and image qualifiers. The method and apparatus provide encoding an image by using a code factor table in conjunction with a set of element codes. The resulting image code allows the set pictorial elements of an image and their associated image qualifiers to be represented by a compact code uniquely representing a given configuration of pictorial elements. The use of the resulting image code facilitates the transmission and storage of images requiring only the code to be sent or stored. The invention further provides a computer readable medium comprising a program element that direct a computer to implement the encoding process.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(10)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8005303B2/US08005303-20110823-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8005303B2/US08005303-20110823-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(42)</span></span></div><div class="patent-text"><div mxw-id="PCLM38523113" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A method for creating a composite image, comprising:
<div class="claim-text">displaying facial feature images on a first area of a first display via a first device associated with the first display, wherein the facial feature images are associated with facial feature element codes;</div>
<div class="claim-text">selecting a facial feature image from the first area of the first display via a user interface associated with the first device, wherein the first device incorporates the selected facial feature image into a composite image on a second area of the first display, wherein the composite image is associated with a composite facial image code having at least a facial feature element code; and</div>
<div class="claim-text">reproducing the composite image on a second display based on the composite facial image code.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second display is associated with a second device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising modifying a visual effect of the incorporated facial feature image via the user interface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein modifying the visual effect comprises displacing the facial feature image in a vertical or horizontal direction.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the facial feature image is displaced in the vertical or horizontal direction using arrows displayed on the first display.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein modifying the visual effect comprises modifying a size of the facial feature image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein modifying the visual effect comprises modifying a shape of the facial feature image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein modifying the visual effect comprises modifying a color of the facial feature image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein modifying the visual effect comprises rotating the facial feature image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the composite image code includes or is based on one or more code factors.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising transmitting the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising saving the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the composite image code is transmitted through an electronic communication means.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the composite image code is transmitted to a device associated with the second display.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein reproducing the composite image on the second display comprises inputting a composite image code, via a user interface into a device associate with the second display.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. A method for creating a composite image, comprising:
<div class="claim-text">displaying selectable classes of feature images on a first area of a first display via a first device associated with the first display;</div>
<div class="claim-text">selecting a class of facial feature images via a user interface associated with the first device;</div>
<div class="claim-text">displaying facial feature images associated with the selected class of facial feature images on the first area of the first display via the first device, wherein the facial feature images are associated with facial feature element codes;</div>
<div class="claim-text">selecting, via the user interface, a facial feature image from the displayed facial feature images associated with the selected class of facial feature images, whereby the first device incorporates the facial feature image into a composite image on a second area of the first display, wherein the composite image is associated with a composite image code having at least one facial feature element code; and</div>
<div class="claim-text">reproducing the composite image on a second display based on the composite image code.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the second display is associated with a second device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising modifying a visual effect of the incorporated facial feature image via the user interface.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text">19. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the composite image code includes or is based on one or more code factors.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text">20. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising transmitting the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
      <div class="claim-text">21. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising saving the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
      <div class="claim-text">22. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein reproducing the composite image on the second display comprises inputting a composite image code into a second device associated with the second display.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00023" num="00023" class="claim">
      <div class="claim-text">23. A method for creating a composite image, comprising:
<div class="claim-text">displaying facial feature images on a first area of a first display via a first device associated with the first display, wherein the facial feature images are associated with facial feature element codes;</div>
<div class="claim-text">selecting a facial feature image from the first area of the first display via a user interface associated with the first device, wherein the first device incorporates the selected facial feature image into a composite image on a second area of the first display, wherein the composite image is associated with a composite image code having at least a facial feature element code; and</div>
<div class="claim-text">selecting and modifying a visual effect of the incorporated facial feature image via the user interface.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00024" num="00024" class="claim">
      <div class="claim-text">24. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, wherein the composite image code includes or is based on one or more code factors.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00025" num="00025" class="claim">
      <div class="claim-text">25. The method <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising reproducing the composite image on a second display based on the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00026" num="00026" class="claim">
      <div class="claim-text">26. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising transmitting the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00027" num="00027" class="claim">
      <div class="claim-text">27. The method of <claim-ref idref="CLM-00023">claim 23</claim-ref>, further comprising saving the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00028" num="00028" class="claim">
      <div class="claim-text">28. The method of <claim-ref idref="CLM-00025">claim 25</claim-ref>, wherein reproducing the composite image on the second display comprises inputting a composite image code into a second device associated with the second screen.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00029" num="00029" class="claim">
      <div class="claim-text">29. A system for creating a composite image, comprising:
<div class="claim-text">a first screen;</div>
<div class="claim-text">a second screen; and</div>
<div class="claim-text">a processor configured to:
<div class="claim-text">display facial feature images on a first area of the first screen, wherein the facial feature images are associated with facial feature element codes;</div>
<div class="claim-text">allow selection of a facial feature image from the first area of the first screen and incorporate the facial feature image into a composite image on a second area of the first screen, wherein the composite image is associated with a composite facial image code having at least a facial feature element code; and</div>
<div class="claim-text">allow the composite image to be reproduced on the second screen based on the composite facial image code.</div>
</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00030" num="00030" class="claim">
      <div class="claim-text">30. The system of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the first screen is associated with a first device and the second screen is associated with a second device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00031" num="00031" class="claim">
      <div class="claim-text">31. The system of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the processor is further configured to allow modification of a visual effect of the incorporated facial feature image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00032" num="00032" class="claim">
      <div class="claim-text">32. The system of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the composite image code includes or is based on one or more code factors.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00033" num="00033" class="claim">
      <div class="claim-text">33. The system of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the processor is further configured to transmit the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00034" num="00034" class="claim">
      <div class="claim-text">34. The system of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the processor is further configured to save the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00035" num="00035" class="claim">
      <div class="claim-text">35. The system of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the composite image is reproduced on the second screen based on a composite image code input on the second screen.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00036" num="00036" class="claim">
      <div class="claim-text">36. A computer program product stored in a computer readable media for creating a composite image, the computer program product comprising:
<div class="claim-text">first instructions for displaying facial feature images on a first area of a first screen;</div>
<div class="claim-text">second instructions for associating the facial feature images with facial feature element codes;</div>
<div class="claim-text">third instructions for incorporating a facial feature image into a composite image on a second area of the first screen based on a selection of the facial feature image from the first area of the first screen;</div>
<div class="claim-text">fourth instructions for associating the composite image with a composite image code having at least a facial feature element code; and</div>
<div class="claim-text">fifth instructions for modifying a visual effect of a selected facial feature image that has been incorporated into the composite image.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00037" num="00037" class="claim">
      <div class="claim-text">37. The computer program product of <claim-ref idref="CLM-00036">claim 36</claim-ref>, wherein the first screen is associated with a first device and the second screen is associated with a second device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00038" num="00038" class="claim">
      <div class="claim-text">38. The computer program product of <claim-ref idref="CLM-00036">claim 36</claim-ref>, wherein the composite image code includes or is based on one or more code factors.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00039" num="00039" class="claim">
      <div class="claim-text">39. The computer program product of <claim-ref idref="CLM-00036">claim 36</claim-ref>, further comprising sixth instructions for reproducing the composite image on a second screen based on the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00040" num="00040" class="claim">
      <div class="claim-text">40. The computer program product of <claim-ref idref="CLM-00036">claim 36</claim-ref>, further comprising sixth instructions for transmitting the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00041" num="00041" class="claim">
      <div class="claim-text">41. The computer program product of <claim-ref idref="CLM-00036">claim 36</claim-ref>, further comprising sixth instructions for saving the composite image code.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00042" num="00042" class="claim">
      <div class="claim-text">42. The computer program product of <claim-ref idref="CLM-00036">claim 36</claim-ref>, further comprising sixth instructions for reproducing the composite image on a second screen based on a composite image code input on the second screen. </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES44056243" lang="EN" load-source="patent-office" class="description">
    <heading>CROSS REFERENCE TO RELATED APPLICATIONS</heading> <p num="p-0002">The present application is a continuation of U.S. patent application Ser. No. 12/276,742, entitled “Method and Apparatus for Encoding/Decoding Image Data,” filed in the U.S. Patent and Trademark Office on Nov. 24,2008, now abandoned, which is a continuation of U.S. patent application Ser. No. 10/761,434, now U.S. Pat. No. 7,471,835, entitled “Method and Apparatus for Encoding/Decoding Image Data,” filed in the U.S. Patent and Trademark Office on Jan. 22, 2004, which is a continuation of U.S. patent application Ser. No. 09/322,932, now U.S. Pat. No. 6,690,830, entitled “Method and Apparatus for Encoding/Decoding Image Data,” filed in the U.S. Patent and Trademark Office on May 28, 1999, which is a continuation-in-part of U.S. patent application Ser. No. 09/087,599, now U.S. Pat. No. 6,731,302, entitled “Method and Apparatus for Creating Facial Images,” filed in the U.S. Patent and Trademark Office on Apr. 29, 1998, each having common inventors as the present document and each hereby incorporated by reference.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p num="p-0003">1. Field of the Invention</p>
    <p num="p-0004">This invention relates to a method and apparatus for encoding/decoding image data. It is particularly applicable to the encoding/decoding of images that can be separated into their constituent parts as may be used in composite picture systems used in law enforcement, artistic creations, recreation and education.</p>
    <p num="p-0005">2. Background</p>
    <p num="p-0006">It is known in the art to create images on the basis of components that are assembled to form a complete image. For example, a common technique for synthesizing single images of faces involves horizontally dividing the image of a face into bands for different features of the face such as hair, eyes, nose, mouth, and chin, respectively. Paper strips containing exemplary features are then be combined to form a composite drawing of a face. Yet another example involves a program element running on a computing platform which allows a user to select individual components and combining them on a pre-selected face. In a typical interaction, the user first selects the shape of the face then eyes, nose, mouth and other components and combines them to form a facial image. Many variations on this theme can be used as described in Kakiyama et al. U.S. Pat. No. 5,600,767, Yoshino et al. U.S. Pat. No. 5,644,690, Sato et al. U.S. Pat. No. 5,537,662 and Belfer et al. U.S. Pat. No. 5,649,096 whose contents are hereby incorporated by reference. For example, the Sato et al. Patent, entitled Electronic Montage composing apparatus, describes a system for creating a montage image of a face using a plurality of basic parts stored in a library.</p>
    <p num="p-0007">In constructing an image, pictorial entities are selected from a library of pictorial entities as assembled into images. These images may then be stored on a computer readable medium commonly referred to as a database or repository. Often, the storage of an image requires significant amounts of memory, often necessitating Large repositories. For example, a composite picture system used in a police department often requires maintaining records of thousands of individuals. The images are typically stored in files in some graphical format such as a “bitmap”, “gif” or “jpeg” are other format. Although such encoding schemes provide a compressed representation of the image, the memory required for storing the image remains significant. In addition, compression methods of the type described above generally degrade the quality of the image. The size and quality of images is also particularly significant when the images are transmitted from one site to another via a digital link. For example, a given police station may transmit a composite picture to another police station in order to share information about a given suspect.</p>
    <p num="p-0008">Thus, there exists a need in the industry to refine the process of encoding images such as to reduce the memory requirements for storage and the bandwidth required for the transmission of the image.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p num="p-0009">The invention provides a novel method and an apparatus for encoding images.</p>
    <p num="p-0010">For the purpose of the specification, the expression “basic elements” is used to describe a part of a specific image. In the preferred embodiment, a basic element is comprised of a pictorial entity conditioned by a set of image qualifiers. Examples of pictorial entities in a facial image are noses, eyes, mouths and eyebrows. In the preferred embodiment, pictorial entities are grouped into classes. For example, in composite picture system, all nose pictorial entities are grouped into the “NOSE” class and all the eye pictorial entities are grouped in the “EYE” class. Each class of pictorial entities is associated to a set of image qualifiers that are used to condition the pictorial entities in the associated class. The image qualifiers may include position qualifiers, zoom qualifiers, color qualifier and the likes.</p>
    <p num="p-0011">For the purpose of this specification, the basic elements used in the special case of a facial image are referred to as “basic morphological elements”.</p>
    <p num="p-0012">For the purpose of this specification, the word “symbol” is used to designate a representation of an object, image, qualifier or the likes. In a specific example, a symbol may be an index mapped to a memory location storing data elements such as a pictorial entity or image qualifier.</p>
    <p num="p-0013">According to a broad aspect, the invention provides, a computer readable storage medium comprising a program element suitable for use on a computer having a memory. The program element is operative to create a first input to receive a set of element codes. The element codes characterized a portion of an image and included at least one symbol. A given symbol is a representation of a certain characteristic of the portion of the element code. A given symbol can acquire a set of possible values indicative of variations of the certain characteristic with which it is associated. The program element is also operative to create a second input to receive code factors associated to respective symbols of the set of element codes. A given code factor is assigned a value that exceeds the highest value that the symbol with which it is associated can acquire. The program element is operative to process the set of element codes to derive an image code. The image code is a compressed digital representation of the image, and is derived at least in part on the basis of the plurality of code factors. The image code can then be released as the output.</p>
    <p num="p-0014">In a preferred embodiment, the image code is a number in a given base. Preferably, a large base is used in order to obtain a reduced number of characters in the image code.</p>
    <p num="p-0015">In a preferred embodiment of the invention, the encoding method and apparatus is integrated into a picture system. The picture system creates images on the basis of images of basic individual parts, herein referred to as basic elements. In the preferred embodiment, the picture system includes a library of pictorial entities and qualifiers, an image builder unit, an encoding unit, a decoding unit and a factor table.</p>
    <p num="p-0016">Each basic element in an image is assigned a unique identifier, herein referred to as element code. The element code contains information data elements, herein referred to as symbols. In a specific embodiment, the element code for each basic element includes a symbol that characterizes the pictorial element. In a preferred embodiment, the element code includes a plurality if symbols. In a specific example two (2) symbols are used namely an pictorial entity symbol and a position qualifier symbol. The element code may contain additional symbols without detracting from the spirit of the invention. For example symbols representative of other image qualifiers may be used such as color, zoom and other image effects may be used. An image is constructed by a set of basic elements. The basic elements present in a given facial image are said be “active” in the given image. The set of active elements is stored in a data structure suitable for that purpose. In a specific example this data structure is an image data table. The image data table stores for each class a record, each record containing a set of fields, each field describing the active pictorial entity and qualifiers.</p>
    <p num="p-0017">The number variations in each of the symbols for each of the classes is stored in a table, herein referred to as a code factor table. The code factor table provides information about the number of possible variations in an image. For each class, the code factor table stores a record, each record containing a set of fields, each field describing a maximum factor. The maximum factor in the code factor table is the largest identifier used for the given factor. Each symbol in the image data table is mapped to a factor in the code factor table.</p>
    <p num="p-0018">According to another broad aspect, the invention provides an apparatus for encoding an image, the image comprising a set of basic elements, each basic element of the set of basic elements being associated to an element code. An encoding unit receiving as input the code factors and the element codes. The encoding unit processes the set of element codes to derive an image code, the image code being a compressed digital representation of the image derived at least in part on the basis of said plurality of code factors. The encoding unit then outputs the image code.</p>
    <p num="p-0019">According to another broad aspect, the invention provides a method for encoding an image, the image comprising a set of basic elements, each basic element of the set of basic elements being associated to an element code. A processing step receives as input the code factors and the element codes to derive an image code. The image code is a compressed digital representation of the image derived at least in part on the basis of said plurality of code factors. The image code is the released.</p>
    <p num="p-0020">In a preferred embodiment, the image code can be used to reproduce the image described by the image code. Image data may be obtained by combining the code factors and the image code with a decoding device. The image data is obtained by applying the inverse operations in the reverse order than those applied in the encoding process to the image code.</p>
    <p num="p-0021">The image code allows each image to be described with a very small number of characters permitting the rapid transmission of the image over a data transmission medium. The receiving device has a decoding unit that is capable of extracting data information from the image code.</p>
    <p num="p-0022">According to another broad aspect, the invention provides a method, apparatus and computer readable medium for decoding an image, the image comprising a set of basic elements, each basic element of the set of basic elements being associated to an element code. A processing step receives as input the code factors and the image code to derive the element codes. The element codes are then released.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0023">These and other features of the present invention will become apparent from the following detailed description considered in connection with the accompanying drawings. It is to be understood, however, that the drawings are designed for purposes of illustration only and not as a definition of the limits of the invention for which reference should be made to the appending claims.</p>
      <p num="p-0024"> <figref idrefs="DRAWINGS">FIG. 1</figref> shows an apparatus including an embodiment of the invention;</p>
      <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 2</figref> shows a high-level block diagram of functional units of the image system including an image encoder in accordance with the spirit of the invention;</p>
      <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 3</figref> shows a high-level block diagram of functional units of the image system including an image decoder in accordance with the spirit of the invention;</p>
      <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 4</figref> shows a detailed block diagram of the encoding process in accordance with the spirit of the invention;</p>
      <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 5</figref> shows a detailed block diagram of the decoding process in accordance with the spirit of the invention;</p>
      <p num="p-0029"> <figref idrefs="DRAWINGS">FIG. 6</figref> <i>a </i>and <b>6</b> <i>b </i>show flow diagrams for the creation of an image and the facial code in accordance with an embodiment of the invention;</p>
      <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 7</figref> shows an alternative apparatus including an embodiment of the invention;</p>
      <p num="p-0031"> <figref idrefs="DRAWINGS">FIG. 8</figref> shows apparatuses including an embodiment of the invention connected by a data transmission medium.</p>
    </description-of-drawings> <heading>DETAILED DESCRIPTION</heading> <p num="p-0032">In the preferred embodiment, the encoding method and apparatus in accordance with the invention is integrated into a picture system for creating images on the basis of images of individual parts, herein referred to as basic elements. For the sake of simplicity, the specification will describe an embodiment of the invention integrated into a composite picture system. It is to be understood that the encoding method and apparatus may be used in systems for creating images on the basis of individual constituent parts other than a composite picture system without detracting from the spirit of the invention.</p>
    <p num="p-0033">In a preferred embodiment, as shown in <figref idrefs="DRAWINGS">FIG. 1</figref>, the composite picture system includes a general-purpose digital computer including a processor <b>100</b> linked to a machine-readable storage element <b>108</b> that may be in the form of a mass storage device such as a hard-drive, a CD-ROM or any other suitable storage medium. The system further includes a device for visualizing the facial image such as a computer monitor <b>110</b> or a printing device. The preferred embodiment also provides data input on which a user interface <b>112</b> is supported in order to allow the user to select through a touch screen, keyboard, pointing device or other input means, the individual basic morphological elements and to view the combined result on the display screen <b>110</b>. The latter <b>110</b> is likely to be part of the data input. Optionally, the system further provides a data transmission medium <b>114</b> such as a telephone line, LAN, digital cable, optical cable, wireless transmission device or any other suitable means for transmitting an image from the general purpose digital computer to a receiving device. The computer readable medium <b>108</b> storing the composite picture system includes of a set of modules namely a library of pictorial entities and image qualifiers <b>104</b> and program instructions <b>102</b> interacting with the library of pictorial entities and image qualifiers to create a facial image. The computer readable medium <b>108</b> may also include symbols where each symbol is associated to a respective one of the pictorial entities and image qualifiers in the library of pictorial entities and image qualifiers <b>104</b>. The computer readable medium further comprising a set of code factors, each code factor being associated to a set of symbols, a given code factor being larger that the largest symbol in the set with which it is associated. The computer readable medium further comprises an encoding program element <b>116</b> to encode a facial image.</p>
    <p num="p-0034">In the preferred embodiment the composite picture system comprises an electronic library of pictorial entities and image qualifiers <b>104</b>. Each pictorial entity in the library is an image of a facial part or an accessory such as glasses, earrings or other. The pictorial entities in the library <b>104</b> are organized into morphological classes, each class describing a part of the face. In a preferred embodiment, the following basic morphological classes are used: hairstyle, forehead, eyebrows, eyes, nose, mouth, chin, moustache, beard, wrinkles and glasses. The pictorial entities are stored on a computer readable medium. The images may be compressed in a format suitable for graphical storage such as a bitmap (BMP), GIF of JPEG file format. Other file formats may be used here without detracting from the spirit of the invention.</p>
    <p num="p-0035">In the preferred embodiment, each pictorial entity is identified with a pictorial entity symbol. Typically, the pictorial entity symbol is a sequence of alphanumeric characters. The pictorial entity symbols are stored on a computer readable medium in the database of symbols. Each image qualifier in the library is a characteristic of a corresponding class. The image qualifiers in the library <b>104</b> may be organized into qualifier types, each qualifier type describing a certain characteristic of the pictorial entity. In a preferred embodiment, the following qualifier types are used: position and color. Other image qualifiers such as zoom and the likes may be used without detracting from the spirit of the invention. The image qualifiers are stored on a computer readable medium. In the preferred embodiment, each image qualifier is identified with an image qualifier symbol. Typically, the image qualifier symbol is a sequence of alphanumeric characters. The image qualifier symbols are stored on a computer readable medium in the database of symbols.</p>
    <p num="p-0036">In a preferred embodiment, a basic morphological element includes a pictorial entity and a set of image qualifiers. The image qualifiers condition the pictorial entity to alter the visual effect of the latter. For example the image qualifier may modify the position, color zoom or any other visual effect of the pictorial entity. The purpose of the specification, the expression “basic morphological element” is used to refer to the pictorial entity conditioned by the image qualifiers. Each basic morphological element is associated to an element code. The element code contains a set of symbols. In a specific example, the element code for each basic morphological element includes two (2) symbols namely a pictorial entity symbol and a position qualifier symbol. The pictorial entity symbol identifies the pictorial entity within a given class in the library of pictorial entities and image qualifiers. Preferably, the pictorial entities of a given class are each assigned a unique symbol. The symbols need not be consecutive provided they can be ordered and the largest symbol assigned to a pictorial entity of a given class can be determined. The position qualifier symbol provides information on the position of the pictorial entity in the facial image. Preferably, the number of possible positions for a pictorial entity of a given class is predetermined. In a specific example, there may be 5 possible positions for the eyes in a facial image. Each position is assigned a position qualifier symbol such as a number from 1 to 5 and each position qualifier symbol corresponds to a position the pictorial entity with which it is associated can acquire. The element code may contain additional symbols without detracting from the spirit of the invention. For example, the element code may contain a “zoom” qualifier indicating the zoom level of the pictorial entity.</p>
    <p num="p-0037">A facial image is constructed by a set of basic morphological elements. The basic morphological element present in a given facial image is said be “active” in the given image. The set of active basic morphological elements is stored in a data structure suitable for that purpose. In a specific example this data structure is an image data table. The image data table stores for each class a record. Each records describes an element code, each record containing a set of fields, each field describing the pictorial entity symbol, position qualifier symbol and any other symbol. The entries in the image data table are referred to as active element symbols. The table below shows a specific example of an image data table.</p>
    <p num="p-0038">
      <tables id="TABLE-US-00001" num="00001"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="21pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="49pt" align="center"> </colspec> <colspec colname="3" colwidth="98pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td"> </td>
                <td class="description-td">Pictorial entity</td>
                <td class="description-td">Position qualifier</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Class</td>
                <td class="description-td">symbol</td>
                <td class="description-td">symbol</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="21pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="49pt" align="char" char="."> </colspec> <colspec colname="3" colwidth="98pt" align="char" char="."> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">EYES</td>
                <td class="description-td">34</td>
                <td class="description-td">2</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">LIPS</td>
                <td class="description-td">2</td>
                <td class="description-td">1</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">GLASSES</td>
                <td class="description-td">111</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0039">As shown above, a basic morphological element of class “EYES” with a pictorial entity symbol “34” which is positioned at position “2” is active in the facial image.</p>
    <p num="p-0040">The number variations in each of the symbols for each of the classes is stored in a table, herein referred to as a code factor table. The code factor table provides information about the number of possible variations in a facial image. For each class, the code factor table stores a record, each record containing a set of fields, each field describing a maximum factor. The maximum factor in the code factor table is the largest symbol assigned to an image qualifier or pictorial entity for a given class. Alternatively, the maximum factor is larger that the largest symbol assigned to an image qualifier or pictorial entity for a given class. This will best be understood in conjunction with a specific example. The table below shows an example of a code factor table.</p>
    <p num="p-0041">
      <tables id="TABLE-US-00002" num="00002"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="63pt" align="center"> </colspec> <colspec colname="3" colwidth="91pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td"> </td>
                <td class="description-td">Maximum pictorial</td>
                <td class="description-td">Maximum position</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Class</td>
                <td class="description-td">entity factor</td>
                <td class="description-td">qualifier factor</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="63pt" align="char" char="."> </colspec> <colspec colname="3" colwidth="91pt" align="char" char="."> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">EYES</td>
                <td class="description-td">900</td>
                <td class="description-td">5</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">LIPS</td>
                <td class="description-td">600</td>
                <td class="description-td">26</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">GLASSES</td>
                <td class="description-td">200</td>
                <td class="description-td">23</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0042">In the above table, there are three classes namely “EYES”, “LIPS” and “GLASSES” having “900”, “600” and “200” pictorial entities respectively as their maximum factor. In this specific example, the pictorial entities are assigned numerical symbols no larger that the maximum factor for each respective class. In the case where pictorial entities are not assigned consecutive numerical symbols, the second column would contain the largest pictorial entity symbol assigned to the pictorial entities of the respective class. The third column includes the maximum position qualifier factor. Class “LIPS” for example has “26” as is maximum position qualifier factor. In this specific example, positions for the individual pictorial entities are pre-determined. Each pre-determined position is given a numerical position symbol that is between 1 and the maximum position qualifier factor in the code factor table.</p>
    <p num="p-0043">As shown in <figref idrefs="DRAWINGS">FIG. 2</figref>, a facial code <b>206</b> for a given facial image may be created by combining the code factors <b>200</b> and the image data <b>202</b> with an encoding device <b>204</b>. In a preferred embodiment, the encoding device <b>204</b> derives the facial code in accordance with the process described in <figref idrefs="DRAWINGS">FIG. 4</figref>.</p>
    <p num="p-0044">The facial code is first initialized at a based value <b>400</b>. Preferably, this base value is zero (0). Following this the encoding method begins with the first class of the pictorial entities <b>402</b> and the first symbol of the element code of the class <b>404</b>. The facial code is first multiplied <b>406</b> by the corresponding factor value in the code factor table. An example in conjunction with the factor table below will better illustrate this step <b>406</b>.</p>
    <p num="p-0045">
      <tables id="TABLE-US-00003" num="00003"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="63pt" align="center"> </colspec> <colspec colname="3" colwidth="91pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td"> </td>
                <td class="description-td">Maximum pictorial</td>
                <td class="description-td">Maximum position</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Class</td>
                <td class="description-td">entity factor</td>
                <td class="description-td">qualifier factor</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="63pt" align="char" char="."> </colspec> <colspec colname="3" colwidth="91pt" align="char" char="."> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">EYES</td>
                <td class="description-td">900</td>
                <td class="description-td">5</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">LIPS</td>
                <td class="description-td">600</td>
                <td class="description-td">26</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">GLASSES</td>
                <td class="description-td">200</td>
                <td class="description-td">23</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0046">If class “EYES” for the pictorial entity is being considered, then the facial code is multiplied by the pictorial entity factor “900”. Following this, the pictorial entity symbol from the image data table is added <b>408</b> to the facial code. An example in conjunction with the image data table below will better illustrate this step <b>408</b>.</p>
    <p num="p-0047">
      <tables id="TABLE-US-00004" num="00004"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="21pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="49pt" align="center"> </colspec> <colspec colname="3" colwidth="98pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td"> </td>
                <td class="description-td">Pictorial entity</td>
                <td class="description-td">Position qualifier</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Class</td>
                <td class="description-td">symbol</td>
                <td class="description-td">symbol</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="21pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="49pt" align="char" char="."> </colspec> <colspec colname="3" colwidth="98pt" align="char" char="."> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">EYES</td>
                <td class="description-td">34</td>
                <td class="description-td">2</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">LIPS</td>
                <td class="description-td">2</td>
                <td class="description-td">1</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">GLASSES</td>
                <td class="description-td">111</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0048">If class “EYES” for pictorial entity is being considered, then the pictorial entity symbol “34” is added to the facial code. The system then proceeds to step <b>410</b> that checks if there are any symbols remaining for the current class. In the affirmative, the system proceeds to step <b>412</b> that determines which symbol to consider next. In the example above, the following symbol to consider is the position qualifier symbol. The system then restarts at step <b>406</b>. In the event that all symbols for the current class have been processed, step <b>410</b> is answered in the negative and the system proceeds to step <b>414</b>. Step <b>414</b> checks if there are any classes remaining. In the affirmative the system proceeds to step <b>416</b> that determines which class to consider next. In the example above, the next class to consider is the “LIPS” class. The system then restarts at step <b>404</b> with the first symbol of the element code of the new class. In the event that all classes have been processed, step <b>414</b> is answered in the negative and the system proceeds to step <b>418</b> with the complete facial code.</p>
    <p num="p-0049">As a variant, the facial code may be further comprise version number information for the purpose of differentiating between different version numbers of the composite picture system. This in turn permits to insure that a composite picture system using the facial code produced by the process described above is not induced in error if its version is not the same than that of the composite picture system that created the image. In a specific example, the version number information is integrated to the facial code by multiplying the code by a specific number.</p>
    <p num="p-0050">In the preferred embodiment, the facial code is a number in a given base. Preferably, a large base is used in order to obtain a reduced number of characters in the facial code. In a specific example, the facial code is a number in base “62” with characters {0-9, a-z, A-Z}. Other bases may be used without detracting from the spirit of the invention. It is to be noted that the computations in steps <b>406</b> and <b>408</b> of the encoding process may result in very large numbers in the order of 10E+66 or bigger for large systems. It may therefore be preferable to provide some specialized functions for the computation of the multiplication and addition operations for these numbers in order to avoid the possibility of overflow. The implementation of such computations will be readily available to the person skilled in the art to which this invention pertains.</p>
    <p num="p-0051">As a variant, characters in the facial code that may be visually confusing are replaced by non-alphanumeric characters. For instance the letter “O” and the number “0” are similar in appearance as are the letter “I”, the letter “l” and the digit “1”. In a specific example, the characters in the facial code that may be visually confusing are replaced by non-alphanumeric characters such as “+”, “=”, “@” and so once the code is computed.</p>
    <p num="p-0052">In a preferred embodiment, the facial code can be used to reproduce the facial image described by the facial code. As shown in <figref idrefs="DRAWINGS">FIG. 3</figref>, facial image data <b>304</b> may be obtained by combining the code factors <b>200</b> and the facial code <b>302</b> with a decoding device <b>300</b>. The facial image data <b>304</b> is obtained by applying the inverse operations in the reverse order than those applied in the encoding process to the facial code. In a preferred embodiment, the decoding device <b>300</b> derives the facial image data <b>804</b> in accordance with the process described in <figref idrefs="DRAWINGS">FIG. 5</figref>.</p>
    <p num="p-0053">The facial code is first obtained <b>500</b>. Following this, the decoding process begins with the last class of the pictorial entities <b>502</b> and the last symbol of the element code of that class <b>504</b>. The facial code is first divided <b>506</b> by the factor value in the code factor table associated to the symbol being considered. An example in conjunction with the factor table below will better illustrate this step <b>506</b>.</p>
    <p num="p-0054">
      <tables id="TABLE-US-00005" num="00005"> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="63pt" align="center"> </colspec> <colspec colname="3" colwidth="91pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td"> </td>
                <td class="description-td">Maximum pictorial</td>
                <td class="description-td">Maximum position</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Class</td>
                <td class="description-td">entity factor</td>
                <td class="description-td">qualifier factor</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="49pt" align="left"> </colspec> <colspec colname="2" colwidth="63pt" align="char" char="."> </colspec> <colspec colname="3" colwidth="91pt" align="char" char="."> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">EYES</td>
                <td class="description-td">900</td>
                <td class="description-td">5</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">LIPS</td>
                <td class="description-td">600</td>
                <td class="description-td">26</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">GLASSES</td>
                <td class="description-td">200</td>
                <td class="description-td">23</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="3" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p num="p-0055">If class “GLASSES” for the position qualifier is being considered, then the facial code is divided by the factor “23”. Following this, the remainder of the division performed in step <b>506</b> is stored as the corresponding position qualifier symbol in the image data table <b>508</b>. The system then proceeds to step <b>510</b> that checks if there are any symbols remaining for the current class. In the affirmative, the system proceeds to step <b>512</b> that determines which symbol to consider next. In the example above, the following symbol to consider is the pictorial entity symbol. The system then restarts at step <b>506</b>. In the event that all symbols for the current class have been processed, step <b>510</b> is answered in the negative and the system proceeds to step <b>514</b>. Step <b>514</b> checks if there are any classes remaining. In the affirmative the system proceeds to step <b>516</b> that determines which class to consider next. In the example above, the next class to consider is the “LIPS” class. The system then restarts at step <b>504</b> with the last symbol of the element code of the new class. In the event that all classes have been processed, step <b>514</b> is answered in the negative and the system proceeds to step <b>518</b> with the image data table including the complete description of the image described by the facial code. The image data table can then be used by the composite picture system to access the library of pictorial entities and image qualifiers <b>104</b> and produce a facial image.</p>
    <p num="p-0056">As shown in <figref idrefs="DRAWINGS">FIG. 3</figref>, the image data <b>304</b> is stored in an image data table that can be accessed by an image builder unit <b>306</b>. The image builder unit <b>306</b> accesses the library of pictorial entities and image qualifiers <b>104</b> of the composite picture system to extract the pictorial entities specified by the image data. The image builder also extracts the image qualifiers specified by the image data and is operative to condition the pictorial entities on the basis of the these extracted image qualifiers. Following this the builder unit <b>300</b> outputs an image which may be displayed to the user of the composite picture system. Extracting data elements from a database on the basis of symbols is well known in the art to which this invention pertains.</p>
    <p num="p-0057">In the event that the facial code comprises version number information, the reverse operation used to imbed the version number in the facial code is applied to the facial code during the decoding process. In a specific example where the version number information is integrated in the facial code by multiplying the code by a specific number, the decoding process involves dividing the facial code by that number.</p>
    <p num="p-0058">In the event that characters in the facial code that may be visually confusing were replaced by non-alphanumeric characters, the reverse operation is performed on the facial code.</p>
    <p num="p-0059">An example of a typical interaction will better illustrate the functionality of the encoding module implemented by the program instructions <b>102</b> of composite picture system and using the data components <b>104</b> <b>106</b>.</p>
    <p num="p-0060">In a typical interaction, as shown in <figref idrefs="DRAWINGS">FIG. 6A</figref>, once the composite picture system is activated <b>600</b>, the user selects a set of pictorial entities <b>602</b> through a user interface. The interface to the composite picture system may be a keyboard, pointing device, touch screen or any other suitable input means. The received input may be an address of the memory location where a given pictorial entity is located or some other way of identifying it. The selection is entered in the image data table in association with corresponding qualifier symbols. Preferably, the pictorial entities in a given class as assigned default qualifier symbols. Once the system has received the request, the entries in the image data table are used to locate in the library of pictorial entities and image qualifiers, the entries corresponding with the received input. When pictorial entity or image qualifier is selected it is considered to be active. Following this, the selected pictorial entities and image qualifiers are combined to form a facial image. The combination is performed by positioning each active pictorial entity in a same frame at the location specified by the position qualifier in the image data table. The system than displays the facial image to allow the user to view it <b>604</b>. Alternatively, after each selection of a pictorial entity, the systems displays it to allow the user to view the image as it stands with the current selection of pictorial entities. At condition <b>606</b>, if the user is satisfied with the appearance of the facial image, the composite picture is complete <b>610</b>. The completeness of the image may be indicated by a user inputting a command indicative that the image is complete. The image data table is then processed by the encoding process to compute the racial code <b>612</b>. The user of the system may then make use of the facial image and facial code as he pleases. For example, the user may print the resulting facial image, he may store the image by storing the facial code computed at step <b>612</b> or he may transmit the image to an external site by transmitting the facial code. In the event that the user is not satisfied with the appearance of the facial image, condition <b>606</b> is answered in the negative and the user may modify the facial image <b>608</b>. The modification of the facial image may comprise different operations. For example, the user may replace a pictorial entity by another of the same class; he may remove a pictorial entity all together; the element may be displaced in the vertical or horizontal direction. In a specific example, the user interface may include a means, such as arrows in the user interface, for displacing the pictorial entities in the vertical and horizontal directions. The arrows may be linked to functional modules that modify the position of the selected image in the screen. When the pictorial entity is displaced, the corresponding position qualifier symbol in the image table is also modified such as to reflect to current positioning of the pictorial entity. The user may select via a pointing device or other input means the element he wishes to displace in the facial image. The user then uses the displacement arrows to position the pictorial entity in the desired position in the facial image. Many variations in the user interface are possible and implementations different from the one presented above do not detract from the spirit of the invention. For every modification performed in step <b>608</b>, the image data table is updated accordingly. Once the facial image has been modified by selecting a revised set of pictorial entities and image qualifiers, the latter are combined to form a facial image. The system then displays the facial image as described in the image data table to allow the user to view it at step <b>604</b>. Alternatively, after each selection of a pictorial entity or and image qualifier, the systems displays it to allow the user to view the updated image as it stands with the current selection. The process continues until the user is satisfied with the image and condition <b>606</b> is answered in the affirmative the system proceeds to step <b>610</b>.</p>
    <p num="p-0061">As a variant, as shown in <figref idrefs="DRAWINGS">FIG. 6</figref> <i>b</i>, the facial code may be computed incrementally as the user selects pictorial entities and image qualifiers and modifies the facial image. Following step <b>602</b>, the image data table is processed <b>652</b> by the encoding unit to compute the facial code corresponding to the data in the image data table. The facial image may then be modified in accordance with steps <b>604</b> <b>606</b> and <b>608</b> described previously. Following step <b>608</b>, the image data table is reprocessed by the encoding unit <b>650</b> to compute the facial code corresponding to the updated data in the image data table. In this variant, the facial code for the image being created is computed as the user creates the image. Once the use stops entering new modifications, the code is readily computed without the need for the user to input a command indicative that the image is complete.</p>
    <p num="p-0062">In another typical interaction, the composite picture system may receive as input the facial code describing a facial image. Using this facial code, the composite picture system reconstructs the facial image. Therefore, the user interface may also include a means for entering the facial codes. The facial code is first decoded by the process described in connection with <figref idrefs="DRAWINGS">FIG. 5</figref>. The decoding process produces an image data table containing information for generating the facial image. The system accesses the library of pictorial entities and image qualifiers and extracts the pictorial entities and image qualifiers corresponding to the data contained in the image data table. The image is then displayed to the user which may make use of it as he please by modifying it, storing it, printing it or transmitting it.</p>
    <p num="p-0063"> <figref idrefs="DRAWINGS">FIG. 7</figref> shows an alternative embodiment of an apparatus including an embodiment of the invention. Such an apparatus comprises a user interface <b>706</b> such as a touch screen, mouse, keyboard are any other suitable input means for communicating with the user of the image system. The user interface communicates with an image builder unit <b>702</b> operative to generate graphical data on the basis of a given set of input data elements. The image builder unit may be implements on a general purpose computing platform running an application software of may be a dedicated CPU unit programmed specifically for the purpose of generating images. The Image builder unit <b>702</b> communicates with an output unit <b>704</b> such as a display unit or a printer unit to send the generated graphical data for output to the user. The image builder unit also communicates with a library of pictorial entities and image qualifiers <b>700</b>. The library of pictorial entities and image qualifiers <b>700</b> may be implemented on a computer readable medium such as a hard disk, CD-ROM, non-volatile RAM or any other suitable device. The image builder unit <b>708</b> also communicates with a computer readable medium including image data <b>708</b>. The image data specifies the pictorial entities that are active in the given image as well as any other relevant image qualifier such as position and zooming. The image data <b>708</b> may also be modified by the image builder unit <b>702</b> to update its entries on the basis of inputs received by the image builder unit <b>702</b> from the user through the user interface <b>706</b>. The image data <b>708</b> can be accessed by and encoder <b>710</b> operative to encode the image data according to the process described in this specification. The encoder may be implemented on a general purpose computing platform running an application software in accordance with the process described or may be a dedicated CPU unit programmed specifically for the purpose of encoding image data. The encoder <b>710</b> outputs the image code. The encoder may further communicate with a communication unit <b>716</b> such as a modem, network card or any other suitable communication devices suitable for transmitting data information over a communication channel <b>718</b>. The image data <b>708</b> can be accessed by a decoder <b>714</b> operative to decode an image code according to the process described in this specification. The decoder <b>714</b> may be implemented on a general purpose computing platform running an application software in accordance with the process described or may be a dedicated CPU unit programmed specifically for the purpose of decoding image codes. The decoder <b>714</b> outputs the image data that is inputted to the computer readable medium containing image data. The decoder may further communicate with the communication unit <b>716</b> in order to receive image codes. The encoder <b>710</b> and decoder <b>714</b> also communicate with a computer readable medium including element code factors <b>712</b>.</p>
    <p num="p-0064">The facial code produced by the process described above allows each facial image to be described with a very small number of characters compared to a graphical representation permitting the rapid transmission of the composite picture over data transmission medium. For example, as shown in <figref idrefs="DRAWINGS">FIG. 8</figref>, a police station at site A <b>804</b> using an embodiment of the invention can transmit the entire composite picture of a suspect to police station at site B <b>802</b> by simply sending the facial code for that facial image either verbally or through an electronic communication means <b>800</b>. At the reception, police station at site B <b>800</b> enters the code into the composite picture system that displays the composite picture. The data transmission medium <b>800</b> between site A <b>802</b> and site B <b>804</b> may be a telephone line with a set of modems, and Ethernet connection, the Internet or any other communication medium suitable for the transfer of data. In the above example, site A <b>804</b> and site B <b>802</b> have on their local site a composite picture system of the type described in <figref idrefs="DRAWINGS">FIG. 1</figref> or <figref idrefs="DRAWINGS">FIG. 7</figref> of the drawings. A copy of the library of pictorial entities and image qualifiers is stored at each site and only the code needs to be transferred. Advantageously, the invention further allows the storage of a facial image by storing the facial code only on a computer readable medium. This may result in substantial savings in terms of memory requirements for storing the images since only a single instance of each pictorial entity and image qualifier needs be stored, the instance being in the library of pictorial entities and image qualifiers.</p>
    <p num="p-0065">Although the present invention has been described in considerable detail with reference to certain preferred versions thereof, other versions are possible. For example, the method and apparatus described may be used in a system to encode a given image provided the image is build on the basis of constituent parts. In these types of application the library of pictorial entities and image qualifiers would include the appropriate set of pictorial entities and image qualifiers. Therefore, the spirit and scope of the appended claims should not be limited to the description of the preferred versions contained herein.</p>
    <p num="p-0066">The reader's attention is directed to all papers and documents which are filed concurrently with or previous to this specification in connection with this application and which are open to public inspection with this specification, and the contents of all such papers and documents are incorporated herein by reference.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5572656">US5572656</a></td><td class="patent-data-table-td patent-date-value">May 2, 1995</td><td class="patent-data-table-td patent-date-value">Nov 5, 1996</td><td class="patent-data-table-td ">Brother Kogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">Portrait drawing apparatus having image data input function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5588096">US5588096</a></td><td class="patent-data-table-td patent-date-value">May 15, 1996</td><td class="patent-data-table-td patent-date-value">Dec 24, 1996</td><td class="patent-data-table-td ">Casio Computer Co., Ltd.</td><td class="patent-data-table-td ">Object image display devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5600767">US5600767</a></td><td class="patent-data-table-td patent-date-value">Feb 17, 1995</td><td class="patent-data-table-td patent-date-value">Feb 4, 1997</td><td class="patent-data-table-td ">Casio Computer Co., Ltd.</td><td class="patent-data-table-td ">Image creation device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5808624">US5808624</a></td><td class="patent-data-table-td patent-date-value">Jul 27, 1995</td><td class="patent-data-table-td patent-date-value">Sep 15, 1998</td><td class="patent-data-table-td ">Brother Kogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">Picture making apparatus for creating a picture for printing by assembling and positioning component parts</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6381346">US6381346</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 1, 1998</td><td class="patent-data-table-td patent-date-value">Apr 30, 2002</td><td class="patent-data-table-td ">Wheeling Jesuit University</td><td class="patent-data-table-td ">Three-dimensional face identification system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S232000">382/232</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S634000">345/634</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09G0005000000">G09G5/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009360000">G06K9/36</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T11/60">G06T11/60</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T9/00">G06T9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=0rH4BgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T9/001">G06T9/001</a></span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Apr 29, 2014</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 10, 19, 24, 32 AND 38 ARE CANCELLED.CLAIMS 1, 16, 23, 29 AND 36 ARE DETERMINED TO BE PATENTABLE AS AMENDED.CLAIMS 2-9, 11-15, 17-18, 20-22, 25-28, 30-31, 33-35, 37 AND 39-42, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 21, 2013</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20130408</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 16, 2011</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20111114</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">RECOGNICORP, LLC, TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:APACHE INNOVATIONS, LP;REEL/FRAME:027400/0341</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 7, 2011</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">APACHE INNOVATIONS, L.P., TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:IQ BIOMETRIX, INC.;REEL/FRAME:027182/0425</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20111011</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 7, 2010</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">4031806 CANADA, INC., CANADA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:BANQUE NATIONALE DU CANADA;REEL/FRAME:025109/0284</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20031031</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">IQ BIOMETRIX, INC., CANADA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INTERQUEST, INC.;REEL/FRAME:025109/0142</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">IQ BIOMETRIX, INC., TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:WHERIFY WIRELESS, INC.;REEL/FRAME:025109/0568</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20080226</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:IQ BIOMETRIX, INC.;REEL/FRAME:025109/0631</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20050722</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">WHERIFY WIRELESS, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20021213</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:IQ BIOMETRIX, INC.;REEL/FRAME:025109/0225</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">BANQUE NATIONALE DU CANADA, CANADA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:COTE, PIERRE;REEL/FRAME:025109/0308</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19990527</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">INTERQUEST, INC., CANADA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:4031806 CANADA, INC.;REEL/FRAME:025109/0390</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20031112</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4ff636b3d23669b7103f3b3a3a18b4cd.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1gpxzDb95kd9fyhgKnvZvvzzc9Uw\u0026id=0rH4BgABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3Ghu2Qc8nl8SBapZK3WBg_NacXfg\u0026id=0rH4BgABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U04Wrv1_52APsdPom2qh2n9K2IRuw","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_and_apparatus_for_encoding_decodi.pdf?id=0rH4BgABERAJ\u0026output=pdf\u0026sig=ACfU3U38VrZN-ibtGPN7XuAyn4w0tJ6NRg"},"sample_url":"http://www.google.com/patents/reader?id=0rH4BgABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>