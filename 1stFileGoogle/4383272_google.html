<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US4383272 - Video signal interpolation using motion estimation - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Video signal interpolation using motion estimation"><meta name="DC.contributor" content="Arun N. Netravali" scheme="inventor"><meta name="DC.contributor" content="John D. Robbins" scheme="inventor"><meta name="DC.contributor" content="Bell Telephone Laboratories, Incorporated" scheme="assignee"><meta name="DC.date" content="1981-4-13" scheme="dateSubmitted"><meta name="DC.description" content="Information defining elements of a picture is estimated by interpolation using information from related locations in preceding and succeeding versions of the picture. The related locations are determined by forming an estimate of the displacement of objects in the picture. Displacement estimates are advantageously formed recursively, with updates being formed only in moving areas of the picture. If desired, an adaptive technique can be used to permit motion compensated interpolation or fixed position interpolation, depending upon which produces better results."><meta name="DC.date" content="1983-5-10" scheme="issued"><meta name="DC.relation" content="US:4218703" scheme="references"><meta name="DC.relation" content="US:4218704" scheme="references"><meta name="DC.relation" content="US:4232338" scheme="references"><meta name="DC.relation" content="US:4307420" scheme="references"><meta name="citation_patent_number" content="US:4383272"><meta name="citation_patent_application_number" content="US:06/253,698"><link rel="canonical" href="http://www.google.com/patents/US4383272"/><meta property="og:url" content="http://www.google.com/patents/US4383272"/><meta name="title" content="Patent US4383272 - Video signal interpolation using motion estimation"/><meta name="description" content="Information defining elements of a picture is estimated by interpolation using information from related locations in preceding and succeeding versions of the picture. The related locations are determined by forming an estimate of the displacement of objects in the picture. Displacement estimates are advantageously formed recursively, with updates being formed only in moving areas of the picture. If desired, an adaptive technique can be used to permit motion compensated interpolation or fixed position interpolation, depending upon which produces better results."/><meta property="og:title" content="Patent US4383272 - Video signal interpolation using motion estimation"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("hKPtU9vaGITIoATfpIGABg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("NZL"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("hKPtU9vaGITIoATfpIGABg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("NZL"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us4383272?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US4383272"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=iDMeBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS4383272&amp;usg=AFQjCNEuzXs6DzmbhJCUKFZVdixYwTm6pw" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US4383272.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US4383272.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US4383272" style="display:none"><span itemprop="description">Information defining elements of a picture is estimated by interpolation using information from related locations in preceding and succeeding versions of the picture. The related locations are determined by forming an estimate of the displacement of objects in the picture. Displacement estimates are...</span><span itemprop="url">http://www.google.com/patents/US4383272?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US4383272 - Video signal interpolation using motion estimation</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US4383272 - Video signal interpolation using motion estimation" title="Patent US4383272 - Video signal interpolation using motion estimation"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US4383272 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 06/253,698</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">May 10, 1983</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Apr 13, 1981</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Apr 13, 1981</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">06253698, </span><span class="patent-bibdata-value">253698, </span><span class="patent-bibdata-value">US 4383272 A, </span><span class="patent-bibdata-value">US 4383272A, </span><span class="patent-bibdata-value">US-A-4383272, </span><span class="patent-bibdata-value">US4383272 A, </span><span class="patent-bibdata-value">US4383272A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Arun+N.+Netravali%22">Arun N. Netravali</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22John+D.+Robbins%22">John D. Robbins</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Bell+Telephone+Laboratories,+Incorporated%22">Bell Telephone Laboratories, Incorporated</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US4383272.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US4383272.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US4383272.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (4),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (117),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (5),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (11)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=iDMeBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/4383272&usg=AFQjCNHRr4hc1xGJwaUdxwqvMgPpI3enJQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=iDMeBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D4383272&usg=AFQjCNF55I9AHvg-DB6-oRpdHc_8XpQ1zw">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=iDMeBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D4383272A%26KC%3DA%26FT%3DD&usg=AFQjCNHsqaySB51z9ikCU5i1VfksWl8nwQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT52921551" lang="EN" load-source="patent-office">Video signal interpolation using motion estimation</invention-title></span><br><span class="patent-number">US 4383272 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA36389034" lang="EN" load-source="patent-office"> <div class="abstract">Information defining elements of a picture is estimated by interpolation using information from related locations in preceding and succeeding versions of the picture. The related locations are determined by forming an estimate of the displacement of objects in the picture. Displacement estimates are advantageously formed recursively, with updates being formed only in moving areas of the picture. If desired, an adaptive technique can be used to permit motion compensated interpolation or fixed position interpolation, depending upon which produces better results.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(4)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4383272-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4383272-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4383272-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4383272-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4383272-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4383272-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4383272-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4383272-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(24)</span></span></div><div class="patent-text"><div mxw-id="PCLM58734499" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. Apparatus for estimating the intensities of elements (pels) in a picture in accordance with information defining intensities of pels in preceding and succeeding versions of the picture including means for determining by interpolation intensities of pels in said picture in accordance with intensities of pels in related locations in said preceding and succeeding versions,<div class="claim-text">characterized in that</div> <div class="claim-text">said determining means includes means for selecting said related locations as a function of the displacement of objects in said picture.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The invention defined in claim 1 wherein said apparatus includes:<div class="claim-text">means for storing a present estimate D<sup>i</sup> of said displacement, and</div> <div class="claim-text">means for recursively updating said estimate for each element in said picture.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The invention defined in claim 2 wherein said apparatus includes means for operating said updating means only in moving areas in said picture.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The invention defined in claim 3 wherein said apparatus further includes:<div class="claim-text">means for computing a frame difference FD(x) indicating the intensity difference at spatially corresponding locations in preceding and succeeding versions, and</div> <div class="claim-text">means for computing a displaced frame difference [DFD(x,D)] indicating the intensity difference at the related locations determined by said displacement estimate,</div> <div class="claim-text">wherein said selecting means is arranged to select said displaced locations if said displaced frame difference is smaller than said frame difference and to select said corresponding locations otherwise.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The invention defined in claim 1 wherein said apparatus further includes:<div class="claim-text">means for storing the intensity values for pels in said preceding and succeeding versions, and</div> <div class="claim-text">means responsive to said present displacement estimate for addressing selected ones of said stored values.</div> </div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6. Apparatus for estimating the intensity values of each element (pel) of a picture being processed by interpolating between the intensity values of related pels in first and second other versions of said picture, including:<div class="claim-text">means for estimating the displacement of objects in said picture occurring between said other versions, and</div> <div class="claim-text">means for selecting said related pels in accordance with said displacement estimate.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The invention defined in claim 6 wherein said first and second other versions occur at intervals K<sub>1</sub> τ before and K<sub>2</sub> τ after said picture being processed, where K<sub>1</sub> and K<sub>2</sub> are positive integers and τ is a predetermined constant, and wherein said related pels are at displaced locations x-K<sub>1</sub> D and x+K<sub>2</sub> D in said first and second versions, respectively, where x is the vector location of the pel in said presently processed picture and D is the vector representing said displacement estimate per time τ.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The invention defined in claim 7 wherein said displacement estimate is recursively updated such that an update term is added to each estimate to form the next estimate, where said update term is a function of the intensity difference at said displaced locations.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The invention defined in claim 8 wherein said apparatus further includes means for comparing said intensity difference at said displaced location with the intensity difference at the same location x in said other versions, and<div class="claim-text">means for operating said selecting means only if said displaced location intensity difference is smaller than said same location intensity difference.</div> </div>
    </div>
    </div> <div class="claim"> <div num="10" class="claim">
      <div class="claim-text">10. Apparatus for reducing the bandwidth needed to transmit a video signal representing a sequence of pictures by encoding the intensity values of pels in ones of said pictures in said sequence and reconstructing missing pictures using information from encoded pictures, including:<div class="claim-text">means for computing the intensity of pels in a missing picture by interpolating the intensity of pels in corresponding locations in the encoded ones of said pictures which precede and follow said missing picture, and</div> <div class="claim-text">means for selecting said corresponding locations as a function of the displacement of objects in said picture between said preceding and following pictures.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The invention defined in claim 10 further including:<div class="claim-text">means for storing an estimate D<sup>i</sup> of said displacement, and</div> <div class="claim-text">means for recursively updating said estimate to form a new estimate D<sup>i+1</sup> by adding a correction term which is a joint function of (a) the intensity difference at said corresponding location, and (b) the spatial gradient of said intensity difference.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The invention defined in claim 11 wherein said apparatus further includes:<div class="claim-text">means for storing the intensity values of pels in said preceding and following pictures, and</div> <div class="claim-text">means for addressing said stored values in accordance with D<sup>i</sup> to obtain the intensities at said corresponding locations.</div> </div>
    </div>
    </div> <div class="claim"> <div num="13" class="claim">
      <div class="claim-text">13. A method of estimating the intensities of elements (pels) in a picture in accordance with information defining intensities of pels in preceding and succeeding versions of the picture including the step of determining by interpolation intensities of pels in said picture in accordance with intensities of pels in related locations in said preceding and succeeding versions,<div class="claim-text">characterized in that</div> <div class="claim-text">said determining step includes selecting said related locations as a function of the displacement of objects in said picture.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The method defined in claim 13 further including the steps of:<div class="claim-text">storing a present estimate D<sup>i</sup> of said displacement, and</div> <div class="claim-text">recursively updating said estimate for each element in said picture.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. The method defined in claim 14 further including the step of operating said updating means only in moving areas in said picture.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The method defined in claim 15 further including the steps of:<div class="claim-text">computing a frame difference FD(x) indicating the intensity difference at spatially corresponding locations in preceding and succeeding versions, and</div> <div class="claim-text">computing a displaced frame difference [DFD(x,D)] indicating the intensity difference at the related locations determined by said displacement estimate,</div> <div class="claim-text">wherein said selecting step includes selecting said displaced locations if said displaced frame difference is smaller than said frame difference and selecting said corresponding locations otherwise.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The method defined in claim 13 wherein said determining step further includes:<div class="claim-text">storing the intensity values for pels in said preceding and succeeding versions, and addressing selected ones of said stored values in response to said present displacement estimate.</div> </div>
    </div>
    </div> <div class="claim"> <div num="18" class="claim">
      <div class="claim-text">18. A method of estimating the intensity values of each element (pel) of a picture being processed by interpolating between the intensity values of related pels in first and second other versions of said picture, including the steps of<div class="claim-text">estimating the displacement of objects in said picture occurring between said other versions, and</div> <div class="claim-text">selecting said related pels in accordance with said displacement estimate.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The method defined in claim 18 wherein said first and second other versions occur at intervals K<sub>1</sub> τ before and K<sub>2</sub> τ after said picture being processed, where K<sub>1</sub> and K<sub>2</sub> are positive integers and τ is a predetermined constant, and wherein said related pels are at displaced locations x-K<sub>1</sub> D and x+K<sub>2</sub> D in said first and second versions, respectively, where x is the vector location of the pel in said presently processed picture and D is the vector representing said displacement estimate per time τ.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The method defined in claim 19 wherein said displacement estimating step includes recursive updating such that an update term is added to each estimate to form the next estimate, where said update term is a function of the intensity difference at said displaced locations.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. The method defined in claim 20 further including the steps of comparing said intensity difference at said displaced location with the intensity difference at the same location x in said other versions, and<div class="claim-text">precluding said selecting step if said displaced location intensity difference is larger than said same location intensity difference.</div> </div>
    </div>
    </div> <div class="claim"> <div num="22" class="claim">
      <div class="claim-text">22. A method of reducing the bandwidth needed to transmit a video signal representing a sequence of pictures by encoding the intensity values of pels in ones of said pictures in said sequence and reconstructing missing pictures using information from encoded pictures, including:<div class="claim-text">computing the intensity of pels in a missing picture by interpolating the intensity of pels in corresponding locations in the encoded ones of said pictures which precede and follow said missing picture, and</div> <div class="claim-text">selecting said corresponding locations as a function of the displacement of objects in said picture between said preceding and following pictures.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. The method defined in claim 22 further including the steps of:<div class="claim-text">storing an estimate D<sup>i</sup> of said displacement, and</div> <div class="claim-text">recursively updating said estimate to form a new estimate D<sup>i+1</sup> by adding a correction term which is a joint function of (a) the intensity difference at said corresponding location, and (b) the spatial gradient of said intensity difference.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" class="claim">
      <div class="claim-text">24. The method defined in claim 23 further including the steps of:<div class="claim-text">storing the intensity values of pels in said preceding and following pictures, and</div> <div class="claim-text">addressing said stored values in accordance with D<sup>i</sup> to obtain the intensities at said corresponding locations.</div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES65252841" lang="EN" load-source="patent-office" class="description">
    <heading>TECHNICAL FIELD</heading> <p>This invention relates generally to interpolation of video signals and, in particular, to interpolation of video signals using motion estimation.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>In various schemes for interframe coding of television pictures, it is advantageous to drop or discard information from some fields or frames by subsampling the video signal at a fraction of the normal rate. This is done in order to prevent overflow of the data rate equalization buffers disposed in the transmission path, or simply to increase the efficiency of the encoder by removing redundant information. At the receiver, a reconstructed version of the information contained in the nontransmitted fields or frames is obtained by interpolation, using information derived from the transmitted fields. Simple linear interpolation may be performed by averaging the intensity information defining picture elements (pels) in the preceding and succeeding transmitted fields at fixed locations which are most closely related to the location of the picture element that is presently being processed. In certain instances, the interpolation may be performed adaptively, such that the pels used to form certain reconstructed or estimated intensity values are selected from two or more groups having different spatial patterns or such that the information obtained from pels in the same relative spatial positions in the prior and succeeding frames are combined in two or more different ways.</p>
    <p>Both the aforementioned fixed and adaptive interpolative techniques are adequate to estimate and thus recover the nontransmitted picture information when little motion occurs in the picture. However, where objects, particularly those with a high degree of detail, are moving quickly in the field of view of the television camera, dropping fields or frames in the encoder and subsequent reconstruction using interpolation often causes blurring and other objectionable visual distortion. Accordingly, the broad object of the present invention is to enable improved estimation of intensity information defining elements in a picture using interpolative techniques on information derived from preceding and succeeding versions of the picture. A specific object is to improve the reconstruction of a nontransmitted field of a video signal using information from previous and succeeding fields, so as to eliminate annoying distortion and flicker.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The foregoing and additional objects are achieved in accordance with the instant invention by estimating the intensity information defining elements in a picture (which may be a nontransmitted field or other portion of a video signal) based on information defining pels in related locations in preceding and succeeding versions of the same picture, using an interpolative technique which takes account of the motion of objects in the picture to identify the related locations. More specifically, apparatus for estimating the desired intensity information includes a recursive motion estimator for providing an indication of the displacement of objects between the two available versions of the picture which precede and follow the picture being processed and an interpolator arranged to utilize information defining pels at the appropriate displaced locations within the preceding and succeeding versions to form an estimate of the desired information. In a preferred embodiment, an adaptive technique is used to switch between displacement compensated interpolation and fixed position interpolation, depending upon which produces the best results in the local picture area.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWING</heading> <p>The features and advantages of the present invention will be more readily understood from the following detailed description when read in light of the accompanying drawing in which:</p>
    <p>FIG. 1 is a representation of a series of video fields indicating the locations of picture elements used to form estimates of nontransmitted information in accordance with prior art fixed position interpolative techniques;</p>
    <p>FIG. 2 is a similar representation of a series of video fields indicating the displaced pel locations in the preceding and succeeding frames used to estimate the information defining the presently processed picture element in accordance with the present invention;</p>
    <p>FIG. 3 is a block diagram of apparatus arranged in accordance with the present invention for reconstructing information defining pels in a nontransmitted field of a video signal by processing information derived from preceding and succeeding versions of the picture using motion compensated interpolation; and</p>
    <p>FIG. 4 illustrates spatial interpolation performed in interpolators 305 and 306 of FIG. 3.</p>
    <heading>DETAILED DESCRIPTION</heading> <p>One embodiment of the present invention, which permits reconstruction of a nontransmitted field of a video signal using information derived from transmitted preceding and succeeding fields, will be better appreciated by consideration of FIG. 1, which illustrates the time-space relationship of a sequence of television fields 101-105, each of which can be thought of as a "snap-shot" or version of a moving picture which is electrically represented by the video signal being processed. Vector 106 indicates the direction of time progression, such that field 101 occurs first and is followed in succession by fields 102 . . . 105. The time interval between successive fields is given by τ, and is generally 1/60<sup>th</sup> of a second for conventional video encoding. Each field is obtained by scanning the picture being processed along a plurality of generally parallel scan lines, such as lines 110-115 in field 104. In order to conserve bandwidth, a conventional video signal generator is arranged to interlace the scan lines in each pair of successive fields. Thus, each line in an odd numbered field is offset from the corresponding line in the previous (and next) field by half the distance between adjacent lines. The NTSC standard requires a total of 525 scan lines for each pair of fields, which together constitute a frame.</p>
    <p>Assuming that even numbered fields 102 and 104 shown in FIG. 1 were encoded for transmission using conventional subsampling and/or other compression techniques, and that these fields have been reconstructed at the receiver, it is known to reconstruct information defining pels in the nontransmitted odd fields 101, 103 and 105 by interpolation. As used herein, "information" can include intensity information describing the different color components (red, green and blue) of a composite signal or combinations thereof, such as luminance and chrominance information. Using "intensity" generally in the foregoing sense, to reconstruct or estimate the intensity value I<sub>E</sub> for a pel E on line 120 in field 103, it is typical to use intensity information from spatially corresponding locations in the transmitted preceding field 102 and the succeeding field 104. Since the scan lines in the even and odd fields are offset from one another, the intensity values in fields 102 and 104 at the precisely corresponding spatial location of pel E are not available. However, intensity values for pels on the scan lines just above and just below line 120 may be used. Thus, the intensity of pel E can be estimated as the average (I<sub>A</sub> +I<sub>B</sub> +I<sub>C</sub> +I<sub>D</sub>)/4 of the intensities of pels A and B in field 104 and pels C and D in field 102. As stated previously, this fixed position interpolation procedure for reconstructing the nontransmitted fields is generally satisfactory, as long as objects in the picture are relatively still. However, in areas of the picture which are changing quickly, the reconstructed version generally appears noticeably blurred and distorted. This significantly reduces the utility of the subsampling, and limits the number of fields which may be dropped at the transmitter and successfully recovered at the receiver.</p>
    <p>The motion compensated interpolation strategy of the present invention, again considered in the context of reconstruction of a nontransmitted field using information from preceding and succeeding fields which are available at the receiver, can be explained by reference to FIG. 2, which again depicts the time-space relationship of a series of fields 201 . . . 205. For the sake of generality, it is assumed that K<sub>1</sub> field intervals τ including field 202 intervene between the previous transmitted field 201 and the present (nontransmitted) field 203, and that K<sub>2</sub> field intervals including field 204 intervene between field 203 and the succeeding transmitted field 205. K<sub>1</sub> and K<sub>2</sub> are, of course, positive integers. In order to obtain an estimate of the intensity value of each pel in nontransmitted field 203, it is first necessary to form an estimate D of the displacement per field interval of moving objects in the picture between the transmitted fields 201 and 205 which bracket field 203. The underscore used for the variable D and hereinbelow indicates a vector having components in the horizontal (picture element to element) and vertical (scan line to line) directions. It is assumed here that objects in the pictures being processed are in simple uniform translation during this period. Second, the intensity values at the displaced locations in the previous and succeeding transmitted fields which "correspond" to the location in the field being processed are determined. As used here, the "correspondence" indicates locations at which the same object is expected to be in different versions of the picture. Finally, the desired intensity value is derived using interpolation or averaging.</p>
    <p>To illustrate, if the position of a presently processed pel 250 in field 203 is denoted by vector x, then the location of the "corresponding" displaced pel 260 in field 201 is given by x-K<sub>1</sub> D and the intensity at that location is written I(x-K<sub>1</sub> D,t-K<sub>1</sub> τ). Similarly, the location in field 205 of pel 270 which contains the object depicted in pel 250 is given by x+K<sub>2</sub> D, and the intensity at this location is I(x+K<sub>2</sub> D,t+K<sub>2</sub> τ). In this example, the desired intensity value I(x,t) for pel 250 is determined by interpolation, such that: ##EQU1## From Equation (1) it is seen that interpolation produces a weighted average of intensity values from fields displaced timewise from the present field 203. If K<sub>1</sub> &gt;K<sub>2</sub>, field 203 is closer in time to field 205, and more weight is given to the intensity value information derived from the latter. On the other hand, if K<sub>2</sub> &gt;K<sub>1</sub>, more weight is given to the intensity value I(x-K<sub>1</sub> D,t-K<sub>1</sub> t) from field 201. When alternate field subsampling is used, K<sub>1</sub> =K<sub>2</sub> =1 and the interpolated intensity value I(x,t) is a simple average of I(x+D,t+τ) and I(x-D,t-τ).</p>
    <p>With respect to formation of the displacement estimate D, it must be understood that the magnitude and direction of this vector varies, in a real television scene, as a function of both time and space. Accordingly, the intensity values at pels 250, 260 and 270 are not likely to be exactly equal. For convenience, a displaced frame difference DFD(x,D) which is a function both of location x and displacement estimate D, is defined such that:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">DFD(x,D)=I(x+K<sub>2</sub> D,t+K<sub>2</sub> τ)-I(x-K<sub>1</sub> D,t-K<sub>1</sub> τ)(2)</pre>
    
    <p>To estimate the value of D, it is advantageous to minimize |DFD(x,D)|<sup>2</sup> recursively for every pel position x within the moving area of the picture. This is analogous to minimizing mean square error (since DFD is an error indicator) and can be done using a steepest descent technique. Thus: ##EQU2## In Equations (3)-(5), D<sup>i</sup> is a present estimate of the displacement vector D and D<sup>i+1</sup> is the next estimate, with the recursion being performed for each picture element i=1, 2, . . . . The symbol ∇<sub>D</sub> indicates a gradient or spatial rate of change calculated assuming a displacement vector D. In the horizontal picture direction, the rate of change can be determined from "element differences" ED(x,t), i.e., the intensity differences between successive picture elements on a single scan line evaluated at the location x in the field occurring at time t. The rate of change in the vertical direction is similarly determined from "line differences" LD(x,t) which are intensity differences between pels in the same horizontal position on difference scan lines, again evaluated at the location x in the field occuring at time t. Scaling factor ε is used in Equations (3) through (5) to limit large changes; ε is always less than one and is preferably in the range of 0.1 to 0.001. Further details concerning the recursive displacement estimation technique described herein may be obtained from applicants' U.S. Pat. No. 4,218,703 issued Aug. 19, 1980.</p>
    <p>The displacement recursion specified in Equations (3)-(5) is carried out only in the moving areas of the picture. These areas can be identified when the frame difference, denoted FD(x), has a magnitude which exceeds a preselected threshold value. The frame difference is defined as the intensity difference, at pel location x, as measured in the previous and succeeding frames. Thus:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">FD(x)=I(x,t+K<sub>2</sub> τ)-I(x,t-K<sub>1</sub> τ).           (6)</pre>
    
    <p>While it is possible to implement the interpolation specified in Eq. (1) and the displacement estimation specified in Eq. (5), several simplifications can significantly reduce circuit complexity. For example, the displacement estimates calculated in Equations (3)-(5) require several multiplications for each iteration. This can be reduced by considering only the sign of the two right-hand terms, i.e., ##EQU3## where the SIGN function is defined by ##EQU4## where T is a small non-negative number. A second simplification results by use of spatial gradients in only one transmitted field rather than in both the previous and succeeding fields. This modification simplifies Eq. (5) as follows: ##EQU5##</p>
    <p>Yet another modification is quite desirable in order to simplify the hardware implementation described below. In this modification, the present displacement estimate D<sup>i</sup> is used to compute the intensity value I(x,t) in Equation (1), instead of the next displacement estimate D<sup>i+1</sup> which more precisely belongs in the intensity value equation. This modification permits the same set of intensity values to be used for both the computation of the displacement estimate and the interpolation of the missing field intensity values.</p>
    <p>While it is not essential in practicing the present invention, an adaptive technique is preferred in the interpolative recovery of nontransmitted fields, such that "displacement compensated interpolation" in accordance with the present invention is used instead of conventional "fixed position" interpolation only when it produces better results. Switching between the two types of interpolation is accomplished under the control of adaption logic which compares the magnitude of the frame difference FD(x) and the displaced frame difference DFD(x,D) to determine which is smaller. If DFD(x,D)&lt;FD(x), displacement compensation is better, and Equation (1) is used in the interpolation. If the frame difference is smaller, the interpolated intensity I(x,t) value is computed conventionally using the same location in the previous and succeeding transmitted fields, as follows: ##EQU6##</p>
    <p>A block diagram of apparatus arranged to estimate the intensity values of elements in a picture (such as a nontransmitted field of a video signal) using either motion compensated interpolation or fixed position interpolation is shown in FIG. 3. Intensity information representing the versions of the picture which precede and follow the picture being estimated, obtained, for example, by decoding transmitted information representing fields such as fields 201 and 205 of FIG. 2, is entered in random access memories 301 and 302, respectively, via lines 370 and 371. The information is stored within these memories such that intensity values for specific addressed groups of pels can be recovered. For this purpose, each of the memories 301 and 302 includes address inputs 303 and 304, respectively, which receive the integer portions of K<sub>1</sub> D<sup>i</sup> and K<sub>2</sub> D<sup>i</sup>, which indicate the position in fields 201 and 205 of the same object which is depicted in the pel for which an intensity is being estimated. The products of the displacement estimate D<sub>i</sub> stored in a delay element 310 and the factors K<sub>1</sub> and K<sub>2</sub>, respectively, are formed by multipliers 331 and 332. The intensity values for several (usually four) picture elements nearest the addressed displaced locations are output from memories 301 and 302 and applied to a pair of interpolators 305 and 306 via lines 307 and 308, respectively.</p>
    <p>Interpolators 305 and 306 are each arranged to use the intensity values output from memories 301 and 302 and the fractional part of the displacement estimates K<sub>1</sub> D<sup>i</sup> and K<sub>2</sub> D<sup>i</sup> received on lines 365 and 366, respectively, to compute the intensity values I(x-K<sub>1</sub> D<sup>i</sup>, t-K<sub>1</sub> τ) and I(x+K<sub>2</sub> D<sup>i</sup>,t+K<sub>2</sub> τ). This procedure, which is essentially intrafield interpolation "in space", is used because the displacement estimates usually do not indicate a single pel location, but rather a position between pels; a second interpolation step described below, which is interfield interpolation "in time", actually calculates the nontransmitted intensity values being reconstructed. To determine the intensity at the in-between locations, the fractional portions of the displacement estimates are resolved into horizontal and vertical components. The intensity values for pels which bracket the specified location both vertically and horizontally are chosen, and the in-between values computed by linear interpolation. An example of this interpolation is given below. The resulting displaced interpolated intensity values are output on lines 309 and 310.</p>
    <p>In order to determine the desired intensity value I(x,t) in accordance with Eq. (1), the intensity values at the displaced locations in fields 201 and 205 are timewise interpolated. For this purpose the outputs on lines 309 and 310 are weighted by factors K<sub>2</sub> and K<sub>1</sub> in multipliers 311 and 312, and a sum of the weighted values is formed in adder 313. The sum is then scaled by 1/(K<sub>1</sub> +K<sub>2</sub>) in multiplier 314. From the foregoing, it is seen that more emphasis is given to the intensity value of the field closest in time to field 203, and less emphasis is given the more remote field. The output of multiplier 314 on line 316 which represents the motion compensated interpolated intensity value specified in Eq. (1), is applied to one input of switch 315.</p>
    <p>Field memories 301 and 302 are also arranged to make available on lines 317 and 318, respectively, the intensity values I(x,t-K<sub>1</sub> τ) and I(x,t+K<sub>2</sub> τ) for pels in the transmitted fields which are in the same spatial position as the pel presently being processed. To obtain an estimate of I(x,t) by fixed position interpolation, the intensity values are again likewise weighted by forming the sum of K<sub>1</sub> times the intensity in field 205 and K<sub>2</sub> times the intensity in field 201, and by dividing the sum by 1/(K<sub>1</sub> +K<sub>2</sub>). This is accomplished by applying the signals on lines 317 and 318 to inputs of adder 319 via multipliers 341 and 342 with coefficients K<sub>1</sub> and K<sub>2</sub>, respectively. The output of adder 319 is applied, in turn, to a multiplier circuit 330 via line 320, where the sum is multiplied by the factor 1/(K<sub>1</sub> +K<sub>2</sub>). The resulting value represents the intensity estimate specified in Eq. (10), which is applied to a second input of switch 315.</p>
    <p>As mentioned previously, the position of switch 315 is adaptively controlled so as to select either the motion compensated interpolated value on line 316 or the fixed position interpolated value output from multiplier 330, depending upon the relative magnitudes of the frame difference FD(x) and the displaced frame difference DFD(x,D). The magnitude of FD(x) is obtained by forming the differences between I(x,t-K<sub>1</sub> τ) and I(x,t+K<sub>2</sub> τ) in a subtractor 325 and applying the subtractor output on line 326 to a magnitude circuit 327, which disregards sign information. The magnitude of DFD(x,D) is obtained by forming the difference between I(x-D,t-K<sub>1</sub> τ) and I(x+D,t+K<sub>2</sub> τ) in a subtractor circuit 322 and applying the difference to a magnitude circuit 324. |FD(x)| and |DFD(x,D)| are compared in a subtractor circuit 321, and a sign bit output is used to control the position of switch 315. Thus, when the frame difference FD(x) is smaller than the displaced frame difference DFD(x,D) in the local area of the picture being processed, switch 315 is arranged to couple the output of multiplier 330, representing a fixed position interpolation, through the switch to output line 390. On the other hand, if the displaced frame difference is smaller, switch 315 is positioned to couple the output of multiplier 314 representing motion compensated interpolation through to output line 390. The estimated intensity value available on line 390 can be accumulated in a memory, not shown, and the entire process described above repeated for the remaining picture elements in the field. When the entire field has been reconstructed, the contents of the memory may be applied to a display medium in the appropriate time position with respect to the transmitted fields, by multiplexing apparatus, not shown.</p>
    <p>As mentioned previously, the displacement estimate D<sup>i</sup> is stored in a one pel delay element 350, and recursively updated for each pel. To implement the updating, the output of delay element 350 is applied to one input of an adder 351, which receives an update or correction term as its second input on line 352. The output of adder 351 is the next displacement estimate D<sup>i+1</sup>, which is, in turn, coupled back to the input of delay element 350 to yield the next estimate. Displacement estimates are updated in accordance with Eq. (5) only in the moving area of the picture, and a "zero" update is used otherwise. For this purpose, the position of switch 353 is controlled by the output of comparator 354, the latter serving to determine whether or not |FD(x)| output from magnitude circuit 327 exceeds a predetermined threshold value T. If the threshold is not exceeded, the picture area being processed is not moving. In this circumstance, switch 353 is positioned as shown in FIG. 3 so as to couple a "0" update to adder 351. On the other hand, if the output of comparator 354 indicates that the frame difference does exceed T, a moving area in the picture has been detected, switch 353 is repositioned, and the displacement correction term (from multiplier 360) is coupled through switch 353 to adder 351. The magnitude of the update term is calculated in accordance with Eq. (5) by multiplying second outputs of interpolators 305 and 306 on lines 343 and 344, which represent the displaced element and line differences in the previous and succeeding fields, by K<sub>1</sub> and K<sub>2</sub>, respectively, in multipliers 368 and 369 and forming the sum of these products in adder 367. The sum is multiplied, in turn, by the displaced frame difference output from subtractor 322, and this product is scaled by the factor ε in multiplier 360 before being applied to the second input of switch 353. The manner in which the element and line differences are formed in interpolators 305 and 306 is explained below, in connection with FIG. 4.</p>
    <p>After each nontransmitted field has been reconstructed by interpolation in accordance with the present invention, it is necessary to update multiplier coefficients K<sub>1</sub> and K<sub>2</sub> (when either or both exceeds one) before the next nontransmitted field is processed. For example, in FIG. 2, assuming that fields 201 and 205 are transmitted and fields 202, 203, and 204 are not, then K<sub>1</sub> =K<sub>2</sub> =2 when field 203 is being processed. When field 202 is processed, K<sub>1</sub> =1 and K<sub>2</sub> =3. On the other hand, when field 204 is processed, K<sub>1</sub> =3 and K<sub>2</sub> =1. Updating of the coefficients K<sub>1</sub> and K<sub>2</sub> is easily carried out by storing their values in random access memories and by reading out appropriate coefficients under control of clocking circuitry not shown. Information needed to control clocking is derived from sync signals recovered from the transmitted video fields.</p>
    <p>An example of the spatial (intrafield) interpolation performed by interpolators 305 and 306 is illustrated graphically in FIG. 4. Locations P, Q, R and S represent four picture elements in a transmitted field of the signal being processed, and I<sub>P</sub>, I<sub>Q</sub>, I<sub>R</sub> and I<sub>S</sub> represent the intensity values at these locations. For convenience, it is assumed that location Q is at the origin of an orthogonal coordinate system, and locations P, R and S are at coordinates (0,1), (1,1) and (1,0), respectively. If the displacement estimate D<sup>i</sup> shown by vector 401 has a horizontal component with a fractional portion x, 0&lt;x&lt;1 and a vertical component with a fractional portion y, 0&lt;y&lt;1, then the intensity value at location (x,0) is obtained by linear interpolation such that:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">I.sub.(x,0) =(1-x)I<sub>Q</sub> +(x)I<sub>s</sub>                      (11)</pre>
    
    <p>and the intensity value at location (x,1) is given by:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">I.sub.(x,1) =(1-x)I<sub>P</sub> +(x)I<sub>R</sub>.                     (12)</pre>
    
    <p>The intensity at location (x,y) is also obtained by interpolation, such that: ##EQU7## From Eq. (14), it is seen that I.sub.(x,y) is a weighted sum of the intensities of the pels surrounding the location specified by the displacement estimate, with more weight being given to the closest pels. If desired, other interpolation weights can be used, or additional samples can be used to contribute to the weighting pattern.</p>
    <p>The manner in which element and line differences ED and LD are formed in interpolators 305 and 306 can also be illustrated by reference to FIG. 4. For example, if I<sub>P</sub>, I<sub>Q</sub>, I<sub>R</sub> and I<sub>S</sub> represent the intensity values for pels in field 201 at time t-K<sub>1</sub> τ and at spatial locations which surround the location indicated by vector 401, then the element difference ED can be represented by 1/2[(I<sub>R</sub> -I<sub>P</sub>)+(I<sub>S</sub> -I<sub>Q</sub>)] and the line difference LD can be represented by 1/2[(I<sub>Q</sub> -I<sub>P</sub>)+(I<sub>S</sub> -I<sub>R</sub>)]. This calculation averages the differences, in both the horizontal (element) and vertical (line) directions, for pels surrounding the location for which an intensity value is being estimated. Alternatively, a simple calculation can use a single difference (I<sub>R</sub> -I<sub>P</sub>) for ED and (I<sub>Q</sub> -I<sub>P</sub>) for LD. In either event, interpolators 305 and 306 may include suitable arithmetic circuits for forming the desired differences.</p>
    <p>The timewise interpolation performed by multipliers 311, 312 and 314 can be further illustrated by several examples. If a series of fields is designated a, b, c, d . . . and if every third field a, d, h . . . is transmitted, then the intensity value I<sub>b</sub> in field b is reconstructed using intensity values I<sub>a</sub> and I<sub>d</sub> from the transmitted fields a and d as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">I<sub>b</sub> =≃(2I<sub>a</sub> +I<sub>d</sub>)</pre>
    
    <p>The intensity value I<sub>c</sub> in field c is given by:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">I<sub>c</sub> =≃(I<sub>a</sub> +2I<sub>d</sub>).</pre>
    
    <p>As a second example, if every fourth field a, e, i . . . in the series is transmitted, the reconstructed intensity value I<sub>b</sub> in field b is given by:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">I<sub>b</sub> =1/4(3I<sub>a</sub> +I<sub>e</sub>)</pre>
    
    <p>Similarly, the reconstructed values for fields c and d are:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">I<sub>c</sub> =1/4(2I<sub>a</sub> +2I<sub>e</sub>), and</pre>
    
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">I<sub>d</sub> =1/4(I<sub>a</sub> +3I<sub>e</sub>).</pre>
    
    <p>Various modifications and adaptations may be made to the present invention by those skilled in the art. Accordingly, it is intended that the invention be limited only by the appended claims. For example, while the preceding description primarily described reconstruction of nontransmitted interlaced fields, it should be clearly understood that the present invention enables efficient reconstruction of information defining a picture or a portion of a picture using similar information derived from preceding and succeeding versions of the picture which include the same spatial area.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4218703">US4218703</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 16, 1979</td><td class="patent-data-table-td patent-date-value">Aug 19, 1980</td><td class="patent-data-table-td ">Bell Telephone Laboratories, Incorporated</td><td class="patent-data-table-td ">Technique for estimation of displacement and/or velocity of objects in video scenes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4218704">US4218704</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 16, 1979</td><td class="patent-data-table-td patent-date-value">Aug 19, 1980</td><td class="patent-data-table-td ">Bell Telephone Laboratories, Incorporated</td><td class="patent-data-table-td ">Method and apparatus for video signal encoding with motion compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4232338">US4232338</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 8, 1979</td><td class="patent-data-table-td patent-date-value">Nov 4, 1980</td><td class="patent-data-table-td ">Bell Telephone Laboratories, Incorporated</td><td class="patent-data-table-td ">Method and apparatus for video signal encoding with motion compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4307420">US4307420</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 2, 1980</td><td class="patent-data-table-td patent-date-value">Dec 22, 1981</td><td class="patent-data-table-td ">Nippon Hoso Kyokai</td><td class="patent-data-table-td ">Motion-compensated interframe coding system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4482970">US4482970</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 6, 1981</td><td class="patent-data-table-td patent-date-value">Nov 13, 1984</td><td class="patent-data-table-td ">Grumman Aerospace Corporation</td><td class="patent-data-table-td ">Boolean filtering method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4496972">US4496972</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 1, 1982</td><td class="patent-data-table-td patent-date-value">Jan 29, 1985</td><td class="patent-data-table-td ">Deutsche Forschungs-Und Versuchsanstalt Fur Luft-Und Raumfahrt E.V.</td><td class="patent-data-table-td ">Method for the representation of video images or scenes, in particular aerial images transmitted at reduced frame rate</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4543607">US4543607</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 24, 1983</td><td class="patent-data-table-td patent-date-value">Sep 24, 1985</td><td class="patent-data-table-td ">Quantel Limited</td><td class="patent-data-table-td ">Video processors</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4563703">US4563703</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 16, 1983</td><td class="patent-data-table-td patent-date-value">Jan 7, 1986</td><td class="patent-data-table-td ">Quantel Limited</td><td class="patent-data-table-td ">Video processing systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4612441">US4612441</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 9, 1984</td><td class="patent-data-table-td patent-date-value">Sep 16, 1986</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Army</td><td class="patent-data-table-td ">Moving object detection system using infrared scanning</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4630114">US4630114</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 5, 1985</td><td class="patent-data-table-td patent-date-value">Dec 16, 1986</td><td class="patent-data-table-td ">Ant Nachrichtentechnik Gmbh</td><td class="patent-data-table-td ">Method for determining the displacement of moving objects in image sequences and arrangement as well as uses for implementing the method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4651207">US4651207</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 5, 1985</td><td class="patent-data-table-td patent-date-value">Mar 17, 1987</td><td class="patent-data-table-td ">Ant Nachrichtentechnik Gmbh</td><td class="patent-data-table-td ">Motion adaptive interpolation of television image sequences</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4663665">US4663665</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 30, 1985</td><td class="patent-data-table-td patent-date-value">May 5, 1987</td><td class="patent-data-table-td ">Nippon Hoso Kyokai</td><td class="patent-data-table-td ">TV system conversion apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4667233">US4667233</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 17, 1985</td><td class="patent-data-table-td patent-date-value">May 19, 1987</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Apparatus for discriminating a moving region and a stationary region in a video signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4668987">US4668987</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 11, 1985</td><td class="patent-data-table-td patent-date-value">May 26, 1987</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Apparatus for band compression processing of a picture signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4679084">US4679084</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 20, 1986</td><td class="patent-data-table-td patent-date-value">Jul 7, 1987</td><td class="patent-data-table-td ">Rca Corporation</td><td class="patent-data-table-td ">Method and apparatus for freezing a television picture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4692801">US4692801</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 14, 1986</td><td class="patent-data-table-td patent-date-value">Sep 8, 1987</td><td class="patent-data-table-td ">Nippon Hoso Kyokai</td><td class="patent-data-table-td ">Bandwidth compressed transmission system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4695882">US4695882</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 30, 1985</td><td class="patent-data-table-td patent-date-value">Sep 22, 1987</td><td class="patent-data-table-td ">Kokusai Denshin Denwa Co., Ltd.</td><td class="patent-data-table-td ">Movement estimation system for video signals using a recursive gradient method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4703350">US4703350</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 3, 1985</td><td class="patent-data-table-td patent-date-value">Oct 27, 1987</td><td class="patent-data-table-td ">Picturetel Corporation</td><td class="patent-data-table-td ">Method and apparatus for efficiently communicating image sequences</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4709393">US4709393</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 16, 1983</td><td class="patent-data-table-td patent-date-value">Nov 24, 1987</td><td class="patent-data-table-td ">Quantel Limited</td><td class="patent-data-table-td ">Video processing systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4710809">US4710809</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 25, 1986</td><td class="patent-data-table-td patent-date-value">Dec 1, 1987</td><td class="patent-data-table-td ">Deutsche Forschungs-Und Versuchsanstalt Fur Luft- Und Raumfahrt E.V.</td><td class="patent-data-table-td ">Method for the representation of video images or scenes, in particular aerial images transmitted at reduced frame rate</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4716453">US4716453</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 20, 1985</td><td class="patent-data-table-td patent-date-value">Dec 29, 1987</td><td class="patent-data-table-td ">At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Digital video transmission system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4717956">US4717956</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 20, 1985</td><td class="patent-data-table-td patent-date-value">Jan 5, 1988</td><td class="patent-data-table-td ">North Carolina State University</td><td class="patent-data-table-td ">Image-sequence compression using a motion-compensation technique</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4720743">US4720743</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 12, 1985</td><td class="patent-data-table-td patent-date-value">Jan 19, 1988</td><td class="patent-data-table-td ">NEC Corporation and Nippon Telegraph and Telephone Corporation</td><td class="patent-data-table-td ">Predictine coding/decoding system for block-formed picture signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4727422">US4727422</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 3, 1985</td><td class="patent-data-table-td patent-date-value">Feb 23, 1988</td><td class="patent-data-table-td ">Picturetel Corporation</td><td class="patent-data-table-td ">Method and apparatus for efficiently communicating image sequence having improved motion compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4771331">US4771331</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 6, 1987</td><td class="patent-data-table-td patent-date-value">Sep 13, 1988</td><td class="patent-data-table-td ">Ant Nachrichtentechnik Gmbh</td><td class="patent-data-table-td ">Motion compensating field interpolation method using a hierarchically structured displacement estimator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4791487">US4791487</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 24, 1986</td><td class="patent-data-table-td patent-date-value">Dec 13, 1988</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Picture signal conversion device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4838685">US4838685</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 3, 1987</td><td class="patent-data-table-td patent-date-value">Jun 13, 1989</td><td class="patent-data-table-td ">Massachusetts Institute Of Technology</td><td class="patent-data-table-td ">Methods and apparatus for motion estimation in motion picture processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4858005">US4858005</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 14, 1987</td><td class="patent-data-table-td patent-date-value">Aug 15, 1989</td><td class="patent-data-table-td ">Independent Broadcasting Authority</td><td class="patent-data-table-td ">System for encoding broadcast quality television signals to enable transmission as an embedded code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4862264">US4862264</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 23, 1986</td><td class="patent-data-table-td patent-date-value">Aug 29, 1989</td><td class="patent-data-table-td ">British Broadcasting Corporation</td><td class="patent-data-table-td ">Method of coding a video signal for transmission in a restricted bandwidth</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4958226">US4958226</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 27, 1989</td><td class="patent-data-table-td patent-date-value">Sep 18, 1990</td><td class="patent-data-table-td ">At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Conditional motion compensated interpolation of digital motion video</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4979037">US4979037</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 14, 1989</td><td class="patent-data-table-td patent-date-value">Dec 18, 1990</td><td class="patent-data-table-td ">Sanyo Electric Co., Ltd.</td><td class="patent-data-table-td ">Apparatus for demodulating sub-nyquist sampled video signal and demodulating method therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4982285">US4982285</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 26, 1990</td><td class="patent-data-table-td patent-date-value">Jan 1, 1991</td><td class="patent-data-table-td ">Victor Company Of Japan, Ltd.</td><td class="patent-data-table-td ">Apparatus for adaptive inter-frame predictive encoding of video signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4985768">US4985768</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 18, 1990</td><td class="patent-data-table-td patent-date-value">Jan 15, 1991</td><td class="patent-data-table-td ">Victor Company Of Japan, Ltd.</td><td class="patent-data-table-td ">Inter-frame predictive encoding system with encoded and transmitted prediction error</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4987480">US4987480</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 11, 1989</td><td class="patent-data-table-td patent-date-value">Jan 22, 1991</td><td class="patent-data-table-td ">Massachusetts Institute Of Technology</td><td class="patent-data-table-td ">Multiscale coding of images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4999705">US4999705</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 3, 1990</td><td class="patent-data-table-td patent-date-value">Mar 12, 1991</td><td class="patent-data-table-td ">At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Three dimensional motion compensated video coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5049991">US5049991</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 20, 1990</td><td class="patent-data-table-td patent-date-value">Sep 17, 1991</td><td class="patent-data-table-td ">Victor Company Of Japan, Ltd.</td><td class="patent-data-table-td ">Movement compensation predictive coding/decoding method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5055925">US5055925</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 9, 1990</td><td class="patent-data-table-td patent-date-value">Oct 8, 1991</td><td class="patent-data-table-td ">U.S. Philips Corporation</td><td class="patent-data-table-td ">Arrangement for estimating motion in television pictures</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5055927">US5055927</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 5, 1989</td><td class="patent-data-table-td patent-date-value">Oct 8, 1991</td><td class="patent-data-table-td ">Deutsche Thomson-Brandt Gmbh</td><td class="patent-data-table-td ">Dual channel video signal transmission system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5057921">US5057921</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 21, 1990</td><td class="patent-data-table-td patent-date-value">Oct 15, 1991</td><td class="patent-data-table-td ">Thomson Consumer Electronics</td><td class="patent-data-table-td ">Process and device for temporal image interpolation, with corrected movement compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5081525">US5081525</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 25, 1990</td><td class="patent-data-table-td patent-date-value">Jan 14, 1992</td><td class="patent-data-table-td ">Hitachi Denshi Kabushikigaisha</td><td class="patent-data-table-td ">Opto-electric converting image pickup element and image pickup apparatus employing the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5107348">US5107348</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 11, 1990</td><td class="patent-data-table-td patent-date-value">Apr 21, 1992</td><td class="patent-data-table-td ">Zenith Electronics Corporation</td><td class="patent-data-table-td ">Temporal decorrelation of block artifacts</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5113255">US5113255</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 11, 1990</td><td class="patent-data-table-td patent-date-value">May 12, 1992</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Moving image signal encoding apparatus and decoding apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5191413">US5191413</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 1, 1990</td><td class="patent-data-table-td patent-date-value">Mar 2, 1993</td><td class="patent-data-table-td ">International Business Machines</td><td class="patent-data-table-td ">System and method for eliminating interlace motion artifacts in captured digital video data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5258836">US5258836</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 5, 1992</td><td class="patent-data-table-td patent-date-value">Nov 2, 1993</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Encoding of motion picture signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5301018">US5301018</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 16, 1993</td><td class="patent-data-table-td patent-date-value">Apr 5, 1994</td><td class="patent-data-table-td ">Ampex Systems Corporation</td><td class="patent-data-table-td ">Method and apparatus for shuffling image data into statistically averaged data groups and for deshuffling the data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5339108">US5339108</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 9, 1992</td><td class="patent-data-table-td patent-date-value">Aug 16, 1994</td><td class="patent-data-table-td ">Ampex Corporation</td><td class="patent-data-table-td ">Ordering and formatting coded image data and reconstructing partial images from the data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5434623">US5434623</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 20, 1991</td><td class="patent-data-table-td patent-date-value">Jul 18, 1995</td><td class="patent-data-table-td ">Ampex Corporation</td><td class="patent-data-table-td ">Method and apparatus for image data compression using combined luminance/chrominance coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5581302">US5581302</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 30, 1995</td><td class="patent-data-table-td patent-date-value">Dec 3, 1996</td><td class="patent-data-table-td ">National Semiconductor Corporation</td><td class="patent-data-table-td ">For generating compressed video data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5592226">US5592226</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 26, 1994</td><td class="patent-data-table-td patent-date-value">Jan 7, 1997</td><td class="patent-data-table-td ">Btg Usa Inc.</td><td class="patent-data-table-td ">Method and apparatus for video data compression using temporally adaptive motion interpolation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5600731">US5600731</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 9, 1991</td><td class="patent-data-table-td patent-date-value">Feb 4, 1997</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Method for temporally adaptive filtering of frames of a noisy image sequence using motion estimation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5623313">US5623313</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 22, 1995</td><td class="patent-data-table-td patent-date-value">Apr 22, 1997</td><td class="patent-data-table-td ">Tektronix, Inc.</td><td class="patent-data-table-td ">Fractional pixel motion estimation of video signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5627601">US5627601</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 30, 1994</td><td class="patent-data-table-td patent-date-value">May 6, 1997</td><td class="patent-data-table-td ">National Semiconductor Corporation</td><td class="patent-data-table-td ">Motion estimation with bit rate criterion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5644361">US5644361</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 30, 1994</td><td class="patent-data-table-td patent-date-value">Jul 1, 1997</td><td class="patent-data-table-td ">National Semiconductor Corporation</td><td class="patent-data-table-td ">Subsampled frame storage technique for reduced memory size</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5682209">US5682209</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 13, 1995</td><td class="patent-data-table-td patent-date-value">Oct 28, 1997</td><td class="patent-data-table-td ">Tektronix, Inc.</td><td class="patent-data-table-td ">Motion estimation using limited-time early exit with prequalification matrices and a predicted search center</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5943096">US5943096</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 24, 1995</td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td ">National Semiconductor Corporation</td><td class="patent-data-table-td ">Motion vector based frame insertion process for increasing the frame rate of moving images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5970504">US5970504</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 3, 1996</td><td class="patent-data-table-td patent-date-value">Oct 19, 1999</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Moving image anchoring apparatus and hypermedia apparatus which estimate the movement of an anchor based on the movement of the object with which the anchor is associated</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6144972">US6144972</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 22, 1997</td><td class="patent-data-table-td patent-date-value">Nov 7, 2000</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Moving image anchoring apparatus which estimates the movement of an anchor based on the movement of the object with which the anchor is associated utilizing a pattern matching technique</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6192080">US6192080</a></td><td class="patent-data-table-td patent-date-value">Dec 4, 1998</td><td class="patent-data-table-td patent-date-value">Feb 20, 2001</td><td class="patent-data-table-td ">Mitsubishi Electric Research Laboratories, Inc.</td><td class="patent-data-table-td ">Motion compensated digital video signal processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6269174">US6269174</a></td><td class="patent-data-table-td patent-date-value">Apr 3, 1998</td><td class="patent-data-table-td patent-date-value">Jul 31, 2001</td><td class="patent-data-table-td ">Ligos Corporation</td><td class="patent-data-table-td ">Apparatus and method for fast motion estimation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6331874">US6331874</a></td><td class="patent-data-table-td patent-date-value">Jun 29, 1999</td><td class="patent-data-table-td patent-date-value">Dec 18, 2001</td><td class="patent-data-table-td ">Lsi Logic Corporation</td><td class="patent-data-table-td ">Motion compensated de-interlacing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6618439">US6618439</a></td><td class="patent-data-table-td patent-date-value">Jul 6, 1999</td><td class="patent-data-table-td patent-date-value">Sep 9, 2003</td><td class="patent-data-table-td ">Industrial Technology Research Institute</td><td class="patent-data-table-td ">Fast motion-compensated video frame interpolator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6621864">US6621864</a></td><td class="patent-data-table-td patent-date-value">Oct 7, 1998</td><td class="patent-data-table-td patent-date-value">Sep 16, 2003</td><td class="patent-data-table-td ">National Semiconductor Corporation</td><td class="patent-data-table-td ">Motion vector based frame insertion process for increasing the frame rate of moving images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6650624">US6650624</a></td><td class="patent-data-table-td patent-date-value">May 19, 2000</td><td class="patent-data-table-td patent-date-value">Nov 18, 2003</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Cable modem apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6731818">US6731818</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 1999</td><td class="patent-data-table-td patent-date-value">May 4, 2004</td><td class="patent-data-table-td ">Realnetworks, Inc.</td><td class="patent-data-table-td ">System and method for generating video frames</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6735338">US6735338</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 1999</td><td class="patent-data-table-td patent-date-value">May 11, 2004</td><td class="patent-data-table-td ">Realnetworks, Inc.</td><td class="patent-data-table-td ">System and method for generating video frames and detecting text</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6753865">US6753865</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 1999</td><td class="patent-data-table-td patent-date-value">Jun 22, 2004</td><td class="patent-data-table-td ">Realnetworks, Inc.</td><td class="patent-data-table-td ">System and method for generating video frames and post filtering</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6760378">US6760378</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 1999</td><td class="patent-data-table-td patent-date-value">Jul 6, 2004</td><td class="patent-data-table-td ">Realnetworks, Inc.</td><td class="patent-data-table-td ">System and method for generating video frames and correcting motion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6961314">US6961314</a></td><td class="patent-data-table-td patent-date-value">Aug 25, 2000</td><td class="patent-data-table-td patent-date-value">Nov 1, 2005</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Burst receiver for cable modem system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6987866">US6987866</a></td><td class="patent-data-table-td patent-date-value">Jun 5, 2001</td><td class="patent-data-table-td patent-date-value">Jan 17, 2006</td><td class="patent-data-table-td ">Micron Technology, Inc.</td><td class="patent-data-table-td ">Multi-modal motion estimation for video sequences</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7103065">US7103065</a></td><td class="patent-data-table-td patent-date-value">Nov 16, 2000</td><td class="patent-data-table-td patent-date-value">Sep 5, 2006</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Data packet fragmentation in a cable modem system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7120123">US7120123</a></td><td class="patent-data-table-td patent-date-value">Nov 9, 2000</td><td class="patent-data-table-td patent-date-value">Oct 10, 2006</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Pre-equalization technique for upstream communication between cable modem and headend</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7139283">US7139283</a></td><td class="patent-data-table-td patent-date-value">Feb 9, 2001</td><td class="patent-data-table-td patent-date-value">Nov 21, 2006</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Robust techniques for optimal upstream communication between cable modem subscribers and a headend</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7342963">US7342963</a></td><td class="patent-data-table-td patent-date-value">Aug 7, 2001</td><td class="patent-data-table-td patent-date-value">Mar 11, 2008</td><td class="patent-data-table-td ">France Telecom</td><td class="patent-data-table-td ">Method for calculating an image interpolated between two images of a video sequence</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7412114">US7412114</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 23, 2004</td><td class="patent-data-table-td patent-date-value">Aug 12, 2008</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Method of generating an interpolation image, an interpolation image generating apparatus, and an image display system using the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7512154">US7512154</a></td><td class="patent-data-table-td patent-date-value">Oct 11, 2006</td><td class="patent-data-table-td patent-date-value">Mar 31, 2009</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Data packet fragmentation in a wireless communication system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7512179">US7512179</a></td><td class="patent-data-table-td patent-date-value">Jan 25, 2002</td><td class="patent-data-table-td patent-date-value">Mar 31, 2009</td><td class="patent-data-table-td ">France Telecom</td><td class="patent-data-table-td ">Image coding and decoding method, corresponding devices and applications</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7519082">US7519082</a></td><td class="patent-data-table-td patent-date-value">Dec 2, 2005</td><td class="patent-data-table-td patent-date-value">Apr 14, 2009</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Data packet fragmentation in a wireless communication system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7564902">US7564902</a></td><td class="patent-data-table-td patent-date-value">Nov 19, 2003</td><td class="patent-data-table-td patent-date-value">Jul 21, 2009</td><td class="patent-data-table-td ">Panasonic Corporation</td><td class="patent-data-table-td ">Device, method and program for generating interpolation frame</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7620254">US7620254</a></td><td class="patent-data-table-td patent-date-value">Feb 10, 2004</td><td class="patent-data-table-td patent-date-value">Nov 17, 2009</td><td class="patent-data-table-td ">Trident Microsystems (Far East) Ltd.</td><td class="patent-data-table-td ">Apparatus and method for motion-vector-aided interpolation of a pixel of an intermediate image of an image sequence</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7706444">US7706444</a></td><td class="patent-data-table-td patent-date-value">May 18, 2004</td><td class="patent-data-table-td patent-date-value">Apr 27, 2010</td><td class="patent-data-table-td ">Realnetworks, Inc.</td><td class="patent-data-table-td ">System and method for intracoding video data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7720152">US7720152</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 2003</td><td class="patent-data-table-td patent-date-value">May 18, 2010</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Implicit weighting of reference pictures in a video decoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7738562">US7738562</a></td><td class="patent-data-table-td patent-date-value">May 4, 2004</td><td class="patent-data-table-td patent-date-value">Jun 15, 2010</td><td class="patent-data-table-td ">Realnetworks, Inc.</td><td class="patent-data-table-td ">System and method for generating video frames and correcting motion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7801217">US7801217</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 2003</td><td class="patent-data-table-td patent-date-value">Sep 21, 2010</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Implicit weighting of reference pictures in a video encoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7821954">US7821954</a></td><td class="patent-data-table-td patent-date-value">Oct 23, 2006</td><td class="patent-data-table-td patent-date-value">Oct 26, 2010</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Methods to compensate for noise in a wireless communication system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7843847">US7843847</a></td><td class="patent-data-table-td patent-date-value">Oct 23, 2006</td><td class="patent-data-table-td patent-date-value">Nov 30, 2010</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Compensating for noise in a wireless communication system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7899034">US7899034</a></td><td class="patent-data-table-td patent-date-value">Feb 2, 2007</td><td class="patent-data-table-td patent-date-value">Mar 1, 2011</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Methods for the synchronization of multiple base stations in a wireless communication system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8005072">US8005072</a></td><td class="patent-data-table-td patent-date-value">Mar 30, 2006</td><td class="patent-data-table-td patent-date-value">Aug 23, 2011</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Synchronization of multiple base stations in a wireless communication system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8189670">US8189670</a></td><td class="patent-data-table-td patent-date-value">Jun 11, 2009</td><td class="patent-data-table-td patent-date-value">May 29, 2012</td><td class="patent-data-table-td ">Panasonic Corporation</td><td class="patent-data-table-td ">Device, method and program for generating interpolation frame</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8755440">US8755440</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 16, 2006</td><td class="patent-data-table-td patent-date-value">Jun 17, 2014</td><td class="patent-data-table-td ">Qualcomm Incorporated</td><td class="patent-data-table-td ">Interpolation techniques in wavelet transform multimedia coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE34965">USRE34965</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 14, 1993</td><td class="patent-data-table-td patent-date-value">Jun 13, 1995</td><td class="patent-data-table-td ">Victor Company Of Japan Limited</td><td class="patent-data-table-td ">Inter-frame predictive encoding system with encoded and transmitted prediction error</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE35158">USRE35158</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 28, 1992</td><td class="patent-data-table-td patent-date-value">Feb 20, 1996</td><td class="patent-data-table-td ">Victor Company Of Japan Limited</td><td class="patent-data-table-td ">Apparatus for adaptive inter-frame predictive encoding of video signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE35910">USRE35910</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 12, 1994</td><td class="patent-data-table-td patent-date-value">Sep 29, 1998</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Moving image signal encoding apparatus and decoding apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE36999">USRE36999</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 12, 1994</td><td class="patent-data-table-td patent-date-value">Dec 26, 2000</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Video signal coding method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/DE3523424C1?cl=en">DE3523424C1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 29, 1985</td><td class="patent-data-table-td patent-date-value">Oct 30, 1986</td><td class="patent-data-table-td ">Deutsche Forsch Luft Raumfahrt</td><td class="patent-data-table-td ">Verfahren zur UEbertragung und Wiedergabe von Videoszenen,insbesondere Luftbildszenen,mit reduzierter Bildfolgefrequenz bei Relativbewegung der aufgenommenen Szene gegenueber dem Aufnahmesensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0154125A2?cl=en">EP0154125A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 18, 1985</td><td class="patent-data-table-td patent-date-value">Sep 11, 1985</td><td class="patent-data-table-td ">ANT Nachrichtentechnik GmbH</td><td class="patent-data-table-td ">Method for movement-adaptive interpolation of a television picture sequence and apparatus and applications therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0154126A2?cl=en">EP0154126A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 18, 1985</td><td class="patent-data-table-td patent-date-value">Sep 11, 1985</td><td class="patent-data-table-td ">ANT Nachrichtentechnik GmbH</td><td class="patent-data-table-td ">Method of determining the displacement in a picture sequence, and arrangement and applications therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0160547A2?cl=en">EP0160547A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 26, 1985</td><td class="patent-data-table-td patent-date-value">Nov 6, 1985</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Motion-adaptive interpolation method for video signal and device for implementing the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0213683A2?cl=en">EP0213683A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 1, 1986</td><td class="patent-data-table-td patent-date-value">Mar 11, 1987</td><td class="patent-data-table-td ">DST Deutsche System-Technik GmbH</td><td class="patent-data-table-td ">Method and device for producing intermediate picture signals from reference picture signals at a reduced frame rate</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0228820A2?cl=en">EP0228820A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 28, 1986</td><td class="patent-data-table-td patent-date-value">Jul 15, 1987</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Method and apparatus of transmitting and decoding video data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0236519A1?cl=en">EP0236519A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 8, 1986</td><td class="patent-data-table-td patent-date-value">Sep 16, 1987</td><td class="patent-data-table-td ">ANT Nachrichtentechnik GmbH</td><td class="patent-data-table-td ">Motion compensating field interpolation method using a hierarchically structured displacement estimator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0340843A1?cl=en">EP0340843A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 24, 1989</td><td class="patent-data-table-td patent-date-value">Nov 8, 1989</td><td class="patent-data-table-td ">Laboratoires D&#39;electronique Philips S.A.S.</td><td class="patent-data-table-td ">System for transmitting pictures using a transmission channel with a relatively narrow bandwidth</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0379217A2?cl=en">EP0379217A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 19, 1990</td><td class="patent-data-table-td patent-date-value">Jul 25, 1990</td><td class="patent-data-table-td ">Victor Company Of Japan, Limited</td><td class="patent-data-table-td ">Inter-frame predictive encoding system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0390660A1?cl=en">EP0390660A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 23, 1990</td><td class="patent-data-table-td patent-date-value">Oct 3, 1990</td><td class="patent-data-table-td ">THOMSON multimedia</td><td class="patent-data-table-td ">Method and apparatus for the temporal interpolation of pictures, with corrected movement compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0420627A2?cl=en">EP0420627A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 27, 1990</td><td class="patent-data-table-td patent-date-value">Apr 3, 1991</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Video signal coding method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0441168A2?cl=en">EP0441168A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 22, 1991</td><td class="patent-data-table-td patent-date-value">Aug 14, 1991</td><td class="patent-data-table-td ">ALCATEL ITALIA Società per Azioni</td><td class="patent-data-table-td ">System, packet structuring and device for processing output information from a signal encoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0447068A2?cl=en">EP0447068A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 28, 1991</td><td class="patent-data-table-td patent-date-value">Sep 18, 1991</td><td class="patent-data-table-td ">Victor Company Of Japan, Ltd.</td><td class="patent-data-table-td ">Motion image data compression system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0572046A1?cl=en">EP0572046A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 19, 1990</td><td class="patent-data-table-td patent-date-value">Dec 1, 1993</td><td class="patent-data-table-td ">Victor Company Of Japan, Limited</td><td class="patent-data-table-td ">Decoding system for decoding video signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0584840A2?cl=en">EP0584840A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 27, 1990</td><td class="patent-data-table-td patent-date-value">Mar 2, 1994</td><td class="patent-data-table-td ">Victor Company Of Japan, Limited</td><td class="patent-data-table-td ">Apparatus for adaptive interframe predictive decoding of a video signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0593099A1?cl=en">EP0593099A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 27, 1990</td><td class="patent-data-table-td patent-date-value">Apr 20, 1994</td><td class="patent-data-table-td ">Victor Company Of Japan, Limited</td><td class="patent-data-table-td ">Apparatus for inter-frame predictive encoding of video signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0650297A2?cl=en">EP0650297A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 24, 1989</td><td class="patent-data-table-td patent-date-value">Apr 26, 1995</td><td class="patent-data-table-td ">Laboratoires D&#39;electronique Philips S.A.S.</td><td class="patent-data-table-td ">System for transmitting pictures using a transmission channel with a relatively narrow bandwidth</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0773688A2?cl=en">EP0773688A2</a></td><td class="patent-data-table-td patent-date-value">Nov 12, 1996</td><td class="patent-data-table-td patent-date-value">May 14, 1997</td><td class="patent-data-table-td ">Tektronix, Inc.</td><td class="patent-data-table-td ">Method for motion estimation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1006732A2?cl=en">EP1006732A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 8, 1999</td><td class="patent-data-table-td patent-date-value">Jun 7, 2000</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Motion compensated interpolation for digital video signal processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1397003A1?cl=en">EP1397003A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 1, 2003</td><td class="patent-data-table-td patent-date-value">Mar 10, 2004</td><td class="patent-data-table-td ">Micronas GmbH</td><td class="patent-data-table-td ">Motion compensated frame interpolation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1422928A2?cl=en">EP1422928A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 18, 2003</td><td class="patent-data-table-td patent-date-value">May 26, 2004</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Motion compensated interpolation of digital video signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1987004033A1?cl=en">WO1987004033A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 23, 1986</td><td class="patent-data-table-td patent-date-value">Jul 2, 1987</td><td class="patent-data-table-td ">British Broadcasting Corp</td><td class="patent-data-table-td ">Method of coding a video signal for transmission in a restricted bandwidth</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1987005179A1?cl=en">WO1987005179A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 17, 1987</td><td class="patent-data-table-td patent-date-value">Aug 27, 1987</td><td class="patent-data-table-td ">Indep Broadcasting Authority</td><td class="patent-data-table-td ">Apparatus for encoding a television signal to be transmitted</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1995020863A1?cl=en">WO1995020863A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 20, 1995</td><td class="patent-data-table-td patent-date-value">Aug 3, 1995</td><td class="patent-data-table-td ">British Tech Group Usa</td><td class="patent-data-table-td ">Method and apparatus for video data compression using temporally adaptive motion interpolation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1996031069A1?cl=en">WO1996031069A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 19, 1996</td><td class="patent-data-table-td patent-date-value">Oct 3, 1996</td><td class="patent-data-table-td ">Nat Semiconductor Corp</td><td class="patent-data-table-td ">Motion vector based frame insertion process for increasing the frame rate of moving images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2001001696A1?cl=en">WO2001001696A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 30, 2000</td><td class="patent-data-table-td patent-date-value">Jan 4, 2001</td><td class="patent-data-table-td ">Realnetworks Inc</td><td class="patent-data-table-td ">System and method for generating video frames</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2002017645A1?cl=en">WO2002017645A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 7, 2001</td><td class="patent-data-table-td patent-date-value">Feb 28, 2002</td><td class="patent-data-table-td ">France Telecom</td><td class="patent-data-table-td ">Method for calculating an image interpolated between two images of a video sequence</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2002060184A1?cl=en">WO2002060184A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 25, 2002</td><td class="patent-data-table-td patent-date-value">Aug 1, 2002</td><td class="patent-data-table-td ">France Telecom</td><td class="patent-data-table-td ">Image coding and decoding method, corresponding devices and applications</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=iDMeBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S416100">348/416.1</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=iDMeBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07250">375/E07.25</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=iDMeBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007460000">H04N7/46</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=iDMeBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00721">H04N19/00721</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N7/46E</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Mar 10, 2009</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIM 13 IS NOW DISCLAIMED. CLAIMS 1-12 AND 14-24 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 23, 2007</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20070806</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 25, 2007</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20070712</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 30, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">MULTIMEDIA PATENT TRUST C/O, DELAWARE</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:LUCENT TECHNOLOGIES INC.;REEL/FRAME:018573/0978</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20061128</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 13, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">LUCENT TECHNOLOGIES INC., NEW JERSEY</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">TERMINATION AND RELEASE OF SECURITY INTEREST IN PATENT RIGHTS;ASSIGNOR:JPMORGAN CHASE BANK, N.A. (F/K/A THE CHASE MANHATTAN BANK), AS ADMINISTRATIVE AGENT;REEL/FRAME:018505/0493</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20061026</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 5, 2001</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">THE CHASE MANHATTAN BANK, AS COLLATERAL AGENT, TEX</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CONDITIONAL ASSIGNMENT OF AND SECURITY INTEREST IN PATENT RIGHTS;ASSIGNOR:LUCENT TECHNOLOGIES INC. (DE CORPORATION);REEL/FRAME:011722/0048</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20010222</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">THE CHASE MANHATTAN BANK, AS COLLATERAL AGENT P.O.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 28, 2001</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">LUCENT TECHNOLOGIES, INC., NEW JERSEY</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AT&amp;T CORP.;REEL/FRAME:011658/0857</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19960329</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">LUCENT TECHNOLOGIES, INC. 600 MOUNTAIN AVENUE, P.O</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AT&amp;T CORP. /AR;REEL/FRAME:011658/0857</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 26, 1994</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 15, 1990</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 12, 1986</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 13, 1981</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">BELL TELEPHONE LABORATORIES,INCORPORATED, 600 MOUN</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST.;ASSIGNORS:NETRAVALI ARUN N.;ROBBINS JOHN D.;REEL/FRAME:003879/0319;SIGNING DATES FROM 19810402 TO 19810403</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">BELL TELEPHONE LABORATORIES, INCORPORATED,  A CORP</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:NETRAVALI ARUN N.;ROBBINS JOHN D.;SIGNING DATES FROM 19810402 TO 19810403;REEL/FRAME:003879/0319</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0BrCE4jllPOUk-hkPP4xGmWxF96g\u0026id=iDMeBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U2GEydDI7ku8cVX61xsVTft4u9F1g\u0026id=iDMeBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U0BdoxXYVHixodFxxhsl4U8SqR9mg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Video_signal_interpolation_using_motion.pdf?id=iDMeBAABERAJ\u0026output=pdf\u0026sig=ACfU3U0z4sIqOgO5bEu9kF37kRPzAZhOWQ"},"sample_url":"http://www.google.com/patents/reader?id=iDMeBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>