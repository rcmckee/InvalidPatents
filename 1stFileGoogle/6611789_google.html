<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6611789 - Monitoring activity of a user in locomotion on foot - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Monitoring activity of a user in locomotion on foot"><meta name="DC.contributor" content="Jesse Darley" scheme="inventor"><meta name="DC.contributor" content="Personal Electric Devices, Inc." scheme="assignee"><meta name="DC.date" content="2000-8-21" scheme="dateSubmitted"><meta name="DC.description" content="In one embodiment, a method includes a step of: (a) with at least one device supported by a user while the user is in locomotion on foot on a surface, determining an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user. In another embodiment, a method includes steps of: (a) with at least one sensor supported by a user, monitoring movement of the user while the user is in locomotion on foot; and (b) determining a cadence of the user based upon an output of the at least one sensor. In another embodiment, a method includes steps of: (a) with at least one sensor supported by a user while the user is in locomotion on foot, monitoring movement of the user while the user is in locomotion on foot; and (b) determining a stride length of the user during at least one footstep taken by the user based upon an output of the at least one sensor."><meta name="DC.date" content="2003-8-26" scheme="issued"><meta name="DC.relation" content="US:3840726" scheme="references"><meta name="DC.relation" content="US:3972038" scheme="references"><meta name="DC.relation" content="US:3974491" scheme="references"><meta name="DC.relation" content="US:4371945" scheme="references"><meta name="DC.relation" content="US:4408183" scheme="references"><meta name="DC.relation" content="US:4409992" scheme="references"><meta name="DC.relation" content="US:4499394" scheme="references"><meta name="DC.relation" content="US:4578769" scheme="references"><meta name="DC.relation" content="US:4649552" scheme="references"><meta name="DC.relation" content="US:4651446" scheme="references"><meta name="DC.relation" content="US:4745564" scheme="references"><meta name="DC.relation" content="US:4757714" scheme="references"><meta name="DC.relation" content="US:4763287" scheme="references"><meta name="DC.relation" content="US:4771394" scheme="references"><meta name="DC.relation" content="US:4774679" scheme="references"><meta name="DC.relation" content="US:4814661" scheme="references"><meta name="DC.relation" content="US:4830021" scheme="references"><meta name="DC.relation" content="US:4855942" scheme="references"><meta name="DC.relation" content="US:4956628" scheme="references"><meta name="DC.relation" content="US:4962469" scheme="references"><meta name="DC.relation" content="US:5033013" scheme="references"><meta name="DC.relation" content="US:5186062" scheme="references"><meta name="DC.relation" content="US:5269081" scheme="references"><meta name="DC.relation" content="US:5285586" scheme="references"><meta name="DC.relation" content="US:5323650" scheme="references"><meta name="DC.relation" content="US:5343445" scheme="references"><meta name="DC.relation" content="US:5357696" scheme="references"><meta name="DC.relation" content="US:5361778" scheme="references"><meta name="DC.relation" content="US:5422628" scheme="references"><meta name="DC.relation" content="US:5437289" scheme="references"><meta name="DC.relation" content="US:5452269" scheme="references"><meta name="DC.relation" content="US:5485402" scheme="references"><meta name="DC.relation" content="US:5524637" scheme="references"><meta name="DC.relation" content="US:5526290" scheme="references"><meta name="DC.relation" content="US:5541860" scheme="references"><meta name="DC.relation" content="US:5583776" scheme="references"><meta name="DC.relation" content="US:5623944" scheme="references"><meta name="DC.relation" content="US:5636146" scheme="references"><meta name="DC.relation" content="US:5720200" scheme="references"><meta name="DC.relation" content="US:5724265" scheme="references"><meta name="DC.relation" content="US:5897457" scheme="references"><meta name="DC.relation" content="US:5899963" scheme="references"><meta name="DC.relation" content="US:5925001" scheme="references"><meta name="DC.relation" content="US:5955667" scheme="references"><meta name="DC.relation" content="US:5963891" scheme="references"><meta name="DC.relation" content="US:5976083" scheme="references"><meta name="DC.relation" content="US:5989200" scheme="references"><meta name="DC.relation" content="US:6018705" scheme="references"><meta name="DC.relation" content="US:6038935" scheme="references"><meta name="DC.relation" content="US:6042549" scheme="references"><meta name="DC.relation" content="US:6052654" scheme="references"><meta name="DC.relation" content="US:6305221" scheme="references"><meta name="DC.relation" content="US:6356856" scheme="references"><meta name="citation_patent_number" content="US:6611789"><meta name="citation_patent_application_number" content="US:09/642,865"><link rel="canonical" href="http://www.google.com/patents/US6611789"/><meta property="og:url" content="http://www.google.com/patents/US6611789"/><meta name="title" content="Patent US6611789 - Monitoring activity of a user in locomotion on foot"/><meta name="description" content="In one embodiment, a method includes a step of: (a) with at least one device supported by a user while the user is in locomotion on foot on a surface, determining an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user. In another embodiment, a method includes steps of: (a) with at least one sensor supported by a user, monitoring movement of the user while the user is in locomotion on foot; and (b) determining a cadence of the user based upon an output of the at least one sensor. In another embodiment, a method includes steps of: (a) with at least one sensor supported by a user while the user is in locomotion on foot, monitoring movement of the user while the user is in locomotion on foot; and (b) determining a stride length of the user during at least one footstep taken by the user based upon an output of the at least one sensor."/><meta property="og:title" content="Patent US6611789 - Monitoring activity of a user in locomotion on foot"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("fpTtU9vhBaO6sQSznIGwCg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("IRL"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("fpTtU9vhBaO6sQSznIGwCg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("IRL"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6611789?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6611789"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=7f1hBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6611789&amp;usg=AFQjCNEYnW9dtk6Rh7vrpwheaEPi_0vjVg" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6611789.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6611789.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6611789" style="display:none"><span itemprop="description">In one embodiment, a method includes a step of: (a) with at least one device supported by a user while the user is in locomotion on foot on a surface, determining an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user. In another embodiment,...</span><span itemprop="url">http://www.google.com/patents/US6611789?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6611789 - Monitoring activity of a user in locomotion on foot</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6611789 - Monitoring activity of a user in locomotion on foot" title="Patent US6611789 - Monitoring activity of a user in locomotion on foot"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6611789 B1</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/642,865</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Aug 26, 2003</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Aug 21, 2000</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Oct 2, 1997</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09642865, </span><span class="patent-bibdata-value">642865, </span><span class="patent-bibdata-value">US 6611789 B1, </span><span class="patent-bibdata-value">US 6611789B1, </span><span class="patent-bibdata-value">US-B1-6611789, </span><span class="patent-bibdata-value">US6611789 B1, </span><span class="patent-bibdata-value">US6611789B1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jesse+Darley%22">Jesse Darley</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Personal+Electric+Devices,+Inc.%22">Personal Electric Devices, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6611789.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6611789.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6611789.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (53),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (94),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (17),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (8)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6611789&usg=AFQjCNHTEJ6zPWS6DHfmmrPiAQrLy4dT6A">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6611789&usg=AFQjCNFjbV_bAKUt-AIrsCD_VLFyDicchA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6611789B1%26KC%3DB1%26FT%3DD&usg=AFQjCNH38skmY2nFUyn16YqmWejUNGGO4Q">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55148603" lang="EN" load-source="patent-office">Monitoring activity of a user in locomotion on foot</invention-title></span><br><span class="patent-number">US 6611789 B1</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50541759" lang="EN" load-source="patent-office"> <div class="abstract">In one embodiment, a method includes a step of: (a) with at least one device supported by a user while the user is in locomotion on foot on a surface, determining an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user. In another embodiment, a method includes steps of: (a) with at least one sensor supported by a user, monitoring movement of the user while the user is in locomotion on foot; and (b) determining a cadence of the user based upon an output of the at least one sensor. In another embodiment, a method includes steps of: (a) with at least one sensor supported by a user while the user is in locomotion on foot, monitoring movement of the user while the user is in locomotion on foot; and (b) determining a stride length of the user during at least one footstep taken by the user based upon an output of the at least one sensor.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(43)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00014.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00014.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00015.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00015.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00016.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00016.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00017.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00017.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00018.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00018.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00019.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00019.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00020.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00020.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00021.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00021.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00022.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00022.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00023.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00023.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00024.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00024.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00025.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00025.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00026.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00026.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00027.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00027.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00028.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00028.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00029.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00029.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00030.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00030.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00031.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00031.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00032.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00032.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00033.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00033.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00034.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00034.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00035.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00035.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00036.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00036.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00037.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00037.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00038.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00038.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00039.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00039.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00040.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00040.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00041.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00041.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-D00042.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6611789B1/US06611789-20030826-D00042.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(78)</span></span></div><div class="patent-text"><div mxw-id="PCLM8536525" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is: </claim-statement> <div class="claim"> <div num="1" id="US-6611789-B1-CLM-00001" class="claim">
      <div class="claim-text">1. A method, comprising steps of:</div>
      <div class="claim-text">(a) with at least one device supported by a user while the user is in locomotion on foot, determining at least one foot contact time of the user for at least one footstep taken by the user; </div>
      <div class="claim-text">(b) comparing a variable having the at least one determined foot contact time as a factor therein with a threshold value; and </div>
      <div class="claim-text">(c1) if the variable is one of greater than or less than the threshold value, determining that the user is walking; and </div>
      <div class="claim-text">(c2) if the variable is the other of greater than or less than the threshold value, determining that the user is running. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6611789-B1-CLM-00002" class="claim">
      <div class="claim-text">2. The method of <claim-ref idref="US-6611789-B1-CLM-00001">claim 1</claim-ref>, further comprising steps of:</div>
      <div class="claim-text">(d1) if the user is walking, calculating at least one of a speed and a pace of the user using a first equation in which the at least one determined foot contact time is a factor; and </div>
      <div class="claim-text">(d2) if the user is running, calculating the at least one of the speed and pace of the user using a second equation which is different than the first equation and in which the at least one determined foot contact time is a factor. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6611789-B1-CLM-00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="US-6611789-B1-CLM-00001">claim 1</claim-ref>, wherein the at least one determined foot contact time is the only variable factor in the variable.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6611789-B1-CLM-00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="US-6611789-B1-CLM-00001">claim 1</claim-ref>, wherein:</div>
      <div class="claim-text">the method further includes a step of (d) determining a step time of the user in locomotion; and </div>
      <div class="claim-text">the determined step time is a factor in the variable. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6611789-B1-CLM-00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="US-6611789-B1-CLM-00004">claim 4</claim-ref>, wherein:</div>
      <div class="claim-text">the step (c1) includes a step of determining that the user if walking if the at least one determined foot contact time is greater than one half of the determined step time; and </div>
      <div class="claim-text">the step (c2) includes a step of determining that the user is running if the at least one determined foot contact time is less than one half of the determined step time. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6611789-B1-CLM-00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="US-6611789-B1-CLM-00001">claim 1</claim-ref>, wherein:</div>
      <div class="claim-text">the method further includes a step of (d) determining a foot air time of the user in locomotion; and </div>
      <div class="claim-text">the determined foot air time is a factor in the variable. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" id="US-6611789-B1-CLM-00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="US-6611789-B1-CLM-00006">claim 6</claim-ref>, wherein:</div>
      <div class="claim-text">the step (c1) includes a step of determining that the user if walking if the at least one determined foot contact time is greater than the determined foot air time; and </div>
      <div class="claim-text">the step (c2) includes a step of determining that the user is running if the at least one determined foot contact time is less than the determined foot air time. </div>
    </div>
    </div> <div class="claim"> <div num="8" id="US-6611789-B1-CLM-00008" class="claim">
      <div class="claim-text">8. A method, comprising steps of:</div>
      <div class="claim-text">(a) determining at least one foot contact time of a user for at least one footstep taken by the user; </div>
      <div class="claim-text">(b) comparing the at least one determined foot contact time with a threshold value; and </div>
      <div class="claim-text">(c1) if the foot contact time is less than the threshold value, determining that the user is running; and </div>
      <div class="claim-text">(c2) if the foot contact time is greater than the threshold value, determining that the user is walking. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" id="US-6611789-B1-CLM-00009" class="claim">
      <div class="claim-text">9. The method of <claim-ref idref="US-6611789-B1-CLM-00008">claim 8</claim-ref>, further comprising steps of:</div>
      <div class="claim-text">(d1) if the user is walking, calculating at least one of a speed and a pace of the user using a first equation in which the at least one determined foot contact time is a factor; and </div>
      <div class="claim-text">(d2) if the user is running, calculating the at least one of the speed and pace of the user using a second equation which is different than the first equation and in which the at least one determined foot contact time is a factor. </div>
    </div>
    </div> <div class="claim"> <div num="10" id="US-6611789-B1-CLM-00010" class="claim">
      <div class="claim-text">10. A system, comprising:</div>
      <div class="claim-text">at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one foot contact time of the user for at least one footstep taken by the user, and compares a variable having the at least one determined foot contact time as a factor therein with a threshold value; wherein, if the variable is one of greater than or less than the threshold value, the at least one processor determines that the user is walking, and, if the variable is the other of greater than or less than the threshold value, the at least one processor determines that the user is running. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" id="US-6611789-B1-CLM-00011" class="claim">
      <div class="claim-text">11. The system of <claim-ref idref="US-6611789-B1-CLM-00010">claim 10</claim-ref>, wherein, if the user is walking, the at least one processor calculates at least one of a speed and a pace of the user using a first equation in which the at least one determined foot contact time is a factor, and, if the user is running, the at least one processor calculates the at least one of the speed and pace of the user using a second equation which is different than the first equation and in which the at least one determined foot contact time is a factor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" id="US-6611789-B1-CLM-00012" class="claim">
      <div class="claim-text">12. The system of <claim-ref idref="US-6611789-B1-CLM-00010">claim 10</claim-ref>, wherein the at least one determined foot contact time is the only variable factor in the variable.</div>
    </div>
    </div> <div class="claim"> <div num="13" id="US-6611789-B1-CLM-00013" class="claim">
      <div class="claim-text">13. A system, comprising:</div>
      <div class="claim-text">at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one foot contact time of the user for at least one footstep taken by the user, and compares the at least one determined foot contact time with a threshold value; wherein, if the foot contact time is less than the threshold value, the at least one processor determines that the user is running, and, if the foot contact time is greater than the threshold value, the at least one processor determines that the user is walking. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" id="US-6611789-B1-CLM-00014" class="claim">
      <div class="claim-text">14. The system of <claim-ref idref="US-6611789-B1-CLM-00013">claim 13</claim-ref>, wherein, if the user is walking, the at least one processor calculates at least one of a speed and a pace of the user using a first equation in which the at least one determined foot contact time is a factor, and, if the user is running, the at least one processor calculates the at least one of the speed and pace of the user using a second equation which is different than the first equation and in which the at least one determined foot contact time is a factor.</div>
    </div>
    </div> <div class="claim"> <div num="15" id="US-6611789-B1-CLM-00015" class="claim">
      <div class="claim-text">15. A system, comprising:</div>
      <div class="claim-text">at least one sensor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one foot contact time of the user for at least one footstep taken by the user; </div>
      <div class="claim-text">means, adapted to be supported by the user while the user is in locomotion on foot, for comparing a variable having the at least one determined foot contact time as a factor therein with a threshold value; </div>
      <div class="claim-text">means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is walking if the variable is one of greater than or less than the threshold value; and </div>
      <div class="claim-text">means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is running if the variable is the other of greater than or less than the threshold value. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" id="US-6611789-B1-CLM-00016" class="claim">
      <div class="claim-text">16. The system of <claim-ref idref="US-6611789-B1-CLM-00015">claim 15</claim-ref>, wherein the at least one sensor does not require compression forces thereon to determine the foot contact time of the user.</div>
    </div>
    </div> <div class="claim"> <div num="17" id="US-6611789-B1-CLM-00017" class="claim">
      <div class="claim-text">17. A system, comprising:</div>
      <div class="claim-text">at least one sensor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one foot contact time of the user for at least one footstep taken by the user; </div>
      <div class="claim-text">means, adapted to be supported by the user while the user is in locomotion on foot, for comparing the at least one determined foot contact time with a threshold value; </div>
      <div class="claim-text">means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is running if the foot contact time is less than the threshold value; and </div>
      <div class="claim-text">means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is walking if the foot contact time is greater than the threshold value. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" id="US-6611789-B1-CLM-00018" class="claim">
      <div class="claim-text">18. The system of <claim-ref idref="US-6611789-B1-CLM-00017">claim 17</claim-ref>, wherein the at least one sensor does not require compression forces thereon to determine the foot contact time of the user.</div>
    </div>
    </div> <div class="claim"> <div num="19" id="US-6611789-B1-CLM-00019" class="claim">
      <div class="claim-text">19. A method, comprising a step of:</div>
      <div class="claim-text">(a) with at least one device supported by a user while the user is in locomotion on foot on a surface, determining an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" id="US-6611789-B1-CLM-00020" class="claim">
      <div class="claim-text">20. The method of <claim-ref idref="US-6611789-B1-CLM-00019">claim 19</claim-ref>, wherein the step (a) includes determining an average amount of force exerted by the at least one foot of the user on the surface during the at least one footstep.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" id="US-6611789-B1-CLM-00021" class="claim">
      <div class="claim-text">21. The method of <claim-ref idref="US-6611789-B1-CLM-00019">claim 19</claim-ref>, wherein the step (a) includes steps of:</div>
      <div class="claim-text">(a1) monitoring movement of the at least one foot with at least one sensor; </div>
      <div class="claim-text">(a2) analyzing an output of the at least one sensor to determine at least one foot contact time of the user; and </div>
      <div class="claim-text">(a3) calculating the amount of force exerted by the at least one foot on the surface based upon the determined at least one foot contact time. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" id="US-6611789-B1-CLM-00022" class="claim">
      <div class="claim-text">22. The method of <claim-ref idref="US-6611789-B1-CLM-00021">claim 21</claim-ref>, wherein the at least one sensor does not require compression forces thereon to sense movement.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" id="US-6611789-B1-CLM-00023" class="claim">
      <div class="claim-text">23. The method of <claim-ref idref="US-6611789-B1-CLM-00022">claim 22</claim-ref>, wherein the at least one sensor includes an accelerometer.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" id="US-6611789-B1-CLM-00024" class="claim">
      <div class="claim-text">24. The method of <claim-ref idref="US-6611789-B1-CLM-00019">claim 19</claim-ref>, wherein the step (a) includes steps of:</div>
      <div class="claim-text">(a1) monitoring movement of the at least one foot with at least one sensor; </div>
      <div class="claim-text">(a2) analyzing an output of the at least one sensor to determine at least one step time of the user; and </div>
      <div class="claim-text">(a3) calculating the amount of force exerted by the at least one foot on the surface based upon the determined at least one step time. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" id="US-6611789-B1-CLM-00025" class="claim">
      <div class="claim-text">25. The method of <claim-ref idref="US-6611789-B1-CLM-00024">claim 24</claim-ref>, wherein the at least one sensor does not require compression forces thereon to sense movement.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" id="US-6611789-B1-CLM-00026" class="claim">
      <div class="claim-text">26. The method of <claim-ref idref="US-6611789-B1-CLM-00025">claim 25</claim-ref>, wherein the at least one sensor includes an accelerometer.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" id="US-6611789-B1-CLM-00027" class="claim">
      <div class="claim-text">27. The method of <claim-ref idref="US-6611789-B1-CLM-00021">claim 21</claim-ref>, wherein the step (a) further comprises the steps of:</div>
      <div class="claim-text">(a4) analyzing the output of the at least one sensor to determine at least one step time of the user; and </div>
      <div class="claim-text">(a5) calculating the amount of force exerted by the at least one foot on the surface based upon the determined at least one step time. </div>
    </div>
    </div> <div class="claim"> <div num="28" id="US-6611789-B1-CLM-00028" class="claim">
      <div class="claim-text">28. A system, comprising:</div>
      <div class="claim-text">at least one processor adapted to be supported by a user while the user is in locomotion on foot, on a surface, the at least one processor being configured to identify an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" id="US-6611789-B1-CLM-00029" class="claim">
      <div class="claim-text">29. The system of <claim-ref idref="US-6611789-B1-CLM-00028">claim 28</claim-ref>, wherein the at least one processor is configured to identify an average amount of force exerted by the at least one foot of the user on the surface during the at least one footstep.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" id="US-6611789-B1-CLM-00030" class="claim">
      <div class="claim-text">30. The system of <claim-ref idref="US-6611789-B1-CLM-00028">claim 28</claim-ref>, further comprising at least one sensor that monitors movement of the at least one foot, and wherein the at least one processor is configured to analyze an output of the at least one sensor to determine at least one foot contact time of the user, and to calculate the amount of force exerted by the at least one foot on the surface based upon the determined at least one foot contact time.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" id="US-6611789-B1-CLM-00031" class="claim">
      <div class="claim-text">31. The system of <claim-ref idref="US-6611789-B1-CLM-00030">claim 30</claim-ref>, wherein the at least one sensor does not require compression forces thereon to sense movement.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="32" id="US-6611789-B1-CLM-00032" class="claim">
      <div class="claim-text">32. The system of <claim-ref idref="US-6611789-B1-CLM-00031">claim 31</claim-ref>, wherein the at least one sensor includes an accelerometer.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" id="US-6611789-B1-CLM-00033" class="claim">
      <div class="claim-text">33. The system of <claim-ref idref="US-6611789-B1-CLM-00028">claim 28</claim-ref>, further comprising at least one sensor that monitors movement of the at least one foot, and wherein the at least one processor is configured to analyze an output of the at least one sensor to determine at least one step time of the user, and to calculate the amount of force exerted by the at least one foot on the surface based upon the determined at least one step time.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="34" id="US-6611789-B1-CLM-00034" class="claim">
      <div class="claim-text">34. The system of <claim-ref idref="US-6611789-B1-CLM-00033">claim 33</claim-ref>, wherein the at least one sensor does not require compression forces thereon to sense movement.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="35" id="US-6611789-B1-CLM-00035" class="claim">
      <div class="claim-text">35. The system of <claim-ref idref="US-6611789-B1-CLM-00034">claim 34</claim-ref>, wherein the at least one sensor includes an accelerometer.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="36" id="US-6611789-B1-CLM-00036" class="claim">
      <div class="claim-text">36. The system of <claim-ref idref="US-6611789-B1-CLM-00030">claim 30</claim-ref>, wherein the at least one processor is further configured to analyze the output of the at least one sensor to determine at least one step time of the user, and to calculate the amount of force exerted by the at least one foot on the surface based upon the determined at least one step time.</div>
    </div>
    </div> <div class="claim"> <div num="37" id="US-6611789-B1-CLM-00037" class="claim">
      <div class="claim-text">37. A system, comprising:</div>
      <div class="claim-text">at least one sensor adapted to be supported by a user while the user is in locomotion on foot on a surface; and </div>
      <div class="claim-text">means for identifying an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user based upon an output of the at least one sensor. </div>
    </div>
    </div> <div class="claim"> <div num="38" id="US-6611789-B1-CLM-00038" class="claim">
      <div class="claim-text">38. A method, comprising steps of:</div>
      <div class="claim-text">(a) with at least one sensor supported by a user, monitoring movement of the user while the user is in locomotion on foot; and </div>
      <div class="claim-text">(b) determining a cadence of the user for footsteps taken by the user based upon an output of the at least one sensor. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="39" id="US-6611789-B1-CLM-00039" class="claim">
      <div class="claim-text">39. The system of <claim-ref idref="US-6611789-B1-CLM-00038">claim 38</claim-ref>, wherein the at least one sensor does not require compression forces thereon to monitor movement of the user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="40" id="US-6611789-B1-CLM-00040" class="claim">
      <div class="claim-text">40. The method of <claim-ref idref="US-6611789-B1-CLM-00038">claim 38</claim-ref>, wherein:</div>
      <div class="claim-text">the step (a) includes monitoring movement of at least one foot of the user; and </div>
      <div class="claim-text">the step (b) includes steps of (b1) analyzing an output of the at least one sensor to determine at least one step time of the user, and (b2) determining the cadence of the user based upon the determined at least one step time. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="41" id="US-6611789-B1-CLM-00041" class="claim">
      <div class="claim-text">41. The method of <claim-ref idref="US-6611789-B1-CLM-00038">claim 38</claim-ref>, further comprising steps of:</div>
      <div class="claim-text">(c) based upon the output of the at least one sensor, determining values of the user's average cadence during one of respective time intervals and respective distance intervals; and </div>
      <div class="claim-text">(d) storing in memory information representing the determined values of the user's average cadence for the one of the respective time intervals and the respective distance intervals. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="42" id="US-6611789-B1-CLM-00042" class="claim">
      <div class="claim-text">42. The method of <claim-ref idref="US-6611789-B1-CLM-00038">claim 38</claim-ref>, further comprising steps of:</div>
      <div class="claim-text">(c) based upon the output of the at least one sensor, determining the user's average cadence during one of respective time intervals and respective distance intervals; and </div>
      <div class="claim-text">(d) displaying a representation of the determined values of the user's average cadence for the one of the respective time intervals and the respective distance intervals. </div>
    </div>
    </div> <div class="claim"> <div num="43" id="US-6611789-B1-CLM-00043" class="claim">
      <div class="claim-text">43. A method, comprising steps of:</div>
      <div class="claim-text">(a) with at least one but fewer than three sensors supported by a user while the user is in locomotion on foot, monitoring movement of the user while the user is in locomotion on foot; and </div>
      <div class="claim-text">(b) determining a stride length of the user for at least one footstep taken by the user based upon an output of the at least one sensor. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="44" id="US-6611789-B1-CLM-00044" class="claim">
      <div class="claim-text">44. The method of <claim-ref idref="US-6611789-B1-CLM-00043">claim 43</claim-ref>, wherein the at least one sensor does not require compression forces thereon to monitor movement of the user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="45" id="US-6611789-B1-CLM-00045" class="claim">
      <div class="claim-text">45. The method of <claim-ref idref="US-6611789-B1-CLM-00043">claim 43</claim-ref>, further comprising steps of:</div>
      <div class="claim-text">(c) based upon the output of the at least one sensor, determining a stride length of the user for each of a plurality of footsteps taken by the user; and </div>
      <div class="claim-text">(d) storing in memory information regarding the determined stride lengths for the plurality of footsteps. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="46" id="US-6611789-B1-CLM-00046" class="claim">
      <div class="claim-text">46. The method of <claim-ref idref="US-6611789-B1-CLM-00043">claim 43</claim-ref>, further comprising steps of:</div>
      <div class="claim-text">(c) based upon the output of the at least one sensor, determining a stride length of the user for each of a plurality of footsteps taken by the user; and </div>
      <div class="claim-text">(d) displaying information regarding the determined stride lengths for the plurality of footsteps. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="47" id="US-6611789-B1-CLM-00047" class="claim">
      <div class="claim-text">47. The method of <claim-ref idref="US-6611789-B1-CLM-00043">claim 43</claim-ref>, wherein:</div>
      <div class="claim-text">the step (a) includes monitoring movement of at least one foot of the user; and </div>
      <div class="claim-text">the step (b) includes steps of (b1) analyzing an output of the at least one sensor to determine at least one of a pace and a speed of the user during the at least one footstep, and (b2) determining the stride length of the user based upon the determined at least one of the pace and the speed of the user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="48" id="US-6611789-B1-CLM-00048" class="claim">
      <div class="claim-text">48. The method of <claim-ref idref="US-6611789-B1-CLM-00043">claim 43</claim-ref>, further comprising steps of:</div>
      <div class="claim-text">(c) based upon the output of the at least one sensor, determining values of the user's average stride length during one of respective time intervals and respective distance intervals; and </div>
      <div class="claim-text">(d) storing in memory information representing the determined values of the user's average stride length for the one of the respective time intervals and the respective distance intervals. </div>
    </div>
    </div> <div class="claim"> <div num="49" id="US-6611789-B1-CLM-00049" class="claim">
      <div class="claim-text">49. A method, comprising steps of:</div>
      <div class="claim-text">(a) with at least one sensor supported by a user while the user is in locomotion on foot, monitoring movement of the user while the user is in locomotion on foot; and </div>
      <div class="claim-text">(b) based upon the output of the at least one sensor, determining values of the user's average stride length during one of respective time intervals and respective distance intervals. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="50" id="US-6611789-B1-CLM-00050" class="claim">
      <div class="claim-text">50. The method of <claim-ref idref="US-6611789-B1-CLM-00043">claim 43</claim-ref>, wherein:</div>
      <div class="claim-text">the step (a) includes monitoring movement of at least one foot of the user; and </div>
      <div class="claim-text">the step (b) includes steps of (b1) analyzing an output of the at least one sensor to determine at least one foot contact time of the user during the at least one footstep; and (b2) determining the stride length of the user based upon the determined at least one foot contact time of the user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="51" id="US-6611789-B1-CLM-00051" class="claim">
      <div class="claim-text">51. The method of <claim-ref idref="US-6611789-B1-CLM-00043">claim 43</claim-ref>, wherein:</div>
      <div class="claim-text">the step (a) includes monitoring movement of at least one foot of the user; and </div>
      <div class="claim-text">the step (b) includes steps of (b1) analyzing an output of the at least one sensor to determine at least one step time of the user during the at least one footstep, and (b2) determining the stride length of the user based upon the determined at least one step time of the user. </div>
    </div>
    </div> <div class="claim"> <div num="52" id="US-6611789-B1-CLM-00052" class="claim">
      <div class="claim-text">52. A system, comprising:</div>
      <div class="claim-text">at least one sensor adapted to be supported by a user and to monitor movement of the user while the user is in locomotion on foot; and </div>
      <div class="claim-text">at least one processor that determines a cadence of the user for footsteps taken by the user based upon an output of the at least one sensor. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="53" id="US-6611789-B1-CLM-00053" class="claim">
      <div class="claim-text">53. The system of <claim-ref idref="US-6611789-B1-CLM-00052">claim 52</claim-ref>, wherein the at least one sensor does not require compression forces thereon to monitor movement of the user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="54" id="US-6611789-B1-CLM-00054" class="claim">
      <div class="claim-text">54. The system of <claim-ref idref="US-6611789-B1-CLM-00052">claim 52</claim-ref>, wherein:</div>
      <div class="claim-text">the at least one sensor is adapted to monitor movement of at least one foot of the user; and </div>
      <div class="claim-text">the at least one processor is configured to analyze an output of the at least one sensor to determine at least one step time of the user, and to determine the cadence of the user based upon the determined at least one step time. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="55" id="US-6611789-B1-CLM-00055" class="claim">
      <div class="claim-text">55. The system of <claim-ref idref="US-6611789-B1-CLM-00052">claim 52</claim-ref>, wherein the at least one processor is configured to, based upon the output of the at least one sensor, determine values of the user's average cadence during one of respective time intervals and respective distance intervals, and wherein the system further comprises a display that displays a representation of the determined values of the user's average cadence for the one of the respective time intervals and the respective distance intervals.</div>
    </div>
    </div> <div class="claim"> <div num="56" id="US-6611789-B1-CLM-00056" class="claim">
      <div class="claim-text">56. A system, comprising:</div>
      <div class="claim-text">at least one but fewer than three sensors adapted to be supported by a user and to monitor movement of the user while the user is in locomotion on foot; and </div>
      <div class="claim-text">at least one processor that, based upon an output of the at least one sensor, determines a stride length of the user for at least one footstep taken by the user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="57" id="US-6611789-B1-CLM-00057" class="claim">
      <div class="claim-text">57. The system of <claim-ref idref="US-6611789-B1-CLM-00056">claim 56</claim-ref>, wherein the at least one sensor does not require compression forces thereon to monitor movement of the user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="58" id="US-6611789-B1-CLM-00058" class="claim">
      <div class="claim-text">58. The system of <claim-ref idref="US-6611789-B1-CLM-00056">claim 56</claim-ref>, wherein the at least one processor is configured to, based upon the output of the at least one sensor, determine a stride length of the user for each of a plurality of footsteps taken by the user, and wherein the system further comprises a display that displays information regarding the determined stride lengths for the plurality of footsteps.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="59" id="US-6611789-B1-CLM-00059" class="claim">
      <div class="claim-text">59. The system of <claim-ref idref="US-6611789-B1-CLM-00056">claim 56</claim-ref>, wherein:</div>
      <div class="claim-text">the at least one sensor is adapted to monitor movement of at least one foot of the user; and </div>
      <div class="claim-text">the at least one processor is configured to analyze an output of the at least one sensor to determine at least one of a pace and a speed of the user during the at least one footstep, and to determine the stride length of the user based upon the determined at least one of the pace and the speed of the user. </div>
    </div>
    </div> <div class="claim"> <div num="60" id="US-6611789-B1-CLM-00060" class="claim">
      <div class="claim-text">60. A system, comprising:</div>
      <div class="claim-text">at least one sensor adapted to be supported by a user and to monitor movement of the user while the user is in locomotion on foot; and </div>
      <div class="claim-text">at least one processor configured to, based upon the output of the at least one sensor, determine values of the user's average stride length during one of respective time intervals and respective distance intervals. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="61" id="US-6611789-B1-CLM-00061" class="claim">
      <div class="claim-text">61. The system of <claim-ref idref="US-6611789-B1-CLM-00056">claim 56</claim-ref>, wherein the at least one sensor is adapted to monitor movement of at least one foot of the user, and wherein the at least one processor is configured to analyze an output of the at least one sensor to determine at least one foot contact time of the user during the at least one footstep, and to determine the stride length of the user based upon the determined at least one foot contact time of the user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="62" id="US-6611789-B1-CLM-00062" class="claim">
      <div class="claim-text">62. The system of <claim-ref idref="US-6611789-B1-CLM-00056">claim 56</claim-ref>, wherein the at least one sensor is adapted to monitor movement of at least one foot of the user, and wherein the at least one processor is configured to analyze an output of the at least one sensor to determine at least one step time of the user during the at least one footstep, and to determine the stride length of the user based upon the determined at least one step time of the user.</div>
    </div>
    </div> <div class="claim"> <div num="63" id="US-6611789-B1-CLM-00063" class="claim">
      <div class="claim-text">63. A system, comprising:</div>
      <div class="claim-text">at least one sensor adapted to be supported by a user and to monitor movement of the user while the user is in locomotion on foot; and </div>
      <div class="claim-text">means for determining a cadence of the user for footsteps taken by the user based upon an output of the at least one sensor. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="64" id="US-6611789-B1-CLM-00064" class="claim">
      <div class="claim-text">64. The system of <claim-ref idref="US-6611789-B1-CLM-00063">claim 63</claim-ref>, wherein the at least one sensor does not require compression forces thereon to monitor movement of the user.</div>
    </div>
    </div> <div class="claim"> <div num="65" id="US-6611789-B1-CLM-00065" class="claim">
      <div class="claim-text">65. A system, comprising:</div>
      <div class="claim-text">at least one sensor adapted to be supported by a user and to monitor movement of the user while the user is in locomotion on foot; and </div>
      <div class="claim-text">means for determining a stride length of the user for at least one footstep taken by the user based upon an output of the at least one sensor. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="66" id="US-6611789-B1-CLM-00066" class="claim">
      <div class="claim-text">66. The system of <claim-ref idref="US-6611789-B1-CLM-00065">claim 65</claim-ref>, wherein the at least one sensor does not require compression forces thereon to monitor movement of the user.</div>
    </div>
    </div> <div class="claim"> <div num="67" id="US-6611789-B1-CLM-00067" class="claim">
      <div class="claim-text">67. A method, comprising steps of:</div>
      <div class="claim-text">(a) determining foot contact times of a user for footsteps taken by the user; </div>
      <div class="claim-text">(b) determining that the user is walking based upon at least one first determined foot contact time of the user; and </div>
      <div class="claim-text">(c) determining that the user is running based upon at least one second determined foot contact time of the user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="68" id="US-6611789-B1-CLM-00068" class="claim">
      <div class="claim-text">68. The method of <claim-ref idref="US-6611789-B1-CLM-00067">claim 67</claim-ref>, further comprising steps of:</div>
      <div class="claim-text">(d1) calculating at least one of a walking speed and a walking pace of the user using a first equation in which the at least one first determined foot contact time is a factor; and </div>
      <div class="claim-text">(d2) calculating at least one of a running speed and a running pace of the user using a second equation which is different than the first equation and in which the at least one second determined foot contact time is a factor. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="69" id="US-6611789-B1-CLM-00069" class="claim">
      <div class="claim-text">69. The method of <claim-ref idref="US-6611789-B1-CLM-00068">claim 68</claim-ref>, wherein the step (a) is performed by at least one device supported by a user while the user is in locomotion on foot.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="70" id="US-6611789-B1-CLM-00070" class="claim">
      <div class="claim-text">70. The method of <claim-ref idref="US-6611789-B1-CLM-00067">claim 67</claim-ref>, wherein the step (a) is performed by at least one device supported by a user while the user is in locomotion on foot.</div>
    </div>
    </div> <div class="claim"> <div num="71" id="US-6611789-B1-CLM-00071" class="claim">
      <div class="claim-text">71. A system, comprising:</div>
      <div class="claim-text">at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that determines foot contact times of the user for footsteps taken by the user, that determines that the user is walking based upon at least one first determined foot contact time of the user, and that determines that the user is running based upon at least one second determined foot contact time of the user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="72" id="US-6611789-B1-CLM-00072" class="claim">
      <div class="claim-text">72. The system of <claim-ref idref="US-6611789-B1-CLM-00071">claim 71</claim-ref>, wherein the at least one processor is configured to calculate at least one of a walking speed and a walking pace of the user using a first equation in which the at least one first determined foot contact time is a factor, and is further configured to calculate at least one of a running speed and a running pace of the user using a second equation which is different than the first equation and in which the at least one second determined foot contact time is a factor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="73" id="US-6611789-B1-CLM-00073" class="claim">
      <div class="claim-text">73. The system of <claim-ref idref="US-6611789-B1-CLM-00071">claim 71</claim-ref>, further comprising at least one sensor, coupled to the at least one processor, to monitor movement of the user and to provide a signal to the at least one processor from which the at least one processor can determine foot contact times for the user, wherein the at least one sensor does not require compression forces thereon to monitor movement of the user.</div>
    </div>
    </div> <div class="claim"> <div num="74" id="US-6611789-B1-CLM-00074" class="claim">
      <div class="claim-text">74. A system, comprising:</div>
      <div class="claim-text">at least one sensor, adapted to be supported by a user while the user is in locomotion on foot, that determines foot contact times of the user for footsteps taken by the user; </div>
      <div class="claim-text">means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is walking based upon at least one first determined foot contact time of the user; and </div>
      <div class="claim-text">means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is running based upon at least one second determined foot contact time of the user. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="75" id="US-6611789-B1-CLM-00075" class="claim">
      <div class="claim-text">75. The system of <claim-ref idref="US-6611789-B1-CLM-00074">claim 74</claim-ref>, wherein the at least one sensor does not require compression forces thereon to determine the foot contact time of the user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="76" id="US-6611789-B1-CLM-00076" class="claim">
      <div class="claim-text">76. The method of <claim-ref idref="US-6611789-B1-CLM-00049">claim 49</claim-ref>, further comprising a step of:</div>
      <div class="claim-text">(d) displaying a representation of the determined values of the user's average stride length for the one of the respective time intervals and the respective distance intervals. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="77" id="US-6611789-B1-CLM-00077" class="claim">
      <div class="claim-text">77. The method of <claim-ref idref="US-6611789-B1-CLM-00049">claim 49</claim-ref>, further comprising a step of:</div>
      <div class="claim-text">(d) storing in memory information representing the determined values of the user's average stride length for the one of the respective time intervals and the respective distance intervals. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="78" id="US-6611789-B1-CLM-00078" class="claim">
      <div class="claim-text">78. The system of <claim-ref idref="US-6611789-B1-CLM-00060">claim 60</claim-ref>, further comprising a display that displays a representation of the determined values of the user's average stride length for the one of the respective time intervals and the respective distance intervals.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES53977346" lang="EN" load-source="patent-office" class="description">
    <heading>RELATED APPLICATIONS</heading> <p>This is a continuation-in-part of each of application Ser. Nos. 09/547,975, 09/547,976, 09/547,977, and 09/548,217, each of which was filed on Apr. 12, 2000, and is now abandoned. Each of application Ser. Nos. 09/547,975, 09/547,976, 09/547,977, and 09/548,217 is a continuation-in-part of application Ser. No. 09/364,559, filed on Jul. 30, 1999, and now U.S. Pat. No. 6,052,654, which is a continuation of application Ser. No. 08/942,802, filed Oct. 2, 1997, and now U.S. Pat. No. 6,018,705.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>The present invention relates to the monitoring of the activity of a user in locomotion on foot.</p>
    <p>2. Discussion of the Related Art</p>
    <p>It is known that useful information may be derived from the measurement of the foot contact time (Tc) of a user in locomotion, wherein foot contact time refers to the period of time that a foot of a user is in contact with the surface during a stride taken by the user while the user is in locomotion on foot. Once the foot contact time (Tc) of the user is known, other information, such as rate of travel, distance traveled, and ambulatory expended energy may be calculated based upon this measured foot contact time (Tc).</p>
    <p>In the past, foot contact time (Tc) has been measured by placing pressure-sensitive sensors or switches, such as resistive sensors, in both the heel and toe portions of the sole of a shoe, and measuring a time difference between a first signal output by the heel sensor (which indicates that the foot has made physical contact with the surface) and a second signal output by the toe sensor (which indicates that the foot has left the surface). These sensors, however, are subjected to a high-impact environment inside of the shoe, and therefore fail frequently. In addition, inaccurate foot contact time (Tc) measurements may result when a user is taking strides during which either the heel sensor or the toe sensor is not activated, for example, when a user is running on his or her toes.</p>
    <p>Another device well-known in the art is a pedometer. A pedometer typically is mounted on the waist of a user and is configured to count the footsteps of the user by measuring the number of times the user's body moves up an down during strides taken by the user. A well-known prior art pedometer design uses a weight mounted on a spring to count the number of times that the user's body moves up and down as the user is walking. By properly calibrating the pedometer according to a previously measured stride length of the user, the distance traveled by the user may be measured by this device. These weight-on-a-spring pedometers, however, generally cannot measure the distance traveled by a runner because the weight experiences excessive bouncing during running and footsteps are often double-counted because of this bouncing, thereby causing the pedometer to produce inaccurate results. These devices therefore cannot be used across different training regimes (e.g., walking, jogging, and running).</p>
    <p>Another prior art pedometer device uses an accelerometer to measure the number of times that a user's foot impacts the surface when the user is in locomotion. That is, an accelerometer is mounted on the user's shoe so as to produce a signal having pronounced downward going peaks that are indicative of moments that the user's foot impacts the surface. These devices therefore produce results similar to the prior art weight-on-a-spring pedometer devices in that they merely count the number of footsteps of the user, and must be calibrated according to the stride length of the user in order to calculate the distance traveled by the user. Thus, these accelerometer-based devices are subject to similar limitations as are the weight-on-a-spring devices, and are not capable of measuring the foot contact time (Tc) of a user in locomotion.</p>
    <p>It is therefore a general object of the present invention to provide a new approach to pedometry.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>According to one aspect of the present invention, a method involves determining at least one calculated parameter based upon at least one determined performance parameter of the user and at least one determined variable physiological parameter of the user.</p>
    <p>According to another aspect of the invention, a method involves identifying at least one of an existence of a non-zero grade of a surface and a value of the grade of the surface based upon at least one determined variable physiological parameter of a user.</p>
    <p>According to another aspect of the invention, a method involves identifying at least one of an existence of a grade of a surface and a value of the grade of the surface based upon at least one determined performance parameter of a user.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to identify at least one of an existence of a non-zero grade of a surface and a value of the grade of the surface based upon at least one determined variable physiological parameter of a user in locomotion on foot on the surface.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to identify at least one of an existence of a non-zero grade of a surface and a value of the grade of the surface based upon at least one determined performance parameter of the user in locomotion on foot on the surface.</p>
    <p>According to another aspect of the invention, a system includes at least one first sensor that determines at least one performance parameter of the user while the user is in locomotion on foot; at least one second sensor that determines at least one variable physiological parameter of the user while the user is in locomotion on foot; and means for determining at least one calculated parameter based upon the at least one determined performance parameter of the user and the at least one determined variable physiological parameter of the user.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor that determines at least one physiological condition of a user while the user is in locomotion on foot on a surface; and means for identifying at least one of an existence of a non-zero grade of the surface and a value of the grade of the surface based upon the at least one determined physiological condition of the user.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor that determines at least one performance parameter of a user while the user is in locomotion on foot on a surface; and means for identifying at least one of an existence of a non-zero grade of the surface and a value of the grade of the surface based upon the at least one determined performance parameter.</p>
    <p>According to another aspect of the invention, a method includes steps of: with at least one device supported by a user while the user is in locomotion on foot, determining at least one performance parameter of the user; and estimating a value of a variable physiological parameter of the user based upon the determined at least one performance parameter of the user.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) identifying at least one of an existence of a non-zero grade of a surface and a value of the grade of the surface; and (b) with at least one device supported by a user while the user is in locomotion on foot, determining at least one performance parameter of the user based upon the identified at least one of an existence of the non-zero grade of the surface and the value of the grade of the surface.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) determining at least one altitude of a user; and (b) with at least one device supported by the user while the user is in locomotion on foot, calculating at least one performance parameter of the user based upon the at least one determined altitude of the user.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one performance parameter of the user; and at least one processor that calculates a value of a variable physiological parameter of the user based upon the determined at least one performance parameter of the user.</p>
    <p>According to another aspect of the invention, a system includes at least one processor, adapted to be supported by a user while the user is in locomotion on foot on a surface, that determines at least one performance parameter of the user based upon at least one of an identified existence of a non-zero grade of the surface and an identified value of the grade of the surface.</p>
    <p>According to another aspect of the invention, a system includes at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that calculates at least one performance parameter of the user based upon at least one identified altitude of the user.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one performance parameter of the user; and means for calculating a value of a variable physiological parameter of the user based upon the determined at least one performance parameter.</p>
    <p>According to another aspect of the invention, a system includes means for identifying at least one of an existence of a non-zero grade of a surface and a value of the grade of the surface; and means, adapted to supported by a user while the user is in locomotion on foot on the surface, for determining at least one performance parameter of the user based upon the identified at least one of the existence of the non-zero grade of the surface and the value of the grade of the surface.</p>
    <p>According to another aspect of the invention, a system includes means for determining at least one altitude of a user; and means, adapted to be supported by the user while the user is in locomotion on foot, for calculating at least one performance parameter of the user based upon the at least one determined altitude of the user.</p>
    <p>According to another aspect of the invention, a method involves, in response to movement of a user during at least one footstep taken by the user, generating a signal that experiences changes during a time period that the foot is airborne during at least one footstep taken by the user. At least one change in the signal generated after the foot has become airborne and before the foot contacts the surface is identified that is indicative of the foot being airborne during the at least one footstep.</p>
    <p>According to another aspect of the invention, a method involves generating a signal in response to movement of a user during at least one footstep taken by the user. The signal is monitored to determine when the signal has experienced a minimum degree of smoothness for at least a given period of time. In response to determining that the signal has experienced the minimum degree of smoothness for at least the given period of time, it is identified that the foot of the user is airborne.</p>
    <p>According to another aspect of the invention, a method involves generating a signal in response to movement of a user during at least one footstep taken by the user. It is determined whether any characteristics of the signal satisfy any one of a plurality of predetermined criteria consistent with a foot of the user engaging in a particular event during a footstep.</p>
    <p>According to another aspect of the invention, a method involves generating a signal in response to movement of a user during at least one footstep taken by the user. The signal is sampled to obtain a plurality of samples of the signal. Differences between pairs of the plurality of samples of the signal are calculated, and the calculated differences between the pairs of the plurality of samples of the signal are monitored to identify at least one pair of the plurality of samples of the signal having a difference therebetween that is indicative of a particular event during the at least one footstep.</p>
    <p>According to another aspect of the invention, a method involves generating a signal in response to movement of a user during a plurality of footsteps taken by the user. A threshold is set based upon at least one first characteristic of the signal generated during at least a first one of the plurality of footsteps preceding a second one of the plurality of footsteps. The signal generated during the second one of the plurality of footsteps is analyzed to determine whether at least one second characteristic of the signal generated during the second one of the plurality of footsteps has exceeded the threshold.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) generating a signal in response to movement of a user during a plurality of footsteps taken by the user; (b) with at least one processor, analyzing the signal to determine a moment that a foot of the user makes contact with a surface during one of the plurality of footsteps taken by the user; (c) after performing the step (b), with the at least one processor, analyzing the signal to determine a moment that the foot leaves the surface during the one of the plurality of footsteps; (d) waiting a given period of time after performing the step (b) to perform the step (c); (e) with the at least one processor, during the given period of time, performing calculations involving at least one of a determined foot contact time and a determined foot loft time; and (f) repeating the steps (b), (c), (d), and (e) for each of the plurality of footsteps.</p>
    <p>According to another aspect of the invention, a system is disclosed that may be used in conjunction with at least one sensor that, in response to movement of a user during at least one footstep taken by the user on a surface, generates a signal that experiences changes during a time period that a foot of the user is airborne during the at least one footstep. The system includes at least one processor configured to identify at least one change in the signal generated after the foot has become airborne and before the foot contacts the surface that is indicative of the foot being airborne during the at least one footstep.</p>
    <p>According to another aspect of the invention, a system is disclosed that may be used in conjunction with at least one sensor that generates a signal in response to movement of a user during at least one footstep taken by the user. The system includes at least one processor configured to monitor the signal to determine when the signal has experienced a minimum degree of smoothness for at least a given period of time, and to, in response to determining that the signal has experienced the minimum degree of smoothness for at least the given period of time, identify that the foot of the user is airborne.</p>
    <p>According to another aspect of the invention, a system is disclosed that may be used in conjunction with at least one sensor that generates a signal in response to movement of a user during at least one footstep taken by the user on a surface. The system includes at least one processor configured to determine whether any characteristics of the signal satisfy any one of a plurality of predetermined criteria consistent with a foot of the user engaging in a particular event during a footstep.</p>
    <p>According to another aspect of the invention, a system is disclosed that may be used in conjunction with at least one sensor that generates a signal in response to movement of a user during at least one footstep taken by the user on a surface. The system includes at least one processor configured to sample the signal to obtain a plurality of samples of the signal, to calculate differences between pairs of the plurality of samples of the signal, and to monitor the calculated differences between the pairs of the plurality of samples of the signal to identify at least one pair of the plurality of samples of the signal having a difference therebetween that is indicative of a particular event during the at least one footstep.</p>
    <p>According to another aspect of the invention, a system is disclosed that may be used in conjunction with at least one sensor that generates a signal in response to movement of a user during a plurality of footsteps taken by the user. The system includes at least one processor configured to set a threshold based upon at least one first characteristic of the signal generated during at least a first one of the plurality of footsteps preceding a second one of the plurality of footsteps, and to analyze the signal generated during the second one of the plurality of footsteps to determine whether at least one second characteristic of the signal generated during the second one of the plurality of footsteps has exceeded the threshold.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to compare a foot contact time of a user with a threshold value, to determine that the user is running if the foot contact time is less than the threshold value, and to determine that the user is walking if the foot contact time is greater than the threshold value.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor that, in response to movement of a user during at least one footstep taken by the user, generates a signal that experiences changes during a time period that the foot is airborne during the at least one footstep, and means for identifying at least one change in the signal generated after the foot has become airborne and before the foot contacts a surface that is indicative of the foot being airborne during the at least one footstep.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor that generates a signal in response to movement of a user during at least one footstep taken by the user, and means for monitoring the signal to determine when the signal has experienced a minimum degree of smoothness for at least a given period of time, and for, in response to determining that the signal has experienced the minimum degree of smoothness for at least the given period of time, identifying that the foot of the user is airborne.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor that generates a signal in response to movement of a user during at least one footstep taken by the user, and means for determining whether any characteristics of the signal satisfy any one of a plurality of predetermined criteria consistent with a foot of the user engaging in a particular event during a footstep.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor that generates a signal in response to movement of a user during at least one footstep taken by the user, and means for sampling the signal to obtain a plurality of samples of the signal, for calculating differences between pairs of the plurality of samples of the signal, and for monitoring the calculated differences between the pairs of the plurality of samples of the signal to identify at least one pair of the plurality of samples of the signal having a difference therebetween that is indicative of a particular event during the at least one footstep.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor that generates a signal in response to movement of a user during a plurality of footsteps taken by the user, and means for setting a threshold based upon at least one first characteristic of the signal generated during at least a first one of the plurality of footsteps preceding a second one of the plurality of footsteps, and for analyzing the signal generated during the second one of the plurality of footsteps to determine whether at least one second characteristic of the signal generated during the second one of the plurality of footsteps has exceeded the threshold.</p>
    <p>According to another aspect of the invention, a method includes steps of (a) generating a signal in response to movement of a user during a footstep taken by the user; (b) identifying a first characteristic in the signal consistent with the occurrence of a toe-off event; (c) identifying a first moment that the first characteristic occurred as a potential occurrence of a toe-off event during the footstep; (d) identifying a second characteristic in the signal, occurring after the first characteristic in the signal, consistent with the occurrence of a toe-off event; and (e) identifying a second moment that the second characteristic occurred as the potential occurrence of the toe-off event during the footstep.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor that generates a signal in response to movement of a user during a footstep taken by the user, and at least one processor that identifies a first characteristic in the signal consistent with the occurrence of a toe-off event, that identifies a first moment that the first characteristic occurred as a potential occurrence of a toe-off event during the footstep, that identifies a second characteristic in the signal, occurring after the first characteristic in the signal, consistent with the occurrence of a toe-off event, and that identifies a second moment that the second characteristic occurred as the potential occurrence of the toe-off event during the footstep.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor that generates a signal in response to movement of a user during a footstep taken by the user; means for identifying a first characteristic in the signal consistent with the occurrence of a toe-off event; means for identifying a first moment that the first characteristic occurred as a potential occurrence of a toe-off event during the footstep; means for identifying a second characteristic in the signal, occurring after the first characteristic in the signal, consistent with the occurrence of a toe-off event; and means for identifying a second moment that the second characteristic occurred as the potential occurrence of the toe-off event during the footstep.</p>
    <p>According to another aspect of the invention, a display unit to be mounted on a wrist of a user includes a display screen, a base, and at least one strap. The display screen visually displays characters, and has a top edge and a bottom edge corresponding, respectively, to tops and bottoms of the characters displayed on the display screen. The base supports the display screen and houses electronic circuitry associated with the display screen. The at least one strap is attached to the base and is adapted to secure the base to the wrist of the user. The base is configured and arranged such that, when the base is secured to the wrist of the user with the at least one strap, the top edge of the display screen is disposed a first distance away from an outer surface of the user's wrist as determined along a first line oriented normal to the outer surface of the user's wrist and passing through the top edge of the display screen, and the bottom edge of the display screen is disposed a second distance away from an outer surface of the user's wrist as determined along a second line oriented normal to the outer surface of the user's wrist and passing through the bottom edge of the display screen, wherein the first distance is greater than the second distance.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one device supported by a user while the user is in locomotion on foot, determining respective values of at least first and second parameters selected from a group consisting of: an instantaneous pace of the user, an average pace of the user, and a distance traveled by the user; and (b) displaying visually-perceptible information indicative of the determined values of the at least first and second parameters, simultaneously.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least, one device supported by a user while the user is in locomotion on foot, determining a value of at least one variable physiological parameter of the user; (b) with the at least one device, determining a value of at least one performance parameter of the user; and (c) displaying visually-perceptible information indicative of the determined values of the at least one variable physiological parameter of the user and the at least one performance parameter of the user, simultaneously.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one device supported by the user, determining respective values of at least first and second parameters selected from a group consisting of: an instantaneous speed of the user, an average speed of the user, and a distance traveled by the user; and (b) displaying visually-perceptible information indicative of the determined values of the at least first and second parameters, simultaneously.</p>
    <p>According to another aspect of the invention, a system includes at least one device adapted to be supported by a user while the user is in locomotion on foot. The at least one device includes at least one sensor to determine respective values of at least first and second parameters selected from a group consisting of: an instantaneous pace of the user, an average pace of the user, and a distance traveled by the user, the at least one device further comprising a display configured to display visually-perceptible information indicative of the determined values of the at least first and second parameters, simultaneously.</p>
    <p>According to another aspect of the invention, a system includes at least one device adapted to be supported by a user while the user is in locomotion on foot. The at least one device includes a first sensor to determine a value of at least one variable physiological parameter of the user, a second sensor to determine a value of at least one performance parameter of the user, and a display configured to display visually-perceptible information indicative of the determined values of the at least one variable physiological parameter of the user and the at least one performance parameter of the user, simultaneously.</p>
    <p>According to another aspect of the invention, a system includes at least one device adapted to be supported by a user while the user is in locomotion on foot. The at least one device includes at least one sensor to determine respective values of at least first and second parameters selected from a group consisting of: an instantaneous speed of the user, an average speed of the user, and a distance traveled by the user, and a display configured to display visually-perceptible information indicative of the determined values of the at least first and second parameters, simultaneously.</p>
    <p>According to another aspect of the invention, a system includes means, adapted to be supported by a user while the user is in locomotion on foot, for determining respective values of at least first and second parameters selected from a group consisting of: an instantaneous pace of the user, an average pace of the user, and a distance traveled by the user; and means, adapted to be supported by the user while the user is in locomotion on foot, for displaying visually-perceptible information indicative of the determined values of the at least first and second parameters, simultaneously.</p>
    <p>According to another aspect of the invention, a system includes first means, adapted to be supported by a user while the user is in locomotion on foot, for determining a value of at least one variable physiological parameter of a user; second means, adapted to be supported by the user while the user is in locomotion on foot, for determining a value of at least one performance parameter of the user; and third means, adapted to be supported by the user while the user is in locomotion on foot, for displaying visually-perceptible information indicative of the determined values of the at least one variable physiological parameter of the user and the at least one performance parameter of the user, simultaneously.</p>
    <p>According to another aspect of the invention, a system includes means, adapted to be supported by a user while the user is in locomotion on foot, for determining respective values of at least first and second parameters selected from a group consisting of: an instantaneous speed of the user, an average speed of the user, and a distance traveled by the user; and means, adapted to be supported by the user while the user is in locomotion on foot, for displaying visually-perceptible information indicative of the determined values of the at least first and second parameters, simultaneously.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) identifying an average foot contact time of a user during a first outing; (b) identifying an average pace of the user during the first outing; (c) defining a relationship between foot contact times of the user and corresponding paces of the user, wherein the relationship is based upon the average foot contact time and the average pace identified during the first outing, and wherein no other average foot contact times and no other average paces identified during any different outings by the user are used to define the relationship; and (d) calibrating at least one device that monitors activity of the user in locomotion on foot based upon the defined relationship between foot contact times of the user and corresponding paces of the user.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) determining a single user-specific calibration constant that defines a relationship between foot contact times of a user and corresponding paces of the user, wherein no other user-specific calibration constants are used to define the relationship; and (b) calibrating at least one device that monitors activity of the user in locomotion on foot based upon the relationship between foot contact times of the user and corresponding paces of the user that is defined by the single user-specific calibration constant.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) on a graph having foot contact times of a user on a first coordinate axis and paces of the user on a second coordinate axis, determining a location of a first point particular to the user; (b) identifying a second point on the graph independent of the user; (c) based upon locations of the first and second points on the graph, defining a curve on the graph that intercepts both of the first and second points; and (d) calibrating at least one device that monitors activity of the user in locomotion on foot based upon the defined curve.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) based upon a first relationship between foot contact times of a user and corresponding paces of the user, defining a second relationship between inverse values of foot contact times of the user and corresponding speeds of the user; and (b) calibrating at least one device that monitors activity of the user in locomotion on foot based upon the second relationship.</p>
    <p>According to another aspect of the invention, a method involves determining a speed of a user in locomotion on foot by including at least one determined foot contact time in an equation defining a relationship between inverse values of foot contact times of the user and corresponding speeds of the user.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) based upon a first relationship between inverse values of foot contact times of a user and corresponding speeds of the user, defining a second relationship between foot contact times of the user and corresponding paces of the user; and (b) calibrating at least one device that monitors activity of the user in locomotion on foot based upon the second relationship.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) identifying an average foot contact time of a user during a first outing; (b) identifying an average speed of the user during the first outing; (c) defining a relationship between inverse values of foot contact times of the user and corresponding speeds of the user, wherein the relationship is based upon the average foot contact time and the average speed identified during the first outing; and (d) calibrating at least one device that monitors activity of the user in locomotion on foot based upon the defined relationship between inverse values of foot contact times of the user and corresponding speeds of the user.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) determining a single user-specific calibration constant that defines a relationship between inverse values of foot contact times of a user and corresponding speeds of the user, wherein no other user-specific calibration constants are used to define the relationship; and (b) calibrating at least one device that monitors activity of the user in locomotion on foot based upon the relationship between inverse values of foot contact times of the user and corresponding speeds of the user that is defined by the single user-specific calibration constant.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to define a relationship between foot contact times of a user and corresponding paces of the user, wherein the relationship is based upon an average foot contact time and an average pace identified during a first outing, and wherein no other average foot contact times and no other average paces identified during any different outings by the user are used to define the relationship, the at least one processor being further configured to calculate at least one of a pace of the user and a distance traveled by the user during a second outing based upon at least one foot contact time determined during the second outing and the defined relationship between foot contact times of the user and corresponding paces of the user.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to use a single user-specific calibration constant to define a relationship between foot contact times of a user and corresponding paces of the user without any other user-specific calibration constants being used to define the relationship, the at least one processor being further configured to calculate at least one of a pace of the user and a distance traveled by the user during an outing based upon at least one foot contact time determined during the outing and the defined relationship between foot contact times of the user and corresponding paces of the user.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to, on a graph having foot contact times of a user on a first coordinate axis and paces of the user on a second coordinate axis, determine a location of a first point particular to the user, to identify a second point on the graph independent of the user, and to, based upon locations of the first and second points on the graph, define a curve on the graph that intercepts both of the first and second points, the at least one processor being further configured to calculate at least one of a pace of the user and a distance traveled by the user during an outing based upon at least one foot contact time determined during the outing and the defined curve.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to, based upon a first relationship between foot contact times of a user and corresponding paces of the user, define a second relationship between inverse values of foot contact times of the user and corresponding speeds of the user, the at least one processor being further configured to calculate at least one of a speed of the user and a distance traveled by the user during an outing based upon at least one foot contact time determined during the outing and the second relation ship.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to, determine a speed of a user in locomotion on foot by including at least one determined foot contact time in an equation defining a relationship between inverse values of foot contact times of the user and corresponding speeds of the user.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to, based upon a first relationship between inverse values of foot contact times of a user and corresponding speeds of the user, define a second relationship between foot contact times of the user and corresponding paces of the user, the at least one processor being further configured to calculate at least one of a speed of the user and a distance traveled by the user during an outing based upon at least one foot contact time determined during the outing and the second relationship.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to define a relationship between inverse values of foot contact times of a user and corresponding speeds of the user based upon an average foot contact time and an average speed determined during a first outing, the at least one processor being further configured to calculate at least one of a speed of the user and a distance traveled by the user during a second outing based upon at least one foot contact time determined during the second outing and the defined relationship.</p>
    <p>According to another aspect of the invention, a system includes at least one processor configured to use a single user-specific calibration constant to define a relationship between inverse values of foot contact times of a user and corresponding speeds of the user without using any other user-specific calibration constants to define the relationship, the at least one processor being further configured to calculate at least one of a speed of the user and a distance traveled by the user during an outing based upon at least one foot contact time determined during the outing and the relationship between inverse values of foot contact times of the user and corresponding speeds of the user that is defined by the single user-specific calibration constant.</p>
    <p>According to another aspect of the invention, a system includes means for defining a relationship between foot contact times of the user and corresponding paces of the user, wherein the relationship is based upon an average foot contact time and an average pace identified during a first outing, and wherein no other average foot contact times and no other average paces identified during any different outings by the user are used to define the relationship; and means for calculating at least one of a pace of the user and a distance traveled by the user during a second outing based upon at least one foot contact time determined during the second outing and the defined relationship between foot contact times of the user and corresponding paces of the user.</p>
    <p>According to another aspect of the invention, a system includes means for using a single user-specific calibration constant to define a relationship between foot contact times of a user and corresponding paces of the user, wherein no other user-specific calibration constants are used to define the relationship; and means for calculating at least one of a pace times of the user and a distance traveled by the user during an outing based upon at least one foot contact time determined during the outing and the defined relationship between foot contact times of the user and corresponding paces of the user.</p>
    <p>According to another aspect of the invention, a system includes means for, based upon a first relationship between foot contact times of a user and corresponding paces of the user, defining a second relationship between inverse values of foot contact times of the user and corresponding speeds of the user; and means for calculating at least one of a speed of the user and a distance traveled by the user during an outing based upon at least one foot contact time determined during the outing and the second relationship.</p>
    <p>According to another aspect of the invention, a system includes means for determining at least on foot contact time of a user; and means for determining a speed of the user by including the at least one foot contact time in an equation defining a relationship between inverse values of foot contact times of the user and corresponding speeds of the user.</p>
    <p>According to another aspect of the invention, a system includes means for, based upon a first relationship between inverse values of foot contact times of a user and corresponding speeds of the user, defining a second relationship between foot contact times of the user and corresponding paces of the user; and means for calculating at least one of a pace of the user and a distance traveled by the user during an outing based upon at least one foot contact time determined during the outing and the second relationship.</p>
    <p>According to another aspect of the invention, a system includes means for defining a relationship between inverse values of foot contact times of the user and corresponding speeds of the user, wherein the relationship is based upon an average foot contact time and an average speed identified during a first outing; and means for calculating at least one of a speed of the user and a distance traveled by the user during a second outing based upon at least one foot contact time determined during the second outing and the relationship between inverse values of foot contact times of the user and corresponding speeds of the user.</p>
    <p>According to another aspect of the invention, a system includes means for using a single user-specific calibration constant to define a relationship between inverse values of foot contact times of a user and corresponding speeds of the user, wherein no other user-specific calibration constants are used to define the relationship; and means for calculating at least one of a speed of the user and a distance traveled by the user during an outing based upon at least one foot contact time determined during the outing and the relationship between inverse values of foot contact times of the user and corresponding speeds of the user that is defined by the single user-specific calibration constant.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one device supported by a user while the user is in locomotion on foot, determining at least one foot contact time of the user in locomotion; (b) comparing a variable having the at least one determined foot contact time as a factor therein with a threshold value; and (c1) if the variable is one of greater than or less than the threshold value, determining that the user is walking; and (c2) if the variable is the other of greater than or less than the threshold value, determining that the user is running.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) determining at least one foot contact time of a user while the user is in locomotion on foot; (b) comparing the at least one determined foot contact time with a threshold value; and (c1) if the foot. contact time is less than the threshold value, determining that the user is running; and (c2) if the foot contact time is greater than the threshold value, determining that the user is walking.</p>
    <p>According to another aspect of the invention, a system includes at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one foot contact time of the user, and compares a variable having the at least one determined foot contact time as a factor therein with a threshold value; wherein, if the variable is one of greater than or less than the threshold value, the at least one processor determines that the user is walking, and, if the variable is the other of greater than or less than the threshold value, the at least one processor determines that the user is running.</p>
    <p>According to another aspect of the invention, a system includes at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one foot contact time of the user, and compares the at least one determined foot contact time with a threshold value; wherein, if the foot contact time is less than the threshold value, the at least one processor determines that the user is running, and, if the foot contact time is greater than the threshold value, the at least one processor determines that the user is walking.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one foot contact time of the user in locomotion; means, adapted to be supported by the user while the user is in locomotion on foot, for comparing a variable having the at least one determined foot contact time as a factor therein with a threshold value; means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is walking if the variable is one of greater than or less than the threshold value; and means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is running if the variable is the other of greater than or less than the threshold value.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor, adapted to be supported by a user while the user is in locomotion on foot, that determines at least one foot contact time of the user in locomotion; means, adapted to be supported by the user while the user is in locomotion on foot, for comparing the at least one determined foot contact time with a threshold value; means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is running if the foot contact time is less than the threshold value; and means, adapted to be supported by the user while the user is in locomotion on foot, for determining that the user is walking if the foot contact time is greater than the threshold value.</p>
    <p>According to another aspect of the invention, a method includes a step of: (a) with at least one device supported by a user while the user is in locomotion on foot on a surface, determining an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user.</p>
    <p>According to another aspect of the invention, a system includes at least one processor adapted to be supported by a user while the user is in locomotion on foot on a surface, the at least one processor being configured to identify an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor adapted to be supported by a user while the user is in locomotion on foot on a surface; and means for identifying an amount of force exerted by at least one foot of the user on the surface during at least one footstep taken by the user based upon an output of the at least one sensor.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one sensor supported by a user, monitoring movement of the user while the user is in locomotion on foot; and (b) determining a cadence of the user based upon an output of the at least one sensor.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one sensor supported by a user while the user is in locomotion on foot, monitoring movement of the user while the user is in locomotion on foot; and (b) determining a stride length of the user during at least one footstep taken by the user based upon an output of the at least one sensor.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor adapted to be supported by a user and to monitor movement of the user while the user is in locomotion on foot; and at least one processor that determines a cadence of the user based upon an output of the at least one sensor.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor adapted to be supported by a user and to monitor movement of the user while the user is in locomotion on foot; and at least one processor that, based upon an output of the at least one sensor, determines a stride length of the user during at least one footstep taken by the user.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor adapted to be supported by a user and to monitor movement of the user while the user is in locomotion on foot; and means for determining a cadence of the user based upon an output of the at least one sensor.</p>
    <p>According to another aspect of the invention, a system includes at least one sensor adapted to be supported by a user and to monitor movement of the user while the user is in locomotion on foot; and means for determining a stride length of the user during at least one footstep taken by the user based upon an output of the at least one sensor.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one device supported by a user while the user is in locomotion on foot on a surface, identifying one of a pace and a speed of the user relative to the surface; and (b) with the at least one device, determining whether the identified one of the pace and the speed of the user falls within one of a zone of paces and a zone of speeds.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one device supported by a user while the user is in locomotion on foot, monitoring a distance traveled by the user; and (b) with the at least one device, when the user has traveled a first predetermined distance during the outing, providing an output indicating that the user has traveled the first predetermined distance.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one device supported by a user while the user is in locomotion on foot, monitoring a distance traveled by the user; (b) receiving a goal distance as an input to the at least one device; and (c) with the at least one device, determining a remaining distance to be traveled by the user to reach one of the input goal distance and a calculated fraction of the input goal distance.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) receiving as an input to at least one device supported by a user a value representing one of a goal time for the user to travel a particular distance, a goal average pace for the user to maintain over the particular distance, and a goal average speed for the user to maintain over the particular distance; (b) with the at least one device, determining a distance traveled by the user while the user is in locomotion on foot; and (c) after the user has traveled a portion of the particular distance, with the at least one device, determining at least one performance parameter based upon the portion of the particular distance traveled and the input value.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one device, determining a distance traveled by a user while the user is in locomotion on foot; (b) with the at least one device, determining one of a current pace and a current speed of the user; and (c) after the user has traveled a portion of a particular distance, with the at least one device, determining a projected time that it will take the user to travel the particular distance based upon the one of the current pace and the current speed of the user, and the portion of the particular distance already traveled by the user.</p>
    <p>According to another aspect of the invention, a method includes steps of: (a) with at least one device supported by a user while the user is in locomotion on foot, determining a distance traveled by the user; (b) during at least one first distance interval during an outing, with the at least one device, providing an indication to the user that the user should be running; and (c) during at least one second distance interval during the outing, with the at least one device, providing an indication to the user that the user should be walking.</p>
    <p>According to another aspect of the invention, a system includes at least one processor, adapted to be supported by a user while the user is in locomotion on foot on a surface, that identifies one of a pace and a speed of the user relative to the surface, and that determines whether the identified one of the pace and the speed of the user falls within one of a zone of paces and a zone of speeds.</p>
    <p>According to another aspect of the invention, a system includes at least one processor that monitors a distance traveled by a user while the user is in locomotion on foot, and that, when the user has traveled a first predetermined distance during an outing, provides an output indicating that the user has traveled the first predetermined distance.</p>
    <p>According to another aspect of the invention, a system includes at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that monitors a distance traveled by the user while the user is in locomotion on foot, that receives a goal distance as an input, and that determines a remaining distance to be traveled by the user to reach one of the input goal distance and a calculated fraction of the input goal distance.</p>
    <p>According to another aspect of the invention, a system includes at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that receives as an input a value representing one of a goal time for the user to travel a particular distance, a goal average pace for the user to maintain over the particular distance, and a goal average speed for the user to maintain over the particular distance, that determines a distance traveled by the user while the user is in locomotion on foot, and that, after the user has traveled a portion of the particular distance, determines at least one performance parameter based upon the portion of the particular distance traveled and the input value.</p>
    <p>According to another aspect of the invention, a system includes at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that determines a distance traveled by the user while the user is in locomotion on foot, that determines one of a current pace and a current speed of the user, and that, after the user has traveled a portion of a particular distance, determines a projected time that it will take the user to travel the particular distance based upon the one of the current pace and the current speed of the user, and the portion of the particular distance already traveled by the user.</p>
    <p>According to another aspect of the invention, a system includes at least one processor, adapted to be supported by a user while the user is in locomotion on foot, that determines a distance traveled by the user while the user is in locomotion on foot; and an indicator coupled to the processor, the at least one processor and the indicator being configured such that, during at least one first distance interval during an outing, the at least one processor causes the indicator to provide an indication to the user that the user should be running, and such that, during at least one second distance interval during the outing, the at least one processor causes the indicator to provide an indication to the user that the user should be walking.</p>
    <p>According to another aspect of the invention, a system includes means, adapted to be supported by a user while the user is in locomotion on foot on a surface, for identifying one of a pace and a speed of the user relative to the surface; and means, adapted to be supported by the user while the user is in locomotion on foot, for determining whether the identified one of the pace and the speed of the user falls within one of a zone of paces and a zone of speeds.</p>
    <p>According to another aspect of the invention, a system includes means, adapted to be supported by the user while a user is in locomotion on foot, for monitoring a distance traveled by the user while the user is in locomotion on foot; and means, adapted to be supported by the user while the user is in locomotion on foot, for providing an output indicating that the user has traveled a first predetermined distance.</p>
    <p>According to another aspect of the invention, a system includes means, adapted to be supported by a user while the user is in locomotion on foot, for monitoring a distance traveled by the user while the user is in locomotion on foot; means, adapted to be supported by the user while the user is in locomotion on foot, for receiving a goal distance as an input to the at least one device; and means, adapted to be supported by the user while the user is in locomotion on foot, for determining a remaining distance to be traveled by the user to reach one of the input goal distance and a calculated fraction of the input goal distance.</p>
    <p>According to another aspect of the invention, a system includes means, adapted to be supported by a user while the user is in locomotion on foot, for receiving as an input to at least one device supported by the user a value representing one of a goal time for the user to travel a particular distance, a goal average pace for the user to maintain over the particular distance, and a goal average speed for the user to maintain over the particular distance; means, adapted to be supported by the user while the user is in locomotion on foot, for determining a distance traveled by the user while the user is in locomotion on foot; and means, adapted to be supported by the user while the user is in locomotion on foot, for, after the user has traveled a portion of the particular distance, determining at least one performance parameter based upon the portion of the particular distance traveled and the input value.</p>
    <p>According to another aspect of the invention, a system includes means, adapted to be supported by a user while the user is in locomotion on foot, for determining a distance traveled by the user while the user is in locomotion on foot; means, adapted to be supported by the user while the user is in locomotion on foot, for determining one of a current pace and a current speed of the user; and means, adapted to be supported by the user while the user is in locomotion on foot, for, after the user has traveled a portion of a particular distance, determining a projected time that it will take the user to travel the particular distance based upon the one of the current pace and the current speed of the user, and the portion of the particular distance already traveled by the user.</p>
    <p>According to another aspect of the invention, a system includes means, adapted to be supported by a user while the user is in locomotion on foot, for determining a distance traveled by the user while the user is in locomotion on foot; means, adapted to be supported by the user while the user is in locomotion on foot, for providing an indication to the user, during at least one first distance interval during an outing, that the user should be running; and means, adapted to be supported by the user while the user is in locomotion on foot, for providing an indication to the user, during at least one second distance interval during the outing, that the user should be walking.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is an illustration of various components of an activity monitoring system mounted to a user's body in accordance with one embodiment of the present invention;</p>
    <p>FIGS. 2A and 2B show perspective and side views, respectively, of an example embodiment of the foot-mounted unit of the activity monitoring system shown in FIG. 1;</p>
    <p>FIGS. 3A and 3B show perspective cutaway and side views, respectively, of an example embodiment of the wrist-mounted unit of the activity monitoring system shown in FIG. 1;</p>
    <p>FIG. 4 is a block diagram of various electronic components that may be included in the foot-mounted and wrist-mounted units of FIGS. 1-3 in accordance with one embodiment of the invention;</p>
    <p>FIG. 5 is a block diagram of an example of an accelerometer-based sensor that may be employed in the foot-mounted unit of FIGS. 1, <b>2</b>, and <b>4</b> in accordance with one embodiment of the invention;</p>
    <p>FIG. 6 is a partial-schematic, partial-block diagram of the sensor and processor of the foot-mounted unit shown in FIGS. 4 and 5 in accordance with one embodiment of the invention;</p>
    <p>FIG. 7 is a graph showing a typical output signal of a sensor such as that shown in FIGS. 4-6 and the various characteristics of the signal that may be monitored according to one embodiment of the invention;</p>
    <p>FIG. 8 is a graph showing the linear relationship between the foot contact time (Tc) of a user in locomotion and the pace at which the user is walking or running (Pace);</p>
    <p>FIG. 9 is an illustration of a user in locomotion on foot that demonstrates the relationship between the foot contact time (Tc) of the user, the speed at which the user is walking or running (Speed), and the step length (Ls) of the user;</p>
    <p>FIG. 10 is a graph illustrating the relationship between a user's step length (Ls) and the speed at which the user is walking or running (Speed);</p>
    <p>FIG. 11 is a graph showing the linear relationship between the foot contact time (Tc) of a user in locomotion and the pace at which the user is walking or running (Pace) wherein universal pivot points are identified along the foot contact time (Tc) axis of each of the walking and running lines;</p>
    <p>FIG. 12 is a graph showing the relationship between the speed of a user in locomotion (Speed) and the inverse of the foot contact time of the user (1/Tc) as it would appear if the curve of FIG. 11 were mapped onto the coordinate axes of the graph of FIG. 12;</p>
    <p>FIG. 13 shows a portion of the graph of FIG. 12 (converted to speed units of miles per hour) and illustrates the substantially linear relationship between the speed of the user in locomotion (Speed) and the inverse of the contact time of the user (1/Tc) within a reasonable range of walking or running speeds;</p>
    <p>FIG. 14 is a flow diagram illustrating an example implementation of a primary routine that may be performed by the processor of the foot-mounted unit shown in FIGS. 4 and 6 in accordance with one embodiment of the present invention;</p>
    <p>FIG. 15 is a flow diagram illustrating an example implementation of the wait routine shown in FIG. 14 which causes the routine to wait a predetermined amount of time after detecting a heel-strike event before beginning to look for a toe-off event;</p>
    <p>FIG. 16 is a flow diagram illustrating an example implementation of the process button routine shown in FIG. 15 which implements the functionality of a button that may be disposed on the foot-mounted unit of FIGS. 1, <b>2</b>, and <b>4</b>;</p>
    <p>FIG. 17 is a flow diagram illustrating an example implementation of the toe-off event? routine shown in FIG. 14 wherein it is determined when the foot of a user leaves the ground during a stride taken by the user;</p>
    <p>FIG. 18 is a flow diagram illustrating an example implementation of the determine whether potential lift off occurred routine shown in FIG. 17;</p>
    <p>FIG. 19 is a flow diagram illustrating an example implementation of the air signature? routine shown in FIG. 17;</p>
    <p>FIG. 20 is a graph showing a typical output signal of a sensor such as that shown in FIGS. 5 and 6 when the heel of a user strikes the ground during a stride taken by the user;</p>
    <p>FIG. 21 is a flow diagram illustrating an example implementation of the heel-strike event? routine shown in FIG. 14, wherein it is determined when the foot of a user comes into contact with the ground during a stride taken by a user;</p>
    <p>FIG. 22 is a flow diagram illustrating an example implementation of the are any of landing criteria met? routine shown in FIG. 21;</p>
    <p>FIG. 23 is a flow diagram illustrating an example implementation of the update threshold routine shown in each of FIGS. 17 and 21 which may be used to dynamically update a threshold value for detecting a heel-strike event in response to one or more changing characteristics of the signal output by the sensor of the foot-mounted device shown in FIGS. 4-6;</p>
    <p>FIG. 24 is a flow diagram illustrating an example implementation of the is landing qualified? routine shown in FIG. 21 during which the value of the variable threshold determined in connection with the routine of FIG. 23 is used to qualify a potential heel-strike event identified by the are any of landing criteria met? routine of FIG. 22;</p>
    <p>FIG. 25 is a flow diagram illustrating an example implementation of the check activity routine shown in FIG. 14 during which the foot-mounted unit may be caused to enter a low-power mode or to shut down entirely if little or no activity is detected;</p>
    <p>FIG. 26 is a flow diagram illustrating an example implementation of the smooth and calculate routine shown in FIG. 14 during which values obtained during the primary routine of FIG. 14 may be validated or corrected, and activity-related calculations may be performed using the same;</p>
    <p>FIG. 27 is a timing diagram illustrating the symmetry between the step times of footsteps measured from toe lift-off to toe lift-off and from heel impact to heel impact during strides taken by a user;</p>
    <p>FIG. 28 is a flow diagram illustrating an example implementation of the toe-to-toe &amp; heel-to-heel Ts comparison and correction routine shown in FIG. 26 during which data collected by the foot-mounted unit of FIGS. 1, <b>2</b>, and <b>4</b> may be validated or corrected to ensure that it has the symmetry shown in FIG. 27;</p>
    <p>FIGS. 29A and 29B are graphs illustrating acceptable ranges for the ratios of foot contact times and step times (Tc/Ts) for data accumulated while a user is walking or running;</p>
    <p>FIG. 30 is a flow diagram illustrating an example implementation of the Tc, Ts &amp; Tc/Ts bounds checking routine shown in FIG. 26 during which each measured foot contact time (Tc) and step time (Ts), as well as the ratio of each foot contact time to its corresponding step time (Tc/Ts), may be validated or replaced to ensure that these values fall within the acceptable ranges therefor illustrated in FIGS. 29A-B;</p>
    <p>FIG. 31 is a flow diagram illustrating an example implementation the Tc<sub>AVE </sub>calculation routine shown in FIG. 26 during which an average foot contact time value (Tc<sub>AVE</sub>) over several footsteps taken by the user may be calculated in a manner depending on the rate at which the measured foot contact time (Tc) values are increasing or decreasing;</p>
    <p>FIGS. 32A-H illustrate examples of respective combinations of parameters that may be displayed on the display of the wrist-mounted unit shown in FIGS. 1, <b>3</b>, and <b>4</b> in accordance with one embodiment of the invention;</p>
    <p>FIG. 33A is a graph showing each of speed and stride length as a function of distance for a user running a four hundred meter race;</p>
    <p>FIG. 33B is a graph similar to FIG. 33A except that values of speed and stride length are averaged over fifty meter intervals;</p>
    <p>FIG. 34A is a graph showing each of speed and stride rate as a function of distance for a user running a four hundred meter race;</p>
    <p>FIG. 34B is a graph similar to FIG. 34A except that the values of speed and stride rate are averaged over fifty meter intervals;</p>
    <p>FIG. 35A is a graph showing each of speed and caloric burn rate as a function of distance for a user running a four hundred meter race;</p>
    <p>FIG. 35B is a graph similar to FIG. 35A except that the values of speed and caloric burn rate are averaged over fifty meter intervals;</p>
    <p>FIG. 36A is a graph showing each of speed and acceleration as a function of distance for a user running a four hundred meter race;</p>
    <p>FIG. 36B is a graph similar to FIG. 36A except that the values of speed and acceleration are averaged over fifty meter intervals;</p>
    <p>FIG. 37 is a chart showing various determined performance parameters averaged over fifty meter intervals of a four hundred meter race run by a user;</p>
    <p>FIG. 38 is a graph showing the relationship between pace and step time (Ts) for a user over a reasonable range of walking speeds;</p>
    <p>FIG. 39 is a graph showing the relationship between speed and the inverse of step time (1/Ts) for a user over a reasonable range of walking speeds;</p>
    <p>FIG. 40 is a chart showing the relationship between each of speed and pace of a user and the average ground force exerted by the user while the user is traveling at that speed or pace, as well as accumulated stress values measured per unit distance and per unit time corresponding to that speed or pace of the user; and</p>
    <p>FIG. 41 is a graph showing the relationship between a user's speed and accumulated stress values, measured both per unit time and per unit distance.</p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading> <p>An illustrative embodiment of a system for monitoring activity of a user in locomotion is shown in FIG. <b>1</b>. As shown, the system includes a foot-mounted unit <b>102</b>, a wrist-mounted unit <b>104</b>, and a chest-mounted unit <b>106</b>, all attached to a user <b>112</b> who is in locomotion (i.e., walking or running) on a surface <b>108</b>. In accordance with one aspect of the present invention, the foot-mounted unit <b>102</b> includes a sensor for sensing motion of a foot <b>114</b> of the user <b>112</b>.</p>
    <p>The sensor included in the foot-mounted unit <b>102</b> may be any of a number of devices capable of sensing the motion of the user's foot <b>114</b>, and the invention is not limited to the use of any particular type of sensor. In one illustrative embodiment, for example, the foot-mounted unit <b>102</b> includes a solid-state accelerometer that senses acceleration along an acceleration sensing axis <b>110</b>, as shown in FIG. <b>1</b>. In another embodiment, the sensor includes a low-cost accelerometer such as that disclosed in co-pending patent application Ser. No. 09/382,049, filed Aug. 24, 1999, the entire contents of which are hereby incorporated herein by reference. Other sensors that may be used include, for example, pressure-sensitive resistive switches, piezoelectric transducers, GMR sensors, simple contact switches, mercury switches, or any other devices capable of generating a signal indicative of motion of the foot <b>114</b> of the user <b>112</b> while the user <b>112</b> is in locomotion.</p>
    <p>It should be appreciated that, advantageously, several of the sensors that can be used in the foot-mounted unit <b>102</b> do not require compression forces thereon to sense motion of the foot <b>114</b>, and therefore need not be subjected to the physical wear and tear typically exerted on motion sensors such as pressure-sensitive resistive switches, contact switches, and the like. Because such sensors are not required to be subjected to compression forces to sense motion, they may be located above a bottom surface <b>116</b> of the user's foot <b>114</b>, e.g., on an instep <b>118</b> of the user's shoe or on the user's ankle or waist. Therefore, the sensors included in these types of devices need not be incorporated within or on the sole-portion of a user's shoe, and specially-designed shoes need not be used to accommodate them.</p>
    <p>It should also be appreciated that the foot-mounted unit <b>102</b> may alternatively be mounted at other locations on the body of the user <b>112</b>, and the invention is not limited to embodiments wherein the unit <b>102</b> is mounted on the user's foot <b>114</b>. It is important only that the output of the sensor included in the unit <b>102</b> produces a signal in response to activity of the user <b>112</b> (e.g., movement of the user's foot <b>114</b> ) while the user <b>112</b> is in locomotion. The unit <b>102</b> may, for example, be mounted on the ankle, thigh, waist, chest, etc., of the user <b>112</b> in connection with different embodiments of the invention.</p>
    <p>As shown in FIG. 1, the wrist-mounted unit <b>104</b> may be mounted to a wrist <b>124</b> of the user <b>112</b>. The wrist-mounted unit <b>104</b> may, for example, include a display for displaying information to the user <b>112</b> based upon data accumulated by the foot-mounted unit <b>102</b> and transmitted to the wrist-mounted unit <b>104</b> via a wireless communication link (e.g., over a radio-frequency (RF) network). Communication between the foot-mounted unit <b>102</b> and the wrist-mounted unit <b>104</b> may either be one-way or two-way.</p>
    <p>In one illustrative embodiment, the foot-mounted unit <b>102</b> accumulates and transmits data to the wrist-mounted unit <b>104</b> where it may be used to display, for example, the current pace (or speed) of the user <b>112</b>, as well as the average pace (or speed) of the user <b>112</b>, the energy (e.g., calories) expended by the user <b>112</b>, and the total distance traveled by the user <b>112</b> during a particular time interval. One illustrative technique for calculating energy expenditure based upon one or more measured foot contact time (Tc) values is disclosed in U.S. Pat. No. 5,925,001, which is hereby incorporated herein by reference in its entirety. Examples of these and other information types that may be simultaneously displayed to the user <b>112</b> in this regard are described below in connection with FIG. <b>32</b>.</p>
    <p>It should be appreciated that the wrist-mounted unit <b>104</b> need not be secured to the wrist <b>124</b> of the user <b>112</b>, and may alternatively be disposed elsewhere on the user's body or at a location remote from the user <b>112</b>. For example, in alternative embodiments, the unit <b>104</b> may be a hand-held device that can be carried by or placed in a pocket of the user <b>112</b>, it may be a so-called head's up display incorporated into a pair of sunglasses or the like so as to display information to the user <b>112</b> on an interior surface of the sunglasses, or it may be a wrist-mounted or hand-held device worn or carried by a third person, e.g., a track coach.</p>
    <p>It should further be appreciated that the functionality of the wrist-mounted unit <b>104</b> may alternatively be incorporated into the foot-mounted unit <b>102</b>, so that the foot-mounted unit <b>102</b> may itself display the relevant information to the user <b>112</b>. As still another alternative, the foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b> may simply accumulate data during a given time period that the user <b>112</b> is in locomotion, and may later download the accumulated data to a personal computer or the like for viewing and/or analysis.</p>
    <p>In addition to those described herein, other suitable embodiments of foot-mounted units and wrist-mounted units are described in U.S. Pat. No. 6,018,705, which is hereby incorporated herein by reference in its entirety.</p>
    <p>In the embodiment of FIG. 1, the chest-mounted unit <b>106</b> may, for example, monitor the heart rate of the user <b>112</b>, and transmit information regarding the user's heart rate over a wireless communicator channel (e.g., over an RF network) to the wrist-mounted unit <b>104</b>. In one illustrative embodiment, the foot-mounted unit <b>102</b>, the wrist-mounted unit <b>104</b>, and the chest-mounted unit <b>106</b> are all members of the same RF network so that each of the units <b>102</b>, <b>104</b> and <b>106</b> is capable of communicating with the other members of the network.</p>
    <p>The chest-mounted unit <b>106</b> may be any of a number of devices capable of monitoring a heart rate or other physiological parameter of interest of the user <b>112</b>, and the invention is not limited to any particular type of physiological monitoring device. In some embodiments, for example, the chest-mounted unit <b>106</b> may comprise a commercially-available heart rate monitor such as the type manufactured by Polar Electo Inc. of Woodbury, N.Y., www.polarusa.com, including or modified to include a suitable RF transmitter capable of communicating with the other devices included in the network. In one embodiment, the chest-mounted device <b>106</b> comprises a heart-rate monitor that has sufficient intelligence to analyze the a signal indicative of the user's heartbeat and to calculate a numerical value representing the user's current heart rate, rather than merely outputting a raw signal in response to detected heartbeats. In this manner, processing power of the wrist-mounted unit <b>104</b> or other device that receives data from the heart-rate monitor is not consumed in performing these functions.</p>
    <p>It should be appreciated that it is not critical that the unit <b>106</b> be mounted to the chest of the user <b>112</b>, and that, in alternative embodiments of the invention, the unit <b>106</b> may instead be mounted to other portions of the user's body where it may sense the physiological parameter of interest. The functionality of the chest-mounted unit <b>106</b> may even be incorporated into either the foot-mounted unit <b>102</b> or the wrist-mounted unit <b>102</b> in alternative embodiments. For example, the foot-mounted unit <b>102</b> or the wrist-mounted unit <b>104</b> may itself include a transducer capable of sensing the heart rate of the user <b>112</b>. An example of a transducer capable of performing this function is a fluid-filled bladder having a sonic transducer associated therewith that monitors audio signals sensed through the fluid in the bladder. An example of such a device is described in U.S. Pat. No. 5,853,005, which is hereby incorporated herein by reference in its entirety.</p>
    <p>With a system such as that shown in FIG. 1, the user <b>112</b> may simultaneously view information on the wrist-mounted unit <b>104</b> regarding his or her heart rate, energy expenditure, current running or walking pace and/or speed, average walking or running pace and/or speed, and distance traveled during a particular outing, or one or more selected ones of the same while the user <b>112</b> is running or walking. Such information has not heretofore been available in this manner to a user in locomotion on foot. As used herein, outing refers to an exercise regime engaged in by a user during which the user is in locomotion on foot, regardless of whether the user is running, walking, jogging, etc.</p>
    <p>FIGS. 2A-2B show, respectively, perspective and side views of an example embodiment of the foot-mounted unit <b>102</b> shown in FIG. <b>1</b>. As shown in FIG. 2A, the foot-mounted unit <b>102</b> may include a housing portion <b>102</b> <i>a </i>and a pedestal portion <b>102</b> <i>b</i>, and the pedestal portion <b>102</b> <i>b </i>may be mounted, for example, to the instep <b>118</b> of the user's foot <b>114</b>. In the illustrative embodiment shown, all of the electronics for the foot-mounted unit <b>102</b> are disposed in the housing portion <b>102</b> <i>a</i>, and the pedestal portion <b>102</b> <i>b </i>includes a lever <b>202</b> which may be depressed to release the housing portion <b>102</b> <i>a </i>from the pedestal portion <b>102</b> <i>b</i>. In this manner, the user <b>112</b> may remove the housing portion <b>102</b> <i>a </i>(and the electronic components included therein) from the pedestal portion <b>102</b> <i>b </i>while the pedestal portion <b>102</b> <i>b </i>remains disposed on the user's shoe (e.g., underneath the shoelaces of the shoe). In this manner, the user <b>112</b> may use the same housing portion <b>102</b> <i>a </i>with two or more different pedestal portions <b>102</b> <i>b </i>disposed on different pairs of shoes, thereby enabling the user <b>112</b> to readily transfer the housing portion <b>102</b> <i>a </i>from one pair of shoes to another. In addition, the user may remove the housing portion <b>102</b> <i>a </i>from the pedestal portion <b>102</b> <i>b </i>(and the shoe) to wash the shoe, or simply for aesthetic reasons. A detailed example of a two-piece, detachable, foot-mounted apparatus that may be used as the foot-mounted unit <b>102</b> is disclosed in co-pending patent application Ser. No. 09/164,654, which is hereby incorporated herein by reference in its entirety. Alternatively, the foot-mounted unit <b>102</b> may be secured to the user's shoelaces or elsewhere using an elastic cord or the like. An example of such a foot-mounted unit <b>102</b>, which may be secured to a shoelace, is disclosed in co-pending patent application Ser. No. 09/521,073, which is hereby incorporated herein by reference in its entirety.</p>
    <p>FIGS. 3A and 3B show, respectively, perspective and side views of an example embodiment of the wrist-mounted unit <b>104</b> shown in FIG. <b>1</b>. FIG. 3B shows the wrist-mounted unit <b>104</b> as it may appear when mounted to the wrist <b>124</b> (shown in cross-section) of the user <b>112</b>. In the illustrative embodiment shown, the wrist-mounted unit <b>104</b> includes a housing <b>302</b>, and a strap <b>304</b> for securing the housing <b>302</b> to the wrist <b>124</b>. As shown, the housing <b>302</b> may include a display face <b>308</b> on which information may be displayed to the user <b>112</b>. The housing <b>302</b> may also have a plurality of buttons <b>306</b> <i>a-e </i>disposed thereon to enable the user to implement the functionality of circuitry (described below in connection with FIG. 4) included in the housing <b>302</b>.</p>
    <p>Referring to FIG. 3B, it is illustrated how the housing <b>302</b> may be configured so as to be ideally suited, in an ergonomic sense, for a runner or walker. Characters (e.g., ASCII characters) may be displayed on the display face <b>308</b> such that tops of and bottoms of the characters correspond, respectively, to a top edge <b>310</b> and a bottom edge <b>312</b> of the display face <b>308</b>. As shown in FIG. 3B, the display face <b>308</b> (which is oriented in the plane P<sub>a</sub>) may be tilted at an acute (i.e., between 0-90 ) angle <sub>f </sub>with respect to a plane P<sub>b </sub>(which passes through a widest portion of the wrist <b>124</b> and extends through the forearm of the user <b>112</b>). When tilted in this manner, the display face <b>308</b> may be readily viewed by the user <b>112</b> without requiring the user <b>112</b> to tilt his or her wrist at an angle that is awkward for the user <b>112</b> when the user <b>112</b> is running or walking. In addition, in the FIG. 3 embodiment, each of the buttons <b>306</b> is disposed substantially in a plane P<sub>c </sub>(the button plane) which is oriented substantially perpendicular to a direction in which the buttons <b>306</b> are depressed during normal operation. As shown in FIG. 3B, the button plane P<sub>c </sub>may also be tilted at an acute angle <sub>g </sub>with respect to the plane P<sub>c </sub>so as to make the buttons <b>306</b> more easily accessible to the user <b>112</b> when the user <b>112</b> is walking or running.</p>
    <p>The manner in which the display face <b>308</b> of the wrist-mounted unit <b>104</b> is tilted may be defined with reference to a pair of lines L<sub>1 </sub>and L<sub>2 </sub>shown in FIG. <b>3</b>B. As shown, each of the lines L<sub>1 </sub>and L<sub>2 </sub>is oriented normal to (i.e., perpendicular with respect to) a surface <b>314</b> of the user's wrist <b>124</b>. The line L<sub>1 </sub>intercepts the top edge <b>310</b> of the display face <b>308</b>, and the line L<sub>2 </sub>intercepts the bottom edge <b>312</b> of the display face <b>308</b>. In the embodiment of FIG. 3B, a distance d<b>1</b> (measured along the line L<sub>1</sub>) between the surface <b>314</b> of the user's wrist <b>124</b> and the upper edge <b>310</b> of the display face <b>308</b> is substantially greater than a distance d<b>2</b> (measured along the line L<sub>2</sub>) between the surface <b>314</b> of the user's wrist <b>124</b> and the bottom edge <b>312</b> of the display face <b>308</b>. The distance d<b>1</b> may, for example, be 5%, 10%, 25%, 50%, 100%, 200%, 300%, or more greater than the distance d<b>2</b>. Any of a number of other ratios between the distances d<b>1</b> and d<b>2</b> also are possible, and the invention is not limited to any particular ratio between these distances.</p>
    <p>The manner in which the display face <b>308</b> of the wrist-mounted unit <b>104</b> is tilted may also be defined in terms of the respective relationships between the lines L<sub>1 </sub>and L<sub>2 </sub>and a pair of lines L<sub>3 </sub>and L<sub>4 </sub>shown in FIG. <b>3</b>B. As shown, each of the lines L<sub>3 </sub>and L<sub>4 </sub>is oriented normal to the plane P<sub>a </sub>in which the display face <b>308</b> is disposed. The line L<sub>3 </sub>passes through the top edge <b>310</b> of the display face <b>308</b> and the line L<sub>4 </sub>passes through the bottom edge <b>312</b> of the display face <b>308</b>. As illustrated, assuming the lines L<sub>1 </sub>and L<sub>2 </sub>intercept the lines L<sub>3 </sub>and L<sub>4</sub>, respectively, the line L<sub>1 </sub>forms an angle <sub>a </sub>with respect to the line L<sub>3</sub>, and the line L<sub>2 </sub>forms an angle <sub>b </sub>with respect to the line L<sub>4</sub>. When the angles <sub>a </sub>and <sub>b </sub>in FIG. 3B are measured in a clockwise direction beginning with the lines L<sub>3 </sub>and L<sub>4</sub>, respectively, each of the angles <sub>a </sub>and <sub>b </sub>is acute (i.e., between 0-90). This may be compared to prior art wrist-watch configurations wherein the plane P<sub>a </sub>in which the display face <b>308</b> is disposed typically is parallel to the plane P<sub>b </sub>of the user's wrist <b>124</b>. In such prior art devices, the angle <sub>a </sub>(when measured as discussed above) is slightly greater than 0, and the angle <sub>b </sub>is slightly less than 360. Therefore, in a typical prior art wrist-watch, only the angle <sub>a</sub>, and not the angle <sub>b</sub>, (when measured as discussed above) is between 0-90.</p>
    <p>Similar to the plane P<sub>a </sub>in which the display face <b>308</b> is disposed, the manner in which the button plane P<sub>c </sub>of the wrist-mounted unit <b>104</b> is tilted may be defined with reference to a pair of lines L<sub>5 </sub>and L<sub>6 </sub>shown in FIG. <b>3</b>B. As shown, each of the lines L<sub>5 </sub>and L<sub>6 </sub>is oriented normal to the surface <b>314</b> of the user's wrist <b>124</b>. The line L<sub>5 </sub>intercepts a button in the button plane P<sub>c </sub>that is closest to the display face <b>308</b> (e.g., the button <b>306</b> <i>a </i>of FIG. <b>3</b>A), and the line L<sub>6 </sub>intercepts a button in the button plane P<sub>c </sub>that is farthest away from the display face <b>308</b> (e.g., the button <b>306</b> <i>e </i>of FIG. <b>3</b>A).</p>
    <p>In the embodiment of FIG. 3B, a distance d<b>3</b> (measured along the line L<sub>5</sub>) between the surface <b>314</b> of the user's wrist <b>124</b> and the button <b>306</b> closest to the display face <b>308</b> is substantially greater than a distance d<b>4</b> (measured along the line L<sub>6</sub>) between the surface <b>314</b> of the user's wrist <b>124</b> and the button <b>306</b> farthest away from the display face <b>308</b>. The distance d<b>3</b> may, for example, be 5%, 10%, 25%, 50%, 100%, 200%, 300%, or more greater than the distance d<b>4</b>. Any of a number of other ratios between the distances d<b>3</b> and d<b>4</b> also are possible, and the invention is not limited to any particular ratio between these distances.</p>
    <p>The manner in which the button plane P<sub>c </sub>of the wrist-mounted unit <b>104</b> is tilted may also be defined in terms of the respective relationships between the lines L<sub>5 </sub>and L<sub>6 </sub>and a pair of lines L<sub>7 </sub>and L<sub>8 </sub>shown in FIG. <b>3</b>B. As shown, each of the lines L<sub>7 </sub>and L<sub>8 </sub>is oriented normal to the button plane P<sub>c</sub>. The line L<sub>7 </sub>passes through the button <b>306</b> disposed closest to the display face <b>308</b>, and the line L<sub>8 </sub>passes through the button <b>306</b> disposed farthest away from the display face <b>308</b>. As illustrated, assuming the lines L<sub>5 </sub>and L<sub>6 </sub>intercept the lines L<sub>7 </sub>and L<sub>8</sub>, respectively, the line L<sub>5 </sub>forms an angle <sub>c </sub>with respect to the line L<sub>7</sub>, and the line L<sub>6 </sub>forms an angle <sub>d </sub>with respect to the line L<sub>8</sub>. When the angles <sub>c </sub>and <sub>d </sub>in FIG. 3B are measured in a clockwise direction beginning with the lines L<sub>5 </sub>and L<sub>6</sub>, respectively, each of the angles <sub>c </sub>and <sub>d </sub>is acute (i.e., between 0-90). This is in contrast to prior art wrist watches wherein functional buttons are disposed in planes that are oriented so that at least one of the angles <sub>c </sub>and <sub>d </sub>(when measured as discussed above) is either exactly 90 (e.g., when buttons are disposed on the side of a watch) or greater than 90 (e.g., when buttons are disposed on a watch's face).</p>
    <p>Also shown in FIG. 3B is an angle <sub>e </sub>measured between the plane P<sub>a </sub>in which the display face <b>308</b> is disposed and the button plane P<sub>c</sub>. The angle <sub>e </sub>may be any of a number of suitable angles, depending on the desired ergonomic characteristics of the wrist-mounted unit <b>104</b>. For example, the angle <sub>e </sub>may be acute as shown in FIG. 3B, it may be a perfect right angle, or it may be obtuse (i.e., greater than 90).</p>
    <p>FIG. 4 shows a block diagram of various electronic components that may be disposed in each of the units <b>102</b> and <b>104</b> in accordance with one illustrative embodiment of the invention. It should be appreciated, however, that the circuitry within each of the wrist-mounted unit <b>104</b> and the foot-mounted unit <b>102</b> may take on any of a number of alternative configurations, and the invention is not limited to the particular circuitry or components described herein for performing the various functions. Also shown in FIG. 4 are additional components of a network system that may be employed in connection with an embodiment of the invention. In particular, the system of FIG. 4 further includes a computer <b>428</b> and a network server <b>442</b>, each coupled to a network cloud <b>440</b>.</p>
    <p>As shown, the foot-mounted unit <b>102</b> may include a processor <b>422</b>, as well as a sensor <b>418</b>, a user interface <b>416</b>, a transceiver <b>420</b>, and a memory <b>424</b> coupled to the processor <b>422</b>. The wrist-mounted unit <b>104</b>, may include both a user interface (UI) processor <b>408</b> and an arithmetic, radio, and calibration (ARC) processor <b>410</b>, as well as memories <b>402</b> and <b>404</b> (coupled to the UI processor <b>408</b> and the ARC processor <b>410</b>, respectively), a user interface <b>406</b> (coupled to the UI processor <b>408</b> ), a display <b>412</b> (coupled to the UI processor <b>408</b> ), and a transceiver <b>414</b> (coupled to the ARC processor <b>410</b>). The computer <b>428</b> may include a processor <b>430</b>, a memory <b>432</b>, a transceiver <b>434</b>, a user interface <b>436</b>, and a display <b>438</b>. In one embodiment, the computer <b>428</b> is a personal computer (PC) to which the user <b>112</b> has access. The network server <b>442</b> is configured to communicate (via the network cloud <b>440</b>) with the computer <b>428</b>, as well as with a number of other computers similar the computer <b>428</b>.</p>
    <p>Each of the processors <b>408</b>, <b>410</b>, <b>422</b>, and <b>430</b> in the FIG. 4 embodiment may be any processor, controller, hard wired circuit, or the like that is capable of performing at least some of the functions discussed herein, and the invention is not limited to the use of any particular types of processors. In addition, in alternative embodiments, the functionality of each of the processors shown in FIG. 4 may be performed by one or more of the other processors shown and/or may be distributed across one or more additional processors. In addition, the functionality of the UI and ARC processors <b>408</b> and <b>410</b> may be implemented using only a single processor. In one embodiment, the UI processor <b>408</b> may comprise, for example, part number NSM63188, manufactured by OKI Electronics; the ARC processor <b>410</b> may comprise, for example, part number PIC16C63, manufactured by Microchip, Inc.; and the processor <b>422</b> may comprise, for example, part number PIC16C73, manufactured by Microchip, Inc.</p>
    <p>The network cloud <b>440</b> may, for example, represent the Internet. Of course, it may alternatively represent any other network scheme. The network server <b>442</b> and the computer <b>428</b> therefore may communicate with one another, and share data and responsibility for various functional attributes with one another in any manner known in the art. In one embodiment, the network server <b>442</b> serves as an application service provider for the computer <b>428</b>. It should be appreciated, however, that such a configuration is not critical, as the network server <b>442</b> may likewise serve solely as a repository for the storage and retrieval of information. User-specific information stored on the network server <b>442</b> may be accessed, for example, using a user-specific (identification) ID. Access to this information may also require a password or successful implementation of some other security measure.</p>
    <p>The user interface <b>406</b> may correspond, for example, to the buttons <b>306</b> shown in FIGS. 3A-B, and the user interface <b>416</b> may correspond, for example, to the button <b>204</b> shown in FIG. <b>2</b>A. It should be appreciated, however, that the invention is not limited in this respect, and that different, fewer, or additional user interface buttons or other suitable user-interface devices or circuitry (e.g., voice activated interface devices) may alternatively be employed. The memories <b>402</b>, <b>404</b>, <b>424</b>, and <b>432</b> may each store a plurality of instructions which, when executed by the processor coupled thereto, may perform one or more of the routines described below. The structure and capabilities of the various components of the computer <b>428</b> (i.e., the processor <b>430</b>, memory <b>432</b>, user interface <b>436</b>, and display <b>438</b>), as well as the network server <b>442</b>, are well understood in the art, and therefore will not be described in further detail.</p>
    <p>As discussed above, the sensor <b>418</b> in the foot-mounted unit <b>102</b> may be any of a number of devices capable of monitoring the motion of the user's foot <b>114</b> to determine, for example, time periods that the user's foot <b>114</b> is in contact with the ground or is in the air. In one illustrative embodiment, a sensor which does not require compression forces thereon to sense motion is employed so as to reduce the wear and tear on the sensor <b>418</b>. Because it is not necessary for such a sensor to be disposed between the bottom surface <b>116</b> of the user's foot <b>114</b> and the surface <b>108</b> on which the user <b>112</b> is walking or running, the entire foot-mounted unit <b>102</b> (including the sensor <b>418</b>) may be mounted above the bottom surface <b>116</b> of the user's foot <b>114</b>. For example, the entire foot-mounted unit <b>102</b> may be mounted on the instep <b>118</b> of the user's foot <b>114</b> as shown in FIG. <b>1</b>.</p>
    <p>In such an embodiment, the foot-mounted unit may readily be disposed on prefabricated footwear (e.g., a running shoe), and specialized footwear having one or more sensors disposed so as to be located underneath the user's foot <b>114</b> need not be employed. It should be appreciated, however, that the invention is not limited in this respect, and that sensors such as contact switches, piezoelectric, pressure sensitive transducers, or the like, that are disposed between the user's foot <b>114</b> and the surface <b>108</b> to sense motion of the user's foot <b>114</b> with respect to the surface <b>108</b> may be employed in some embodiments of the invention.</p>
    <p>As discussed below in more detail, an output signal from the sensor <b>418</b> may be provided to the processor <b>422</b>, and the processor <b>422</b> may analyze the received signal in accordance with an algorithm stored in the memory <b>424</b>. Data generated by the processor <b>422</b> in response to this analysis, may be transmitted by the transceiver <b>420</b> (e.g., over an RF communication channel) to the transceiver <b>414</b> of the wrist-mounted unit <b>104</b>. It should be appreciated, of course, that other wireless transmission media may alternatively be employed, and the invention is not limited to the use of an RF communication channel as the wireless communication link between the units <b>102</b> and <b>104</b>. It should also be appreciated that, in some embodiments of the invention, the transceiver <b>420</b> may comprise only a transmitter and the transceiver <b>414</b> may comprise only a receiver, and that the invention is not limited to embodiments wherein transceivers are employed in both units.</p>
    <p>When information from the foot-mounted unit <b>102</b> is received by the transceiver <b>414</b> of the wrist-mounted unit <b>104</b>, this information may be processed by the ARC processor <b>410</b> to calculate various parameters to be displayed to the user <b>112</b> on the display <b>412</b>. Any of a number of parameters may be calculated based upon the information received from the foot-mounted unit <b>102</b>, and the invention is not limited to the calculation of any particular parameters. In one illustrative embodiment, the ARC processor <b>410</b> is responsible for calculating both the instantaneous and average pace of the user <b>112</b>, the distance traveled and calories expended by the user <b>112</b> during a given period, and the total time interval during which the distance, pace, and calorie measurements are calculated (i.e., a chronograph). In alternative embodiments, one or more of these parameters may instead be calculated by processor <b>422</b> of the foot-mounted unit <b>102</b>, and the pre-calculated values may then be passed to the wrist-mounted unit <b>104</b>.</p>
    <p>After the ARC processor <b>410</b> calculates or receives the aforementioned parameters, the calculated parameters may be passed to the UI processor <b>408</b> which is responsible for displaying them on the display <b>412</b>. The UI <b>408</b> processor may also perform standard time and date keeping functions, and may display time and date information on the display <b>412</b> either along with, or separately from, the parameters received from the ARC processor <b>410</b>.</p>
    <p>By properly manipulating the user-interface <b>406</b> (e.g., by pushing selected ones of the buttons <b>306</b> <i>a-e</i>), the user <b>112</b> may, for example, start or stop the time period during which data received from the foot-mounted unit <b>102</b> is accumulated, may alter the display modes of the UI processor <b>408</b>/display <b>412</b>, or may otherwise enable the user <b>112</b> to control of the functionality of the UI processor <b>408</b> and/or the ARC processor <b>410</b>.</p>
    <p>As shown, the transceiver <b>420</b> and/or the transceiver <b>414</b> may also communicate with the transceiver <b>434</b> of the computer <b>428</b> via a wireless communication link. As discussed below in more detail, this communication link enables information to be downloaded from the wrist-mounted unit <b>104</b> and/or the foot-mounted unit <b>102</b> to the computer <b>428</b>, and possibly, in turn, to the network server <b>428</b>. This communication link also enables the user <b>112</b> to operate software running on the computer <b>428</b> and/or network server <b>442</b> to analyze received data and/or to select operating parameters for the wrist-mounted unit <b>104</b> and/or foot-mounted unit <b>102</b>, which parameters then may be transmitted to those devices via the transceiver <b>434</b>.</p>
    <p>As discussed below in more detail, the parameters calculated by the wrist-mounted unit <b>104</b> and/or the foot-mounted unit <b>102</b>, as well as parameters calculated by or calculated in response to a signal from the chest-mounted unit <b>106</b>, may be analyzed in various ways so as to provide feedback to the user during or after an exercise session by the user. During an exercise session, such analysis may be performed by the processor(s) in the foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b>, and feedback may be provided to the user by either device. For example, the user may receive a textual message on the display <b>412</b>, may receive an audio, vibrational, or visual (e.g., a light) alert via the user interface <b>406</b> or the user interface <b>416</b>, or may receive any other indication responsive to one or more identified characteristics in analyzed data. As used herein, the phrase indication to the user refers to the output provided by any one or any combination of these user-feedback methods or any other user-feedback method known in the art.</p>
    <p>The system of FIG. 4 may be designed such that multiple users (e.g., multiple family members or track team members) may employ the same equipment, but so that user-specific data and operating parameters may be selectively stored and accessed. This may be accomplished, for example, by requiring each user to input a particular ID code or name, or to select an appropriate ID code or name from a list thereof, and permitting access to or logging information and parameters based upon that ID code or name. The ID code or name may, for example, be entered or selected using any of the devices in the system, and then may be transmitted, if necessary, to the other devices.</p>
    <p>FIG. 5 shows an illustrative example of a motion sensor that may be employed as the sensor <b>418</b> in the FIG. 4 embodiment. In the example shown, the sensor <b>418</b> includes an accelerometer <b>502</b>, and an amplifier circuit <b>504</b> (including a high-pass filter <b>504</b> <i>a </i>integrated therein). The accelerometer <b>502</b> may comprise any of numerous devices or circuits capable of detecting acceleration of the user's foot <b>114</b> and producing an output signal in response thereto, and the invention is not limited to the use of any particular type of accelerometer. In one illustrative embodiment, for example, the accelerometer <b>502</b> comprises part number ADXL250, manufactured by Analog Devices, Inc. Again, as mentioned above, it should be appreciated that the invention is not limited to embodiments that employ an accelerometer as the sensor <b>418</b>, and that other suitable devices may alternatively be used.</p>
    <p>FIG. 6 shows a partial-schematic, partial-block diagram of an example embodiment of the sensor <b>418</b> of FIGS. 4 and 5, in addition to the processor <b>422</b> of FIG. <b>4</b>. As shown in FIG. 6, the, amplifier circuit <b>504</b> may include a capacitor C<b>1</b>, resistors R<b>1</b>-R<b>4</b>, and an operational amplifier A. The operational amplifier A may, for example, comprise part number MA418, manufactured by MAXIM, Inc.</p>
    <p>In the example embodiment of FIG. 6, the resistor R<b>1</b> is connected between the input capacitor C<b>1</b> and the inverting input of the operational amplifier A, and the resistor R<b>2</b> is connected in feedback between the inverting input and an output <b>606</b> of the operational amplifier A. The combination of the input capacitor C<b>1</b> and the resistor R<b>1</b> form a high-pass filter, and the configuration of the resistors R<b>1</b> and R<b>2</b> place the amplifier circuit <b>504</b> in an inverting configuration with a gain-factor dependent on the relative values of the resistors R<b>1</b> and R<b>2</b>. In the embodiment shown, the resistor R<b>2</b> has a value of 1 mega-ohm, and the resistor R<b>2</b> has a value of 150 kill-ohms, so that the gain factor of the amplifier circuit <b>504</b> is approximately (6.6). In addition, in the embodiment shown, the capacitor C<b>1</b> has a value of 0.15 microfarads, so that the high-pass filter section <b>504</b> <i>a </i>of the amplifier circuit <b>504</b> cuts off input signal frequencies that are less than approximately 7.07 hertz.</p>
    <p>In the FIG. 6 embodiment, the resistor R<b>3</b> is connected between a VCC supply node <b>610</b> and the non-inverting input of the operational amplifier A, and the resistor R<b>4</b> is connected between the non-inverting input of the operational amplifier A and a ground node <b>612</b> of the circuit. The VCC supply node <b>610</b> may be maintained at approximately 5 volts (e.g., regulated from a six-volt battery) in relation to the ground node <b>612</b>, and the resistors R<b>3</b> and R<b>4</b> may be of equal values (e.g., 50 kill-ohms each) so that the voltage at a node <b>608</b> between the resistors R<b>3</b> and R<b>4</b>, which is connected to the non-inverting input of the amplifier A, is maintained approximately midway between the voltage at the VCC supply node <b>610</b> and the ground node <b>612</b> (e.g., at approximately 2.5 volts). It should be appreciated, of course, that any other suitable supply voltage (e.g., 3 volts) may alternatively be applied between the VCC supply node <b>610</b> and the ground node <b>612</b>, and that the invention is not limited to the use of a 5 volt supply.</p>
    <p>As shown in FIG. 6, the node <b>608</b> is also coupled to a reference input <b>604</b> of the processor <b>422</b>, and the output <b>606</b> of the operational amplifier A is connected to a signal input <b>602</b> of the processor <b>422</b>. In one embodiment, the processor <b>422</b> includes on-board memory, A/D converters, and timers. Therefore, in such an embodiment, the memory <b>424</b> of the embodiment of FIG. 4 may be incorporated into the same micro-chip as the processor <b>422</b>. It should be appreciated, however, that the invention is not limited in this respect, and that any of the above-noted on-board elements may alternatively be employed external to the controller <b>422</b>.</p>
    <p>In the circuit of FIG. 6, when the VCC supply node <b>610</b> is maintained at five volts, the input <b>604</b> of the processor <b>422</b> may serve as a zero-reference that is maintained at approximately 2.5 volts (as described above), and the input <b>602</b> of the processor <b>422</b> may serve as a variable input that fluctuates between 0 and 5 volts. The processor <b>422</b> may, for example, sample the voltage at each of the inputs <b>602</b> and <b>604</b> at a rate of approximately 500 samples per second, and convert each of these samples into a respective 8-bit unsigned digital value. Therefore, for each sample taken at the inputs <b>602</b> and <b>604</b>, the voltage at each of these inputs, with reference to a digital ground input (not shown) of the processor <b>422</b>, will be converted to a level between 0 and 255.</p>
    <p>Because of the voltage division performed by the resistors R<b>3</b> and R<b>4</b>, each sample taken at the input <b>604</b> remains close to the level 128 of the 255 possible levels. Each sample taken at the input <b>602</b> fluctuates between the level 0 and the level 255 depending on the voltage generated by the accelerometer <b>502</b> in response to acceleration thereof. A positive acceleration of the accelerometer <b>502</b> along the acceleration sensing axis <b>110</b> may, for example, cause the sample taken at the input <b>604</b> to be some level between the levels 129 and 255, whereas a negative acceleration of the accelerometer <b>502</b> along the acceleration sensing axis <b>110</b> (see FIGS. 1 and 2B) may, for example, cause the sample taken at the input <b>604</b> to be some level between the levels 0 and 127.</p>
    <p>FIG. 7 shows an example of signals <b>712</b> and <b>710</b> that may be provided by the sensor <b>418</b> of FIG. 6 to the inputs <b>602</b> and <b>604</b>, respectively, of the processor <b>422</b> when the user <b>112</b> is in locomotion on foot. As shown, the signal <b>710</b> may be converted by the processor <b>422</b> into a digital value of approximately 128 on the scale of 0 to 256. It should be appreciated that, due to the voltage division performed by the resistors R<b>3</b> and R<b>4</b>, the voltage at the input <b>604</b> may change slightly in response to changes in the voltage at the VCC supply node <b>610</b>. The level of the sample taken at the input <b>604</b> may therefore deviate slightly from the level 128 when such changes in the supply voltage occur.</p>
    <p>As also shown in FIG. 7, the signal <b>712</b> may fluctuate dynamically between the level 0 and the level 256 in response to movement of the user's foot <b>114</b> that occur when the user is walking or running. When the level of the signal <b>712</b> is greater than the level of the signal <b>710</b>, this indicates that the accelerometer is sensing a positive acceleration along the acceleration sensing axis <b>110</b>, and when the level of the signal <b>712</b> is lower than the level of the signal <b>710</b>, this indicates that the accelerometer <b>502</b> is sensing a negative acceleration along the acceleration axis <b>110</b>.</p>
    <p>In accordance with various aspects of the present invention, the signals <b>710</b> and <b>712</b> generated during strides taken by the user <b>112</b> may be analyzed, and particular characteristics of the signals <b>710</b> and <b>712</b> may be identified which are indicative of particular occurrences during each footstep. As shown in FIG. 7, for example, the signals <b>710</b> and <b>712</b> may be analyzed: (1) to identify occasions when the user's toe first leaves the surface <b>108</b> after having been in contact with the ground during a footstep (e.g., toe-off events <b>704</b> <i>a </i>and <b>704</b> <i>b</i>), and (2) to identify occasions when the user's heel first impacts the ground after having been airborne (e.g., heel-strike events <b>702</b> <i>a </i>and <b>702</b> <i>b</i>). When the user <b>112</b> is wearing shoes, the term toe, as used herein, refers to the front-most portion of the user's shoe that accommodates the user's toes, and the term heel, as used herein, refers to the rear-most portion of the user's shoe that accommodates the user's heel.</p>
    <p>In accordance with one aspect of the invention, the toe-off events <b>704</b> may be identified by monitoring the signals <b>710</b> and <b>712</b> for: (a) characteristics that indicate a toe-off event <b>704</b> may have potentially occurred, and (b) characteristics that indicate the foot <b>114</b> is definitely airborne (i.e., when no portion of the foot <b>114</b> is in contact with the surface <b>108</b>). The latter characteristics are referred to herein as the signal's air signature <b>706</b>.</p>
    <p>One characteristic in the signals <b>710</b> and <b>712</b> that may be indicative of a potential toe-off event is large inflection in the signal <b>712</b>. Therefore, in one embodiment of the invention, inflections in the signal <b>712</b> are monitored to identify and to continuously update the identification of a largest inflection to occur in the signal <b>712</b> subsequent to the most recent heel-strike event <b>702</b>.</p>
    <p>As shown in FIG. 7, an air signature <b>706</b> of the signal <b>712</b> may be identified between each toe-off event <b>704</b> and the subsequent heel-strike event <b>702</b>. The air signature <b>706</b> may, for example, be an identified period of relative smoothness in the signal <b>712</b>. When it is determined that the foot <b>114</b> is airborne (e.g., an air signature <b>706</b> is identified), the most recently identified potential toe-off event is identified as an actual toe-off event <b>704</b>. An example of a routine that may be performed by the processor <b>422</b> to monitor the signals <b>710</b> and <b>712</b> to identify occurrences of actual toe-off events <b>704</b> by looking for potential toe-off events and air signatures <b>706</b> in the signals is described below in connection with FIGS. 17-19.</p>
    <p>In accordance with another aspect of the invention, heel-strike events <b>702</b> may be identified by monitoring the signals <b>710</b> and <b>712</b> for sudden, sharp inflections following the relatively smooth condition of the signal <b>712</b> generated while the foot is airborne. In accordance with one embodiment of the invention, characteristics of the signals <b>710</b> and <b>712</b> are monitored to determine whether the signals satisfy at least one of a plurality of predetermined criteria consistent with the occurrence of a heel-strike event <b>702</b>. An example of a routine that may be performed by the processor <b>422</b> to monitor the signals <b>710</b> and <b>712</b> for heel-strike events <b>702</b> in this manner is described below in connection with FIGS. 21, and <b>23</b>-<b>25</b>.</p>
    <p>As shown in FIG. 7, the period of a complete footstep of the user <b>112</b> (i.e., a step time (Ts)) may be measured between the identified heel-strike events <b>702</b> of the user <b>112</b> (e.g., between the heel-strike events <b>702</b> <i>a </i>and <b>702</b> <i>b</i>). The portion of each measured step time (Ts) during which the user's foot <b>114</b> is in contact with the surface <b>108</b> (i.e., a foot contact time (Tc)) may be measured between each detected heel-strike event <b>702</b> and a subsequently-detected toe-off event <b>704</b> (e.g., between the heel-strike <b>702</b> <i>a </i>and the toe-off <b>704</b> <i>a</i>). Finally, the portion of each measured step time (Ts) during which the user's foot <b>114</b> is airborne (i.e., a foot air time (Ta)) may be measured between each detected toe-off event <b>704</b> and a subsequently-detected heel-strike event <b>702</b> (e.g., between the toe-off <b>704</b> <i>a </i>and the heel-strike <b>702</b> <i>b</i>). Thus, for each complete footstep taken by the user <b>112</b>, an accurate measurement may be made of each step time (Ts) of the user <b>112</b>, as well as the portions of that step time (Ts) attributable to foot contact time (Ts) and foot air time (Ta). As discussed in more detail below, this information may be used by the processor <b>422</b> or the foot-mounted unit <b>102</b> and/or the ARC processor <b>410</b> of the wrist-mounted unit <b>104</b> to accurately calculate the speed and/or pace of the user <b>112</b>, the distance traveled by the user <b>112</b>, the energy expended by the user <b>112</b>, etc., during the corresponding footstep taken by the user <b>112</b>.</p>
    <p>As used herein, a complete footstep means a movement cycle during which the foot of a user <b>112</b> begins in a particular position and again returns to that same position. For example, complete footsteps of the user <b>112</b> may be measured between consecutive heel-strike events (i.e., occasions when the user's heel <b>120</b> impacts the surface <b>108</b>), or between consecutive toe-off events (i.e., occasions when the user's toe <b>122</b> leaves the surface <b>108</b>).</p>
    <p>After each heel-strike event <b>702</b> (e.g., the heel-strike event <b>702</b> <i>a</i>), we have recognized that the foot <b>114</b> of the user <b>112</b> will necessarily be on the ground for at least a minimum period of time, and that it is not necessary during this period of time to analyze the signals <b>710</b> and <b>712</b> to identify potential occurrences of a toe-off event <b>704</b>. Therefore, as shown in FIG. 7, it is possible to ignore the signals during this particular period of time. These periods during which the signals <b>710</b> and <b>712</b> may be ignored are illustrated in FIG. 7 as ignore times <b>708</b> <i>a </i>and <b>708</b> <i>b. </i> </p>
    <p>In accordance with another aspect of the invention, radio transmissions between the foot-mounted unit <b>102</b> and the wrist-mounted unit <b>104</b> may be made only during the ignore times <b>708</b> because the processor <b>422</b> need not be employed to monitor the signals <b>710</b> and <b>712</b> during these time periods. Similarly, according to another aspect of the invention, calculations involving data accumulated by the foot-mounted unit <b>102</b> may be made only during the ignore times <b>708</b>, thereby consuming processing power only during time periods when the signals <b>710</b> and <b>712</b> need not be actively analyzed.</p>
    <p>It is known that the instantaneous pace (Pace<sub>INST</sub>) of a user <b>112</b> in locomotion is linearly related to the foot contact time (Tc) measured during a single footstep (Tc<sub>FS</sub>) of the user <b>112</b>. In particular, the instantaneous pace of the user <b>112</b> may be defined by the equation:</p>
    <p>
      <maths> <formula-text>Pace<sub>INST</sub> <i>=Mp*Tc</i> <sub>FS</sub> <i>+Bp,</i>(1)</formula-text> </maths> </p>
    <p>wherein Mp and Bp are constants representing the slope and Y-intercept points of a graph of Pace vs. Tc, and the symbol * is the multiplication operator. In light of this relationship, the average pace of the user during a given time period (Pace<sub>AVE</sub>) may be calculated by replacing the individual foot contact time (Tc<sub>FS</sub>) in the equation (1) with the average value of several individual foot contact times during the measured time period (Tc<sub>AVE</sub>) above to yield the equation:</p>
    <p>
      <maths> <formula-text>Pace<sub>AVE</sub> <i>=Mp*Tc</i> <sub>AVE</sub> <i>+Bp</i>(2)</formula-text> </maths> </p>
    <p>As discussed in U.S. Pat. No. 6,018,705, the constants Mp and Bp may be different when the user <b>112</b> is running than when the user is walking, and each value of Mp and Bp (for both walking or running) may vary from individual to individual. The relationships between Pace and Tc for walking and running (for either instantaneous or average pace calculations) may be represented by the following two equations:</p>
    <p>
      <maths> <formula-text>Pace=<i>Mp</i> <sub>w</sub> <i>*Tc</i> <sub>w</sub> <i>+Bp</i> <sub>w</sub> </formula-text> </maths> </p>
    <p>
      <maths> <formula-text>Pace=<i>Mp</i> <sub>R</sub> <i>*Tc</i> <sub>R</sub> <i>+Bp</i> <sub>R</sub>(3)</formula-text> </maths> </p>
    <p>The graph of FIG. 8 includes lines <b>802</b> and <b>804</b>, which represent the two relationships presented in the equations (3). In particular, the line <b>802</b> represents the relationship between a measured foot contact time (Tc) (either a single value or an average value) of the user <b>112</b> and the corresponding pace (either instantaneous or average) of the user <b>112</b> when the user is walking, and the line <b>804</b> represents the relationship between a measured foot contact time (Tc) of the user <b>112</b> and the corresponding pace of the user <b>112</b> when the user is running. Although linear relationships between foot contact time (Tc) and pace are illustrated in FIG. 8, it should be appreciated that higher-order polynomials may alternatively be used to define these relationships.</p>
    <p>We have discovered that it can be determined whether a user, e.g., the user <b>112</b>, is walking or running during a particular footstep taken by the user <b>112</b>, simply by comparing the foot contact time (Tc) of the user <b>112</b> measured during the footstep with a single threshold value. Therefore, in connection with each measured foot contact time (Tc), it is possible to determine which of the equations represented by the lines <b>802</b> and <b>804</b> should be used to calculate the user's pace simply by comparing the measured foot contact time (Tc) with this threshold value.</p>
    <p>In the example of FIG. 8, the threshold value used to discern whether the user <b>112</b> is walking or running is 420 milliseconds (ms). As shown, the lines <b>802</b> and <b>804</b> are divided into solid portions <b>802</b> <i>a </i>and <b>804</b> <i>a </i>and dashed portions <b>802</b> <i>b </i>and <b>804</b> <i>b</i>. The solid portions <b>802</b> <i>a </i>and <b>804</b> <i>a </i>of the lines <b>802</b> and <b>804</b>, respectively, represent the equations that may be used to calculate the user's pace based upon measured foot contact times. When, for example, a measured foot contact time (Tc) is less than 420 ms, it may be determined that the user <b>112</b> is running, and the solid portion <b>804</b> <i>a </i>of the line <b>804</b> may be used to calculate the user's pace. When, on the other hand, a measured foot contact time (Tc) is greater than 420 ms, it may be determined that the user <b>112</b> is walking, and the solid portion <b>802</b> <i>a </i>of the line <b>802</b> may be used to calculate the user's pace.</p>
    <p>In the example of FIG. 8, the dashed portion <b>802</b> <i>b </i>of the line <b>802</b> is never used to calculate the user's pace while the user <b>112</b> is walking because it corresponds to a range of foot contact times that typically do not occur when the user <b>112</b> is walking. Similarly, the dashed portion <b>804</b> <i>b </i>of the line <b>804</b> is never used to calculate the user's pace while the user <b>112</b> is running because it corresponds to a range of foot contact times that typically do not occur when the user <b>112</b> is running.</p>
    <p>In another embodiment of the invention, for each given footstep, one of: (1) the ratio of the measured foot contact time (Tc) to the measured step time (Ts) (i.e., Tc/Ts); (2) the ratio of the measured foot air time (Ta) to the measured step time (Ts) (i.e., Ta/Ts); or (3) the ratio of the measured foot contact time (Tc) to the measured foot air time (Ta) (i.e., Tc/Ta), or the inverse value of any such ratios, may be compared with a single threshold value to determine whether the user is running or walking. In one embodiment, the threshold value chosen represents the point when the user's foot is in the air and is on the ground for equal time periods during a complete footstep (i.e., when Tc=Ta). These threshold values may be readily calculated given that, for each complete footstep, Ts=Tc+Ta. If the user's foot is on the ground longer than it is in the air during a complete footstep, it may be determined that the user is walking. Conversely, if it is determined that the user's foot is in the air longer than it is on the ground, it may be determined that the user is running.</p>
    <p>In the example shown in FIG. 8, the slopes Mp<sub>W </sub>and Mp<sub>R </sub>of the lines <b>802</b> and <b>804</b>, respectively, are positive, indicating that longer foot contact times correspond to slower paces and shorter foot contact times correspond to faster paces. Each of the constants Bp<sub>W </sub>and Bp<sub>R </sub>is negative in the example shown. However, it should be appreciated that, because speed and pace are related according to the equation: Speed=1/Pace, the portions of the lines <b>802</b> and <b>804</b> that are close to or fall below the 0 pace level are never used, as a pace of 0 corresponds to an infinite speed. In theory, the relationships (for walking and running) between Pace and Tc are non-linear near the origin of the graph of FIG. <b>8</b>. However, these non-linear portions of the relationships fall outside the possible range of foot contact times for human beings. Within the possible range of foot contact times for human beings, the relationships between Pace and Tc for both walking and running are, in fact, substantially linear.</p>
    <p>As mentioned above, in the graph of FIG. 8, the values of the constants Mp<sub>R</sub>, Mp<sub>W</sub>, Bp<sub>R</sub>, and Bp<sub>W </sub>may vary from individual to individual. The curves <b>802</b> and <b>804</b> of FIG. 8 may be optimized for a particular user <b>112</b> by having the user <b>112</b> run or walk a known twice, at different speeds, while measuring the average foot contact time (Tc<sub>AVE</sub>), as described below, during each of the two outings. By measuring the time taken to run the known distance during each outing, the average pace (Pace<sub>AVE</sub>) of the user may be calculated for each of the two outings. Therefore, using an appropriate one of the equations (3) (depending on whether the user was walking or running during the two outings), two points may be identified on the graph of FIG. <b>8</b>. Once these two points are identified, if the user <b>112</b> walked during both outings, the line <b>802</b> may be interpolated through the two points, and, if the user <b>112</b> ran during both outings, the line <b>804</b> may be interpolated through the two points.</p>
    <p>Unfortunately, any error in one or both of these points can significantly impact the accuracy of the calibration performed using this technique. Therefore, in some embodiments, three, four, or more points may be obtained during corresponding outings at different speeds, and a best fit line may be plotted through all of the obtained points to yield a more accurate Pace vs. Tc line for walking (if the user <b>112</b> walked during all of the outings) or for running (if the user <b>112</b> ran during all of the outings).</p>
    <p>As illustrated in FIG. 9, we have recognized that the step length (Ls) of the user <b>112</b> (i.e., the distance traversed during each stride taken by one foot of the user) is approximately equal to the foot contact time (Tc) measured during the stride multiplied by the speed at which the user <b>112</b> is traveling (Speed), as illustrated by the equation:</p>
    <p><i>Ls=Tc</i>*Speed(4)</p>
    <p>In addition, based upon empirical measurements, we have discovered that the step length (Ls) of the user <b>112</b> is also (substantially) linearly related to the speed of the user <b>112</b> over a reasonable range of speeds for running or walking, according to the equations:</p>
    <p>
      <maths> <formula-text> <i>Ls=M</i>step<sub>W</sub>*Speed+<i>B</i>step<sub>W</sub> </formula-text> </maths> </p>
    <p>
      <maths> <formula-text> <i>Ls=M</i>step<sub>R</sub>*Speed+<i>B</i>step<sub>R</sub>(5)</formula-text> </maths> </p>
    <p>These substantially linear relationships are illustrated in FIG. <b>10</b>. Curves <b>1002</b> and <b>1004</b> in FIG. 10 illustrate typical relationships between the user's step length (Ls) and the walking speed (curve <b>1002</b>) or running speed (curve <b>1004</b>) of the user <b>112</b>. As illustrated by line <b>1006</b> in FIG. 10, the relationship between the step length (Ls) of the user <b>112</b> and the speed of the user <b>112</b> is substantially linear through a reasonable range of walking speeds (e.g., between 2.5 and 4.5 miles per hour (MPH)). Similarly, as illustrated by line <b>1008</b> in FIG. 10, the relationship between the step length (Ls) of the user <b>112</b> and the speed of the user <b>112</b> also is substantially linear through a reasonable range of running speeds (e.g., between 5 and 12 MPH). As shown, the line <b>1006</b> has a slope equal to Mstep<sub>W </sub>and a Y-intercept equal to Bstep<sub>W</sub>, and the line <b>1008</b> has a slope equal to Mstep<sub>R </sub>and a Y-intercept equal to Bstep<sub>R</sub>.</p>
    <p>We have further discovered, again based upon empirical measurements, that the values of the slopes Mstep<sub>W </sub>and Mstep<sub>R </sub>of the lines <b>1006</b> and <b>1008</b>, respectively, are substantially constant across a large portion of the population, and that the values of the Y-intercepts Bstep<sub>W </sub>and Bstep<sub>R </sub>for the lines <b>1006</b> and <b>1008</b>, respectively, are generally the only values in equations (5) which vary significantly from person to person. By combining equations (3) and (4) and (5), we have discovered that the values Mp<sub>W </sub>and Mp<sub>R </sub>in the equations (3) are equal to 1/Bstep<sub>W </sub>and 1/Bstep<sub>R</sub>, respectively, and that the values Bp<sub>W </sub>and Bp<sub>R </sub>in the equations (3) are equal to Mstep<sub>W</sub>/Bstep<sub>W </sub>and Mstep<sub>R</sub>/Bstep<sub>R</sub>, respectively. Equation (3) therefore may be rewritten as follows:</p>
    <p>
      <maths> <formula-text>Pace=1<i>/B</i>step<sub>W</sub> <i>*Tc</i> <sub>W</sub> <i>M</i>step<sub>W</sub> <i>/B</i>step<sub>W</sub> </formula-text> </maths> </p>
    <p>
      <maths> <formula-text>Pace=1<i>/B</i>step<sub>R</sub> <i>*Tc</i> <sub>R</sub> <i>M</i>step<sub>R</sub> <i>/B</i>step<sub>R</sub>(6)</formula-text> </maths> </p>
    <p>FIG. 11 shows the lines <b>802</b> and <b>804</b> of the Pace vs. Tc lines of FIG. 8, and also illustrates the above-calculated replacement values of Mp<sub>W</sub>, Bp<sub>W</sub>, Mp<sub>R</sub>, and Bp<sub>R </sub>included in the equations (6). By setting the value of Pace in the equations (6) to be equal to 0, and then solving the equations (6) for Tc, it is discovered that the locations of the constant X-intercept points <b>1106</b> and <b>1108</b> of the lines <b>802</b> and <b>804</b>, respectively, are equal to Mstep<sub>W </sub>and Mstep<sub>R</sub>, respectively. As discussed above, our empirical measurements have revealed that these values are relatively constant across a substantial cross-section of the population. Therefore, the X-intercept points of each of the lines <b>802</b> and <b>804</b> (i.e., points <b>1106</b> and <b>1108</b>, respectively) do not change significantly from person to person, so that the lines <b>802</b> and <b>804</b> simply pivot about the respective points <b>1106</b> and <b>1108</b> on the graph of FIG. <b>11</b>. Our empirical measurements have revealed that the constant X-intercept value for the walking line <b>802</b> (Mstep<sub>W</sub>) is equal to approximately 200 milliseconds (ms), and the constant X-intercept value for the running line <b>804</b> (Mstep<sub>R</sub>) is equal to approximately 75 milliseconds (ms).</p>
    <p>This discovery is significant because each of the Pace vs. Tc lines <b>802</b> and <b>804</b> for a particular user <b>112</b> may be plotted by locating only a single point on the graph of FIG. 11 when the user <b>112</b> is walking or running at a comfortable pace, and interpolating a line between the measured point and the corresponding constant X-intercept point <b>1106</b> or <b>1108</b>.</p>
    <p>When a Pace vs. Tc line (such as one of the lines <b>802</b> and <b>804</b> of FIG. 11) is plotted by identifying two or more points and interpolating a line therebetween, it should be appreciated that the user <b>112</b> must walk or run outside of the user's most comfortable pace for walking or running to obtain at least one of these points. The point(s) obtained when the user is not running or walking at the user's most comfortable pace may not be at the optimal location on the Pace vs. Tc graph, and therefore may cause the line interpolated therethrough to be at a less than optimal location. Thus, the single-point calibration scheme discussed above is advantageous not only because the user <b>112</b> is required to walk or run a known distance only a single time, but also because the user <b>112</b> may walk or run the known distance at the user's most comfortable pace, thereby possibly obtaining more accurate calibration information than if one of the points on the Pace vs. Tc graph was obtained when the user was walking or running at a pace other than the user's most comfortable pace.</p>
    <p>As is well known, speed (miles/minute) is related to pace (minutes/mile) according the following equation:</p>
    <p>
      <maths> <formula-text>Speed=1/Pace(7)</formula-text> </maths> </p>
    <p>Therefore, in light of the equations (3), speed may be defined according to the following equations:</p>
    <p>
      <maths> <formula-text>Speed=1/(<i>Mp</i> <sub>w</sub> <i>*Tc</i> <sub>W</sub> <i>+Bp</i> <sub>W</sub>)</formula-text> </maths> </p>
    <p>
      <maths> <formula-text>Speed=1/(<i>Mp</i> <sub>R</sub> <i>*Tc</i> <sub>R</sub> <i>+Bp</i> <sub>R</sub>)(8)</formula-text> </maths> </p>
    <p>When Speed, defined according to the equations (8), is plotted against 1/Tc, curves <b>1202</b> and <b>1204</b> shown in FIG. 12 may be obtained. As shown in FIG. 12, the relationships between Speed and 1/Tc while the user <b>112</b> is walking (curve <b>1202</b>) and while the user is running (curve <b>1204</b>) appear to be substantially non-linear, as compared to the relatively linear relationships between Pace and Tc illustrated in FIGS. 8 and 11.</p>
    <p>FIG. 13 illustrates the same relationship as does FIG. 12, but uses the units miles-per-hour (MPH) on the Speed axis, rather than miles-per-minute (i.e., a factor of 60 adjustment). In addition, the graph of FIG. 13 focuses only on the relative portion of the graph of FIG. 12 that corresponds to reasonable ranges of walking and running speeds for a human being. As shown, FIG. 13 illustrates that, within a reasonable range of walking speeds (e.g., between 3 and 4 MPH), the curve <b>1202</b> is substantially linear. Similarly, between a reasonable range of running speeds (e.g., between 7.5 and 10.8 MPH), the curve <b>1204</b> also is substantially linear. Therefore, in accordance with an aspect of the present invention, a line <b>1302</b>, which passes through the aforementioned substantially linear portion of the curve <b>1202</b>, may used to define an approximation of the relationship between Speed and 1/Tc when the user <b>112</b> is walking, and a line <b>1304</b>, which passes through the aforementioned substantially linear portion of the curve <b>1204</b>, may be used to define an approximation of the relationship between Speed and 1/Tc when the user <b>112</b> is running. As shown, the lines <b>1302</b> and <b>1304</b> may be defined using the equations:</p>
    <p>
      <maths> <formula-text>Speed=(1<i>/Tc</i>)*<i>Ms</i> <sub>W</sub> <i>+Bs</i> <sub>W</sub> </formula-text> </maths> </p>
    <p>
      <maths> <formula-text>Speed=(1<i>/Tc</i>)*<i>Ms</i> <sub>R</sub> <i>+Bs</i> <sub>R</sub>(9)</formula-text> </maths> </p>
    <p>wherein Ms<sub>W </sub>and Ms<sub>R </sub>are constants representing the slopes of the lines <b>1302</b> and <b>1304</b>, respectively, and Bs<sub>W </sub>and Bs<sub>R </sub>are constants representing the Y-intercepts of the lines <b>1302</b> and <b>1304</b>, respectively. Although linear relationships between the inverse of foot contact time (1/Tc) and speed are illustrated in FIG. 13, it should be appreciated that higher-order polynomials may alternatively be used to define these relationships.</p>
    <p>Unfortunately, because the universal pivot points <b>1106</b> and <b>1108</b> of FIG. 11 are defined at a pace equal to 0, such pivot points cannot be identified on the graph of FIG. 13 because, as is evident from the equation (7), a pace of 0 corresponds to an infinite speed. When a single point calibration scheme is used wherein a single point on the graph of FIG. 11 is identified for either walking or running and a line is interpolated between the identified point and one of the universal pivot points <b>1106</b> and <b>1108</b>, however, it is possible to pick a few (at least two) points from the interpolated walking line <b>802</b> or the interpolated running line <b>804</b> of FIG. 11 that fall within a reasonable range of paces for running or walking. These selected points may then be transferred onto the graph of FIG. 13, and a line may be interpolated between the transferred points to obtain a corresponding one of the lines <b>1302</b> and <b>1304</b> shown in FIG. <b>13</b>.</p>
    <p>As discussed above, the foot-mounted unit <b>102</b> and the wrist-mounted unit <b>104</b> may communicate using either a one-way or a two-way communication link. When a two-way communication link is employed, any of the calibration values discussed herein may be calculated (based upon user inputs regarding the starting and stopping of a calibration procedure) using the wrist-mounted unit <b>104</b>, and may be subsequently communicated from the wrist-mounted unit <b>104</b> to the foot-mounted unit <b>102</b>. Alternatively, commands instructing the foot-mounted unit <b>102</b> to start and stop a calibration procedure at appropriate times may be communicated from the wrist-mounted unit <b>104</b> to the foot-mounted unit <b>102</b>. In either case, it is possible to store calibration values in the foot-mounted unit <b>102</b> based upon user input to the wrist-mounted unit (e.g., using one or more of the buttons <b>306</b>).</p>
    <p>Of course, it is also possible for a user to input calibration commands directly to the foot-mounted unit <b>102</b>, and thereby cause such values to be calculated by and stored in the foot-mounted unit <b>102</b> without any intervention by the wrist-mounted unit <b>104</b>. We recognize, however, that it may be more convenient and yield more accurate calibration results for the user <b>112</b> to input such commands to the wrist-mounted unit <b>104</b>, rather than the foot-mounted unit <b>102</b>. This is true because the user is able to input commands to the wrist-mounted unit <b>104</b> while in locomotion, as opposed to having to stop walking or running and bend over to input such commands to the foot-mounted unit <b>102</b>.</p>
    <p>Regardless of their origin, once appropriate calibration value obtained, the processor <b>422</b> of the foot-mounted unit <b>102</b>, for example, may use these calibration values (as explained below) to perform calculations involving the user's instantaneous and average pace and/or speed, as well as calculations involving the distance traveled by the user during a given outing. The results of these calculations then may be displayed on the foot-mounted unit <b>102</b> and/or transmitted to the wrist-mounted unit <b>104</b> for display to the user <b>112</b>.</p>
    <p>In alternative embodiments of the invention, the ARC processor <b>410</b> of the wrist-mounted unit <b>104</b>, or another processor distinct from both the foot-mounted unit <b>102</b> and the wrist-mounted unit <b>104</b>, may instead perform these calculations. For example, each measured foot contact time (Tc) and step time (Ts) may be transmitted from the foot-mounted unit <b>102</b> to the wrist-mounted unit <b>104</b> or another device, and the ARC processor <b>410</b> the wrist-mounted unit <b>104</b> or a processor in the other device may perform all of the calculations described herein based these values. In fact, in some embodiments, the signal from the sensor <b>418</b> may be the only information that is transmitted (wirelessly) from the foot-mounted unit <b>102</b> to the wrist-mounted unit <b>104</b> or another device, and the wrist-mounted unit <b>104</b> or the other device may itself perform the analysis of the sensor signal during which foot contact times, etc., are measured, as well as performing all or some of the other calculations described herein involving such measured values. In any of these alternative embodiments, appropriate calibration values may be both calculated by and stored directly in the wrist-mounted unit <b>104</b>.</p>
    <p>The user <b>112</b> may instruct the foot-mounted unit <b>102</b> to start and stop performing such calculations either by providing appropriate inputs directly to the foot-mounted unit <b>102</b> (e.g., using the button <b>204</b> or one or more other buttons on the foot-mounted unit <b>102</b>), or by providing appropriate inputs to the wrist-mounted unit <b>104</b> (e.g., by depressing one or more of the buttons <b>306</b>), which then can transmit the instructions to the foot-mounted unit <b>102</b>. Examples of how the above-mentioned calculations may be performed by the processor <b>422</b> will now be provided, recognizing, of course, that the invention is not limited to embodiments wherein the processor <b>422</b> is the entity that performs these calculations.</p>
    <p>While the user <b>112</b> is walking or running during an outing, for each complete footstep by the user, both the step time (Ts) of the footstep and the portion of that step time (Ts) constituting the foot contact time (Tc) of the footstep may be measured as described herein. As discussed above in connection with FIG. 8, each measured foot contact time (Tc) may be compared with a threshold value (e.g., 420 milliseconds), and, based upon that comparison, may be categorized as a walking foot contact time (Tc<sub>W</sub>) or as a running foot contact time (Tc<sub>R</sub>). Each step time (Ts) may also be placed into the same category as the foot contact time (Tc) with which it is associated. That is, each step time (Ts) associated with a walking foot contact time (Tc<sub>W</sub>) may be categorized as walking step time (Ts<sub>W</sub>), and each step time (Ts) associated with a running foot contact time (Tc<sub>R</sub>) may be categorized as running step time (Ts<sub>R</sub>).</p>
    <p>By accumulating running totals of measured foot contact times for both walking and running (i.e., Tc<sub>W </sub>and Tc<sub>R</sub>), and also keeping track of the number of walking and running foot contact times so accumulated (i.e., Tc<sub>WNUM </sub>and Tc<sub>RSUM</sub>), an average walking foot contact time (Tc<sub>W/aVE</sub>) may be calculated by dividing the value of Tc<sub>W </sub>by the value of Tc<sub>WNUM </sub>(i.e., Tc<sub>W/aVE</sub>=Tc<sub>W</sub>/Tc<sub>WNUM</sub>), and an average running foot contact time (Tc<sub>RAVE</sub>) may be calculated by dividing the value of Tc<sub>R </sub>by the value of Tc<sub>RNUM </sub>(i.e., Tc<sub>R/aVE</sub>=TC<sub>R</sub>/Tc<sub>RNUM</sub>). Based upon these values, the average walking and/or running pace (Pace<sub>WAVE </sub>and/or Pace<sub>RAVE</sub>) during an outing may be calculated by simply plugging the current average value of Tc<sub>WAVE </sub>and/or the current average value of Tc<sub>RAVE </sub>into one or both of the equations (3) above. Similarly, the instantaneous pace as a result of the last measured foot contact time (Tc), or as a result of an average of the last several (e.g., four) measured foot contact times, may be calculated by plugging the current or average value of Tc<sub>W </sub>and/or the current or average value of Tc<sub>R </sub>into one or both of the equations (3) above.</p>
    <p>In addition, using the well-known relationship: Distance=Time/Pace, the distance traveled during each complete footstep may be calculated by plugging the measured foot contact time (i.e., Tc<sub>W </sub>or Tc<sub>R</sub>) for the footstep into an appropriate one of the equations (3) to yield the pace for that footstep, and then dividing the measured step time (Ts) for the footstep by the pace calculated for the same. The total distance traveled by the user <b>112</b> therefore can be calculated, regardless of whether the user <b>112</b> is walking and/or running during the outing, by accumulating a running total of such per-footstep distances.</p>
    <p>Alternatively, in addition to calculating the values of Tc<sub>WAVE </sub>and Tc<sub>RAVE</sub>, as discussed above, cumulative totals of the values of Ts<sub>W </sub>and Ts<sub>R </sub>(i.e., Ts<sub>W </sub>and Ts<sub>R</sub>) may be maintained in memory. Based upon these values, walking and running distance values may be calculated using the following equations, which represent a combination of the equations (3) with the relationship: Distance=Time/Pace:</p>
    <p>
      <maths> <formula-text>Distance<sub>W</sub> <i>=Ts</i> <sub>W</sub>/(<i>Mp</i> <sub>W</sub> <i>*Tc</i> <sub>WAVE</sub> <i>+Bp</i> <sub>w</sub>)</formula-text> </maths> </p>
    <p>
      <maths> <formula-text>Distance<sub>R</sub> <i>=Ts</i> <sub>R</sub>/(<i>Mp</i> <sub>R</sub> <i>*Tc</i> <sub>RAVE</sub> <i>+Bp</i> <sub>R</sub>)(10)</formula-text> </maths> </p>
    <p>Therefore, the total distance traveled by the user during the outing (regardless of whether the user is walking or running) may be calculated by adding together both of the equations (10), thereby yielding the equation:</p>
    <p>
      <maths> <formula-text>Distance<sub>TOTAL</sub> <i>=Ts</i> <sub>W</sub>/(<i>Mp</i> <sub>W</sub> <i>*Tc</i> <sub>WAVE</sub> <i>+Bp</i> <sub>W</sub>)+Ts<sub>R</sub>/(Mp<sub>R</sub> <i>*Tc</i> <sub>RAVE</sub> <i>+Bp</i> <sub>R</sub>)(11)</formula-text> </maths> </p>
    <p>As mentioned above, after performing these calculations, the foot-mounted unit may periodically transmit information, such as distance traveled, average pace, instantaneous pace, etc., to the wrist-mounted unit <b>104</b> for display to the user <b>112</b>. Alternatively, the foot-mounted unit <b>102</b> may itself display some or all of the desired information.</p>
    <p>With regard to the equations discussed herein involving pace, it should be appreciated that, in light of the relationship: Speed=1/Pace, similar equations involving speed, rather than pace, may alternatively be used to calculate the various performance parameters, including the parameter Speed itself.</p>
    <p>As is well-known, the distance traveled by a user during a given time interval may be calculated by the following equation:</p>
    <p>
      <maths> <formula-text>Distance=Speed*Time(12)</formula-text> </maths> </p>
    <p>Therefore, by combining the equations (9) and (12), for each complete footstep taken by the user <b>112</b> (i.e., during each step time (Ts)), the distance traveled by the user <b>112</b> during that footstep may be determined using the equations:</p>
    <p>
      <maths> <formula-text>Distance=(<i>Ts/Tc</i>)*<i>Ms</i> <sub>W</sub> <i>+Ts*Bs</i> <sub>W</sub> </formula-text> </maths> </p>
    <p>
      <maths> <formula-text>Distance=(<i>Ts/Tc</i>)*<i>Ms</i> <sub>R</sub> <i>+Ts*Bs</i> <sub>R</sub>(13)</formula-text> </maths> </p>
    <p>As discussed above, the one of the equations (13) that is used to calculate the distance traveled by the user during a given footstep may be determined based upon a comparison of the measured foot contact time (Tc) with the threshold value discussed above (e.g., 420 ms) in connection with FIG. <b>8</b>. Therefore, to calculate the total distance traveled by the user <b>112</b> during a particular outing, the values Tc and Ts may be monitored during each footstep taken by the user <b>112</b>, and each monitored Tc and Ts value may be identified as having been measured either when the user <b>112</b> was walking or when user <b>112</b> was running. After having been identified as either walking Tc and Ts values (Tc<sub>W </sub>and Ts<sub>W</sub>) or running Tc and Ts values (Tc<sub>R </sub>and Ts<sub>R</sub>), a running total of each of the values Tc<sub>W</sub>, Ts<sub>W</sub>, Tc<sub>R</sub>, and Ts<sub>R </sub>obtained during the outing may be stored, and the total distances traveled by the user while running and walking may be calculated using the equations:</p>
    <p>
      <maths> <formula-text>Total Walking Distance=(<i>Ts</i> <sub>W</sub> <i>/Tc</i> <sub>W</sub>)*<i>Ms</i> <sub>W</sub> <i>+Ts</i> <sub>R</sub> <i>*Bs</i> <sub>W</sub>(14)</formula-text> </maths> </p>
    <p>
      <maths> <formula-text>Total Running Distance=(<i>Ts</i> <sub>R</sub> <i>/Tc</i> <sub>R</sub>)*<i>Ms</i> <sub>R</sub> <i>+Ts</i> <sub>R</sub> <i>*Bs</i> <sub>R</sub>(15)</formula-text> </maths> </p>
    <p>Therefore, the total distance traveled by the user during the outing (regardless of whether the user is walking or running) may be calculated by adding together the equations (14) and (15), thereby yielding the equation:</p>
    <p>
      <maths> <formula-text>Total Distance=(<i>Ts</i> <sub>W</sub> <i>/Tc</i> <sub>W</sub>)*<i>Ms</i> <sub>W</sub> <i>+Ts</i> <sub>R</sub> <i>*Bs</i> <sub>W</sub>+(<i>Ts</i> <sub>R</sub> <i>/Tc</i> <sub>R</sub>)*<i>Ms</i> <sub>R</sub> <i>+Ts</i> <sub>R</sub> <i>*Bs</i> <sub>R</sub>(16)</formula-text> </maths> </p>
    <p>Using these equations, the values (Ts<sub>W</sub>/Tc<sub>W</sub>), Ts<sub>W</sub>, (Ts<sub>R</sub>/Tc<sub>R</sub>), and Ts<sub>R </sub>(the Tc/Ts and Ts sum values) may be cumulatively updated by the foot-mounted unit <b>102</b> as the user <b>112</b> is walking or running, and the Tc/Ts and Ts sum values accumulated by the foot-mounted unit <b>102</b> may be periodically transmitted (e.g., once every millisecond) to the wrist-mounted unit <b>104</b>. When the wrist-mounted unit <b>104</b> receives a transmission from the foot-mounted unit <b>102</b> including updated Tc/Ts and Ts sum values, these values may be combined with the calibration values Ms<sub>W</sub>, Bs<sub>W</sub>, Ms<sub>R </sub>and Bs<sub>R </sub>in accordance with equation (16) to calculate the total distance traveled by the user <b>112</b> during the outing for which the Tc/Ts and Ts sum values were accumulated.</p>
    <p>When the user provides an indication to the wrist-mounted unit <b>104</b> that the user <b>112</b> wants the wrist-mounted unit to begin measuring a total distance traveled by the user <b>112</b> (e.g., by depressing one of the buttons <b>306</b>), the wrist mounted unit <b>104</b> may, for example, record the values of the Tc/Ts and Ts sum values last received from the foot-mounted unit <b>102</b> as starting values. The wrist-mounted unit may then subtract the recorded starting values from any updated Tc/Ts and Ts sum values later received from the foot-mounted unit <b>102</b> to obtain an accurate measurement of the Tc/Ts and Ts sum values accumulated that have been accumulated since the user instructed to the wrist-mounted unit <b>102</b> to begin a total distance measurement.</p>
    <p>Alternatively, each measured foot contact time (Tc) and step time (Ts) may be transmitted from the foot-mounted unit <b>102</b> to the wrist-mounted unit <b>104</b> or another device, and the wrist-mounted unit <b>104</b> or the other device may perform all of the calculations described herein based these values. In fact, in some embodiments, the signal from the sensor <b>418</b> may be the only information that is transmitted (wirelessly) from the foot-mounted unit <b>102</b> to the wrist-mounted unit <b>104</b> or another device, and the wrist-mounted unit <b>104</b> or the other device may itself perform the analysis of the sensor signal during which foot contact times, etc., are measured, as well as performing all or some of the other calculations described herein involving such measured values.</p>
    <p>In light of the universal pivot points <b>1106</b> and <b>1108</b> identified in the graph of FIG. 11 for the lines <b>802</b> and <b>804</b>, respectively, we have recognized that, for each of the two lines <b>802</b> and <b>804</b>, each individual user may be assigned a single calibration value that identifies the location of that line. For example, each user may be assigned a first calibration value between 1 and 200 that identifies a corresponding angular orientation of the running line <b>802</b> about the pivot point <b>1106</b>, and may be assigned a second calibration value between 1 and 200 that identifies a corresponding angular orientation of the walking line <b>804</b> about the pivot point <b>1108</b>.</p>
    <p>In one embodiment, a baseline value of a foot contact time (Tc) is selected, and an equation including the single calibration value (e.g., a number between 1 and 200) as a variable is used to define the pace that corresponds to the baseline foot contact time (Tc). Thus, each change in the value of the single calibration value causes a corresponding change in the value of the pace associated with the baseline foot contact time (Tc). In this manner, a point is defined on the Pace vs. Tc graph of FIG. <b>11</b> through which an appropriate one of the lines <b>802</b> and <b>804</b> may be interpolated, with the other point through which the line is interpolated being one of the universal pivot points <b>1106</b> and <b>1108</b>. In one illustrative embodiment, this relationship is defined (for each of the lines <b>802</b> and <b>804</b>) using the following equation:</p>
    <p>
      <maths> <formula-text>Pace<sub>TcBASELINE</sub> <i>=m</i> <sub>CalVal</sub>*CalVal<sub>p</sub> <i>+b</i> <sub>CalVal</sub>(17)</formula-text> </maths> </p>
    <p>Wherein CalVal<sub>P </sub>is the single calibration value (e.g., a number between 0 and 200) and m<sub>CalVal </sub>and b<sub>CalVal </sub>are constants defining, respectively, the slope and Y-intercept of the relationship between Pace<sub>TcBASELINE </sub>and CalVal<sub>P</sub>. It should be appreciated that the relationship between the single calibration value and pace, for the baseline foot contact time (Tc), may alternatively be non-linear, and the invention is not limited to a linear relationship such as that shown.</p>
    <p>In one embodiment of the invention, after a value of CalVal<sub>P </sub>is set initially (for either running or walking), this value can later be optimized whenever the user runs or walks a reported distance (e.g., a five mile race), and obtains a measured distance for the race (e.g., 3.1 miles) using the foot-mounted unit <b>102</b> and/or wrist-mounted unit <b>104</b>. This optimization may be achieved in response to the user inputting only the reported distance and the measured distance, and may be performed by one or more of the foot-mounted unit <b>102</b>, the wrist-mounted unit <b>104</b>, the computer <b>428</b>, and the network server <b>442</b>, as follows.</p>
    <p>Referring to FIG. 11, the user may run or walk a reported distance (e.g., five miles), while the foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b> calculates a measured distance (e.g., 3.1 miles) based upon measured foot contact times and the initial value of CalVal<sub>P</sub>. Next, using the line corresponding to the initial value of CalVal<sub>P</sub>, the value of Tc corresponding to an arbitrarily-picked value of Pace (e.g., seven minutes/mile) may be determined. In addition, the arbitrarily-picked value of Pace (e.g., seven minutes/mile) may be multiplied by the reported distance (e.g., five miles) to obtain a time value (e.g., 17.5 minutes). Next, this time value (e.g., 17.5 minutes) may be divided by the measured distance (e.g., 3.1 miles), which was calculated using the line corresponding to the initial value of CalVal<sub>P</sub>, to obtain a calculated value of Pace (e.g., 5.64 minutes/mile). A point on the graph of FIG. 11 may then be identified having a Pace coordinate corresponding to the calculated value of Pace (e.g., 5.64 minutes/mile) and a Tc coordinate corresponding to the value of Tc corresponding to the arbitrary pace (e.g., seven minutes/mile) identified above. Finally, a new line may be interpolated between this identified point and the universal pivot point discussed above, which line represents a newly-calibrated Pace vs. Tc line for the user. Based upon the position of this line, a new value of CalVal<sub>P </sub>may be determined and may be stored in memory for the user. This new value of CalVal<sub>P</sub>, and the line corresponding thereto, may then be used for future measurements by the foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b>. This procedure may be used to optimize either the walking line <b>802</b> or the running line <b>804</b> of FIG. <b>11</b>.</p>
    <p>It should be appreciated that this technique can likewise be performed in other situations wherein a set of lines is known for which a single calibration value and/or a single point defines each line in the set. For example, the above-described technique may also be employed in connection with the set of lines identifying the relationship between Speed and 1/Tc, explained below in connection with FIG. 13, because a single calibration value can be used therein to define each line in that set of lines.</p>
    <p>As discussed above, each line in the graph of FIG. 11 can be translated into a corresponding line in the graphs of FIG. 13 (e.g., by selecting a few reasonable values of Tc and Pace, calculating values of 1/Tc and Speed based thereupon, plotting points corresponding to the calculated values, and interpolating a line between the points so plotted). Therefore, because a single calibration point can identify the position of each of the curves <b>802</b> and <b>804</b> in the graph of FIG. 11, a single calibration point can also be used to identify the position of each of the curves <b>1302</b> and <b>1304</b> in the graph of FIG. <b>13</b>. In this regard, it should be understood that, while each single calibration value used in connection with the graph of FIG. 11 identifies a corresponding degree of rotation of one of the lines <b>802</b> and <b>804</b> about its pivot point, each of the single calibration values used in connection with the graph of FIG. 13 identifies both a corresponding degree of rotation and a corresponding degree of translation of one of the lines <b>1302</b> and <b>1304</b> with respect to the Speed and 1/Tc axes of the graph.</p>
    <p>Based upon empirical measurements of the relationships between Tc and Pace and 1/Tc and Speed for a large number of users, we have discovered universal relationships between the calibration constants Mp<sub>R </sub>and Bs<sub>R </sub>and between the calibration constants Mp<sub>W </sub>and Bs<sub>W </sub>of the equations (3) and (11), respectively, that have enabled us to derive respective equations (each including a single, user-specific constant) that identify corresponding rotational and translational positions of the curves <b>1302</b> and <b>1304</b> in the graph of FIG. <b>13</b>. Therefore, using these equations, each user may simply be assigned a first calibration constant that defines that user's walking curve <b>1302</b> in the graph of FIG. <b>13</b> and second calibration constant that defines that user's running curve <b>1304</b>. This may compared to the alternative technique of using two separate calibration constants (i.e., the calibration constants Ms<sub>W </sub>and Bs<sub>W </sub>or Ms<sub>R </sub>and Bs<sub>R </sub>of equations (9)) to define each of the lines <b>1302</b> and <b>1304</b>.</p>
    <p>The discovered relationships between the constants Mp and Bs from the equations (3) and (11), respectively, are identified by the following equations: <maths> <math> <mtable> <mtr> <mtd> <mrow> <mrow> <msub> <mi>Mp</mi> <mi>W</mi> </msub> <mo>=</mo> <mrow> <mi>C1</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> </mrow> <mo></mo> <mstyle> <mtext> </mtext> </mstyle> <mo></mo> <mrow> <msub> <mi>Mp</mi> <mi>R</mi> </msub> <mo>=</mo> <mrow> <mi>C2</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mo>(</mo> <mn>18</mn> <mo>)</mo> </mrow> </mtd> </mtr> </mtable> </math> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00001.png"> <img id="EMI-M00001" file="US06611789-20030826-M00001.TIF" img-content="math" img-format="tif" alt="Figure US06611789-20030826-M00001" src="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00001.png" class="patent-full-image"> </a> </div> <attachments> <attachment idref="MATHEMATICA-00001" attachment-type="nb" file="US06611789-20030826-M00001.NB"> </attachment> </attachments> </maths> </p>
    <p>wherein C<b>1</b> and C<b>2</b> are universal constants. The constants C<b>1</b> and C<b>2</b> are referred to herein as the Darley constants, named after their discoverer, Jesse Darley, of Watertown, Mass. When the units used in the graphs of FIGS. 11 and 13 are employed, we have discovered that the Darley constant C<b>1</b> is equal to 1 and that the Darley constant C2 is equal to 1/1.4062 (which can be approximated by the fraction 32/45).</p>
    <p>Because the locations of the universal pivot points <b>1106</b> and <b>1108</b> (i.e., the Tc values when pace is equal to 0) are known, the equations (3) can be simplified to: <maths> <math> <mtable> <mtr> <mtd> <mrow> <mrow> <msub> <mi>Bp</mi> <mi>W</mi> </msub> <mo>=</mo> <mrow> <mrow> <mo>-</mo> <msub> <mi>PP</mi> <mi>W</mi> </msub> </mrow> <mo>*</mo> <msub> <mi>Mp</mi> <mi>W</mi> </msub> </mrow> </mrow> <mo></mo> <mstyle> <mtext> </mtext> </mstyle> <mo></mo> <mrow> <msub> <mi>Bp</mi> <mi>R</mi> </msub> <mo>=</mo> <mrow> <mrow> <mo>-</mo> <msub> <mi>PP</mi> <mi>R</mi> </msub> </mrow> <mo>*</mo> <msub> <mi>Mp</mi> <mi>R</mi> </msub> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mo>(</mo> <mn>19</mn> <mo>)</mo> </mrow> </mtd> </mtr> </mtable> </math> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00002.png"> <img id="EMI-M00002" file="US06611789-20030826-M00002.TIF" img-content="math" img-format="tif" alt="Figure US06611789-20030826-M00002" src="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00002.png" class="patent-full-image"> </a> </div> <attachments> <attachment idref="MATHEMATICA-00002" attachment-type="nb" file="US06611789-20030826-M00002.NB"> </attachment> </attachments> </maths> </p>
    <p>wherein PP<sub>W </sub>is equal to the Tc value at the pivot point <b>1106</b> of the line <b>802</b> (i.e., Mstep<sub>W</sub>), and PP<sub>R </sub>is equal to the Tc value at the pivot point <b>1108</b> of the line <b>804</b> (i.e., Mstep<sub>R</sub>). In the units used in the graph of FIG. 11, the values of PP<sub>W </sub>and PP<sub>R </sub>are 200 and 75, respectively.</p>
    <p>As shown below, the equations (18) and (19) may be combined to yield the equations: <maths> <math> <mtable> <mtr> <mtd> <mrow> <mrow> <msub> <mi>Bp</mi> <mi>W</mi> </msub> <mo>=</mo> <mrow> <mrow> <mo>-</mo> <msub> <mi>PP</mi> <mi>W</mi> </msub> </mrow> <mo>*</mo> <mi>C1</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> </mrow> <mo></mo> <mstyle> <mtext> </mtext> </mstyle> <mo></mo> <mrow> <msub> <mi>Bp</mi> <mi>R</mi> </msub> <mo>=</mo> <mrow> <mrow> <mo>-</mo> <msub> <mi>PP</mi> <mi>R</mi> </msub> </mrow> <mo>*</mo> <mi>C2</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mo>(</mo> <mn>20</mn> <mo>)</mo> </mrow> </mtd> </mtr> </mtable> </math> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00003.png"> <img id="EMI-M00003" file="US06611789-20030826-M00003.TIF" img-content="math" img-format="tif" alt="Figure US06611789-20030826-M00003" src="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00003.png" class="patent-full-image"> </a> </div> <attachments> <attachment idref="MATHEMATICA-00003" attachment-type="nb" file="US06611789-20030826-M00003.NB"> </attachment> </attachments> </maths> </p>
    <p>The equations (3) and (1) may be solved for Tc and Ms, respectively, to yield the equations: <maths> <math> <mtable> <mtr> <mtd> <mrow> <mrow> <mi>Tc</mi> <mo>=</mo> <mrow> <mrow> <mo>(</mo> <mrow> <mi>Pace</mi> <mo>-</mo> <msub> <mi>Bp</mi> <mi>W</mi> </msub> </mrow> <mo>)</mo> </mrow> <mo>/</mo> <msub> <mi>Mp</mi> <mi>W</mi> </msub> </mrow> </mrow> <mo></mo> <mstyle> <mtext> </mtext> </mstyle> <mo></mo> <mrow> <mi>Tc</mi> <mo>=</mo> <mrow> <mrow> <mo>(</mo> <mrow> <mi>Pace</mi> <mo>-</mo> <msub> <mi>Bp</mi> <mi>R</mi> </msub> </mrow> <mo>)</mo> </mrow> <mo>/</mo> <msub> <mi>Mp</mi> <mi>R</mi> </msub> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mo>(</mo> <mn>21</mn> <mo>)</mo> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mrow> <msub> <mi>Ms</mi> <mi>W</mi> </msub> <mo>=</mo> <mrow> <mi>Tc</mi> <mo>*</mo> <mrow> <mo>(</mo> <mrow> <mi>Speed</mi> <mo>-</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> <mo></mo> <mstyle> <mtext> </mtext> </mstyle> <mo></mo> <mrow> <msub> <mi>Ms</mi> <mi>R</mi> </msub> <mo>=</mo> <mrow> <mi>Tc</mi> <mo>*</mo> <mrow> <mo>(</mo> <mrow> <mi>Speed</mi> <mo>-</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mo>(</mo> <mn>22</mn> <mo>)</mo> </mrow> </mtd> </mtr> </mtable> </math> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00004.png"> <img id="EMI-M00004" file="US06611789-20030826-M00004.TIF" img-content="math" img-format="tif" alt="Figure US06611789-20030826-M00004" src="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00004.png" class="patent-full-image"> </a> </div> <attachments> <attachment idref="MATHEMATICA-00004" attachment-type="nb" file="US06611789-20030826-M00004.NB"> </attachment> </attachments> </maths> </p>
    <p>The equations (19) and (20) then may be combined to yield the equations:</p>
    <p>
      <maths> <formula-text> <i>Ms</i> <sub>W</sub>=(Speed<sub>EPW</sub> <i>Bs</i> <sub>W</sub>)*(Pace<sub>EPW</sub> <i>Bp</i> <sub>W</sub>)/<i>Mp</i> <sub>W</sub> </formula-text> </maths> </p>
    <p>
      <maths> <formula-text> <i>Ms</i> <sub>R</sub>=(Speed<sub>EPR</sub> <i>Bs</i> <sub>R</sub>)*(Pace<sub>EPR</sub> <i>Bp</i> <sub>R</sub>)<i>/Mp</i> <sub>R</sub>(23)</formula-text> </maths> </p>
    <p>wherein Speed<sub>EPW </sub>and Pace<sub>EPW </sub>represent, respectively, the speed at one of the end points <b>1306</b> and <b>1308</b> of the line segment <b>1302</b> <i>a </i>of the walking line <b>1302</b> and the pace (i.e., 1/Speed) corresponding therewith, and Speed<sub>EPR </sub>and Pace<sub>EPR </sub>represent, respectively, the speed at one of the end points <b>1310</b> and <b>1312</b> of the line segment <b>1304</b> <i>a </i>of the running line <b>1304</b> and the pace (i.e., 1/Speed) corresponding therewith. The speed with which each of the endpoints is associated therefore corresponds precisely with a pace on one of the lines <b>802</b> and <b>804</b> in the graph of FIG. 11, whereas the speeds with which central portions of the line segments <b>1302</b> <i>a </i>and <b>1304</b> <i>a </i>are associated may not correspond precisely with paces on the lines <b>802</b> and <b>804</b> in the graph of FIG. 11 because of the slight bend in the curves <b>1202</b> and <b>1204</b> between the endpoints of the line segments <b>1302</b> <i>a </i>and <b>1304</b> <i>a</i>, respectively.</p>
    <p>With the units used in FIGS. 11 and 13, the endpoint paces (Pace<sub>EPW</sub>) corresponding to the endpoint speeds (Speed<sub>EPW</sub>) of the line segment <b>1302</b> <i>a </i>of 4 and 4.5 MPH are 15 and a 13.333 minutes/mile, respectively, and the endpoint paces (Pace<sub>EPR</sub>) corresponding to the endpoint speeds (Speed<sub>EPR</sub>) of the line segment <b>1304</b> <i>a </i>of 7.5 and 9 MPH are 8 and 6.666 minutes/mile, respectively.</p>
    <p>As shown below, the equations (18), (20), and (23) may be combined to yield the following values for Ms<sub>W </sub>and Ms<sub>R</sub>:</p>
    <p>
      <maths> <formula-text> <i>Ms</i> <sub>W</sub>=(Speed<sub>EPW</sub> <i>Bs</i> <sub>W</sub>)*(Pace<sub>EPW</sub> <i>+PP</i> <sub>W</sub> <i>*C</i> <b>1</b>*<i>Bs</i> <sub>W</sub>)/(<i>C</i> <b>1</b>*<i>Bs</i> <sub>W</sub>)</formula-text> </maths> </p>
    <p>
      <maths> <formula-text> <i>Ms</i> <sub>R</sub>=(Speed<sub>EPR</sub> <i>Bs</i> <sub>R</sub>)*(Pace<sub>EPR</sub> <i>+PP</i> <sub>R</sub> <i>*C</i> <b>2</b>*<i>Bs</i> <sub>R</sub>)/(<i>C</i> <b>2</b>*<i>Bs</i> <sub>R</sub>)(24)</formula-text> </maths> </p>
    <p>Thus, in the equations (24), the value of each of the constants in the equations (11) (i.e., Ms<sub>W </sub>or Ms<sub>R</sub>) is defined in terms of the other constant (i.e., Bs<sub>W </sub>or Bs<sub>R</sub>) in the same equation. The equations (24) therefore can be combined with the equations (11) to yield the following equations for speed that depend on only one user-specific constant (i.e., Bs<sub>W </sub>or Bs<sub>R</sub>): <maths> <math> <mtable> <mtr> <mtd> <mtable> <mtr> <mtd> <mrow> <mi>Speed</mi> <mo>=</mo> <mstyle> <mtext></mtext> </mstyle> <mo></mo> <mrow> <mrow> <mo>(</mo> <mrow> <mn>1</mn> <mo>/</mo> <mi>Tc</mi> </mrow> <mo>)</mo> </mrow> <mo>*</mo> <mrow> <mo>(</mo> <mrow> <msub> <mi>Speed</mi> <mi>EPW</mi> </msub> <mo>-</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> <mo>)</mo> </mrow> <mo>*</mo> </mrow> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mstyle> <mtext></mtext> </mstyle> <mo></mo> <mrow> <mrow> <mo>(</mo> <mrow> <msub> <mi>Pace</mi> <mi>EPW</mi> </msub> <mo>+</mo> <mrow> <msub> <mi>PP</mi> <mi>W</mi> </msub> <mo>*</mo> <mi>C1</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> </mrow> <mo>)</mo> </mrow> <mo>/</mo> </mrow> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mstyle> <mtext></mtext> </mstyle> <mo></mo> <mrow> <mrow> <mrow> <mo>(</mo> <mrow> <mi>C1</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> <mo>)</mo> </mrow> <mo>/</mo> <mrow> <mo>(</mo> <mrow> <mi>C1</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> <mo>)</mo> </mrow> </mrow> <mo>+</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> </mrow> </mtd> </mtr> </mtable> </mtd> <mtd> <mrow> <mo>(</mo> <mn>25</mn> <mo>)</mo> </mrow> </mtd> </mtr> </mtable> </math> <math> <mtable> <mtr> <mtd> <mrow> <mi>Speed</mi> <mo>=</mo> <mstyle> <mtext></mtext> </mstyle> <mo></mo> <mrow> <mrow> <mo>(</mo> <mrow> <mn>1</mn> <mo>/</mo> <mi>Tc</mi> </mrow> <mo>)</mo> </mrow> <mo>*</mo> <mrow> <mo>(</mo> <mrow> <msub> <mi>Speed</mi> <mi>EPR</mi> </msub> <mo>-</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> <mo>)</mo> </mrow> <mo>*</mo> </mrow> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mstyle> <mtext></mtext> </mstyle> <mo></mo> <mrow> <mrow> <mo>(</mo> <mrow> <msub> <mi>Pace</mi> <mi>EPR</mi> </msub> <mo>+</mo> <mrow> <msub> <mi>PP</mi> <mi>R</mi> </msub> <mo>*</mo> <mi>C2</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> </mrow> <mo>)</mo> </mrow> <mo>/</mo> </mrow> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mstyle> <mtext></mtext> </mstyle> <mo></mo> <mrow> <mrow> <mo>(</mo> <mrow> <mi>C2</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> <mo>)</mo> </mrow> <mo>+</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> </mrow> </mtd> </mtr> </mtable> </math> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00005.png"> <img id="EMI-M00005" file="US06611789-20030826-M00005.TIF" img-content="math" img-format="tif" alt="Figure US06611789-20030826-M00005" src="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00005.png" class="patent-full-image"> </a> </div> <attachments> <attachment idref="MATHEMATICA-00005" attachment-type="nb" file="US06611789-20030826-M00005.NB"> </attachment> </attachments> </maths> </p>
    <p>Finally, the equations (12) and (25), may be combined, in a manner similar to that by which the equations (11) and (12) above were combined to yield equation (17), to yield the following equation: <maths> <math> <mtable> <mtr> <mtd> <mrow> <mstyle> <mtext>TotalDistance</mtext> </mstyle> <mo>=</mo> <mrow> <mrow> <mrow> <mi></mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <msub> <mi>Ts</mi> <mi>W</mi> </msub> <mo>/</mo> <msub> <mi>Tc</mi> <mi>W</mi> </msub> </mrow> <mo>)</mo> </mrow> </mrow> <mo>*</mo> <mrow> <mo>(</mo> <mrow> <msub> <mi>Speed</mi> <mi>EPW</mi> </msub> <mo>-</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> <mo>)</mo> </mrow> <mo>*</mo> <mrow> <mrow> <mrow> <mo>(</mo> <mrow> <msub> <mi>Pace</mi> <mi>EPW</mi> </msub> <mo>+</mo> <mrow> <msub> <mi>PP</mi> <mi>W</mi> </msub> <mo>*</mo> <mi>C1</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> </mrow> <mo>)</mo> </mrow> <mo>/</mo> <mrow> <mo>(</mo> <mrow> <mi>C1</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> <mo>)</mo> </mrow> </mrow> <mo>/</mo> <mrow> <mo>(</mo> <mrow> <mi>C1</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> <mo>+</mo> <mrow> <mi></mi> <mo></mo> <mstyle> <mtext></mtext> </mstyle> <mo></mo> <msub> <mi>Ts</mi> <mi>W</mi> </msub> <mo>*</mo> <msub> <mi>Bs</mi> <mi>W</mi> </msub> </mrow> <mo>+</mo> <mrow> <mrow> <mi></mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <msub> <mi>Ts</mi> <mi>R</mi> </msub> <mo>/</mo> <msub> <mi>Tc</mi> <mi>R</mi> </msub> </mrow> <mo>)</mo> </mrow> </mrow> <mo>*</mo> <mrow> <mo>(</mo> <mrow> <msub> <mi>Speed</mi> <mi>EPR</mi> </msub> <mo>-</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> <mo>)</mo> </mrow> <mo>*</mo> <mrow> <mrow> <mo>(</mo> <mrow> <msub> <mi>Pace</mi> <mi>EPR</mi> </msub> <mo>+</mo> <mrow> <msub> <mi>PP</mi> <mi>R</mi> </msub> <mo>*</mo> <mi>C2</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> </mrow> <mo>)</mo> </mrow> <mo>/</mo> <mrow> <mo>(</mo> <mrow> <mi>C2</mi> <mo>*</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> <mo>+</mo> <mrow> <mi></mi> <mo></mo> <mstyle> <mtext></mtext> </mstyle> <mo></mo> <msub> <mi>Ts</mi> <mi>R</mi> </msub> <mo>*</mo> <msub> <mi>Bs</mi> <mi>R</mi> </msub> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mo>(</mo> <mn>26</mn> <mo>)</mo> </mrow> </mtd> </mtr> </mtable> </math> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00006.png"> <img id="EMI-M00006" file="US06611789-20030826-M00006.TIF" img-content="math" img-format="tif" alt="Figure US06611789-20030826-M00006" src="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00006.png" class="patent-full-image"> </a> </div> <attachments> <attachment idref="MATHEMATICA-00006" attachment-type="nb" file="US06611789-20030826-M00006.NB"> </attachment> </attachments> </maths> </p>
    <p>As mentioned above, when the unit shown in the graphs of FIGS. 9 and 11 are used in the equation (26), the values of the Darley constants C<b>1</b> and C<b>2</b> may be 1 and 32/45, respectively, the values of the constants PP<sub>W </sub>and PP<sub>R </sub>may be 200 and 75 ms, respectively, the constants Speed<sub>EPW </sub>and Pace<sub>EPW </sub>may be 4 MPH and 15 minutes/mile (or and 4.5 MPH and 13.333 minutes/mile), respectively, and the constants Speed<sub>EPR </sub>and Pace<sub>EPR </sub>may be 7.5 MPH and 9 minutes/mile (or and 9 MPH and 6.666 minutes/mile), respectively. Thus, the only unknowns in the equation (26) are the accumulated values of Ts<sub>W</sub>, Tc<sub>W</sub>, Ts<sub>R</sub>, and Tc<sub>R</sub>, and the user-specific constants Bs<sub>W </sub>and Bs<sub>R</sub>.</p>
    <p>When the equation (26) is used and the user <b>112</b> wishes to set the value of the user-specific constants Bs<sub>W</sub>, the user can simply walk a known distance (e.g.,  of a mile) while permitting the values Ts<sub>W</sub>, Tc<sub>W</sub>, Ts<sub>R</sub>, and Tc<sub>R </sub>to accumulate during the time period taken to walk the distance. Because the values Ts<sub>R </sub>and Tc<sub>R </sub>will be zero when the user is walking, the constant Bs<sub>R </sub>drops out of the equation, and the equation (26) can be solved for the value of Bs<sub>W</sub>. This value of Bs<sub>W </sub>can then be stored and used in the equation (26), to calculate distance traveled by the user <b>112</b> during normal operation. Alternatively, the user can select a calibration mode specifically for walking, and only the portion of the equation (26) relating to walking can be used to calculate the value of Bs<sub>W </sub>after the user walks a known distance.</p>
    <p>Similarly, when the equation (26) is used and the user <b>112</b> wishes to set the value of the user-specific constants Bs<sub>R</sub>, the user can simply run a known distance (e.g.,  of a mile) while permitting the values Ts<sub>W</sub>, Tc<sub>W</sub>, Ts<sub>R</sub>, and Tc<sub>R </sub>to accumulate during the time period taken to walk the distance. Because the values Ts<sub>W </sub>and Tc<sub>W </sub>will be zero when the user is running, the constant Bs<sub>W </sub>drops out of the equation, and the equation (26) can be solved for the value of Bs<sub>R</sub>. As with the value of Bs<sub>W</sub>, this value of Bs<sub>R </sub>can then be stored and used in the equation (26) to calculate distance traveled by the user <b>112</b> during normal operation. Alternatively, similar to the walking calibration discussed above, the user can select a calibration mode specifically for running, and only the portion of the equation (26) relating to running can be used to calculate the value of Bs<sub>R </sub>after the user runs a known distance.</p>
    <p>Regardless of the equation(s) used to determine the user's pace or speed, and regardless of the calibration technique(s) used to optimize those equation(s), in one illustrative embodiment of the invention, as discussed above in connection with FIG. 4, user-specific information (such as one or more calibration constants) may be stored somewhere in the system for each of several users (e.g., family members or members of a track team), and such information be selectively accessed and used in response to the user entering his or her name, user ID or other identifier into the wrist-mounted unit <b>104</b> or elsewhere. In addition, to the extent a user's choice of running or walking shoe or other accessory (e.g., a knee or ankle brace) has any effect on the proper selection of his or her calibration constant(s), each user may also input another code to indicate the user's choice. In response to the entry of such data, the wrist-mounted unit <b>104</b> (or other device) may then access and use previously-stored calibration information corresponding to the user's choice. In addition, the entry of such information may also permit the appropriate device to place accumulated information (e.g., distance traveled) into a log corresponding to the choice. For example, data such as total distance traveled may be separately logged for each pair or shoes worn by the user.</p>
    <p>FIG. 14 shows and illustrative example of a primary routine <b>1400</b> that may be performed by the processor <b>422</b> of the foot-mounted unit <b>102</b> (FIG. 4) in accordance with one embodiment of the present invention. The processor <b>422</b> may, for example, execute a plurality of instructions stored in the memory <b>424</b> or another computer-readable medium to perform the various method steps and routines of the primary routine <b>1400</b>. Alternatively, of course, the primary routine <b>1400</b> can be implemented using dedicated hardware or firmware, or any combination of hardware, firmware and software capable of achieving a similar result.</p>
    <p>With regard to the illustrative routine <b>1400</b> and the constituent routines thereof, it should be appreciated that the precise order of the method steps and routines is not critical, and that the invention is not limited to embodiments that perform method steps and routines precisely in the order shown. Additionally, it should be appreciated that the method steps and routines described herein represent only one of numerous possible routines that can achieve the desired result, and the invention is not limited to the particular routine shown. Further, it should be understood that some embodiments of the invention can perform fewer than all of the functions performed by the method steps and routines described herein, and that the invention is not limited to embodiments which employ all of the functions performed by the illustrated routines.</p>
    <p>The primary routine <b>1400</b> may be best understood with reference to FIG. 7 in conjunction with FIG. 14, as the primary routine <b>1400</b> is concerned primarily with identifying the various characteristics in a signal such as that shown in FIG. 7 that are indicative of particular events during a user's footsteps (e.g., the heel-strike events <b>702</b> <i>a-b </i>and toe-off events <b>704</b> <i>a-b </i>of FIG. <b>7</b>), and in performing calculations and analyses based upon measured time periods between such events.</p>
    <p>As shown, the primary routine <b>1400</b> is a continuous loop. As discussed below, various routines within the primary routine <b>1400</b> may be capable of performing functions such as responding to a user input to shut down the power of the foot-mounted unit <b>102</b>, transmitting information from the foot-mounted unit <b>102</b> to the wrist-mounted unit <b>104</b>, and altering a network address of the foot-mounted unit <b>102</b>/wrist-mounted unit <b>104</b> combination. For ease of description, however, these underlying functions will be ignored at the outset, and it will be assumed that the power in the foot-mounted unit <b>102</b> remains on at all times. First, a high-level description of the primary routine <b>1400</b> will be provided, and then functionality of each of the constituent routines of the primary routine <b>1400</b> will be described in more detail below.</p>
    <p>For convenience, it may be assumed initially that the primary routine <b>1400</b> begins at a routine <b>1404</b>, wherein the signals <b>710</b> and <b>712</b> are analyzed to attempt to identify one or more characteristics thereof indicative of a toe-off event <b>704</b>.</p>
    <p>When, during the toe-off event? routine <b>1404</b>, a toe-off event is identified, the primary routine <b>1400</b> proceeds to a step <b>1406</b>, wherein a foot contact time (Tc) is recorded based upon a measured time difference between the time of the identified toe-off even <b>704</b> and the time of a heel-strike event <b>702</b> previously identified in connection with a heel-strike event? routine <b>1408</b> of the primary routine <b>1400</b> (as described below). It should be appreciated that, during the initial cycle of the primary routine <b>1400</b>, the first identified toe-off event <b>704</b> does not follow a previously identified heel-strike event <b>702</b>. Therefore, the initial recorded Tc value will be inaccurate. In light of this, the primary routine <b>1400</b> may, for example, be permitted to cycle until data for at least one complete footstep has been accumulated before any Tc or Ts values are recorded or used (at the step <b>1406</b> or elsewhere) in performing distance, pace, speed, and/or energy expenditure calculations based thereupon. Alternatively, a dummy Tc value may be recorded during the initial iteration of the step <b>1406</b>.</p>
    <p>When, during the toe-off event? routine <b>1404</b>, a toe-off event <b>704</b> is not identified within a pre-determined period of time, the primary routine <b>1400</b> proceeds to a step <b>1418</b>, wherein an activity flag is set to false to indicate a lack of activity of the user <b>112</b>.</p>
    <p>After the step <b>1418</b>, the primary routine <b>1400</b> proceeds to a step <b>1426</b>, wherein the various timers used to measure the foot contact time (Tc), foot-air time (Ta), and step time (Ts) are reset because of the identified lack of activity.</p>
    <p>After the step <b>1406</b> (discussed above), the primary routine <b>1400</b> proceeds to a heel-strike event? routine <b>1408</b>, wherein it is determined whether one or more characteristics in the signals <b>710</b> and <b>712</b> can be identified that are indicative of a heel-strike event <b>702</b>.</p>
    <p>When, during the heel-strike event? routine <b>1408</b>, a heel-strike event <b>702</b> is identified, the primary routine <b>1400</b> proceeds to a step <b>1410</b>, wherein the activity flag (if false) is set to true to indicate that the user <b>112</b> is currently active. In addition, at the step <b>1410</b>, a step error flag (if true) is set to false to indicate that both a toe-off event <b>704</b> and a heel-strike event <b>702</b> were identified in connection with the current footstep.</p>
    <p>After the step <b>1410</b>, the primary routine <b>1400</b> proceeds to a step <b>1412</b>, wherein a measured step-time (Ts) and a measured foot air time (Ta) are recorded. Because, during the initial iteration of the primary routine <b>1400</b>, the step time (Ts) cannot be accurate, the primary routine <b>1400</b> may, for example, wait until both a toe-off even <b>704</b> and a heel-strike even <b>702</b> have been identified at least once before recording a value of Ts. Alternatively, a dummy value may be recorded as the value of Ts. Because both a toe-off event <b>704</b> and a heel-strike event <b>702</b> were identified in the steps <b>1404</b> and <b>1408</b>, however, the value of the step air time (Ta) may be assumed to be accurate at this stage and that therefore may be recorded, if desired.</p>
    <p>When, during the heel-strike event? routine <b>1408</b>, it is determined that a heel-strike event <b>702</b> has not occurred within a predetermined time period, the primary routine <b>1400</b> proceeds to a step <b>1420</b>, wherein it is determined whether this is the third consecutive time that a heel-strike event <b>702</b> was not identified during the heel-strike event? routine <b>1408</b>.</p>
    <p>When, at the step <b>1420</b>, it is determined that it is not the third consecutive time that a heel-strike event <b>702</b> has not been identified during the heel-strike event? routine <b>1408</b>, the primary routine <b>1400</b> proceeds to a step <b>1422</b>, wherein the value of Tc is set to the last recorded Tc value, rather than the current incorrect value, and the value of Ts is set to maximum allowable value of Ts (i.e., the threshold Ts value that caused the heel-strike event? routine <b>1408</b> to kick out to the step <b>1420</b>. The value of Ts is not replaced by a substitute value in this situation because it is desirable to use cumulative sum of all recorded Ts values as the total elapsed time of the outing, and such replacement would result in an error in this value.</p>
    <p>When, at the step <b>1420</b>, it is determined that it is the third consecutive time that a heel-strike event <b>702</b> has not been identified during the heel-strike event? routine <b>1408</b>, the primary routine <b>1400</b> proceeds to a step <b>1424</b>, wherein the step error flag (if false) is set to true to indicate that a step monitoring error has occurred. As discussed below, the step error flag may be passed to the wrist-mounted unit <b>104</b>, and used thereby to indicate an anomaly to the user <b>112</b>.</p>
    <p>After the step <b>1424</b>, the primary routine <b>1400</b> proceeds to the step <b>1426</b>, wherein the Tc, Ta, and Ts timers are reset because of the identified missing of the heel-strike event.</p>
    <p>Following either of the steps <b>1412</b> or <b>1426</b>, the primary routine <b>1400</b> proceeds to a routine <b>1414</b> wherein a determination is made whether the foot-mounted unit <b>102</b> should remain powered on, should be powered down, or should be temporarily set to a low-power sleep mode. As explained in more detail below in connection with FIG. 25, based upon the level of activity detected (i.e., whether and for how long the activity flag has been false), the check activity? routine <b>1414</b> may take appropriate action. For example, it may cause the foot-mounted unit <b>102</b> to enter a temporary, low-power sleep mode, or may set a flag that will cause the foot-mounted unit <b>102</b> to power down completely.</p>
    <p>After the step <b>1414</b>, the primary routine <b>1400</b> proceeds to a routine <b>1416</b>, wherein the recorded values of Tc, Ts, and Ta accumulated during the previous iteration of the primary routine <b>1400</b> are evaluated and smoothed, and certain values are calculated based thereupon. Such values may, for example, be displayed to the user <b>112</b> via a display on the foot-mounted unit <b>102</b> and/or may be transmitted to the wrist-mounted unit <b>104</b> or elsewhere for display to the user, processing, and/or storage.</p>
    <p>After the routine <b>1416</b>, the primary routine <b>1400</b> proceeds to a routine <b>1402</b>, wherein the primary routine <b>1400</b> waits for a predetermined amount of time (see ignore time <b>708</b> of FIG. 7) before attempting to identify the next toe-off event <b>704</b>.</p>
    <p>After the routine <b>1402</b>, the primary routine <b>1400</b> returns to the toe-off event? routine <b>1404</b> (discussed above).</p>
    <p>The various routines of the primary routine <b>1400</b> and a number of subroutines thereof now will be discussed. Each of these routines and subroutines may be best understood with reference to FIG. 7, in conjunction with the flow diagram illustrating the same. An example implementation of the wait routine <b>1402</b> of the primary routine <b>1400</b> is illustrated in FIG. <b>15</b>.</p>
    <p>As shown, the routine <b>1402</b> begins at a step <b>1502</b>, wherein it is determined whether the ignore time <b>708</b> has elapsed since the last heel-strike event <b>702</b>.</p>
    <p>When, at the step <b>1502</b>, it is determined that the ignore time <b>708</b> has not yet elapsed, the routine <b>1402</b> proceeds to the process button routine <b>1504</b>, which is described below in connection with FIG. <b>16</b>.</p>
    <p>After the process button routine <b>1504</b>, the routine <b>1402</b> proceeds to a process RF routine <b>1506</b>, during which any necessary RF transmission/reception functions, e.g., information transmissions to and/or from the wrist-mounted unit <b>104</b> may be performed.</p>
    <p>After the routine <b>1506</b>, the routine <b>1402</b> returns to the routine <b>1502</b> (discussed above).</p>
    <p>An example implementation of the process button routine <b>1504</b> of FIG. 15 is shown in FIG. <b>16</b>. As shown, the routine <b>1504</b> begins at step <b>1602</b>, wherein it is determined whether the button <b>204</b> on the foot-mounted unit <b>102</b> is currently depressed.</p>
    <p>When, at the step <b>1602</b>, it is determined that the button <b>204</b> is not depressed, the routine <b>1504</b> proceeds to a step <b>1604</b>, wherein it is determined whether the foot-mounted unit <b>102</b> is currently powered on.</p>
    <p>When, at the step <b>1604</b>, it is determined that the foot-mounted unit <b>102</b> is not yet powered on, the routine <b>1504</b> proceeds back to the step <b>1602</b>, wherein it is again determined whether the button <b>1502</b> is depressed.</p>
    <p>When, at the step <b>1602</b>, it is determined that the button <b>204</b> is depressed, the routine <b>1504</b> proceeds to a step <b>1606</b>, wherein it is determined whether the foot-mounted unit <b>102</b> is powered on.</p>
    <p>When, at the step <b>1606</b>, it is determined that the foot-mounted unit <b>102</b> is not yet powered on, the routine <b>1504</b> proceeds to a step <b>1608</b>, wherein the foot-mounted unit <b>102</b> is powered up and initialized, and the routine <b>1504</b> terminates.</p>
    <p>When, at the step <b>1606</b>, it is determined that the foot-mounted unit <b>102</b> is already powered on, the routine <b>1504</b> proceeds to a step <b>1610</b>, wherein it is determined whether the button <b>204</b> has been depressed for more than three seconds.</p>
    <p>When, at the step <b>1610</b>, it is determined that the button has not been depressed for more than 3 seconds, the routine <b>1504</b> proceeds to a step <b>1626</b>, wherein it is determined whether the shutting down flag is currently true.</p>
    <p>When, at the step <b>1626</b>, it is determined that the shutting down flag is currently true, the routine <b>1504</b> proceeds to a step <b>1628</b>, wherein the shutting down flag is set to false, and the routine <b>1504</b> terminates.</p>
    <p>When, at the step <b>1626</b>, it is determined that the shutting down flag is not currently true, the routine <b>1504</b> proceeds to a step <b>1630</b>, wherein the shutting down flag is set to true, ant the routine <b>1504</b> terminates. As discussed below in connection with step <b>1622</b>, after the shutting down flag has been true for more than thirty seconds, the foot-mounted unit is powered down.</p>
    <p>When, at the step <b>1610</b> (discussed above), it is determined that the button <b>204</b> has been depressed for more than three seconds, the routine <b>1504</b> proceeds to a step <b>1614</b>, wherein a new network address for the foot-mounted unit <b>102</b> may be selected. In one embodiment of the invention, a new address is selected at random from a group of one-hundred possible addresses.</p>
    <p>After the step <b>1614</b>, the routine <b>1504</b> proceeds to a step <b>1616</b>, wherein it is determined whether the button remains depressed.</p>
    <p>When, at the step <b>1616</b>, it is determined that the button remains depressed, the routine <b>1504</b> proceeds to a step <b>1618</b>, wherein a new network address for the foot-mounted device is broadcasted by the transceiver <b>420</b>.</p>
    <p>When, at the step <b>1616</b>, it is determined that the button is no longer depressed, the routine <b>1504</b> terminates.</p>
    <p>When, at the step <b>1604</b> (discussed above), it is determined that the foot-mounted unit <b>102</b> is currently powered on, the routine <b>1504</b> proceeds to a step <b>1620</b>, wherein it is determined whether the shutting down flag is true.</p>
    <p>When, at the step <b>1620</b>, it is determined that the shutting down flag is true, the routine <b>1504</b> proceeds to the step <b>1622</b>, wherein it is determined whether the shutting down flag has been true for more than thirty seconds.</p>
    <p>When, at the step <b>1622</b>, it is determined that the shutting down flag has been true for more than thirty seconds, the routine <b>1504</b> proceeds to a step <b>1624</b>, wherein the foot-mounted unit is powered down.</p>
    <p>After the step <b>1624</b>, the routine <b>1504</b> returns to the step <b>1602</b> (discussed above).</p>
    <p>FIG. 17 shows an illustrative implementation of the toe-off event? routine <b>1404</b> of the primary routine <b>1400</b>. As shown in FIG. 17, the toe-off event routine <b>1404</b> begins at a step <b>1701</b>, wherein certain values (discussed below) are initialized.</p>
    <p>After the step <b>1701</b>, the toe-off event? routine <b>1404</b> proceeds to a step <b>1702</b>, wherein a sample of an output signal of the sensor <b>418</b> (i.e., a difference between the signals <b>710</b> and <b>712</b> of FIG. <b>7</b>), is taken.</p>
    <p>After the step <b>1702</b>, the toe-off event? routine <b>1404</b> proceeds to an update threshold routine <b>1704</b>, during which the value of a variable threshold which is used in connection with the heel-strike event? heel-strike event? routine <b>1408</b> (described below). An example of implementation of the update threshold routine <b>1704</b> is described below in connection with FIG. <b>23</b>.</p>
    <p>After the routine <b>1704</b>, the toe-off event? routine <b>1404</b> proceeds to a step <b>1706</b>, wherein it is determined whether an amount of time has elapsed that is in excess of a maximum possible time of a foot-step (i.e., it is determined whether the toe-off event must have been missed because too much time has elapsed since the last heel-strike event <b>702</b>).</p>
    <p>When, at the step <b>1706</b>, it is determined that an excessive amount of time has elapsed since the last heel-strike event <b>704</b>, the toe-off event? routine <b>1404</b> proceeds to the step <b>1418</b> (discussed above in connection with the primary routine <b>1400</b>).</p>
    <p>When, at the step <b>1706</b>, it is determined that an excessive amount of time has not yet elapsed since the last heel-strike event <b>704</b>, the toe-off event? routine <b>1404</b> proceeds to a routine <b>1708</b>, wherein it is determined whether a potential toe-off event <b>704</b> occurred in connection with the last sample taken at the step <b>1702</b>. An example implementation of the routine <b>1708</b> is described below in connection with FIG. <b>18</b>.</p>
    <p>After the routine <b>1708</b>, the toe-off event? routine <b>1404</b> proceeds to an air signature? routine <b>1710</b>, wherein it is determined whether an air signature <b>706</b> has been identified in the signals <b>710</b> and <b>712</b>. An example implementation of the air signature? routine <b>1710</b> is described below in connection with FIG. <b>19</b>. As shown in FIG. 7, an air signature in the signals <b>710</b> and <b>712</b> may be an extended period of relatively constant, negative acceleration during a footstep.</p>
    <p>When, at the step <b>1710</b>, it is determined that an air signature has not yet been identified in the signals <b>710</b> and <b>712</b>, the toe-off event? routine <b>1404</b> proceeds to the process button routine <b>1506</b> (discussed above), then to the process RF routine <b>1504</b> (also discussed above), and finally back to the step <b>1702</b>, wherein another sample of the signals <b>710</b> and <b>712</b> is taken.</p>
    <p>When, at the step <b>1710</b>, it is determined that an air signature has been identified in the sensor signal, the toe-off event? routine <b>1404</b> proceeds to the step <b>1406</b> of the primary routine <b>1400</b>.</p>
    <p>FIG. 18 shows an illustrative implementation of the routine <b>1708</b> of FIG. 17, wherein it is determined whether a potential toe-off event <b>704</b> has occurred.</p>
    <p>As shown in FIG. 18, the routine <b>1708</b> begins at a step <b>1802</b> wherein it is determined whether the most recent sample taken during the step <b>1702</b> is greater than the next most recent sample taken at the step <b>1702</b>.</p>
    <p>When, at the step <b>1802</b>, it is determined that the most recent sample is greater than the next most recent sample, the routine <b>1708</b> proceeds to a step <b>1806</b>, wherein a variable count is incremented by one. The variable count is one of the values that may be initialized in connection with the step <b>1701</b> of the toe-off event? routine <b>1404</b> of FIG. <b>17</b>.</p>
    <p>When, at the step <b>1802</b>, it is determined that the most recent sample is not greater than the next most recent sample, the routine <b>1708</b> proceeds to a step <b>1804</b>, wherein the variable count is reset to zero, and the routine <b>1708</b> then terminates.</p>
    <p>After the step <b>1806</b> (discussed above), the routine <b>1708</b> proceeds to a step <b>1808</b>, wherein it is determined whether the variable count is greater than one.</p>
    <p>When, at the step <b>1808</b>, it is determined that the variable count is not greater than one, the routine <b>1708</b> terminates.</p>
    <p>When, at the step <b>1808</b>, it is determined that the variable count is greater than one, the routine <b>1708</b> proceeds to a step <b>1810</b>, wherein a variable diff is set to be equal to the value of the current sample minus the value of the third most recent sample, plus the value of the current sample divided by four.</p>
    <p>After the step <b>1810</b>, the routine <b>1708</b> proceeds to a step <b>1812</b>, wherein it is determined whether the variable diff is greater than another variable diff_max. The variable diff_max is one of the values which may be initialized in connection with the step <b>1701</b> of the toe-off event? routine <b>1404</b> of FIG. <b>17</b>.</p>
    <p>When, at the step <b>1812</b>, it is determined that the variable diff is greater than the variable diff_max, the routine <b>1708</b> proceeds to a step <b>1816</b>, wherein the variable diff_max is set to be equal to the variable diff.</p>
    <p>After the step <b>1816</b>, the routine <b>1708</b> proceeds to a step <b>1818</b>, wherein, the current value of a timer used to measure foot contact times (the Tc timer) is recorded as a possible foot contact time (Tc). The Tc timer may have been reset in connection with the identification of a heel-strike event <b>702</b> in the heel-strike event? heel-strike event? routine <b>1408</b> of the primary routine <b>1400</b>, or may have been reset in connection with the step <b>1426</b> of the primary routine <b>1400</b>.</p>
    <p>After the step <b>1818</b>, the routine <b>1708</b> proceeds to a step <b>1820</b> wherein the timer used to measure foot air time (the Ta timer) is reset so that, if the current sample is later determined to be an actual lift-off event, the Ta timer is set appropriately. After the step <b>1820</b>, the routine <b>1708</b> terminates.</p>
    <p>When, at the step <b>1812</b> (discussed above), it is determined that the variable diff is not greater than the variable diff_max, the routine <b>1708</b> proceeds to a step <b>1814</b>, wherein it is determined whether the variable diff is greater than 80% of the variable diff_max.</p>
    <p>When, at the step <b>1814</b>, it is determined that the variable diff is not greater than 80% of the variable diff_max, the routine <b>1708</b> terminates.</p>
    <p>When, at the step <b>1814</b>, it is determined that the variable diff is greater than 80% of the variable diff_max, the routine <b>1708</b> proceeds to the step <b>1818</b> (discussed above), then to the step <b>1820</b> (also discussed above), and the routine <b>1708</b> then terminates.</p>
    <p>FIG. 19 illustrates an illustrative implementation of the air signature? routine <b>1710</b> of the toe-off event? routine <b>1404</b> of FIG. 17, during which the signals <b>710</b> and <b>712</b> are analyzed to identify an air signature <b>706</b>.</p>
    <p>As shown, the air signature? routine <b>1710</b> beings at a step <b>1902</b>, wherein it is determined whether the current sample is negative. As used herein, a sample refers to a voltage difference between the signals <b>710</b> and <b>712</b> at a particular moment in time. With reference to FIG. 7, assuming that the signal <b>710</b> is exactly at level 128, a sample would be positive if it were taken when the signal <b>712</b> is at a level greater than level 128, and would be negative if it were taken when the signal is at a level less than level 128.</p>
    <p>When, at the step <b>1902</b>, it is determined that the current sample is positive, the air signature? routine <b>1710</b> proceeds to a step <b>1904</b>, wherein a counter that keeps track of a time period during which sequential samples of the signals <b>710</b> and <b>712</b> are negative (the below<sub></sub>0 counter) is reset, and a variable max_level_below<sub></sub>0 also is reset. The variable max_level_below<sub></sub>0 represents the maximum negative acceleration that has occurred since the last time the below<sub></sub>0 counter was reset.</p>
    <p>After the step <b>1904</b>, the air signature? routine <b>1710</b> proceeds to the routine <b>1506</b> (as shown in FIG. <b>17</b>).</p>
    <p>When, at the step <b>1902</b>, it is determined that the current sample is negative, the air signature? routine <b>1710</b> proceeds to step <b>1906</b>, wherein it is determined whether the absolute value of the sample is greater than the variable max_level_below<sub></sub>0.</p>
    <p>When, at the step <b>1906</b>, it is determined that the absolute value of the sample is greater than the variable max_level_below<sub></sub>0, the air signature? routine <b>1710</b> proceeds to a step <b>1908</b>, wherein the variable max_level_below<sub></sub>0 is updated to be equal to the absolute value of the sample. After the step <b>1908</b>, the air signature? routine <b>1710</b> proceeds to a step <b>1910</b> (discussed below).</p>
    <p>When, at the step <b>1906</b>, it is determined that the sample is not greater than the variable max_level_below<sub></sub>0, the air signature? routine <b>1710</b> proceeds to the step <b>1910</b>, wherein it is determined whether: (1) the below<sub></sub>0 counter has reached fifty milliseconds (ms), and (2) the variable max_level_below<sub></sub>0 is greater than seventeen.</p>
    <p>When, at the step <b>1910</b>, it is determined that both of these conditions are not met, the air signature? routine <b>1710</b> proceeds to the routine <b>1506</b> as shown in FIG. <b>17</b>.</p>
    <p>When, at the step <b>1910</b>, it is determined that both of these conditions are met, the air signature? routine <b>1710</b> proceeds to a step <b>1912</b>, wherein both the below<sub></sub>0 counter and the variable max_level_below<sub></sub>0 are reset.</p>
    <p>After the step <b>1912</b>, the air signature? routine <b>1710</b> proceeds to a step <b>1914</b>, wherein it is determined whether at least one possible Tc has been recorded at the step <b>1818</b> of the routine <b>1708</b> of FIG. <b>18</b>.</p>
    <p>When, at the step <b>1914</b>, it is determined that at least one possible Tc has been recorded, the air signature? routine <b>1710</b> proceeds to the step <b>1406</b> of FIG. 14 (discussed above).</p>
    <p>When, at the step <b>1914</b>, it is determined that no Tc has been recorded in connection with step <b>1818</b> of the routine <b>1708</b>, the air signature? routine <b>1710</b> proceeds to the process button routine <b>1506</b> as shown in FIG. <b>17</b>.</p>
    <p>As mentioned above, one of the events identified during each footstep taken by the user <b>112</b> is a heel-strike event <b>702</b>. In accordance with one aspect of the invention, the signals <b>710</b> and <b>712</b> are analyzed to identify any of a plurality of predetermined criteria indicative of such an event. An example of one such criteria is illustrated in FIG. <b>20</b>. As shown, after an air signature <b>706</b> of the signal <b>712</b> has been identified (i.e., it has been determined that the foot <b>114</b> of the user <b>112</b> is airborne), a subsequent sharp, positive peak <b>2002</b> in the signal <b>712</b> is one characteristic in the signal <b>712</b> that is indicative of the foot <b>114</b> of the user <b>112</b> impacting the surface <b>108</b>. Other criteria which, if satisfied, may also be indicative of a heel-strike event <b>702</b> are discussed below in connection with the routine <b>2110</b> (shown in FIGS. <b>21</b> and <b>22</b>).</p>
    <p>In the example embodiment described herein, the heel-strike event? routine <b>1408</b> of the primary routine <b>1400</b> is the routine responsible for performing this analysis.</p>
    <p>An illustrative implementation of the heel-strike event? routine <b>1408</b> is shown in FIG. <b>21</b>.</p>
    <p>Referring briefly to FIG. 7, the period during which the user's foot <b>114</b> is airborne (i.e., the period between each toe-off event <b>704</b> and the subsequent heel-strike event <b>702</b>) is characterized by a relatively smooth signal that is substantially free of sharp transitions. Based upon this characteristic, one goal of the heel-strike event? routine <b>1408</b> is to identify when one or more sharp transitions first begin to appear in the signal <b>712</b>. When such sharp transition(s) appear in the signal, it may be concluded that the foot <b>114</b> has impacted with the surface <b>108</b>.</p>
    <p>As shown in FIG. 21, the heel-strike event? routine <b>1408</b> begins at a step <b>2101</b>, wherein certain values (discussed below) used in connection with the heel-strike event? routine <b>1408</b> are initialized.</p>
    <p>After the step <b>2101</b>, the heel-strike event? routine <b>1408</b> proceeds to a step <b>2102</b>, wherein a sample of the signals <b>712</b> and <b>710</b> (discussed above) is taken.</p>
    <p>After the step <b>2102</b>, a value of the variable threshold is updated in connection with the routine <b>1704</b> (discussed below in connection with FIG. <b>23</b>). As explained below, the variable threshold may be used in connection with the steps <b>2110</b> and <b>2112</b> to determine whether the user's foot <b>114</b> has, in fact, impacted with the surface <b>108</b>. Advantageously, the variable threshold is updated dynamically in response to measured characteristics of the samples taken during the preceding five footsteps taken by the user <b>112</b>.</p>
    <p>After the routine <b>1704</b>, the heel-strike event? routine <b>1408</b> proceeds to a step <b>2106</b>, wherein a variable qualifying cycles is incremented by one. The variable qualifying cycles may, for example, be one of the values that was initialized in connection with the step <b>2101</b> discussed above.</p>
    <p>After the step <b>2106</b>, the heel-strike event? routine <b>1408</b> proceeds to a step <b>2108</b>, wherein it is determined whether an excessive amount of time has elapsed since the heel-strike event? routine <b>1408</b> began looking for a heel-strike event <b>702</b>. That is, it is determine whether the sought-after heel-strike event <b>702</b> must have been missed by the heel-strike event? routine <b>1408</b> because the currently-measured step time (Ts) has reached a value that is outside of a predetermined range of acceptable step times for human beings. In one embodiment, this upper limit on acceptable step time (Ts) is approximately 1360 milliseconds. In this regard, it should be appreciated that, in addition to or in lieu of the maximum acceptable step time (Ts), other variables such as a foot air time (Ta) may also or alternatively be examined at the step <b>2108</b> to determine whether the sought-after heel-strike event <b>702</b> must have been missed.</p>
    <p>When, at the step <b>2108</b>, it is determined that the current step time (Ts) value has exceeded that maximum acceptable step time, the heel-strike event? routine <b>1408</b> proceeds to the step <b>1420</b> of the primary routine <b>1400</b>, as shown in FIG. <b>14</b>.</p>
    <p>When, at the step <b>2108</b>, it is determined that an excessive amount of time has not elapsed since the heel-strike event? routine <b>1408</b> began looking for a heel-strike event even <b>702</b>, the heel-strike event? routine <b>1408</b> proceeds to a step <b>2110</b>, wherein it is determined whether any of a number of predetermined landing criteria have been met as a result of the most recent sample taken at the step <b>2102</b>. An example implementation of the routine <b>2110</b> is described below in connection with FIG. <b>22</b>.</p>
    <p>When, during the routine <b>2110</b>, it is determined that at least one of the several predetermined landing criteria was met as a result of the most recent sample taken at the step <b>2102</b>, the heel-strike event? routine <b>1408</b> proceeds to a is landing qualified? is landing qualified? routine <b>2112</b>, wherein additional analysis may be performed to ensure that the satisfied landing criteria was definitely the result of a heel-strike event <b>702</b>. An example implementation of the is landing qualified? is landing qualified? routine <b>2112</b> is described below in connection with FIG. <b>24</b>.</p>
    <p>When, during the is landing qualified? is landing qualified? routine <b>2112</b>, it is determined that a heel-strike event <b>702</b> has indeed been identified, the heel-strike event? routine <b>1408</b> proceeds to steps <b>2114</b>, <b>2116</b>, <b>2118</b>, and <b>2120</b>, wherein various variables are set based upon the value of a so-called down correction timer. As explained below, this down correction timer would have been preset previously in connection with the routine <b>2110</b> (FIG. 22) in response to one of the plurality of landing criteria being met.</p>
    <p>In essence, the down correction timer is used to measure the amount of time that has elapsed since the identification of the first of several samples that are determined to satisfy one of the landing criteria. For example, if three samples are used to satisfy a landing criteria, recognizing that the first of the three samples occurred two sample periods prior to the third sample, the down correction timer would have been preset during the routine <b>2110</b> to a value equal to two sample periods, and would therefore reflect a time period that has elapsed since the time of that first sample.</p>
    <p>At the step <b>2114</b>, the value of Ts is set to be equal to the current value of the Ts timer minus the current value of the down correction timer. The Ts timer may have been preset to the value of the down correction timer in connection with a step <b>2120</b> (described below) during a previous iteration of the heel-strike event? routine <b>1408</b>, or may have been reset in connection with the step <b>1426</b> (discussed above) of the primary routine <b>1400</b>.</p>
    <p>Similarly, at the step <b>2116</b>, the value of Ta is set to be equal to the current value of the Ta timer minus the current value of the down correction timer. Therefore, the value of Ta also takes into account the time at which the first of several samples used to satisfy one of the landing criteria was taken. The Ta timer may have been reset at the step <b>1820</b> of the routine <b>1708</b> (FIG. <b>18</b>), or it may have been reset at the step <b>1426</b> of the primary routine <b>1400</b>.</p>
    <p>At the steps <b>2118</b> and <b>2120</b>, the Tc timer and Ts timer each are preset to the current value of the down correction timer.</p>
    <p>After the step <b>2120</b>, the heel-strike event? routine <b>1408</b> proceeds to the step <b>1410</b> of the primary routine <b>1400</b>, as shown in FIG. <b>14</b>.</p>
    <p>When, during the routine <b>2110</b> (described above), it is determined that none of the landing criteria were met as a result of the most recent sample taken at the step <b>2102</b>, the heel-strike event? routine <b>1408</b> proceeds to step <b>2122</b>, wherein it is determined whether a variable qualifying cycles is greater than seven. The significance of the variable qualifying cycles, as well as the so-called qualification flag, will be explained below in connection with the description of the is landing qualified? routine <b>2112</b> (FIG. <b>24</b>).</p>
    <p>When, at the step <b>2122</b>, it is determined that the variable qualifying cycles is not greater than seven, the heel-strike event? routine <b>1408</b> proceeds first to the routines <b>1504</b> and <b>1506</b> (discussed above), and then back to the step <b>2102</b>, wherein another sample of the signals <b>710</b> and <b>712</b> is taken.</p>
    <p>When, at the step <b>2122</b>, it is determined that the variable qualifying cycles is greater than seven, the heel-strike event? routine <b>1408</b> proceeds to steps <b>2124</b> and <b>2126</b>, wherein the variable qualifying cycles is reset to zero, and the qualification flag is set to false.</p>
    <p>After the step <b>2126</b>, the heel-strike event? routine <b>1408</b> proceeds first to the routines <b>1504</b> and <b>1506</b> (discussed above), and then back to the step <b>2102</b>, wherein another sample of the signals <b>710</b> and <b>712</b> is taken.</p>
    <p>When, at during the is landing qualified? routine <b>2112</b>, it is determined that a heel-strike event <b>702</b> has not yet been confirmed, the heel-strike event? routine <b>1408</b> proceeds first to the routines <b>1504</b> and <b>1506</b> (discussed above), and then back to the step <b>2102</b>, wherein another sample of the signals <b>710</b> and <b>712</b> is taken.</p>
    <p>FIG. 22 shows an example implementation of the routine <b>2110</b> shown in FIG. <b>21</b>. As mentioned above, the routine <b>2110</b> serves to identify one or more characteristics in the signals <b>710</b> and <b>712</b> that satisfy at least one of a plurality of predetermined criteria consistent with the occurrence of a heel-strike event <b>702</b>.</p>
    <p>As shown, the routine <b>2110</b> begins at a step <b>2202</b>, wherein it is determined whether the difference between a current sample and the next most recent sample is greater than the variable threshold. As mentioned above, the value of the variable threshold may be dynamically adjusted based upon at least one characteristic of one or more previously taken samples. For example, in the illustrative routine <b>1704</b> described below in connection with FIG. 23, samples taken during the last five footsteps of the user <b>112</b> are used to dynamically set the value of the variable threshold. It should be appreciated, however, that the quantity threshold may alternatively be a fixed (i.e., non-variable) value, and the invention is not limited to embodiments that employ a dynamically-adjusted value as the threshold.</p>
    <p>When, at the step <b>2202</b>, it is determined that the difference between the current sample and the next most recent sample is greater than the value of the variable threshold, the routine <b>2110</b> proceeds to a step <b>2204</b>, wherein a variable down correction value is set to be equal to the single sample period between the two samples. The variable down correction value is used to preset the down correction timer in connection with the is landing qualified? is landing qualified? routine <b>2112</b> (see FIG. <b>24</b>).</p>
    <p>After the step <b>2204</b>, the routine <b>2110</b> proceeds immediately to the is landing qualified? is landing qualified? routine <b>2112</b> of the heel-strike event? routine <b>1408</b>, as shown in FIG. <b>21</b>.</p>
    <p>When, at the step <b>2202</b>, it is determined the difference between the two most recent samples is not greater than the value of the variable threshold, the routine <b>2110</b> proceeds to a step <b>2206</b>, wherein it is determined whether the sum of the last three differences (i.e., the three differences between consecutive ones of the last four samples) is greater than two times the value of the variable threshold.</p>
    <p>When, at the step <b>2206</b>, it is determined that the sum of the last three differences is greater than two times the value of the variable threshold, the routine <b>2110</b> proceeds to a step <b>2208</b>, wherein it is determined whether the first one of the last three differences is greater than two-thirds of the value of the variable threshold.</p>
    <p>When, at the step <b>2208</b>, it is determined that the first of the last three differences is greater than two-thirds of the value of the variable threshold, the routine <b>2110</b> proceeds to a step <b>2210</b>, wherein the variable down correction value is set to be equal to three times the sample period. The variable down correction value is set to this value because it is recognized that three sample periods have occurred since the first of the four samples analyzed in connection with the steps <b>2206</b> and <b>2208</b> was taken.</p>
    <p>When, at the step <b>2208</b>, it is determined that the first of the last three differences is not greater than two-thirds of the value of the variable threshold, the routine <b>2210</b> proceeds to a step <b>2212</b> (described below).</p>
    <p>When, at the step <b>2206</b>, it is determined that the sum of the last three differences is not greater than two times the value of the variable threshold, the routine <b>2110</b> also proceeds to the step <b>2212</b>.</p>
    <p>At the step <b>2212</b>, it is determined whether three of the last four differences (i.e., the differences between consecutive ones of the last five samples) are greater than two-thirds of the value of the variable threshold.</p>
    <p>When, at the step <b>2212</b>, it is determined that three of the last four differences are greater than two-thirds of the value of the variable threshold, the routine <b>2110</b> proceeds to a step <b>2214</b>, wherein it is determined whether the first one of the last four differences is greater than two-thirds of the value of the variable threshold.</p>
    <p>When, at the step <b>2214</b>, it is determined that the first one of the last four differences is greater than two-thirds of the value of the variable threshold, the routine <b>2110</b> proceeds to a step <b>2216</b>, wherein the variable down correction value is set to be equal to four times the sample period. The variable down correction value is set to this value because it is recognized that four full sample periods have elapsed since the first of the five samples analyzed in connection with the steps <b>2212</b> and <b>2214</b> was taken.</p>
    <p>When, at the step <b>2214</b>, it is determined that the first of the last four differences is not greater than two-thirds of the value of the variable threshold, the routine <b>2110</b> proceeds to a step <b>2218</b>, wherein the variable down correction value is set to be equal to three times the sample period. The variable down correction value is set to this value because it is recognized that the first of the last five samples was not used in satisfying a criterion of the steps <b>2212</b> and <b>2214</b>, but that the second of the last five samples must have been so used. Therefore, three sample periods would have elapsed between the second of the last five samples and the most recent one of the last five samples.</p>
    <p>When, at the step <b>2212</b>, it is determined that three of the last four differences are not greater than two-thirds of the value of the variable threshold, routine <b>2110</b> proceeds to a step <b>2220</b>, wherein it is determined whether the difference between any two of the last four samples is greater than 40 levels (using the scale of 0-256 levels discussed above in connection with FIG. <b>7</b>).</p>
    <p>When, at the step <b>2220</b>, it is determined that the difference between two of the last four samples is greater than 40 levels, the routine <b>2110</b> proceeds to a step <b>2222</b>, wherein the variable down correction value is set to be equal to a single sample period.</p>
    <p>After the step <b>2222</b>, the routine <b>2110</b> proceeds to the is landing qualified? routine <b>2112</b> of the routine <b>1408</b>, as shown in FIG. <b>21</b>.</p>
    <p>When, at the step <b>2220</b>, it is determined that no difference between any two of the last four samples is greater than 40 levels, the routine <b>2110</b> proceeds to the step <b>2122</b> of the heel-strike event? routine <b>1408</b>, as shown in FIG. <b>21</b>.</p>
    <p>FIG. 23 shows an example implementation of the routine update threshold <b>1704</b>, which may be performed after each of the steps <b>1702</b> and <b>2102</b> of the toe-off event? routine <b>1404</b> and the heel-strike event? routine <b>1408</b>, respectively.</p>
    <p>As shown in FIG. 23, the update threshold routine <b>1704</b> begins at a step <b>2302</b>, wherein it is determined whether the sample is less than 64. Again, it should be appreciated that each sample taken represents a difference between the current level (on a scale of 0-255) of the active signal <b>712</b> and the current level of the reference signal <b>710</b>. Therefore, a given sample will be less than 64 only when the current level of the active signal <b>712</b> is more than 64 levels below the current level of the reference signal <b>710</b>.</p>
    <p>When, at the step <b>2302</b>, it is determined that the current sample is not less than 64, the update threshold routine <b>1704</b> terminates.</p>
    <p>When, at the step <b>2302</b>, it is determined that the current sample is less than 64, the update threshold routine <b>1704</b> proceeds to a step <b>2304</b>, wherein a variable neg_val is set to be equal to the absolute value of the sample (which will be positive and greater than 64) minus 64.</p>
    <p>After the step <b>2304</b>, the update threshold routine <b>1704</b> proceeds to a step <b>2306</b>, wherein it is determined whether five consecutive valid steps have been identified in connection with the primary routine <b>1400</b> of FIG. 14. A valid step may be identified, for example, when the activity flag is true and the step error flag is false for five consecutive iterations of the primary routine <b>1400</b>.</p>
    <p>When, at the step <b>2306</b>, it is determined that five consecutive valid steps have not yet been identified, the update threshold routine <b>1704</b> proceeds to a step <b>2312</b>, wherein the variable threshold is set to be equal to a default value of 25,</p>
    <p>After the step <b>2312</b>, the update threshold routine <b>1704</b> terminates.</p>
    <p>When, at the step <b>2306</b>, it is determined that five consecutive valid steps have been identified, the update threshold routine <b>1704</b> proceeds to a step <b>2308</b>, wherein the current value of the variable neg_val is averaged with all other values of the variable neg_val that have been obtained during the last five footsteps taken by the user <b>112</b>, thereby obtaining another variable ave_neg_val.</p>
    <p>After the step <b>2308</b>, the update threshold routine <b>1704</b> proceeds to a step <b>2310</b>, wherein the variable threshold is set to be equal to 15, plus the value of the variable ave_neg_val divided by 2.</p>
    <p>After the step <b>2310</b>, the update threshold routine <b>1704</b> terminates.</p>
    <p>FIG. 24 is a flow diagram of an example implementation of the is landing qualified? routine <b>2112</b> of the heel-strike event? routine <b>1408</b> shown in FIG. <b>21</b>. As shown in FIG. 24, the is landing qualified? routine <b>2112</b> begins at a step <b>2402</b>, wherein it is determined whether the qualification flag is true. The qualification flag may, for example, be one of the values initialized in connection with the step <b>2101</b> (FIG. <b>21</b>), so that the qualification flag is set to be false when the is landing qualified? routine <b>2112</b> begins.</p>
    <p>When, at the step <b>2402</b>, it is determined that the qualification flag is not yet true, the is landing qualified routine <b>2112</b> proceeds to a step <b>2410</b>, wherein the qualification flag is set to true. Because the is landing qualified? routine <b>2112</b> is entered only when at least one of the several landing criteria of the routine <b>2110</b> has been met, the qualification flag is set to true in connection with the step <b>2410</b> only after at least one of these landing criteria has been met. As explained in more detail below, the setting of the qualification flag to true in connection with the step <b>2410</b> enables a heel-strike event <b>702</b> to possibly be qualified during a subsequent iteration of the is landing qualified? routine <b>2112</b>.</p>
    <p>After the step <b>2410</b>, the is landing qualified? routine <b>2112</b> proceeds to a step <b>2412</b>, wherein the down correction timer is set to be equal to the current value of the variable down correction value. The variable down correction value may have been set, for example, in connection with the routine <b>2110</b> of FIG. <b>22</b>. By so setting the down correction timer at the step <b>2412</b>, the down correction timer correctly reflects the time period that has elapsed since the first of several samples that satisfied one of the landing criteria of the routine <b>2110</b> was taken. In this manner, when a heel-strike event <b>702</b> eventually is qualified in connection with a subsequent iteration of the heel-strike event? routine <b>1408</b>, the value of the down correction timer can be used to correct the values of the Ts and Ta timers in connection with the steps <b>2114</b> and <b>2116</b>, respectively, of the heel-strike event? routine <b>1408</b> of FIG. <b>21</b>.</p>
    <p>After the step <b>2412</b>, the is landing qualified? routine <b>2112</b> proceeds to steps <b>2414</b> and <b>2416</b>, wherein the variables qualifying cycles and sum_of diff are each reset to zero. In accordance with one embodiment of the invention, after the qualification flag is set to true at the step <b>2410</b> in response to one of the landing criteria of the routine <b>2110</b> being met, the heel-strike event? routine <b>1408</b> requires again that one of the landing criteria be met, this time within the next six iterations of the heel-strike event? routine <b>1408</b>. This is why, at the step <b>2122</b> of the heel-strike event? routine <b>1408</b>, it is determined whether the variable qualifying cycles is greater than seven, and why the qualification flag is set to false at the step <b>2126</b> if more than seven qualifying cycles have elapsed.</p>
    <p>After the step <b>2416</b>, the is landing qualified? routine <b>2112</b> proceeds to the step <b>2102</b> of the heel-strike event? routine <b>1408</b>, as shown in FIG. 21, wherein the next sample of the signals <b>710</b> and <b>712</b> is taken.</p>
    <p>When, at the step <b>2402</b> (described above), it is determined that the qualification flag is true, the is landing qualified? routine <b>2112</b> proceeds to a step <b>2404</b>, wherein it is determined whether the variable qualifying cycles is greater than seven.</p>
    <p>When, at the step <b>2404</b>, it is determined that the variable qualifying cycles is greater than seven, the is landing qualified? routine <b>2112</b> proceeds to a step <b>2418</b>, wherein the qualification flag is set to false, thereby preventing the identified characteristic of the signals <b>710</b> and <b>712</b> that initially caused the qualification flag to be set to true from being qualified as an actual heel-strike event <b>702</b>.</p>
    <p>When, at the step <b>2404</b>, it is determined that the variable qualifying cycles is not greater than seven, the is landing qualified? routine <b>2112</b> proceeds to a step <b>2406</b>, wherein it is determined whether more than one qualifying cycle has elapsed since the qualification flag was set to true. In other words, the step <b>2406</b> prevents the is landing qualified? routine <b>2112</b> from qualifying a heel-strike event <b>702</b> when a landing criterion is met only during two consecutive iterations of the heel-strike event? routine <b>1408</b>. Rather, the step <b>2406</b> requires the heel-strike event? routine <b>1408</b> to undergo at least one iteration after a first landing criterion is met before a second landing criterion can be used to qualify a heel-strike event <b>702</b>.</p>
    <p>When, at the step <b>2406</b>, it is determined that the variable qualifying cycles is not greater than one, the is landing qualified? routine <b>2112</b> proceeds to the step <b>2102</b> of the heel-strike event? routine <b>1408</b> so that a new sample may be taken.</p>
    <p>When, at the step <b>2406</b>, it is determined that the variable qualifying cycles is two or greater, the is landing qualified? routine <b>2112</b> proceeds to a step <b>2408</b>, wherein the variable sum_of_diff is incremented by the difference between the current sample and the next most recent sample taken at the step <b>2102</b> of the heel-strike event? routine <b>1408</b>.</p>
    <p>After the step <b>2408</b> (discussed above), the is landing qualified? routine <b>2112</b> proceeds to a step <b>2420</b>, wherein it is determined whether the value of the variable sum_of_diff is greater than two times the value of the variable threshold (discussed above).</p>
    <p>When, at the step <b>2420</b>, it is determined that the value of the variable sum_of_diff is not greater than two times the value of the variable threshold, the is landing qualified? routine <b>2112</b> proceeds to the step <b>2102</b> of the heel-strike event? routine <b>1408</b> so that the next sample may be taken.</p>
    <p>When, at the step <b>2420</b>, it is determined that the value of the variable sum_of_diff is greater than two times the value of the variable threshold, the is landing qualified? routine <b>2112</b> proceeds to the steps <b>2114</b>, <b>2116</b>, <b>2118</b>, and <b>2120</b> of the heel-strike event? routine <b>1408</b>, as shown in FIG. <b>21</b>.</p>
    <p>FIG. 25 is a flow diagram showing an example implementation of the check activity? routine <b>1414</b> of the primary routine <b>1400</b> (FIG. <b>14</b>). As shown, the check activity? routine <b>1414</b> begins at a step <b>2502</b>, wherein it is determined whether the activity flag is true.</p>
    <p>When, at the step <b>2502</b>, it is determined that the activity flag is true, the check activity? routine <b>1414</b> terminates.</p>
    <p>When, at the step <b>2502</b>, it is determined that the activity flag is not true, the check activity? routine <b>1414</b> proceeds to a step <b>2504</b>, wherein it is determined whether the activity flag has been false for more than sixty minutes.</p>
    <p>When, at the step <b>2504</b>, it is determined that the activity flag has been false for more than sixty minutes, the routine check activity? routine <b>1414</b> proceeds to a step <b>2510</b>, wherein the shutting down flag is set to false. As described above in connection with the process button routine <b>1504</b> (FIG. <b>16</b>), the placing of the shutting down flag in the false state will cause the foot-mounted device <b>102</b> to be powered down unless the user <b>112</b> pushes. the button <b>204</b> within 30 seconds (see steps <b>1620</b>-<b>24</b>).</p>
    <p>When, at the step <b>2504</b>, it is determined that the activity flag has not been false for more than sixty minutes, the check activity? routine <b>1414</b> proceeds to a step <b>2506</b>, wherein it is determined whether the activity flag has been false for more than five minutes.</p>
    <p>When, at the step <b>2506</b>, it is determined that the activity flag has been false for more than five minutes, the check activity? routine <b>1414</b> proceeds to a step <b>2508</b>, wherein the foot-mounted unit <b>102</b> is placed into a low-power sleep mode for approximately five seconds. Thus, whenever it is determined that the foot-mounted unit <b>102</b> has been inactive for a particular period of time (e.g., five minutes), it may be kept in a low-power mode, waking up only briefly every five seconds or so to determine whether any new activity can be identified.</p>
    <p>After the step <b>2508</b>, the check activity? routine terminates.</p>
    <p>When, at the step <b>2506</b>, it is determined that the activity flag has not been false for more than 5 minutes, the check activity? routine <b>1414</b> terminates.</p>
    <p>FIG. 26 is a flow diagram of an illustrative implementation of the smooth and calculate routine <b>1416</b> of the primary routine <b>1400</b> (FIG. <b>14</b>.). As shown in FIG. 26, the smooth and calculate routine <b>1416</b> begins at a step <b>2602</b>, wherein it is determined whether the activity flag is true.</p>
    <p>When, at the step <b>2602</b>, it is determined that the activity flag is not true, the smooth and calculate routine <b>1416</b> terminates.</p>
    <p>When, at the step <b>2602</b>, it is determined that the activity flag is true, the smooth and calculate routine <b>1416</b> proceeds to a step <b>2604</b>, wherein it is determined whether the step error flag is false.</p>
    <p>When, at the step <b>2604</b>, it is determined that the step error flag is false, the smooth and calculate routine <b>1416</b> terminates.</p>
    <p>When, at the step <b>2604</b>, it is determined that the step error flag is not false, the smooth and calculate routine <b>1416</b> proceeds to a routine <b>2606</b>, wherein, for each footstep, the measured time between consecutive toe-off events <b>704</b> is compared to the measured time between corresponding consecutive heel-strike events <b>702</b>, and correction are (possibly) made based upon these comparisons. An example implementation of the routine <b>2606</b> is described below in connection with FIGS. 27 and 28.</p>
    <p>After the routine <b>2606</b>, the smooth and calculate routine <b>1416</b> proceeds to a routine <b>2608</b>, wherein the values of Tc and Ts measured during the most recent iteration of the primary routine <b>1400</b> (as well as the ratio between these values) are checked to be sure that they fall within acceptable ranges. An example implementation of the routine <b>2608</b> is described below in connection with FIGS. 29 and 30.</p>
    <p>After the routine <b>2608</b>, the smooth and calculate routine <b>1416</b> proceeds to a routine <b>2610</b>, during which an average value of the foot contact times (Tc<sub>AVE</sub>) for the last several footsteps is calculated. In accordance with one embodiment, the number of Tc values used to calculate the value of Tc<sub>AVE </sub>is dependent upon the difference between the most recent Tc value and the last-calculated value of Tc<sub>AVE</sub>. An example implementation of the routine <b>2610</b> is described below in connection with FIG. <b>31</b>.</p>
    <p>After routine <b>2610</b>, the smooth and calculate routine <b>1416</b> proceeds to a step <b>2611</b>, wherein it is determined whether the user <b>112</b> is walking. This determination may, for example, be made solely upon the most recently measured Tc value. According to one embodiment, when the most recent Tc value is greater than 420 milliseconds, it is determined at step <b>2611</b> that the user <b>112</b> is walking. On the other hand, when the most recent Tc value is less than 420 milliseconds, it is determined at the step <b>2611</b> that the user <b>112</b> is running.</p>
    <p>When, at the step <b>2611</b>, it is determined that the user <b>112</b> is walking, the smooth and calculate routine <b>1416</b> proceeds to a step <b>2612</b>, wherein the most recent walking Tc value (Tc<sub>W</sub>) is added to a running total of previously-obtained walking Tc values (Tc<sub>W</sub>), and the current walking Ts value (Ts<sub>W</sub>) is added to a running total of previously-obtained walking Ts values (Ts<sub>W</sub>).</p>
    <p>After the step <b>2612</b>, the smooth and calculate routine <b>1416</b> terminates.</p>
    <p>When, at the step <b>2611</b>, it is determined that the user <b>112</b> is not walking, the smooth and calculate routine <b>1416</b> proceeds to a step <b>2614</b>, wherein the most recent running Tc value (Tc<sub>R</sub>) is added to a running total of previously-obtained running Tc values (Tc<sub>R</sub>), and the most recent running Ts value (Ts<sub>R</sub>) is added to a running total of previously-obtained running Ts values (Ts<sub>R</sub>).</p>
    <p>After the step <b>2614</b>, the smooth and calculate routine <b>1416</b> terminates.</p>
    <p>The running totals Tc<sub>W</sub>, Ts<sub>W</sub>, Tc<sub>R</sub>, and Ts<sub>R </sub>may be stored, for example, in respective 12-bit registers, with each bit representing a particular discrete period of time. In one embodiment of the invention, the current Tc and Ts values are added to the respective registers regardless of whether such addition would cause the registers to drop a most significant bit of the current count (i.e., the registers are permitted to roll over to zero). In such an embodiment, the foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b> may be left to determine when such a roll over has occurred.</p>
    <p>FIG. 27 is a timing diagram illustrating how step time (Ts) measurements between consecutive toe-off events <b>704</b> and corresponding consecutive heel-off events <b>702</b> may be compared to ensure that each measured toe-off event <b>704</b> and each measured heel-off event <b>702</b> was identified accurately. In the example of FIG. 27, toe-off events <b>704</b> are indicated by hatch marks along the line <b>2702</b>, e.g., the hatch mark <b>2702</b> <i>a</i>. Two separate toe-to-toe step times (i.e., Ts(TT)<sub>1 </sub>and Ts(TT)) are labeled between respective pairs of the hatch marks on the line <b>2702</b>. Similarly, heel-strike events <b>702</b> are indicated by hatch marks along the line <b>2704</b>, e.g., the hatch mark <b>2704</b> <i>a</i>. Three separate heel-to-heel step times (i.e., Ts(HH)<sub>2</sub>, Ts(HH)<sub>1</sub>, and Ts(HH)) are labeled between respective pairs of the hatch marks on the line <b>2704</b>.</p>
    <p>FIG. 28 is a flow diagram of an illustrative implementation of the routine <b>2606</b> of the smooth and calculate routine <b>1416</b> (FIG. <b>26</b>). During the routine <b>2606</b>, heel-to-heel and toe-to-toe step times, such as those illustrated in FIG. 27, may be compared to verify the accuracy of the identified occurrences of the heel-strike events <b>702</b> and toe-off events <b>704</b> on which these values are based.</p>
    <p>As shown in FIG. 28, the routine <b>2606</b> beings at a step <b>2802</b>, wherein it is determined whether the heel-to-heel step time Ts(HH)<sub>1 </sub>is greater than the heel-to-heel step time Ts(HH).</p>
    <p>When, at the step <b>2802</b>, it is determined that the heel-to-heel step time Ts(HH)<sub>1 </sub>is greater than the heel-to-heel step time Ts (CH), the routine <b>2606</b> proceeds to a step <b>2804</b>, wherein it is determined whether the heel-to-heel step time Ts(HH) is less than the toe-to-toe step time Ts(TT).</p>
    <p>When, at the step <b>2804</b>, it is determined that the heel-to-heel step time Ts(HH) is not less than the toe-to-toe step time Ts(TT), the routine <b>2606</b> terminates.</p>
    <p>When, at the step <b>2804</b>, it is determined that the heel-to-heel step time Ts(HH) is less than the toe-to-toe step time Ts(TT), the routine <b>2606</b> proceeds to a step <b>2818</b>, wherein the current value of Tc is replaced with the next most recent value of Tc. It should be appreciated that, when the questions asked by the steps <b>2802</b> and <b>2804</b> are both answered in the affirmative, a determination has been made that the heel-strike event <b>702</b> corresponding to the hatch mark <b>2704</b> <i>a </i>in FIG. 27 was identified too late, and that the Tc value obtained with respect to this late landing should be replaced with a previously obtained good Tc value.</p>
    <p>When, at the step <b>2802</b>, it is determined that the heel-to-heel Ts value Ts(HH)<sub>1 </sub>is not greater than the heel-to-heel step value Ts(HH), the routine <b>2606</b> proceeds to a step <b>2806</b>, wherein it is determined whether the heel-to-heel step time Ts(HH)<sub>1 </sub>is less than the heel-to-heel step time Ts(HH).</p>
    <p>When, at the step <b>2806</b>, it is determined that the heel-to-heel step time Ts(HH)<sub>1 </sub>is less than the heel-to-heel step time Ts(HH), the routine <b>2606</b> proceeds to a step <b>2808</b>, wherein it is determined whether the heel-to-heel step time Ts(HH) is greater than the toe-to-toe step time Ts(TT).</p>
    <p>When, at the step <b>2808</b>, it is determined that the heel-to-heel step time Ts(HH) is not greater than the toe-to-toe step time Ts(TT), the routine <b>2606</b> terminates.</p>
    <p>When, at the step <b>2808</b>, it is determined that the heel-to-heel step time Ts(HH) is greater than the toe-to-toe step time Ts(TT), the routine <b>2606</b> proceeds to the step <b>2818</b>, wherein the current value of Tc is replaced with the next most recent value of Tc. It should be appreciated that, when the questions asked by the steps <b>2806</b> and <b>2808</b> are both answered in the affirmative, a determination has been made that the heel-strike event <b>702</b> corresponding to the hatch mark <b>2704</b> <i>a </i>in FIG. 27 was identified too early, and that the Tc value obtained with respect to this early landing should be replaced with a previously obtained good Tc value.</p>
    <p>When, at the step <b>2806</b> (discussed above), it is determined that the heel-to-heel step time Ts(HH)<sub>1 </sub>is not less than the heel-to-heel step time Ts(HH), the routine <b>2606</b> proceeds to a step <b>2810</b>, wherein it is determined whether the toe-to-toe step time Ts(TT)<sub>1 </sub>is greater than the toe-to-toe step time Ts(TT).</p>
    <p>When, at the step <b>2810</b>, it is determined that the toe-to-toe step time Ts(TT)<sub>1 </sub>is greater than the toe-to-toe step time Ts(TT), the routine <b>2606</b> proceeds to a step <b>2812</b>, wherein it is determined whether the toe-to-toe step time Ts(TT) is less than the heel-to-heel step time Ts(HH).</p>
    <p>When, at the step <b>2812</b>, it is determined that the toe-to-toe step time Ts(TT) is not less than the heel-to-heel step time Ts(HH), the routine <b>2606</b> terminates.</p>
    <p>When, at the step <b>2812</b>, it is determined that the toe-to-toe step time Ts(TT) is less than the heel-to-heel step time Ts(HH), the routine <b>2606</b> proceeds to the step <b>2818</b>, wherein the current value of Tc is replaced with the next most recent value of Tc. It should be appreciated that, when the questions asked by the steps <b>2810</b> and <b>2812</b> are both answered in the affirmative, a determination has been made that the toe-off event corresponding to the hatch mark <b>2702</b> <i>a </i>in FIG. 27 was identified too late, and that the Tc value obtained with respect to this late takeoff should be replaced with a previously obtained good Tc value.</p>
    <p>When, at the step <b>2810</b> (discussed above), it is determined that the toe-to-step time Ts(TT)<sub>1 </sub>is not greater than the toe-to-toe step time Ts(TT), the routine <b>2606</b> proceeds to a step <b>2814</b>, wherein it is determined whether the toe-to-toe step time Ts(TT)<sub>1 </sub>is less than the toe-to-toe step time Ts(TT).</p>
    <p>When, at the step <b>2814</b>, it is determined that the toe-to-toe step time Ts(TT)<sub>1 </sub>is less than the toe-to-toe step time Ts(TT), the routine <b>2606</b> proceeds to a step <b>2816</b>, wherein it is determined whether the toe-to-toe step time Ts(TT) is greater than the heel-to-heel step time Ts(HH).</p>
    <p>When, at the step <b>2816</b>, it is determined that the toe-to-toe step time Ts(TT) is not greater than the heel-to-heel step time Ts(HH), the routine <b>2606</b> terminates.</p>
    <p>When, at the step <b>2816</b>, it is determined that the toe-to-toe step time Ts(TT) is greater than the heel-to-heel step time Ts(HH), the routine <b>2606</b> proceeds to the step <b>2818</b>, wherein the current value of Tc is replaced with the next most recent value of Tc. It should be appreciated that, when the questions asked by the steps <b>2814</b> and <b>2816</b> are both answered in the affirmative, a determination has been made that the toe-off event corresponding to the hatch mark <b>2702</b> <i>a </i>in FIG. 27 was identified too early, and that the Tc value obtained with respect to this early takeoff should be replaced with a previously obtained good Tc value.</p>
    <p>When, at the step <b>2814</b> (discussed above), it is determined that the toe-to-toe step time Ts(TT)<sub>1 </sub>is not less than the toe-to-toe step time Ts(TT), the routine <b>2606</b> terminates.</p>
    <p>FIGS. 29A and 29B are graphs representing, respectively, ratios of the values of Tc and Ts measured for multiple individuals throughout a variety of walking and running speeds. Based upon empirical measurements, we have discovered that, when a user is walking, each of the measured ratios of Tc<sub>W </sub>to Ts<sub>W </sub>(e.g., each of the points <b>2902</b>W) tends to fall between a first pair of lines identified by respective equations involving Tc<sub>W </sub>and Ts<sub>W</sub>. Similarly, we have discovered that, when a user is running, each of the measured ratios of Tc<sub>R </sub>to Ts<sub>R </sub>(e.g., each of the points <b>2902</b>R) tends to fall between a second pair of lines identified by respective equations involving Tc<sub>R </sub>and Ts<sub>R</sub>.</p>
    <p>In light of these discoveries, in one embodiment of the invention, for each footstep taken by the user <b>112</b>, the ratio of Tc to Ts is checked to make sure it falls within the bounds identified by these lines. That is, for Tc values in the walking range (e.g., above 420 milliseconds), each measured ratio of Tc<sub>W </sub>to Ts<sub>W </sub>is checked to make sure it falls between the lines <b>2904</b> <i>a </i>and <b>2904</b> <i>b </i>of FIG. <b>29</b>A. Similarly, for Tc values in the walking range (e.g., less than 420 milliseconds), each measured ratio of Tc<sub>R </sub>to Ts<sub>R </sub>is checked to make sure it falls between the lines <b>2906</b> <i>a </i>and <b>2906</b> <i>b </i>of FIG. <b>29</b>B. Each of the Tc and Ts values also may be separately checked to ensure that, by itself, it falls within a reasonable range for such values. As shown, the lines <b>2904</b> <i>a </i>and <b>2904</b> <i>b </i>may be defined by the equations Tc<sub>WAX</sub>=Ts<sub>W</sub>*X<sub>W</sub>+A<sub>W </sub>and Tc<sub>WMIN</sub>=Ts<sub>W</sub>*Y<sub>W</sub>+B<sub>W</sub>, respectively, wherein the values X<sub>W </sub>and Y<sub>W </sub>are slopes of the respective lines, and the values A<sub>W </sub>and B<sub>W </sub>are the respective Y-intercepts thereof. Similarly, as shown, the lines <b>2906</b> <i>a </i>and <b>2906</b> <i>b </i>may be defined by the equations Tc<sub>RMAX</sub>=Ts<sub>R</sub>*X<sub>R</sub>+A<sub>R </sub>and Tc<sub>RMIN</sub>=Ts<sub>R</sub>*Y<sub>R</sub>+B<sub>R</sub>, respectively, wherein the values X<sub>R </sub>and Y<sub>R </sub>are slopes of the respective lines, and the values A<sub>R </sub>and B<sub>R </sub>are the respective Y-intercepts thereof.</p>
    <p>FIG. 30 is a flow diagram illustrating an example implementation of the routine <b>2608</b> of the smooth and calculate routine <b>1416</b> shown in FIG. <b>26</b>. Pursuant to the routine <b>2608</b>, the values of Tc and Ts are checked individually to ensure that each falls within an acceptable range, and each ratio of these two values is checked as well to ensure that it falls within the bounds of the lines discussed above.</p>
    <p>As shown, the routine <b>2608</b> begins at a step <b>3002</b>, wherein it is determined whether the measured Tc value is less than 420 milliseconds.</p>
    <p>When, at the step <b>3002</b>, the measured Tc value is determined to be less than 420 milliseconds, it is determined that the user <b>112</b> is running, and the routine <b>2608</b> proceeds to a step. <b>3004</b>, wherein it is determined whether the measured Tc value is greater than 120 milliseconds.</p>
    <p>When, at the step <b>3004</b>, it is determined that the Tc value is not greater than 120 milliseconds, it is determined that the Tc value is outside of the acceptable range for Tc values for running, and the routine <b>2608</b> proceeds to a step <b>3020</b>, wherein the measured Tc value is replaced with the next most recent Tc value, and the routine <b>2608</b> then terminates.</p>
    <p>When, at the step <b>3004</b>, it is determined that the measured Tc value is greater than 120 milliseconds, the routine <b>2608</b> proceeds to a step <b>3006</b>, wherein it is determined whether the measured Ts value is between 400 and 910 milliseconds (i.e., an acceptable range of Ts values for running).</p>
    <p>When, at the step <b>3006</b>, it is determined that the measured Ts value is not between 400 and 910 milliseconds, it is determined that the Ts value is outside of the acceptable range for Ts values for running, and the routine <b>2608</b> proceeds to the step <b>3020</b>, wherein the measured Tc value is replaced with the next most recent Tc value, and the routine <b>2608</b> then terminates.</p>
    <p>When, at the step <b>3006</b>, it is determined that the measured Ts value is between 400 and 910 milliseconds, the routine <b>2608</b> proceeds to steps <b>3008</b> and <b>3010</b>, wherein it is determined whether the ratio of the measured Tc and Ts values falls between running lines <b>2906</b> <i>a </i>and <b>2906</b> <i>b </i>of FIG. <b>29</b>.</p>
    <p>When, at the steps <b>3008</b> and <b>3010</b>, it is determined that the ratio of the measured Tc and Ts values falls above the line <b>2906</b> <i>a </i>(step <b>3008</b>) or below the line <b>2906</b> <i>b </i>(step <b>2910</b>), the routine <b>2608</b> proceeds to the step <b>3020</b>, wherein the measured Tc value is replaced with the next most recent Tc value, and the routine <b>2608</b> then terminates.</p>
    <p>When, at the steps <b>3008</b> and <b>3010</b>, it is determined that the ratio of the measured Tc and Ts values falls both below the line <b>2906</b> <i>a </i>(step <b>3008</b>) and above the line <b>2906</b> <i>b </i>(step <b>2910</b>), the routine <b>2608</b> terminates.</p>
    <p>When, at the step <b>3002</b> (described above), it is determined that the measured Tc value is not less than 420 milliseconds, it is determined that the user <b>112</b> is walking, and the routine <b>2608</b> proceeds to a step <b>3012</b>, wherein it is determined whether the measured Tc value is less than 900 milliseconds.</p>
    <p>When, at the step <b>3012</b>, it is determined that the measured Tc value is not greater than 900 milliseconds, it is determined that the Tc value is outside of the acceptable range for Tc values for walking, and the routine <b>2608</b> proceeds to the step <b>3020</b>, wherein the measured Tc value is replaced with the next most recent Tc value, and the routine <b>2608</b> then terminates.</p>
    <p>When, at the step <b>3012</b>, the measured Tc value is determined to be less than 900 milliseconds, the routine <b>2608</b> proceeds to a step <b>3014</b>, wherein it is determined whether the measured Ts value is between 700 and 1360 milliseconds (i.e., an acceptable range of Ts values for walking).</p>
    <p>When, at the step <b>3014</b>, it is determined that the measured Ts value is not between 700 and 1360 milliseconds, the routine <b>2608</b> proceeds to the step <b>3020</b>, wherein the measured Tc value is replaced with the next most recent Tc value, and the routine <b>2608</b> then terminates.</p>
    <p>When, at the step <b>3014</b>, it is determined that the measured Ts value is between 700 and 1360 milliseconds, the routine <b>2608</b> proceeds to steps <b>3016</b> and <b>3618</b>, wherein it is determined whether the ratio of the measured values of Tc and Ts falls between the lines <b>2906</b> <i>a </i>and <b>2906</b> <i>b </i>of FIG. <b>29</b>.</p>
    <p>When, at the steps <b>3016</b> and <b>3018</b>, it is determined that the ratio of the measured values of Tc and Ts falls above the line <b>2906</b> <i>a </i>(step <b>3016</b>) or falls below the line <b>2906</b> <i>b </i>(step <b>3018</b>), the routine <b>2608</b> proceeds to the step <b>3020</b>, wherein the measured Tc value is replaced with the next most recent Tc value, and the routine <b>2608</b> then terminates.</p>
    <p>When, at the steps <b>3016</b> and <b>3018</b>, it is determined that the ratio of the measured values of Tc and Ts falls both below the line <b>2906</b> <i>a </i>(step <b>3016</b>) and above the line <b>2906</b> <i>b </i>(step <b>3018</b>), the routine <b>2608</b> terminates.</p>
    <p>FIG. 31 is a flow diagram showing an illustrative implementation of the routine <b>2610</b> of the smooth and calculate routine <b>1416</b> shown in FIG. <b>26</b>. As shown, the routine <b>2610</b> begins at steps <b>3102</b> and <b>3104</b>, wherein it is determined whether the current Tc value and the next most recent Tc value are each more than eight seconds greater than the currently-stored value of Tc<sub>ave </sub>(i.e., the average value of Tc over the last several steps).</p>
    <p>When, at the steps <b>3102</b> and <b>3104</b>, it is determined that the current Tc value and the next most recent Tc value are each more than eight seconds greater than the currently-stored value of Tc<sub>ave</sub>, the routine <b>2610</b> proceeds to a step <b>3110</b>, wherein the two most recent Tc values obtained (including the current Tc value) are averaged to obtain a new value of Tc<sub>ave</sub>, and the routine <b>2610</b> then terminates.</p>
    <p>When, at the steps <b>3102</b> and <b>3104</b>, it is determined that either the current Tc value or the next most recent Tc value is not more than eight milliseconds greater than the currently-stored value of Tc<sub>ave</sub>, the routine <b>2610</b> proceeds to steps <b>3106</b> and <b>3108</b>, wherein it is determined whether the current Tc value and the next most recent Tc value are each more than eight milliseconds less than the currently-stored value of Tc<sub>ave</sub>.</p>
    <p>When, at the steps <b>3106</b> and <b>3108</b>, it is determined that both the current Tc value and the next most recent value are each more than eight milliseconds less than the currently-stored value of Tc<sub>ave</sub>, the routine <b>2610</b> proceeds to the step <b>3110</b>, wherein the two most recent Tc values are averaged to obtain a new value of Tc<sub>ave</sub>, and the routine <b>2610</b> then terminates.</p>
    <p>Therefore, the steps <b>3102</b>-<b>3108</b> ensure that, if at least two Tc values suddenly deviate from a current value of Tc<sub>ave </sub>by more than eight milliseconds, the value of Tc<sub>ave </sub>will be updated using only the two most recent values of Tc. This technique ensures that the value of Tc<sub>ave </sub>responds quickly to a new pace of the user <b>112</b> so that the user can receive instant feedback regarding the same.</p>
    <p>When, at the steps <b>3106</b> and <b>3108</b>, it is determined that either the current Tc value or the next most recent Tc value is not more than eight milliseconds less than the currently-stored value of Tc<sub>ave</sub>, the routine <b>2610</b> proceeds to steps <b>3112</b> and <b>3114</b>, wherein it is determined whether the current Tc value and the next most recent Tc value are each more than four milliseconds greater than the currently-stored value of Tc<sub>ave</sub>.</p>
    <p>When, at the steps <b>3112</b> and <b>2114</b>, it is determined that the current Tc value and the next most recent Tc value are each more than four milliseconds greater than the currently-stored value of Tc<sub>ave</sub>, the routine <b>2610</b> proceeds to a step <b>3120</b>, wherein up to four of the most recent Tc values are averaged to obtain a new value of Tc<sub>ave</sub>, and the routine <b>2610</b> then terminates.</p>
    <p>When, at the steps <b>3112</b> and <b>3114</b>, either the current Tc value or the next most recent Tc value is determined to not be more than four milliseconds greater than the currently-stored value of Tc<sub>ave</sub>, the routine <b>2610</b> proceeds to steps <b>3116</b> and <b>3118</b>, wherein it is determined whether the current Tc value and the next most recent Tc value are each more than four milliseconds less than the currently-stored value of Tc<sub>ave</sub>.</p>
    <p>When, at the steps <b>3116</b> and <b>3118</b>, is determined that the current Tc value and the next most recent Tc value are each more than four milliseconds less than the currently-stored value of Tc<sub>ave</sub>, the routine <b>2610</b> proceeds to the step <b>3120</b>, wherein up to the four most recent Tc values are averaged to obtain a new value of Tc<sub>ave</sub>, and the routine <b>2610</b> then terminates.</p>
    <p>When, at the steps <b>3116</b> and <b>3118</b>, it is determined that either the current Tc value or the next most recent Tc value is not more than four milliseconds less than the currently-stored value of Tc<sub>ave</sub>, the routine <b>2610</b> proceeds to a step <b>3122</b>, wherein up to nine of the most recent Tc values are averaged to obtain a new value of Tc<sub>ave</sub>, and the routine <b>2610</b> then terminates.</p>
    <p>Based upon the above, it should be appreciated that the routine <b>2610</b> ensures that the value Tc<sub>ave </sub>will be updated at a rate commensurate with the rate at which the Tc values being measured are changing. In this manner, when the value Tc<sub>ave </sub>is used to calculate the instantaneous pace of a user in locomotion on foot, the pace displayed to the user <b>112</b> may respond quickly to sudden changes in the user's pace, but may also be smoothed over several footsteps when the user's pace is relatively steady.</p>
    <p>FIGS. 32A-H each shows the front face <b>308</b> of the wrist-mounted unit <b>104</b>. In each of FIGS. 32A-H, the display <b>412</b> of the wrist-mounted unit <b>104</b> has simultaneously displayed thereon a respective combination of parameters. Any or all of these combinations of parameters may be made available to the user <b>112</b>, and the user <b>112</b> may select (e.g., by pushing one or more of the buttons <b>306</b> <i>a-e</i>) which combination is displayed at a given time. In one illustrative embodiment of the invention, the user may use the computer <b>428</b> (e.g., using software running on the computer <b>428</b> and/or the network server <b>442</b>) to select the combination of parameters to be displayed on the display <b>412</b>, and information relating to the user's selection may then be selectively or automatically transmitted to the wrist and/or foot mounted units, e.g., via an RF communication channel. It should be appreciated that any other parameters or information relating to the operation of the wrist-mounted unit <b>104</b> and/or the foot-mounted unit <b>102</b> (some of which are described herein) may also be generated by the user via the computer <b>428</b> and transmitted to the appropriate unit(s) in this manner.</p>
    <p>In one illustrative embodiment of the invention, the display <b>412</b> has simultaneously displayed thereon at least one determined performance parameter of the user (e.g., pace) and at least one determined variable physiological parameter of the user (e.g., heart rate), each of which may be determined, for example, using the techniques and devices described elsewhere herein. As used herein, variable physiological parameter refers to any physiological condition of a user's body that may experience a measurable change when the user is exercising, and is intended to encompass parameters such as heart rate, respiration rate, body temperature, lactate level, etc. The term variable physiological parameter is not intended to encompass static physiological parameters such as weight, height, etc. As used herein, performance parameter refers to any measurable amount, level, type or degree of physical activity engaged in by the user, and is intended to encompass parameters such as foot contact time, foot loft time, step time, instantaneous speed, average speed, instantaneous pace, average pace, energy expenditure rate, total energy expenditure, distance traveled, etc.</p>
    <p>In the first example (FIG. <b>32</b>A), the display <b>412</b> of the wrist-mounted unit <b>104</b> has displayed thereon: (a) the instantaneous pace of the user, (b) the average pace of the user during a particular outing, (c) the distance traveled by the user during the outing, and (d) a chronograph indicating the time that has elapsed during the outing. The advantages of simultaneously displaying these particular parameters are numerous, especially for a runner engaged in a competition, e.g., a marathon, a 10K, or the like. For example, during a race, the user <b>112</b> may increase or decrease his or her current pace based upon the displayed value of the user's average pace thus far during the race. In this manner, the user <b>112</b> may ensure that the overall average pace for the completed race is close to a predetermined target value.</p>
    <p>In lieu of a numeric display, this same advantage may be achieved, for example, using two so-called pace fans akin to the hands on a wristwatch. For example, one fan (e.g., a watch hand) may maintain an angular orientation indicative of the user's current pace, and the other fan may maintain an angular orientation indicative of the user's average pace. As yet another alternative, side-by-side graduated bar graphs may be displayed to the user, with the height of each bar graph corresponding to a respective one of the user's current pace and the user's average pace. The benefits of displaying the chronograph value and the distance traveled by the user, both separately and in combination with the other units in the example of FIG. 32A, are apparent and therefore will not be discussed further.</p>
    <p>In the next example (FIG. <b>32</b>B), the display <b>412</b> of the wrist-mounted unit <b>104</b> has displayed thereon: (a) the total calories expended during an outing, (b) the distance traveled by the user during the outing, (c) the current heart rate of the user (or average heart rate of the user during the outing), and (d) a chronograph indicating the total time that has elapsed during the outing.</p>
    <p>In the example of FIG. 32C, only the time and date are displayed. The user may, for example, selectively choose this display combination when the user is engage in non-athletic activities, and simply wants a typical wrist-watch display.</p>
    <p>In the next example (FIG. <b>32</b>D), the display <b>412</b> of the wrist-mounted unit <b>104</b> has displayed thereon: (a) a chronograph indicating the total time that has elapsed during the outing, (b) the distance traveled by the user during the outing, (c) the instantaneous pace of the user, (d) the average pace of the user during the outing, (e) the current heart rate of the user (or the average heart rate of the user during the outing), (f) the total calories expended by the user during the outing, (g) the instantaneous speed of the user, and (h) the average speed of the user during the outing.</p>
    <p>In the example of FIG. 32E, the display <b>412</b> has displayed thereon an indication that a calibration procedure has been selected. Also displayed is an indication as to whether a walk calibration or a run calibration has been selected. In this mode, the user may start and stop a calibration procedure (e.g., by depressing one or more of the buttons <b>306</b> <i>a-e</i>) during which the calibration constants discussed above may be determined.</p>
    <p>In the example of FIG. 32F, the display <b>412</b> of the wrist-mounted unit <b>104</b> has displayed thereon: (a) the instantaneous speed of the user, (b) the calories expended by the user during the outing, (c) a chronograph indicating the total time that has elapsed during the outing, and (d) the distance traveled by the user during the outing.</p>
    <p>In the example of FIG. 32G, the display <b>412</b> of the wrist-mounted unit <b>104</b> has displayed thereon: (a) the instantaneous pace of the user, (b) the distance traveled by the user during the outing, (c) the average pace of the user during the outing, and (d) the current heart rate of the user.</p>
    <p>Finally, in the example of FIG. 32H, the display <b>412</b> of the wrist-mounted unit <b>104</b> has displayed thereon: (a) the instantaneous speed of the user, (b) the distance traveled by the user during the outing, (c) the average speed of the user during the outing, and (d) the current heart rate of the user.</p>
    <p>With regard to the displayable values discussed above in connection with FIGS. 32A-H, it should be appreciated that any of the values that are described as being monitored and displayed during a particular outing may additionally or alternatively be monitored and displayed during multiple outings. That is, the value displayed may alternatively be the cumulative total or overall average value for each of the several outings. For example, the distance displayed may represent the distance traveled by the user <b>112</b> during all runs engaged in by the user <b>112</b> during a week, a month, a year, etc., or the average pace displayed may represent the average pace of the user <b>112</b> during all runs engaged in by the user <b>112</b> during a week, a month, a year, etc.</p>
    <p>In addition, it should be appreciated that any or all of the parameters described as being displayable may additionally or alternatively be displayed on a display on the foot-mounted unit <b>102</b>, or on a display disposed remote from the user <b>112</b>, e.g., the computer <b>428</b> or another display (not shown) held by a track coach or the like. Other examples of parameters that may be displayed on the wrist-mounted unit <b>104</b> and/or the foot-mounted unit <b>102</b>, either together with or separately from the examples shown in FIGS. 32A-H, include cadence (stride rate), stride length, and acceleration. Illustrative techniques for determining and displaying each of these parameters are discussed elsewhere herein.</p>
    <p>In one illustrative embodiment of the invention, the ARC processor <b>410</b> in the wrist-mounted unit <b>104</b> is configured (e.g., by instructions stored in the memory <b>404</b>) to calculate time splits automatically on a per-unit-distance basis (e.g., per mile or kilometer). For example, the ARC processor <b>410</b> may calculate a time split for each of the twenty six miles of a marathon. Such splits may be displayed to the user <b>112</b> during the event and/or may be stored in memory for later retrieval and analysis and/or display. Because information regarding total distance traveled and a chronograph are both maintained in the wrist-mounted unit <b>104</b>, such splits may readily be calculated by automatically recording the time of the chronograph each time a split distance is reached. Of course, splits may alternatively be determined using the foot-mounted unit <b>102</b>, or another device in the system that receives the necessary information. When the foot-mounted unit <b>102</b> is used to calculate splits, the foot-mounted unit <b>102</b> can display the split information itself and/or it can transmit the information to the wrist-mounted unit <b>104</b> for display.</p>
    <p>In one illustrative embodiment, in addition to being given information regarding the last, split completed, the user can also be provided with feedback regarding progress on the split currently being measured. For example, the user may be provided with an indication regarding the user's average pace since the last split, or the projected time for the current split based upon the user's average pace since the last split.</p>
    <p>In one embodiment of the invention, one or more of the devices in the system (i.e., the foot-mounted unit <b>102</b>, the wrist-mounted unit <b>104</b>, the computer <b>428</b>, and/or the network server <b>442</b>) may be used to determine whether the speed, pace and/or heart rate of the user <b>112</b> are within particular zones. As used herein, the term zone refers to a range of values bounded by at least one threshold. Therefore, unless otherwise specified, zone may refer to any one of: (1) all values greater than a certain value, (2) all values less than a certain value, and (3) all values falling between two different values. If it is determined that one or more of the monitored parameters falls outside the particular zone therefor, an output may be generated by the processor performing the monitoring. This output may, for example, cause information representing the same to be stored in memory to later provide feedback to the user <b>112</b>, or it may cause an output that is perceptible to the user to be generated so that the user is provided with immediate feedback. When employed, any of a number of outputs perceptible to the user <b>112</b> may be used, and the invention is not limited to any particular type of perceptible output. Examples of suitable output devices include: audio indicators such as buzzers, chimes, or voice synthesizers; visual indicators such as those capable of displaying numbers, text, symbols, and/or lights; and physical indicators such as vibrators.</p>
    <p>When immediate feedback is provided to the user <b>112</b>, the user may, in response to such feedback, adjust his or her workout, if necessary, to bring the monitored parameter(s) back into the particular zone(s). The user <b>112</b> may, for example, preset the zone(s) prior to beginning a workout, and/or may adjust the zones (or even disable the zone monitoring function entirely, or perhaps only the feedback functionality thereof) during the workout if he or she desires a more or less intense workout. In one illustrative embodiment, the user <b>112</b> may program a particular zone-specific workout, during which zones are adjusted automatically during the workout in response to time and/or distance measurements. For example, the user may program a workout during which a first zone (e.g., a warm up zone) is set during a first time period or distance interval, a second zone (e.g., a workout zone) is set during a second time period or distance interval, and a third zone (e.g., a cool down zone) is set during a third time period or distance interval. In another example, the user may set zones on a per-mile or per-minute basis so as to perform interval training. The number of possibilities of zone adjustments in response to distance and/or time goals being met is virtually without limit, and the user may preset his or her workout to his or her particular tastes or needs. It should be appreciated that, when both heart rate and speed or pace are monitored simultaneously, negative feedback (i.e., an indication that workout intensity should be increased) may be provided only in response to one or more combinations of the monitored parameters falling outside of the preset zones. For example, during a particular time period or distance interval, negative feedback may be provided to the user only when both heart rate or speed/pace fall outside the preset zones therefor.</p>
    <p>In one illustrative embodiment, the wrist-mounted unit <b>104</b> and/or the foot-mounted unit <b>102</b> can be programmed so as to provide the user with feedback in response to one or more particular distances being traveled or in response to one or more time periods elapsing during a workout. Such time periods and/or distances may, for example, be preprogrammed or selected by the user. For example, a perceptible indication may be provided to the user <b>112</b> each time the user <b>112</b> has traveled a mile or each time the user <b>112</b> has been running or walking for an additional ten minutes. This sort of feedback can enables the user to monitor the progress of his or her workout, and to be reminded as to the progress in achieving a certain goal, e.g., to run ten miles or to walk for one hour. Alternatively. the user may program the wrist-mounted unit <b>104</b> and/or the foot-mounted unit <b>102</b> such that feedback is provided when each of several different time and/or distance intervals are completed. For example, during a workout, the user may be provided with a first perceptible indication after a warm up distance has been completed or after a warm up time period has elapsed, may be provided with a second perceptible indication after a workout distance has been completed or after a workout time period has elapsed, and may be provided with a third perceptible indication after a cool-down distance has been completed or after a cool-down time period has elapsed. A perceptible indication may also be provided to the user instructing the user to rest (i.e., slow down considerably or stop exercising completely) during one or more particular time intervals or following one or more particular distance intervals.</p>
    <p>In one illustrative embodiment, the user may program the wrist-mounted unit <b>104</b> and/or the foot-mounted unit <b>102</b> with a predetermined distance to be achieved during an outing, as well as an indication as to how the user desires to receive feedback during the race. For example, the user may enter a certain goal distance (e.g., five miles), and request to be given feedback each time a certain fraction (e.g., one-fourth) of the goal distance has been completed. If the fraction is chosen to be one-half, the user may complete an out and back walk, or run (i.e., an outing during which the user travels back and forth along the same path) of a certain distance, and may be given a perceptible indication as to exactly when to turn around and go in the opposite direction.</p>
    <p>In one embodiment, the user may program the foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b> with information regarding a distance to be traveled during an outing, and one or both of (1) a goal time in which the user wishes to complete the distance, and (2) a goal average speed or pace the user wishes to achieve during the outing. Based upon this information, as well as a measured distance traveled during the outing, the user can be provided with real-time feedback regarding future performance during the outing that is required for the user to achieve the input goal(s), e.g., the average speed or pace required during the remainder of the race in order to achieve the input goal(s). In addition, based upon an input goal distance, the measured elapsed time during all outing, the measured distance traveled thus far during the outing, and the measured current pace of the user, the user also can be provided with feedback regarding a projected time in which the user will complete the goal distance if the user maintains his or her current pace. Many other forms of feedback using one or more other combinations of such input and measured parameters also are possible in connection with different embodiments of the invention, and the invention is not limited to any particular form of feedback.</p>
    <p>As discussed above in connection with FIG. 8, in one embodiment of the invention, the foot-mounted unit <b>102</b> and/or the wrist-mounted unit can readily determine whether the user <b>112</b> is walking or running during each footstep taken by the user. Therefore, in such an embodiment, the user may program the foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b> such that the user is instructed to walk or run during certain distance and/or time intervals. When so programmed, the device may provide a perceptible indication to the user that the user should be running or walking, if the user is walking when he or she should be running, or vice versa. Any variety and/or number of interval lengths during which the user should walk and run during an outing may be programmed. In one embodiment, the respective total amounts of time that the user walks and runs during an outing is displayed to the user and/or stored in memory for later use. Such feedback to the user may help the user optimize a workout, for example, if the user wishes to walk and run equal distances during an outing. Ratios of walk time to run time and/or walk distance to run distance, or other ratios of such values, may also be calculated and displayed to the user and/or stored in memory for later use.</p>
    <p>As discussed above, one way the user can program workouts or input parameters such as those discussed above is to use software executing on the computer <b>428</b> and/or the network server <b>442</b> to preset the parameters for his or her workout, and then cause the programmed information to be transmitted to the wrist-mounted unit <b>104</b> and/or the foot-mounted unit <b>102</b>.</p>
    <p>In embodiments of the invention wherein both the heart rate (HR) and foot contact times of a user are measured, a pair of so-called fitness indexes (one for walking and one for running) may be calculated by a processor receiving this information. The fitness indexes (FI) for a particular user may, for example, be calculated according to the following equations: <maths> <math> <mtable> <mtr> <mtd> <mrow> <mrow> <msub> <mi>FI</mi> <mi>W</mi> </msub> <mo>=</mo> <mrow> <mi>HR</mi> <mo>*</mo> <msub> <mi>Tc</mi> <mi>W</mi> </msub> </mrow> </mrow> <mo></mo> <mstyle> <mtext> </mtext> </mstyle> <mo></mo> <mrow> <msub> <mi>FI</mi> <mi>R</mi> </msub> <mo>=</mo> <mrow> <mi>HR</mi> <mo>*</mo> <msub> <mi>Tc</mi> <mi>R</mi> </msub> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mo>(</mo> <mn>27</mn> <mo>)</mo> </mrow> </mtd> </mtr> </mtable> </math> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00007.png"> <img id="EMI-M00007" file="US06611789-20030826-M00007.TIF" img-content="math" img-format="tif" alt="Figure US06611789-20030826-M00007" src="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00007.png" class="patent-full-image"> </a> </div> <attachments> <attachment idref="MATHEMATICA-00007" attachment-type="nb" file="US06611789-20030826-M00007.NB"> </attachment> </attachments> </maths> </p>
    <p>Significantly, we have discovered that the values of a user's walking fitness index (FI<sub>W</sub>) and running fitness index (FI<sub>R</sub>) are substantially unaffected by changes in the user's speed when the user is walking and running, respectively. That is, as a user's speed increases, the amount that the user's heart rate (HR) increases tends to offset the amount that the value of Tc decreases, so that the product of the two variables remains substantially constant. Similarly, as a user's speed decreases, the amount that the user's heart rate decreases tends to offset the amount that the value of Tc increases.</p>
    <p>In one embodiment of the invention, an average fitness index (FI<sub>AVE</sub>) for a user <b>112</b> is calculated each time the user walks or runs for a particular period of time, and the value of this average fitness index (FI<sub>AVE</sub>) may be used as an indicator of the user's physical fitness level. A user's average fitness index (FI<sub>AVE</sub>) for a particular outing may be calculated, for example, by multiplying each foot contact time (Tc) value obtained during the outing by the user's heart rate (HR) at the time that the foot contact time (Tc) value is measured, and maintaining a running sum of all such products of Tc and HR. The running sum then may be divided by the total number of foot contact time (Tc) values obtained during the outing to yield the average fitness index value.</p>
    <p>The calculated average fitness index value (FI<sub>AVE</sub>) may, for example, be calculated and/or displayed on the wrist-mounted unit <b>104</b>, the foot-mounted unit <b>102</b>, and/or another device such as a personal computer linked to the foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b> via a wireless communication link. The fitness index value may be displayed simultaneously with any of the other displayable information discussed above in connection with FIGS. 32A-H, or may be displayed separately therefrom.</p>
    <p>Given the relationships between foot contact time (Tc) and other performance parameters (e.g., pace, speed, energy expenditure, etc.) that are either described herein or are known in the art, we have recognized that other equations including both heart rate and one or more of such other performance parameters as variables therein would, when the variables are properly combined, likewise yield a constant value. Therefore, such other performance parameters may be used in lieu of or in addition to measured foot contact times in an equation used to calculate a fitness index (FI) value. For example, a fitness index (FI) value may be obtained using an equation having both: (1) heart rate (HR), and (2) any one of Speed, Pace, and energy expenditure as variables therein. In this regard, it should be appreciated that, to the extent that other techniques may be used to obtain such other performance parameters (i.e., techniques other than measuring foot contact times and calculating the performance parameters based thereon), such other techniques may be used to obtain values of one or more of these performance parameters, and a fitness index may be calculated based thereupon. Therefore, in some embodiments, a fitness index value may be obtained without requiring the measurement of foot contact times. In the illustrative embodiment described herein, the measurement of foot contact times and/or other performance parameters, and the calculation of a fitness index based thereupon, are performed by one or more devices that are ambulatory (i.e., may be supported by the user while the user is in locomotion on foot).</p>
    <p>Significantly, once a fitness index value is determined for a particular user, the user's heart rate can be estimated based solely upon one or more measured foot contact times of the user, or based upon one of the other measured performance parameters discussed above. This may be accomplished, for example, by rewriting the equations (27) as follows: <maths> <math> <mtable> <mtr> <mtd> <mrow> <mrow> <mi>HR</mi> <mo>=</mo> <mrow> <msub> <mi>FI</mi> <mi>W</mi> </msub> <mo>/</mo> <msub> <mi>Tc</mi> <mi>W</mi> </msub> </mrow> </mrow> <mo></mo> <mstyle> <mtext> </mtext> </mstyle> <mo></mo> <mrow> <mi>HR</mi> <mo>=</mo> <mrow> <msub> <mi>FI</mi> <mi>R</mi> </msub> <mo>/</mo> <msub> <mi>Tc</mi> <mi>R</mi> </msub> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mo>(</mo> <mn>28</mn> <mo>)</mo> </mrow> </mtd> </mtr> </mtable> </math> <div class="patent-image small-patent-image"> <a href="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00008.png"> <img id="EMI-M00008" file="US06611789-20030826-M00008.TIF" img-content="math" img-format="tif" alt="Figure US06611789-20030826-M00008" src="//patentimages.storage.googleapis.com/US6611789B1/US06611789-20030826-M00008.png" class="patent-full-image"> </a> </div> <attachments> <attachment idref="MATHEMATICA-00008" attachment-type="nb" file="US06611789-20030826-M00008.NB"> </attachment> </attachments> </maths> </p>
    <p>Using the equations (28), the user's instantaneous heart rate HR can be estimated by: (1) measuring a foot contact time during a footstep taken by the user, (2) determining whether the user was walking or running when the foot contact time was measured, and (3) including the measured foot contact time in an appropriate one of the equations (28)(depending on whether the user was walking or running) along with the previously-determined average fitness index value (FI<sub>AVE</sub>). Therefore, in one embodiment of the invention, an ambulatory device or system (i.e., a device or group of devices that may be carried by the user while the user is in locomotion on foot) may be used to measure the heart rate of a user based upon the measurement of a parameter other than the user's pulse. While, in the illustrative embodiment described herein, this measured parameter is the foot contact time (Tc) of the user, it should be appreciated that other performance parameters may alternatively be measured and used to estimate a user's heart rate (HR) in a similar fashion. For example, measured values of a user's Pace, Speed, or energy expenditure may be used to estimate the user's heart rate (HR) based upon a known relationship between such a measured value and heart rate for the user.</p>
    <p>We have recognized that, when a user first begins walking or running, the FI values tend to be less consistent than after the user has warmed up. Therefore, it may be desirable to wait for a period of time after a user begins walking or running to begin measuring fitness index (FI) values. Any of a number of alternative techniques can be used to implement this waiting function, and the invention is not limited to any particular technique for accomplishing the same. In one illustrative embodiment, for example, after a user begins walking or running, the percentage differences between consecutive FI values is determined, and FI values are accumulated for the purpose of calculating an average fitness index (FI) only after the percentage difference between consecutive FI values is less than a predetermined threshold. Alternatively, the device performing the calculations may simply wait a predetermined period of time or wait until the user has traveled a predetermined distance before it begins accumulating good FI values.</p>
    <p>After a user's fitness index has leveled out during an exercise session (e.g., after the user has warmed up), the fitness index may be monitored for abnormal deviations from its expected value. Such deviations may, for example, be indicative of conditions such as dehydration, fatigue, stress, etc. In one embodiment, a user's fitness index is continuously monitored and, if it deviates from its expected value by more than a particular percentage, an indication is provided to the user that something may be wrong. As discussed above, such an indication may be provided in any of a number of ways (e.g., text, sound such as beeps or buzzers, lights, etc.), and the invention is not limited to any particular type of indication.</p>
    <p>Based upon the average fitness index (FI<sub>AVE</sub>) measured during each outing by a user <b>112</b>, improvements in the user's fitness level will be marked by decreases in the value of FI<sub>AVE</sub>, and decreases in the user's fitness level will be marked by increases in the value of FI<sub>AVE</sub>. The user <b>112</b> may also compare his or her fitness index to the fitness indexes of other people, and thereby compare his or her level of fitness to that of those people. For convenience, the value of FI or FI<sub>AVE </sub>may be scaled by a constant value so as to yield a value that is within a common range (e.g., between 1 and 100).</p>
    <p>While a user's fitness index (FI) is substantially constant when the user is walking or running on a flat surface, we have recognized that the calculated values of FI tend to increase slightly as the grade on which the user is walking or running increases, and tend to decrease slightly as the grade on which the user is walking or running decreases. In light of this, the calculated value of a user's fitness index for a given measured foot contact time (Tc) value, may be used to ascertain whether the user is walking or running on a grade at the time the foot contact time (Tc) is measured. As used herein, grade refers to the slope of a surface with respect to a level plane at the point the grade is measured. Most commonly, grade is measured in terms of the vertical rise in the surface divided by the horizontal run of the surface along a particular distance, and its value is typically expressed as a percentage. It should be appreciated, however, that the invention is not limited in this respect, and that grade may be measured in any of a number of alternative ways.</p>
    <p>Empirical measurements have shown that a user's fitness index (FI) increases and decreases approximately linearly with corresponding increases and decreases in the value of the grade of the surface on which the user is walking or running. Therefore, once the linear relationships between FI and the current walking or running grade are known for a given user, an approximation of the actual value of the grade on which the user <b>112</b> is walking or running may be made by analyzing changes in the value of FI with respect to the value of FI when the user walks or runs on a flat (i.e., 0%) grade. Alternatively, a higher-order polynomial may be generated to more accurately reflect the actual relationship between FI and the current walking or running grade.</p>
    <p>This information regarding the grade of the surface on which the user <b>112</b> is walking or running may be used, for example, to correct calculated values of Pace, Speed, distance traveled, and/or expended energy to account for the changes in surface grade. This value correction may be based upon a simple determination that a non-zero grade condition exists (e.g., determining that the user is on one of three surfaces: negative grade, level surface, or positive grade), or may be based upon a determination of the actual value of the grade (e.g., a percent grade). In addition, information regarding changes in surface grade can be exploited to identify changes in the altitude of the user <b>112</b> while the user is walking or running. Information regarding altitude changes may be stored in memory, along with corresponding distance measurements, and may be used for a number of purposes. For example, in one embodiment of the invention, such information may be transferred (e.g., via a wireless communication link) to the computer <b>428</b>, where it may be displayed to the user in graph form. For example, a graph may be displayed that shows, for a particular outing, changes in altitude over the distance of the outing. In one embodiment, a second graph may be superimposed over the altitude/distance graph showing, for example, changes in pace over the distance of the outing. The computer <b>428</b> and/or the server <b>442</b> may analyze the received data to evaluate, for example, the degree by which a user's pace or speed changes in response to changing grades or altitudes. This information may therefore be used to provide feedback to the user regarding the effectiveness or effort level exerted during a given workout.</p>
    <p>It should be appreciated that any of a number of other measurable variable physiological parameters (i.e., physiological parameters such as respiration rate, blood pressure, body temperature, lactate level, etc.) may alternatively or additionally be determined and combined with a measured foot contact time or other performance parameter (e.g., speed, pace, energy expenditure, etc.) to yield a calculated parameter reflecting useful information. We have recognized that at least some of such variable physiological parameters, e.g., respiration rate, are related to heart rate. Therefore, when a variable physiological parameter such as respiration rate (which is related to heart rate) is combined with a measured foot contact time or other performance parameter (e.g., pace, energy expenditure or the like), a fitness index value may be yielded in a manner similar to that in which a fitness index value is yielded when heart rate and foot contact time or another performance parameter are combined as discussed above. When applicable, the fitness index so calculated may be used in any of the ways or for any of the purposes that the fitness index described above is used. It should be appreciated, of course, that the invention is not limited to the combinations of performance parameters and variable physiological parameters that yield substantially constant values, as useful information may also be derived from combinations of performance parameters and variable physiological parameters having values that change in response to increases in the user's speed, etc. For example, a such a calculated parameter may be used as an indicator of the user's effort level during an outing. Therefore. various embodiments of the invention may combine any measured performance parameter (e.g., foot contact time, foot loft time, step time, speed, pace, energy expenditure, distance traveled, etc.) with any measured variable physiological parameter (e.g., heart rate, respiration rate, body temperature, lactate level, etc.) to yield a useful result.</p>
    <p>As shown in FIG. 4, in one illustrative embodiment of the invention, the foot-mounted unit <b>102</b> includes an altimeter <b>426</b> to measure the current altitude (with respect to a reference altitude such as sea level) of the user <b>112</b>. The altimeter <b>426</b> may be disposed on the user <b>112</b> in any of a number of ways, and need not be included in the foot-mounted unit <b>112</b>. For example, the altimeter <b>426</b> may alternatively be disposed within the wrist-mounted unit <b>104</b>, the chest-mounted unit <b>106</b>, or elsewhere on the user <b>112</b>. The output from the altimeter <b>426</b> may be exploited in any of a number of ways. For example, information from the altimeter <b>426</b> may be stored in memory and/or transferred to the computer <b>428</b> or the server <b>442</b> for display on the display <b>438</b> and/or analysis, as discussed above.</p>
    <p>In one embodiment, the output from the altimeter <b>426</b>, together with distance traveled measurements, may be used to determine a grade of the surface on which the user <b>112</b> is walking or running. This determination of grade may then be used to calculate or correct calculated values such as Pace, Speed, distance traveled, energy expenditure, and the like, in a manner similar to that discussed above. Such performance parameters therefore may be calculated based upon measured altitudes of the user.</p>
    <p>As discussed above, information regarding any oft the parameters and values discussed herein may be transmitted from the foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b> to the computer <b>428</b>, and possibly the network server <b>442</b>. Once this information is so transferred, software executing on the computer <b>428</b> and/or the network server <b>442</b> may analyze and/or process it so as to provide meaningful feedback to the user, for example, in the form of graphs, charts, data logs, etc. For example, the user may view (e.g., on the display <b>438</b>) displayed information such as graphs (e.g., time lapse graphs), charts, and/or data logs representing: (1) daily, weekly, monthly, yearly values (and/or any of the forgoing measured to date) of: (a) total distance traveled while walking and/or running, (b) total time spent walking and/or running, (c) average pace or speed while walking and/or running, and/or (c) average fitness index; (2) average pace, speed, heart rate, stride length, cadence (stride rate), caloric burn rate, acceleration, and/or elevation per unit of choice (e.g., per mile or per minute) during a particular outing; and/or (3) mileage traveled by, or an amount of accumulated stress encountered by, a respective pairs of running shoes or by a particular user; etc. A few examples of such graphs and charts that may be displayed to the user are discussed below in connection with FIGS. 33A-37. When appropriate, any combination of the above-identified items may be combined on the same graph so as to tell the story of a particular outing. For example, a user's average pace, heart rate, and course elevation, may be shown simultaneously on a per-unit distance (e.g., per mile) basis, thereby giving the person reviewing the graph sufficient information to understand the correlation between changes in such values during the race, e.g., a significant increase in elevation may be found to correlate with the user's decrease in speed and increase in heart rate, or vice versa.</p>
    <p>The graphs of FIGS. 33A-36B and the chart of FIG. 37 illustrate examples of how different types of information may be displayed to the user (e.g., using the display <b>438</b> of the computer <b>428</b>) based upon data accumulated while the user is in locomotion on foot (i.e., data accumulated using an ambulatory device).</p>
    <p>The graph of FIG. 33A shows both measured speed and measured stride lengths of the user as a function of distance during a four hundred meter race. Specifically, the curve <b>3302</b>A represents the measured speed of the user <b>112</b> as a function of distance during the race, and the curve <b>3304</b>A represents measured stride lengths of the user <b>112</b> as a function of distance during the race. Curves <b>3302</b>B and <b>3302</b>B in the graph of FIG. 33B are based upon the same values as are the curves <b>3302</b>A and <b>3302</b>A, respectively; however, the values shown therein have been averaged over fifty meter intervals. The stride length of a user is the distance between locations where the left foot and the right foot of the user, or vice versa, make contact with the ground during a complete footstep (defined above) taken by the user. A user's stride length therefore may be calculated by dividing the distance traveled during a complete footstep by two. The stride length for a given footstep may be calculated, for example, either (1) by dividing the measured step time (Ts) for the footstep by two times the calculated pace during the footstep (i.e., Ts/(2*Pace)(and converting to different units, if desired), or (2) by multiplying the calculated speed during the footstep by the measured step time (Ts) for the footstep, and dividing the result by two (i.e., Ts*Speed/2) (and converting to different units, if desired).</p>
    <p>The graph of FIG. 34A shows both measured speed and measured stride rate (cadence) of the user as a function of distance during a four hundred meter race. Specifically, the curve <b>3302</b>A represents the measured speed of the user <b>112</b> as a function of distance during the race, and the curve <b>3402</b>A represents the cadence of the user <b>112</b> as a function of distance during the race. Curves <b>3302</b>B and <b>3402</b>B in the graph of FIG. 34B are based upon the same values as are the curves <b>3302</b>A and <b>3402</b>A, respectively; however, the values shown therein have been averaged over fifty meter intervals. The cadence for each footstep may be calculated, for example, by taking the inverse of the measured step time (Ts) for that footstep, and (if desired) adjusting the units of the value so obtained to a typical measure such as steps/minute.</p>
    <p>The graph of FIG. 35A shows both measured speed and measured caloric burn rate of the user as a function of distance during a four hundred meter race. Specifically, the curve <b>3302</b>A represents the measured speed of the user <b>112</b> as a function of distance during the race, and the curve <b>3502</b>A represents the caloric burn rate of the user <b>112</b> as a function of distance during the race. Curves <b>3302</b>B and <b>3502</b>B in the graph of FIG. 35B are based upon the same values as are the curves <b>3302</b>A and <b>3502</b>A, respectively; however, the values shown therein have been averaged over fifty meter intervals. The caloric burn rate for each footstep may be calculated, for example, in the manner described in U.S. Pat. No. 5,925,001, incorporated by reference above.</p>
    <p>The graph of FIG. 36A shows both measured speed and measured acceleration of the user as a function of distance during a four hundred meter race. Specifically, the curve <b>3302</b>A represents the measured speed of the user <b>112</b> as a function of distance during the race, and the curve <b>3602</b>A represents the acceleration of the user <b>112</b> as a function of distance during the race. Curves <b>3302</b>B and <b>3602</b>B in the graph of FIG. 36B are based upon the same values as are the curves <b>3302</b>A and <b>3602</b>A, respectively; however, the values shown therein have been averaged over fifty meter intervals. The acceleration for each footstep may be calculated, for example, by calculating the change in speed between footsteps (e.g., by subtracting the speed measured during the footstep succeeding the current footstep from the speed measured during the footstep preceding the current footstep), and dividing that value by the measured step time (Ts) for the current footstep (and converting to different units, if desired).</p>
    <p>The chart of FIG. 37 includes entries for race time, split time, average speed (both meters-per-second and miles-per-hour), average stride length (both meters and feet), average stride rate, average caloric burn rate, total calories burned, and acceleration, each calculated based upon fifty meter intervals of a four hundred meter race.</p>
    <p>In addition to calculating pace based upon the measured foot contact time for a footstep (as discussed above in connection with FIG. <b>8</b>), and calculating speed based upon the inverse of the measured foot contact time for a footstep (as discussed above in connection with FIG. <b>13</b>), we have discovered that it is also possible to calculate the Pace of a user during a particular footstep based upon the measured step time (Ts) for that footstep, and to calculate the Speed of the user during a particular footstep based upon the inverse value of the measured step time (1/Ts) for that footstep. Examples of empirically measured relationships between Pace and Ts and between Speed and 1/Ts for a particular user <b>112</b> (when the user <b>112</b> is walking) are shown as lines <b>3802</b> and <b>3902</b> in FIGS. 38 and 39, respectively. Because these relationships are approximately linear, linear equations can be derived that define them with substantial precision, and such equations can be used to calculate the pace and/or speed of the user while the user is in locomotion on foot simply by measuring the step times of the user. These lines may be identified and calibrated for a particular user using any of the techniques discussed above in connection with the Pace vs. Tc and Speed vs. 1/Tc lines. The measured values of Speed and/or Pace obtained using the relationships of FIGS. 38 and 39 can also be used in any of the ways and for any of the purposes discussed elsewhere herein. For example, parameters such as distance traveled, average speed, average pace, etc. may be calculated based upon the calculated Speed and/or Pace values. Although only the walking curves <b>3802</b> and <b>3902</b> are shown in FIG. 38, it should be appreciated that separate, different lines or curves may also be employed to calculate Speed and/or Pace values, based upon measured step times, when the user <b>112</b> is running. Whether a walking or running line is to be used for a particular footstep may be determined in the same or similar manner as is done in connection with the Pace vs. Tc and Speed vs. 1/Tc curves discussed above.</p>
    <p>It is known that the average amount of force (F<sub>AVE</sub>) exerted on the ground by a user during a footstep taken by the user may be calculated using the equation (29) below:</p>
    <p>
      <maths> <formula-text> <i>F</i> <sub>AVE</sub>=(<i>Ts*W</i>)/(2<i>*Tc</i>)(29)</formula-text> </maths> </p>
    <p>wherein W is equal to the weight of the user.</p>
    <p>In one embodiment of the invention, Ts and Tc values are measured during respective footsteps of the user during an outing, and the equation (29) is used to measure a value representing a total amount of stress exerted by the user (Accumulated Stress) during that outing. One way this can be accomplished is by maintaining a running total of per-footstep average force measurements (calculated using the equation (29)) throughout the outing, e.g., using the equation (30) below:</p>
    <p>Accumulated Stress=<i>F</i> <sub>AVE</sub>=(<i>W*Ts</i>)/(2<i>*Tc</i>).(30)</p>
    <p>Alternatively, average values of Tc and Ts can be calculated for the outing and can be inserted in the equation (29) to obtain a value of F<sub>AVE</sub>. The value of F<sub>AVE </sub>so obtained then can be multiplied by the number of steps taken by the user to yield the value of Accumulated Stress. In either case, foot-mounted unit <b>102</b> and/or the wrist-mounted unit <b>104</b> may obtain the values of Ts and Tc, and either of these units, or one or more other devices, such as the computer <b>428</b> and/or the network server <b>442</b>, may be employed to calculate the values of F<sub>AVE </sub>and/or Accumulated Stress. It should be appreciated that the value of Accumulated stress may be scaled by a particular factor to render a value that is easier to comprehend and store in memory. In such a situation, the factor of two in the denominator of equations (29) and (30) could be omitted, as it would be included in the scaling factor that was employed. Separate values of Force and/or Accumulated stress may be obtained for walking or running, if desired. Any of the techniques discussed above for distinguishing between occasions when the user <b>112</b> is walking or running may be employed for this purpose.</p>
    <p>Values of Accumulated Stress may also be accumulated over more than one outing, if desired. One application for this type accumulated information is to measure the amount of stress encountered by a pair of shoes over the lifetime of the shoes. The stress accumulated on a per-outing basis can also be employed by a user to permit the user to gauge the stress encountered during each outing, and adjust or plan his or her workout routine accordingly to minimize the risk of injury or to optimize a workout regime during the current workout or during future workouts. For example, a beginning runner may be advised to increase the amount of stress encountered during successive runs at a gradual rate, and thereby minimize the risk of overexertion before his or her body is physically conditioned to withstand certain levels of stress.</p>
    <p>We have recognized that, when Accumulated Stress is measured as discussed above, as the Speed of the user increases (and the user's Pace decreases accordingly), the amount of Accumulated Stress exerted per unit of time (e.g., per minute) tends to increase, whereas the amount of Accumulated Stress per unit of distance (e.g., per mile) tends to decrease. This phenomenon is illustrated both in the chart of FIG. <b>40</b> and the graph of FIG. <b>41</b>.</p>
    <p>In the chart of FIG. 40, average values of Tc and Ts for a particular user (weighing 150 pounds) traveling at each of several paces and speeds are used to calculate corresponding values of average ground force using the equation (29). The chart of FIG. 40 also shows values of Stress Per {fraction (1/10)} Mile and Stress Per Minute, with each of these values being calculated by multiplying the average ground force value by the number of steps taken during the corresponding time or distance interval. The curve <b>4102</b> in FIG. 41 represents the relationship between Accumulated Stress measured on a per-minute basis for a particular user and the Speed of the user. The curve <b>4104</b> in FIG. 41 represents the relationship between Accumulated Stress measured on a per-{fraction (1/10)} mile basis for a particular user and the Speed of the user. If desired, these types of charts or curves for Accumulated Stress, or other information calculated based thereupon, can be generated and displayed using any of the devices in the system of FIG. <b>4</b>.</p>
    <p>It should be understood that each of the features, techniques, and capabilities of the devices and systems described herein may be employed in combination with any of the other described features, techniques, and capabilities, and the invention is not limited to the particular combinations of features, techniques, and capabilities described herein. For example, any of the described features, capabilities, or techniques with regard to the display of certain performance parameters and/or variable physiological parameters, or graphs, charts, etc., based thereon, can be employed in combination with any of the described features, capabilities or techniques involved with accumulating data during footsteps taken by the user, or performing or optimizing calculations based thereupon (e.g... calibrating Pace vs. Tc or Ts and/or Speed vs. 1/Tc or 1/Ts lines).</p>
    <p>Having thus described at least one illustrative embodiment of the invention, various alterations, modifications and improvements will readily occur to those skilled in the art. Such alterations, modifications and improvements are intended to be within the spirit and scope of the invention. Accordingly, the foregoing description is by way of example only and is not intended as limiting. The invention is limited only as defined in the following claims and the equivalents thereto.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3840726">US3840726</a></td><td class="patent-data-table-td patent-date-value">Jan 15, 1973</td><td class="patent-data-table-td patent-date-value">Oct 8, 1974</td><td class="patent-data-table-td ">Westinghouse Electric Corp</td><td class="patent-data-table-td ">Position locator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3972038">US3972038</a></td><td class="patent-data-table-td patent-date-value">Mar 28, 1975</td><td class="patent-data-table-td patent-date-value">Jul 27, 1976</td><td class="patent-data-table-td ">Nasa</td><td class="patent-data-table-td ">Accelerometer telemetry system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3974491">US3974491</a></td><td class="patent-data-table-td patent-date-value">Jul 22, 1974</td><td class="patent-data-table-td patent-date-value">Aug 10, 1976</td><td class="patent-data-table-td ">Smithkline Corporation</td><td class="patent-data-table-td ">Load signaling device for a patient&#39;s foot</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4371945">US4371945</a></td><td class="patent-data-table-td patent-date-value">Dec 1, 1980</td><td class="patent-data-table-td patent-date-value">Feb 1, 1983</td><td class="patent-data-table-td ">Lawrence Joseph Karr</td><td class="patent-data-table-td ">Electronic pedometer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4408183">US4408183</a></td><td class="patent-data-table-td patent-date-value">Jun 6, 1977</td><td class="patent-data-table-td patent-date-value">Oct 4, 1983</td><td class="patent-data-table-td ">Wills Thomas A</td><td class="patent-data-table-td ">Exercise monitoring device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4409992">US4409992</a></td><td class="patent-data-table-td patent-date-value">Oct 16, 1980</td><td class="patent-data-table-td patent-date-value">Oct 18, 1983</td><td class="patent-data-table-td ">Sidorenko Georgy I</td><td class="patent-data-table-td ">Electronic ergometer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4499394">US4499394</a></td><td class="patent-data-table-td patent-date-value">Oct 21, 1983</td><td class="patent-data-table-td patent-date-value">Feb 12, 1985</td><td class="patent-data-table-td ">Koal Jan G</td><td class="patent-data-table-td ">Polymer piezoelectric sensor of animal foot pressure</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4578769">US4578769</a></td><td class="patent-data-table-td patent-date-value">Feb 9, 1983</td><td class="patent-data-table-td patent-date-value">Mar 25, 1986</td><td class="patent-data-table-td ">Nike, Inc.</td><td class="patent-data-table-td ">Device for determining the speed, distance traversed, elapsed time and calories expended by a person while running</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4649552">US4649552</a></td><td class="patent-data-table-td patent-date-value">Dec 31, 1984</td><td class="patent-data-table-td patent-date-value">Mar 10, 1987</td><td class="patent-data-table-td ">Matsushita Electric Works, Ltd.</td><td class="patent-data-table-td ">Electronic pedometer with step sensor in removable insole</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4651446">US4651446</a></td><td class="patent-data-table-td patent-date-value">Dec 24, 1984</td><td class="patent-data-table-td patent-date-value">Mar 24, 1987</td><td class="patent-data-table-td ">Matsushita Electric Works, Ltd.</td><td class="patent-data-table-td ">Electronic pedometer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4745564">US4745564</a></td><td class="patent-data-table-td patent-date-value">Feb 7, 1986</td><td class="patent-data-table-td patent-date-value">May 17, 1988</td><td class="patent-data-table-td ">Board Of Trustees Operating Michigan State University</td><td class="patent-data-table-td ">Impact detection apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4757714">US4757714</a></td><td class="patent-data-table-td patent-date-value">Apr 10, 1987</td><td class="patent-data-table-td patent-date-value">Jul 19, 1988</td><td class="patent-data-table-td ">Insight, Inc.</td><td class="patent-data-table-td ">For a self-propelled sportsman</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4763287">US4763287</a></td><td class="patent-data-table-td patent-date-value">May 21, 1987</td><td class="patent-data-table-td patent-date-value">Aug 9, 1988</td><td class="patent-data-table-td ">Puma Ag Rudolf Dassler Sport</td><td class="patent-data-table-td ">Measuring performance information in running disciplines and shoe systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4771394">US4771394</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 1986</td><td class="patent-data-table-td patent-date-value">Sep 13, 1988</td><td class="patent-data-table-td ">Puma Aktiengesellschaft Rudolf Dassler Sport</td><td class="patent-data-table-td ">Computer shoe system and shoe for use therewith</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4774679">US4774679</a></td><td class="patent-data-table-td patent-date-value">Feb 20, 1986</td><td class="patent-data-table-td patent-date-value">Sep 27, 1988</td><td class="patent-data-table-td ">Carlin John A</td><td class="patent-data-table-td ">Produced by a sport participant in a sporting event</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4814661">US4814661</a></td><td class="patent-data-table-td patent-date-value">Oct 26, 1987</td><td class="patent-data-table-td patent-date-value">Mar 21, 1989</td><td class="patent-data-table-td ">Washington State University Research Foundation, Inc.</td><td class="patent-data-table-td ">Systems for measurement and analysis of forces exerted during human locomotion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4830021">US4830021</a></td><td class="patent-data-table-td patent-date-value">Aug 29, 1988</td><td class="patent-data-table-td patent-date-value">May 16, 1989</td><td class="patent-data-table-td ">Thornton William E</td><td class="patent-data-table-td ">Monitoring system for locomotor activity</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4855942">US4855942</a></td><td class="patent-data-table-td patent-date-value">Oct 28, 1987</td><td class="patent-data-table-td patent-date-value">Aug 8, 1989</td><td class="patent-data-table-td ">Elexis Corporation</td><td class="patent-data-table-td ">Pedometer and/or calorie measuring device and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4956628">US4956628</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 1988</td><td class="patent-data-table-td patent-date-value">Sep 11, 1990</td><td class="patent-data-table-td ">Dennis Furlong</td><td class="patent-data-table-td ">Electronic monitoring of ground contact by an athlete&#39;s shoes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4962469">US4962469</a></td><td class="patent-data-table-td patent-date-value">Apr 14, 1989</td><td class="patent-data-table-td patent-date-value">Oct 9, 1990</td><td class="patent-data-table-td ">Casio Computer Co., Ltd.</td><td class="patent-data-table-td ">Exercise measuring instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5033013">US5033013</a></td><td class="patent-data-table-td patent-date-value">May 14, 1990</td><td class="patent-data-table-td patent-date-value">Jul 16, 1991</td><td class="patent-data-table-td ">Yamasa Tokei Meter Co., Ltd.</td><td class="patent-data-table-td ">Method and apparatus for measuring the amount of exercise</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5186062">US5186062</a></td><td class="patent-data-table-td patent-date-value">May 18, 1989</td><td class="patent-data-table-td patent-date-value">Feb 16, 1993</td><td class="patent-data-table-td ">Standard St Sensortechnik Ag.</td><td class="patent-data-table-td ">Method of investigating the gait of a living being</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5269081">US5269081</a></td><td class="patent-data-table-td patent-date-value">May 1, 1992</td><td class="patent-data-table-td patent-date-value">Dec 14, 1993</td><td class="patent-data-table-td ">Gray Frank B</td><td class="patent-data-table-td ">Force monitoring shoe</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5285586">US5285586</a></td><td class="patent-data-table-td patent-date-value">Jun 26, 1992</td><td class="patent-data-table-td patent-date-value">Feb 15, 1994</td><td class="patent-data-table-td ">Goldston Mark R</td><td class="patent-data-table-td ">Athletic shoe having plug-in module</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5323650">US5323650</a></td><td class="patent-data-table-td patent-date-value">Jan 14, 1993</td><td class="patent-data-table-td patent-date-value">Jun 28, 1994</td><td class="patent-data-table-td ">Fullen Systems, Inc.</td><td class="patent-data-table-td ">System for continuously measuring forces applied to the foot</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5343445">US5343445</a></td><td class="patent-data-table-td patent-date-value">Jul 6, 1993</td><td class="patent-data-table-td patent-date-value">Aug 30, 1994</td><td class="patent-data-table-td ">David Stern</td><td class="patent-data-table-td ">Athletic shoe with timing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5357696">US5357696</a></td><td class="patent-data-table-td patent-date-value">Oct 12, 1993</td><td class="patent-data-table-td patent-date-value">Oct 25, 1994</td><td class="patent-data-table-td ">Gray Frank B</td><td class="patent-data-table-td ">Device for measuring force applied to a wearer&#39;s foot</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5361778">US5361778</a></td><td class="patent-data-table-td patent-date-value">Jan 26, 1993</td><td class="patent-data-table-td patent-date-value">Nov 8, 1994</td><td class="patent-data-table-td ">Seitz Ronald H</td><td class="patent-data-table-td ">Method and apparatus for sensing and evaluating foot borne motion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5422628">US5422628</a></td><td class="patent-data-table-td patent-date-value">Dec 2, 1993</td><td class="patent-data-table-td patent-date-value">Jun 6, 1995</td><td class="patent-data-table-td ">Rodgers; Nicholas A.</td><td class="patent-data-table-td ">Reed switch actuated circuit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5437289">US5437289</a></td><td class="patent-data-table-td patent-date-value">Apr 2, 1992</td><td class="patent-data-table-td patent-date-value">Aug 1, 1995</td><td class="patent-data-table-td ">Liverance; Howard L.</td><td class="patent-data-table-td ">Interactive sports equipment teaching device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5452269">US5452269</a></td><td class="patent-data-table-td patent-date-value">Aug 29, 1994</td><td class="patent-data-table-td patent-date-value">Sep 19, 1995</td><td class="patent-data-table-td ">David Stern</td><td class="patent-data-table-td ">Athletic shoe with timing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5485402">US5485402</a></td><td class="patent-data-table-td patent-date-value">Mar 21, 1994</td><td class="patent-data-table-td patent-date-value">Jan 16, 1996</td><td class="patent-data-table-td ">Prosthetics Research Study</td><td class="patent-data-table-td ">Gait activity monitor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5524637">US5524637</a></td><td class="patent-data-table-td patent-date-value">Jun 29, 1994</td><td class="patent-data-table-td patent-date-value">Jun 11, 1996</td><td class="patent-data-table-td ">Erickson; Jon W.</td><td class="patent-data-table-td ">Interactive system for measuring physiological exertion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5526290">US5526290</a></td><td class="patent-data-table-td patent-date-value">Jul 29, 1994</td><td class="patent-data-table-td patent-date-value">Jun 11, 1996</td><td class="patent-data-table-td ">Casio Computer Co., Ltd.</td><td class="patent-data-table-td ">Pace calculation devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5541860">US5541860</a></td><td class="patent-data-table-td patent-date-value">Jul 10, 1995</td><td class="patent-data-table-td patent-date-value">Jul 30, 1996</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Small size apparatus for measuring and recording acceleration</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5583776">US5583776</a></td><td class="patent-data-table-td patent-date-value">Mar 16, 1995</td><td class="patent-data-table-td patent-date-value">Dec 10, 1996</td><td class="patent-data-table-td ">Point Research Corporation</td><td class="patent-data-table-td ">Dead reckoning navigational system using accelerometer to measure foot impacts</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5623944">US5623944</a></td><td class="patent-data-table-td patent-date-value">Jun 7, 1995</td><td class="patent-data-table-td patent-date-value">Apr 29, 1997</td><td class="patent-data-table-td ">Neurocom International, Inc.</td><td class="patent-data-table-td ">Method for characterizing gait</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5636146">US5636146</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 21, 1994</td><td class="patent-data-table-td patent-date-value">Jun 3, 1997</td><td class="patent-data-table-td ">Phatrat Technology, Inc.</td><td class="patent-data-table-td ">Apparatus and methods for determining loft time and speed</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5720200">US5720200</a></td><td class="patent-data-table-td patent-date-value">Jan 6, 1995</td><td class="patent-data-table-td patent-date-value">Feb 24, 1998</td><td class="patent-data-table-td ">Anderson; Kenneth J.</td><td class="patent-data-table-td ">Performance measuring footwear</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5724265">US5724265</a></td><td class="patent-data-table-td patent-date-value">Dec 12, 1995</td><td class="patent-data-table-td patent-date-value">Mar 3, 1998</td><td class="patent-data-table-td ">Hutchings; Lawrence J.</td><td class="patent-data-table-td ">System and method for measuring movement of objects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5897457">US5897457</a></td><td class="patent-data-table-td patent-date-value">Apr 29, 1996</td><td class="patent-data-table-td patent-date-value">Apr 27, 1999</td><td class="patent-data-table-td ">Mackovjak; Paul</td><td class="patent-data-table-td ">Athletic performance monitoring system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5899963">US5899963</a></td><td class="patent-data-table-td patent-date-value">Jun 17, 1997</td><td class="patent-data-table-td patent-date-value">May 4, 1999</td><td class="patent-data-table-td ">Acceleron Technologies, Llc</td><td class="patent-data-table-td ">System and method for measuring movement of objects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5925001">US5925001</a></td><td class="patent-data-table-td patent-date-value">Apr 11, 1994</td><td class="patent-data-table-td patent-date-value">Jul 20, 1999</td><td class="patent-data-table-td ">Hoyt; Reed W.</td><td class="patent-data-table-td ">To measure energy expended during walking or running</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5955667">US5955667</a></td><td class="patent-data-table-td patent-date-value">Oct 14, 1997</td><td class="patent-data-table-td patent-date-value">Sep 21, 1999</td><td class="patent-data-table-td ">Governors Of The University Of Alberta</td><td class="patent-data-table-td ">Motion analysis system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5963891">US5963891</a></td><td class="patent-data-table-td patent-date-value">Apr 24, 1997</td><td class="patent-data-table-td patent-date-value">Oct 5, 1999</td><td class="patent-data-table-td ">Modern Cartoons, Ltd.</td><td class="patent-data-table-td ">System for tracking body movements in a virtual reality system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5976083">US5976083</a></td><td class="patent-data-table-td patent-date-value">Jul 30, 1997</td><td class="patent-data-table-td patent-date-value">Nov 2, 1999</td><td class="patent-data-table-td ">Living Systems, Inc.</td><td class="patent-data-table-td ">Portable aerobic fitness monitor for walking and running</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5989200">US5989200</a></td><td class="patent-data-table-td patent-date-value">Apr 2, 1998</td><td class="patent-data-table-td patent-date-value">Nov 23, 1999</td><td class="patent-data-table-td ">Omron Corporation</td><td class="patent-data-table-td ">Exercise amount measuring device capable of displaying the amount of exercise to be performed further</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6018705">US6018705</a></td><td class="patent-data-table-td patent-date-value">Oct 2, 1997</td><td class="patent-data-table-td patent-date-value">Jan 25, 2000</td><td class="patent-data-table-td ">Personal Electronic Devices, Inc.</td><td class="patent-data-table-td ">Measuring foot contact time and foot loft time of a person in locomotion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6038935">US6038935</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 1998</td><td class="patent-data-table-td patent-date-value">Mar 21, 2000</td><td class="patent-data-table-td ">Fullen Systems, Inc.</td><td class="patent-data-table-td ">Apparatus and method for measuring the magnitude and distribution of forces on the foot of a quadruped</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6042549">US6042549</a></td><td class="patent-data-table-td patent-date-value">Mar 21, 1997</td><td class="patent-data-table-td patent-date-value">Mar 28, 2000</td><td class="patent-data-table-td ">Seiko Epson Corporation</td><td class="patent-data-table-td ">Exercise intensity measuring device and exercise quantity measuring device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6052654">US6052654</a></td><td class="patent-data-table-td patent-date-value">Jul 30, 1999</td><td class="patent-data-table-td patent-date-value">Apr 18, 2000</td><td class="patent-data-table-td ">Personal Electronic Devices, Inc.</td><td class="patent-data-table-td ">Measuring foot contact time and foot loft time of a person in locomotion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6305221">US6305221</a></td><td class="patent-data-table-td patent-date-value">Jun 14, 1999</td><td class="patent-data-table-td patent-date-value">Oct 23, 2001</td><td class="patent-data-table-td ">Aeceleron Technologies, Llc</td><td class="patent-data-table-td ">Rotational sensor system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6356856">US6356856</a></td><td class="patent-data-table-td patent-date-value">Feb 22, 1999</td><td class="patent-data-table-td patent-date-value">Mar 12, 2002</td><td class="patent-data-table-td ">U.S. Philips Corporation</td><td class="patent-data-table-td ">Method of and system for measuring performance during an exercise activity, and an athletic shoe for use in system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7089151">US7089151</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 6, 2004</td><td class="patent-data-table-td patent-date-value">Aug 8, 2006</td><td class="patent-data-table-td ">Batterman Engineering, Llc.</td><td class="patent-data-table-td ">Method and system for determining occurrence of slips leading to falls</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7114822">US7114822</a></td><td class="patent-data-table-td patent-date-value">Nov 12, 2004</td><td class="patent-data-table-td patent-date-value">Oct 3, 2006</td><td class="patent-data-table-td ">Bbc International, Ltd.</td><td class="patent-data-table-td ">Article of footwear with remote sound activating unit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7171331">US7171331</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 21, 2006</td><td class="patent-data-table-td patent-date-value">Jan 30, 2007</td><td class="patent-data-table-td ">Phatrat Technology, Llc</td><td class="patent-data-table-td ">Shoes employing monitoring devices, and associated methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7225565">US7225565</a></td><td class="patent-data-table-td patent-date-value">Jan 31, 2005</td><td class="patent-data-table-td patent-date-value">Jun 5, 2007</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Intelligent footwear systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7237446">US7237446</a></td><td class="patent-data-table-td patent-date-value">Sep 16, 2005</td><td class="patent-data-table-td patent-date-value">Jul 3, 2007</td><td class="patent-data-table-td ">Raymond Chan</td><td class="patent-data-table-td ">System and method for measuring gait kinematics information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7305323">US7305323</a></td><td class="patent-data-table-td patent-date-value">Jan 9, 2006</td><td class="patent-data-table-td patent-date-value">Dec 4, 2007</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Method and apparatus for counting a number of steps taken by walker</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7353137">US7353137</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 28, 2006</td><td class="patent-data-table-td patent-date-value">Apr 1, 2008</td><td class="patent-data-table-td ">Phatrat Technology, Llc</td><td class="patent-data-table-td ">Shoe-based weight measuring system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7433546">US7433546</a></td><td class="patent-data-table-td patent-date-value">Oct 25, 2004</td><td class="patent-data-table-td patent-date-value">Oct 7, 2008</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Image scaling arrangement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7467603">US7467603</a></td><td class="patent-data-table-td patent-date-value">May 24, 2005</td><td class="patent-data-table-td patent-date-value">Dec 23, 2008</td><td class="patent-data-table-td ">Equusys, Incorporated</td><td class="patent-data-table-td ">Animal instrumentation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7506460">US7506460</a></td><td class="patent-data-table-td patent-date-value">Sep 18, 2006</td><td class="patent-data-table-td patent-date-value">Mar 24, 2009</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Intelligent footwear systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7527023">US7527023</a></td><td class="patent-data-table-td patent-date-value">May 10, 2007</td><td class="patent-data-table-td patent-date-value">May 5, 2009</td><td class="patent-data-table-td ">Equusys Incorporated</td><td class="patent-data-table-td ">Animal instrumentation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7532977">US7532977</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 30, 2005</td><td class="patent-data-table-td patent-date-value">May 12, 2009</td><td class="patent-data-table-td ">Yu-Yu Chen</td><td class="patent-data-table-td ">Portable personal positioner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7536565">US7536565</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 2005</td><td class="patent-data-table-td patent-date-value">May 19, 2009</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Techniques for improved playlist processing on media devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7565036">US7565036</a></td><td class="patent-data-table-td patent-date-value">May 16, 2007</td><td class="patent-data-table-td patent-date-value">Jul 21, 2009</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Image scaling arrangement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7589629">US7589629</a></td><td class="patent-data-table-td patent-date-value">Feb 28, 2007</td><td class="patent-data-table-td patent-date-value">Sep 15, 2009</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Event recorder for portable media device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7590772">US7590772</a></td><td class="patent-data-table-td patent-date-value">Aug 22, 2005</td><td class="patent-data-table-td patent-date-value">Sep 15, 2009</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Audio status information for a portable electronic device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7593782">US7593782</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 2005</td><td class="patent-data-table-td patent-date-value">Sep 22, 2009</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Highly portable media device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7596891">US7596891</a></td><td class="patent-data-table-td patent-date-value">Mar 30, 2006</td><td class="patent-data-table-td patent-date-value">Oct 6, 2009</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Shoe housing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7610813">US7610813</a></td><td class="patent-data-table-td patent-date-value">Sep 29, 2006</td><td class="patent-data-table-td patent-date-value">Nov 3, 2009</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and apparatus for a self-powered RFID-readable pedometer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7620520">US7620520</a></td><td class="patent-data-table-td patent-date-value">Dec 28, 2006</td><td class="patent-data-table-td patent-date-value">Nov 17, 2009</td><td class="patent-data-table-td ">Phatrat Technology, Llc</td><td class="patent-data-table-td ">Methods for determining weight of a person</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7623740">US7623740</a></td><td class="patent-data-table-td patent-date-value">Jun 24, 2008</td><td class="patent-data-table-td patent-date-value">Nov 24, 2009</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Image scaling arrangement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7631382">US7631382</a></td><td class="patent-data-table-td patent-date-value">Mar 23, 2006</td><td class="patent-data-table-td patent-date-value">Dec 15, 2009</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Intelligent footwear systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7673238">US7673238</a></td><td class="patent-data-table-td patent-date-value">Jan 5, 2006</td><td class="patent-data-table-td patent-date-value">Mar 2, 2010</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Portable media device with video acceleration capabilities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7673587">US7673587</a></td><td class="patent-data-table-td patent-date-value">May 10, 2007</td><td class="patent-data-table-td patent-date-value">Mar 9, 2010</td><td class="patent-data-table-td ">Equusys, Incorporated</td><td class="patent-data-table-td ">Animal instrumentation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7676960">US7676960</a></td><td class="patent-data-table-td patent-date-value">Apr 5, 2007</td><td class="patent-data-table-td patent-date-value">Mar 16, 2010</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Intelligent footwear systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7676961">US7676961</a></td><td class="patent-data-table-td patent-date-value">Apr 6, 2007</td><td class="patent-data-table-td patent-date-value">Mar 16, 2010</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Intelligent footwear systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7698101">US7698101</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 7, 2007</td><td class="patent-data-table-td patent-date-value">Apr 13, 2010</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Smart garment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7706637">US7706637</a></td><td class="patent-data-table-td patent-date-value">Sep 27, 2006</td><td class="patent-data-table-td patent-date-value">Apr 27, 2010</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Host configured for interoperation with coupled portable media player device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7729791">US7729791</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 2006</td><td class="patent-data-table-td patent-date-value">Jun 1, 2010</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Portable media playback device including user interface event passthrough to non-media-playback processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7771371">US7771371</a></td><td class="patent-data-table-td patent-date-value">Aug 11, 2005</td><td class="patent-data-table-td patent-date-value">Aug 10, 2010</td><td class="patent-data-table-td ">Andante Medical Devices Ltd</td><td class="patent-data-table-td ">Sports shoe with sensing and control</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7826983">US7826983</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 5, 2007</td><td class="patent-data-table-td patent-date-value">Nov 2, 2010</td><td class="patent-data-table-td ">Majd Alwan</td><td class="patent-data-table-td ">Instrumented mobility assistance device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7831199">US7831199</a></td><td class="patent-data-table-td patent-date-value">Sep 1, 2006</td><td class="patent-data-table-td patent-date-value">Nov 9, 2010</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Media data exchange, transfer or delivery for portable electronic devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7841966">US7841966</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 29, 2007</td><td class="patent-data-table-td patent-date-value">Nov 30, 2010</td><td class="patent-data-table-td ">At&amp;T Intellectual Property I, L.P.</td><td class="patent-data-table-td ">Methods, systems, and products for monitoring athletic performance</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7856564">US7856564</a></td><td class="patent-data-table-td patent-date-value">Mar 18, 2009</td><td class="patent-data-table-td patent-date-value">Dec 21, 2010</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Techniques for preserving media play mode information on media devices during power cycling</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7865745">US7865745</a></td><td class="patent-data-table-td patent-date-value">Mar 3, 2009</td><td class="patent-data-table-td patent-date-value">Jan 4, 2011</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Techniques for improved playlist processing on media devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7881564">US7881564</a></td><td class="patent-data-table-td patent-date-value">Oct 12, 2009</td><td class="patent-data-table-td patent-date-value">Feb 1, 2011</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Image scaling arrangement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7881902">US7881902</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 26, 2010</td><td class="patent-data-table-td patent-date-value">Feb 1, 2011</td><td class="patent-data-table-td ">Dp Technologies, Inc.</td><td class="patent-data-table-td ">Human activity monitoring device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7889497">US7889497</a></td><td class="patent-data-table-td patent-date-value">Jul 30, 2007</td><td class="patent-data-table-td patent-date-value">Feb 15, 2011</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Highly portable media device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7921716">US7921716</a></td><td class="patent-data-table-td patent-date-value">Mar 20, 2009</td><td class="patent-data-table-td patent-date-value">Apr 12, 2011</td><td class="patent-data-table-td ">University Of Utah Research Foundation</td><td class="patent-data-table-td ">Method and system for measuring energy expenditure and foot incline in individuals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7938013">US7938013</a></td><td class="patent-data-table-td patent-date-value">Sep 25, 2009</td><td class="patent-data-table-td patent-date-value">May 10, 2011</td><td class="patent-data-table-td ">Intel-Ge Care Innovations Llc</td><td class="patent-data-table-td ">Method and apparatus for a self-powered RFID-readable pedometer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7953549">US7953549</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">May 31, 2011</td><td class="patent-data-table-td ">Adidas Ag</td><td class="patent-data-table-td ">Wireless device, program products and methods of using a wireless device to deliver services</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7980009">US7980009</a></td><td class="patent-data-table-td patent-date-value">Aug 27, 2009</td><td class="patent-data-table-td patent-date-value">Jul 19, 2011</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Shoe housing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8044795">US8044795</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 2009</td><td class="patent-data-table-td patent-date-value">Oct 25, 2011</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Event recorder for portable media device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8056268">US8056268</a></td><td class="patent-data-table-td patent-date-value">Nov 9, 2009</td><td class="patent-data-table-td patent-date-value">Nov 15, 2011</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Intelligent footwear systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8090130">US8090130</a></td><td class="patent-data-table-td patent-date-value">Apr 24, 2007</td><td class="patent-data-table-td patent-date-value">Jan 3, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Highly portable media devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8099258">US8099258</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 25, 2010</td><td class="patent-data-table-td patent-date-value">Jan 17, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Smart garment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8103802">US8103802</a></td><td class="patent-data-table-td patent-date-value">Jan 17, 2008</td><td class="patent-data-table-td patent-date-value">Jan 24, 2012</td><td class="patent-data-table-td ">Ll International Shoe Company</td><td class="patent-data-table-td ">Portable data system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8151259">US8151259</a></td><td class="patent-data-table-td patent-date-value">Jan 3, 2006</td><td class="patent-data-table-td patent-date-value">Apr 3, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Remote content updates for portable media devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8162804">US8162804</a></td><td class="patent-data-table-td patent-date-value">Feb 14, 2008</td><td class="patent-data-table-td patent-date-value">Apr 24, 2012</td><td class="patent-data-table-td ">Nike, Inc.</td><td class="patent-data-table-td ">Collection and display of athletic information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8166923">US8166923</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 15, 2010</td><td class="patent-data-table-td patent-date-value">May 1, 2012</td><td class="patent-data-table-td ">Equusys, Incorporated</td><td class="patent-data-table-td ">Animal instrumentation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8184070">US8184070</a></td><td class="patent-data-table-td patent-date-value">Jul 6, 2011</td><td class="patent-data-table-td patent-date-value">May 22, 2012</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Method and system for selecting a user interface for a wearable computing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8187182">US8187182</a></td><td class="patent-data-table-td patent-date-value">Aug 29, 2008</td><td class="patent-data-table-td patent-date-value">May 29, 2012</td><td class="patent-data-table-td ">Dp Technologies, Inc.</td><td class="patent-data-table-td ">Sensor fusion for activity identification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8200629">US8200629</a></td><td class="patent-data-table-td patent-date-value">Apr 6, 2009</td><td class="patent-data-table-td patent-date-value">Jun 12, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Image scaling arrangement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8217788">US8217788</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 24, 2011</td><td class="patent-data-table-td patent-date-value">Jul 10, 2012</td><td class="patent-data-table-td ">Vock Curtis A</td><td class="patent-data-table-td ">Shoe wear-out sensor, body-bar sensing system, unitless activity assessment and associated methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8234798">US8234798</a></td><td class="patent-data-table-td patent-date-value">Jul 1, 2009</td><td class="patent-data-table-td patent-date-value">Aug 7, 2012</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Intelligent footwear systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8255640">US8255640</a></td><td class="patent-data-table-td patent-date-value">Oct 18, 2006</td><td class="patent-data-table-td patent-date-value">Aug 28, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Media device with intelligent cache utilization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8259444">US8259444</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 2010</td><td class="patent-data-table-td patent-date-value">Sep 4, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Highly portable media device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8280679">US8280679</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 7, 2007</td><td class="patent-data-table-td patent-date-value">Oct 2, 2012</td><td class="patent-data-table-td ">Pad Technologies Ltd</td><td class="patent-data-table-td ">Activity monitor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8285344">US8285344</a></td><td class="patent-data-table-td patent-date-value">May 20, 2009</td><td class="patent-data-table-td patent-date-value">Oct 9, 2012</td><td class="patent-data-table-td ">DP Technlogies, Inc.</td><td class="patent-data-table-td ">Method and apparatus for adjusting audio for a user environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8300841">US8300841</a></td><td class="patent-data-table-td patent-date-value">Jun 3, 2005</td><td class="patent-data-table-td patent-date-value">Oct 30, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Techniques for presenting sound effects on a portable media player</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8321601">US8321601</a></td><td class="patent-data-table-td patent-date-value">Jul 16, 2009</td><td class="patent-data-table-td patent-date-value">Nov 27, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Audio status information for a portable electronic device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8341524">US8341524</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 2006</td><td class="patent-data-table-td patent-date-value">Dec 25, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Portable electronic device with local search capabilities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8358273">US8358273</a></td><td class="patent-data-table-td patent-date-value">May 23, 2006</td><td class="patent-data-table-td patent-date-value">Jan 22, 2013</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Portable media device with power-managed display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8375784">US8375784</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 2011</td><td class="patent-data-table-td patent-date-value">Feb 19, 2013</td><td class="patent-data-table-td ">University Of Utah Research Foundation</td><td class="patent-data-table-td ">Method and system for measuring energy expenditure and foot incline in individuals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8387468">US8387468</a></td><td class="patent-data-table-td patent-date-value">Apr 15, 2011</td><td class="patent-data-table-td patent-date-value">Mar 5, 2013</td><td class="patent-data-table-td ">Intel-Ge Care Innovations Llc</td><td class="patent-data-table-td ">Method and apparatus for a self-powered RFID-readable pedometer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8458929">US8458929</a></td><td class="patent-data-table-td patent-date-value">Jun 14, 2011</td><td class="patent-data-table-td patent-date-value">Jun 11, 2013</td><td class="patent-data-table-td ">Adidas International Marketing B.V.</td><td class="patent-data-table-td ">Shoe housing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8467979">US8467979</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 8, 2010</td><td class="patent-data-table-td patent-date-value">Jun 18, 2013</td><td class="patent-data-table-td ">Alluvial Joules, Inc.</td><td class="patent-data-table-td ">Intelligent sport shoe system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8473082">US8473082</a></td><td class="patent-data-table-td patent-date-value">Apr 21, 2010</td><td class="patent-data-table-td patent-date-value">Jun 25, 2013</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Portable media playback device including user interface event passthrough to non-media-playback processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8512211">US8512211</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 5, 2008</td><td class="patent-data-table-td patent-date-value">Aug 20, 2013</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Method for quickstart workout generation and calibration</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8548768">US8548768</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 9, 2006</td><td class="patent-data-table-td patent-date-value">Oct 1, 2013</td><td class="patent-data-table-td ">Riddell, Inc.</td><td class="patent-data-table-td ">System and method for evaluating and providing treatment to sports participants</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8554509">US8554509</a></td><td class="patent-data-table-td patent-date-value">Nov 24, 2004</td><td class="patent-data-table-td patent-date-value">Oct 8, 2013</td><td class="patent-data-table-td ">Riddell, Inc.</td><td class="patent-data-table-td ">System and method for measuring the linear and rotational acceleration of a body part</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8555282">US8555282</a></td><td class="patent-data-table-td patent-date-value">Jul 27, 2007</td><td class="patent-data-table-td patent-date-value">Oct 8, 2013</td><td class="patent-data-table-td ">Dp Technologies, Inc.</td><td class="patent-data-table-td ">Optimizing preemptive operating system with motion sensing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8568310">US8568310</a></td><td class="patent-data-table-td patent-date-value">May 21, 2012</td><td class="patent-data-table-td patent-date-value">Oct 29, 2013</td><td class="patent-data-table-td ">Dp Technologies, Inc.</td><td class="patent-data-table-td ">Sensor fusion for activity identification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8620353">US8620353</a></td><td class="patent-data-table-td patent-date-value">Jan 26, 2007</td><td class="patent-data-table-td patent-date-value">Dec 31, 2013</td><td class="patent-data-table-td ">Dp Technologies, Inc.</td><td class="patent-data-table-td ">Automatic sharing and publication of multimedia from a mobile device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8620585">US8620585</a></td><td class="patent-data-table-td patent-date-value">Apr 14, 2011</td><td class="patent-data-table-td patent-date-value">Dec 31, 2013</td><td class="patent-data-table-td ">Adidas Ag</td><td class="patent-data-table-td ">Systems and methods for presenting comparative athletic performance information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8654993">US8654993</a></td><td class="patent-data-table-td patent-date-value">Dec 7, 2005</td><td class="patent-data-table-td patent-date-value">Feb 18, 2014</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Portable audio device providing automated control of audio volume parameters for hearing protection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8676541">US8676541</a></td><td class="patent-data-table-td patent-date-value">Jun 12, 2009</td><td class="patent-data-table-td patent-date-value">Mar 18, 2014</td><td class="patent-data-table-td ">Nike, Inc.</td><td class="patent-data-table-td ">Footwear having sensor system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8688928">US8688928</a></td><td class="patent-data-table-td patent-date-value">Jul 20, 2012</td><td class="patent-data-table-td patent-date-value">Apr 1, 2014</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Media device with intelligent cache utilization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8694024">US8694024</a></td><td class="patent-data-table-td patent-date-value">Oct 21, 2010</td><td class="patent-data-table-td patent-date-value">Apr 8, 2014</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Media data exchange, transfer or delivery for portable electronic devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8696520">US8696520</a></td><td class="patent-data-table-td patent-date-value">Mar 8, 2013</td><td class="patent-data-table-td patent-date-value">Apr 15, 2014</td><td class="patent-data-table-td ">Adidas Ag</td><td class="patent-data-table-td ">Data transfer systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8712723">US8712723</a></td><td class="patent-data-table-td patent-date-value">Jan 31, 2011</td><td class="patent-data-table-td patent-date-value">Apr 29, 2014</td><td class="patent-data-table-td ">Dp Technologies, Inc.</td><td class="patent-data-table-td ">Human activity monitoring device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8739639">US8739639</a></td><td class="patent-data-table-td patent-date-value">Feb 22, 2012</td><td class="patent-data-table-td patent-date-value">Jun 3, 2014</td><td class="patent-data-table-td ">Nike, Inc.</td><td class="patent-data-table-td ">Footwear having sensor system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8749345">US8749345</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 24, 2004</td><td class="patent-data-table-td patent-date-value">Jun 10, 2014</td><td class="patent-data-table-td ">Milton Thompson</td><td class="patent-data-table-td ">Security authorization system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8784309">US8784309</a></td><td class="patent-data-table-td patent-date-value">Oct 23, 2013</td><td class="patent-data-table-td patent-date-value">Jul 22, 2014</td><td class="patent-data-table-td ">Dp Technologies, Inc.</td><td class="patent-data-table-td ">Sensor fusion for activity identification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20060273885">US20060273885</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 24, 2004</td><td class="patent-data-table-td patent-date-value">Dec 7, 2006</td><td class="patent-data-table-td ">Milton Thompson</td><td class="patent-data-table-td ">Security authorisation system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100062905">US20100062905</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 5, 2008</td><td class="patent-data-table-td patent-date-value">Mar 11, 2010</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Method for quickstart workout generation and calibration</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110087445">US20110087445</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 8, 2010</td><td class="patent-data-table-td patent-date-value">Apr 14, 2011</td><td class="patent-data-table-td ">Alluvial Joules, Inc.</td><td class="patent-data-table-td ">Intelligent Sport Shoe System</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130131972">US20130131972</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 18, 2011</td><td class="patent-data-table-td patent-date-value">May 23, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Computing-device localization based on inertial sensors</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2312420A1?cl=en">EP2312420A1</a></td><td class="patent-data-table-td patent-date-value">Sep 27, 2007</td><td class="patent-data-table-td patent-date-value">Apr 20, 2011</td><td class="patent-data-table-td ">Nike International Ltd</td><td class="patent-data-table-td ">Sensor device with persistent low power beacon</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2336845A1?cl=en">EP2336845A1</a></td><td class="patent-data-table-td patent-date-value">Sep 27, 2007</td><td class="patent-data-table-td patent-date-value">Jun 22, 2011</td><td class="patent-data-table-td ">Nike International Ltd</td><td class="patent-data-table-td ">Sensor device with persistent low power beacon</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2005103943A2?cl=en">WO2005103943A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 4, 2005</td><td class="patent-data-table-td patent-date-value">Nov 3, 2005</td><td class="patent-data-table-td ">Batterman Engineering Llc</td><td class="patent-data-table-td ">Method and system for determining occurrence of slips leading to falls</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2006056907A2?cl=en">WO2006056907A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 14, 2005</td><td class="patent-data-table-td patent-date-value">Jun 1, 2006</td><td class="patent-data-table-td ">Philips Intellectual Property</td><td class="patent-data-table-td ">Depression detection system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2007141526A1?cl=en">WO2007141526A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 7, 2007</td><td class="patent-data-table-td patent-date-value">Dec 13, 2007</td><td class="patent-data-table-td ">Pal Technologies Ltd</td><td class="patent-data-table-td ">An activity monitor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2008042720A1?cl=en">WO2008042720A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 27, 2007</td><td class="patent-data-table-td patent-date-value">Apr 10, 2008</td><td class="patent-data-table-td ">Terry Dishongh</td><td class="patent-data-table-td ">Method and apparatus for a self-powered rfid-readable pedometer</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc702/defs702.htm&usg=AFQjCNEwDgPZO8lzVvNBu0VAYuT88y7k4g#C702S160000">702/160</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc702/defs702.htm&usg=AFQjCNEwDgPZO8lzVvNBu0VAYuT88y7k4g#C702S176000">702/176</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc702/defs702.htm&usg=AFQjCNEwDgPZO8lzVvNBu0VAYuT88y7k4g#C702S142000">702/142</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc702/defs702.htm&usg=AFQjCNEwDgPZO8lzVvNBu0VAYuT88y7k4g#C702S141000">702/141</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G04G0021020000">G04G21/02</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=A61B0005103000">A61B5/103</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01C0022000000">G01C22/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=A61B5/1038">A61B5/1038</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G04G21/025">G04G21/025</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=A61B5/6831">A61B5/6831</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G01C22/006">G01C22/006</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=7f1hBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=A61B5/681">A61B5/681</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">A61B5/68B3B</span>, <span class="nested-value">A61B5/68B1H</span>, <span class="nested-value">G01C22/00P</span>, <span class="nested-value">A61B5/103P2</span>, <span class="nested-value">G04G21/02B</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Mar 8, 2011</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 38-42, 52-55, 63 AND 64 ARE CANCELLED. CLAIMS 1-37, 43-51, 56-62 AND 65-78 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 26, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 18, 2009</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20090617</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 2, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 4, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">NIKE, INC., OREGON</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CORRECTIVE ASSIGNMENT TO CORRECT THE ASSIGNOR S NAME PREVIOUSLY RECORDED ON REEL 018061, FRAME 0499;ASSIGNOR:FITSENSE TECHNOLOGY, INC.;REEL/FRAME:018350/0094</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060130</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CORRECTIVE ASSIGNMENT TO CORRECT THE ASSIGNOR S NAME PREVIOUSLY RECORDED ON REEL 018061, FRAME 0499.  ASSIGNOR HEREBY CONFIRMS THE ASSIGNMENT OF THE ENTIRE INTEREST.;ASSIGNOR:FITSENSE TECHNOLOGY, INC.;REEL/FRAME:018350/0094</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 4, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">NIKE, INC., OREGON</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:BLACKADAR, THOMAS P.;REEL/FRAME:018061/0499</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20060130</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 11, 2004</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 2, 2001</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">PERSONAL ELECTRONIC DEVICES, INC., MASSACHUSETTS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:DARLEY, JESSE;REEL/FRAME:011565/0561</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20010212</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">PERSONAL ELECTRONIC DEVICES, INC. 212 WORCESTER ST</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:DARLEY, JESSE /AR;REEL/FRAME:011565/0561</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1PB70VpXaBXpDKiM_JTce7sQk3Zw\u0026id=7f1hBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0HJKnKi_3T_bvG8PjGSPngVx6OLQ\u0026id=7f1hBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1LebO5Jc7FBcsdeEdtIJHSN9nUpw","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Monitoring_activity_of_a_user_in_locomot.pdf?id=7f1hBAABERAJ\u0026output=pdf\u0026sig=ACfU3U1YcINICiIfhdS8-nbzC-zKQliW0w"},"sample_url":"http://www.google.com/patents/reader?id=7f1hBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>