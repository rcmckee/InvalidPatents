<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6674464 - Imaging apparatus for performing selective processing of image data - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Imaging apparatus for performing selective processing of image data"><meta name="DC.contributor" content="Yoichi Mizutani" scheme="inventor"><meta name="DC.contributor" content="Masayuki Takezawa" scheme="inventor"><meta name="DC.contributor" content="Hideki Matsumoto" scheme="inventor"><meta name="DC.contributor" content="Ken Nakajima" scheme="inventor"><meta name="DC.contributor" content="Toshihisa Yamamoto" scheme="inventor"><meta name="DC.contributor" content="Sony Corporation" scheme="assignee"><meta name="DC.date" content="1999-7-15" scheme="dateSubmitted"><meta name="DC.description" content="An imaging apparatus for performing efficient signal processing depending on the operational mode. In the finder mode, a CCD interface 21 a decimates horizontal components of image data supplied from an image generating unit 10 to one-third and moreover processes the decimated image data with data conversion and resolution conversion to produce Y, Cb and Cr image data which are routed to and written in an image memory 32 over a memory controller 22. In the recording mode, the CCD interface 21 a causes the image data from the image generating unit 10 to be written in the image memory 32 via memory controller 22 after decimation and gamma correction etc. The camera DSP 21 c reads out the image data via memory controller 22 from the image memory 32 to effect data conversion for writing the resulting data via memory controller 22 in the image memory 32."><meta name="DC.date" content="2004-1-6" scheme="issued"><meta name="DC.relation" content="US:5751350" scheme="references"><meta name="DC.relation" content="US:6097430" scheme="references"><meta name="DC.relation" content="US:6144411" scheme="references"><meta name="DC.relation" content="US:6177956" scheme="references"><meta name="citation_patent_number" content="US:6674464"><meta name="citation_patent_application_number" content="US:09/354,476"><link rel="canonical" href="http://www.google.com/patents/US6674464"/><meta property="og:url" content="http://www.google.com/patents/US6674464"/><meta name="title" content="Patent US6674464 - Imaging apparatus for performing selective processing of image data"/><meta name="description" content="An imaging apparatus for performing efficient signal processing depending on the operational mode. In the finder mode, a CCD interface 21 a decimates horizontal components of image data supplied from an image generating unit 10 to one-third and moreover processes the decimated image data with data conversion and resolution conversion to produce Y, Cb and Cr image data which are routed to and written in an image memory 32 over a memory controller 22. In the recording mode, the CCD interface 21 a causes the image data from the image generating unit 10 to be written in the image memory 32 via memory controller 22 after decimation and gamma correction etc. The camera DSP 21 c reads out the image data via memory controller 22 from the image memory 32 to effect data conversion for writing the resulting data via memory controller 22 in the image memory 32."/><meta property="og:title" content="Patent US6674464 - Imaging apparatus for performing selective processing of image data"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("FS7uU_v5GsqusASa04H4Aw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("DEU"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("FS7uU_v5GsqusASa04H4Aw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("DEU"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6674464?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6674464"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=71ZkBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6674464&amp;usg=AFQjCNFzGpO6VKDH5buVYq3K1AfY1-pnwQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6674464.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6674464.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6674464" style="display:none"><span itemprop="description">An imaging apparatus for performing efficient signal processing depending on the operational mode. In the finder mode, a CCD interface 21 a decimates horizontal components of image data supplied from an image generating unit 10 to one-third and moreover processes the decimated image data with data conversion...</span><span itemprop="url">http://www.google.com/patents/US6674464?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6674464 - Imaging apparatus for performing selective processing of image data</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6674464 - Imaging apparatus for performing selective processing of image data" title="Patent US6674464 - Imaging apparatus for performing selective processing of image data"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6674464 B1</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/354,476</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Jan 6, 2004</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jul 15, 1999</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jul 17, 1998</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN1173553C">CN1173553C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN1243384A">CN1243384A</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN1327692C">CN1327692C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN1533156A">CN1533156A</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7358992">US7358992</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7839447">US7839447</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8248506">US8248506</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20040056968">US20040056968</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20080246859">US20080246859</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20110019059">US20110019059</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120274821">US20120274821</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09354476, </span><span class="patent-bibdata-value">354476, </span><span class="patent-bibdata-value">US 6674464 B1, </span><span class="patent-bibdata-value">US 6674464B1, </span><span class="patent-bibdata-value">US-B1-6674464, </span><span class="patent-bibdata-value">US6674464 B1, </span><span class="patent-bibdata-value">US6674464B1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Yoichi+Mizutani%22">Yoichi Mizutani</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Masayuki+Takezawa%22">Masayuki Takezawa</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Hideki+Matsumoto%22">Hideki Matsumoto</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Ken+Nakajima%22">Ken Nakajima</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Toshihisa+Yamamoto%22">Toshihisa Yamamoto</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Sony+Corporation%22">Sony Corporation</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6674464.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6674464.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6674464.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (4),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (19),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (11),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6674464&usg=AFQjCNEJJitba_nzlsYR5G1YytQYBpKB1w">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6674464&usg=AFQjCNF9SXPIG5LnOmbwfpNI_uIZG18YgQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6674464B1%26KC%3DB1%26FT%3DD&usg=AFQjCNEWrj9d3KOxe0MBD4IPlk0LrQYq9A">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55212226" lang="EN" load-source="patent-office">Imaging apparatus for performing selective processing of image data</invention-title></span><br><span class="patent-number">US 6674464 B1</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50605763" lang="EN" load-source="patent-office"> <div class="abstract">An imaging apparatus for performing efficient signal processing depending on the operational mode. In the finder mode, a CCD interface <b>21</b> <i>a </i>decimates horizontal components of image data supplied from an image generating unit <b>10 </b>to one-third and moreover processes the decimated image data with data conversion and resolution conversion to produce Y, Cb and Cr image data which are routed to and written in an image memory <b>32 </b>over a memory controller <b>22</b>. In the recording mode, the CCD interface <b>21</b> <i>a </i>causes the image data from the image generating unit <b>10 </b>to be written in the image memory <b>32 </b>via memory controller <b>22 </b>after decimation and gamma correction etc. The camera DSP <b>21</b> <i>c </i>reads out the image data via memory controller <b>22 </b>from the image memory <b>32 </b>to effect data conversion for writing the resulting data via memory controller <b>22 </b>in the image memory <b>32. </b> </div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(14)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6674464B1/US06674464-20040106-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6674464B1/US06674464-20040106-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(5)</span></span></div><div class="patent-text"><div mxw-id="PCLM8606532" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is: </claim-statement> <div class="claim"> <div num="1" id="US-6674464-B1-CLM-00001" class="claim">
      <div class="claim-text">1. An imaging apparatus comprising:</div>
      <div class="claim-text">an imaging section for generating image data based on image light from an object; </div>
      <div class="claim-text">a memory for storing the image data; </div>
      <div class="claim-text">a plurality of signal processing sections for performing different predetermined signal processing on the image data; </div>
      <div class="claim-text">a display for displaying an image corresponding to said image data; </div>
      <div class="claim-text">a storage section that uses a recording medium for recording the image data thereon; and </div>
      <div class="claim-text">a controller for performing control in a first and second operation modes, wherein </div>
      <div class="claim-text">in the first operation mode, (1) decimating the image data generated by the imaging section, (2) processing decimated image data in real-time signal processing sections, (3) storing the decimated and processed image data in the memory, (4) reading-out and displaying the image data stored in the memory, and (5) the real-time signal processing sections being included in the plurality of signal processing sections and performing real-time signal processing; and </div>
      <div class="claim-text">in the second mode, (a) storing the image data generated by the imaging section in the memory, (b) reading-out the image data stored in the memory, (c) providing read-out image data to the signal processing sections for signal processing, and (d) storing processed image data in the recording medium, (e) the image data stored in the memory being not decimated. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6674464-B1-CLM-00002" class="claim">
      <div class="claim-text">2. The imaging apparatus according to <claim-ref idref="US-6674464-B1-CLM-00001">claim 1</claim-ref> wherein one of the plural signal processing sections comprises resolution conversion means for converting the resolution of the image data;</div>
      <div class="claim-text">said controller performing control in said second operation mode for reading out the image data from said memory to send the read-out image data to said resolution conversion means and for recording the image data converted in resolution in said resolution conversion means on said recording medium. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6674464-B1-CLM-00003" class="claim">
      <div class="claim-text">3. The imaging apparatus according to <claim-ref idref="US-6674464-B1-CLM-00001">claim 1</claim-ref> wherein one of the plural signal processing sections comprises compression means for compressing the image data;</div>
      <div class="claim-text">said controller performing control in said second operation mode for reading out the image data from said memory to route the read-out image data to said compression means and for recording the image data compressed by said compression means on said recording medium. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6674464-B1-CLM-00004" class="claim">
      <div class="claim-text">4. The imaging apparatus according to <claim-ref idref="US-6674464-B1-CLM-00001">claim 1</claim-ref>, wherein a resolution of the decimated and processed image data is down-converted before the image data is stored in the memory.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6674464-B1-CLM-00005" class="claim">
      <div class="claim-text">5. The imaging apparatus according to <claim-ref idref="US-6674464-B1-CLM-00004">claim 4</claim-ref>, wherein a resolution of the image data stored in the memory is up-converted before the image data is displayed in the display.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES54114250" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>This invention relates to an imaging apparatus for performing signal processing depending on the operational modes.</p>
    <p>2. Description of the Related Art</p>
    <p>A digital still camera retrieves image data obtained by a CCD image sensor into a DRAM or a flash memory and subsequently transfers the image data to a so-called personal computer or the like. A major proportion of this type of the digital still camera has hitherto been of the type coping with the video graphics array (VGA) system.</p>
    <p>Referring for example to FIG. 1, this digital still camera <b>200</b> includes a CCD image sensor <b>201</b> for generating image signals, an input processing/image processing circuit <b>202</b>, a memory controller <b>203</b> for reading and writing image data, an output processing circuit <b>204</b> for conversion to an output image of a pre-set system, a finder <b>205</b> for displaying the state of an object at the time of image shooting, a recording unit <b>207</b> for recording compressed image data over a CPU bus <b>206</b> and a compression/expansion circuit <b>208</b> for compressing/expanding image data. The digital still camera <b>200</b> also includes a memory <b>209</b>, formed by, for example, a DRAM, and a CPU <b>210</b> for controlling the overall device.</p>
    <p>Before starting the image shooting of an object, the user has to confirm an object image displayed on the finder <b>205</b>. This state is termed a finder mode. At this time, the CCD image sensor <b>201</b> sends image signals obtained on photoelectric conversion to the input processing/image processing circuit <b>202</b>. The input processing/image processing circuit <b>202</b> performs the correlated dual sampling processing on the image signals to digitize the image signals. The input processing/image processing circuit <b>202</b> then performs pre-set signal processing, such as gamma correction, knee processing or camera processing and routes the processed image signals to the memory controller <b>203</b>. The memory controller <b>203</b> then is responsive to the control by the CPU <b>210</b> to send the image data from the input processing/image processing circuit <b>202</b> to the output processing circuit <b>204</b>. The output processing circuit <b>204</b> encodes image data in accordance with, for example, the National Television System Committee (NTSC) system, and analogizes the encoded image data to route the resulting analog data to the finder <b>205</b>. This allows the object as an object of image shooting to be indicated on the finder <b>205</b>.</p>
    <p>On the other hand, if the user pushes a shutter button, not shown, to shift to the recording mode, the memory controller <b>203</b> causes the image data furnished from the input processing/image processing circuit <b>202</b> to be written in the memory <b>209</b>. The CPU <b>210</b> causes the image data to be read out from the memory <b>209</b> and compresses the image data from the recording unit <b>207</b>in the compression/expansion circuit <b>208</b> with compression in accordance with, for example, the Joint photographic Experts Group (JPEG) system to record the compressed image data in the recording unit <b>207</b>.</p>
    <p>If the user performs pre-set processing to shift to the reproducing mode, the CPU <b>210</b> causes image data to be read out from the recording unit <b>207</b> to cause the image data to be expanded in JPEG system in the compression/expansion circuit <b>208</b> to route the resulting data via memory controller <b>203</b> and output processing circuit <b>204</b> to the finder <b>205</b>. This causes the as-shot image to be displayed on the finder <b>205</b>.</p>
    <p>In keeping up with recent outstanding technical progress in the CCD image sensor, the resolution of image data is nearly surpassing 1,000,000 pixels. On the other hand, it may be feared that the digital still camera of the above-described structure cannot sufficiently cope with the image data exceeding 1,000,000 pixels.</p>
    <p>If, for example, the CCD image sensor <b>201</b> outputs image signals of high resolution in the finder mode, the input processing/image processing circuit <b>202</b>, memory controller <b>203</b> or the output processing circuit <b>204</b> cannot process image data in real-time, such that an image of the object is displayed on the finder <b>205</b> in a frame-skipping fashion. This incurs an inconvenience in shooting an image of object even if the object makes the slightest movement.</p>
    <p>In the recording mode, since in which only multi-pixel image data is recorded in the recording unit <b>207</b>, it is unnecessary to perform the processing in e.g., the input processing/image processing circuit <b>202</b>.</p>
    <p>That is, in the digital still camera <b>200</b>, since the pre-set signal processing is performed on e.g., the input processing/image processing circuit <b>202</b> without regard to the operational mode, the signal processing has not necessarily been efficient insofar as the entire apparatus is concerned.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>It is therefore an object of the present invention to provide an imaging apparatus that is able to perform efficient signal processing depending on the operational mode.</p>
    <p>In another aspect, the present invention provides a controlling method for a signal processing apparatus adapted for transmitting/receiving image data between a plurality of signal processing means and storage means for storing image data, the signal processing means being adapted for processing the image data in a pre-set fashion and for outputting to the control means a request signal for demanding furnishment of the image data for signal processing or demanding the outputting of the processed image data. The controlling method includes selecting, on furnishment of the request signal from the plural signal processing means, one or more of the signal processing means which has outputted the request signal, and furnishing the image data read out from the storage means to the selected signal processing means or writing the image data outputted by the selected signal processing means in the storage means.</p>
    <p>In still another aspect, the present invention provides an imaging apparatus including imaging means, storage means for transiently storing image data from the imaging means, control means for controlling the writing/readout of the image data for the storage means, a plurality of signal processing means for processing the image data in a pre-set fashion and for outputting to the control means a request signal for demanding furnishment of the image data for signal processing or demanding the outputting of the processed image data, and outputting means for outputting image data processed by the signal processing means. The control means manages control on furnishment of the request signal to select one or more of the signal processing means which has outputted the request signal to furnish the image data read out from the storage means to the selected signal processing means or to write the image data outputted by the selected signal processing means in the storage means.</p>
    <p>In yet another aspect, the present invention provides a recording/reproducing apparatus including imaging means, input processing means for performing pre-set input processing on image data from the imaging means, display processing means for displaying image data on display means, first storage means for transiently storing the image data from the imaging means, control means for controlling the writing/readout of the image data for the first storage means, resolution converting means for converting the resolution of image data, compression/expansion means for compressing/expanding the image data and recording/reproducing controlling means for causing the compressed image data to be recorded on second storage means and for causing the image data recorded on the second storage means to be reproduced. The control means selects one or more signal processing means from the input processing means, display processing means, resolution converting means and the compression/expansion means. The control means causes the image data read out from the first storage means to be sent to the selected signal processing means or causes the image data outputted by the selected signal processing means to be written in the first storage means.</p>
    <p>In the signal processing apparatus and the control method therefor, according to the present invention, if a request signal is sent from each signal processing means, the signal processing means which has outputted the request signal having the utmost priority in the priority order is selected. Control is then performed for supplying the image data read out from the storage means over the image data bus to the selected signal processing means, or writing the processed image data of the selected signal processing means over the image data bus to the storage means, so that efficiently signal processing will be executed in the respective signal processing means.</p>
    <p>The present invention provides a An imaging apparatus comprising:</p>
    <p>imaging means for generating image data based on the imaging light from an object;</p>
    <p>memory means for storing the image data;</p>
    <p>a plurality of signal processing means for performing pre-set signal processing on the image data;</p>
    <p>display means for displaying an image corresponding to said image data;</p>
    <p>a recording medium for recording the image data thereon; and</p>
    <p>control means for performing control in a first operational mode for processing the image data from said imaging means in a pre-set fashion by the signal processing means of said plural signal processing means required to perform real-time processing to write the image data in said memory means and for reading out the processed image data from said memory means to supply the read-out image data to said display means, said control means performing control in a second operational mode for writing the image data from said imaging means in said memory means and subsequently reading out the written image data to route the read-out image data to said plural signal processing means to record the image data processed by said plural signal processing means on said recording medium.</p>
    <p>In the first mode of the imaging apparatus, the image data from the imaging means are decimated and processed in a pre-set fashion by signal processing means required to perform real-time processing. In the second mode, multi-pixel image data are first written in the memory means. The multi-pixel image data are then read out therefrom and routed to and processed by the plural signal processing means.</p>
    <p>More specifically, the signal processing means of the plural signal processing means which is required to perform real-time processing is caused to perform pre-set signal processing on the image data from the imaging means, in the first operational mode of the imaging apparatus, the resulting image data being then written in the memory means and the processed image data being then read out from the memory means and routed to the display means. In the second operational mode, the image data from the imaging means is written in the memory means and read out therefrom so as to be routed to the respective signal processing means for processing, with the processed image data being then recorded on the recording medium. This realizes signal processing most efficient depending on the operational mode.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is a block diagram for illustrating the structure of a conventional digital still camera.</p>
    <p>FIG. 2 is a block diagram showing a schematic structure of a digital still camera embodying the present invention.</p>
    <p>FIG. 3 is a block diagram showing the schematic structure of the digital still camera shown in FIG. <b>2</b>.</p>
    <p>FIG. 4 is a block diagram for illustrating flow of image data in a signal processing unit of the digital still camera shown in FIG. <b>2</b>.</p>
    <p>FIG. 5 is a block diagram for illustrating the structure of a simplified resolution conversion circuit in an input processing circuit of the signal processing unit.</p>
    <p>FIG. 6 is a block diagram showing the structure of the resolution conversion circuit of the signal processing unit.</p>
    <p>FIG. 7 is a block diagram showing a specified structure of a horizontal direction buffer, a horizontal direction conversion processing circuit, a vertical direction buffer and a vertical direction conversion processing circuit of the resolution conversion circuit.</p>
    <p>FIG. 8 is a block diagram showing an alternative structure of the resolution conversion circuit.</p>
    <p>FIG. 9 is a block diagram showing the structure of the vertical direction buffer of the resolution conversion circuit.</p>
    <p>FIG. 10 illustrates a technique for reading out image data from the image memory by the memory controller.</p>
    <p>FIG. 11 illustrates the coordinate position of pixels making up an image.</p>
    <p>FIG. 12 illustrates another technique for reading out image data from the image memory by the memory controller.</p>
    <p>FIG. 13 is a block diagram showing the structure of the horizontal direction buffer of the resolution conversion c constituted by a line buffer.</p>
    <p>FIG. 14 illustrates the technique when the memory controller reads out image data from the image memory.</p>
    <p>FIG. 15 is a block diagram showing the structure of the simplified resolution conversion circuit in the NTSC/PAL encoder of the signal processing unit.</p>
    <p>FIGS. 16A to <b>16</b>F show a timing chart for illustrating the contents of the signal processing in the respective circuits in the finder mode.</p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>Referring to the drawings, preferred embodiments of the present invention will be explained in detail.</p>
    <p>The present invention is applied to digital still camera <b>1</b>, configured as shown for example in FIG. <b>2</b>.</p>
    <p>The digital still camera <b>1</b> includes an image generating unit <b>10</b> for generating image signals, an input signal processor <b>20</b> for processing image data in a pre-set fashion, an image memory <b>32</b>, comprised of an SDRAM, and a controller <b>40</b> for controlling the input signal processor <b>20</b>.</p>
    <p>The image generating unit <b>10</b> includes a solid-state imaging device for generating image signals, such as a CCD image sensor <b>11</b>, a sample holding-analog/digital circuit (S/H-A/D circuit <b>12</b>) for sample-holding and digitizing the image signals to output image data, and a timing generator <b>13</b> for generating timing signals. This timing generator <b>13</b> generates horizontal synchronization signals and vertical synchronization signals for controlling respective circuits of the image generating unit <b>10</b> based on synchronization signals supplied from the signal processor input .</p>
    <p>The CCD image sensor <b>11</b> generates image data corresponding to XGA (extended graphic array: 1024768) pixel data made up of, for example, 800,000 pixels. The CCD image sensor <b>11</b> is driven based on the synchronization signals from the timing generator <b>13</b> to output image signals at a rate of 30 frames per second. Meanwhile, the CCD image sensor <b>11</b> has the function of thinning out image signals and is able to thin out vertical components of the image signals to , , , . . . to output the resulting thinned-out signals.</p>
    <p>The S/H-A/D circuit <b>12</b> is also adapted to perform sample-holding and A/D conversion at a pre-set sampling interval based on the synchronization signals from the timing generator <b>13</b> to send the resulting image data to the signal processor <b>20</b>.</p>
    <p>The signal processor <b>20</b> includes a sole LSI (large scale integrated circuit). The signal processor <b>20</b> includes an input signal processor <b>21</b> for input processing and camera processing on image data from the image generating unit <b>10</b>, a memory controller <b>22</b> for controlling the readout/write of image data for the image memory <b>32</b>, an NTSC/PAL (phase alternation by line) encoder <b>23</b>, a D/A converter <b>24</b> for analogizing image data and outputting the resulting analog signals to outside, and a sync generator <b>26</b> for generating synchronization signals and supplying the resulting synchronization signals to the timing generator <b>13</b>.</p>
    <p>The signal processor <b>20</b> also includes a memory interface <b>27</b>, as an interface for the image memory <b>32</b>, a resolution conversion circuit <b>28</b> for converting the resolution of the image data, a JPEG (Joint Photographic Experts Group) encoder/decoder <b>29</b>, for compressing/expanding image data, a JPEG interface <b>30</b>, as an interface of the JPEG encoder/decoder <b>29</b>, and a host interface <b>31</b>, as an interface for having data transmission/reception with the CPU of the controller <b>40</b>.</p>
    <p>The input signal processor <b>21</b> processes the image data from the S/H-A/D circuit <b>12</b> with digital clamp, shading correction, aperture correction, gamma correction or color processing and routes the resulting processed signals to the memory controller <b>22</b>. The input signal processor <b>21</b> has the function of processing input data to convert the input data into Y, Cb and Cr. If the resolution of the image data is larger than that of the VGA (Video Graphics Array), the input signal processor <b>21</b> is able to perform the processing of lowering the resolution. The input signal processor <b>21</b> also performs the auto-focussing and auto-iris detection to route the data to the controller <b>40</b> to effect automatic adjustment of the focussing mechanism and the iris mechanism. The input signal processor <b>21</b> also detects the signal level of the three prime colors making up the image data to adjust automatic white balance.</p>
    <p>The memory controller <b>22</b> also performs control to cause image data supplied from the input signal processor <b>21</b> or other circuitry to be written in the image memory <b>32</b> via a memory interface <b>27</b> and to read out image data of the image memory <b>32</b> via the memory interface <b>27</b>. At this time, the memory controller <b>22</b> detects whether or not there is any defective pixel in the CCD image sensor <b>11</b> based on the image data stored in the image memory <b>32</b>.</p>
    <p>The memory controller <b>22</b> routes the image data read out from the image memory <b>32</b> to, for example, the NTSC/PAL encoder <b>23</b>. When fed with the image data from the memory controller <b>22</b>, the NTSC/PAL encoder <b>23</b> encodes the image data in accordance with the NTSC system or the PAL system to send the encoded data to the D/A converter <b>24</b>. The D/A converter <b>24</b> analogizes the image data to output the resulting analog signals via output terminal <b>25</b>.</p>
    <p>The memory controller <b>22</b> routes the image data, read out from the memory controller <b>22</b>, to the resolution conversion circuit <b>28</b> to cause the image data to be converted in resolution, while causing the image data outputted by the resolution conversion circuit <b>28</b> to be written in the image memory <b>32</b>.</p>
    <p>The memory controller <b>22</b> routes the image data via the JPEG interface <b>30</b> to the JPEG encoder/decoder <b>29</b> to effect compression of the still image, while causing the image data expanded by the JPEG encoder/decoder <b>29</b> to be written in the image memory <b>32</b>.</p>
    <p>The image memory <b>32</b> not only stores the image data as described above but also stores OSD data (on-screen-display data) as the so-called character generator data. The OSD data is made up of bit map data. The controller <b>22</b> controls the readout/write of the OSD data. The image data and the OSD data are synthesized by the NTSC/PAL encoder <b>23</b>.</p>
    <p>The controller <b>40</b> includes a CPU (central processing unit) <b>41</b> for controlling the respective circuits of the signal processor <b>20</b>, a DRAM (dynamic random access memory) <b>42</b>, a ROM (read-only memory) <b>43</b>, having the control program for the CPU <b>41</b> stored therein, a flash memory interface <b>44</b>, as an interface for exchanging image data with a storage device <b>51</b>, such as a flash memory, and an IrDA interface <b>45</b>, as an interface of the communication circuit <b>52</b> constituted such as by IrLED.</p>
    <p>For example, the CPU <b>41</b> causes image data compressed by the JPEG encoder/decoder <b>29</b> to be written via a flash memory/interface <b>44</b> in a storage device <b>51</b>, made up of a flash memory, while causing image data to be read out from the storage device <b>51</b> to route the image data read out from the JPEG encoder/decoder <b>29</b>. The CPU <b>41</b> also causes the image data read out from the storage device <b>51</b> to be outputted via the IrDA interface <b>45</b> and the communication circuit <b>52</b> as infrared light to outside.</p>
    <p>The schematic structure of the digital still camera <b>1</b> is shown in FIG. <b>3</b>.</p>
    <p>The input signal processor <b>21</b> routes the image data from the CCD image sensor <b>11</b> via an image data bus <b>33</b> to the image memory <b>32</b>. The NTSC/PAL encoder <b>23</b> encodes the image data from the image memory <b>32</b> in a pre-set fashion to send the resulting encoded data to the finder <b>36</b>. This causes an image of an object to be displayed on the finder <b>36</b> which is adapted to display the image in association with the image data up to the VGA format.</p>
    <p>The memory controller <b>22</b> performs data transfer between the image memory <b>32</b> and the signal processing circuits connecting to the image data bus <b>33</b>. The resolution conversion circuit <b>28</b> performs resolution conversion of the image data from the image memory <b>32</b> to route the results to the image memory <b>32</b>. The JPEG encoder/decoder <b>29</b> compresses the image data from the image memory <b>32</b> in accordance with the JPEG system to route the compressed image data via CPU bus <b>34</b> to the CPU <b>41</b>, which then causes the compressed image data to be written in the storage device <b>51</b>. The CPU <b>41</b> is also able to output the compressed image data via the CPU bus <b>34</b> and the communication circuit <b>52</b> to outside.</p>
    <p>Thus, is FIG. 3, the respective circuits of the signal processor <b>20</b> are interconnected over the image data bus <b>33</b>. The image data bus <b>33</b> is a virtual bus and indicates that there is placed a limit to the transfer band for image data exchanged between the respective circuits.</p>
    <p>In the signal processor <b>20</b>, the respective circuits, such as NTSC/PAL encoder <b>23</b> or the resolution conversion circuit <b>28</b>, send to the memory controller <b>22</b> a request signal indicating that image data are demanded. These circuits also transmit a request signal to the memory controller <b>22</b> when outputting the image data after the end of the processing of the image data.</p>
    <p>On reception of the request signals from the respective circuits, the memory controller <b>22</b> selects those circuits having the high priority sequence, and transmits an acknowledge signal to the selected circuit. The acknowledge signal indicates that image data can be routed to a circuit receiving the signal or that image data outputted by a circuit which has received the acknowledge signal is ready to be received. The memory controller <b>22</b> reads out image data from the image memory <b>32</b> to route the read-out image data via image data bus <b>33</b> to the circuit corresponding to the destination of the acknowledge signal. The memory controller <b>22</b> receives the image data outputted by the circuit which has sent the acknowledge signal to write the image data in the image memory <b>32</b>.</p>
    <p>On reception of the request signals from plural circuits, the memory controller <b>22</b> is able to select preferentially the circuit which has to perform the processing in real-time. For example, if an image of an object is to be displayed on the finder <b>36</b>, the memory controller <b>22</b> preferentially selects the input signal processor <b>21</b> and the NTSC/PAL encoder <b>23</b>. It is also possible for the memory controller <b>22</b> to decipher the bus occupation ratio of the image data on the image data bus <b>33</b> to determine the priority sequence of the respective circuits depending on the occupation ratio.</p>
    <p>If image data can be routed to the respective circuits within the transfer band limitation of the image data bus <b>33</b>, it is possible for the memory controller <b>22</b> to perform control to send the acknowledge signal to the respective circuits time-divisionally to permit the respective circuits to perform pre-set processing. This enables the memory controller <b>22</b> to have access in real-time to data in the respective circuits to cause the image data from the respective circuits to be written in the image memory <b>32</b> or to cause the image data in the image memory <b>32</b> to be read out and sent to the respective circuits.</p>
    <p>If, when the memory controller <b>22</b> has access to external circuitry, not shown, over the image data bus <b>33</b>, the external circuitry can send the above-mentioned request signal or receive the transmitted acknowledge signal, the memory controller <b>22</b> can have access simultaneously and time-divisionally to the respective circuits within the signal processor <b>20</b> within the transfer band limitation range of the image data bus <b>33</b>. That is, if within the range of the band of the image data bus <b>33</b>, the memory controller <b>22</b> can have simultaneous access to the circuits in the signal processor <b>20</b> or to the external circuits within the signal processor <b>20</b> time-divisionally without regard to the number of the circuits within the signal processor <b>20</b> or the external circuit.</p>
    <p>As mentioned above, the memory controller <b>22</b> performs arbitration of the image data bus <b>33</b>, write/readout control of image data between the image memory <b>32</b> and the respective circuits and data transfer to the CPU bus <b>34</b>.</p>
    <p>The specified flow of image data in the signal processor <b>20</b> is explained with reference to FIG. <b>4</b>.</p>
    <p>The input signal processor <b>21</b> includes a CCD interface <b>21</b> <i>a </i>for performing pre-set signal processing on the image data from the image generating unit <b>10</b>, a detection circuit <b>21</b> b for processing the CCD interface <b>21</b> <i>a</i>, and a camera digital signal processor <b>21</b> <i>c </i>(camera DSP <b>21</b> <i>c</i>) for doing conversion processing of the image data.</p>
    <p>The CCD interface <b>21</b> <i>a </i>performs the processing, such as the digital clamp, white balance adjustment or gamma correction, on the image data made up of R, G and B from the S/H-A/D circuit <b>12</b> shown information FIG. 2, or decimates the components in the horizontal direction of image data in case of necessity. After such processing, the CCD interface <b>21</b> <i>a </i>routes image data to the camera DSP <b>21</b> <i>c </i>or to the memory controller <b>22</b> via the image data bus <b>33</b>.</p>
    <p>From the image data of the CCD interface <b>21</b> <i>a</i>, the detection circuit <b>21</b> <i>b </i>performs detection for auto-focussing, auto-iris or white balance adjustment.</p>
    <p>The camera DSP <b>21</b> <i>c </i>converts the image data of R, G and B from the CCD interface <b>21</b> <i>a </i>into image data made up of luminance signal Y and chrominance signals Cb, Cr. The camera DSP <b>21</b> <i>c </i>also has a simplified resolution conversion circuit <b>21</b> which not only performs the above processing but also converts the resolution of the image data in a simplified fashion.</p>
    <p>The simplified resolution conversion circuit <b>21</b> <i>d </i>operates for converting the resolution of the image data to lower values if the resolution of the image data generated by the CCD image sensor <b>11</b> is larger than, for example, the VGA format.</p>
    <p>Specifically, the simplified resolution conversion circuit <b>21</b> <i>d </i>includes a B-Y/R-Y separation circuit <b>61</b>, for separating chrominance signals, a horizontal direction linear interpolation circuit <b>62</b> for interpolation in the horizontal direction, a B-Y/R-Y synthesis circuit <b>63</b> for synthesizing the chrominance signals, a 1H delay circuit <b>64</b> for delaying the respective signals by a horizontal scanning period (1H period), and a vertical direction linear interpolation circuit <b>65</b>.</p>
    <p>The B-Y/R-Y separation circuit <b>61</b> separates the chrominance signals B-Y and R-Y, as chroma signals Cb, Cr, from the image data from the camera DSP <b>21</b> <i>c </i>to route the separated chroma signals to the horizontal direction linear interpolation circuit <b>62</b>. The horizontal direction linear interpolation circuit <b>62</b> interpolates the luminance signals Y and the chrominance signals B-Y, R-Y in the horizontal direction to lower the luminance in the horizontal direction to route the interpolated luminance signals Y and the chrominance signals B-Y, R-Y to the B-Y/R-Y synthesis circuit <b>63</b>.</p>
    <p>The B-Y/R-Y synthesis circuit <b>63</b> synthesizes the chrominance signals B-Y, R-Y, to route the luminance signals Y from the horizontal direction linear interpolation circuit <b>62</b> and the synthesized chrominance signals B-Y, R-Y to the 1H delay circuit <b>64</b> and to the vertical direction linear interpolation circuit <b>65</b>. The 1H delay circuit <b>64</b> delays the luminance signals Y and the chrominance signals by 1H to route the delayed signals to the vertical direction linear interpolation circuit <b>65</b>. The vertical direction linear interpolation circuit <b>65</b> performs linear interpolation processing in the vertical direction, based on the luminance signals Y and the chrominance B-Y, R-Y from the B-Y/R-Y synthesis circuit <b>63</b> and the 1H delay circuit <b>64</b>, to output image data made up of luminance signals Y and chrominance signals (B-Y), (R-Y) lowered in resolution in both the horizontal and vertical directions.</p>
    <p>The resolution conversion circuit <b>28</b> performs resolution conversion processing of converting [pq] image data into [mn] image data. The resolution conversion circuit <b>28</b> performs processing for suppressing the resolution to a pre-set value if the image data produced in the CCD image sensor <b>11</b> are of high resolution. It is however possible to process the image data of low resolution into data of high resolution.</p>
    <p>Referring to FIG. 6, the resolution conversion circuit <b>28</b> includes an input buffer <b>71</b> for storing image data, inputted from the image data bus <b>33</b>, a horizontal direction buffer <b>72</b>, for buffering the image data from the an input buffer <b>71</b> in the horizontal direction, a horizontal direction transform processing circuit <b>73</b> for converting the resolution of the image data from the horizontal direction buffer <b>72</b> in the horizontal direction, a vertical direction buffer <b>74</b> for buffering the image data from the horizontal direction transform processing circuit <b>73</b> in the vertical direction, a vertical direction transform processing circuit <b>75</b> for converting the resolution of the image data in the vertical direction, and an output buffer <b>76</b> for buffering at the time of outputting.</p>
    <p>When ready for converting the resolution of the image data, the resolution conversion circuit <b>28</b> outputs a read request signal requesting the memory controller <b>22</b> to read out image data from the image memory <b>32</b>, while outputting a write request signal requesting the memory controller <b>22</b> to write the image data in the image memory <b>32</b> after the conversion processing of the image data. The resolution conversion circuit <b>28</b> also receives an acknowledge signal indicating that the memory controller <b>22</b> has responded to the request signal.</p>
    <p>Referring to FIG. 7, the horizontal direction buffer <b>72</b> is made up of a first delay circuit <b>81</b>, a second delay circuit <b>82</b> and a third delay circuit <b>83</b> each for producing the delay of one pixel. Thus, the first delay circuit <b>81</b> outputs image data delayed by one pixel, while the second and third delay circuits <b>81</b>, <b>82</b> output image data delayed by two pixels and image data delayed by three pixels, respectively.</p>
    <p>Referring to FIG. 7, the horizontal direction transform processing circuit <b>73</b> includes first to fourth multipliers <b>84</b>, <b>85</b>, <b>86</b>, <b>87</b>, and first to third adders <b>88</b>, <b>89</b>, <b>90</b>. A circuit for normalizing data is incidentally annexed at back of the adder <b>90</b>.</p>
    <p>The first multiplier <b>84</b> multiplies the image data supplied from the an input buffer <b>71</b> with a pre-set coefficient to route the resulting data to the adder <b>88</b>. The second multiplier <b>85</b> multiplies the image data supplied from the first delay circuit <b>81</b> with a pre-set coefficient to route the resulting data to the adder <b>88</b>. The third multiplier <b>86</b> multiplies the image data supplied from the second delay circuit <b>82</b> with a pre-set coefficient to route the resulting data to the adder <b>89</b>. The fourth multiplier <b>87</b> multiplies the image data supplied from the third delay circuit <b>83</b> with a pre-set coefficient to route the resulting data to the adder <b>90</b>. The first adder <b>88</b> synthesizes the image data to send the resulting data to the second adder <b>89</b>. The second adder <b>89</b> synthesizes the image data to send the resulting data to the third adder <b>90</b>. The third adder <b>90</b> synthesizes the respective image data to send the resulting data as image data converted in resolution in the horizontal direction to the vertical direction buffer <b>74</b>.</p>
    <p>Thus, the horizontal direction transform processing circuit <b>73</b> weights plural image data each having one pixel delay in a pre-set fashion with pre-set weights and synthesizes the weighted image data to interpolate or decimate the pixels in the horizontal direction to convert the resolution in the horizontal direction.</p>
    <p>The vertical direction buffer <b>74</b> is constituted by a serial connection of first to third buffers <b>91</b>, <b>92</b>, <b>93</b>, each adapted to produce a one-line delay. Thus, the first bufer memory <b>91</b> outputs image data delayed by one line, while the second and third buffer memories <b>92</b>, <b>93</b> output the image data delayed by two and three lines, respectively.</p>
    <p>Referring to FIG. 7, the vertical direction transform processing circuit <b>75</b> includes fifth to eighth multipliers <b>94</b> to <b>97</b> and fourth to sixth adders <b>98</b> to <b>100</b>. The vertical direction transform processing circuit <b>75</b> occasionally includes a circuit for normalizing data on the downstream side of the adder <b>90</b>.</p>
    <p>The fifth multiplier <b>94</b> multiplies the image data supplied from the horizontal direction conversion circuit <b>73</b> with a pre-set coefficient to route the resulting data to the fourth adder <b>98</b>. The sixth multiplier <b>95</b> multiplies the image data supplied from the first line memory <b>91</b> with a pre-set coefficient to route the resulting data to the fourth adder <b>98</b>. The seventh multiplier <b>96</b> multiplies the image data supplied from the second line memory <b>92</b> with a pre-set coefficient to route the resulting data to the fifth adder <b>99</b>. The eighth multiplier <b>97</b> multiplies the image data supplied from the third line memory <b>93</b> with a pre-set coefficient to route the resulting data to the sixth adder <b>100</b>. The fourth adder <b>98</b> synthesizes the image data to send the resulting data to the fifth adder <b>99</b>. The fifth adder <b>99</b> synthesizes the image data to send the resulting data to the sixth adder <b>100</b>. The sixth adder <b>100</b> synthesizes the respective image data to output the resulting data as image data converted in resolution in the horizontal direction.</p>
    <p>Thus, the vertical direction transform processing circuit <b>75</b> weights plural image data each having one line delay in a pre-set fashion with pre-set weights and synthesizes the weighted image data to interpolate or decimate the pixels in the horizontal direction to convert the resolution in the vertical direction.</p>
    <p>In FIG. 7, the resolution conversion circuit <b>28</b> first performs resolution conversion in the horizontal direction followed by resolution conversion in the vertical direction. It is however possible for the resolution conversion circuit <b>28</b> to perform resolution conversion in the vertical direction followed by conversion in the horizontal direction. That is, the resolution conversion circuit <b>28</b> may be configured to supply the image data from the input buffer <b>71</b> to the vertical direction buffer <b>74</b> and to effect the processing in the vertical direction buffer <b>74</b>, vertical direction transform processing circuit <b>75</b>, horizontal direction buffer <b>72</b> and in the horizontal direction transform processing circuit <b>73</b>, in this order.</p>
    <p>In the above-described embodiment, the first to third buffer memories <b>91</b> to <b>93</b> in the vertical direction buffer <b>74</b> are configured to store one-line (1H) image data. Alternatively, the first to third buffer memories <b>91</b> to <b>93</b> may be configured for storing image data lesser than one line, as shown in FIG. <b>9</b>. It is then necessary for the memory controller <b>22</b> to read out the image data stored in the image memory <b>32</b> every N pixels, as shown in FIG. <b>10</b>.</p>
    <p>Specifically, the memory controller <b>22</b> reads out pixel data corresponding to a viewing screen stored in the image memory <b>32</b> every N pixels on the line basis in the vertical direction. Referring to FIG. 11, each viewing screen is made up of pq pixels, with the coordinate of the upper left pixel being (<b>1</b>,<b>1</b>), that of the upper right pixel being (p,<b>1</b>), that of the lower left pixel being (<b>1</b>,q) and with the lower right pixel being (p,q).</p>
    <p>Referring to FIG. 12, the memory controller <b>22</b> causes the image data of N pixels to be read out on the line basis in the horizontal direction in the sequence of the rows <b>1</b>, <b>2</b>, . . . , q. This causes the memory controller <b>22</b> to read out image data corresponding to N pixels from the left end, or Nq pixels, that is pixel data in an area defined by (<b>1</b>,<b>1</b>), (<b>1</b>,q), (N,q) and (N,<b>1</b>). This image data is referred to below as image data set (<b>1</b>).</p>
    <p>The memory controller <b>22</b> then reads out image data in a range defined by (N1, <b>1</b>) (N1, q), (2N2, q), (2N2, <b>1</b>), referred to below as the image data set (<b>2</b>). If the memory controller <b>22</b> reads out the image data set (<b>1</b>) and the image data set (<b>2</b>), it is tantamount to reading out the image data of the (N1)st column and the Nth column twice.</p>
    <p>The reason is that, since the vertical direction transform processing circuit <b>75</b> performs interpolation beginning from the surrounding pixel, the pixels stored in the beginning end and the trailing end of the first to third buffer memories <b>91</b> to <b>93</b> are not the object of processing. For example, if the image data set (<b>1</b>) is read out, the pixel (N, <b>1</b>) is not the object of the interpolation processing in the vertical direction. However, this pixel (N, <b>1</b>) is read out when the pixel data set (<b>2</b>) is read out, and becomes the object of interpolation processing.</p>
    <p>In similar manner, the memory controller <b>22</b> reads out image data of N pixels in the horizontal direction every line so that image data of the last two columns of the directly previous image data set will be included. This routes the image data set to the resolution conversion circuit <b>28</b>.</p>
    <p>The vertical direction buffer <b>74</b> is fed with image data, in an amount corresponding to the capacity of the first to third buffers <b>91</b> to <b>93</b>, on the line basis. Thus, image data offset one line is stored in each f the first to third buffer memories <b>91</b> to <b>93</b>. The vertical direction transform processing circuit <b>75</b> is able to perform the resolution conversion processing in the vertical direction based on the image data from the first to third buffers <b>91</b> to <b>93</b> of the vertical direction buffer <b>74</b>.</p>
    <p>With the memory controller <b>22</b>, the memory controller <b>22</b> can cause the resolution conversion circuit <b>28</b> to execute the resolution conversion in the vertical direction, by readout in meeting with the capacity of the buffer memory, even if the capacity of the buffer memory required for resolution conversion in the vertical direction is not up to one line.</p>
    <p>Although the read-out overlap between the image data sets is two columns, it is probable that the overlap exceeds two columns or there is no overlap. It is noted that the present invention is applicable to image signal processing, such as camera signal processing, without limitation to resolution conversion.</p>
    <p>Although the foregoing description is directed to the embodiment in which the buffer memory is being used for interpolation for the vertical direction, the present invention is also applicable to an embodiment in which the buffer memory is being used for interpolation for the horizontal direction.</p>
    <p>That is, the resolution conversion circuit <b>28</b> may perform resolution conversion in the horizontal direction using a horizontal direction buffer <b>72</b> <i>a </i>comprised of a buffer memory <b>72</b> <i>a </i>having a capacity of N pixels, as shown in FIG. <b>13</b>. The memory controller <b>22</b> can read out image data of N pixels on the column basis in the sequence of the rows <b>1</b>, <b>2</b>, . . . , p in the vertical direction, as shown in FIG. <b>14</b>. Meanwhile, it is necessary for the memory controller <b>22</b> to read out the image data stored at the leading and trailing ends of the buffer memory twice, as in the above-described vertical interpolation processing, so that these image data will be the object of the horizontal interpolation processing.</p>
    <p>Thus, the memory controller <b>22</b> is able to read out image data from the image memory <b>32</b> so that resolution conversion processing in the horizontal and vertical directions will be effected for the first to third buffer memories <b>91</b> to <b>93</b> each having a capacity of N pixels. This enables the circuit scale of the horizontal direction buffer <b>72</b> and the vertical direction buffer <b>74</b> to be reduced to lower the production cost.</p>
    <p>The NTSC/PAL encoder <b>23</b>, executing the encoding as described above, also has a simplified resolution conversion circuit <b>23</b> <i>a </i>for increasing the resolution of the image data, if need be, before proceeding to encoding.</p>
    <p>The simplified resolution conversion circuit <b>23</b> <i>a </i>performs resolution conversion for matching to the display standard of the finder <b>36</b> if the image data on the image memory <b>32</b> is lower than the resolution required for display.</p>
    <p>Referring to FIG. 15, the simplified resolution conversion circuit <b>23</b> <i>a </i>includes a line memory <b>101</b> for storing image data from the image data bus <b>33</b>, a vertical direction linear interpolation circuit (V-direction linear interpolation circuit <b>102</b>) for interpolating image data in the vertical direction, and a horizontal direction interpolation circuit <b>103</b>.</p>
    <p>The line memory <b>101</b> stores image data from an input terminal in in an amount corresponding to one line to send the image data to the V-direction linear interpolation circuit <b>102</b> in the order it is stored. The V-direction linear interpolation circuit <b>102</b> weights the image data from the input terminal in and the image data from the V-direction linear interpolation circuit <b>102</b> with a pre-set weighting to perform linear interpolation in the vertical direction. The horizontal direction interpolation circuit <b>103</b> interpolates Y with an order-seven filter, while interpolating Cb and Cr with an order-three filter. This is simply the interpolation for increasing the resolution by a factor of two. The horizontal direction interpolation circuit <b>103</b> outputs the image data at an output terminal out.</p>
    <p>For example, if image data inputted from the input terminal in is denoted a, image data read out from the line memory <b>101</b> is b, a coefficient for weighting is g, where 0g1, and image data outputted by the V-direction linear interpolation circuit <b>102</b> is c, the V-direction linear interpolation circuit <b>102</b> effectuates the following processing:</p>
    <p>
      <maths> <formula-text> <i>c=g*a</i>+(1<i>g</i>)*<i>b.</i> </formula-text> </maths> </p>
    <p>The image data outputted by the output terminal out is encoded by the NTSC/PAL encoder <b>23</b>, as mentioned previously.</p>
    <p>In the signal processing system, the digital still camera <b>1</b> is made up of so-called two chips, namely s signal processor <b>20</b> and a CPU <b>41</b>. Therefore, the respective signal processing circuits are each of the chip configuration, so that the substrate surface area and further the power consumption can be made smaller than if the respective signal processing circuits are of separate chip configurations.</p>
    <p>Also, since the signal processor <b>20</b> is not of the chip configuration inclusive of the CPU, signal processing can be adaptively effectuated even if the application in connection with the CPU <b>41</b> is changed. That is, if the signal processor <b>20</b> is of the chip configuration inclusive of the CPU, it is impossible to reconstruct the chip in case the application of the CPU is changed. However, the signal processor <b>20</b> can perform the pre-set signal processing using a CPU of an optimum structure on the application basis.</p>
    <p>The digital still camera <b>1</b> of the above-described structure has a finder mode for confirming the status or the position of an object prior to image shooting, a recording mode for shooting the image of the object as confirmed, and a reproducing mode for confirming the shot state of the object image, and effects the processing depending on the prevailing mode.</p>
    <p>In the finder mode, the user has to observe the state of the object indicated on the finder <b>36</b> before thrusting a shutter button, not shown, to shoot the object. In this finder mode, the memory controller <b>22</b> and other circuits are controlled in the following manner. For illustrating the respective modes, reference is had mainly to FIG. <b>4</b> and occasionally to FIG. <b>16</b>.</p>
    <p>In the finder mode, the CCD image sensor <b>11</b> generates image signals, thinned out to one-third from the vertical components, and furnishes the digitized image data via the S/H-A/D circuit <b>12</b> to the CCD interface <b>21</b> <i>a. </i> </p>
    <p>The CCD interface <b>21</b> <i>a </i>performs signal processing in synchronism with clocks shown in FIG. <b>16</b>A. Specifically, the CCD interface <b>21</b> <i>a </i>decimates the horizontal components of the image data supplied by the image generating unit <b>10</b> to one-third and corrects the decimated image data for gamma to send the gamma-corrected data to the camera DSP <b>21</b> <i>c</i>. The CCD interface <b>21</b> <i>a </i>furnishes the image data converted to 340256 from the  decimation process to the camera DSP <b>21</b> <i>c. </i> </p>
    <p>The camera DSP <b>21</b> <i>c </i>performs data conversion processing on the decimated image data into YCrCb image data. The camera DSP <b>21</b> <i>c </i>converts the resolution of the image data in the simplified resolution conversion circuit <b>21</b> <i>d </i>(340256320240) for lowering the resolution of the image data to route the converted image data via image data bus <b>33</b> to the memory controller <b>22</b>.</p>
    <p>It is noted that the simplified resolution conversion circuit <b>21</b> <i>d </i>lowers the resolution in a simplified fashion to an extent necessary for subsequent processing. In this manner, if image data generated by the CCD image sensor <b>11</b> is of high resolution, the transfer range taken up by the image data generated by the CCD image sensor <b>11</b> can be decreased to evade the stagnancy on the image data bus <b>33</b> to maintain the real-time characteristics of the finder mode.</p>
    <p>The memory controller <b>22</b> writes the image data in the image memory <b>32</b>, while reading out the image data from the image memory <b>32</b> as shown in FIG. 16D to send the read-out image data via the image data bus <b>33</b> to the NTSC/PAL encoder <b>23</b>. Simultaneously, the memory controller <b>22</b> reads out the OSD data stored in the image memory <b>32</b>, as shown in FIG. 16E, to send the OSD data stored in the image memory <b>32</b>, as shown in FIG. <b>16</b>E. FIG. 16F shows the state of transfer on the image data bus <b>33</b> which enables the above-described real-time processing.</p>
    <p>The NTSC/PAL encoder <b>23</b> performs resolution conversion of 320240640240 or 320240640288 in the case of the NTSC system or the PAL system, respectively, to send the converted image data to the NTSC/PAL encoder <b>23</b>. The NTSC/PAL encoder <b>23</b> also converts the image data into data of the NTSC system or the PAL system into OSD data which is routed to the finder <b>36</b> shown in FIG. <b>3</b>. This allows the image of the object and the title information etc to be displayed in-real time on the finder <b>36</b>.</p>
    <p>Meanwhile, the NTSC/PAL encoder <b>23</b> converts the resolution so that data with low resolution will be increased in resolution, such that, if 320200 image data is furnished, it is converted into 640240 image data and into 640288 image data for the NTSC system and for the PAL system, respectively.</p>
    <p>In the digital still camera <b>1</b>, the resolution of the image data generated by the CCD image sensor <b>11</b> is lowered in a simplified fashion in the finder mode to reduce the data volume, so that the image data will be within the bandwidth limitation of the image data bus <b>33</b> and so that the resolution will be increased at an output stage to the extent that is necessary for display, at a timing shown in FIG. <b>16</b>F.</p>
    <p>Thus, with the digital still camera <b>1</b>, the image data is held in the bandwidth limitation of the image data bus <b>33</b> to permit the image of the object to be displayed on the finder <b>36</b>, even if the image data is of high resolution, without the necessity of performing the time-consuming decimation processing.</p>
    <p>If the circuitry for preferential processing, namely the CCD interface <b>21</b> <i>a</i>, camera DSP <b>21</b> <i>c </i>or the NTSC/PAL encoder <b>23</b>, is previously set in the CPU <b>41</b>, and signal processing is carried out time-divisionally in other circuits as in the above circuits, the processing of the respective circuits with high priority may be preferentially performed depending on the data volume of the image data.</p>
    <p>In the event of the large data volume of the image data in the simplified resolution conversion circuit <b>21</b> <i>d</i>, data processing may be performed at a high processing speed, in order to give priority to real-time processing, even though the picture quality is degraded to a certain extent, under control by the CPU <b>41</b>. In this manner, high-speed processing can be effected in the finder mode even in case of the large data volume of the image data generated in the image generating unit <b>10</b>.</p>
    <p>In the case of the digital still camera <b>1</b>, having an electronic zooming function, the CPU <b>41</b> can control the respective circuits in the following manner.</p>
    <p>The memory controller <b>22</b> causes the image data, supplied via the CCD interface <b>21</b> <i>a </i>and camera DSP <b>21</b> <i>c</i>, to be written in the image memory <b>32</b>, while causing the image data to be read out from the image memory <b>32</b> and routed to the resolution conversion circuit <b>28</b>. The resolution conversion circuit <b>28</b> formulates image data enlarged from a portion of the input image, by an electronic zooming function, to output the resulting image data to the image memory <b>32</b>. This image data is read out from the image memory <b>32</b> and outputted to the finder <b>36</b> via the NTSC/PAL encoder <b>23</b>. This generates electronically zoomed image data.</p>
    <p>Since the finder mode gives utmost priority to the real-time characteristics, time-consuming processing is not executed by the respective circuits. However, the CPU <b>41</b> can be configured to cause the memory controller <b>22</b> and other circuits to perform various processing operations if within the range allowed by the transfer area of the image data bus <b>33</b>.</p>
    <p>For example, the memory controller <b>22</b> may be configured to read out image data from the image memory <b>32</b>, in which is stored the image data furnished from the CCD interface <b>21</b> <i>a</i>, and to finish the read-out image data to the NTSC/PAL encoder <b>23</b> over the image data bus <b>33</b> and to the JPEG encoder/decoder <b>29</b>. The finder <b>36</b> displays the image of the object in real-time, while the JPEG encoder/decoder <b>29</b> compresses the image data in accordance with the JPEG system.</p>
    <p>The JPEG encoder/decoder <b>29</b> compresses/expands the still image, while it cannot process high-pixel image in real-time. It is thus possible for the JPEG encoder/decoder <b>29</b> to decimate a pre-set number of frames of the image data supplied from the image data bus <b>33</b> (number of frames or fields) by way of compression or to slice a portion of the image to lower the resolution by way of compression. This enables shooting of a frame-decimated still image continuously or shooting of a low-resolution image continuously.</p>
    <p>The user observes the state of the object displayed on the finder <b>36</b> in the above-mentioned finder mode. If the object is decided to be shot, the user pushes a shutter button, not shown.</p>
    <p>If the shutter button is pushed, the digital still camera <b>1</b> proceeds to the recording mode. In the recording mode, the CPU <b>41</b> controls the memory controller <b>22</b> or the respective circuits in the following manner to record the image of the as-shot object on a recording device <b>51</b>.</p>
    <p>The CCD image sensor <b>11</b> halts the decimation operation in synchronism with the thrusting the shutter button to generate image signals of the XGA format to route the digitized image data via the S/H-A/D circuit <b>12</b> to the CCD interface <b>21</b> <i>a. </i> </p>
    <p>The CCD interface <b>21</b> <i>a </i>routes the image data furnished from the S/H-A/D circuit <b>12</b> not to the camera DSP <b>21</b> <i>c</i>, but to the memory controller <b>22</b> via the image data bus <b>33</b>. The memory controller <b>22</b> first writes the image data in the image memory <b>32</b> and subsequently reads out the image data to route the read-out image data via the image data bus <b>33</b> to the camera DSP <b>21</b> <i>c</i>. The camera DSP <b>21</b> <i>c </i>converts the image data made up of RGB into image data made up of Y, Cb and Cr.</p>
    <p>The camera DSP <b>21</b> <i>c </i>is fed with image data once written in the image memory <b>32</b>. That is, the camera DSP <b>21</b> <i>c </i>effects data conversion on the image data from the image memory <b>32</b> instead of on the image data directly supplied from the CCD interface <b>21</b> <i>a</i>. Thus, it is unnecessary for the camera DSP <b>21</b> <i>c </i>to perform high-speed data conversion, but it is only sufficient if the camera DSP <b>21</b> <i>c </i>executes such processing when the image data bus <b>33</b> is not busy. Stated differently, it is unnecessary for the camera DSP <b>21</b> <i>c </i>to perform the processing in real-time, so that data conversion processing can be executed with priority given to the high picture quality rather than to the high processing speed and the resulting converted image data may be routed to the memory controller <b>22</b> via the image data bus <b>33</b>. The memory controller <b>22</b> causes the image data to be written in the image memory <b>32</b>.</p>
    <p>The memory controller <b>22</b> causes the image data to be read out from the image memory <b>32</b> to route the read-out image data to the JPEG encoder/decoder <b>29</b>. The JPEG encoder/decoder <b>29</b> compresses the image data in accordance with the JPEG system to write the compressed image data in the recording device <b>51</b> shown in FIG. <b>3</b>.</p>
    <p>If real-time processing is not unnecessary, as during recording, the CPU <b>41</b> permits the pre-set processing to be executed after writing the image data transiently in the image memory <b>32</b> to exploit the transfer band of the image data bus <b>33</b> to process the high-pixel image.</p>
    <p>The CPU <b>41</b> records the image data of the XGA format directly in the recording device <b>51</b> in the recording mode. It is however possible for the resolution conversion circuit <b>28</b> to convert the resolution of the image data before recording the image data on the recording device <b>51</b>. Specifically, it is possible to cause the resolution conversion circuit <b>28</b> to convert the resolution of the image data read out from the image memory <b>32</b> via the memory controller <b>22</b> in meeting with the VGA (1024768640480) to permit the JPEG encoder/decoder <b>29</b> to compress the image data to record the compressed data in the recording device <b>51</b>.</p>
    <p>If desirous to confirm the as-shot image after image shooting, the operator thrusts the playback button, not shown, for reproducing the as-shot image.</p>
    <p>If the reproducing button is thrust, the digital still camera <b>1</b> moves to the reproducing mode. In the reproducing mode, the CPU <b>41</b> controls the respective circuits in the following manner to read out the image data of the object.</p>
    <p>That is, on detecting the thrusting the reproducing button, the CPU <b>41</b> reads out the image data from the recording device <b>51</b> and transiently stores the read-out image data in the DRAM <b>42</b> before routing the data via CPU bus <b>34</b> to the JPEG encoder/decoder <b>29</b>. The JPEG encoder/decoder <b>29</b> expands the image data read out from the recording device <b>51</b> in accordance with the JPEG system to produce image data of the XGA format to route the resulting image data via the image data bus <b>33</b> to the memory controller <b>22</b>.</p>
    <p>The memory controller <b>22</b> writes the image data on the image memory <b>32</b> and reds out the image data from the image memory <b>32</b> to send the read-out image data via the image data bus <b>33</b> to the resolution conversion circuit <b>28</b>.</p>
    <p>The resolution conversion circuit <b>28</b> effects resolution conversion so that the image data will be in meeting with the VGA format (1024768640480 in the NTSC system and 1024768640576 in the PAL system) to route the converted image data over the image data bus <b>33</b> to the memory controller <b>22</b>. The image data then is read from the image memory <b>32</b> and routed via the NTSC/PAL encoder <b>23</b> to the finder <b>36</b>. This displays an image corresponding to the image data recorded in the recording device <b>51</b> on the finder <b>36</b>.</p>
    <p>That is, since the image data recorded in the recording device <b>51</b> has high resolution, the CPU <b>41</b> first lowers the resolution and subsequently routes the image data to the finder <b>36</b>.</p>
    <p>It is also possible for the CPU <b>41</b> to set, for each of the finder mode, recording mode and the reproducing mode, the order of priority of the circuits to be processed in preference and to cause the pertinent circuit to execute the processing in accordance with the order of priority on movement to one of the modes. This enables the signal processing of image data to be executed efficiently depending on the processing contents in each mode.</p>
    <p>In the above-described embodiment, it is assumed that the data being processed is the image data equivalent to XGA. It is to be noted that the present invention is not limited to this embodiment and can be applied to, for example, the processing of image data comprised of one million or more pixels.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5751350">US5751350</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 15, 1997</td><td class="patent-data-table-td patent-date-value">May 12, 1998</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Dual mode electronic camera having a large recording capacity</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6097430">US6097430</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 10, 1995</td><td class="patent-data-table-td patent-date-value">Aug 1, 2000</td><td class="patent-data-table-td ">Olympus Optical Co., Ltd.</td><td class="patent-data-table-td ">Image processing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6144411">US6144411</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 4, 1997</td><td class="patent-data-table-td patent-date-value">Nov 7, 2000</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing apparatus with format conversion capabilities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6177956">US6177956</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 23, 1996</td><td class="patent-data-table-td patent-date-value">Jan 23, 2001</td><td class="patent-data-table-td ">Flashpoint Technology, Inc.</td><td class="patent-data-table-td ">System and method for correlating processing data and image data within a digital camera device</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6999115">US6999115</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 7, 2000</td><td class="patent-data-table-td patent-date-value">Feb 14, 2006</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Image taking apparatus with an A/D converter and DSP with variable quantization bit numbers</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7154550">US7154550</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 31, 2000</td><td class="patent-data-table-td patent-date-value">Dec 26, 2006</td><td class="patent-data-table-td ">Sanyo Electric Co., Ltd</td><td class="patent-data-table-td ">Electronic camera for quickly confirming a recorded image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7202893">US7202893</a></td><td class="patent-data-table-td patent-date-value">Jan 3, 2005</td><td class="patent-data-table-td patent-date-value">Apr 10, 2007</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method and apparatus for the display of still images from image files</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7256826">US7256826</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 29, 2003</td><td class="patent-data-table-td patent-date-value">Aug 14, 2007</td><td class="patent-data-table-td ">Mega Chips Corporation</td><td class="patent-data-table-td ">Image processing circuit of image input device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7345701">US7345701</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 25, 2003</td><td class="patent-data-table-td patent-date-value">Mar 18, 2008</td><td class="patent-data-table-td ">Samsung Electro-Mechanics Co., Ltd.</td><td class="patent-data-table-td ">Line buffer and method of providing line data for color interpolation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7349012">US7349012</a></td><td class="patent-data-table-td patent-date-value">Aug 26, 2003</td><td class="patent-data-table-td patent-date-value">Mar 25, 2008</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Imaging apparatus with higher and lower resolution converters and a compression unit to compress decreased resolution image data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7382402">US7382402</a></td><td class="patent-data-table-td patent-date-value">Jul 24, 2003</td><td class="patent-data-table-td patent-date-value">Jun 3, 2008</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Imaging system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7403212">US7403212</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2005</td><td class="patent-data-table-td patent-date-value">Jul 22, 2008</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method and apparatus for the display of still images from image files</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7432920">US7432920</a></td><td class="patent-data-table-td patent-date-value">Nov 30, 2004</td><td class="patent-data-table-td patent-date-value">Oct 7, 2008</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method and apparatus for the display of still images from image files</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7469689">US7469689</a></td><td class="patent-data-table-td patent-date-value">Sep 9, 2005</td><td class="patent-data-table-td patent-date-value">Dec 30, 2008</td><td class="patent-data-table-td ">Jones Daniel W</td><td class="patent-data-table-td ">Fluid cooled supercharger</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7474838">US7474838</a></td><td class="patent-data-table-td patent-date-value">Jul 2, 2004</td><td class="patent-data-table-td patent-date-value">Jan 6, 2009</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Signal processing apparatus, control method for signal processing apparatus, imaging apparatus and recording/reproducing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7663585">US7663585</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 18, 2005</td><td class="patent-data-table-td patent-date-value">Feb 16, 2010</td><td class="patent-data-table-td ">Funai Electric Co., Ltd.</td><td class="patent-data-table-td ">Television apparatus having liquid crystal display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7733406">US7733406</a></td><td class="patent-data-table-td patent-date-value">Jun 25, 2009</td><td class="patent-data-table-td patent-date-value">Jun 8, 2010</td><td class="patent-data-table-td ">Casio Computer Co., Ltd.</td><td class="patent-data-table-td ">Image signal generation unit, digital camera, and image signal generation method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7750946">US7750946</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 8, 2006</td><td class="patent-data-table-td patent-date-value">Jul 6, 2010</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Signal processing apparatus allowing an increase in pixels without an increase in driving frequency and circuit area</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7750967">US7750967</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 2007</td><td class="patent-data-table-td patent-date-value">Jul 6, 2010</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image capturing apparatus, electronic apparatus, display method, and program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7880775">US7880775</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 4, 2007</td><td class="patent-data-table-td patent-date-value">Feb 1, 2011</td><td class="patent-data-table-td ">Candela Microsystems, Inc.</td><td class="patent-data-table-td ">Image sensor with interleaved image output</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7924319">US7924319</a></td><td class="patent-data-table-td patent-date-value">May 18, 2010</td><td class="patent-data-table-td patent-date-value">Apr 12, 2011</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Signal processing apparatus allowing an increase in pixels without an increase in driving frequency and circuit area</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8081106">US8081106</a></td><td class="patent-data-table-td patent-date-value">Feb 2, 2009</td><td class="patent-data-table-td patent-date-value">Dec 20, 2011</td><td class="patent-data-table-td ">Bae Systems Information And Electric Systems Integration Inc.</td><td class="patent-data-table-td ">Target ranging using information from two objects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8189102">US8189102</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 26, 2009</td><td class="patent-data-table-td patent-date-value">May 29, 2012</td><td class="patent-data-table-td ">Panasonic Corporation</td><td class="patent-data-table-td ">Image processing apparatus using interpolation direction</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S222100">348/222.1</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S333010">348/333.01</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348SE05047">348/E05.047</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S231990">348/231.99</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005225000">H04N5/225</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005781000">H04N5/781</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005920000">H04N5/92</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005232000">H04N5/232</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005907000">H04N5/907</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=71ZkBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N5/23293">H04N5/23293</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N5/232V</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jun 30, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 6, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 28, 2006</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-5 IS CONFIRMED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 18, 2005</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20041202</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 28, 1999</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SONY CORPORATION, JAPAN</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:MIZUTANI, YOICHI;TAKEZAWA, MASAYUKI;MATSUMOTO, HIDEKI;AND OTHERS;REEL/FRAME:010269/0048;SIGNING DATES FROM 19990906 TO 19990908</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U2RzryX0dvTcBarMA9-kaRUCk8SOA\u0026id=71ZkBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0Yka72Xw3kKUTfG1zAS06YklJhNg\u0026id=71ZkBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U078yduamXmTOJrfJAOELL9rtkNTg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Imaging_apparatus_for_performing_selecti.pdf?id=71ZkBAABERAJ\u0026output=pdf\u0026sig=ACfU3U1Sd94HqOyKWM6ylEsit9TFXtQkag"},"sample_url":"http://www.google.com/patents/reader?id=71ZkBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>