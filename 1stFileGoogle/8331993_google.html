<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US8331993 - Mobile terminal and operation control method thereof - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4ff636b3d23669b7103f3b3a3a18b4cd/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4ff636b3d23669b7103f3b3a3a18b4cd__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Mobile terminal and operation control method thereof"><meta name="DC.contributor" content="Jungsu LEE" scheme="inventor"><meta name="DC.contributor" content="Jinwook Choi" scheme="inventor"><meta name="DC.contributor" content="Seungwon Lee" scheme="inventor"><meta name="DC.contributor" content="Seungcheon Baek" scheme="inventor"><meta name="DC.contributor" content="Lg Electronics Inc." scheme="assignee"><meta name="DC.date" content="2012-5-15" scheme="dateSubmitted"><meta name="DC.description" content="Disclosed herein is a mobile terminal and an operation control method thereof in which a delay time of the screen lock execution is controlled according to the type of application, thereby improving the inconvenience of a user interface and effectively managing a battery according to an interrupt when required to continuously receive an input from the user or continuously provide visual information to the user. For this purpose, a mobile terminal according to an embodiment of the present disclosure may include an input unit configured to receive a user input; an execution controller configured to execute screen lock if the user input is not received for a predetermined time; and a change controller configured to change the predetermined time based on a type of application."><meta name="DC.date" content="2012-12-11" scheme="issued"><meta name="DC.relation" content="KR:20020093426" scheme="references"><meta name="DC.relation" content="KR:20040026560" scheme="references"><meta name="DC.relation" content="KR:20060044206" scheme="references"><meta name="DC.relation" content="KR:20100053144" scheme="references"><meta name="DC.relation" content="US:20050198661:A1" scheme="references"><meta name="DC.relation" content="US:20070078552:A1" scheme="references"><meta name="DC.relation" content="US:20080118152:A1" scheme="references"><meta name="DC.relation" content="US:20080303443:A1" scheme="references"><meta name="DC.relation" content="US:20090082066:A1" scheme="references"><meta name="DC.relation" content="US:20100259387:A1" scheme="references"><meta name="DC.relation" content="US:6665805" scheme="references"><meta name="DC.relation" content="US:7091471" scheme="references"><meta name="citation_patent_number" content="US:8331993"><meta name="citation_patent_application_number" content="US:13/472,286"><link rel="canonical" href="http://www.google.com/patents/US8331993"/><meta property="og:url" content="http://www.google.com/patents/US8331993"/><meta name="title" content="Patent US8331993 - Mobile terminal and operation control method thereof"/><meta name="description" content="Disclosed herein is a mobile terminal and an operation control method thereof in which a delay time of the screen lock execution is controlled according to the type of application, thereby improving the inconvenience of a user interface and effectively managing a battery according to an interrupt when required to continuously receive an input from the user or continuously provide visual information to the user. For this purpose, a mobile terminal according to an embodiment of the present disclosure may include an input unit configured to receive a user input; an execution controller configured to execute screen lock if the user input is not received for a predetermined time; and a change controller configured to change the predetermined time based on a type of application."/><meta property="og:title" content="Patent US8331993 - Mobile terminal and operation control method thereof"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("LOHoU5veGomosQSj64G4CQ"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407291699.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CZE"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("LOHoU5veGomosQSj64G4CQ"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407291699.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CZE"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us8331993?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US8331993"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=OEKxBwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS8331993&amp;usg=AFQjCNEbzKAFj8l4Qd-tIKYfe215EwoX_Q" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US8331993.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US8331993.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20120225697"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US8331993"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US8331993" style="display:none"><span itemprop="description">Disclosed herein is a mobile terminal and an operation control method thereof in which a delay time of the screen lock execution is controlled according to the type of application, thereby improving the inconvenience of a user interface and effectively managing a battery according to an interrupt when...</span><span itemprop="url">http://www.google.com/patents/US8331993?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US8331993 - Mobile terminal and operation control method thereof</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US8331993 - Mobile terminal and operation control method thereof" title="Patent US8331993 - Mobile terminal and operation control method thereof"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US8331993 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 13/472,286</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Dec 11, 2012</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">May 15, 2012</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Sep 13, 2010</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CN103081449A">CN103081449A</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2618626A1">EP2618626A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2618626A4">EP2618626A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8489150">US8489150</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8639297">US8639297</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120064948">US20120064948</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120225697">US20120225697</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130115875">US20130115875</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130116013">US20130116013</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20140085195">US20140085195</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2012036324A1">WO2012036324A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">13472286, </span><span class="patent-bibdata-value">472286, </span><span class="patent-bibdata-value">US 8331993 B2, </span><span class="patent-bibdata-value">US 8331993B2, </span><span class="patent-bibdata-value">US-B2-8331993, </span><span class="patent-bibdata-value">US8331993 B2, </span><span class="patent-bibdata-value">US8331993B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jungsu+LEE%22">Jungsu LEE</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jinwook+Choi%22">Jinwook Choi</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Seungwon+Lee%22">Seungwon Lee</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Seungcheon+Baek%22">Seungcheon Baek</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Lg+Electronics+Inc.%22">Lg Electronics Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US8331993.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8331993.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8331993.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (12),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (21),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/8331993&usg=AFQjCNHujLhp5VoPr3Jl8wSW5-aRh5aRvg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D8331993&usg=AFQjCNGzb1vs8D62iW_UVZsO0xzsMGNdfg">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D8331993B2%26KC%3DB2%26FT%3DD&usg=AFQjCNF4bcq5na8uXFH2jJ3uFRIdYGCvjQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT117787363" lang="EN" load-source="patent-office">Mobile terminal and operation control method thereof</invention-title></span><br><span class="patent-number">US 8331993 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA103015770" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">Disclosed herein is a mobile terminal and an operation control method thereof in which a delay time of the screen lock execution is controlled according to the type of application, thereby improving the inconvenience of a user interface and effectively managing a battery according to an interrupt when required to continuously receive an input from the user or continuously provide visual information to the user. For this purpose, a mobile terminal according to an embodiment of the present disclosure may include an input unit configured to receive a user input; an execution controller configured to execute screen lock if the user input is not received for a predetermined time; and a change controller configured to change the predetermined time based on a type of application.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(12)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8331993B2/US08331993-20121211-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8331993B2/US08331993-20121211-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(18)</span></span></div><div class="patent-text"><div mxw-id="PCLM46820185" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A mobile terminal, comprising:
<div class="claim-text">a mobile communication unit configured to transmit and receive a radio signal over a communication network;</div>
<div class="claim-text">a display unit configured to display visual information processed in the mobile terminal;</div>
<div class="claim-text">an input unit configured to receive a user input;</div>
<div class="claim-text">at least one sensor configured to detect user's gaze information;</div>
<div class="claim-text">an execution controller configured to execute screen lock when the user input is not received for a first delay time T<b>1</b>; and</div>
<div class="claim-text">a change controller configured to change the first delay time T<b>1</b> to a second delay time T<b>2</b> based on the user's gaze information,</div>
<div class="claim-text">wherein the gaze information indicates a line connecting a user's eyes to the display unit and the change controller determines whether the user stares at the display unit based on the user's gaze information, and</div>
<div class="claim-text">wherein the change controller further configured to extend the first delay time T<b>1</b> to the second delay time T<b>2</b> when the change controller determines that the user stares at the display unit based on the user's gaze information or to reduce the first delay time T<b>1</b> to the second delay time T<b>2</b> when the change controller determines that the user does not stare at the display unit based on the user's gaze information.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The mobile terminal of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one sensor comprises at least one optical sensor for capturing image of the user.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The mobile terminal of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the user's gaze information includes information indicating whether the user's face area is detected from the image of the user which is captured by the at least one optical sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The mobile terminal of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the change controller determines that the user stares at the display unit when the change controller detects the user's face area from the image of the user and the size of the user's face area is larger than a threshold value.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The mobile terminal of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the user's gaze information further indicates gaze time indicating a period the user stares the display unit.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The mobile terminal of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">wherein the change controller further changes the first delay time T<b>1</b> to the second delay time T<b>2</b> based on a type of application, and the type of application is classified according to whether the user's gaze at the visual information is required.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The mobile terminal of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the at least one sensor comprises at least one acceleration sensor for detecting tilt of the mobile terminal and/or at least one touch sensor for detecting a grip type of the mobile terminal.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The mobile terminal of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the user's gaze information further indicates the tilt of the mobile terminal and/or the user's grip type of the mobile terminal.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The mobile terminal of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the change controller changes the first delay time T<b>1</b> to the second delay time T<b>2</b> further based on the user's application execution pattern or screen lock release pattern.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. A method of controlling the operation of a mobile terminal, the method comprising:
<div class="claim-text">detecting user's gaze information which indicates a line connecting a user's eyes to a display unit of the mobile terminal;</div>
<div class="claim-text">changing a first delay time T<b>1</b> to a second delay time T<b>2</b> by determining whether the user stares at the display unit based on the user's gaze information; and</div>
<div class="claim-text">executing screen lock when a user input is not received for the second delay time T<b>2</b>,</div>
<div class="claim-text">wherein the changing step further comprises extending the first delay time T<b>1</b> to the second delay time T<b>2</b> when determining that the user stares at the display unit based on the user's gaze information or reducing the first delay time T<b>1</b> to the second delay time T<b>2</b> when determining that the user does not stare at the display unit based on the user's gaze information.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, the method further comprising:
<div class="claim-text">capturing an image of the user for detecting the user's gaze information.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the user's gaze information includes information indicating whether a user's face area is detected from the captured image of the user.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the determining step further comprises:
<div class="claim-text">determining that the user stares at the display unit when the user's face area is detected from the image of the user and the size of the user's face area is larger than a threshold value.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the user's gaze information further indicates gaze time indicating a period the user stares the display unit.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the changing step further comprises:
<div class="claim-text">changing the first delay time T<b>1</b> to the second delay time T<b>2</b> based on a type of application, and the type of application is classified according to whether the user's gaze at the visual information is required.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, the method further comprising:
<div class="claim-text">detecting tilt of the mobile terminal or a user's grip type of the mobile terminal.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the user's gaze information further indicates tilt of the mobile terminal or the user's grip type of the mobile terminal.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the changing step further comprises:
<div class="claim-text">changing the first delay time T<b>1</b> to the second delay time T<b>2</b> further based on the user's application execution pattern or screen lock release pattern.</div>
</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES53146406" lang="EN" load-source="patent-office" class="description">
    <heading>CROSS-REFERENCE TO RELATED APPLICATIONS</heading> <p num="p-0002">This application is a Continuation of co-pending U.S. application Ser. No. 13/203,908 filed on Aug. 30, 2011, which is the national phase of PCT International Application No. PCT/KR2010/006237 filed on Sep. 13, 2010. The entire contents of the above U.S. application are hereby incorporated by reference.</p>
    <heading>TECHNICAL FIELD</heading> <p num="p-0003">The present disclosure relates to a mobile terminal and an operation control method thereof, and more particularly, to a mobile terminal for controlling the execution of screen lock, and a method for controlling the execution of screen lock provided in such a mobile terminal.</p>
    <heading>BACKGROUND ART</heading> <p num="p-0004">In recent years, as a mobile terminal provides complicated and various functions, considerations are required for the convenience of a user interface (UI) including a screen lock function, and the like.</p>
    <heading>TECHNICAL GIST OF THE PRESENT INVENTION</heading> <p num="p-0005">A technical task of the present invention is to provide a mobile terminal and an operation control method thereof in which a delay time of the screen lock execution is controlled according to the type of application, thereby improving the inconvenience of a user interface and effectively managing a battery according to an interrupt when required to continuously receive an input from the user or continuously provide visual information to the user.</p>
    <p num="p-0006">In addition, another technical task of the present invention is to provide a mobile terminal and an operation control method thereof in which a delay time of the screen lock execution is controlled according to the user's gaze information, thereby improving the inconvenience of a user interface and effectively managing a battery according to an interrupt when required to continuously receive an input from the user or continuously provide visual information to the user.</p>
    <p num="p-0007">In order to solve the foregoing technical task, it is characterized in that a mobile terminal may include an input unit configured to receive a user input; an execution controller configured to execute screen lock if the user input is not received for a predetermined time; and a change controller configured to change the predetermined time based on a type of application.</p>
    <p num="p-0008">According to an embodiment, it is characterized in that the change controller may reduce or extend the predetermined time based on the type of application.</p>
    <p num="p-0009">Furthermore, according to an embodiment, it is characterized in that the application may include a content-based application, and the change controller may change the predetermined time based on reproduction information of content. Furthermore, according to an embodiment, it is characterized in that the application may include a search-based application, and the change controller may change the predetermined time based on an input time or search time of search word. Furthermore, according to an embodiment, it is characterized in that the application may include a messaging service-based application, and the change controller may change the predetermined time based on an input time of message.</p>
    <p num="p-0010">Furthermore, according to an embodiment, it is characterized in that the application may include a location information-based application, and the change controller may change the predetermined time based on a change of location information. Furthermore, according to an embodiment, it is characterized in that the application may include a time information-based application, and the change controller may change the predetermined time based on a change of time information.</p>
    <p num="p-0011">Furthermore, according to an embodiment, it is characterized in that the change controller may change the predetermined time based on a security setting for an object approached by the application. Furthermore, according to an embodiment, it is characterized in that the change controller may change the predetermined time based on an interrupt generated by the application.</p>
    <p num="p-0012">On the other hand, in order to solve the foregoing technical task, it is characterized in that a method of controlling the operation of a mobile terminal may include checking a type of application; changing a predetermined time based on the type of application; and executing screen lock when a user input is not received for the predetermined time or a time to which the predetermined time has been changed.</p>
    <p num="p-0013">On another hand, in order to solve the foregoing another technical task, it is characterized in that a mobile terminal may include an input unit configured to receive a user input; at least one sensor configured to detect user's gaze information; an execution controller configured to execute screen lock if the user input is not received for a predetermined time; and a change controller configured to change the predetermined time based on the user's gaze information.</p>
    <p num="p-0014">According to an embodiment, it is characterized in that the at least one sensor may include at least one acceleration sensor for detecting tilt of the mobile terminal and/or at least one touch sensor for detecting a grip type of the mobile terminal. Furthermore, according to an embodiment, it is characterized in that the at least one sensor may include at least one optical sensor for capturing the user.</p>
    <p num="p-0015">Furthermore, according to an embodiment, it is characterized in that the change controller may reduce or extend the predetermined time based on the user's gaze information.</p>
    <p num="p-0016">Furthermore, according to an embodiment, it is characterized in that the mobile terminal may further include a display unit for displaying visual information, wherein the change controller determines whether the user gazes at the visual information or a gaze time for the visual information based on the gaze information, and changes the predetermined time based on whether to gaze or the gaze time. Furthermore, according to an embodiment, it is characterized in that the change controller may change the predetermined time based on a type of application, and the type of application may be classified according to whether the user's gaze at the visual information is required.</p>
    <p num="p-0017">Furthermore, according to an embodiment, it is characterized in that the gaze information may include tilt of the mobile terminal and/or the user's grip type of the mobile terminal. Furthermore, according to an embodiment, it is characterized in that the change controller may change the predetermined time further based on the user's application execution pattern or screen lock release pattern. Furthermore, according to an embodiment, it is characterized in that the gaze information may include information on whether a face region is detected on an image in which the user has been captured.</p>
    <p num="p-0018">On another hand, in order to solve the foregoing another technical task, it is characterized in that a method of controlling the operation of a mobile terminal may include detecting user's gaze information; changing a predetermined time based on the user's gaze information; and executing screen lock when a user input is not received for the predetermined time or a time to which the predetermined time has been changed.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0019">The accompanying drawings, which are included to provide a further understanding of the invention and are incorporated in and constitute a part of this specification, illustrate embodiments of the invention and together with the description serve to explain the principles of the invention.</p>
      <p num="p-0020">In the drawings:</p>
      <p num="p-0021"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a mobile terminal associated with an embodiment of the present disclosure;</p>
      <p num="p-0022"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a detailed block diagram illustrating a screen lock module <b>200</b> illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
      <p num="p-0023"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a view for describing a delay time for screen lock execution according to an embodiment of the present disclosure;</p>
      <p num="p-0024"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a view for describing the change of a delay time for screen lock execution according to an embodiment of the present disclosure;</p>
      <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a view for describing the change of a delay time for screen lock execution in a content-based application according to a first embodiment of the present disclosure;</p>
      <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a view for describing the change of a delay time for screen lock execution in a search-based application according to a first embodiment of the present disclosure;</p>
      <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a view for describing the change of a delay time for screen lock execution in a messaging service-based application according to a first embodiment of the present disclosure;</p>
      <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a view for describing the change of a delay time for screen lock execution in a location information-based application according to a first embodiment of the present disclosure;</p>
      <p num="p-0029"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a view for describing the change of a delay time for screen lock execution in a time information-based application according to a first embodiment of the present disclosure;</p>
      <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a view for describing the change of a delay time for screen lock execution in an application that can approach security set data according to a first embodiment of the present disclosure;</p>
      <p num="p-0031"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a view for describing the change of a delay time for screen lock execution in an application by which an interrupt has been generated according to a first embodiment of the present disclosure;</p>
      <p num="p-0032"> <figref idrefs="DRAWINGS">FIG. 12</figref> is a view illustrating the structure of a delay time information table according to a type of application according to a first embodiment of the present disclosure;</p>
      <p num="p-0033"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a view illustrating the structure of a delay time information table according to a type of parameter according to a first embodiment of the present disclosure;</p>
      <p num="p-0034"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a flow chart illustrating the process of changing a delay time for screen lock execution according to a first embodiment of the present disclosure;</p>
      <p num="p-0035"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a conceptual view for describing user's gaze information according to a second embodiment of the present disclosure;</p>
      <p num="p-0036"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a view for describing the change of a delay time for screen lock execution based on a tilt pattern according to a second embodiment of the present disclosure;</p>
      <p num="p-0037"> <figref idrefs="DRAWINGS">FIG. 17</figref> is a view for describing the change of a delay time for screen lock execution based on a tilt pattern according to a second embodiment of the present disclosure;</p>
      <p num="p-0038"> <figref idrefs="DRAWINGS">FIG. 18</figref> is a view for describing the change of a delay time for screen lock execution based on a grip pattern according to a second embodiment of the present disclosure;</p>
      <p num="p-0039"> <figref idrefs="DRAWINGS">FIG. 19</figref> is a view for describing the change of a delay time for screen lock execution based on a face region detection according to a second embodiment of the present disclosure;</p>
      <p num="p-0040"> <figref idrefs="DRAWINGS">FIGS. 20A-20C</figref> are views illustrating the structure of a delay time information table according to gaze information according to a second embodiment of the present disclosure; and</p>
      <p num="p-0041"> <figref idrefs="DRAWINGS">FIG. 21</figref> is a flow chart illustrating the process of changing a delay time for screen lock execution according to a second embodiment of the present disclosure.</p>
    </description-of-drawings> <heading>MODE FOR CARRYING OUT THE PREFERRED EMBODIMENTS</heading> <p num="p-0042">A screen lock function typically provided in the mobile terminal is a useful function in the aspect of saving battery and user security. For example, if the user does not apply an input to the mobile terminal for a predetermined time, then screen lock will be carried out, thereby allowing the mobile terminal to enter a screen lock mode. In a screen lock mode, if the user does not apply a preset input to the mobile terminal, then any other input cannot be provided to the mobile terminal. In a screen lock mode, furthermore, the mobile terminal may display a preset screen in the screen lock mode instead of the screen associated with a function being executed just prior to entering the screen lock mode. Accordingly, the mobile terminal <b>100</b> may save battery power consumed while continuously waiting for a user input or displaying visual information, thereby preventing any other person's use without permission that can happen while the user does not occupy the mobile terminal.</p>
    <p num="p-0043">Hereinafter, a mobile terminal associated with according to an embodiment of the present disclosure will be described in more detail with reference to the accompanying drawings. A suffix module or unit used for constituent elements used in the following description is merely intended for easy description of the specification, and the suffix itself does not give any special meaning or function.</p>
    <p num="p-0044"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram illustrating a mobile communication terminal associated with an embodiment of the present invention.</p>
    <p num="p-0045">The mobile communication terminal <b>100</b> may include a wireless communication unit <b>110</b>, an audio/video (A/V) input unit <b>120</b>, a user input unit <b>130</b>, a sensing unit <b>140</b>, an output unit <b>150</b>, a memory <b>160</b>, an interface unit <b>170</b>, a controller <b>180</b>, a power supply unit <b>190</b>, and the like. However, the constituent elements as illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref> are not necessarily required, and the mobile communication terminal may be implemented with greater or less number of elements than those illustrated elements. Hereinafter, the constituent elements will be described in sequence.</p>
    <p num="p-0046">The wireless communication unit <b>110</b> typically includes one or more elements allowing radio communication between the mobile communication terminal <b>100</b> and a wireless communication system, or allowing radio communication between radio communication the mobile communication terminal <b>100</b> and a network in which the mobile communication terminal <b>100</b> is located. For example, the wireless communication unit <b>110</b> may include a broadcast receiving module <b>111</b>, a mobile communication module <b>112</b>, a wireless Internet module <b>113</b>, a short-range communication module <b>114</b>, a location information module <b>115</b>, and the like.</p>
    <p num="p-0047">The broadcast receiving module <b>111</b> receives broadcast signals and/or broadcast associated information from an external broadcast management server through a broadcast channel. The broadcast channel may include a satellite channel and/or a terrestrial channel. The broadcast management server may mean a server that generates and transmits a broadcast signal and/or broadcast associated information or a server that receives a previously generated broadcast signal and/or broadcast associated information and transmits to the mobile communication terminal <b>100</b>. The broadcast signal may include a TV broadcast signal, a radio broadcast signal and a data broadcast signal as well as a broadcast signal in a form that a data broadcast signal is coupled to the TV or radio broadcast signal.</p>
    <p num="p-0048">The broadcast associated information may mean information regarding a broadcast channel, a broadcast program, a broadcast service provider, and the like. The broadcast associated information may also be provided through a mobile communication network, and in this case, the broadcast associated information may be received by the mobile communication module <b>112</b>. The broadcast associated information may exist in various forms. For example, it may exist in the form of an electronic program guide (EPG) of digital multimedia broadcasting (DMB), electronic service guide (ESG) of digital video broadcast-handheld (DVB-H), and the like.</p>
    <p num="p-0049">The broadcast receiving module <b>111</b> may receive a broadcast signal using various types of broadcast systems. In particular, the broadcast receiving module <b>111</b> may receive a digital broadcast signal using a digital broadcast system such as digital multimedia broadcasting-terrestrial (DM B-T), digital multimedia broadcasting-satellite (DMB-S), media forward link only (MediaFLO), digital video broadcast-handheld (DVB-H), integrated services digital broadcast-terrestrial (ISDB-T), and the like. The broadcast receiving module <b>111</b> is, of course, configured to be suitable for every broadcast system that provides a broadcast signal as well as the above-mentioned digital broadcast systems.</p>
    <p num="p-0050">The broadcast signal and/or broadcast-associated information received through the broadcast receiving module <b>111</b> may be stored in the memory <b>160</b>.</p>
    <p num="p-0051">The mobile communication module <b>112</b> transmits and/or receives a radio signal to and/or from at least one of a base station, an external terminal and a server over a mobile communication network. Here, the radio signal may include a voice call signal, a video call signal and/or various types of data according to text and/or multimedia message transmission and/or reception.</p>
    <p num="p-0052">The wireless Internet module <b>113</b> means a module for supporting wireless Internet access. The wireless Internet module <b>113</b> may be built-in or externally installed to the mobile communication terminal <b>100</b>. Here, it may be used a wireless Internet access technique including a WLAN (Wireless LAN), Wi-Fi, Wibro (Wireless Broadband), Wimax (World Interoperability for Microwave Access), HSDPA (High Speed Downlink Packet Access), and the like.</p>
    <p num="p-0053">The short-range communication module <b>114</b> is a module for supporting a short-range communication. Here, it may be used a short-range communication technology including Bluetooth, Radio Frequency IDentification (RFID), Infrared Data Association (IrDA), Ultra WideBand (UWB), ZigBee, and the like.</p>
    <p num="p-0054">The location information module <b>115</b> is a module for checking or acquiring a location of the mobile communication terminal, and there is a GPS module as a representative example.</p>
    <p num="p-0055">Referring to <figref idrefs="DRAWINGS">FIG. 1</figref>, the A/V (audio/video) input unit <b>120</b> receives an audio or video signal, and the A/V (audio/video) input unit <b>120</b> may include a camera <b>121</b> and a microphone <b>122</b>. The camera <b>121</b> processes a image frame, such as still picture or video, obtained by an image sensor in a video phone call or image capturing mode. The processed image frame may be displayed on a display unit <b>151</b>.</p>
    <p num="p-0056">The image frames processed by the camera <b>121</b> may be stored in the memory <b>160</b> or transmitted to an external device through the wireless communication unit <b>110</b>. Two or more cameras <b>121</b> may be provided according to the use environment of the mobile communication terminal.</p>
    <p num="p-0057">The microphone <b>122</b> receives an external audio signal through a microphone in a phone call mode, a recording mode, a voice recognition mode, and the like, and processes the audio signal into electrical voice data. The processed voice data may be converted and outputted into a format that is transmittable to a mobile communication base station through the mobile communication module <b>112</b> in the phone call mode. The microphone <b>122</b> may implement various types of noise canceling algorithms to cancel noise generated in a procedure of receiving the external audio signal.</p>
    <p num="p-0058">The user input unit <b>130</b> may generate input data to control an operation of the terminal. The user input unit <b>130</b> may be configured by including a keypad, a dome switch, a touch pad (pressure/capacitance), a jog wheel, a jog switch, and the like.</p>
    <p num="p-0059">The sensing unit <b>140</b> detects a current status of the mobile communication terminal <b>100</b> such as an opened or closed status of the mobile communication terminal <b>100</b>, a location of the mobile communication terminal <b>100</b>, an orientation of the mobile communication terminal <b>100</b>, and the like, and generates a sensing signal for controlling the operation of the mobile communication terminal <b>100</b>. For example, when the mobile communication terminal <b>100</b> is a slide phone type, it may sense an opened or closed status of the slide phone. Furthermore, the sensing unit <b>140</b> takes charge of a sensing function associated with whether or not power is supplied from the power supply unit <b>190</b>, or whether or not an external device is coupled to the interface unit <b>170</b>. On the other hand, the sensing unit <b>140</b> may include a proximity sensor <b>141</b>.</p>
    <p num="p-0060">The output unit <b>150</b> is configured to provide an output for audio signal, video signal, or alarm signal, and the output unit <b>150</b> may include the display unit <b>151</b>, an audio output module <b>152</b>, an alarm unit <b>153</b>, a haptic module <b>154</b>, and the like.</p>
    <p num="p-0061">The display unit <b>151</b> may display (output) information processed in the mobile communication terminal <b>100</b>. For example, when the mobile communication terminal <b>100</b> is in a phone call mode, the display unit <b>151</b> may display a User Interface (UI) or a Graphic User Interface (GUI) associated with a call. When the mobile communication terminal <b>100</b> is in a video call mode or image capturing mode, the display unit <b>151</b> may display a captured image and/or received image, a UI or GUI.</p>
    <p num="p-0062">The display unit <b>151</b> may include at least one of a Liquid Crystal Display (LCD), a Thin Film Transistor-LCD (TFT-LCD), an Organic Light Emitting Diode (OLED) display, a flexible display, a three-dimensional (3D) display.</p>
    <p num="p-0063">Some of those displays may be configured with a transparent or optical transparent type to allow viewing of the exterior through the display unit, which may be called transparent displays. An example of the typical transparent displays may include a transparent LCD (TOLED), and the like. Under this configuration, a user can view an object positioned at a rear side of a terminal body through a region occupied by the display unit <b>151</b> of the terminal body.</p>
    <p num="p-0064">The display unit <b>151</b> may be implemented in two or more in number according to a configured aspect of the portable terminal <b>100</b>. For instance, a plurality of the display units <b>151</b> may be arranged on one surface to be spaced apart from or integrated with each other, or may be arranged on different surfaces.</p>
    <p num="p-0065">Here, if the display unit <b>151</b> and a touch sensitive sensor (referred to as a touch sensor) have an interlayer structure, the structure may be referred to as a touch screen. The display unit <b>151</b> may be used as an input device rather than an output device. The touch sensor may be implemented as a touch film, a touch sheet, a touch pad, and the like.</p>
    <p num="p-0066">The touch sensor may be configured to convert changes of a pressure applied to a specific part of the display unit <b>151</b>, or a capacitance occurring from a specific part of the display unit <b>151</b>, into electric input signals. Also, the touch sensor may be configured to sense not only a touched position and a touched area, but also a touch pressure.</p>
    <p num="p-0067">When touch inputs are sensed by the touch sensors, corresponding signals are transmitted to a touch controller (not shown). The touch controller processes the received signals, and then transmits corresponding data to the controller <b>180</b>. Accordingly, the controller <b>180</b> may sense which region of the display unit <b>151</b> has been touched.</p>
    <p num="p-0068">Referring to <figref idrefs="DRAWINGS">FIG. 1</figref>, a proximity sensor <b>141</b> may be arranged at an inner region of the portable terminal <b>100</b> covered by the touch screen, or near the touch screen. The proximity sensor indicates a sensor to sense presence or absence of an object approaching to a surface to be sensed, or an object disposed near a surface to be sensed, by using an electromagnetic field or infrared rays without a mechanical contact. The proximity sensor has a longer lifespan and a more enhanced utility than a contact sensor.</p>
    <p num="p-0069">The proximity sensor may include an optical transmission type photoelectric sensor, a direct reflective type photoelectric sensor, a mirror reflective type photoelectric sensor, a high-frequency oscillation proximity sensor, a capacitance type proximity sensor, a magnetic type proximity sensor, an infrared rays proximity sensor, and so on. When the touch screen is implemented as a capacitance type, proximity of a pointer to the touch screen is sensed by changes of an electromagnetic field. In this case, the touch screen (touch sensor) may be categorized into a proximity sensor.</p>
    <p num="p-0070">Hereinafter, for the sake of convenience of brief explanation, a status that the pointer is positioned to be proximate onto the touch screen without contact will be referred to as proximity touch, whereas a status that the pointer substantially comes in contact with the touch screen will be referred to as contact touch. For the position corresponding to the proximity touch of the pointer on the touch screen, such position corresponds to a position where the pointer faces perpendicular to the touch screen upon the proximity touch of the pointer.</p>
    <p num="p-0071">The proximity sensor senses proximity touch, and proximity touch patterns (e.g., proximity touch distance, proximity touch direction, proximity touch speed, time, proximity touch position, proximity touch moving status, etc.). Information relating to the sensed proximity touch and the sensed proximity touch patterns may be output onto the touch screen.</p>
    <p num="p-0072">The audio output module <b>152</b> may output audio data received from the wireless communication unit <b>110</b> or stored in the memory <b>160</b>, in a call-receiving mode, a call-placing mode, a recording mode, a voice recognition mode, a broadcast reception mode, and so on. The audio output module <b>152</b> may output audio signals relating to functions performed in the portable terminal <b>100</b>, e.g., sound alarming a call received or a message received, and so on. The audio output module <b>152</b> may include a receiver, a speaker, a buzzer, and so on.</p>
    <p num="p-0073">The alarm <b>153</b> outputs signals notifying occurrence of events from the portable terminal <b>100</b>. The events occurring from the portable terminal <b>100</b> may include call received, message received, key signal input, touch input, and so on. The alarm <b>153</b> may output not only video or audio signals, but also other types of signals such as signals notifying occurrence of events in a vibration manner. Since the video or audio signals can be output through the display unit <b>151</b> or the audio output unit <b>152</b>, the display unit <b>151</b> and the audio output module <b>152</b> may be categorized into a part of the alarm <b>153</b>.</p>
    <p num="p-0074">The haptic module <b>154</b> generates various tactile effects which a user can feel. A representative example of the tactile effects generated by the haptic module <b>154</b> includes vibration. Vibration generated by the haptic module <b>154</b> may have a controllable intensity, a controllable pattern, and so on. For instance, different vibration may be output in a synthesized manner or in a sequential manner.</p>
    <p num="p-0075">The haptic module <b>154</b> may generate various tactile effects, including not only vibration, but also arrangement of pins vertically moving with respect to a skin being touched, air injection force or air suction force through an injection hole or a suction hole, touch by a skin surface, presence or absence of contact with an electrode, effects by stimulus such as an electrostatic force, reproduction of cold or hot feeling using a heat absorbing device or a heat emitting device, and the like.</p>
    <p num="p-0076">The haptic module <b>154</b> may be configured to transmit tactile effects through a user's direct contact, or a user's muscular sense using a finger or a hand. The haptic module <b>154</b> may be implemented in two or more in number according to the configuration of the portable terminal <b>100</b>.</p>
    <p num="p-0077">The memory <b>160</b> may store a program for processing and controlling the controller <b>180</b>. Alternatively, the memory <b>160</b> may temporarily store input/output data (e.g., phonebook data, messages, audios, still images, videos, and the like). Also, the memory <b>160</b> may store data related to various patterns of vibrations and sounds outputted upon the touch input on the touch screen.</p>
    <p num="p-0078">The memory <b>160</b> may be implemented using any type of suitable storage medium including a flash memory type, a hard disk type, a multimedia card micro type, a memory card type (e.g., SD or DX memory), Random Access Memory (RAM), Static Random Access Memory (SRAM), Read-Only Memory (ROM), Electrically Erasable Programmable Read-only Memory (EEPROM), Programmable Read-only Memory (PROM), magnetic memory, magnetic disk, optical disk, and the like. Also, the mobile communication terminal <b>100</b> may operate a web storage which performs the storage function of the memory <b>160</b> on the Internet.</p>
    <p num="p-0079">The interface unit <b>170</b> may generally be implemented to interface the portable terminal with external devices. The interface unit <b>170</b> may allow a data reception from an external device, a power delivery to each component in the portable terminal <b>100</b>, or a data transmission from the portable terminal <b>100</b> to an external device. The interface unit <b>170</b> may include, for example, wired/wireless headset ports, external charger ports, wired/wireless data ports, memory card ports, ports for coupling devices having an identification module, audio Input/Output (I/O) ports, video I/O ports, earphone ports, and the like. The identification module may be configured as a chip for storing various information required to authenticate an authority to use the portable terminal <b>100</b>, which may include a User Identity Module (UIM), a Subscriber Identity Module (SIM), and the like. Also, the device having the identification module (hereinafter, referred to as identification device) may be implemented in a type of smart card. Hence, the identification device can be coupled to the portable terminal <b>100</b> via a port.</p>
    <p num="p-0080">Also, the interface unit may serve as a path for power to be supplied from an external cradle to the portable terminal <b>100</b> when the portable terminal <b>100</b> is connected to the external cradle or as a path for transferring various command signals inputted from the cradle by a user to the portable terminal <b>100</b>. Such various command signals or power inputted from the cradle may operate as signals for recognizing that the portable terminal <b>100</b> has accurately been mounted to the cradle.</p>
    <p num="p-0081">The controller <b>180</b> typically controls the overall operations of the portable terminal <b>100</b>. For example, the controller <b>180</b> performs the control and processing associated with telephony calls, data communications, video calls, and the like. The controller <b>180</b> may include a multimedia module <b>181</b> which provides multimedia playback. The multimedia module <b>181</b> may be configured as part of the controller <b>180</b> or as a separate component.</p>
    <p num="p-0082">The controller <b>180</b> can perform a pattern recognition processing so as to recognize writing or drawing input on the touch screen as text or image.</p>
    <p num="p-0083">The power supply unit <b>190</b> provides power required by various components under the control of the controller <b>180</b>.</p>
    <p num="p-0084">On the other hand, according to the embodiments of the present disclosure, the controller <b>180</b> may include a screen lock module <b>200</b>. The screen lock module <b>200</b> will be described in detail with reference to <figref idrefs="DRAWINGS">FIG. 2</figref>.</p>
    <p num="p-0085">On the other hand, according to an embodiment of the present disclosure, the sensing unit <b>140</b> may include at least one sensor for detecting the user's gaze information. The at least one sensor may include at least one acceleration sensor for detecting tilt of the mobile terminal <b>100</b>. The acceleration sensor may measure the acceleration of gravity for earth's gravity to measure a degree of the mobile terminal <b>100</b> being inclined to the surface of the earth. The acceleration sensor may detect an inclined degree of the mobile terminal <b>100</b> against a single axis (x, y, or z-axis) or multiple axes (at least two axes among x, y, and z).</p>
    <p num="p-0086">Furthermore/otherwise, the at least one sensor may include at least one touch sensor for detecting a grip type of the mobile terminal. The at least one touch sensor may be a lateral surface touch sensor, and the lateral surface touch sensor may be provided at a left/right lateral surface of the mobile terminal or both lateral surfaces thereof. Each lateral surface touch sensor may include a plurality of cells for recognizing one touch as an input, and the plurality of cells may be arranged in a grid form. If the user's finger is touched to some cells of the plurality of cells through a lateral surface touch, then the user's grip type may be determined by a combination of some cells touched with the user's finger.</p>
    <p num="p-0087">Furthermore, at least one sensor may include at least one optical sensor for capturing a user's face. The optical sensor may be located at the same surface as the surface provided with the display unit <b>151</b> to capture the user. In this case, a user's face region may be detected from an image in which the user has been captured. For example, the controller <b>180</b> may detect a user's face region from the captured image through an edge extraction, pattern extraction, or the like.</p>
    <p num="p-0088">Various embodiments described herein may be implemented in a computer or similar device readable medium using software, hardware, or any combination thereof.</p>
    <p num="p-0089">For hardware implementation, it may be implemented by using at least one of application specific integrated circuits (ASICs), digital signal processors (DSPs), digital signal processing devices (DSPDs), programmable logic devices (PLDs), field programmable gate arrays (FPGAs), processors, controllers, micro-controllers, microprocessors, and electrical units designed to perform the functions described herein. In some cases, such embodiments may be implemented in the controller <b>180</b> itself.</p>
    <p num="p-0090">For software implementation, the embodiments such as procedures or functions may be implemented together with separate software modules that allow performing of at least one function or operation. Software codes can be implemented by a software application written in any suitable programming language. The software codes may be stored in the memory <b>160</b> and executed by the controller <b>180</b>.</p>
    <p num="p-0091"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a detailed block diagram illustrating a screen lock module <b>200</b> illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
    <p num="p-0092">The screen lock module <b>200</b> according to the embodiments of the present disclosure may include an execution controller <b>210</b> and a change controller <b>220</b>. If a user input is not received through the user input unit <b>130</b> for a preset time (delay time), then the execution controller <b>210</b> may execute screen lock. For example, when the user of the mobile terminal <b>100</b> does not apply a user input for a delay time through the user input unit <b>130</b>, the execution controller <b>210</b> may execute screen lock. In this case, the mobile terminal <b>100</b> enters a screen lock mode, and the user may apply a preset input in the screen lock mode to get out of the screen lock mode.</p>
    <p num="p-0093">The change controller <b>220</b> according to a first embodiment of the present disclosure may change a delay time based on a type of application. Here, the type of application may mean an attribute of the application divided according to a function provided by the application. According to an embodiment, the type of application may be divided according to the kinds of data being approached, used or inputted in the application, such as content-based, messaging service-based, search-based, location information-based, time information-based, and the like.</p>
    <p num="p-0094">For example, the type of application may be stored in the mobile terminal <b>100</b> and checked from the registration information of the application managed by an operating system. The registration information of the application may include an ID for identifying the application, a name of the application, and the like. If an application is executed, for example, then the change controller <b>220</b> may determine and check the type of application based on the name of the application from the registration information of the application.</p>
    <p num="p-0095">Otherwise, the type of application may be checked from the registration information of the application stored in the mobile terminal <b>100</b> and independently managed by an operating system. In this case, the registration information of the application may include an ID for identifying the application, a name of the application, a type of the application, and the like. If an application is executed, for example, then the change controller <b>220</b> may determine and check the type of application from the registration information of the application.</p>
    <p num="p-0096">Furthermore, the change controller <b>220</b> may change a delay time based on the checked type of application. In this case, the change controller <b>220</b> may reduce or extend a delay time based on the checked type of application.</p>
    <p num="p-0097">For example, if a user input is not received for T seconds, then screen lock may be carried out by the execution controller <b>210</b>. In this case, for the type of application being executed, if an input of information may be delayed as in the writing of a message or a display of information may be delayed as in the searching for data, then the change controller <b>220</b> may change the delay time from T to 2T seconds, for example. Accordingly, the execution controller <b>210</b> may not execute screen lock even when T seconds have passed, but may execute screen lock when a user input is not received until 2T seconds have passed.</p>
    <p num="p-0098">Otherwise, for the type of application being executed, if an input or display of information is unnecessary or at least is not delayed as in case of being executed on a background, then the change controller <b>220</b> may change the delay time from T to 0.5T second, for example. Accordingly, the execution controller <b>210</b> may execute screen lock without waiting until T seconds have passed if a user input is not received until 0.5T second has passed.</p>
    <p num="p-0099">The change controller <b>220</b> according to a second embodiment of the present disclosure may change a delay time based on the user's gaze information. Here, the gaze information may mean a line connecting a user's eye to the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>. The change controller <b>220</b> may determine whether the user stares at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> based on the gaze information. Furthermore, the change controller <b>220</b> may determine the user's stare time at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> based on the gaze information.</p>
    <p num="p-0100">According to an embodiment, if a user's input is applied through the user input unit <b>130</b> or visual information is continuously displayed through the display unit <b>151</b>, then tilt of the mobile terminal and/or the user's grip type of the mobile terminal may form a predetermined pattern. For example, a situation requiring a user input such as the writing of a message, a situation requiring a display of visual information such as the reproduction of an image, and a situation where the user merely possesses the mobile terminal <b>100</b> or puts it in his or her pocket may be distinguished by tilt of the mobile terminal <b>100</b> or the user's grip type of the mobile terminal <b>100</b>. In this case, if the tilt of the mobile terminal <b>100</b> or the user's grip type of the mobile terminal <b>100</b> corresponds to a predetermined pattern, then the change controller <b>220</b> may determine it as a state in which the user stares at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>.</p>
    <p num="p-0101">Otherwise, if a user's input is applied through the user input unit <b>130</b> or visual information is continuously displayed through the display unit <b>151</b>, then the user's face region may be detected on an image in which the user has been captured through an optical sensor provided at the same surface as the surface provided with the display unit <b>151</b>. For example, a situation requiring a user input such as the writing of a message, a situation requiring a display of visual information such as the reproduction of an image, and a situation where the user approaches the mobile terminal <b>100</b> to his or her ear or puts it in his or her pocket may be distinguished by the user's face region detected on an image in which the user has been captured. In this case, if a face region is detected on a captured image of the mobile terminal <b>100</b>, then the change controller <b>220</b> may determine it as a state in which the user stares at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>.</p>
    <p num="p-0102">Furthermore, the change controller <b>220</b> may change a delay time based on the user's gaze information. In this case, the change controller <b>220</b> may reduce or extend the delay time based on the user's gaze information.</p>
    <p num="p-0103">For example, if a user input is not received for T seconds, then screen lock may be executed by the execution controller <b>210</b>. If it is determined that the user stares at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>, then the change controller <b>220</b> may change the delay time from T to 2T seconds, for example. Accordingly, the execution controller <b>210</b> may not execute screen lock even when T seconds have passed, but may execute screen lock when a user input is not received until 2T seconds have passed.</p>
    <p num="p-0104">Furthermore, if it is determined that the user does not stare at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>, then the change controller <b>220</b> may change the delay time from T to 0.5 T second, for example. Accordingly, the execution controller <b>210</b> may execute screen lock without waiting until T seconds have passed if a user input is not received until 0.5T second has passed.</p>
    <p num="p-0105">As a result, the execution of screen lock may be advanced or delayed according to the type of application or the user's gaze information, and the execution of screen lock by the controller <b>180</b> may be managed in a flexible manner, thereby reducing inconvenience due to an interrupt that can be generated during the user's input or display of the mobile terminal <b>100</b>, as well as enhancing the effectiveness of a battery.</p>
    <p num="p-0106"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a view for describing a delay time for screen lock execution according to an embodiment of the present disclosure.</p>
    <p num="p-0107">If a user input is not received for a delay time, then the execution controller <b>210</b> may execute screen lock. For example, if there is no application being executed on a foreground in the mobile terminal <b>100</b>, then an idle screen may be displayed on the display unit <b>151</b>. An object <b>310</b> set to call a function provided by the mobile terminal <b>100</b> may be displayed on the idle screen.</p>
    <p num="p-0108">Referring to <figref idrefs="DRAWINGS">FIG. 3</figref>, for example, a time at which all applications being executed on a foreground are terminated to display an idle screen on the display unit <b>151</b> may be START. The execution controller <b>210</b> counts a time until a user input such as an input for selecting the object <b>310</b> is received from the user, for example. If the user input is not received until a preset T seconds have passed, in other words, until the time is END, then the execution controller <b>210</b> may execute screen lock. Accordingly, the idle screen may be switched to a preset screen including an item <b>320</b> indicating screen lock.</p>
    <p num="p-0109"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a view for describing the change of a delay time for screen lock execution according to an embodiment of the present disclosure.</p>
    <p num="p-0110">The change controller <b>220</b> may change a delay time based on the type of application. Here, the change controller <b>220</b> may reduce or extend a delay time based on the type of application.</p>
    <p num="p-0111">Referring to <figref idrefs="DRAWINGS">FIG. 4</figref>, for example, a time when a phone book is executed in the mobile terminal <b>100</b> and contact information <b>410</b> is displayed on the display unit <b>151</b> of the mobile terminal <b>100</b> may be START. In this case, the change controller <b>220</b> may check the type of application. The execution controller <b>210</b>, for example, counts a time until a user input such as an input for terminating the display of contact information is received from the user.</p>
    <p num="p-0112">The change controller <b>220</b> may change a delay time, T seconds, based on the type of application. If a delay time of screen lock execution corresponding to the type of application is 2T, then the change controller <b>220</b> may change the delay time of screen lock execution that can be approached by the execution controller <b>210</b> from T to 2T. Accordingly, a display screen of the contact information <b>410</b> may be switched to a preset screen including an item <b>420</b> indicating screen lock after 2T has passed by the execution controller <b>210</b>.</p>
    <p num="p-0113">Otherwise, if a delay time of screen lock execution corresponding to the type of application is 0.5T, then the change controller <b>220</b> may change the delay time of screen lock execution that can be approached by the execution controller <b>210</b> from T to 0.5T. Accordingly, a display screen of the contact information <b>410</b> may be switched to a preset screen including an item <b>420</b> indicating screen lock after 0.5T has passed by the execution controller <b>210</b>.</p>
    <p num="p-0114"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a view for describing the change of a delay time for screen lock execution in a content-based application according to a first embodiment of the present disclosure.</p>
    <p num="p-0115">When an application being executed is a content-based application, the change controller <b>220</b> may change a delay time based on the reproduction information of content. For example, the content-based application may include video player, music player, photo viewer, and the like.</p>
    <p num="p-0116">Referring to <figref idrefs="DRAWINGS">FIG. 5</figref>, for example, an application for playing content may be executed in the mobile terminal <b>100</b>, and a content reproduction screen <b>510</b> may be displayed on the display unit <b>151</b>. Furthermore, a reproduction control region <b>520</b> of content may be further displayed on the display unit <b>151</b> together with the content reproduction screen <b>510</b>. The change controller <b>220</b> may check that the type of application being executed is a content-based application, and may check a delay time for the content-based application. Furthermore, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> to the checked delay time.</p>
    <p num="p-0117">Furthermore, in this case, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> according to the reproduction information of content. For example, the change controller <b>220</b> may change a delay time to delay screen lock execution if the content is being reproduced, and change a delay time to advance screen lock execution if the content is not being reproduced.</p>
    <p num="p-0118"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a view for describing the change of a delay time for screen lock execution in a search-based application according to a first embodiment of the present disclosure.</p>
    <p num="p-0119">When an application being executed is a search-based application, the change controller <b>220</b> may change a delay time based on an input time or search time of search word. The search-based application may include web browser, phone book, file explorer, and the like.</p>
    <p num="p-0120">Referring to <figref idrefs="DRAWINGS">FIG. 6</figref>, for example, an application for searching for information may be executed in the mobile terminal <b>100</b>, and an information search screen may be displayed on the display unit <b>151</b>. The information search screen may include a key input interface <b>610</b> and a search word display region <b>620</b>. The change controller <b>220</b> may check that the type of application being executed is a search-based application, and check a delay time for the search-based application. Furthermore, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> to the checked delay time.</p>
    <p num="p-0121">Furthermore, in this case, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> according to an input time or search time of search word. For example, the change controller <b>220</b> may change a delay time to a time in which the user's search word input time (for example, an average time consumed from an input start time of search word (an input time of the first letter (or, numeral or symbol) of search word) to an input end time (an input time of search command)) is added to the delay time. Furthermore, the change controller <b>220</b> may change a delay time to a time in which the information search time of an application (for example, an average time consumed from an search start time (an input time of search command) to an search end time (a display time of searched information)) is added to the delay time. An item <b>630</b> indicating that information is being searched may be further displayed on the display unit <b>151</b> during the information search of an application.</p>
    <p num="p-0122"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a view for describing the change of a delay time for screen lock execution in a messaging service-based application according to a first embodiment of the present disclosure.</p>
    <p num="p-0123">When an application being executed is a messaging service-based application, the change controller <b>220</b> may change a delay time based on an input time of message. The messaging service may be any one of a text message service, an instant message service, and an email service. Furthermore, the text message service may be any one of a short message service, a multimedia message service, and an enhanced message service.</p>
    <p num="p-0124">Referring to <figref idrefs="DRAWINGS">FIG. 7</figref>, for example, an application for writing a message is executed in the mobile terminal <b>100</b>, and a message preparation screen may be displayed on the display unit <b>151</b>. The message preparation screen may include a key input interface <b>710</b>, a receiver information display region <b>720</b>, and a message content display region <b>730</b>. The change controller <b>220</b> may check that the type of application being executed is a messaging service-based application, and check a delay time for the messaging service-based application. Furthermore, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> to the checked delay time.</p>
    <p num="p-0125">Furthermore, in this case, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> according to an input time of message. For example, the change controller <b>220</b> may change a delay time to a time in which the user's search word input time (for example, an average time consumed from the user's input start time of message content (an input time of the first letter (or, numeral or symbol) of message content) to an input end time (an input time of message content input complete command or message transmission command)) is added to the delay time.</p>
    <p num="p-0126"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a view for describing the change of a delay time for screen lock execution in a location information-based application according to a first embodiment of the present disclosure.</p>
    <p num="p-0127">When an application being executed is a location information-based application, the change controller <b>220</b> may change a delay time based on a change of location information. The location information-based application may include navigation (road guide), traffic information, map application, and the like.</p>
    <p num="p-0128">Referring to <figref idrefs="DRAWINGS">FIG. 8</figref>, for example, an application for displaying road guide information may be executed in the mobile terminal <b>100</b>, and a display screen of road guide information may be displayed on the display unit <b>151</b>. The display screen of road guide information may further include a map information display region <b>810</b>, a road guide information display region <b>820</b>, and a turn information display region <b>830</b>. The change controller <b>220</b> may check that the type of application being executed is a location information-based application, and may check a delay time for the location information-based application. Furthermore, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> to the checked delay time.</p>
    <p num="p-0129">Furthermore, in this case, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> according to a change of location information. For example, the change controller <b>220</b> may change a delay time to delay screen lock execution if the location information is being changed, and change a delay time to advance screen lock execution if the location information is not being changed.</p>
    <p num="p-0130"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a view for describing the change of a delay time for screen lock execution in a time information-based application according to a first embodiment of the present disclosure.</p>
    <p num="p-0131">When an application being executed is a time information-based application, the change controller <b>220</b> may change a delay time based on a change of time information. The time information-based application may include alarm, scheduler, traffic information, and the like.</p>
    <p num="p-0132">Referring to <figref idrefs="DRAWINGS">FIG. 9</figref>, for example, an application for displaying traffic information may be executed in the mobile terminal <b>100</b>, and a display screen of traffic information may be displayed on the display unit <b>151</b>. The display screen of traffic information may further include a location display region <b>910</b>, a traffic information display region <b>920</b>, and a refresh menu display region <b>930</b>. The change controller <b>220</b> may check that the type of application being executed is a time-based application, and may check a delay time for the time-based application. Furthermore, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> to the checked delay time.</p>
    <p num="p-0133">Furthermore, in this case, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b> according to a change of time information. For example, if information displayed on traffic information display region <b>920</b> is being changed according to time variation (i.e., if refreshed periodically), then the change controller <b>220</b> may change a delay time to delay screen lock execution. Furthermore, if information displayed on traffic information display region <b>920</b> is not being changed according to time variation, then the change controller <b>220</b> may change a delay time to advance screen lock execution.</p>
    <p num="p-0134"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a view for describing the change of a delay time for screen lock execution in an application that can approach security set data according to a first embodiment of the present disclosure.</p>
    <p num="p-0135">The change controller <b>220</b> may change a delay time based on security setting for an object being approached by an application. For example, the change controller <b>220</b> may check security setting for an object being approached by an application to change a delay time based on the security setting.</p>
    <p num="p-0136">Referring to <figref idrefs="DRAWINGS">FIG. 10</figref>, for example, an application displaying an object <b>1010</b> (for example, content) is being executed, and the change controller <b>220</b> may change a delay time based on the type of application. The security setting for an object may include a public setting capable of immediately approaching an object without an authentication key and a non-public setting capable of approaching an object only by inputting an authentication key. If security setting for an object being approached by an application is non-public, the extension of a delay time may be restricted, but only the reduction of a delay time may be allowed. Accordingly, it may be possible to prevent worry of harming the security of an object due to the extension of a delay time to an object with a non-public setting.</p>
    <p num="p-0137"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a view for describing the change of a delay time for screen lock execution in an application by which an interrupt has been generated according to a first embodiment of the present disclosure.</p>
    <p num="p-0138">The change controller <b>220</b> may change a delay time based on an interrupt generated by an application. The change controller <b>220</b> may monitor the generation of an interrupt such as notification of a message arrival event in the application to change a start time of the delay time to an interrupt generation time when an interrupt has been generated. The execution controller <b>210</b> may count a delay time of screen lock execution again from the changed start time of the delay time.</p>
    <p num="p-0139">Referring to <figref idrefs="DRAWINGS">FIG. 11</figref>, for example, an application for writing a message is executed in the mobile terminal <b>100</b>, and a message writing screen may be displayed on the display unit <b>151</b>. The message writing screen may include a key input interface <b>1112</b>, <b>1122</b>, a receiver information display region <b>1114</b>, <b>1124</b>, and a message content display region <b>1116</b>, <b>1126</b>. A start time of the delay time of screen lock execution by the execution controller <b>210</b> may be START<b>1</b> that has received the last input. For example, if the notification of a message arrival event is generated in the application, then a message arrival event <b>1128</b> may be displayed on the screen. In this case, the change controller <b>220</b> may change the start time of the delay time of screen lock execution to START<b>2</b>, which is a time at which the notification of a message arrival event has been generated. The execution controller <b>210</b> may count the delay time of screen lock execution again from START<b>2</b>.</p>
    <p num="p-0140"> <figref idrefs="DRAWINGS">FIG. 12</figref> is a view illustrating the structure of a delay time information table according to a type of application according to a first embodiment of the present disclosure.</p>
    <p num="p-0141">A delay time information table <b>1200</b> according to a first embodiment of the present disclosure may include an application type field (APPLICATION_TYPE) and a delay time field (DURATION_TIME). The application type field may include information on the type of application divided by a function provided by the application. The delay time field may include information on a delay time of screen lock execution by the execution controller <b>210</b> according to the type of application. According to an embodiment, a reference delay time for which screen lock is executed by the execution controller <b>210</b> may be T, and a delay time of screen lock execution for an application not included in the application type field may be T.</p>
    <p num="p-0142"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a view illustrating the structure of a delay time information table according to a type of parameter according to a first embodiment of the present disclosure.</p>
    <p num="p-0143">A delay time information table <b>1300</b> according to a first embodiment of the present disclosure may include an parameter type field (PARAMETER_TYPE) and a delay time field (DURATION_TIME). The parameter type field may include information on the type of application divided by a different function provided by the same application. The parameter type may be information on parameters associated with a function provided by the application such as reproduction information of content, an input or search time of search word, an input time of message, a change of location information, a change of time information, or the like. The delay time field may include information on a delay time of screen lock execution by the execution controller <b>210</b> according to the type of parameter.</p>
    <p num="p-0144"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a flow chart illustrating the process of changing a delay time for screen lock execution according to a first embodiment of the present disclosure.</p>
    <p num="p-0145">If an application is executed, for example, then the change controller <b>220</b> may check the executed type of application (S<b>110</b>). The type of application may be checked from the registration information of an application stored in the mobile terminal <b>100</b> and managed by an operating system. Otherwise, the type of application may be checked from the registration information of an application stored in the mobile terminal <b>100</b> and independently managed by an operating system.</p>
    <p num="p-0146">Furthermore, the change controller <b>220</b> may change a delay time based on the checked type of application (S<b>120</b>). In this case, the change controller <b>220</b> may reduce or extend a delay time based on the checked type of application.</p>
    <p num="p-0147">Furthermore, the execution controller <b>210</b> may check whether the delay time has been changed (S<b>130</b>), and execute screen lock if a user input is not received for the delay time when the delay time has not been changed (S<b>140</b>). If a user input is not received for the changed delay time when the delay time has been changed, then the execution controller <b>210</b> may execute screen lock for the changed delay time (S<b>150</b>).</p>
    <p num="p-0148"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a conceptual view for describing user's gaze information according to a second embodiment of the present disclosure.</p>
    <p num="p-0149">The change controller <b>220</b> may change a delay time based on the display unit <b>151</b> detected through the sensing unit <b>140</b> or the user's gaze information on visual information displayed on the display unit <b>151</b>. The change controller <b>220</b> may reduce or extend a delay time based on user's gaze information. Furthermore, the change controller <b>220</b> may determine whether to stare at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> or a stare time at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> based on the user's gaze information, and change a delay time based on whether to stare or the stare time.</p>
    <p num="p-0150">Referring to <figref idrefs="DRAWINGS">FIG. 15</figref>, for example, visual information may be displayed on the display unit <b>151</b> of the mobile terminal <b>100</b>, and the user may apply a user input to the mobile terminal <b>100</b> or check visual information displayed on the mobile terminal <b>100</b>. In this case, the change controller <b>220</b> may check the user's gaze information <b>1400</b>, namely, information on a line connecting a user's eye to the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>. Furthermore, the change controller <b>220</b> may determine whether the user stares at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> based on the gaze information. Furthermore, the change controller <b>220</b> may determine the user's stare time at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> based on the gaze information. The change controller <b>220</b> may change a delay time based on whether the user stares at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> or the stare time at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>.</p>
    <p num="p-0151">For example, if it is determined that the user stares at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>, then the change controller <b>220</b> may change a delay time to delay screen lock execution by the execution controller <b>210</b>. If it is determined that the user does not stare at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>, then the change controller <b>220</b> may change a delay time to advance screen lock execution by the execution controller <b>210</b>.</p>
    <p num="p-0152">Furthermore, for example, if it is determined that the user gazes at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> for more than a threshold time, then the change controller <b>220</b> changes a delay time to delay screen lock execution by the execution controller <b>210</b>. Furthermore, if it is determined that the user gazes at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> for less than a threshold time, then the change controller <b>220</b> may not change a delay time.</p>
    <p num="p-0153"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a view for describing the change of a delay time for screen lock execution based on a tilt pattern according to a second embodiment of the present disclosure.</p>
    <p num="p-0154">The user's gaze information may include information on tilt of the mobile terminal <b>100</b>. In this case, the sensing unit <b>140</b> may include at least one acceleration sensor, and if the tilt of the mobile terminal <b>100</b> is detected by the sensing unit <b>140</b>, then the change controller <b>220</b> may check whether there is the user' gaze or a gaze time based on, for example, a prestored tilt pattern when the user executes an application or releases screen lock.</p>
    <p num="p-0155">Referring to <figref idrefs="DRAWINGS">FIG. 16</figref>, for example, if the tilt of the mobile terminal <b>100</b> is measured as a by the sensing unit <b>140</b> with reference to the central axis, then the change controller <b>220</b> may determine whether a is included in a prestored tilt pattern. If a is included in the prestored tilt pattern, then the change controller <b>220</b> may change a delay time. For example, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b>, or change a start time of the screen lock execution delay time to a time at which a tilt has been detected by the sensing unit <b>140</b>.</p>
    <p num="p-0156"> <figref idrefs="DRAWINGS">FIG. 17</figref> is a view for describing the change of a delay time for screen lock execution based on a tilt pattern according to a second embodiment of the present disclosure.</p>
    <p num="p-0157">Referring to <figref idrefs="DRAWINGS">FIG. 17</figref>, for example, if the tilt of the mobile terminal <b>100</b> is measured as  by the sensing unit <b>140</b> with reference to the central axis, then the change controller <b>220</b> may determine whether  is included in a prestored tilt pattern. If  is included in the prestored tilt pattern, then the change controller <b>220</b> may change a delay time. Here, the angle  of <figref idrefs="DRAWINGS">FIG. 16</figref> and the angle  of <figref idrefs="DRAWINGS">FIG. 17</figref> are different, but both the angles  and  may be included in the tilt pattern since there may be a plurality of tilt patterns. For example, tilt patterns may be different from each other when the user sits on a chair to use the mobile terminal <b>100</b> and when the user lays down on a bed to use the mobile terminal <b>100</b>.</p>
    <p num="p-0158"> <figref idrefs="DRAWINGS">FIG. 18</figref> is a view for describing the change of a delay time for screen lock execution based on a grip pattern according to a second embodiment of the present disclosure.</p>
    <p num="p-0159">The user's gaze information may include information on the user's grip type of the mobile terminal <b>100</b>. In this case, the sensing unit <b>140</b> may include a touch sensor, and if a grip type is detected by the sensing unit <b>140</b>, then the change controller <b>220</b> may check whether there is the user' gaze or a gaze time based on, for example, a prestored grip pattern when the user executes an application or releases screen lock.</p>
    <p num="p-0160">Referring to <figref idrefs="DRAWINGS">FIG. 18</figref>, for example, the sensing unit <b>140</b> may include a plurality of lateral surface touch sensors <b>1510</b>, <b>1520</b>, and each lateral surface touch sensor may be configured with a plurality of cells capable of accommodating one touch input. The sensing unit <b>140</b> may detect a combination of touch inputs applied to a plurality of cells included in each lateral surface touch sensor. The change controller <b>220</b> may compare the detected combination of touch inputs with a prestored grip type pattern, and change a delay time when a combination of touch inputs detected by the sensing unit <b>140</b> is included in the prestored grip type pattern. For example, the change controller <b>220</b> may change a delay time of screen lock execution by the execution controller <b>210</b>, or change a start time of the screen lock execution delay time to a time at which a tilt has been detected by the sensing unit <b>140</b>.</p>
    <p num="p-0161">On the other hand, according to an embodiment of the present disclosure, the user's gaze information may include information on tilt of the mobile terminal <b>100</b> and information on the user's grip type of the mobile terminal <b>100</b>. In this case, the change controller <b>220</b> may change a delay time based on information on the tilt of the mobile terminal <b>100</b> and information on the user's grip type of the mobile terminal <b>100</b>.</p>
    <p num="p-0162"> <figref idrefs="DRAWINGS">FIG. 19</figref> is a view for describing the change of a delay time for screen lock execution based on a face region detection according to a second embodiment of the present disclosure.</p>
    <p num="p-0163">The user's gaze information may include information on whether the user's face region is detected on an image in which the user has been captured. The change controller <b>220</b> may capture the user through an optical sensor included in the camera <b>121</b> or sensing unit <b>140</b>. In this case, the optical sensor included in the camera <b>121</b> or sensing unit <b>140</b> may be provided on the same surface as the surface provided with the display unit <b>151</b>. The change controller <b>220</b> may capture the user through an optical sensor included in the camera <b>121</b> or sensing unit <b>140</b> to acquire a captured image. Furthermore, the change controller <b>220</b> may detect the user's face region from the captured image through an edge extraction, pattern extraction, or the like to determine the user's gaze information based on the detected face region.</p>
    <p num="p-0164">Referring to <figref idrefs="DRAWINGS">FIG. 19</figref>, for example, the change controller <b>220</b> may acquire an image <b>1600</b> in which the user has been captured through an optical sensor included in the camera <b>121</b> or sensing unit <b>140</b>. Furthermore, the change controller <b>220</b> may detect a face region <b>1610</b> from the image <b>1600</b> in which the user has been captured to determine the user's gaze information according to whether the face region has been detected or a size of the detected face region.</p>
    <p num="p-0165">For example, if a size of the face region <b>1610</b> detected from the image <b>1600</b> in which the user has been captured is larger than a threshold value, then the change controller <b>220</b> may determine that the user gazes at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b>. According to the embodied example, the change controller <b>220</b> may detect an eye's shape or pupil's shape even in the user's face region, and determine whether the user gazes at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> according to a state of eyes open or closed, a direction of gaze, or the like.</p>
    <p num="p-0166"> <figref idrefs="DRAWINGS">FIGS. 20A-20C</figref> are views illustrating the structure of a delay time information table according to gaze information according to a second embodiment of the present disclosure.</p>
    <p num="p-0167"> <figref idrefs="DRAWINGS">FIG. 20A</figref> is a view illustrating the structure of a delay time information table according to a second embodiment of the present disclosure. Referring to <figref idrefs="DRAWINGS">FIG. 20A</figref>, the delay time information table may include a tilt pattern field (ANGLE_PATTERN) and a delay time field (DURATION_TIME). The tilt pattern field may include information on a tilt pattern of the mobile terminal <b>100</b> in a situation requiring the user's gaze at visual information when the user executes an application or releases screen lock. The tilt pattern may be a set of predetermined tilt. Furthermore, the change controller <b>220</b> may collect tilt information according to the user's pattern of using the mobile terminal <b>100</b> to generate or change a tilt pattern. The delay time field may include information on a delay time of screen lock execution by the execution controller <b>210</b> according to a tilt pattern. According to an embodiment, a reference delay time for which screen lock is carried out by the execution controller <b>210</b> may be T, and a delay time of screen lock execution for the tilt not included in the tilt pattern field may be T.</p>
    <p num="p-0168"> <figref idrefs="DRAWINGS">FIG. 20B</figref> is a view illustrating the structure of a delay time information table according to a second embodiment of the present disclosure. Referring to <figref idrefs="DRAWINGS">FIG. 20B</figref>, the delay time information table may include a grip type pattern field (GRIP_TYPE_PATTERN) and a delay time field (DURATION_TIME). The grip type pattern field may include information on a grip type pattern of the mobile terminal <b>100</b> in a situation requiring the user's gaze at visual information when the user executes an application or releases screen lock. The grip type pattern may be a set of predetermined grip types. Furthermore, the change controller <b>220</b> may collect grip types according to the user's pattern of using the mobile terminal <b>100</b> to generate or change a grip type pattern. The delay time field may include information on a delay time of screen lock execution by the execution controller <b>210</b> according to a grip type pattern. According to an embodiment, a reference delay time for which screen lock is carried out by the execution controller <b>210</b> may be T, and a delay time of screen lock execution for the grip type not included in the grip type pattern field may be T.</p>
    <p num="p-0169"> <figref idrefs="DRAWINGS">FIG. 20C</figref> is a view illustrating the structure of a delay time information table according to a second embodiment of the present disclosure. The delay time information table may include an application type field (APPLICATION_TYPE) and a delay time field (DURATION_TIME). The application type field may include information on an application type of the mobile terminal <b>100</b> divided according to whether an application requires the user's stare at visual information. The change controller <b>220</b> may change a delay time based on the type of application displaying visual information. The delay time field may include information on a delay time of screen lock execution by the execution controller <b>210</b> according to a application type. According to an embodiment, a reference delay time for which screen lock is carried out by the execution controller <b>210</b> may be T, and a delay time of screen lock execution may be larger than T if the type of application is an application requiring the user's stare at visual information, and the delay time of screen lock execution may be less than T if the type of application is an application not requiring the user's stare at visual information.</p>
    <p num="p-0170"> <figref idrefs="DRAWINGS">FIG. 21</figref> is a flow chart illustrating the process of changing a delay time for screen lock execution according to a second embodiment of the present disclosure.</p>
    <p num="p-0171">The change controller <b>220</b> may check the user's gaze information at the display unit <b>151</b> or visual information displayed on the display unit <b>151</b> (S<b>210</b>). The change controller <b>220</b> may check gaze information including tilt of the mobile terminal <b>100</b>, a user's grip type for the mobile terminal <b>100</b>, or whether a face region is detected on an image in which the user has been captured.</p>
    <p num="p-0172">Furthermore, the change controller <b>220</b> may change a delay time based on the checked gaze information (S<b>220</b>). In this case, the change controller <b>220</b> may reduce or extend a delay time based on the gaze information.</p>
    <p num="p-0173">Furthermore, the execution controller <b>210</b> may check whether the delay time has been changed (S<b>230</b>), and execute screen lock if a user input is not received for the delay time when the delay time has not been changed (S<b>240</b>). If a user input is not received for the changed delay time when the delay time has been changed, then the execution controller <b>210</b> may execute screen lock for the changed delay time (S<b>250</b>).</p>
    <p num="p-0174">According to an embodiment of the present disclosure, the mobile terminal recognizes the user's expected operation or status to dynamically control an interrupt of an input or display that can be generated at an interface, thereby providing a user-friendly interface environment. Accordingly, the utilization of a screen lock function may be maximized, and particularly, the use for various applications provided by the mobile terminal may be also maximized, and a battery may be effectively managed, thereby providing an advantage of enhancing the use of the mobile terminal.</p>
    <p num="p-0175">A mobile terminal disclosed herein may include all kinds of terminals capable of transmitting and receiving a text message, such as a portable phone, a smart phone, a laptop computer, a digital broadcast terminal, a personal digital assistant (PDA), a portable multimedia player (PMP), a navigation, and the like. The configurations and methods according to the above-described embodiments will not be applicable in a limited way, and all or part of each embodiment may be selectively combined and configured to make various modifications thereto.</p>
    <p num="p-0176">Here, the terms and words used herein and the claims should not be construed by limiting to their typical or lexical meaning, but should be construed based on the meaning and concept conforming to the technical spirit of the present invention. Accordingly, the configuration illustrated in the embodiments disclosed herein and the drawings is merely one embodiment of the present invention, and is not intended to represent all the technical spirit of the present invention, and thereby it should be appreciated that there may exist various equivalents and modifications for substituting those at the time of filing this application.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6665805">US6665805</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 1999</td><td class="patent-data-table-td patent-date-value">Dec 16, 2003</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and apparatus for real time monitoring of user presence to prolong a portable computer battery operation time</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7091471">US7091471</a></td><td class="patent-data-table-td patent-date-value">Mar 15, 2004</td><td class="patent-data-table-td patent-date-value">Aug 15, 2006</td><td class="patent-data-table-td ">Agilent Technologies, Inc.</td><td class="patent-data-table-td ">Using eye detection for providing control and power management of electronic devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20050198661">US20050198661</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2005</td><td class="patent-data-table-td patent-date-value">Sep 8, 2005</td><td class="patent-data-table-td ">Andrew Collins</td><td class="patent-data-table-td ">Display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070078552">US20070078552</a></td><td class="patent-data-table-td patent-date-value">Nov 21, 2006</td><td class="patent-data-table-td patent-date-value">Apr 5, 2007</td><td class="patent-data-table-td ">Outland Research, Llc</td><td class="patent-data-table-td ">Gaze-based power conservation for portable media players</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080118152">US20080118152</a></td><td class="patent-data-table-td patent-date-value">Nov 20, 2006</td><td class="patent-data-table-td patent-date-value">May 22, 2008</td><td class="patent-data-table-td ">Sony Ericsson Mobile Communications Ab</td><td class="patent-data-table-td ">Using image recognition for controlling display lighting</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080303443">US20080303443</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 6, 2008</td><td class="patent-data-table-td patent-date-value">Dec 11, 2008</td><td class="patent-data-table-td ">Tektronix, Inc.</td><td class="patent-data-table-td ">Position lock trigger</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090082066">US20090082066</a></td><td class="patent-data-table-td patent-date-value">Sep 26, 2007</td><td class="patent-data-table-td patent-date-value">Mar 26, 2009</td><td class="patent-data-table-td ">Sony Ericsson Mobile Communications Ab</td><td class="patent-data-table-td ">Portable electronic equipment with automatic control to keep display turned on and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100259387">US20100259387</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 30, 2009</td><td class="patent-data-table-td patent-date-value">Oct 14, 2010</td><td class="patent-data-table-td ">Shenzhen Futaihong Precision Industry Co., Ltd.</td><td class="patent-data-table-td ">Electronic device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=OEKxBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DKR%26NR%3D20020093426A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHnamU_WXC6Ts-y4Z1G1sfhsqJ6PA">KR20020093426A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=OEKxBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DKR%26NR%3D20040026560A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFsUlISnbl3Y3aS0h5iZPCDcynW1w">KR20040026560A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=OEKxBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DKR%26NR%3D20060044206A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGLPTBrHMe6i_GbYp4LHwEeb_LfKA">KR20060044206A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=OEKxBwABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DKR%26NR%3D20100053144A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGaba9xdCh_VYoxYeF6LgoFQ_EFcw">KR20100053144A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc455/defs455.htm&usg=AFQjCNFL3EGhrZhenbDalCuSOJ_Q_FR4Vw#C455S566000">455/566</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375S371000">375/371</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc340/defs340.htm&usg=AFQjCNGk_NCDWkt8oMijCQ2jvfqday0GbA#C340S571000">340/571</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04W0088020000">H04W88/02</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W52/027">H04W52/027</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M2250/12">H04M2250/12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M2250/52">H04M2250/52</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W52/0254">H04W52/0254</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F1/3231">G06F1/3231</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/005">G06F3/005</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W4/001">H04W4/001</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M2250/22">H04M2250/22</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W4/025">H04W4/025</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M1/67">H04M1/67</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W4/008">H04W4/008</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F1/1694">G06F1/1694</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W12/08">H04W12/08</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/013">G06F3/013</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=OEKxBwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W88/02">H04W88/02</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04W4/00A</span>, <span class="nested-value">H04M1/67</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Apr 29, 2014</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 2-4 AND 11-13 ARE CANCELLED.CLAIMS 1, 5-7, 10 AND 14-17 ARE DETERMINED TO BE PATENTABLE AS AMENDED.CLAIM 8, DEPENDENT ON AN AMENDED CLAIM, IS DETERMINED TO BE PATENTABLE.CLAIMS 9 AND 18 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 24, 2013</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20130731</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4ff636b3d23669b7103f3b3a3a18b4cd.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U3MWq1TWGSDoVjgsI3ZcbQNOQy3dQ\u0026id=OEKxBwABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U2RlPdelI9uCbO6SUzqzBq_tIcSSA\u0026id=OEKxBwABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U0h11anfhs1oxRZDKUfsk-n3KFrvQ","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Mobile_terminal_and_operation_control_me.pdf?id=OEKxBwABERAJ\u0026output=pdf\u0026sig=ACfU3U0jGGEXNN9xko2Qe-l8KoU0Zz1RkA"},"sample_url":"http://www.google.com/patents/reader?id=OEKxBwABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>