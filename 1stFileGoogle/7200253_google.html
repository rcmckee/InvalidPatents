<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7200253 - Motility analysis within a gastrointestinal tract - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4ff636b3d23669b7103f3b3a3a18b4cd/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4ff636b3d23669b7103f3b3a3a18b4cd__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Motility analysis within a gastrointestinal tract"><meta name="DC.contributor" content="Arkady Glukhovsky" scheme="inventor"><meta name="DC.contributor" content="Gavriel Meron" scheme="inventor"><meta name="DC.contributor" content="Ofra Zinaty" scheme="inventor"><meta name="DC.contributor" content="Given Imaging Ltd." scheme="assignee"><meta name="DC.date" content="2005-8-11" scheme="dateSubmitted"><meta name="DC.description" content="A system and method for measuring and analyzing motility within a body lumen such as the gastrointestinal (GI) tract, where an in vivo imaging device such as a capsule captures images and transmits the images to a processor, which calculates the motility of the device based on comparison of the images. Preferably, the processor compares the intensity of pairs of images or of elements of pairs of images, generates a variance for the compared images, and calculates the motility of the imaging device from the variances. The motility data may be presented to a user in various manners; for example, a plot of motility over time may be generated, or indications of low motility may be presented to the user of the system."><meta name="DC.date" content="2007-4-3" scheme="issued"><meta name="DC.relation" content="US:20020103417:A1" scheme="references"><meta name="DC.relation" content="US:4278077" scheme="references"><meta name="DC.relation" content="US:5604531" scheme="references"><meta name="DC.relation" content="US:5993378" scheme="references"><meta name="DC.relation" content="US:6240312" scheme="references"><meta name="DC.relation" content="US:6428469" scheme="references"><meta name="DC.relation" content="US:6621917" scheme="references"><meta name="DC.relation" content="US:6709387" scheme="references"><meta name="citation_reference" content="PCT Search Report International Application No.: PCT/IL02/00386 International Filing Date: May 19, 2002."><meta name="citation_reference" content="Rowell, Nancy D., Endoscopes Go Wireless Biophotonics In Action Photonics Spectra Mar. 2001."><meta name="citation_patent_number" content="US:7200253"><meta name="citation_patent_application_number" content="US:11/201,217"><link rel="canonical" href="http://www.google.com/patents/US7200253"/><meta property="og:url" content="http://www.google.com/patents/US7200253"/><meta name="title" content="Patent US7200253 - Motility analysis within a gastrointestinal tract"/><meta name="description" content="A system and method for measuring and analyzing motility within a body lumen such as the gastrointestinal (GI) tract, where an in vivo imaging device such as a capsule captures images and transmits the images to a processor, which calculates the motility of the device based on comparison of the images. Preferably, the processor compares the intensity of pairs of images or of elements of pairs of images, generates a variance for the compared images, and calculates the motility of the imaging device from the variances. The motility data may be presented to a user in various manners; for example, a plot of motility over time may be generated, or indications of low motility may be presented to the user of the system."/><meta property="og:title" content="Patent US7200253 - Motility analysis within a gastrointestinal tract"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("3mnoU570EKKlsASTzoGYBw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407291699.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("NLD"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("3mnoU570EKKlsASTzoGYBw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407291699.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("NLD"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7200253?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7200253"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=FNp6BAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7200253&amp;usg=AFQjCNHWDDhOOVNeDEZXH-y8x1XjDSymcg" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7200253.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7200253.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20050281446"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US7200253"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7200253" style="display:none"><span itemprop="description">A system and method for measuring and analyzing motility within a body lumen such as the gastrointestinal (GI) tract, where an in vivo imaging device such as a capsule captures images and transmits the images to a processor, which calculates the motility of the device based on comparison of the images....</span><span itemprop="url">http://www.google.com/patents/US7200253?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7200253 - Motility analysis within a gastrointestinal tract</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7200253 - Motility analysis within a gastrointestinal tract" title="Patent US7200253 - Motility analysis within a gastrointestinal tract"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7200253 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 11/201,217</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Apr 3, 2007</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Aug 11, 2005</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jun 20, 2001</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6944316">US6944316</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20030077223">US20030077223</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20050281446">US20050281446</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2002102223A2">WO2002102223A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2002102223A3">WO2002102223A3</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">11201217, </span><span class="patent-bibdata-value">201217, </span><span class="patent-bibdata-value">US 7200253 B2, </span><span class="patent-bibdata-value">US 7200253B2, </span><span class="patent-bibdata-value">US-B2-7200253, </span><span class="patent-bibdata-value">US7200253 B2, </span><span class="patent-bibdata-value">US7200253B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Arkady+Glukhovsky%22">Arkady Glukhovsky</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Gavriel+Meron%22">Gavriel Meron</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Ofra+Zinaty%22">Ofra Zinaty</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Given+Imaging+Ltd.%22">Given Imaging Ltd.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7200253.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7200253.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7200253.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (8),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (2),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (14),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (10),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7200253&usg=AFQjCNEB_vYx0UjU3Qq-ob7HeVOEwgnLXA">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7200253&usg=AFQjCNGn-yDB43OGdWK3_P-YpW3LzmDHBg">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7200253B2%26KC%3DB2%26FT%3DD&usg=AFQjCNFNwov_6vo1-vauAF-G1flf-eNIeg">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55723634" lang="EN" load-source="patent-office">Motility analysis within a gastrointestinal tract</invention-title></span><br><span class="patent-number">US 7200253 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA51131114" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">A system and method for measuring and analyzing motility within a body lumen such as the gastrointestinal (GI) tract, where an in vivo imaging device such as a capsule captures images and transmits the images to a processor, which calculates the motility of the device based on comparison of the images. Preferably, the processor compares the intensity of pairs of images or of elements of pairs of images, generates a variance for the compared images, and calculates the motility of the imaging device from the variances. The motility data may be presented to a user in various manners; for example, a plot of motility over time may be generated, or indications of low motility may be presented to the user of the system.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(5)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7200253B2/US07200253-20070403-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7200253B2/US07200253-20070403-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7200253B2/US07200253-20070403-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7200253B2/US07200253-20070403-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7200253B2/US07200253-20070403-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7200253B2/US07200253-20070403-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7200253B2/US07200253-20070403-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7200253B2/US07200253-20070403-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7200253B2/US07200253-20070403-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7200253B2/US07200253-20070403-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(38)</span></span></div><div class="patent-text"><div mxw-id="PCLM9186797" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A system for displaying in-vivo image data of a body lumen comprising:
<div class="claim-text">an in-vivo imaging device configured for moving within a body lumen;</div>
<div class="claim-text">a receiver to receive image frames captured by said in-vivo device; and</div>
<div class="claim-text">a display comprising:</div>
<div class="claim-text">a first window displaying a moving image wherein the moving image includes a series of image frames captured by said in-vivo device; and</div>
<div class="claim-text">a second window displaying information against time, wherein the information corresponds to the image frames being displayed in said first window.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein the information comprises motility information of said in-vivo device in said lumen.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref> comprising a label on said information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The system according to <claim-ref idref="CLM-00003">claim 3</claim-ref> wherein the label is marked by color.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The system according to <claim-ref idref="CLM-00003">claim 3</claim-ref> wherein clicking on the label enables viewing of a corresponding image frame of said moving image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The system according to <claim-ref idref="CLM-00003">claim 3</claim-ref> wherein said label indicates a frame with low motility of the in-vivo device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The system according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said display is configured to display a position of the in-vivo device in said body lumen.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The system according to <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein said display of said position of said device comprises a rendering of a path of said device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The system according to <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein said display of position in said body lumen is linked to an image frame in said series captured by said device at said position in said body lumen.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The system according to <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein said display of position in said body lumen is linked to said information displayed in said second window.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The system according to <claim-ref idref="CLM-00007">claim 7</claim-ref> wherein said display of position comprises an indication of an area corresponding to an altered pattern of said information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The display according to <claim-ref idref="CLM-00011">claim 11</claim-ref> wherein the indication comprises a color change.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The display according to <claim-ref idref="CLM-00001">claim 1</claim-ref> wherein said images and said information are displayed in real time.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. A method of displaying data obtained from an in-vivo imaging device configured for moving within a body lumen comprising:
<div class="claim-text">capturing images of a body lumen with an in-vivo imaging device;</div>
<div class="claim-text">displaying a moving image wherein the moving image includes a series of said images;</div>
<div class="claim-text">displaying information against time, wherein the information corresponds to the images being displayed.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the information comprises motility of said in-vivo device in said body lumen.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref> wherein the displaying a moving Image and the displaying information is in real time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref> comprising labeling a section of the information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. The method according to <claim-ref idref="CLM-00017">claim 17</claim-ref> wherein the labeling is by user indication.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text">19. The method according to <claim-ref idref="CLM-00014">claim 14</claim-ref> comprising displaying a position of the in-vivo device in said body lumen.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text">20. The method according to <claim-ref idref="CLM-00019">claim 19</claim-ref> comprising linking said display of said position to said images of said moving image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
      <div class="claim-text">21. The method according to <claim-ref idref="CLM-00019">claim 19</claim-ref> comprising linking an area of said display of position to an area of said display of information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
      <div class="claim-text">22. The method according to <claim-ref idref="CLM-00019">claim 19</claim-ref> comprising indicating on said display of position an area corresponding to an altered pattern of said display of information.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
      <div class="claim-text">23. The method according to <claim-ref idref="CLM-00022">claim 22</claim-ref> wherein the indicating is by color change.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00024" num="00024" class="claim">
      <div class="claim-text">24. A method far displaying in vivo data, the method comprising:
<div class="claim-text">storing images received from an in vivo imaging system;</div>
<div class="claim-text">analyzing pixel properties of the stored images;</div>
<div class="claim-text">displaying an image frame on a monitor;</div>
<div class="claim-text">displaying on the monitor an indication of information based on analysis of pixel properties of the image frame being displayed; and</div>
<div class="claim-text">clicking on the indication of information being displayed to display an image frame corresponding to the indication.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00025" num="00025" class="claim">
      <div class="claim-text">25. The method according to <claim-ref idref="CLM-00024">claim 24</claim-ref> wherein the analyzing pixel properties of the stored images comprises analyzing sequential images received from the in vivo device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00026" num="00026" class="claim">
      <div class="claim-text">26. The method according to <claim-ref idref="CLM-00024">claim 24</claim-ref> wherein pixel properties is selected from a group including: brightness, intensity, and color data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00027" num="00027" class="claim">
      <div class="claim-text">27. The method according to <claim-ref idref="CLM-00024">claim 24</claim-ref> wherein the indication is a color indication.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00028" num="00028" class="claim">
      <div class="claim-text">28. The method according to <claim-ref idref="CLM-00024">claim 24</claim-ref> comprising displaying a time elapsed far the image frame being displayed.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00029" num="00029" class="claim">
      <div class="claim-text">29. The method according to <claim-ref idref="CLM-00024">claim 24</claim-ref> comprising displaying a series of the images in a moving image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00030" num="00030" class="claim">
      <div class="claim-text">30. The method according to <claim-ref idref="CLM-00024">claim 24</claim-ref> comprising displaying a plot, the plot comprising a time axis and an indication mark.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00031" num="00031" class="claim">
      <div class="claim-text">31. The method according to <claim-ref idref="CLM-00030">claim 30</claim-ref> wherein the indication mark includes color.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00032" num="00032" class="claim">
      <div class="claim-text">32. The method according to <claim-ref idref="CLM-00030">claim 30</claim-ref> wherein the plot comprises an in vivo location indication.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00033" num="00033" class="claim">
      <div class="claim-text">33. A method for displaying in vivo data, the method comprising:
<div class="claim-text">storing images received from an in vivo imaging system;</div>
<div class="claim-text">analyzing pixel properties of the stored images;</div>
<div class="claim-text">displaying an image frame on a monitor;</div>
<div class="claim-text">displaying on the monitor an indication of information based on analysis of pixel properties of the image frame being displayed; and</div>
<div class="claim-text">displaying on the monitor an indication of motility information based on the analysis of pixel properties of the stored images.</div>
</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00034" num="00034" class="claim">
      <div class="claim-text">34. A system for displaying in vivo data, the system comprising an in vivo imaging capsule for obtaining and transmitting image data to an external receiver;
<div class="claim-text">a receiver for receiving image data from the capsule, said receiver connected to a monitor;</div>
<div class="claim-text">a monitor to display an image frame, a time axis and a color indication, the color indication corresponding to pixel data analysis of the image data.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00035" num="00035" class="claim">
      <div class="claim-text">35. The system according to <claim-ref idref="CLM-00034">claim 34</claim-ref> comprising a pointing device far clicking to display an image frame corresponding to the color indication.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00036" num="00036" class="claim">
      <div class="claim-text">36. The system according to <claim-ref idref="CLM-00034">claim 34</claim-ref> comprising a pointing device for clicking to display an image frame corresponding to the time axis.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00037" num="00037" class="claim">
      <div class="claim-text">37. The system according to <claim-ref idref="CLM-00034">claim 34</claim-ref> wherein the image data is of sequential images.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00038" num="00038" class="claim">
      <div class="claim-text">38. The system according to <claim-ref idref="CLM-00034">claim 34</claim-ref> wherein the color indication is to indicate motility of the capsule within the gastrointestinal tract.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES16209341" lang="EN" load-source="patent-office" class="description">
    <heading>PRIOR APPLICATION</heading> <p num="p-0002">The application is a Continuation Application of U.S. patent application Ser. No. 10/175,148, filed Jun. 20, 2002, now patent application Ser. No. 6,944,316, which is a continuation of International Patent Application No. PCT/1L02/00386, filed on May 19, 2002 which in turn claims the benefit of U.S. Provisional Application No. 60/299,178, filed on Jun. 20, 2001, all of which are incorporated by reference herein in their entirety.</p>
    <heading>FIELD OF THE INVENTION</heading> <p num="p-0003">The present invention relates to a method and system for analysis of motility within a body lumen, such as within the gastrointestinal (GI) tract.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p num="p-0004">Normal peristalsis within a GI tract is responsible for transporting swallowed food and aiding in digestion and eventual evacuation. Peristalsis results in pressure waves moving along the GI tact, in turn resulting in the motility of a bolus within the GI tract. Thus, changes in motility along the GI tract may indicate normal conditions such as food passing from one section of the GI tract to another (such as passage from the stomach to the small intestine or passage from the small intestine to the large intestine). Certain pathological conditions can alter the normal motility within the GI tact. Low motility may be caused by an obstruction or blockage or by other pathological conditions. It is often difficult to detect areas of low or abnormal motility within the GI tract, since these areas may be in difficult to reach locations. It is difficult to “see” inside the tract, especially in sections that are hard to reach via conventional methods, such as the small intestines. Motility is the result of complex neuro-physiological processes. Motility disorders may be caused by nervous disorders and may not necessarily be visible as, for example, physiological changes in the intestinal tissue.</p>
    <p num="p-0005">Various in vivo measurement systems for examining a body lumen are known in the art. A commonly known and used type of system is an endoscope. Endoscopes are devices which include a tube (either rigid or flexible) and an optical system, and which are introduced into the body to view the interior The range of endoscopes—the portion of the GI tract, which endoscopes are capable of viewing—is limited. Endoscopes are usually not helpful in providing information on GI tract motility. Probes, such as pressure probes, may be used to measure peristaltic pressure waves. Other systems that may be used for obtaining information on GI tract motility include dissolvable vehicles containing non dissolving markers that are visible by X-ray. The vehicle is ingested and the progression of the markers, which are released in the GI tract once the vehicle is dissolved, can be followed by X-ray. This method, however, can not be used for continuous monitoring and also exposes the patient to hazardous X-rays.</p>
    <p num="p-0006">A non hazardous system and method for monitoring and/or analyzing movement along the entire GI tract is needed, inter alia, for facilitating the understanding of GI tract motility and for expanding diagnostic (and perhaps therapeutic) possibilities in the GI tract.</p>
    <heading>SUMMARY OF THE INVENTION </heading> <p num="p-0007">An exemplary embodiment of the system and method of the present invention measures and analyzes motility within a body lumen such as the GI tract. In another embodiment of the invention a method is provided for diagnosis of in vivo conditions in the GI tract of a patient. In one embodiment an in vivo imaging device such as an ingestible imaging capsule captures images and transmits the images to a processor, which calculates the motility of the device based on comparison of the images. In one embodiment the processor compares the intensity of pairs of images or of elements of pairs of images, generates an average difference for the compared images, and calculates the motility of the imaging device from the average differences. In other embodiments indicators, such as radio frequency (RF) signals, stain gauges, velocity meters or accelerometers may be used to calculate the motility of a device. In another embodiment a geometrical location or in vivo position of the device may be determined for later calculation of the motility. The motility data may be presented to a use in various manners; for example, a plot of motility over time may be generated, or indications of low or abnormal motility may be presented to the user of the system.</p>
    <p num="p-0008">According to an embodiment of the invention motility analysis data is examined for at least one parameter, the parameter is compared to a reference and at least one condition in the GI tract is deduced from the comparison.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0009">The present invention will be understood and appreciated more fully from the following detailed description taken in conjunction with the drawings in which:</p>
      <p num="p-0010"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a schematic illustration of an in vivo imager system, according to one embodiment of the present invention;</p>
      <p num="p-0011"> <figref idrefs="DRAWINGS">FIGS. 2A and 2B</figref> show a simplified series of images, which may be captured by the vivo imager system of <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
      <p num="p-0012"> <figref idrefs="DRAWINGS">FIG. 3</figref> depicts a motility chart produced by the system of <figref idrefs="DRAWINGS">FIG. 1</figref>, according to one embodiment of the present invention;</p>
      <p num="p-0013"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a flow chart showing the steps for determining the motility of a device recording images from a body lumen according to an exemplary embodiment of the present invention; and</p>
      <p num="p-0014"> <figref idrefs="DRAWINGS">FIGS. 5A and 5B</figref> are histograms used to calculate motility according to an embodiment of the present invention.</p>
    </description-of-drawings> <heading>DETAILED DESCRIPTION OF THE INVENTION </heading> <p num="p-0015">In the following description, various aspects of the present invention will be described For purposes of explanation, specific configurations and details are set forth in order to provide a thorough understanding of the present invention. However, it will also be apparent to one skilled in the art that the present invention may be practiced without the specific details presented herein. Furthermore, well known features may be omitted or simplified in order not to obscure the present invention.</p>
    <p num="p-0016">The present invention relates to a method and system for analyzing motility within a GI tract and for displaying motility to a user such as a health professional, who may use such data to, for example, diagnose pathologies. In an exemplary embodiment of the present invention, the motility of a capsule or other vehicle, which is propelled through the GI tract by the natural action of the GI tract is measured, giving an indication of the motility in the GI tract, in different portions of the GI tract. In one embodiment, the motility of the vehicle is calculated via an analysis of sequential images captured by the vehicle; the greater the difference between sequential images, the greater the motility.</p>
    <p num="p-0017">Reference is made to <figref idrefs="DRAWINGS">FIG. 1</figref>, which shows a schematic diagram of an in vivo imaging system according to one embodiment of the present invention. In an exemplary embodiment, the system comprises a capsule <b>40</b> having an imager <b>46</b>, for capturing images, an illumination source <b>42</b>, for illuminating the body lumen, and a transmitter <b>41</b>, for transmitting image and possibly other information to a receiving device. An optical system (not shown), including, for example, lenses or minors, may aid in focusing reflected light onto the imager <b>46</b>. The capsule <b>40</b> is swallowed by a patient and preferably traverses the patient's GI tract. In alternate embodiments the capsule <b>40</b> may have different configurations and include other sets of components.</p>
    <p num="p-0018">Preferably, while the capsule <b>40</b> traverses a patient's GI tract, the capsule <b>40</b> transmits image and possibly other data to components located outside the patient's body, which receive and process the data. Preferably, located outside the patient's body in one or more locations, are an image receiver <b>12</b>, preferably including an antenna or antenna array, an image receiver storage unit <b>16</b>, a data processor <b>14</b>, a data processor storage unit <b>19</b>, and an image monitor <b>18</b>, for displaying, inter alia, the images recorded by the capsule <b>40</b> and motility information. In one embodiment, the image receiver <b>12</b> and image receiver storage unit <b>16</b> are small and portable, and are worn on the patient's body during recording of the images. Optionally, data processor <b>14</b>, data processor storage unit <b>19</b> and monitor <b>18</b> may be part of a personal computer or workstation, which includes standard components such as processor <b>14</b>, a memory, a disk drive, and input-output devices, although alternate configurations are possible.</p>
    <p num="p-0019">Data processor <b>14</b> may include any standard data processor, such as a microprocessor, multiprocessor, accelerator board, or any other serial or parallel high performance data processor. Image monitor <b>18</b> may be a computer screen or a conventional video display, but may, in addition, be a prints or any other device capable of providing an indication of image and/or position data.</p>
    <p num="p-0020">Preferably, the imager <b>46</b> is a suitable CMOS camera, such as a “camera on a chip” type CMOS manager specified by Given Imaging Ltd. of Israel and designed by Photobit Corporation of California, USA. In alternate embodiments, the imager <b>46</b> may be, for example, a CCD. The illumination source <b>42</b> may be, for example, a light emitting diode.</p>
    <p num="p-0021">In operation, imager <b>46</b> captures images and sends data representing the images to transmitter <b>41</b>, which transmits images to image receiver <b>12</b> using, for example, electromagnetic radio waves. Image receiver <b>12</b> transfers the image data to image receiver storage unit <b>16</b>. After a certain period of time of data collection, the image data stored in storage unit <b>16</b> is sent to data processor <b>14</b> or data processor storage unit <b>19</b>. For example, the image receiver storage unit <b>16</b> may be taken off the patient's body and connected to the personal computer or workstation which includes the data processor <b>14</b> and data processor storage unit <b>19</b> via a standard data link, e.g., a serial or parallel interface of known construction. The image data is then transferred from the image receiver storage unit <b>16</b> to the data processor storage unit <b>19</b>. Data processor <b>14</b> analyzes the data and provides the analyzed data to the image monitor <b>18</b>, where a health professional views, for example, the image data and motility information.</p>
    <p num="p-0022">The image data collected and stored may be stored indefinitely, transferred to other locations, or manipulated or analyzed. A health professional may use the images to diagnose pathological conditions of the GI tract and, in addition, the system may provide information about the location of these pathologies. While, using a system where the data processor storage unit <b>19</b> first collects data and then transfers data to the data processor <b>14</b>, the image data is not viewed in real time, other configurations allow for real time viewing. In such systems, image motility may be calculated and displayed in real time.</p>
    <p num="p-0023">The image monitor <b>18</b> presents the image data, preferably in the form of still and moving pictures, and in addition may present other information. In an exemplary embodiment, such additional information may include, but is not limited to, absolute time elapsed for the current image being shown and the relative or absolute motility of the capsule <b>40</b>, over the course of the capsule's travel through the GI tract, and/or at the time corresponding to the current image being displayed. Absolute time elapsed for the current image being shown may be, for example, the amount of time that elapsed between the moment the capsule <b>40</b> was first activated and the image receiver <b>12</b> started receiving transmissions from the capsule <b>40</b>, and the moment that the current image being displayed was captured. Various methods may be used to display the motility of the capsule <b>40</b>; such methods are discussed below. In an exemplary embodiment, the various categories of information are displayed in windows. Multiple monitors may be used to display image and other data.</p>
    <p num="p-0024">Preferably, the image data recorded and transmitted by the capsule <b>40</b> is digital color image data, although in alternate embodiments other image formats may be used. In an exemplary embodiment, each frame of image data includes 256 rows of 256 pixels each, each pixel including data for color and brightness, according to known methods For example, in each pixel color may be represented by a mosaic of four sub-pixels, each sub-pixel corresponding to primaries such as red, green, or blue (where one primary is presented twice). The brightness of the overall pixel is recorded by a one byte (ie, 0–255) brightness value. Preferably, images are stored sequentially in data process storage unit <b>19</b>. The stored data is comprised of one or more pixel properties, including color and brightness.</p>
    <p num="p-0025">While, preferably, information gathering, storage and processing is performed by certain units, the system and method of the present invention may be practiced with alternate configurations. For example, components providing for motility analysis may be located inside a capsule or, alternately, on a portable device worn on the patient. Furthermore, the components gathering image information need not be contained in a capsule, but may be contained in any other vehicle suitable for traversing a lumen in a human body, such as an endoscope, stent, catheter, needle, etc.</p>
    <p num="p-0026">The in vivo imager system may collect a large volume of data, as the capsule <b>40</b> may take several hours to traverse the GI tract and may record images at a rate of, for example, two images every second, resulting in the recordation of tens of thousands of images. The series of still images collected may later be presented as still images or as a moving image of the traverse of the GI tract. The image recordation rate (or frame capture rate) may be varied; for example, the image recordation rate may be varied based on capsule motility. While in the GI tact, the capsule <b>40</b> undergoes intermittent motion with long residence time at some positions. These periods of long residence may be normal or can be due to pathologies, such as blockages, within the digestive tract. The system and method of the present invention aids health professionals in monitoring the capsule motion and in diagnosing and locating, for example, areas of blockage. In addition, changes in motility may be indicative of a normal condition such as the passage of the capsule <b>40</b> from one section of the GI tract to another, and thus the system and method of the present invention may use motility data to determine the position of the capsule <b>40</b> or other diagnostic device.</p>
    <p num="p-0027">In an exemplary embodiment, each image P<sub>i </sub>in the data stream of images is compared to its predecessor image P<sub>i-l </sub>(or to other previous image P<sub>i-n</sub>) to determine the motility of the capsule <b>40</b> during the time between the capture of the two images. Various methods of determining motility based on image comparison may be used. In an exemplary embodiment, the system and method analyze image similarity to obtain a measure of motility. It can be assumed that the more similar two compared images are, the slower the movement of the capsule <b>40</b> between the times the two images are captured. In an extreme situation—if the two compared images are identical—it can be assumed the capsule <b>40</b> has not moved between the times the two images were captured. If two compared images differ greatly, it is an indication that the capsule <b>40</b> was moving quickly between the times of capture of the images. This concept is illustrated further in <figref idrefs="DRAWINGS">FIGS. 2A and 2B</figref>.</p>
    <p num="p-0028"> <figref idrefs="DRAWINGS">FIGS. 2A and 2B</figref> show a simplified series of images, which may be captured by the vivo image system of <figref idrefs="DRAWINGS">FIG. 1</figref>. Referring to <figref idrefs="DRAWINGS">FIGS. 2A and 2B</figref>, a comparison of images provides information about the speed of the capsule <b>40</b>. In <figref idrefs="DRAWINGS">FIG. 2A</figref>, several consecutive images are shown in which a specific point X is located in approximately the same location within each of the images. In <figref idrefs="DRAWINGS">FIG. 2B</figref>, the same point X is located in varying positions within the images, taken over the same period of time. It can be inferred that the images shown in <figref idrefs="DRAWINGS">FIG. 2A</figref> were taken by an imager whose position did not change by much between the times each image was taken, and thus which had relatively low motility. It can be inferred that the images shown in <figref idrefs="DRAWINGS">FIG. 2B</figref> were taken by an imager which is moving more rapidly.</p>
    <p num="p-0029">Preferably, data processor storage unit <b>19</b> stores a series of images recorded by a capsule <b>40</b>. The images may be combined consecutively to form a moving image of the images the capsule <b>40</b> recorded as it moved through a patient's GI tract. This moving image may be displayed in a window on monitor <b>18</b>. The moving image may be frozen to view one frame, speeded up, or reversed; sections may be skipped; or any other method for viewing an image may be applied to the moving image. While the following discussion relates to the case where data from a capsule <b>40</b> is stored for later use, the system and method of the present invention may be used with systems allowing for real time viewing of image data.</p>
    <p num="p-0030">In an exemplary embodiment, to determine the motility of the capsule <b>40</b> at various points during its journey through the GI tract, data processor <b>14</b> first receives image data from data processor storage unit <b>19</b>. Data processor <b>14</b> then compares each image P<sub>i </sub>in the data stream to its predecessor image P<sub>i-l </sub>(or P<sub>i-n</sub>) to determine the motility of the capsule <b>40</b> during the time between the capture of the two images.</p>
    <p num="p-0031">The comparison of images may be made on a pixel-by pixel basis or, alternatively, on a pixel cluster basis. In alternate embodiments, images may be compared without division into sections such as pixels or clusters. In an exemplary embodiment, the 256×256 pixel grid of each image is divided into a 32×32 grid of pixel clusters, to form 1,032 clusters. In alternate embodiments, other methods of dividing an image may be used. Based on the comparison of the two images, data processor <b>14</b> calculates the relative motility for the capsule <b>40</b> that captured the images for the time period between the capture of the two images. In an exemplary embodiment, the resulting motility value at a certain point is a relative number on a certain scale, which indicates the motility of the capsule <b>40</b> relative to other points in the capsule's traverse of the GI tract. In alternate embodiments, absolute motility may be calculated.</p>
    <p num="p-0032">The motility calculation is repeated for all or a set of images in the series of images, and a series of motility values is generated. The resulting motility values may be presented to the user in various manners. Preferably, the monitor <b>18</b> includes a window displaying an image frame or a moving image, a window showing the absolute time elapsed in the image series for the frame being displayed (or the current point in the moving image), and a window including a chart of the relative motility of the capsule <b>40</b> plotted against time. An indication may be provided on the display on monitor <b>18</b> connecting certain motility values, or regions having low motility or certain motility patterns, to images or sections of the moving image. The user may be able to indicate certain motility values or a portion of the motility chart or plot by, for example, clicking with a mouse, and have displayed the corresponding still or moving image.</p>
    <p num="p-0033">Additional windows may display other data. For example, the position of the capsule <b>40</b> as it traverses the GI tract may be graphed as a two-dimensional rendering of the three-dimensional path; such data may be combined with or linked to image or motility data. Areas of low motility, or areas of altered or abnormal patterns of motility, may be indicated on such a capsule path representation by using, for example, color changes or labels.</p>
    <p num="p-0034">In one embodiment, a spectral analysis of the motility data may be performed, and the spectral analysis may be presented to the user or may be used for diagnostic or other purposes. In a normal human GI tract, peristaltic waves are typically generated with some repetition. A spectral analysis, according to known methods, of the peristaltic waves of different time periods or sections of the series of motility data, may be performed and, for example, presented to the user. Such a spectral analysis may present, for example, the frequency of repetition of peristaltic waves at different times or positions in a vehicle's travel through the GI tract. In alternate embodiments, other visual indications of motility may be provided</p>
    <p num="p-0035">According to one embodiment of the invention, motility data can be examined for at least one parameter or measurement that may be presented as, for example, a specific pattern or representation of a pattern in a spectral analysis of the motility data or a specific repetition or representation of a repetition of peristaltic waves. The parameter, possibly represented by a pattern or specific patterns, can be compared to a reference, such as a parameter value in a normal or healthy individual or a specific pattern typical of a pathological condition in the GI tract. The comparison results can indicate, for example, a prevailing condition (or conditions) in the GI tract, thereby providing a diagnostic tool for identifying conditions in the GI tract. For example, a spectral analysis may be performed on the motility of an in-vivo device. The spectral analysis may be represented, for example, as a graph of movement waves over time; other ways of representing a spectral analysis may be used. A pattern matching module (for example, processor <b>14</b> operating according to software) may seek to match the recorded spectral analysis to spectral analyses corresponding to various conditions, and a match or near match may be reported to a user.</p>
    <p num="p-0036"> <figref idrefs="DRAWINGS">FIG. 3</figref> depicts a motility chart produced, for example, by the system of <figref idrefs="DRAWINGS">FIG. 1</figref>, according to one embodiment of the present invasion. The plot or chart <b>100</b> includes a time axis <b>102</b>, a relative motility axis <b>104</b>, and a motility plot or graphing <b>106</b>. Preferably, if the health professional indicates a certain point along the motility chart, using, for example, a pointing device such as a mouse, the corresponding image appears in the image window. While, in an exemplary embodiment the relative motility is expressed in arbitrary units (for example, 0 to 10, adjusted logarithmically), other methods of expressing motility may be used, and absolute motility may also be expressed.</p>
    <p num="p-0037">The chart <b>100</b> may include indications of low motility <b>108</b>, which may be, for example, marks or colored or shaded regions indicating areas where motility is low enough to warrant investigation by a professional. The data processor <b>14</b> may filter for certain patterns of motility, where such patterns may commonly indicate either normal conditions, such as passage between areas of the GI tract, or pathological conditions. Such conditions may be labeled on the motility chart. In response to such indications of low motility, the health professional may click or otherwise indicate the area on the motility chart in question, and view images (still or moving) of the corresponding area in the GI tract.</p>
    <p num="p-0038">Any number of methods may be used to analyze the image data to form motility data For example, motility analysis may be based on a calculation of the difference in a given property between corresponding pixels of two, not necessarily consecutive frames; a calculation of the cross-correlation function between two, not necessarily consecutive, frames, a calculation of the changes of local statistical distributions in two, not necessarily consecutive, frames; or a calculation of the changes between corresponding local statistical distributions in two, not necessity consecutive, frames. Local statistical distributions may include, but are not limited to, the mean, the variance, or the standard deviation of pixel clusters.</p>
    <p num="p-0039">In an exemplary embodiment, each image in a pair of images being compared is divided into a number of sections. Each section in the first image is compared to the corresponding section in the second image. The variance of the difference of the brightness for the two sections, normalized by the number of sections, is calculated. The variance is used to ascertain the relative motility of the vehicle capturing images, which in an exemplary embodiment is capsule <b>40</b>.</p>
    <p num="p-0040">Reference is now made to <figref idrefs="DRAWINGS">FIG. 4</figref>, a flow chart showing the steps for determining the motility of a device recording images from a body lumen according to an exemplary embodiment of the present invention.</p>
    <p num="p-0041">In step <b>200</b>, image data is recorded by the capsule <b>40</b> and transmitted to the data processor storage unit <b>19</b>. In step <b>202</b>, data processor <b>14</b> receives from data processor storage unit <b>19</b> images P<sub>i </sub>and P<sub>i+x</sub>, where x is usually, but not necessarily, 1. If the stream of images is too lengthy or rapid, a decimation may be performed and non-adjacent images may be compared, e.g., image P<sub>i </sub>and P<sub>i+x</sub>, where x&gt;1.</p>
    <p num="p-0042">In step <b>204</b>, data processor <b>14</b> may divide each of the two images into pixel clusters, sections or cells. In an exemplary embodiment, each image P<sub>i </sub>is divided into 1024 clusters A<sub>i</sub>(m,n), where 1&lt;m&lt;32 and 1&lt;n&lt;32.</p>
    <p num="p-0043">In step <b>206</b>, data processor <b>14</b> calculates the average intensity I<sub>Ai(m,n) </sub>of each cluster A<sub>i</sub>(m,n) of each of image P<sub>i </sub>and P<sub>i+x</sub>. Preferably, the intensity value for a cluster is the average of the brightness values for the pixels in the cluster. A matrix of the intensities of the clusters may be formed for each image. Alternate methods of calculating intensity may be used; for example, color data may be used to compare images.</p>
    <p num="p-0044">In step <b>208</b>, data processor <b>14</b> determines the absolute value D<sub>i</sub>(m,n) of the difference of the average intensities I of A<sub>i</sub>(m,n) and A<sub>i+x</sub>(m,n) of corresponding clusters A(m,n) in the frames P<sub>i </sub>and P<sub>i+x</sub>. D<sub>i</sub>(m,n) is defined as:
<br> <i>D</i> <sub>i</sub>(<i>k,l</i>)=|<i>I</i> <sub>A</sub> <sub> <sub2>i</sub2> </sub> <sub>(k,l)</sub> <i>−I</i> <sub>A</sub> <sub> <sub2>i+x</sub2> </sub> <sub>(k,l)</sub>|<br>
A matrix of the absolute values of differences is formed, one value being generated for each cluster compared.
</p>
    <p num="p-0045">In step <b>210</b>, data processor <b>14</b> determines the average difference (Diff) between the two images. In an exemplary embodiment, the average difference is calculated by first subtracting from each absolute value in the matrix created in step <b>208</b> the average value of all the differences in the matrix, summing the resulting values, taking the square root of the resulting sum, and dividing by the number of the differences in the matrix (in an exemplary embodiment 1024). This may be expressed by the formula:</p>
    <p num="p-0046"> <maths id="MATH-US-00001" num="00001"> <math overflow="scroll"> <mrow> <mi>Diff</mi> <mo>=</mo> <mrow> <munder> <mo>∑</mo> <mrow> <mrow> <mi>m</mi> <mo>=</mo> <mn>1</mn> </mrow> <mo>,</mo> <mrow> <mn>32</mn> <mo>;</mo> <mrow> <mi>n</mi> <mo>=</mo> <mn>1</mn> </mrow> </mrow> <mo>,</mo> <mn>32</mn> </mrow> </munder> <mo>⁢</mo> <mstyle> <mspace width="0.3em" height="0.3ex"> </mspace> </mstyle> <mo>⁢</mo> <mrow> <mrow> <msub> <mi>D</mi> <mi>l</mi> </msub> <mo>⁡</mo> <mrow> <mo>(</mo> <mrow> <mi>m</mi> <mo>,</mo> <mi>n</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>/</mo> <mn>1024</mn> </mrow> </mrow> </mrow> </math> </maths> <br>
where Diff corresponds to the average of the values in the difference matrix.
</p>
    <p num="p-0047">In an exemplary embodiment the resulting average difference is a value from 0 to U, where U is an arbitrary upper limit which depends upon the parameters. A low average difference indicates that the measured value (in an exemplary embodiment, brightness) varies little be the compared frames, and a high value of the average difference indicates that the measured value varies a large amount. A low difference is an indication of low motility, as, if the capsule <b>40</b> is not moving quickly, the images in the two compared frames will not vary by a large amount.</p>
    <p num="p-0048">In step <b>212</b>, if more frames exist in the image stream, data processor <b>14</b> returns to step <b>202</b>. If no more flames exist data processor <b>14</b> proceeds to step <b>214</b>. At this point, the difference data exists as a series of difference values, one for each frame pair analyzed, preferably X-1 variances, where X is the number of frames analyzed.</p>
    <p num="p-0049">In step <b>214</b>, data processor <b>14</b> may normalize or decimate the resulting difference data to an arbitrary scale. This normalized data represents the relative motility of the capsule <b>40</b>. In an exemplary embodiment, each difference datum, represented as a value from 0–U, is normalized to a number between 0 and 10; other ranges may be used. The normalization process may be linear or may be non-linear—for example, a logarithmic function may be used. In alternate embodiments, other normalization or decimation functions may be used, for example, the difference data may be translated to a set of integers. During normalization, various functions, such as logarithmic functions, may be applied to the data.</p>
    <p num="p-0050">In step <b>216</b>, data processor <b>14</b> provides an indication of motility for the capsule <b>40</b>. In an exemplary embodiment, data processor <b>14</b> creates a plot or graph of relative motility over time for display on the monitor <b>18</b> using the normalized values created in step <b>214</b>. Data processor <b>14</b> may augment the graph with indications of low motility or indications of certain conditions. For example, sections of the graph where motility falls below a certain threshold may be marked in a certain color or pattern, or may be otherwise labeled.</p>
    <p num="p-0051">In alternate embodiments, other methods of analyzing the image data to form motility data may be used. For example, for each frame pair, data processor <b>14</b> may organize the difference values D<sub>i</sub>(k,l) into a chart, for example, a histogram, as shown in <figref idrefs="DRAWINGS">FIGS. 5A</figref> and B. <figref idrefs="DRAWINGS">FIGS. 5A</figref> and B depict histograms used to calculate motility according to an embodiment of the present invention. Referring to <figref idrefs="DRAWINGS">FIGS. 5A</figref> and B, the absolute value D<sub>i</sub>(m,n) of the difference is plotted on the x-axis of the histograms and the number of corresponding pairs of cells, A<sub>i</sub>(m,n) and A<sub>i+x</sub>(m,n), which have a difference of magnitude D<sub>i</sub>(k,l), is plotted on the y-axis. The histogram of in <figref idrefs="DRAWINGS">FIG. 5A</figref> presents a histogram of cells in relatively similar frames, while the histogram of <figref idrefs="DRAWINGS">FIG. 5B</figref> shows a histogram of cells in significantly different frames. It should be readily apparent that if two images are similar, the histogram of the differences in the cells of those images are concentrated at low values of D<sub>i</sub>(m,n). It should also be readily apparent that the center of mass CM<sub>a </sub>(the average difference between the two images) of the histogram shown in <figref idrefs="DRAWINGS">FIG. 5A</figref> has a smaller value of D than the center of mass CM<sub>b </sub>of the histogram shown in <figref idrefs="DRAWINGS">FIG. 5B</figref>, and corresponds to a slower moving capsule <b>40</b>. To calculate the difference between the two frames, processor <b>14</b> determines the centers of mass CM of the histograms corresponding to the two frames, and creates a difference value based on the location of the CM. In another embodiment image analysis may be used to determine the location of the capsule <b>40</b> in vivo (for example by identifying image parameters that are typical to a specific region in the GI tract) and the position information together with known factors; either the time that has elapsed during the translocation of the capsule <b>40</b> or the velocity of the capsule <b>40</b> along its path, can be used to calculate the motility. Similarly, the location of the capsule may be determined by other known methods and the location information can be used to calculate motility.</p>
    <p num="p-0052">In alternate embodiments, methods of measuring motility may be used which are not based on image analysis. Fat example, the capsule <b>40</b> may include an accelerometer which determines the instantaneous acceleration of capsule <b>40</b> as it moves through the GI tract. An integrator may convert the acceleration data to velocity data, and this velocity data may be used by the data processor to determine motility. Alternately, a pressure sensor or shear gauge attached to the capsule <b>40</b> may detect peristaltic induced pressure or movement exerted by the walls of the small intestine. The relationship between pressure and velocity may be determined empirically, and then utilized to determine the velocity or relative velocity of the capsule <b>40</b>. A sensor in the capsule <b>40</b> may detect movement relative to an artificially induced magnetic field, which is generated in the area of the patient's GI tract. The magnetic field induces a current in a coil in the sensor, whose magnitude is a function of the velocity of the coil through the field. Data on the induced current is converted to motility information. Further, external sensors may also be used, such as a Doppler, ultrasound unit, which continuously tracks the capsule <b>40</b>. Additionally, the receiver <b>12</b>, which, according to one embodiment is adapted to receive RF signals from the transmitter <b>41</b>, may be used to monitor the intensity of the transmitted signal, whereas signals of unchanging intensities indicate that the transmitter <b>41</b> (and hence the capsule <b>40</b>) is unmoving and signals of different intensities indicate that the transmitter <b>41</b> is moving. One or more of the above methods, or other methods, may be combined to provide a determination of capsule motility.</p>
    <p num="p-0053">It will be appreciated by persons skilled in the art that the present invention is not limited by what has been particularly shown and described hereinabove. Rather the scope of the invention is defined by the claims that follow:</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4278077">US4278077</a></td><td class="patent-data-table-td patent-date-value">Jul 24, 1979</td><td class="patent-data-table-td patent-date-value">Jul 14, 1981</td><td class="patent-data-table-td ">Olympus Optical Co., Ltd.</td><td class="patent-data-table-td ">Medical camera system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5604531">US5604531</a></td><td class="patent-data-table-td patent-date-value">Jan 17, 1995</td><td class="patent-data-table-td patent-date-value">Feb 18, 1997</td><td class="patent-data-table-td ">State Of Israel, Ministry Of Defense, Armament Development Authority</td><td class="patent-data-table-td ">In vivo video camera system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5993378">US5993378</a></td><td class="patent-data-table-td patent-date-value">Sep 19, 1994</td><td class="patent-data-table-td patent-date-value">Nov 30, 1999</td><td class="patent-data-table-td ">Lemelson; Jerome H.</td><td class="patent-data-table-td ">Electro-optical instruments and methods for treating disease</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6240312">US6240312</a></td><td class="patent-data-table-td patent-date-value">Oct 23, 1998</td><td class="patent-data-table-td patent-date-value">May 29, 2001</td><td class="patent-data-table-td ">Robert R. Alfano</td><td class="patent-data-table-td ">Remote-controllable, micro-scale device for use in in vivo medical diagnosis and/or treatment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6428469">US6428469</a></td><td class="patent-data-table-td patent-date-value">Dec 15, 1998</td><td class="patent-data-table-td patent-date-value">Aug 6, 2002</td><td class="patent-data-table-td ">Given Imaging Ltd</td><td class="patent-data-table-td ">Energy management of a video capsule</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6621917">US6621917</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 11, 1997</td><td class="patent-data-table-td patent-date-value">Sep 16, 2003</td><td class="patent-data-table-td ">Imedos Intelligente Optische Systeme Der Medizin-Und Messtechnik Gmbh</td><td class="patent-data-table-td ">Device and method for examining biological vessels</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6709387">US6709387</a></td><td class="patent-data-table-td patent-date-value">May 15, 2000</td><td class="patent-data-table-td patent-date-value">Mar 23, 2004</td><td class="patent-data-table-td ">Given Imaging Ltd.</td><td class="patent-data-table-td ">System and method for controlling in vivo camera capture and display rate</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020103417">US20020103417</a></td><td class="patent-data-table-td patent-date-value">Mar 8, 2002</td><td class="patent-data-table-td patent-date-value">Aug 1, 2002</td><td class="patent-data-table-td ">Gazdzinski Robert F.</td><td class="patent-data-table-td ">Endoscopic smart probe and method</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">PCT Search Report International Application No.: PCT/IL02/00386 International Filing Date: May 19, 2002.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Rowell, Nancy D., Endoscopes Go Wireless Biophotonics In Action Photonics Spectra Mar. 2001.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7670288">US7670288</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 8, 2006</td><td class="patent-data-table-td patent-date-value">Mar 2, 2010</td><td class="patent-data-table-td ">Sher Philip M</td><td class="patent-data-table-td ">Fluctuating blood glucose notification threshold profiles and methods of use</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8022980">US8022980</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2005</td><td class="patent-data-table-td patent-date-value">Sep 20, 2011</td><td class="patent-data-table-td ">Given Imaging Ltd.</td><td class="patent-data-table-td ">System and method for displaying an image stream</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8045000">US8045000</a></td><td class="patent-data-table-td patent-date-value">Nov 26, 2008</td><td class="patent-data-table-td patent-date-value">Oct 25, 2011</td><td class="patent-data-table-td ">Given Imaging, Ltd.</td><td class="patent-data-table-td ">System and method for displaying an image stream</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8164672">US8164672</a></td><td class="patent-data-table-td patent-date-value">Dec 29, 2004</td><td class="patent-data-table-td patent-date-value">Apr 24, 2012</td><td class="patent-data-table-td ">Given Imaging Ltd.</td><td class="patent-data-table-td ">System and method for displaying an image stream</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8478010">US8478010</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 17, 2010</td><td class="patent-data-table-td patent-date-value">Jul 2, 2013</td><td class="patent-data-table-td ">Olympus Corporation</td><td class="patent-data-table-td ">Image processing apparatus, image processing program recording medium, and image processing method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8512241">US8512241</a></td><td class="patent-data-table-td patent-date-value">Sep 6, 2007</td><td class="patent-data-table-td patent-date-value">Aug 20, 2013</td><td class="patent-data-table-td ">Innurvation, Inc.</td><td class="patent-data-table-td ">Methods and systems for acoustic data transmission</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8588887">US8588887</a></td><td class="patent-data-table-td patent-date-value">Sep 6, 2007</td><td class="patent-data-table-td patent-date-value">Nov 19, 2013</td><td class="patent-data-table-td ">Innurvation, Inc.</td><td class="patent-data-table-td ">Ingestible low power sensor device and system for communicating with same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8615284">US8615284</a></td><td class="patent-data-table-td patent-date-value">Sep 6, 2007</td><td class="patent-data-table-td patent-date-value">Dec 24, 2013</td><td class="patent-data-table-td ">Innurvation, Inc.</td><td class="patent-data-table-td ">Method for acoustic information exchange involving an ingestible low power capsule</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8617058">US8617058</a></td><td class="patent-data-table-td patent-date-value">Jul 9, 2009</td><td class="patent-data-table-td patent-date-value">Dec 31, 2013</td><td class="patent-data-table-td ">Innurvation, Inc.</td><td class="patent-data-table-td ">Displaying image data from a scanner capsule</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8647259">US8647259</a></td><td class="patent-data-table-td patent-date-value">Mar 28, 2011</td><td class="patent-data-table-td patent-date-value">Feb 11, 2014</td><td class="patent-data-table-td ">Innurvation, Inc.</td><td class="patent-data-table-td ">Ultrasound scanning capsule endoscope (USCE)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8682142">US8682142</a></td><td class="patent-data-table-td patent-date-value">Mar 18, 2011</td><td class="patent-data-table-td patent-date-value">Mar 25, 2014</td><td class="patent-data-table-td ">Given Imaging Ltd.</td><td class="patent-data-table-td ">System and method for editing an image stream captured in-vivo</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8696602">US8696602</a></td><td class="patent-data-table-td patent-date-value">Mar 30, 2010</td><td class="patent-data-table-td patent-date-value">Apr 15, 2014</td><td class="patent-data-table-td ">Given Imaging, Inc.</td><td class="patent-data-table-td ">Method of determining body exit of an ingested capsule</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080262304">US20080262304</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 30, 2005</td><td class="patent-data-table-td patent-date-value">Oct 23, 2008</td><td class="patent-data-table-td ">Micha Nisani</td><td class="patent-data-table-td ">In-Vivo Sensing System Device and Method for Real Time Viewing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110085717">US20110085717</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 17, 2010</td><td class="patent-data-table-td patent-date-value">Apr 14, 2011</td><td class="patent-data-table-td ">Olympus Corporation</td><td class="patent-data-table-td ">Image processing apparatus, image processing program recording medium, and image processing method</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S128000">382/128</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc600/defs600.htm&usg=AFQjCNGoRRWCr3AADgOfjOLv9kXGux4XKA#C600S160000">600/160</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc600/defs600.htm&usg=AFQjCNGoRRWCr3AADgOfjOLv9kXGux4XKA#C600S117000">600/117</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=A61B0001040000">A61B1/04</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=A61B0001050000">A61B1/05</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009000000">G06K9/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=A61B1/042">A61B1/042</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FNp6BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=A61B1/041">A61B1/041</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">A61B1/04C</span>, <span class="nested-value">A61B1/04D</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Feb 19, 2013</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20121219</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 27, 2010</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 11, 2005</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">GIVEN IMAGING LTD., ISRAEL</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:GLUKHOVSKY, ARKADY;MERON, GAVRIEL;ZINATI, OFRA;REEL/FRAME:016889/0174;SIGNING DATES FROM 20021018 TO 20021021</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4ff636b3d23669b7103f3b3a3a18b4cd.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U13wq0Mce6IsvEUB3kGcycobFRhGA\u0026id=FNp6BAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U1-IFlOuZl4_UvyaNTyhTNwhYdkgw\u0026id=FNp6BAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2Swt_LRbSZNY7K1Z385m7yduKq6A","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Motility_analysis_within_a_gastrointesti.pdf?id=FNp6BAABERAJ\u0026output=pdf\u0026sig=ACfU3U3j86xgRc7jFn-4pGOp4FwTpmlZ-w"},"sample_url":"http://www.google.com/patents/reader?id=FNp6BAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>