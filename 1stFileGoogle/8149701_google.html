<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US8149701 - System, method, and computer readable medium for creating a video clip - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4ff636b3d23669b7103f3b3a3a18b4cd/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4ff636b3d23669b7103f3b3a3a18b4cd__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="System, method, and computer readable medium for creating a video clip"><meta name="DC.contributor" content="Jason Sumler" scheme="inventor"><meta name="DC.contributor" content="Tomer Alpert" scheme="inventor"><meta name="DC.contributor" content="Silver Screen Tele-Reality, Inc." scheme="assignee"><meta name="DC.date" content="2011-1-31" scheme="dateSubmitted"><meta name="DC.description" content="The present invention provides a system, method, and computer readable medium for creating a video clip. In one embodiment, a method, comprising creating a copy of a still image by a first module, the copy of the still image comprising reduced dimensions of the still image, creating a new still image from a selected area of the still image, automatically ordering the new still image and the copy of the still image, creating an audio file by at least one of a second module and a third module, creating a timeline, by the first module, related to the ordered images and the created audio file, and rendering the timeline into a video clip by a fourth module, wherein the timeline includes a length of the audio file, a length of the video clip, the ordered images, a display time of each of the ordered images, transition identifiers, transition lengths. The present invention further discloses a system for assembling and distributing multi-media output, comprising: a rendering server; a web server; and storage, wherein the servers and the storage are operably coupled; the storage adapted to receive digital media and properties of the media, store the media and the properties, and transmit the media and the properties; the web server adapted to perform at least one of a following action: retrieve the media and properties of the media; manipulate the media and the properties; assemble the properties; and transmit at least one of a following element from a group consisting of: the properties; and the assembled properties; and the rendering server adapted to receive commands from the web server."><meta name="DC.date" content="2012-4-3" scheme="issued"><meta name="DC.relation" content="US:20020097327:A1" scheme="references"><meta name="DC.relation" content="US:20040257380:A1" scheme="references"><meta name="DC.relation" content="US:5642135" scheme="references"><meta name="DC.relation" content="US:6046734" scheme="references"><meta name="DC.relation" content="US:6195503" scheme="references"><meta name="DC.relation" content="US:6256061" scheme="references"><meta name="DC.relation" content="US:6353699" scheme="references"><meta name="citation_patent_number" content="US:8149701"><meta name="citation_patent_application_number" content="US:13/018,191"><link rel="canonical" href="http://www.google.com/patents/US8149701"/><meta property="og:url" content="http://www.google.com/patents/US8149701"/><meta name="title" content="Patent US8149701 - System, method, and computer readable medium for creating a video clip"/><meta name="description" content="The present invention provides a system, method, and computer readable medium for creating a video clip. In one embodiment, a method, comprising creating a copy of a still image by a first module, the copy of the still image comprising reduced dimensions of the still image, creating a new still image from a selected area of the still image, automatically ordering the new still image and the copy of the still image, creating an audio file by at least one of a second module and a third module, creating a timeline, by the first module, related to the ordered images and the created audio file, and rendering the timeline into a video clip by a fourth module, wherein the timeline includes a length of the audio file, a length of the video clip, the ordered images, a display time of each of the ordered images, transition identifiers, transition lengths. The present invention further discloses a system for assembling and distributing multi-media output, comprising: a rendering server; a web server; and storage, wherein the servers and the storage are operably coupled; the storage adapted to receive digital media and properties of the media, store the media and the properties, and transmit the media and the properties; the web server adapted to perform at least one of a following action: retrieve the media and properties of the media; manipulate the media and the properties; assemble the properties; and transmit at least one of a following element from a group consisting of: the properties; and the assembled properties; and the rendering server adapted to receive commands from the web server."/><meta property="og:title" content="Patent US8149701 - System, method, and computer readable medium for creating a video clip"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("VlzpU9nmGdTMsASOtIG4Bw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407464522.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("USA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("VlzpU9nmGdTMsASOtIG4Bw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407464522.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("USA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us8149701?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US8149701"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=HwM2BwABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS8149701&amp;usg=AFQjCNFoiHQeaT1bVSZyWnAlUX5sbA88zA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US8149701.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US8149701.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20110214045"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US8149701"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US8149701" style="display:none"><span itemprop="description">The present invention provides a system, method, and computer readable medium for creating a video clip. In one embodiment, a method, comprising creating a copy of a still image by a first module, the copy of the still image comprising reduced dimensions of the still image, creating a new still image...</span><span itemprop="url">http://www.google.com/patents/US8149701?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US8149701 - System, method, and computer readable medium for creating a video clip</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US8149701 - System, method, and computer readable medium for creating a video clip" title="Patent US8149701 - System, method, and computer readable medium for creating a video clip"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US8149701 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 13/018,191</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Apr 3, 2012</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jan 31, 2011</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Feb 5, 2003</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7882258">US7882258</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8353406">US8353406</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20110093608">US20110093608</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20110214045">US20110214045</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20120254711">US20120254711</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130086277">US20130086277</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130091300">US20130091300</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">018191, </span><span class="patent-bibdata-value">13018191, </span><span class="patent-bibdata-value">US 8149701 B2, </span><span class="patent-bibdata-value">US 8149701B2, </span><span class="patent-bibdata-value">US-B2-8149701, </span><span class="patent-bibdata-value">US8149701 B2, </span><span class="patent-bibdata-value">US8149701B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jason+Sumler%22">Jason Sumler</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Tomer+Alpert%22">Tomer Alpert</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Silver+Screen+Tele-Reality,+Inc.%22">Silver Screen Tele-Reality, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US8149701.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8149701.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8149701.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (7),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (21),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (2)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/8149701&usg=AFQjCNGNhYpx553Dyhvo9ZvNI9gX9EVSqg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D8149701&usg=AFQjCNH0cAlvLslF-uKfLkPAxKhWzxR3XA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D8149701B2%26KC%3DB2%26FT%3DD&usg=AFQjCNGJ9dR6TfeIgjrU71t3bybcB_O-BA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT110785148" lang="EN" load-source="patent-office">System, method, and computer readable medium for creating a video clip</invention-title></span><br><span class="patent-number">US 8149701 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA93758068" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">The present invention provides a system, method, and computer readable medium for creating a video clip. In one embodiment, a method, comprising creating a copy of a still image by a first module, the copy of the still image comprising reduced dimensions of the still image, creating a new still image from a selected area of the still image, automatically ordering the new still image and the copy of the still image, creating an audio file by at least one of a second module and a third module, creating a timeline, by the first module, related to the ordered images and the created audio file, and rendering the timeline into a video clip by a fourth module, wherein the timeline includes a length of the audio file, a length of the video clip, the ordered images, a display time of each of the ordered images, transition identifiers, transition lengths. The present invention further discloses a system for assembling and distributing multi-media output, comprising: a rendering server; a web server; and storage, wherein the servers and the storage are operably coupled; the storage adapted to receive digital media and properties of the media, store the media and the properties, and transmit the media and the properties; the web server adapted to perform at least one of a following action: retrieve the media and properties of the media; manipulate the media and the properties; assemble the properties; and transmit at least one of a following element from a group consisting of: the properties; and the assembled properties; and the rendering server adapted to receive commands from the web server.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(44)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00014.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00014.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00015.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00015.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00016.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00016.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00017.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00017.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00018.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00018.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00019.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00019.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00020.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00020.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00021.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00021.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00022.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00022.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00023.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00023.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00024.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00024.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00025.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00025.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00026.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00026.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00027.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00027.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00028.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00028.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00029.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00029.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00030.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00030.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00031.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00031.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00032.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00032.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00033.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00033.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00034.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00034.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00035.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00035.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00036.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00036.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00037.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00037.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00038.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00038.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00039.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00039.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00040.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00040.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00041.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00041.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00042.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00042.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US8149701B2/US08149701-20120403-D00043.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US8149701B2/US08149701-20120403-D00043.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(14)</span></span></div><div class="patent-text"><div mxw-id="PCLM57502576" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A method, comprising:
<div class="claim-text">creating a copy of a still image by a first module, the copy of the still image comprising reduced dimensions of the still image;</div>
<div class="claim-text">creating a new still image from a selected area of the still image;</div>
<div class="claim-text">automatically ordering the new still image and the copy of the still image;</div>
<div class="claim-text">creating an audio file by at least one of a second module and a third module;</div>
<div class="claim-text">creating a timeline, by the first module, related to the ordered images and the created audio file; and</div>
<div class="claim-text">rendering the timeline into a video clip by a fourth module, wherein the timeline includes: a length of the audio file, a length of the video clip, the ordered images, a display time of each of the ordered images, transition identifiers, and transition lengths.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> comprising storing at least one of: metadata related to the still image and the copy of the still image, metadata related to the audio file, the timeline, or information comprising the creating of the audio file.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the metadata is stored in a command.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the metadata stores at least one of:
<div class="claim-text">a height;</div>
<div class="claim-text">a width;</div>
<div class="claim-text">a size;</div>
<div class="claim-text">compression data; and</div>
<div class="claim-text">a file format.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the copy of the still image is used for display purposes.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the new created still image is displayed as an image with reduced dimension.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> comprising panning and zooming at least one of: a portion of or the copy of the still image, a portion of or the new created still image, a portion of or the stored new still image, or a portion of or the stored copy of the still image, wherein the panning and the zooming is a set of coordinates related to the image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the set of coordinates is stored in the timeline.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref> comprising transitioning from one to another one of the ordered images, and further comprising storing a transition identifier and a transition length.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref> comprising retrieving at least one of: the metadata related to the audio file, the metadata related to the still image and the copy of the still image, the timeline, or the information comprising the creating of the audio file, by the first module.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref> comprising optionally previewing the timeline via a fifth module.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. A system, comprising:
<div class="claim-text">a device configured to create audio;</div>
<div class="claim-text">a first server configured to:</div>
<div class="claim-text">receive still images;
<div class="claim-text">automatically order the still images; and</div>
<div class="claim-text">create a timeline related to the ordered images and the created audio, wherein the timeline includes a length of the ordered images and a length of the created audio;</div>
</div>
<div class="claim-text">a second server configured to render the timeline into a video clip; and</div>
<div class="claim-text">memory configured to store at least one of: the created audio, the still images, the ordered still images, the timeline and the video clip;</div>
<div class="claim-text">wherein the device and the first server are communicably coupled;</div>
<div class="claim-text">wherein the first server and the second server are communicably coupled;</div>
<div class="claim-text">wherein the memory is communicably coupled to the first server and the second server; and</div>
<div class="claim-text">wherein the device is at least one of:
<div class="claim-text">a text-to-speech module; and</div>
<div class="claim-text">an integrated voice response module.</div>
</div>
</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. A non-transitory computer readable medium, comprising instructions for:
<div class="claim-text">creating a copy of a still image by the first module, the copy of the still image comprising reduced dimensions of the still image;</div>
<div class="claim-text">creating a new still image from a selected area of the still image;</div>
<div class="claim-text">automatically ordering the new still image and the copy of the still image;</div>
<div class="claim-text">creating an audio file by at least one of a second module and a third module;</div>
<div class="claim-text">creating a timeline, by the first module, related to the ordered images and the created audio; and</div>
<div class="claim-text">rendering the timeline into a video clip by a fourth module, wherein the timeline includes a length of the audio file, an identifier of the audio file created by the second module or the third module, or a volume envelope associated with the audio file.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. The non-transitory computer readable medium of <claim-ref idref="CLM-00013">claim 13</claim-ref> comprising instructions for:
<div class="claim-text">storing at least one of: metadata related to the still image and the copy of the still image, metadata related to the audio file, the timeline, and information comprising the creating of the audio file; and</div>
<div class="claim-text">transitioning from one to another one of the ordered images, and further comprising storing a transition identifier and a transition length.</div>
</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES45474070" lang="EN" load-source="patent-office" class="description">
    <heading>CROSS-REFERENCE TO RELATED APPLICATIONS</heading> <p num="p-0002">The present invention is a continuation of and claims the benefit and priority of U.S. patent application Ser. No. 11/293,005, filed on Dec. 2, 2005 now U.S. Pat. No. 7,882,258, entitled System, Method, and Computer Readable Medium for Creating A Video Clip, which is related to and claims the benefit and priority of U.S. Provisional Patent Application Ser. No. 60/632,410, filed on Dec. 2, 2004 now abandoned, entitled Picture To Video (Pic-2-Vid) In Internet Commerce and which is a Continuation-In-Part of U.S. patent application Ser. No. 10/773,130, filed on Feb. 5, 2004, entitled System And Method For Assembling And Distributing Multi-Media Output, which is related to and claims the benefit and priority of U.S. Provisional Patent Application Ser. No. 60/445,261 filed on Feb. 5, 2003, entitled System And Method For Generating A Unified File Name. The entire contents of each of the above noted patent applications are enclosed by reference herein.</p>
    <heading>FILED OF THE INVENTION</heading> <p num="p-0003">The present invention is generally related to video, and more specifically, to a system, method, and computer readable medium for creating a video clip. The present invention relates generally to multi-media content and, more specifically, to a system and method for assembling and distributing multi-media output. The present invention also relates generally to multi-media content and more specifically, to a system, method, and computer-readable medium for assembling and distributing multi-media output.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p num="p-0004">The transcoding of pictures to video is a known technique that includes U.S. Pat. No. 6,195,503 that describes the transformation of compressed images and audio into video. Also, video editing using server Internet tools, including the transcoding and rendering of pictures into video is known. However, a limitation exists for using pictures as a tool for Internet commerce. Almost all sites for selling and buying items on the Internet use simple pictures as the main tool for explaining, demonstrating and educating customers about these items. Pictures are simple to take and use. Further, pictures do not use complex editing tools and processing power and do not require a high level of expertise to either take, process, or deliver.</p>
    <p num="p-0005">It would be very beneficial if improved systems, methods, and computer readable media are devised which allow better options to convey pertinent information while using the same pictures that are used today.</p>
    <p num="p-0006">Large numbers of organizations are producing and making use of video, audio, flash animation, HTML and pictures collectively known as Multi Media Content (MMC). There is also an abundant amount of video and audio in analog format (such as tapes) which are typically converted to digital format. Another major source of MMC is commercial material produced by the entertainment (movie studios) and broadcasting industry (TV), as well as individuals using camcorders. Most of the MMC is distributed on CD's and DVD's. Production of such media is costly and distribution via the mail system is time consuming.</p>
    <p num="p-0007">An alternative to DVD's and CD's is electronic distribution that can be accomplished via a Local Area Network (LAN), Wide Area Network (WAN), using TCP/IP via a public network (the Internet), or via an internal system (Intranet). Other means of distribution are wireless such as microwave, a cellular network, and a WI-FL network, for example. However, MMC content, (especially video) typically comprised large files, and distributing such content electronically can be very expensive, time consuming, and in many cases, simply impossible due to the limited capacity of the receiving device.</p>
    <p num="p-0008">Trading, licensing and selling of MMC by commercial providers (such as movie studios, TV networks, sport channels, etc.) is cumbersome since the providers may consider the content to be proprietary and may find it difficult to prevent a receiver of the content from creating multiply copies.</p>
    <p num="p-0009">Progressive download, widely known as Streaming Media (a client-server system), is an excellent solution since the encoding process reduces the original file size by 80-90%. Upon request, the server sends a small amount of data (Buffering). As soon as the buffering is completed the receiving device starts the play back while the process of downloading and decoding occurs in the background, often times simultaneously. The process of encoding MMC to a streaming format, however, is cumbersome, time consuming, and requires significant technical expertise as the user has to select a wide range of parameters. Furthermore, the nature of TCP/IP and a secured network, block the user from direct accesses to the operating system and file storage process. A separate process of uploading is required and the final stage of storage and indexing for retrieval must be done by authorized personnel (for example, a system administrator).</p>
    <p num="p-0010">Other issues that prevent wide use of MMC content include:</p>
    <p num="p-0011">1. Once the MMC is uploaded it cannot be changedany change requires creation of a new file (rendering) and repeating the upload process;</p>
    <p num="p-0012">2. Streaming video can be played within flash and HTML but there is no way to tell what and when the receiving device will play each component since the buffering time can change randomly; and</p>
    <p num="p-0013">3. There are many types of receiving devices using many communication protocols, players and streaming technology. Distributing MMC in streaming format also enables the MMC provider to license the use of content without proprietary concern since the progressive download process prevents it. However, establishing a commerce platform for licensing and trading MMC requires an agreed upon protocol and a large, centralized database to monitor the transactions. Many attempts to do so have failed. It is therefore desirable for the present invention to overcome the aforementioned problems and limitations associated with multi-media output.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p num="p-0014">The present invention provides a system, method, and computer readable medium for creating a video clip. In one embodiment, a method, comprising creating a copy of a still image by a first module, the copy of the still image comprising reduced dimensions of the still image, creating a new still image from a selected area of the still image, automatically ordering the new still image and the copy of the still image, creating an audio file by at least one of a second module and a third module, creating a timeline, by the first module, related to the ordered images and the created audio file, and rendering the timeline into a video clip by a fourth module, wherein the timeline includes a length of the audio file, a length of the video clip, the ordered images, a display time of each of the ordered images, transition identifiers, transition lengths.</p>
    <p num="p-0015">In another embodiment, a system for creating a video clip comprises a device configured to create an audio file, and a web server configured to create a copy of a still image, a new still image from a selected area of the still image, wherein the new still image and the copy of the still image are automatically ordered, and a time line related to the ordered images and the created audio file, wherein the time line includes a length of the audio file.</p>
    <p num="p-0016">In a further embodiment, a computer readable medium comprises creating a copy of a still image by the first module, the copy of the still image comprising reduced dimensions of the still image, creating a new still image from a selected area of the still image, automatically ordering the new still image and the copy of the still image, creating an audio file by at least one of a second module and a third module, creating a timeline, by the first module, related to the ordered images and the created audio, and rendering the timeline into a video clip by a fourth module, wherein the timeline includes a length of the audio file, an identifier of the audio file created by the second module or the third module, or a volume envelope associated with the audio file.</p>
    <p num="p-0017">The present invention also achieves technical advantages as a system, method and computer-readable medium for assembling and distributing multi-media output. Various embodiments of the present invention are noted below:</p>
    <p num="p-0018">1. Allow any user a simple method of encoding and uploading. This can be done by setting pre-defined profiles containing specific parameters for encoding, indexing, sorting and uploading any type of MMC. The profiles can be created by a system administrator, for example, and stored on a server. The user computing device automatically downloads these profiles.</p>
    <p num="p-0019">2. The user is able to select any type of content. The system is able to allocate the right encoding and compressing process for each type of content. Setting the content attributes, indexing and encoding are done on the user's computing device. The uploaded MMC will then be much smaller than the original MMC thus saving significant upload time. Since the MMC has been identified, described and indexed, the content can be automatically directed to the right storage device. Retrieval by indexing, attribute and key word search is enabled. Once stored on the server, the content can be instantly edited by selecting entry and exit points for the streaming server.</p>
    <p num="p-0020">3. The user can also select separate files and/or segments to be played together as one show (movie making).</p>
    <p num="p-0021">4. Allow the user to add voice to the MMC by means of a telephone, cellular phone, microphone and other similar devices. The user is able to play the voice over while the MMC is played or as an introduction before the MMC. The user should also be able to control the volume setting of the audio channels.</p>
    <p num="p-0022">5. The user is able to mix and integrate different types of MMC such as video, audio, animation and pictures instantly and without rendering a new file. Since the system stores only the instruction sets and the server produces the edited clips, made-up movies and customized production, (on the fly), only a fraction of the storage capacity is required. The server creates Multi Media Presentations (MMP) that are displayed using HTML based platform and Multi Media Messaging (MMS) that are displayed directly on the device (for example, wireless devices such as cell phones).</p>
    <p num="p-0023">6. Organizations are able to create and store pre-defined templates allowing their users to change the MMC content, add text, animation and voice over as needed.</p>
    <p num="p-0024">7. The user is able to distribute the MMC in many format such as:</p>
    <p num="p-0025">E-mail with a link to the message in HTML format (Vid-Mail);</p>
    <p num="p-0026">Independent web site;</p>
    <p num="p-0027">Embedded object in a web site;</p>
    <p num="p-0028">Multi Media Message (MMS) to cell phone and wireless devices; and</p>
    <p num="p-0029">On line instant messaging systems.</p>
    <p num="p-0030">8. Security and access level is built into the system such that user access to the MMC is controlled. Security features are enabled for the MMS and MMP as well such that certain clips will not play for unauthorized viewers.</p>
    <p num="p-0031">9. The system has the ability to automatically attach other MMC to any MMP and MMS such as advertisement and sponsors' messages. This process is known as wrapping and can be done on random basis or triggered by external parameters (such as demographic targeted wrappers).</p>
    <p num="p-0032">10. The integration and execution of commands between different media types (such as streaming and flash) can be controlled and modified even after the publication. Viewers can interfere with the control system via a computing device or any telephone.</p>
    <p num="p-0033">11. The system permits copying and sharing content between different project and storage devices based on the user's access level.</p>
    <p num="p-0034">12. Allow for search and retrieval of MMC based on a unique identifier, indexing system and keyword search. The search and retrieval is machine independent and does not require any specific database and/or synchronization.</p>
    <p num="p-0035">13. By defining commerce criteria, such as pricing, duration of license and time limits, one can offer the MMC for trade without copying and downloading the MMC (thus protecting intellectual properties). The process of such trade is independentone can define the terms of commerce and exchange confirmation without any predefined protocol and/or centralized system.</p>
    <p num="p-0036">14. Using the MMP and MMS command set stored on the server or on the user's computer, a new file can be rendered in the background. The new file is seamless, contains all the elements of MMP or MMS, and can include special effect, transitions, embedded text etc. The rendered file can be stored on the server as a new MMC. The rendered file can also be sent via MMS or downloaded to the user.</p>
    <p num="p-0037">15. The command set can be sent directly to any video editing as a story board. The editing system is automatically loading the right clips at the right places and times for the video editor to complete the editing process. A tremendous amount of time is saved and the communication between the parties is much more effective.</p>
    <p num="p-0038">In one embodiment, is a system for assembling and distributing multi-media output which comprises: a rendering server; a web server; and storage, wherein the servers and the storage are operably coupled; the storage adapted to receive digital media and properties of the media, store the media and the properties, and transmit the media and the properties; the web server adapted to perform at least one of a following action: retrieve the media and properties of the media; manipulate the media and the properties; assemble the properties; and transmit at least one of a following element from a group consisting of: the properties; and the assembled properties; the rendering server adapted to receive commands from the web server. In another embodiment is a method for creating a unified file name, which comprises: assigning a unique identifier based on a destination of a file; assigning a code based on a type of the file after the unique identifier; assigning a code based on a user defined category after the code based on the file type; assigning a code based on a user defined sub-category after the code based on the user defined category; assigning a code related to at least one of: a creator of the file; and a creator of a content of the file, after the code based on the user defined sub-category; and assigning a creation date of at least one of: the creator of the file; and the creator of the content of the file, after the previously assigned code. In a further embodiment, is a computer readable medium which comprises instructions for: indicating, via a first instruction, a time index within a multi-media output; indicating, via a second instruction, a file within the multi-media output; playing the multi-media output via a first player; receiving an audio file at a second player; buffering the audio file at the second player; and playing the buffered audio file during at least one of a following location: the time index at the first player; and at a point the file is encountered at the first player.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0039"> <figref idrefs="DRAWINGS">FIG. 1</figref> depicts a system for creating a video clip in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0040"> <figref idrefs="DRAWINGS">FIG. 2</figref> depicts a more detailed system for creating a video clip in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0041"> <figref idrefs="DRAWINGS">FIG. 3</figref> depicts a flowchart for synchronization in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0042"> <figref idrefs="DRAWINGS">FIG. 4</figref> depicts a timer process in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0043"> <figref idrefs="DRAWINGS">FIG. 5</figref> depicts a transcoding/rendering process in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0044"> <figref idrefs="DRAWINGS">FIG. 6</figref> depicts a user interface for management of uploading images into the system in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0045"> <figref idrefs="DRAWINGS">FIG. 7</figref> depicts a user interface for uploading images from a user's computer into the system in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0046"> <figref idrefs="DRAWINGS">FIG. 8</figref> depicts a simpler user interface to upload images into the system in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0047"> <figref idrefs="DRAWINGS">FIG. 9</figref> depicts a mixer user interface where an end user can assemble a video production in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0048"> <figref idrefs="DRAWINGS">FIG. 10</figref> depicts a video transition chooser interface in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0049"> <figref idrefs="DRAWINGS">FIG. 11</figref> depicts a click or context menu that is displayed when a user clicks on a thumbnail image in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0050"> <figref idrefs="DRAWINGS">FIG. 12</figref> depicts a Pan and Zoom interface window in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0051"> <figref idrefs="DRAWINGS">FIG. 13</figref> depicts a Crop Image interface window in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0052"> <figref idrefs="DRAWINGS">FIG. 14</figref> depicts a male voice text-to-speech input interface in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0053"> <figref idrefs="DRAWINGS">FIG. 15</figref> depicts a voice recording interface window in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0054"> <figref idrefs="DRAWINGS">FIG. 16</figref> depicts a Workbench user interface window in accordance with a preferred embodiment of the present invention;</p>
      <p num="p-0055"> <figref idrefs="DRAWINGS">FIG. 17</figref> illustrates an architecture in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0056"> <figref idrefs="DRAWINGS">FIG. 18</figref> illustrates a receiving and play back in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0057"> <figref idrefs="DRAWINGS">FIG. 19</figref> illustrates an uploader in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0058"> <figref idrefs="DRAWINGS">FIG. 20</figref> <i>a </i>illustrates a screen shot of an uploader login screen in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0059"> <figref idrefs="DRAWINGS">FIG. 20</figref> <i>b </i>illustrates a screen shot of a select media in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0060"> <figref idrefs="DRAWINGS">FIG. 20</figref> <i>c </i>illustrates a screen shot of a thumbnail creator in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0061"> <figref idrefs="DRAWINGS">FIG. 20</figref> <i>d </i>illustrates a screen shot of a encode and upload content in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0062"> <figref idrefs="DRAWINGS">FIG. 21</figref> illustrates a unified file name in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0063"> <figref idrefs="DRAWINGS">FIG. 22</figref> illustrates a screen shot of the unified file naming selection of a UFN field in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0064"> <figref idrefs="DRAWINGS">FIGS. 23</figref> <i>a </i>and <b>23</b> <i>b </i>illustrate a storage and unified filing system in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0065"> <figref idrefs="DRAWINGS">FIG. 24</figref> illustrates a system design in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0066"> <figref idrefs="DRAWINGS">FIG. 25</figref> illustrates the process that the owner of digital media uses to publish the media along with its terms;</p>
      <p num="p-0067"> <figref idrefs="DRAWINGS">FIG. 26</figref> <i>a </i>illustrates a screen shot of sister exchange of exporting digital media in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0068"> <figref idrefs="DRAWINGS">FIG. 26</figref> <i>b </i>illustrates a screen shot of sister exchange of UFN fields in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0069"> <figref idrefs="DRAWINGS">FIG. 27</figref> illustrates selections from user to populate the SISController in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0070"> <figref idrefs="DRAWINGS">FIG. 28</figref> illustrates a SISController in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0071"> <figref idrefs="DRAWINGS">FIG. 29</figref> <i>a </i>illustrates screen shots of multi-media presentation creation of selecting media in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0072"> <figref idrefs="DRAWINGS">FIG. 29</figref> <i>b </i>illustrates screen shots of multi-media presentation creation of selecting destination options in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0073"> <figref idrefs="DRAWINGS">FIG. 29</figref> <i>c </i>illustrates screen shots of multi-media presentation creation of send/save multimedia presentation in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0074"> <figref idrefs="DRAWINGS">FIG. 30</figref> <i>a </i>illustrates a screen shot of editing a clip in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0075"> <figref idrefs="DRAWINGS">FIG. 30</figref> <i>b </i>illustrates a screen shot of sequencing clips in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0076"> <figref idrefs="DRAWINGS">FIG. 31</figref> <i>a </i>illustrates an alternate process controlled by user interface;</p>
      <p num="p-0077"> <figref idrefs="DRAWINGS">FIG. 31</figref> <i>b </i>illustrates an alternate process controlled by user interface;</p>
      <p num="p-0078"> <figref idrefs="DRAWINGS">FIG. 32</figref> illustrates a voice over in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0079"> <figref idrefs="DRAWINGS">FIG. 33</figref> <i>a </i>illustrates a screen shot of the voice over application of the phone line monitor in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0080"> <figref idrefs="DRAWINGS">FIG. 33</figref> <i>b </i>illustrates a screen shot of the voice over application of the media encoding settings in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0081"> <figref idrefs="DRAWINGS">FIGS. 34</figref> <i>a </i>and <b>34</b> <i>b </i>illustrate a sample of receiving a multi-media presentation in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0082"> <figref idrefs="DRAWINGS">FIG. 35</figref> <i>a </i>illustrates the process flow to trigger animation events;</p>
      <p num="p-0083"> <figref idrefs="DRAWINGS">FIG. 35</figref> <i>b </i>illustrates a command to an animation file to play the ending animation;</p>
      <p num="p-0084"> <figref idrefs="DRAWINGS">FIG. 36</figref> illustrates an MMS process flow in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0085"> <figref idrefs="DRAWINGS">FIG. 37</figref> illustrates a SISCommand instruction flow and sample SISCommand instructions in accordance with an exemplary embodiment of the present invention;</p>
      <p num="p-0086"> <figref idrefs="DRAWINGS">FIG. 38</figref> illustrates a rendering server flow in accordance with an exemplary embodiment of the present invention; and</p>
      <p num="p-0087"> <figref idrefs="DRAWINGS">FIG. 39</figref> illustrates an M-GEN in accordance with an exemplary embodiment of the present invention.</p>
    </description-of-drawings> <heading>DETAILED DESCRIPTION OF THE INVENTION</heading> <p num="p-0088">The present invention describes a process of creating video clips from any given set of digital pictures and of creating an audio track in either an automatic mode or a manual mode that is interchangeable. The pictures are provided as a set of Universal Resource Locators (URL's, pointing to one or more servers), uploaded manually or created on line by cropping and saving many pictures from one source. The audio track can be created from several sources including:
</p> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0088">Interactive Voice Response (IVR)using any telephone system the user can call into a computer based telephony application that calls a WMA encoder;</li> <li id="ul0002-0002" num="0089">Text-To-Speech (TTS)a TTS module can be used to convert text to speech;</li> <li id="ul0002-0003" num="0090">Microphoneconnected to a client device which records a voice file on the server; and</li> <li id="ul0002-0004" num="0091">Existing audio fileusually pre-recorded audio such as music or sound effects.</li> </ul> </li> </ul> <p num="p-0089">In manual mode, a preview module synchronizes a visual display (play-list) and an audio track for instant replay. a rendering server receives a command set (or SIS Commands) from a mixer or a predefined set of rules (in automatic mode) and creates a video file in .WMV format, for example. An embedded player recognizes the existence of the .WMV file and plays the video thus eliminating the need to post new HTML code.</p>
    <p num="p-0090">The present invention further describes processing and delivering pictures made to video in a secure manner for use in commerce, such as for use in Internet commerce. Referring now to <figref idrefs="DRAWINGS">FIG. 1</figref>, a system <b>10</b> of the present invention comprises a first module (such as a web server <b>14</b>), at least one of: a second module (such as a TTS engine) <b>16</b> and a third module (such as an IVR engine) <b>18</b>, a fourth module (such as a rendering server) <b>20</b>, a fifth module (such as a media steaming server) <b>22</b>, and memory (not shown). The system <b>10</b> is accessed by a user device <b>12</b> such as a computer, cellular phone, and/or any wireless or wired device capable of communicating with the system <b>10</b>. The user device <b>12</b> is coupled to the fist module <b>14</b>, which is coupled to the second module and/or the third module directly or via the memory. The first module <b>14</b> is coupled to the fourth module <b>20</b> and is optionally coupled to the fifth module <b>22</b>. In other embodiments, a lesser or greater number of modules can be used and the functionality performed by the current invention can be performed by these lesser or greater number of modules without departing from the scope of the present invention. Also, the connections between the modules may be wired, wireless, and a combination of wired and wireless.</p>
    <p num="p-0091">Editing Process</p>
    <p num="p-0092">In one embodiment of the invention, the user uploads images (pictures), preferably in compressed format (such as JPEG) to a dedicated server for editing and transcoding from pictures and audio tracks to video, preferably WMV. A main portion of the invention is the editing process. Instead of transforming the pictures to video and then editing, the software of the present invention prepares (edits) the video using the original pictures and the original sound track (audio). This method allows for very simple editing that is extremely light in processing power. The editing process, as will be explained later, does not require the actual transcoding process to take place until the editing is completed and the editing instructions are summarized in a special command file (a SIS Command) using special command language. Instead of requiring several multiple servers dedicated to the editing process (because the requirement for processing power), the system uses fewer and lighter processing engines. This method also allows a streamlining of the transcoding process (transforming the pictures and associated audio to actual video). Once the user finishes editing the pictures and associated audio, the file containing the instructions on how to use the pictures and audio in the transcoding process are queued for the transcoding process. This achieves two main goals: (1) very efficient use of the transcoding engine, which typically requires most of the processing power, as files are processed only once, and (2) the files are queued (video encoding) in real time on their way to their final destination (the streaming server) as depicted in <figref idrefs="DRAWINGS">FIG. 5</figref>.</p>
    <p num="p-0093">In one embodiment of the present invention, the system uses two players, one for audio and one for pictures. The editing process is premised on creating synchronization points between the two multimedia files (as depicted in <figref idrefs="DRAWINGS">FIGS. 3 and 4</figref>). In one instance, the pictures are displayed evenly in time according to the length of the audio file. For example, if there are 10 pictures to be transformed to video and the length of the audio file is 45 seconds, then each picture will be displayed for approximately 4.5 seconds. In another instance, the user (who created the video) can decide on different allocations of times to each picture based on the content of the audio file. This can be done either interactively (the user clicks the mouse for example when it desires a transition to the next picture) or by setting manually the time allocationin percentages for example.</p>
    <p num="p-0094">In another embodiment of the present invention, the audio track for the video is obtained using a telephone. The user calls a number, dials in an identification number of work in progress, and the server digitizes and compresses the incoming audio track in preparation for the editing process. In yet another variant of the invention, the audio track is uploaded from the user's computer where he/she digitizes the audio locally.</p>
    <p num="p-0095">Text-To-Speech</p>
    <p num="p-0096">In another embodiment of the invention, which can be used in many other applications (beyond Internet commerce), TTS is integrated into the system. This is important for both occasional users as well as aggregators (aggregators assist clients who are large sellers (Power Sellers) selling large quantities of items). The occasional user can benefit from TTS because it provides a professional sounding voice to the video (and the user can choose from a variety of voice options). The aggregator (and by extension his customers) can benefit from TTS because it can automatically create large amounts of sound tracks for many video clips (without the need for human interaction).</p>
    <p num="p-0097">In a further embodiment of the invention, every picture has its associated TTS and the switch to a next picture is performed when the paragraph is over. In yet another embodiment of the current invention, the user can inject quiet periods when needed in order to keep a picture with short text on the screen longer. Likewise, the user can also include music or any other external audio clips to supplement the final video.</p>
    <p num="p-0098">Focal Points</p>
    <p num="p-0099">In yet another element of the present invention, the high resolution of available pictures allow the user to use a much higher quality video by using what are referred to as focal points. In many cases a single picture contains several objects that can be listed on sale. For example, a user may want to sell 10 tools and he created a single high resolution picture of all 10 tools. By using 10 focal points on the image (for example, selecting the focal points by clicks of the mouse), the software of the current invention can create the following: (1) 10 different pictures, and (2) a real video in which the camera is fluidly moving from one object to the next. This is especially useful when there are connections from one object to the next. A user can add pop-up messages and possibly associated text to help in the selling process. Such type of pop-up windows can create the mood for the visualization (add humor) or put a special slant on the object that is easier to do with a pop-up picture (typically smaller) than with the audio track.</p>
    <p num="p-0100">Picture Security</p>
    <p num="p-0101">One of the best ways to sell on the Internet is by using high quality pictures. These pictures often take a great deal of effort to create. Unfortunately, once the pictures are on the Internet they are easy to copy and use. There are no good methods to protect pictures. In one embodiment of the invention, the pictures are transformed to video to facilitate protection. There are many video formats that support DRM (Digital Rights Management) which provides the protection of the pictures that the user worked hard to create. In one embodiment of the invention WMV with its DRM system is used for picture protection.</p>
    <p num="p-0102">The present invention includes a number of features:</p>
    <p num="p-0103">1. Picture to video editing that uses the original pictures and audio tracks in the editing process.</p>
    <p num="p-0104">2. (1) when two players are used for the editing process.</p>
    <p num="p-0105">3. (1) where the transcoding process is streamlined.</p>
    <p num="p-0106">4. Making the video playing length a function of the audio track length.</p>
    <p num="p-0107">5. (4) where time allocated to each picture is equal.</p>
    <p num="p-0108">6. (4) where the time allocated to each picture is manually set by the user.</p>
    <p num="p-0109">7. Using a telephone to create the audio track.</p>
    <p num="p-0110">8. Using text to speech as a source for the sound track.</p>
    <p num="p-0111">9. (8) where every picture has its own text and the duration of the time allocated to each picture is a function of the length of the speech resulting from the text.</p>
    <p num="p-0112">10. (8) where automatic picture to video is created for multiple streamlined advertisements.</p>
    <p num="p-0113">11. (10) directed specifically at aggregators.</p>
    <p num="p-0114">12. (1) or in (10) that facilitates the insertion of external audio clips and music into the picture to video process.</p>
    <p num="p-0115">13. Use of focal points to improve the quality of the video.</p>
    <p num="p-0116">14. A picture to video method in conjunction with a video DRM to protect the pictures from illegal distribution.</p>
    <p num="p-0117">Referring now to <figref idrefs="DRAWINGS">FIG. 2</figref>, a more detailed system <b>30</b> of the present invention includes a user device <b>32</b>, which may be a wired or wireless device, is adapted to send pictures <b>34</b> via a manual process <b>36</b> or an automated process <b>38</b>. If a manual process <b>36</b> is used, the pictures <b>40</b> are received by a mixer <b>40</b>, the pictures are uploaded <b>42</b> to a web server, and can be created <b>44</b> and arranged <b>46</b> or ordered, panned, or zoomed, via a GUI accessible by the user device <b>32</b>. A voice can be recorded via an IVR recording <b>48</b> or a TTS application <b>50</b>, and music can be added <b>52</b> via a music interface. The audio and video can then be previewed <b>54</b>. If the automated process <b>38</b> is used, a pre-defined destination <b>56</b> and pre-defined commands <b>58</b> would perform the uploading, creating, editing, etc. that was previously described in the manual process. Audio and music can also be added via the TTS application <b>50</b> and the music interface <b>52</b>, respectively. In either process <b>36</b>, <b>38</b>, a rendering server <b>60</b> provides a rendering process that is further described in <figref idrefs="DRAWINGS">FIG. 5</figref> which results in a video clip that can be stored <b>62</b>.</p>
    <p num="p-0118">Referring now to <figref idrefs="DRAWINGS">FIG. 3</figref>, a synchronization process <b>70</b> of the present invention is depicted. The process includes retrieving a URL for a first player <b>72</b>, setting the first player to the retrieved URL (first URL) <b>74</b>, retrieving a URL for a second player <b>76</b>, setting the second player to the retrieved URL (second URL) <b>78</b>, starting a timer process <b>80</b> (that is more fully described in <figref idrefs="DRAWINGS">FIG. 4</figref>), and signaling the first player to begin playing <b>82</b>. This process can be used to preview pictures in one media player and audio in another player or both media and audio in one player with the pictures and the audio synchronized.</p>
    <p num="p-0119">Referring now to <figref idrefs="DRAWINGS">FIG. 4</figref>, a timer process <b>90</b> of the present invention is depicted. The process includes determining <b>92</b> if a first player is playing streamed data. If it is not, the process proceeds to step <b>94</b> where a period of time (typically milliseconds) is elapsed before the determining <b>92</b> occurs again. If the player is playing the streamed data, signaling <b>96</b> a second player to begin playing.</p>
    <p num="p-0120">Referring now to <figref idrefs="DRAWINGS">FIG. 5</figref>, a timer process <b>100</b> of the present invention is depicted. The process includes retrieving a dataset (SIS Commands) for the unique picture to video (or multi-media production) identifier <b>102</b>, converting the dataset to an XTL file <b>104</b>, invoking a rendering engine and providing the XTL file, an output path, a file name, a file type, and an encoding profile <b>106</b>, and storing the resulting output file <b>108</b>.</p>
    <p num="p-0121">Referring now to <figref idrefs="DRAWINGS">FIG. 6</figref> a user interface for management of uploading images <b>200</b> into the system is depicted. The reference numerals in the figure include: <b>202</b> which is a UI Button that opens another interface (<b>240</b>) to select images from the user's computer to upload, <b>204</b> which is a UI Button that opens another interface to select images from a web site for upload into the system, <b>206</b> which is a UI Button that opens another simpler interface (<b>260</b>) to allow the user to select images to upload, <b>208</b> which is the image wallet where all the uploaded images are displayed, <b>210</b> which is a UI Button that moves selected clips from the wallet to the storyboard (<b>288</b>), <b>212</b> which is a UI Button that moves all clips from the wallet to the storyboard (<b>288</b>), <b>214</b> which is a UI Button that closes the wallet window, <b>216</b> which is a UI Button that loads the Workbench UI (<b>420</b>), <b>218</b> which is a UI Button that loads the Mixer UI (<b>280</b>), <b>220</b> which is a UI Button that loads the Upload Management UI (<b>200</b>), <b>222</b> which is a UI Button that allows the user to manage their application preferences, <b>224</b> which is a UI Button that displays Help Topics in a text view, <b>226</b> which is a UI Button that displays a video tutorial about the process, and <b>228</b> which is an area for display of textual messages to the user.</p>
    <p num="p-0122">Referring now to <figref idrefs="DRAWINGS">FIG. 7</figref> a user interface for uploading images from a user's computer <b>240</b> into the system is depicted. The reference numerals in the figure include: <b>242</b> which is a file directory listing of the end user's computer, <b>244</b> which is a thumbnail display area of images on the end user's computer, <b>246</b> which is a thumbnail display area of images selected to be uploaded into the system, <b>248</b> which is a set of UI Buttons to manage selected images being displayed in <b>246</b>, <b>250</b> which is a UI Button to start the upload process, <b>252</b> which is a UI Button to select how the images are displayed in <b>244</b>, <b>254</b> which is a UI Button to select how the images are displayed in <b>246</b>, and <b>256</b> which is a set of display graphics detailing the number and size of currently uploaded file.</p>
    <p num="p-0123">Referring now to <figref idrefs="DRAWINGS">FIG. 8</figref> a simpler user interface to upload images <b>260</b> into the system is depicted. The reference numerals in the figure include: <b>262</b> which is a UI Button to open an image selection dialogue, and <b>264</b> which is a UI Button to start the upload process.</p>
    <p num="p-0124">Referring now to <figref idrefs="DRAWINGS">FIG. 9</figref> a mixer user interface where an end user can assemble a video production <b>280</b> is depicted. The reference numerals in the figure include: <b>282</b> which is a Media Player to play the video production, <b>284</b> which is a thumbnail image that represents the original image's sequence in the video, <b>286</b> which is the End Clip marker (which designates the end of the video production), <b>288</b> which is the Storyboard where the end user interacts with the thumbnail images, <b>290</b> which is a UI button that opens the image wallet (<b>208</b>), <b>292</b> which is a UI button that open the Video Transition Chooser Interface (<b>310</b>), <b>294</b> which is a text based help menu system, <b>296</b> which is a UI button that opens the voice recording interface (<b>400</b>), <b>298</b> which is a UI button that opens the female voice text-to-speech input interface, and <b>300</b> which is a UI button that opens the male voice text-to-speech input interface (<b>390</b>).</p>
    <p num="p-0125">Referring now to <figref idrefs="DRAWINGS">FIG. 10</figref> a video transition chooser interface <b>310</b> is depicted. The reference numerals in the figure include: <b>312</b> which is a listing of available video transitions to choose from, <b>314</b> which is a listing of available transition speeds to choose from, <b>316</b> which is a UI button to disable use of video transitions, <b>318</b> which is a UI button to close the current window without saving any choices made by the end user, and <b>320</b> which is a UI button to accept the currently selected transition type and speed.</p>
    <p num="p-0126">Referring now to <figref idrefs="DRAWINGS">FIG. 11</figref> a click or context menu that is displayed when a user clicks on a thumbnail image <b>330</b> is depicted. The reference numerals in the figure include: <b>332</b> which is a UI button that displays a preview of the image, <b>334</b> which is a UI button the creates a duplicate of the current image, <b>336</b> which is a UI button that opens the Pan and Zoom interface window (<b>350</b>), <b>338</b> which is a UI button that opens the Crop Image interface window (<b>370</b>), <b>340</b> which is a set of UI buttons that set the duration of the current image, and <b>342</b> which is a set of UI buttons to remove special effects that have been added to the image.</p>
    <p num="p-0127">Referring now to <figref idrefs="DRAWINGS">FIG. 12</figref> a Pan and Zoom interface window <b>350</b> is depicted. The end user makes a selection for the beginning viewport (<b>352</b>) and the end viewport (<b>354</b>). These selections will create simulated motion in the end video by morphing the image from the beginning viewport to the end viewport. The reference numerals in the figure include: <b>356</b> which is the UI button that saves the changes made to the Pan and Zoom options, and <b>358</b> which is the UI button to cancel any changes made and close the current window.</p>
    <p num="p-0128">Referring now to <figref idrefs="DRAWINGS">FIG. 13</figref> a Crop Image interface window <b>370</b> is depicted, which allows for a user to select a portion of the original image using the selection box (<b>372</b>) and save the new image. The reference numerals in the figure include: <b>374</b> which is a UI button to close the current interface window, <b>376</b> which is a UI button to save the current cropped image as a new image, <b>378</b> which is a UI button to zoom into the current viewport, and <b>380</b> which is a UI button to preview the cropped image.</p>
    <p num="p-0129">Referring now to <figref idrefs="DRAWINGS">FIG. 14</figref> a male voice text-to-speech input interface <b>390</b> is depicted. The reference numerals in the figure include: <b>390</b> which is the male voice text-to-speech input interface. This interface allows the end user to type text into the window (<b>392</b>) and have that text processed into audio by pressing the process speech UI button (<b>394</b>).</p>
    <p num="p-0130">Referring now to <figref idrefs="DRAWINGS">FIG. 15</figref> a voice recording interface window <b>400</b> is depicted, which allows the user to type a script into the window (<b>406</b>) to be recited during a recording. The reference numerals in the figure include: <b>402</b> which is a display area for the telephone number to call to make the voice recording, <b>404</b> which is a display area for the code number that is inputted into the voice recording system, and <b>408</b> which is a UI button to preview the recorded audio.</p>
    <p num="p-0131">Referring now to <figref idrefs="DRAWINGS">FIG. 16</figref> a Workbench user interface window <b>420</b> is depicted. The reference numerals in the figure include: <b>422</b> which is a display area for the title and description of the video, <b>424</b> which is a display area for textual information and help, <b>426</b> which is a UI button that triggers a download of the final video to the end user, <b>428</b> which is a UI button that allows the end user to send the video link via e-mail, <b>430</b> which is a UI button that allows the end user to view the video link, and <b>432</b> which is the UI button that allows the end user to download HTML code to display the video from within a HTML page.</p>
    <p num="p-0132">In one embodiment of the present invention, a method for creating a video clip comprises receiving still image files by a first module, creating a copy of a still image from the still image files with reduced dimensions (such as a thumb nail) by the first module, creating a new still image from a selected area of the still image (i.e. cropping), storing the new still image and the copy of the still image with a unified file name (UFN), ordering the stored images, creating an audio file by at least one of a second module and a third module, creating a timeline, by the first module, related to the ordered images and the created audio, and rendering the timeline into the video clip by a fourth module.</p>
    <p num="p-0133">The method further comprises storing at least one of: metadata related to the still image and the copy of the still image, metadata related to the audio file, the timeline, and information comprising the creating of the audio file (for example, if a user uses TTS, then the information that is stored is the text used to generate the audio. If the user uses a phone number, then the information that is stored is the dialed number, the calling number, a record number or a code number of the IVR application), transitioning from one to another one of the ordered images, and further comprising storing a transition identifier and a transition length, and retrieving at least one of: the metadata related to the audio file, the metadata related to the still image and the copy of the still image, the timeline, and the information comprising the creating of the audio file, the by the first module, wherein the metadata is stored in a command (such as a SIS Command), wherein the metadata stores at least one of: a height, a width, a size, compression data, and a file format.</p>
    <p num="p-0134">The method also comprises panning and zooming at least one of: a portion of or the copy of the still image, a portion of or the new created still image, a portion of or the stored new still image, and a portion of or the stored copy of the still image, wherein the panning and the zooming is a set of coordinates related to the image, wherein the copy of the still image is used for display purposes (i.e. a thumbnail), wherein the new created still image is displayed as an image with reduced dimension, wherein the set of coordinates is stored in the timeline. The method further comprises optionally previewing the timeline via a fifth module, wherein the timeline includes at least one of: a length of the audio file, a length of the video clip, the order of the images, a display time of each of the images, transition identifiers, transition lengths, panning and zooming coordinates, an identifier of the audio file created by the second module or the third module, and a volume envelope (which includes volume points that are the volume and the time that the volume occurs) associated with the created audio file.</p>
    <p num="p-0135">In another embodiment of the present invention, a system for creating a video clip comprises a web server adapted to receive one or more images, the web server adapted to create a copy of the images, the web server adapted to create one or more new images from one or more selected areas of the images, and the web server adapted to provide a unified file name to each of the new images and a unified file name to each of the copies of the images, wherein the copy of the still images is created with reduced dimensions.</p>
    <p num="p-0136">The system further comprises memory adapted to store at least one of: the new image, the copy of the image, the new image provided with the unified file name, the copy of the image provided with the unified file name, wherein the memory is coupled to the web server, a device coupled to the web server, wherein the device is adapted to order at least one of: the received images, the copy of the images, the new images, the stored images, and the ordered images, a text-to-speech module, and an integrated voice response module, wherein at least one of the modules is adapted to create an audio file, wherein at least one of the modules is coupled to at least one of the web server and the memory, wherein the web server is adapted to create a timeline related to the ordered images and the created audio file, wherein the timeline and the audio file are stored in the memory, and a rendering server adapted to render the timeline into the video clip.</p>
    <p num="p-0137">In a further embodiment of the present invention, a computer readable medium comprises instructions for: creating a copy of an image with reduced dimensions, creating a new image from a selected area of the copied image, storing the new image and the copy of the image with a unified file name, and creating a timeline related to the image, the new image, and to audio related to the image and to the new image, wherein the timeline is used to create a video clip.</p>
    <p num="p-0138">Assembling and Distributing Multi-Media Output</p>
    <p num="p-0139">Referring now to <figref idrefs="DRAWINGS">FIG. 33</figref>, reference numeral <b>10</b> describes the overall flow of multimedia from the user to a final multimedia output such as a multimedia presentation. Reference numeral <b>11</b> is the internal processing of the multimedia data and user interaction. Reference numeral <b>12</b> depicts a storage system on which the multimedia is stored. Reference numeral <b>14</b> is the rendering server. This is hardware and/or software that takes many media files as input and outputs a single file. Reference numeral <b>16</b> describes the voiceover system which is hardware and/or software that allows a telephone to record audio that is saved into the storage system <b>12</b>. Reference numeral <b>18</b> is the uploader. It is a software program that is run on the user's machine. This allows the user to select the media that is desired to be placed into the system. It then encodes it into the proper format and allows the user to categorize each media file.</p>
    <p num="p-0140">Reference numeral <b>20</b> is the user's interface into the system, which is preferably web-based using the web server and a scripting language. Reference numeral <b>22</b> are raw multimedia files that are chosen by the user to be saved into the system. Reference numeral <b>24</b> is the end user's hardware that receives the multimedia presentation. Reference numeral <b>26</b> is the end user's storage system. This could be CD Rom, DVD and MP3 player hardware, for example. Reference numeral <b>28</b> is the flow of raw multimedia files into the uploader system. Reference numeral <b>30</b> are the encoded multimedia files that the uploader sends to the storage system <b>12</b>. Reference numeral <b>32</b> is data sent by the uploader <b>18</b> into the storage system <b>12</b>. Reference numeral <b>34</b> is an end user query or search that is used to populate the user interface. Reference numeral <b>36</b> is the flow of data from the storage system <b>12</b> to the user interface <b>20</b>. Reference numeral <b>38</b> are the audio files that the voiceover system <b>16</b> sends into the user interface <b>20</b> that is then sent into the storage system <b>12</b> via message <b>36</b>. Reference numeral <b>40</b> is the decision of a destination based on how the information is sent to the user. Message <b>42</b> is a set of commands sent to the rendering server <b>14</b>. Reference numeral <b>44</b> is the output from <b>40</b> that is sent to an end user via email, the web, MMS, SMS or other text messaging options. Reference numeral <b>46</b> are the multimedia files taken from the storage system <b>12</b> into the rendering server <b>14</b>. The rendering server <b>14</b> takes many of these data files <b>46</b> and creates a single file which it sends to the storage system <b>12</b>, via message <b>48</b> <i>a</i>. It also has the ability to send it via messages <b>48</b> <i>b</i> and <b>48</b> <i>c</i>, to the end user <b>24</b>, and/or directly to a CD Rom <b>26</b>.</p>
    <p num="p-0141"> <figref idrefs="DRAWINGS">FIG. 33</figref> is now further described. The uploader (<b>1</b>) converts and encodes any content (video clips, audio files, animation, graphic, HTML and text, etc.). The content can be retrieved from disk or direct capture from camcorder, web cam, digital camera, camera equipped cell phone, microphone and other similar devices. The upholder also creates a Unified File Name (UFN). The UFN components and a text/XML file (<b>2</b>) with the same file name provides for index and keyword searching. The content is then sent to the right project stored on a stand alone PC, a local file server, or via the Internet to a data center via an FTP site in XML format (<b>3</b>). The UFN prevents the need for a proprietary database and allows users to collaborate across different organizations. Using the user interface <b>20</b> or M-Plat, the users organize content, edit the media, create movies, add voice over via any telephone and creates digital presentations (<b>5</b>). The content is organized in projects or retrieved in real time using indexes built into the UFN or a keyword search (<b>4</b>).</p>
    <p num="p-0142">Using an IVR (telephony) system of the present invention, (<b>6</b>) the user can add a voice over using any ordinary telephone. The M-Plat also controls publishing, distribution, reporting and archiving. If distributed via e-mail or web site, the instruction sets (SISCommands) are stored on-line and e-mail notifications are sent (<b>7</b>). If a new file is required, the SISCommand is sent to the M-Gen (<b>8</b>) and a new file is rendered. The new file is stored in the project and is sent to mobile users (<b>9</b>) via a cellular network or destination device via an FTP site (<b>10</b>).</p>
    <p num="p-0143"> <figref idrefs="DRAWINGS">FIG. 33</figref> further depicts a system for assembling and distributing multi-media output, comprising: a rendering server; a web server; and storage, wherein the servers and the storage are operably coupled; the storage adapted to receive digital media and properties of the media, store the media and the properties, and transmit the media and the properties; the web server adapted to perform at least one of a following action: retrieve the media and properties of the media; manipulate the media and the properties; assemble the properties; and transmit at least one of a following element from a group consisting of: the properties; and the assembled properties; and the rendering server adapted to receive commands from the web server. The commands include at least one of a following element from a group consisting of: the properties; and the assembled properties; and based on the commands, performs at least one of a following action: retrieve the media based on the commands; render the retrieved media; and store the retrieved media on the storage; and transmit the retrieved media to a destination. The system further comprises an audio capture module operably coupled to the web server, the audio capture module adapted to capture audio and DTMF tones, encode the captured audio, and transmit the encoded audio and information related to a call involved with generating the DTMF tones. The digital media comprises at least one of a following type of media from a group consisting of: video; audio; still images; file attachments; animation; and HTML. The manipulation of the media comprises at least one of a following action: copy the media; delete the media; and rename the media. The manipulation of the properties is adapted to change a value of the properties. The assembly of the properties is adapted to sequence the properties associated with each of the media. The transmission of the properties is adapted to transmit at least one of a following element from a group consisting of: the sequence; the properties and the media. The commands further include at least one of a following element from a group consisting of: a destination; and 5.a type of the media.</p>
    <p num="p-0144">Referring now to <figref idrefs="DRAWINGS">FIG. 34</figref>, reference numeral <b>50</b> is an over all process from the receipt of commands <b>44</b> to the receipt of the multimedia presentation <b>56</b>. The process starts with the receipt of sis commands <b>44</b>, to the end user <b>24</b>. Reference numeral <b>52</b> is the user's request to view the multimedia presentation. This is sent to the storage system <b>12</b>. Reference numeral <b>54</b> is a decision based on what type of hardware <b>24</b> the user originates from; either a computer or a mobile device. If it is a computer, then <b>56</b> shows the streaming of the media, the multimedia presentation to the end user's computer. If it is a mobile device, then a decision <b>58</b> has to be made on what type of device it is and how to send the multimedia to it. If the decision is that the mobile device can handle stream multimedia <b>56</b>, the media is sent to the device <b>24</b>. If the mobile device cannot handle stream media, then a set of commands <b>42</b> is sent to the rendering server <b>14</b> to create a single file which is then sent via <b>60</b> to the mobile device <b>24</b>.</p>
    <p num="p-0145"> <figref idrefs="DRAWINGS">FIG. 34</figref> is further described below.</p>
    <p num="p-0146">The SISCommands are sent to recipients via the Internet (<b>1</b>) or wireless networks (<b>2</b>). Upon request the content is played back using streaming technology. (<b>3</b>) In the wireless environment the network carrier determines the right format for streaming or download (<b>4</b>). The receiving party may choose to respond or forward the message and can even add Voice Over using any telephone (<b>5</b>). The reply/forward message is stored on the project and notification is sent to the receiver (<b>6</b>). Upon request for play back the content is sent to Internet Users using Streaming Technology (<b>7</b>). Mobile users, upon determinating the right player, receive stream media (<b>8</b>) or a new, downloadable file, via the M-Gen (<b>9</b>). Since the SIScommand are small (1-5 k) compared to any typical Rich Media file (1-100 MB), storage space and airtime are largely reduced.</p>
    <p num="p-0147">Referring now to <figref idrefs="DRAWINGS">FIG. 35</figref>, the uploader <b>18</b> is depicted. The process flow from login to the system until the media is sent to the storage system <b>12</b> is described. At reference numeral <b>70</b>, the user logs in with a set of credentials. At reference numeral <b>72</b>, a check is made to see if the credentials are valid. If they are not valid, the application exits <b>74</b>. If a current library is found with the user's credentials <b>73</b>, then a request is made to get the project information <b>84</b>. If a project is not found, one path to <b>76</b> will allow them to solve an application. Reference numeral <b>78</b> allows a choice of the look and feel, the background, the color scheme, and then <b>80</b> sends a notification to have the project built. On a simpler version, a new project <b>82</b> is created automatically. Once a project exists for the logged-in user <b>84</b>, project information is then requested from the server <b>12</b>. At reference numeral <b>86</b>, if previous multimedia has already been encoded and is ready to send, it goes directly to <b>104</b> and is uploaded into the system. At reference numeral <b>88</b>, the user can choose to work in an offline mode in which the data is not sent to the server after it is finished encoding but waits until a later time. Reference numeral <b>90</b> is a decision whether to capture multimedia data directly from the computer or to select files. If the user wishes to capture live data directly from the computer, then a capture device <b>92</b> is used. After the files have either been captured or selected <b>94</b>, a jpeg image is extracted from the file to allow the media to be represented by a graphic icon or thumbnail. This happens automatically. Reference numeral <b>96</b> is a check for advanced options. If the user does not have advanced options, then <b>98</b> they are given an opportunity to select a custom graphic or jpeg to be used as a thumbnail <b>98</b>. At reference numeral <b>100</b>, if they do have advanced options, then they are allowed to select a graphic representation or thumbnail to categorize using the UFN (unified file name) and to type in a description of this media file. At reference numeral <b>102</b>, the media is then encoded into the proper streaming format and at reference numeral <b>104</b>, it is uploaded into the storage system <b>12</b>. At reference numeral <b>106</b>, the data on the user's machine is then deleted and at reference numeral <b>108</b>, the user receives a done message that the process has been completed.</p>
    <p num="p-0148">Referring now to <figref idrefs="DRAWINGS">FIG. 36</figref> <i>a</i>, a login screen of the uploader is depicted. At reference numeral <b>70</b>, the login tab <b>112</b>, and the user input <b>114</b> for the library ID <b>206</b> are shown. The user input <b>116</b> for the project ID <b>208</b>, the input for the user's user name <b>118</b> into the system <b>202</b>, the user's input <b>120</b> for the password, the button the user clicks to verify their login information <b>122</b>, and a checkbox that the user can determine whether they are in online or offline mode <b>124</b> as shown on <figref idrefs="DRAWINGS">FIG. 35</figref> (reference numeral <b>88</b>) are shown.</p>
    <p num="p-0149">Reference numeral <b>128</b> is a button to clear the cache. This removes any extraneous files on the user's desktop and is the same process as shown in <figref idrefs="DRAWINGS">FIG. 35</figref> (reference numeral <b>106</b>).</p>
    <p num="p-0150">Referring now to <figref idrefs="DRAWINGS">FIG. 36</figref> <i>b</i>, the main screen of the application <b>90</b> (which allows users to select digital media from their local computer) includes embedded help videos <b>126</b> The following are banners and backgrounds used by the application: video <b>132</b>, screen shots <b>134</b>, file attachments <b>136</b>, static pictures or graphics <b>138</b>, audio files <b>140</b>, look and feel <b>142</b>, HTML gilrd <b>144</b>, beginning the encoding and uploading <b>146</b>, a descriptive help text <b>148</b>, an area where the selected files are displayed <b>150</b>, a button that allows users to add files <b>152</b>, clearing any files <b>154</b> in the list <b>150</b>, removing only files that are checked <b>156</b> in the list <b>150</b>, another textural help box <b>158</b> allowing the user to choose different formats and profiles for their encoding sessions <b>160</b>, allowing the users to view online help <b>162</b>, allowing the users to capture a custom thumbnail from an image in the media <b>164</b>, and a next button <b>166</b> which takes the users to a next step or area.</p>
    <p num="p-0151">Referring now to <figref idrefs="DRAWINGS">FIG. 36</figref> <i>c </i>the thumbnail extractor <b>94</b> is depicted.</p>
    <p num="p-0152">Referring now to <figref idrefs="DRAWINGS">FIG. 36</figref> <i>d </i>the encoding and uploading screen, <b>102</b> and <b>104</b>, are depicted.</p>
    <p num="p-0153">Referring now to <figref idrefs="DRAWINGS">FIG. 37</figref>, the processing <b>170</b> which the user categorizes their media by choosing its UFN (unified file name), is depicted. Reference numeral <b>172</b> is the unique contact ID of the person uploading or storing the file, reference numeral <b>174</b> is a general category that describes the content of the file, reference numeral <b>176</b> is another category or subcategory describing the file, reference numeral <b>178</b> is the creator of the file, reference numeral <b>180</b> is the date the file was created, reference numeral <b>182</b> is the version or sequence number and reference numeral <b>184</b> can be any user defined codes. When all these different categories and codes are put together, you end up with a UFN that is unique to this file.</p>
    <p num="p-0154">UNF is done by grouping together set of codes, ID's and dates. The actual code naming can be done by the end-user or automatically following sets of rules (for example, a predefined set of rules). The main advantages of the UNF are that it is virtually impossible to create a duplicate file name by any user, and a query and retrieval of specific data/raw material can be done directly by the Operating System. There is no need for an agreed-upon database in order to share data among users and cross organizations.</p>
    <p num="p-0155">Referring now to <figref idrefs="DRAWINGS">FIG. 38</figref>, the user interface to choose the UFN for a media file is disclosed. The screen shot of the user interface <b>170</b> includes the general category <b>174</b>, the class or subcategory <b>176</b>, the creator <b>178</b>, the creation date <b>180</b>, the sequence number <b>182</b>, the thumbnail or the graphic representation of this digital media <b>184</b>, the textural description <b>186</b> that can be entered by the user, the section <b>188</b> in which this file will be placed in the storage system <b>12</b>, a displayed <b>190</b> UFN, a checkbox <b>192</b> that the user selects when done choosing all the categories, and, to process or import into the system any checked files, button <b>194</b> is used</p>
    <p num="p-0156">The button copy down <b>196</b> allows the user to copy <b>174</b>, <b>176</b>, <b>178</b>, <b>180</b>, <b>186</b>, <b>188</b> to the fields below it. Reference numeral <b>198</b> depicts a set of fields that have been chosen, reference numeral <b>199</b> shows that in the UFN, the files automatically identified by the type of file (that is determined from <figref idrefs="DRAWINGS">FIG. 36</figref> <i>b</i>, <b>132</b> through <b>144</b>), reference numeral <b>200</b> is the media player in the user interface that is both used to display help clips and display the media as its playing, reference numeral <b>202</b> is the user's login or user name, reference numeral <b>204</b> is their access level, reference numeral <b>206</b> is the unique library ID that they are currently in, and reference numeral <b>208</b> is the unique project they are currently in.</p>
    <p num="p-0157">Referring now to <figref idrefs="DRAWINGS">FIGS. 39</figref> <i>a </i>and <b>39</b> <i>b </i>an alternate user interface to <figref idrefs="DRAWINGS">FIG. 38</figref> is depicted.</p>
    <p num="p-0158">Users are capable of defining the source, purpose, type, creator and date created while dumping the raw material (video, audio or pictures) or creating the files (text and images). The following steps are taken:</p>
    <p num="p-0159">The user name and captured date are collected, a unique ID is set to each user and or production, text describing the them and the flow is added, category and classes are added from a pre-defined, self learning database, abbreviation of the creator name and the creation date are added to create a unique identifier, file type is automatically collected and a code is added to the file name, and a unique file name with time stamp is generated and the data is stored.</p>
    <p num="p-0160">Regardless of the source, the file type and the user, the file stored using the SISController allows for storage and retrieval of all types of data and digital video, pictures and audio allowing different users to collaborate. The unique file naming prevent duplications and can be retrieved either by using a proprietary database with full text search capability, search by defined filed, or directly by any operating system.</p>
    <p num="p-0161">The present invention further describes a method for creating a unified file name that comprises: assigning a unique identifier based on a destination of a file; assigning a code based on a type of the file after the unique identifier; assigning a code based on a user defined category after the code based on the file type; assigning a code based on a user defined sub-category after the code based on the user defined category; assigning a code related to at least one of: a creator of the file; and a creator of a content of the file, after the code based on the user defined sub-category; and assigning a creation date of at least one of: the creator of the file; and the creator of the content of the file, after the previously assigned code. The method further optionally comprises assigning a version of the file after the creation date and optionally comprising at least one user defined code after the assigned version.</p>
    <p num="p-0162">Referring now to <figref idrefs="DRAWINGS">FIG. 24</figref>, reference numeral <b>220</b> shows three process flows for the exchanging of digital media between two entities. Reference numeral <b>221</b> is the path for publishing in which files are selected to be published or authored <b>222</b>, terms for the purchase or reuse of the media to be specified <b>224</b>, and the publishing of the media along with their terms <b>226</b>. Reference numeral <b>227</b> is the process of purchasing digital media in which the purchaser makes a response <b>228</b> to any published media from <b>226</b>. The buyer or purchase can <b>230</b> modify the offer or <b>232</b> make a bid on the digital media that they wish to purchase. Reference numeral <b>234</b> is the acceptance by the publisher of the offer or bid for the digital media. Reference numeral <b>235</b> is the process flow of the digital media after an agreement has been reached on its purchase in which the original file from <b>222</b> is copied in the owner's project <b>236</b> a jpeg image or thumbnail is created into the purchaser or buyer's project <b>238</b> and a tracker or reporting system is activated for this piece of digital media <b>240</b>.</p>
    <p num="p-0163">Referring now to <figref idrefs="DRAWINGS">FIG. 25</figref>, reference numeral <b>221</b> is the process that the owner of digital media uses to publish the media along with its terms. At reference numeral <b>222</b>, the owner can view a list of current catalogs or stores that contain current digital media. The owner then has a choice to edit or delete current catalogs <b>225</b> create a new catalog of content <b>223</b>. At reference numeral <b>228</b>, the owner selects clips to be published, creates a description for the catalog or store and then saves it. At reference numeral <b>224</b>, the owner of the digital media sets forth the terms for the purchase of their media, selects look and feel, banner, backgrounds, color schemes, etc.k and at reference numeral <b>226</b> the list of media is then published on an electronic storefront. Referring now to <figref idrefs="DRAWINGS">FIG. 26</figref> <i>a</i>, reference numeral <b>221</b> is the user interface for publishing or exporting digital media for purchase.</p>
    <p num="p-0164">Referring now to <figref idrefs="DRAWINGS">FIG. 26</figref> <i>b </i>is the user interface to specify terms <b>224</b> is depicted. Reference numeral <b>500</b> is the field code that becomes part of the UFN, reference numeral <b>502</b> is a short textural description, reference numeral <b>504</b> is the business description that is used in the exchange agreement, and reference numeral <b>506</b> is the catalog description which is used when the site is published in <b>226</b>.</p>
    <p num="p-0165">Referring now to <figref idrefs="DRAWINGS">FIG. 27</figref>, the process <b>34</b> that a user creates a query or search into the storage system <b>12</b> to populate the user interface <b>20</b> is depicted. At reference numeral <b>241</b> the user starts the process. The user can select from a plurality (1-6 for example) of different search variables. Reference numeral <b>242</b> is the client ID to search on, reference numeral <b>244</b> are categories to search, reference numeral <b>246</b> are subcategories to search, reference numeral <b>248</b> are creators to search, reference numeral <b>250</b> can be a range of creation dates to search, reference numeral <b>252</b> are any key words contained in the description of the file to search on, reference numeral <b>254</b> ends the user selections, at reference numeral <b>256</b>, the query is sent to the database, at reference numeral <b>258</b>, data is returned to populate the user interface.</p>
    <p num="p-0166">Retrieving any data and populating the user interface <b>20</b> is done by simple query, following the same coding system that created the file name or by keyword search. This presents the data as a set of images. The human brain can process images by far much faster than text. Efficiency and productivity increase and there is no need for users training.</p>
    <p num="p-0167">Referring now to <figref idrefs="DRAWINGS">FIG. 28</figref>, the overall process flow <b>259</b> that the user follows to create their multimedia presentation is depicted. Reference numeral <b>260</b> begins the process. At reference numeral <b>262</b>, media files are selected and optionally start and end times within the media file are selected, at reference numeral <b>264</b>, text audio tracts or special effects are selected. At reference numeral <b>266</b>, a decision is made to whether the user wishes to add more digital media. If yes, they can select a transition <b>268</b> between medias that takes the user back to <b>262</b>. If they do not wish to add any more media, they select their output type <b>270</b>. If the output type is rich media <b>272</b>, they select a destination. At reference numeral <b>274</b>, the job can be submitted to the rendering server, at reference numeral <b>278</b>, the instructions are sent to the chosen destination. After the process is complete the user is prompted to create another multimedia presentation <b>280</b>. If they select no <b>282</b>, the process ends. If they select yes <b>260</b> starts the process over again. At reference numeral <b>276</b>, if a user chooses to output sys commands only, then they select a destination <b>278</b> and commands are sent to that destination.</p>
    <p num="p-0168">The user identifies (visually or by text) the desired clip (<b>1</b>) and can play or run the associated application on the user interface <b>20</b> display window. Text and media can be selected from pre-defined menus (<b>2</b>). (The menus are defined by the system administrator/service provider). Transition types are selected as well (<b>3</b>). If a Rich Media output is selected (<b>4</b>) then the SISCommands <b>42</b> are sent directly to the Rendering Server (<b>5</b>) for production, otherwise the SISCommands are sent to another end-user, portable device, service provider or storage (<b>6</b>). The process is fast and requires no training. A novice user can produce a rich media presentation in minutes, a task that otherwise requires a studio and many hours of labor by highly trained professionals.</p>
    <p num="p-0169">Referring now to <figref idrefs="DRAWINGS">FIG. 29</figref> <i>a</i>, the user interface <b>20</b> is depicted. Once the user has selected their clips, they select different templates in which the multimedia presentation resides <b>284</b>.</p>
    <p num="p-0170">Referring now to <figref idrefs="DRAWINGS">FIG. 29</figref> <i>b</i>, the user interface <b>290</b> for various options for the multimedia presentation is depicted.</p>
    <p num="p-0171">Referring now to <figref idrefs="DRAWINGS">FIG. 29</figref> <i>c</i>, the destination selection <b>276</b> is depicted.</p>
    <p num="p-0172">Referring now to <figref idrefs="DRAWINGS">FIG. 30</figref> <i>a</i>, the user interface <b>262</b> for selecting start and end times within a clip is depicted.</p>
    <p num="p-0173">Referring now to <figref idrefs="DRAWINGS">FIG. 30</figref> <i>b</i>, the user interface <b>263</b> for sequencing clips, and selecting text, audio tracts, special effects, and transitions <b>264</b>-<b>268</b> is depicted.</p>
    <p num="p-0174">Referring now to <figref idrefs="DRAWINGS">FIGS. 31</figref> <i>a</i>-<b>31</b> <i>b </i>an alternate process controlled by user interface <b>20</b> is depicted. The process is described below. Upon starting a new project, raw video is collected from all sources including the user's PC, dedicated servers, other stations on the network and via the Internet, for example. Time stamps are captured for the START and STOP of individual clip, and audio from different sources (such as music, voice, sound effects) is selected. The user provides text information that is played as banner (at a bottom of movie, for example) or a stand alone picture. Delivery information is selected which includes: physical media (CDR) or sending rendering instructions to an end user via e-mail.</p>
    <p num="p-0175">Referring now to <figref idrefs="DRAWINGS">FIG. 32</figref>, the voiceover process flow <b>16</b> for capturing audio over a telephone, coding it into a string format, and saving it onto a storage system <b>12</b> is depicted. Reference numeral <b>300</b> is an incoming call where Caller ID is captured. At reference numeral <b>302</b>, the number that was dialed is detected and, depending on which number the user dialed, different greeting sets are encountered. Reference numeral <b>304</b> is the standard greeting set, and reference numeral <b>306</b> is a custom greeting set with help and samples. At reference numeral <b>310</b>, the user's input is captured to direct them to the help system <b>312</b>, the sample system <b>314</b> or to the prompt for voice recording <b>318</b>.</p>
    <p num="p-0176">Reference numeral <b>308</b> is another customer greeting set that includes a subset of greetings <b>316</b>. At reference numeral <b>318</b>, the user is prompted to record their message. At reference numeral <b>320</b> a decision is made regarding DTMF enabling. At reference numeral <b>322</b>, the DTMF capturing is set to on, at reference numeral <b>324</b>, the audio is recorded, at reference numeral <b>326</b>, if advanced options is enabled this allows the user to <b>328</b>, play back the recording <b>328</b> or re-record their message <b>330</b>. At reference numeral <b>332</b>, after recording is finished, the voice file is then stored on the storage system <b>12</b>, at reference numeral <b>334</b>, the caller's number is also stored on the storage system, at reference numeral <b>336</b>, if DTMF tones were captured, they are also stored on the storage system, and at reference numeral <b>38</b> (which refers back to <figref idrefs="DRAWINGS">FIG. 33</figref>), data flows from the voiceover system into the user interface into the storage system <b>12</b>.</p>
    <p num="p-0177"> <figref idrefs="DRAWINGS">FIG. 32</figref> is further described below. Upon calling in, the caller ID is captured (<b>1</b>) and, based on the call in phone number, a greeting to play is selected (<b>2</b>). The system administrator can set any number of voice boxes and greeting paths. In this example, set <b>1</b> goes directly to voice prompt, set <b>2</b> provides for help and pre-recorded samples and set <b>3</b> is a combination of several voice boxes. The user is then prompted to record his voice upon a tone signal (<b>3</b>). If the DTMF option (<b>4</b>) is enabled then DTMF tones and time is captured. If playback and re-record option is enabled then the user is promoted (<b>5</b>). The voice file is encoded and stored on the server (<b>6</b>) as well as the caller ID (<b>7</b>) and DTMF time code (<b>8</b>).</p>
    <p num="p-0178">Referring now to <figref idrefs="DRAWINGS">FIG. 33</figref> <i>a</i>, the user interface <b>340</b> to the voiceover system console is depicted. Reference numeral <b>341</b> is a button that starts or stops the software, reference numeral <b>342</b> is the system status display page, reference numeral <b>344</b> is the host settings, reference numeral <b>346</b> is the media and coding settings, and reference numeral <b>348</b> is the voice recording settings. Reference numeral <b>350</b> shows the current status of the phone lines, reference numeral <b>352</b> displays the name of the group that each phone line is associated with, reference numeral <b>354</b> displays the current time spent in each step of process <b>16</b>, reference numeral <b>356</b> shows the total accumulated duration of the current call, and reference numeral <b>358</b> shows the current application designated for each phone call.</p>
    <p num="p-0179">Referring now to <figref idrefs="DRAWINGS">FIG. 33</figref> <i>b</i>, the user interface <b>346</b> for the media and coder settings are depicted. Reference numeral <b>360</b> includes user inputs for the settings, and reference numeral <b>362</b> is the testing and debugging interface.</p>
    <p num="p-0180">Referring now to <figref idrefs="DRAWINGS">FIG. 34</figref> <i>a</i>, a sample multimedia presentation <b>370</b> is depicted. Reference numeral <b>372</b> is a timeline to allow the user to sequence a subset of clips to play their own personal movie. Reference numeral <b>374</b> is the interface for a user to record their own personal voice message. Reference numeral <b>376</b> allows the end user to send a copy of their personalized presentation via email.</p>
    <p num="p-0181">Referring now to <figref idrefs="DRAWINGS">FIG. 34</figref> <i>b</i>, an alternate sample of the end user's experience from a multimedia presentation <b>371</b> is depicted.</p>
    <p num="p-0182"> <figref idrefs="DRAWINGS">FIG. 35</figref> <i>a </i>includes Instruction Set A: to play the starting animation and stay in loop until movie <b>1</b> is playing for a defined minimum time, if applicable (buffering done). At Instruction Set B: As soon as movie <b>1</b> ends play Transition and stay in loop while Movie is buffering for a defined minimum time, if applicable. At Instruction Set C: Upon Event A, activate the Special Effect <b>1</b> and upon Event B activate the Special Effect.</p>
    <p num="p-0183"> <figref idrefs="DRAWINGS">FIG. 35</figref> <i>a </i>is further described below:</p>
    <p num="p-0184">1. The page is loaded and the Starting Animation plays.</p>
    <p num="p-0185">2. At the predefined time Movie <b>1</b> is called to play. Buffering starts <b>3</b> while Starting Animation stays in a loop.</p>
    <p num="p-0186">3. As soon as Movie <b>1</b> starts, Starting Animation stops.</p>
    <p num="p-0187">4. Movie <b>1</b> plays. Once finished, the Transition Animation plays.</p>
    <p num="p-0188">5. At the predefined time Movie <b>2</b> is called to play. Buffering starts while Transition Animation stays in a loop.</p>
    <p num="p-0189">6. Movie <b>2</b> plays until the end.</p>
    <p num="p-0190">7. Upon Event A (Mouse click, DTMF signal, key pad pressed etc.), Special Effect <b>1</b> plays.</p>
    <p num="p-0191">8. Upon Event B (Mouse click, DTMF signal, key pad pressed etc.) Special effect Animation <b>2</b> plays.</p>
    <p num="p-0192">9. Animation ends.</p>
    <p num="p-0193">Referring again to <figref idrefs="DRAWINGS">FIG. 35</figref> <i>a</i>, <b>379</b> is the process flow to trigger animation events based on instructions sent while streaming media is playing, <b>380</b> is the animation file, <b>382</b> is the instruction set file, <b>56</b> is the streaming file, <b>384</b> is a starting animation as it is played after the page is loaded, <b>386</b> refers to the event of the page load or the page starting while the animation is playing, <b>388</b> shows the start of the streaming files buffering event, <b>394</b> shows the effect of that event which stops the beginning animation, <b>396</b> is the event that the streaming file has finished and triggers <b>398</b>, the start of the transition <b>400</b> in the animation file, <b>402</b> is the start of the next streaming file, <b>404</b> is its buffering event, <b>406</b> is the event that the buffering is completed, <b>408</b> is the instruction to start the transition from the animation file, <b>410</b> is the event triggered from the instruction set <b>382</b> which plays special effect animation <b>412</b>, <b>414</b> shows another triggered event from the instruction set that plays a separate animation special effect <b>416</b>, <b>418</b> is the event that the streaming file has ended, and <b>420</b> sends a command to the animation file to play the ending animation <b>422</b> (<figref idrefs="DRAWINGS">FIG. 35</figref> <i>b</i>).</p>
    <p num="p-0194">Referring now to <figref idrefs="DRAWINGS">FIG. 36</figref>, the following steps occur:</p>
    <p num="p-0195">1. Content is uploaded to the server from existing data files, video camera or cam-equipped cell phone.</p>
    <p num="p-0196">2. Using the web based M-Plat any user can customize the content, create a personalize movie, add a voice over and send to any PC, web site or cell phone.</p>
    <p num="p-0197">3. The web server holds the content and customized messages. The stream server distributes the content.</p>
    <p num="p-0198">4. If the message is to be sent to a cell phone, the M-Gen receives the time stamps and creates a new file using DES and the media encoders.</p>
    <p num="p-0199">5. The M-Gen transfers the appropriate file and destination information to the carrier. Content is forwarded to the devices (download or streaming).</p>
    <p num="p-0200">6. Mobile user can respond to the message by SMS and/or voice. The voice message is embedded in the response e-mail.</p>
    <p num="p-0201">Referring further to <figref idrefs="DRAWINGS">FIG. 36</figref> <i>a</i>, a process flow <b>429</b> for receiving and replying to, a multimedia message received by a global device user is depicted. This is an abbreviated process flow from <figref idrefs="DRAWINGS">FIG. 33</figref> and <figref idrefs="DRAWINGS">FIG. 34</figref> and includes raw media <b>22</b> that is stored on storage devices <b>12</b>. A multimedia presentation is created at the user interface <b>20</b> and then is sent <b>42</b> to the rendering server <b>14</b>, which creates a single file and sends it to the mobile device <b>60</b>. The mobile device receives it <b>24</b>, <b>432</b>, the mobile device user has a chance to reply to this presentation, <b>25</b> and sends the reply via <b>434</b> back to the storage system.</p>
    <p num="p-0202">Referring now to <figref idrefs="DRAWINGS">FIG. 37</figref>, <b>430</b> is the information flow from the user through the rendering server with a single file being created then and some samples of the information.</p>
    <p num="p-0203">At <b>42</b> the user submits instructions to the rendering server, <b>438</b> the rendering server retrieves one or more file, creates a single file, <b>440</b>, that single file is sent to the user, <b>442</b> the process ends. <b>444</b> is an example of possible commands created by the user that the rendering server uses to assemble files into a new single file. The box labeled <b>262</b>-<b>268</b>, <b>276</b>, <b>290</b> is an example of the data that is captured by the user to create his multimedia</p>
    <p num="p-0204">Referring now to <figref idrefs="DRAWINGS">FIG. 38</figref>, <b>14</b>this is the process flow of the rendering server, <b>14</b>, from the rendering server's prospective.backslash., <b>42</b>one or more sets of instructions have been to the rendering server, <b>46</b>the rendering server accesses raw files from the storage system, <b>12</b>. <b>456</b>the rendering server runs a process that combines one or more files into a new single file. <b>48</b>A-<b>48</b>Cis the return of this single file from the media from the rendering server back to the user.</p>
    <p num="p-0205">Referring now to <figref idrefs="DRAWINGS">FIG. 39</figref>, <b>14</b>this is an expanded view of the rendering server process. It begins <b>42</b> a set of commands is received <b>42</b> is the list of possible fields included in this command set, <b>470</b> refers to a job control process. This process is responsible for initiating the actual rendering of the files, <b>474</b> is the actual rendering process once it is initialized, <b>476</b> is the timeline of the final movie that needs to be outputted. It retrieves data from <b>46</b> audio, video, pictures, raw data from system <b>12</b>, the storage system, <b>444</b> is a project file that describes how they combine and render the files <b>46</b>, <b>478</b> is the raw data stream of a single file that has been created, <b>480</b> is the output process for rendering engine. Depending on the format of the output file, it has the ability to take as an input <b>472</b> and encode a project file. This project file contains all the parameters needed to reduce a streaming media file. This is an optional input. <b>480</b> also has the ability to produce a file in a non-streaming format. <b>482</b> is the final product for file that is stored on <b>48</b>A or sent through <b>48</b>C and <b>48</b>B.</p>
    <p num="p-0206">Although an exemplary embodiment of the system, method, and computer readable medium of the present invention has been illustrated in the accompanied drawings and described in the foregoing detailed description, it will be understood that the invention is not limited to the embodiments disclosed, but is capable of numerous rearrangements, modifications, and substitutions without departing from the spirit or scope of the invention as set forth and defined by the following claims. For example, the capabilities of the systems <b>10</b> and <b>30</b> can be performed by one or more of the modules or components described herein or in a distributed architecture. For example, all or part of the functionality performed by the individual modules, may be performed by one or more of these modules. Further, the functionality described herein may be performed at various times and in relation to various events, internal or external to the modules or components. Also, the information sent between various modules can be sent between the modules via at least one of: a data network, the Internet, a voice network, an Internet Protocol network, a wireless device, a wired device and/or via plurality of protocols. Also, the messages sent or received by any of the modules may be sent or received directly and/or via one or more of the other modules.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5642135">US5642135</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 25, 1994</td><td class="patent-data-table-td patent-date-value">Jun 24, 1997</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">For storing binary input picture data having a black-and-white picture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6046734">US6046734</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 1997</td><td class="patent-data-table-td patent-date-value">Apr 4, 2000</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image processor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6195503">US6195503</a></td><td class="patent-data-table-td patent-date-value">Feb 6, 1998</td><td class="patent-data-table-td patent-date-value">Feb 27, 2001</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Image and sound recording/reproducing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6256061">US6256061</a></td><td class="patent-data-table-td patent-date-value">Jun 9, 1998</td><td class="patent-data-table-td patent-date-value">Jul 3, 2001</td><td class="patent-data-table-td ">Interactive Pictures Corporation</td><td class="patent-data-table-td ">Method and apparatus for providing perceived video viewing experiences using still images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6353699">US6353699</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 24, 1995</td><td class="patent-data-table-td patent-date-value">Mar 5, 2002</td><td class="patent-data-table-td ">Barry H. Schwab</td><td class="patent-data-table-td ">Method and apparatus for compiling audio/video information from remote sites into a final video program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020097327">US20020097327</a></td><td class="patent-data-table-td patent-date-value">Jan 23, 2002</td><td class="patent-data-table-td patent-date-value">Jul 25, 2002</td><td class="patent-data-table-td ">Masafumi Yamasaki</td><td class="patent-data-table-td ">Electronic camera, imaging system and imaging method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040257380">US20040257380</a></td><td class="patent-data-table-td patent-date-value">Jun 20, 2003</td><td class="patent-data-table-td patent-date-value">Dec 23, 2004</td><td class="patent-data-table-td ">Herbert Leslie B.</td><td class="patent-data-table-td ">Imaging method and system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20140025510">US20140025510</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 23, 2012</td><td class="patent-data-table-td patent-date-value">Jan 23, 2014</td><td class="patent-data-table-td ">Sudheer Kumar Pamuru</td><td class="patent-data-table-td ">Inventory video production</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc370/defs370.htm&usg=AFQjCNEr5EDctcusna2HU7Iww2g4dx3BIw#C370S230000">370/230</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc709/defs709.htm&usg=AFQjCNFBXWYqUOVuuxerz7B8cqt9daJk7Q#C709S231000">709/231</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0015160000">G06F15/16</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G01R0031080000">G01R31/08</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N21/422">H04N21/422</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/034">G11B27/034</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N21/47205">H04N21/47205</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N21/42203">H04N21/42203</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N7/17318">H04N7/17318</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N21/8153">H04N21/8153</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N21/854">H04N21/854</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N21/25891">H04N21/25891</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=HwM2BwABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F13/00">G06F13/00</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N21/422M</span>, <span class="nested-value">H04N21/854</span>, <span class="nested-value">H04N7/173B2</span>, <span class="nested-value">H04N21/422</span>, <span class="nested-value">H04N21/472E</span>, <span class="nested-value">H04N21/258U3</span>, <span class="nested-value">G11B27/034</span>, <span class="nested-value">H04N21/81G1</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Nov 12, 2013</td><td class="patent-data-table-td ">FPB1</td><td class="patent-data-table-td ">Expired due to reexamination which canceled all claims</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 27, 2012</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120906</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4ff636b3d23669b7103f3b3a3a18b4cd.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0Z1gpjTk3eGU5Kt-J3LAUn2bZ8vg\u0026id=HwM2BwABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U1be5JkEmGizHMwQ-2LthdTw5Llww\u0026id=HwM2BwABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U3ejQXhUnbsBl7sI3CT5F4q91TuXA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/System_method_and_computer_readable_medi.pdf?id=HwM2BwABERAJ\u0026output=pdf\u0026sig=ACfU3U1PMeLclbWOKmZO8P1ZVAxhFhOmmg"},"sample_url":"http://www.google.com/patents/reader?id=HwM2BwABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>