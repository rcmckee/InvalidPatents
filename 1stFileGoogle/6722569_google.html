<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6722569 - Optical reader having a color imager - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Optical reader having a color imager"><meta name="DC.contributor" content="Michael Ehrhart" scheme="inventor"><meta name="DC.contributor" content="Andrew Longacre, Jr." scheme="inventor"><meta name="DC.contributor" content="Welch Allyn Data Collection, Inc." scheme="assignee"><meta name="DC.date" content="2001-7-13" scheme="dateSubmitted"><meta name="DC.description" content="The present invention relates to an optical reader that includes a color imaging assembly that generates color imaging data. An image analysis circuit determines if the acquired image should be characterized as a color photograph or as including a graphical symbol. A processing circuit processes the imaging data based on the image analysis circuit&#39;s determination of whether the image is a graphical symbol or a color photograph. The present invention allows a user to acquire and process both color images and graphical symbols, such as bar codes, text, OCR symbols or signatures. The optical reader of the present invention is also configured to associate an acquired image with at least one other acquired image."><meta name="DC.date" content="2004-4-20" scheme="issued"><meta name="DC.relation" content="EP:0978990:A2" scheme="references"><meta name="DC.relation" content="GB:2357209" scheme="references"><meta name="DC.relation" content="US:5091975" scheme="references"><meta name="DC.relation" content="US:5420943" scheme="references"><meta name="DC.relation" content="US:5714745" scheme="references"><meta name="DC.relation" content="US:5804805" scheme="references"><meta name="DC.relation" content="US:5869828" scheme="references"><meta name="DC.relation" content="US:5929418" scheme="references"><meta name="DC.relation" content="US:6070805" scheme="references"><meta name="DC.relation" content="US:6089455" scheme="references"><meta name="DC.relation" content="US:6108612" scheme="references"><meta name="DC.relation" content="US:6375075" scheme="references"><meta name="DC.relation" content="US:6384907" scheme="references"><meta name="citation_reference" content="Application No. 10318006, Sep. 11, 1998."><meta name="citation_reference" content="Text String Extraction from Images of Colour-Printed Documents -IEEE Ptroc. -Vis. Image Signal Process., vol. 143, No. 4, Aug. 1996."><meta name="citation_patent_number" content="US:6722569"><meta name="citation_patent_application_number" content="US:09/904,697"><link rel="canonical" href="http://www.google.com/patents/US6722569"/><meta property="og:url" content="http://www.google.com/patents/US6722569"/><meta name="title" content="Patent US6722569 - Optical reader having a color imager"/><meta name="description" content="The present invention relates to an optical reader that includes a color imaging assembly that generates color imaging data. An image analysis circuit determines if the acquired image should be characterized as a color photograph or as including a graphical symbol. A processing circuit processes the imaging data based on the image analysis circuit&#39;s determination of whether the image is a graphical symbol or a color photograph. The present invention allows a user to acquire and process both color images and graphical symbols, such as bar codes, text, OCR symbols or signatures. The optical reader of the present invention is also configured to associate an acquired image with at least one other acquired image."/><meta property="og:title" content="Patent US6722569 - Optical reader having a color imager"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("zZjtU4qLMdH4oATy7oLADw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("JPN"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("zZjtU4qLMdH4oATy7oLADw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("JPN"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6722569?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6722569"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=ENllBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6722569&amp;usg=AFQjCNEQUh3DNFua5J3aTmXN-GsRqcEigQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6722569.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6722569.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20030062419"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US6722569"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6722569" style="display:none"><span itemprop="description">The present invention relates to an optical reader that includes a color imaging assembly that generates color imaging data. An image analysis circuit determines if the acquired image should be characterized as a color photograph or as including a graphical symbol. A processing circuit processes the...</span><span itemprop="url">http://www.google.com/patents/US6722569?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6722569 - Optical reader having a color imager</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6722569 - Optical reader having a color imager" title="Patent US6722569 - Optical reader having a color imager"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6722569 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/904,697</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Apr 20, 2004</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jul 13, 2001</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jul 13, 2001</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/EP1415269A1">EP1415269A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2407911A2">EP2407911A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2407911A3">EP2407911A3</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20030062419">US20030062419</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2004008383A1">WO2004008383A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09904697, </span><span class="patent-bibdata-value">904697, </span><span class="patent-bibdata-value">US 6722569 B2, </span><span class="patent-bibdata-value">US 6722569B2, </span><span class="patent-bibdata-value">US-B2-6722569, </span><span class="patent-bibdata-value">US6722569 B2, </span><span class="patent-bibdata-value">US6722569B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Michael+Ehrhart%22">Michael Ehrhart</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Andrew+Longacre,+Jr.%22">Andrew Longacre, Jr.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Welch+Allyn+Data+Collection,+Inc.%22">Welch Allyn Data Collection, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6722569.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6722569.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6722569.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (13),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (2),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (55),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (22),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (6)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6722569&usg=AFQjCNHVHPlNxgVP1tzk66Q3cvHj5WY62w">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6722569&usg=AFQjCNFTaGm2id5RkVU5ystPrd50eFx9Dw">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6722569B2%26KC%3DB2%26FT%3DD&usg=AFQjCNEuOPq19OhHnF1VFTE-ZSZY9wmHHw">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55248633" lang="EN" load-source="patent-office">Optical reader having a color imager</invention-title></span><br><span class="patent-number">US 6722569 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50656201" lang="EN" load-source="patent-office"> <div class="abstract">The present invention relates to an optical reader that includes a color imaging assembly that generates color imaging data. An image analysis circuit determines if the acquired image should be characterized as a color photograph or as including a graphical symbol. A processing circuit processes the imaging data based on the image analysis circuit's determination of whether the image is a graphical symbol or a color photograph. The present invention allows a user to acquire and process both color images and graphical symbols, such as bar codes, text, OCR symbols or signatures. The optical reader of the present invention is also configured to associate an acquired image with at least one other acquired image.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(18)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00014.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00014.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00015.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00015.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00016.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00016.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6722569B2/US06722569-20040420-D00017.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6722569B2/US06722569-20040420-D00017.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(83)</span></span></div><div class="patent-text"><div mxw-id="PCLM8660832" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is: </claim-statement> <div class="claim"> <div num="1" id="US-6722569-B2-CLM-00001" class="claim">
      <div class="claim-text">1. An optical reader comprising:</div>
      <div class="claim-text">a color imaging assembly for acquiring an image of an object, the color imaging assembly generating color imaging data corresponding to the image; </div>
      <div class="claim-text">an image analysis circuit coupled to the color imaging assembly, the image analysis circuit being configured to determine if the color imaging data includes at least one graphical symbol, whereby the image is classified as a graphical symbol image if the color imaging data includes at least one graphical symbol, or the image is classified as a color photograph if the color imaging data does not include at least one graphical symbol; and </div>
      <div class="claim-text">a processing circuit coupled to the image analysis circuit, the processing circuit being operative to process the color imaging data based on the classification of the image. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6722569-B2-CLM-00002" class="claim">
      <div class="claim-text">2. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, wherein the processing circuit decodes a 1D bar code symbol based on the classification.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6722569-B2-CLM-00003" class="claim">
      <div class="claim-text">3. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, wherein the processing circuit decodes a 2D bar code symbol based on the classification.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6722569-B2-CLM-00004" class="claim">
      <div class="claim-text">4. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, wherein the processing circuit performs optical character recognition based on the classification.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6722569-B2-CLM-00005" class="claim">
      <div class="claim-text">5. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, wherein the processing circuit performs a signature capture based on the classification.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6722569-B2-CLM-00006" class="claim">
      <div class="claim-text">6. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, wherein the processing circuit stores a color image based on the classification.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" id="US-6722569-B2-CLM-00007" class="claim">
      <div class="claim-text">7. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, wherein the portion of the color imaging data is processed by evaluating only green pixel values in the color imaging data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" id="US-6722569-B2-CLM-00008" class="claim">
      <div class="claim-text">8. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, wherein the classification circuit aggregates values of a red, blue and green triplet to form a super-pixel in the process of selecting one of a plurality of classifications.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" id="US-6722569-B2-CLM-00009" class="claim">
      <div class="claim-text">9. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, wherein the color imaging data is converted into a gray scale image in the process of selecting one of a plurality of classifications.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" id="US-6722569-B2-CLM-00010" class="claim">
      <div class="claim-text">10. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, further comprising an illumination light source including white LEDs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" id="US-6722569-B2-CLM-00011" class="claim">
      <div class="claim-text">11. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00001">claim 1</claim-ref>, further comprising an illumination light source including red LEDs.</div>
    </div>
    </div> <div class="claim"> <div num="12" id="US-6722569-B2-CLM-00012" class="claim">
      <div class="claim-text">12. An optical reader for capturing an image of an object, the optical reader comprising:</div>
      <div class="claim-text">a color imaging assembly for converting the image of the object into color digital data corresponding to the image; </div>
      <div class="claim-text">an automatic mode selection circuit coupled to the color imaging assembly, the mode selection circuit using at least a portion of the color digital data to select one of a plurality of operational modes of the optical reader, the operational modes including at least graphical symbol mode and a color photography mode; and </div>
      <div class="claim-text">a processing circuit coupled to the mode selection circuit, the processing circuit being configured to process the color digital data based on the selected operational mode. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" id="US-6722569-B2-CLM-00013" class="claim">
      <div class="claim-text">13. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00012">claim 12</claim-ref>, wherein the at least one graphical symbol mode includes decoding a 1D bar code.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" id="US-6722569-B2-CLM-00014" class="claim">
      <div class="claim-text">14. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00012">claim 12</claim-ref>, wherein the at least one graphical symbol mode includes decoding a 2D bar code.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" id="US-6722569-B2-CLM-00015" class="claim">
      <div class="claim-text">15. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00012">claim 12</claim-ref>, wherein the at least one graphical symbol mode includes optical character recognition.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" id="US-6722569-B2-CLM-00016" class="claim">
      <div class="claim-text">16. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00012">claim 12</claim-ref>, wherein the at least one graphical symbol mode includes capturing a signature.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" id="US-6722569-B2-CLM-00017" class="claim">
      <div class="claim-text">17. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00012">claim 12</claim-ref>, wherein the color photography mode includes storing a color photographic image in a computer-readable medium.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" id="US-6722569-B2-CLM-00018" class="claim">
      <div class="claim-text">18. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00012">claim 12</claim-ref>, further comprising an illumination light source including white LEDs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" id="US-6722569-B2-CLM-00019" class="claim">
      <div class="claim-text">19. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00012">claim 12</claim-ref>, further comprising an illumination light source including red LEDs.</div>
    </div>
    </div> <div class="claim"> <div num="20" id="US-6722569-B2-CLM-00020" class="claim">
      <div class="claim-text">20. An optical reader for capturing an image of an object, the optical reader comprising:</div>
      <div class="claim-text">a color imaging assembly for capturing the image as color imaging data; </div>
      <div class="claim-text">a classification circuit coupled to the color imaging assembly, the classification circuit being configured to process at least a portion of the color imaging data to thereby select one of a plurality of classifications, whereby the image is classified as a color photographic image, or as an image that includes at least one graphical symbol; </div>
      <div class="claim-text">an automatic mode selector coupled to the classification circuit, the automatic mode selector being configured to select an optical reader mode in accordance with the selected classification; and </div>
      <div class="claim-text">a processor coupled to the classification circuit, the processor being programmed to process the color imaging data in accordance with the optical reader mode selected by the automatic mode selector. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" id="US-6722569-B2-CLM-00021" class="claim">
      <div class="claim-text">21. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00020">claim 20</claim-ref>, wherein the portion of the color imaging data is processed by evaluating only green pixel values in the color imaging data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" id="US-6722569-B2-CLM-00022" class="claim">
      <div class="claim-text">22. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00020">claim 20</claim-ref>, wherein the classification circuit aggregates values of a red, blue and green triplet to form a super-pixel in the process of selecting one of a plurality of classifications.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" id="US-6722569-B2-CLM-00023" class="claim">
      <div class="claim-text">23. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00020">claim 20</claim-ref>, wherein the color imaging data is converted into a gray scale image in the process of selecting one of a plurality of classifications.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" id="US-6722569-B2-CLM-00024" class="claim">
      <div class="claim-text">24. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00020">claim 20</claim-ref>, wherein the processor decodes a 1D bar code symbol.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" id="US-6722569-B2-CLM-00025" class="claim">
      <div class="claim-text">25. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00020">claim 20</claim-ref>, wherein the processor decodes a 2D bar code symbol.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" id="US-6722569-B2-CLM-00026" class="claim">
      <div class="claim-text">26. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00020">claim 20</claim-ref>, wherein the processor performs an optical character recognition process.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" id="US-6722569-B2-CLM-00027" class="claim">
      <div class="claim-text">27. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00020">claim 20</claim-ref>, wherein the processor performs a signature capture process.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" id="US-6722569-B2-CLM-00028" class="claim">
      <div class="claim-text">28. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00020">claim 20</claim-ref>, wherein the processor stores a color image in a computer-readable medium.</div>
    </div>
    </div> <div class="claim"> <div num="29" id="US-6722569-B2-CLM-00029" class="claim">
      <div class="claim-text">29. An optical reader for capturing an image of an object, the optical reader comprising:</div>
      <div class="claim-text">a color imaging assembly for capturing the image as color imaging data; </div>
      <div class="claim-text">a user mode selector coupled to the color imaging assembly, the user mode selector being switchable between at least one automatic user mode, or a manual user mode for manually selecting one of a plurality of imaging modes of the optical reader, whereby the plurality of imaging modes includes at least one graphical symbol mode and a color photography mode; </div>
      <div class="claim-text">an automatic imaging mode selector coupled to the user mode selector and the color imaging assembly, the automatic imaging mode selector being operative to automatically select one of the plurality of imaging modes when in the automatic user mode; and </div>
      <div class="claim-text">a processing circuit coupled to the user mode selector and the automatic mode selector, the processing circuit being programmed to process the color imaging data based on the selected one of the plurality of operational modes. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" id="US-6722569-B2-CLM-00030" class="claim">
      <div class="claim-text">30. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00029">claim 29</claim-ref>, wherein the plurality of imaging modes includes a 1D bar code decoding mode.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" id="US-6722569-B2-CLM-00031" class="claim">
      <div class="claim-text">31. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00029">claim 29</claim-ref>, wherein the plurality of imaging modes includes a 2D bar code decoding mode.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="32" id="US-6722569-B2-CLM-00032" class="claim">
      <div class="claim-text">32. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00029">claim 29</claim-ref>, wherein the plurality of imaging modes includes an optical character recognition mode.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" id="US-6722569-B2-CLM-00033" class="claim">
      <div class="claim-text">33. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00029">claim 29</claim-ref>, wherein the plurality of imaging modes includes a signature capture mode.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="34" id="US-6722569-B2-CLM-00034" class="claim">
      <div class="claim-text">34. The optical reader of <claim-ref idref="US-6722569-B2-CLM-00029">claim 29</claim-ref>, wherein the plurality of imaging modes includes a color photography mode.</div>
    </div>
    </div> <div class="claim"> <div num="35" id="US-6722569-B2-CLM-00035" class="claim">
      <div class="claim-text">35. A method for acquiring an image of an object with an optical reader, the method comprising:</div>
      <div class="claim-text">acquiring first color imaging data representing the image; </div>
      <div class="claim-text">analyzing the color imaging data to provide an image classification, whereby the image is classified as a color photograph, or as including at least one graphical symbol; and </div>
      <div class="claim-text">processing the color imaging data in accordance with the image classification. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="36" id="US-6722569-B2-CLM-00036" class="claim">
      <div class="claim-text">36. The method of <claim-ref idref="US-6722569-B2-CLM-00035">claim 35</claim-ref>, wherein the step of processing includes decoding a 1D bar code.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="37" id="US-6722569-B2-CLM-00037" class="claim">
      <div class="claim-text">37. The method of <claim-ref idref="US-6722569-B2-CLM-00035">claim 35</claim-ref>, wherein the step of processing includes decoding a 2D bar code.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="38" id="US-6722569-B2-CLM-00038" class="claim">
      <div class="claim-text">38. The method of <claim-ref idref="US-6722569-B2-CLM-00035">claim 35</claim-ref>, wherein the step of processing includes an optical character recognition process.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="39" id="US-6722569-B2-CLM-00039" class="claim">
      <div class="claim-text">39. The method of <claim-ref idref="US-6722569-B2-CLM-00035">claim 35</claim-ref>, wherein the step of processing includes capturing a signature.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="40" id="US-6722569-B2-CLM-00040" class="claim">
      <div class="claim-text">40. The method of <claim-ref idref="US-6722569-B2-CLM-00035">claim 35</claim-ref>, wherein the step of processing includes storing a color photographic image in a computer-readable medium.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="41" id="US-6722569-B2-CLM-00041" class="claim">
      <div class="claim-text">41. The method of <claim-ref idref="US-6722569-B2-CLM-00035">claim 35</claim-ref>, wherein the step of analyzing includes an analysis of only one color of the color imaging data during the step of providing an image classification.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="42" id="US-6722569-B2-CLM-00042" class="claim">
      <div class="claim-text">42. The method of <claim-ref idref="US-6722569-B2-CLM-00035">claim 35</claim-ref>, further comprising:</div>
      <div class="claim-text">acquiring at least one second color imaging data representing at least one second image; </div>
      <div class="claim-text">analyzing the at least one second color imaging data to provide at least one second image classification, whereby the at least one second image is classified as a color photograph, or as an image including at least one graphical symbol; </div>
      <div class="claim-text">processing the at least one second color imaging data in accordance with the at least one second image classification; and </div>
      <div class="claim-text">associating the at least one second color imaging data with the first color imaging data. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="43" id="US-6722569-B2-CLM-00043" class="claim">
      <div class="claim-text">43. The method of <claim-ref idref="US-6722569-B2-CLM-00042">claim 42</claim-ref>, wherein the step of associating includes displaying the at least one second color imaging data with the first color imaging data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="44" id="US-6722569-B2-CLM-00044" class="claim">
      <div class="claim-text">44. The method of <claim-ref idref="US-6722569-B2-CLM-00043">claim 43</claim-ref>, wherein the step of associating includes electronically displaying the at least one second color imaging data with the first color imaging data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="45" id="US-6722569-B2-CLM-00045" class="claim">
      <div class="claim-text">45. The method of <claim-ref idref="US-6722569-B2-CLM-00042">claim 42</claim-ref> wherein the step of associating includes printing the at least one second color imaging data with the first color imaging data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="46" id="US-6722569-B2-CLM-00046" class="claim">
      <div class="claim-text">46. The method of <claim-ref idref="US-6722569-B2-CLM-00042">claim 42</claim-ref>, wherein the step of associating includes linking the at least one second color imaging data with the first color imaging data in memory.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="47" id="US-6722569-B2-CLM-00047" class="claim">
      <div class="claim-text">47. The method of <claim-ref idref="US-6722569-B2-CLM-00042">claim 42</claim-ref>, wherein the step of associating includes storing the at least one second color imaging data with the first color imaging data as a record in a database.</div>
    </div>
    </div> <div class="claim"> <div num="48" id="US-6722569-B2-CLM-00048" class="claim">
      <div class="claim-text">48. A computer readable medium having computer-executable instructions for performing a method comprising:</div>
      <div class="claim-text">acquiring color imaging data; </div>
      <div class="claim-text">analyzing the color imaging data to provide an image classification, whereby the image is classified as a color photograph, or the image is classified as including at least one graphical symbol; and </div>
      <div class="claim-text">processing the color imaging data in accordance with the image classification. </div>
    </div>
    </div> <div class="claim"> <div num="49" id="US-6722569-B2-CLM-00049" class="claim">
      <div class="claim-text">49. In an optical reader having a color imaging assembly for acquiring color imaging data, and a graphical user interface including a display and a selection device, a method for selecting at least one optical reader operating mode, the method comprising:</div>
      <div class="claim-text">displaying at least one icon on the graphical user interface, the at least one icon corresponding to the at least one optical reader operating mode; </div>
      <div class="claim-text">clicking on the at least one icon with the selection device to thereby select the at least one optical reader operating mode corresponding to the selected at least one icon; and </div>
      <div class="claim-text">processing the color imaging data based on the selected at least one icon, whereby the color imaging data is processed as a color photographic image, or as an image that includes at least one graphical symbol. </div>
    </div>
    </div> <div class="claim"> <div num="50" id="US-6722569-B2-CLM-00050" class="claim">
      <div class="claim-text">50. In an optical reader having a color imaging assembly for acquiring color imaging data, and a graphical user interface including a display and a selection device, a method of providing and selecting from a menu on the display, the method comprising:</div>
      <div class="claim-text">retrieving a set of menu entries for the menu, each of the menu entries representing at least one operational mode of the optical reader; </div>
      <div class="claim-text">displaying the set of menu entries on the display; </div>
      <div class="claim-text">selecting a menu entry; </div>
      <div class="claim-text">emitting a menu selection signal indicative of a selected operational mode; and </div>
      <div class="claim-text">processing the imaging data based on the selected menu entry, whereby the imaging data is processed as a color photographic image or as an image that includes at least one graphical symbol. </div>
    </div>
    </div> <div class="claim"> <div num="51" id="US-6722569-B2-CLM-00051" class="claim">
      <div class="claim-text">51. A method for acquiring an image of an object with an optical reader, the method comprising:</div>
      <div class="claim-text">providing a color imaging assembly; </div>
      <div class="claim-text">converting the image into color imaging data; </div>
      <div class="claim-text">classifying the image as either a color photograph, or as a color image that includes at least one graphical symbol; and </div>
      <div class="claim-text">processing the color imaging data in accordance with the step of classifying. </div>
    </div>
    </div> <div class="claim"> <div num="52" id="US-6722569-B2-CLM-00052" class="claim">
      <div class="claim-text">52. A method for acquiring an image of an object with an optical reader, the optical reader having a plurality of imaging modes including at least one graphical symbol mode, and a color photography mode, the method comprising:</div>
      <div class="claim-text">capturing the image by acquiring color imaging data; </div>
      <div class="claim-text">analyzing at least a portion of the color imaging data to provide an image classification, whereby the image classification includes at least one graphical symbol classification and a color photography classification; </div>
      <div class="claim-text">automatically selecting one of a plurality of image processing modes based on the image classification provided in the step of analyzing; and </div>
      <div class="claim-text">processing the color imaging data based on the selected one of the plurality of image processing modes. </div>
    </div>
    </div> <div class="claim"> <div num="53" id="US-6722569-B2-CLM-00053" class="claim">
      <div class="claim-text">53. A method for acquiring an image of an object with an optical reader, the optical reader having a plurality of imaging modes including at least one graphical symbol mode, and a color photography mode, the method comprising:</div>
      <div class="claim-text">capturing the image by acquiring color imaging data; </div>
      <div class="claim-text">automatically selecting one of the plurality of imaging modes based on an analysis of the color imaging data; and </div>
      <div class="claim-text">processing the color imaging data in accordance with a selected one of the plurality of imaging modes. </div>
    </div>
    </div> <div class="claim"> <div num="54" id="US-6722569-B2-CLM-00054" class="claim">
      <div class="claim-text">54. A system for processing at least one image, the system including at least one network element, the system comprising:</div>
      <div class="claim-text">an optical reader including a color imager and a processor, the color imager being configured to capture the at least one image by generating color imaging data corresponding to the at least one image, the processor being configured to provide a classification of the color imaging data based on whether the color imaging data includes at least one graphical symbol, the processor being programmed to process the color imaging data in accordance with the classification; and </div>
      <div class="claim-text">a network coupled to the color optical reader and the at least one network element, whereby processed image data is transmitted between the network and the at least one network element. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="55" id="US-6722569-B2-CLM-00055" class="claim">
      <div class="claim-text">55. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the network includes the Internet.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="56" id="US-6722569-B2-CLM-00056" class="claim">
      <div class="claim-text">56. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the network includes a wireless network.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="57" id="US-6722569-B2-CLM-00057" class="claim">
      <div class="claim-text">57. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the network includes a circuit switched network.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="58" id="US-6722569-B2-CLM-00058" class="claim">
      <div class="claim-text">58. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the network includes an IP network.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="59" id="US-6722569-B2-CLM-00059" class="claim">
      <div class="claim-text">59. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the network includes a private network.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="60" id="US-6722569-B2-CLM-00060" class="claim">
      <div class="claim-text">60. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the network element includes a LAN.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="61" id="US-6722569-B2-CLM-00061" class="claim">
      <div class="claim-text">61. The system of <claim-ref idref="US-6722569-B2-CLM-00060">claim 60</claim-ref>, wherein the LAN further comprises:</div>
      <div class="claim-text">a server coupled to the network; and </div>
      <div class="claim-text">at least one optical reader coupled to the server. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="62" id="US-6722569-B2-CLM-00062" class="claim">
      <div class="claim-text">62. The system of <claim-ref idref="US-6722569-B2-CLM-00061">claim 61</claim-ref>, wherein the at least one optical reader includes a color imager.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="63" id="US-6722569-B2-CLM-00063" class="claim">
      <div class="claim-text">63. The system of <claim-ref idref="US-6722569-B2-CLM-00060">claim 60</claim-ref>, wherein the LAN includes a database, the database being configured to store a plurality of associated processed images.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="64" id="US-6722569-B2-CLM-00064" class="claim">
      <div class="claim-text">64. The system of <claim-ref idref="US-6722569-B2-CLM-00063">claim 63</claim-ref>, wherein the plurality of associated processed images includes a color photographic image associated with decoded bar code data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="65" id="US-6722569-B2-CLM-00065" class="claim">
      <div class="claim-text">65. The system of <claim-ref idref="US-6722569-B2-CLM-00063">claim 63</claim-ref>, wherein the plurality of associated processed images includes a color photographic image associated with decoded OCR data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="66" id="US-6722569-B2-CLM-00066" class="claim">
      <div class="claim-text">66. The system of <claim-ref idref="US-6722569-B2-CLM-00063">claim 63</claim-ref>, wherein the plurality of associated processed images includes a color photographic image associated with decoded text data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="67" id="US-6722569-B2-CLM-00067" class="claim">
      <div class="claim-text">67. The system of <claim-ref idref="US-6722569-B2-CLM-00063">claim 63</claim-ref>, wherein the plurality of associated processed images includes a color photographic image associated with a captured signature.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="68" id="US-6722569-B2-CLM-00068" class="claim">
      <div class="claim-text">68. The system of <claim-ref idref="US-6722569-B2-CLM-00063">claim 63</claim-ref>, wherein the plurality of associated processed images includes decoded bar code data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="69" id="US-6722569-B2-CLM-00069" class="claim">
      <div class="claim-text">69. The system of <claim-ref idref="US-6722569-B2-CLM-00063">claim 63</claim-ref>, wherein the plurality of associated processed images includes decoded OCR data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="70" id="US-6722569-B2-CLM-00070" class="claim">
      <div class="claim-text">70. The system of <claim-ref idref="US-6722569-B2-CLM-00063">claim 63</claim-ref>, wherein the plurality of associated processed images includes decoded text data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="71" id="US-6722569-B2-CLM-00071" class="claim">
      <div class="claim-text">71. The system of <claim-ref idref="US-6722569-B2-CLM-00063">claim 63</claim-ref>, wherein the plurality of associated processed images includes a captured signature.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="72" id="US-6722569-B2-CLM-00072" class="claim">
      <div class="claim-text">72. The system of <claim-ref idref="US-6722569-B2-CLM-00060">claim 60</claim-ref>, wherein the LAN includes a POS terminal.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="73" id="US-6722569-B2-CLM-00073" class="claim">
      <div class="claim-text">73. The system of <claim-ref idref="US-6722569-B2-CLM-00060">claim 60</claim-ref>, wherein the LAN includes a credit card authentication module.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="74" id="US-6722569-B2-CLM-00074" class="claim">
      <div class="claim-text">74. The system of <claim-ref idref="US-6722569-B2-CLM-00060">claim 60</claim-ref>, wherein the LAN includes a signature verification module.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="75" id="US-6722569-B2-CLM-00075" class="claim">
      <div class="claim-text">75. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the network element includes a PAN, the Pan having at least one optical reader coupled thereto.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="76" id="US-6722569-B2-CLM-00076" class="claim">
      <div class="claim-text">76. The system of <claim-ref idref="US-6722569-B2-CLM-00075">claim 75</claim-ref>, wherein the at least one optical reader includes a color imager.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="77" id="US-6722569-B2-CLM-00077" class="claim">
      <div class="claim-text">77. The system of <claim-ref idref="US-6722569-B2-CLM-00075">claim 75</claim-ref>, wherein the PAN includes a POS terminal.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="78" id="US-6722569-B2-CLM-00078" class="claim">
      <div class="claim-text">78. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the network element further comprises:</div>
      <div class="claim-text">a wireless base station coupled to the network, the wireless base station being configured to transmit and receive processed image data to and from the network; and </div>
      <div class="claim-text">at least one wireless optical reader coupled to the wireless base station via an RF communications link. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="79" id="US-6722569-B2-CLM-00079" class="claim">
      <div class="claim-text">79. The system of <claim-ref idref="US-6722569-B2-CLM-00078">claim 78</claim-ref>, wherein the at least one wireless optical reader includes a color imager.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="80" id="US-6722569-B2-CLM-00080" class="claim">
      <div class="claim-text">80. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the processor further comprises an image analysis circuit coupled to the color imager, the image analysis circuit being configured to determine if the color imaging data includes at least one graphical symbol, whereby the image is classified as a graphical symbol image if the color imaging data includes at least one graphical symbol, or the image is classified as a color photograph if the color imaging data does not include at least one graphical symbol.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="81" id="US-6722569-B2-CLM-00081" class="claim">
      <div class="claim-text">81. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the processor further comprises an automatic mode selection circuit coupled to the color imager, the automatic mode selection circuit using at least a portion of the color imaging data to select one of a plurality of operational modes of the optical reader, the operational modes including at least graphical symbol mode and a color photography mode.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="82" id="US-6722569-B2-CLM-00082" class="claim">
      <div class="claim-text">82. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the processor further comprises:</div>
      <div class="claim-text">a classification circuit coupled to the color imager, the classification circuit being configured to process at least a portion of the color imaging data to thereby select one of a plurality of classifications, whereby the image is classified as a color photographic image, or as an image that includes at least one graphical symbol; </div>
      <div class="claim-text">an automatic mode selector coupled to the classification circuit, the automatic mode selector being configured to select an optical reader mode in accordance with the selected one of a plurality of classifications. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="83" id="US-6722569-B2-CLM-00083" class="claim">
      <div class="claim-text">83. The system of <claim-ref idref="US-6722569-B2-CLM-00054">claim 54</claim-ref>, wherein the optical reader further comprises:</div>
      <div class="claim-text">a user mode selector coupled to the color imager, the user mode selector being switchable between at least one automatic user mode, or a manual user mode for manually selecting one of a plurality of imaging modes of the optical reader, whereby the plurality of imaging modes includes at least one graphical symbol mode and a color photography mode; </div>
      <div class="claim-text">an automatic imaging mode selector coupled to the user mode selector and the color imager, the automatic imaging mode selector being operative to automatically select one of the plurality of imaging modes when in the automatic user mode.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES54168553" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>The present invention relates generally to optical readers, and particularly to optical readers employing color imagers.</p>
    <p>2. Technical Background</p>
    <p>Optical indicia readers equipped to read one-dimensional or two-dimensional bar code symbols are well known in the art. There are a number of optical character recognition systems on the market as well. In addition, many financial institutions today employ computer-driven signature capture systems. Many of these systems employ monochrome imagers because monochrome imagers are well-suited to read graphical symbols, such as bar codes, OCR symbols, or signatures.</p>
    <p>On the other hand, the ability to provide image capture functionality along with indicia reading in one device is very appealing. Currently, optical readers having image capture functionality use monochrome imagers that provide gray scale images. While such devices are useful, gray scale images are less desirable than color images for viewing purposes. The public has come to expect color imaging. Further, monochrome images are often less distinct and not as informative as color images.</p>
    <p>Unfortunately, there are problems associated with using color imaging systems to read graphical symbols. The first problem relates to the difficulty of distinguishing bi-tonal indicia in a color image. Because color imagers provide more information that bi-tonal indicia readers can use, color imaging data is often confusing to graphical symbol indicia readers. One way to solve this problem is to convert the color imaging data into gray-scale data. However, commercially available methods for converting color images to gray-scale are too slow for high-volume scanning. Thus, an optical reader employing a color imager with a gray scale converter would be slower and more expensive than an optical reader using monochrome imager because of the additional processing required.</p>
    <p>Thus, a need exists for an inexpensive optical reader that is capable of performing color photography and evaluating graphical symbols. This optical reader must be capable of automatically determining whether an image includes a graphical symbol or is merely a color photographic image, and process the acquired color imaging data based on that determination. A need also exists for an optical reader that is able to associate an acquired color image with any subsequent acquired color image.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention addresses the needs identified above. The present invention is directed to an inexpensive optical reader that is configured to perform color photography or evaluate graphical symbols. The optical reader of the present invention automatically, or through manual selection, determines whether a captured image is a color photographic image or, a color image that includes a graphical symbol. Subsequently, the optical reader of the present invention processes the acquired imaging data in accordance with that determination. The optical reader of the present invention is operative to acquire and associate a plurality of acquired images.</p>
    <p>One aspect of the present invention is an optical reader. The optical reader includes a color imaging assembly for acquiring an image of an object, the color imaging assembly generating imaging data corresponding to the image. An image analysis circuit is coupled to the color imaging assembly. The image analysis circuit being configured to determine if the color imaging data includes at least one graphical symbol. The image is classified as a graphical symbol, or the image is classified as a color photograph if the color imaging data does not include at least one graphical symbol. A processing circuit is coupled to the image analysis circuit. The processing circuit is operative to process the imaging data based on the determination.</p>
    <p>In another aspect, the present invention includes an optical reader for capturing an image of an object. The optical reader includes a color imaging assembly for converting the image of the object into color digital data corresponding to the image.</p>
    <p>An automatic mode selection circuit is coupled to the color imaging assembly. The mode selection circuit uses at least a portion of the color digital data to select one of a plurality of operational modes of the optical reader. The operational modes include at least a graphical symbol mode and a color photography mode. A processing circuit is coupled to the mode selection circuit. The processing circuit is configured to process the color digital data based on the selected operational mode.</p>
    <p>In another aspect, the present invention includes an optical reader for capturing an image of an object. The optical reader includes a color imaging assembly for capturing the image as color imaging data. A classification circuit is coupled to the color imaging assembly, the classification circuit being configured to process at least a portion of the color imaging data to thereby select one of a plurality of classifications, whereby the image is classified as a color photographic image, or as an image that includes at least one graphical symbol. An automatic mode selector is coupled to the classification circuit, the automatic mode selector being configured to select an optical reader mode in accordance with the selected classification. A processor is coupled to the classification circuit, the processor being programmed to process the color imaging data in accordance with the optical reader mode selected by the automatic mode selector.</p>
    <p>In another aspect, the present invention includes an optical reader for capturing an image of an object. The optical reader includes a color imaging assembly for capturing the image as color imaging data. A user mode selector is coupled to the color imaging assembly, the user mode selector being switchable between at least one automatic user mode, or a manual user mode for manually selecting one of a plurality of imaging modes of the optical reader, whereby the plurality of imaging modes includes at least one graphical symbol mode and a color photography mode. An automatic imaging mode selector is coupled to the user mode selector and the color imaging assembly, the automatic imaging mode selector being operative to automatically select one of the plurality of imaging modes when in the automatic user mode. A processing circuit is coupled to the user mode selector and the automatic mode selector, the processing circuit being programmed to process the color imaging data based on the selected one of the plurality of operational modes.</p>
    <p>In another aspect, the present invention includes a method for acquiring an image of an object with an optical reader. The method includes: acquiring first color imaging data representing the image; analyzing the color imaging data to provide an image classification, whereby the image is classified as a color photograph, or as including at least one graphical symbol; and processing the color imaging data in accordance with the image classification.</p>
    <p>In another aspect, the present invention includes a computer readable medium having computer-executable instructions for performing a method including: acquiring color imaging data; analyzing the color imaging data to provide an image classification, whereby the image is classified as a color photograph, or the image is classified as including at least one graphical symbol; and processing the color imaging data in accordance with the image classification.</p>
    <p>In another aspect, the present invention includes an optical reader having a color imaging assembly for acquiring color imaging data, and a graphical user interface including a display and a selection device. In the optical reader, a method for selecting at least one optical reader operating mode includes: displaying at least one icon on the graphical user interface, the at least one icon corresponding to the at least one optical reader operating mode; clicking on the at least one icon with the selection device to thereby select the at least one optical reader operating mode corresponding to the selected at least one icon; and processing the color imaging data based on the selected at least one icon, whereby the color imaging data is processed as a color photographic image, or as an image that includes at least one graphical symbol.</p>
    <p>In another aspect, the present invention includes an optical reader having a color imaging assembly for acquiring color imaging data, and a graphical user interface including a display and a selection device. In the optical reader, a method of providing and selecting from a menu on the display includes: retrieving a set of menu entries for the menu, each of the menu entries representing at least one operational mode of the optical reader; displaying the set of menu entries on the display; selecting a menu entry; emitting a menu selection signal indicative of a selected operational mode; and processing the imaging data based on the selected menu entry, whereby the imaging data is processed as a color photographic image or as an image that includes at least one graphical symbol.</p>
    <p>In another aspect, the present invention includes a method for acquiring an image of an object with an optical reader. The method includes: providing a color imaging assembly; converting the image into color imaging data; classifying the image as either a color photograph, or as a color image that includes at least one graphical symbol; and processing the color imaging data in accordance with the step of classifying.</p>
    <p>In another aspect, the present invention includes a method for acquiring an image of an object with an optical reader. The optical reader has a plurality of imaging modes including at least one graphical symbol mode, and a color photography mode. The method includes: capturing the image by acquiring color imaging data; analyzing at least a portion of the color imaging data to provide an image classification, whereby the image classification includes at least one graphical symbol classification and a color photography classification; automatically selecting one of a plurality of image processing modes based on the image classification provided in the step of analyzing; and processing the color imaging data based on the selected one of the plurality of image processing modes.</p>
    <p>In another aspect, the present invention includes a method for acquiring an image of an object with an optical reader. The optical reader has a plurality of imaging modes including at least one graphical symbol mode, and a color photography mode. The method includes: capturing the image by acquiring color imaging data; automatically selecting one of the plurality of imaging modes based on an analysis of the color imaging data; and processing the color imaging data in accordance with a selected one of the plurality of imaging modes.</p>
    <p>In another aspect, the present invention includes a system for processing at least one image. The system includes at least one network element. The system includes an optical reader including a color imager and a processor. The color imager is configured to capture the at least one image by generating color imaging data corresponding to the at least one image. The processor is configured to provide a classification of the color imaging data based on whether the color imaging data includes at least one graphical symbol. The processor is programmed to process the color imaging data in accordance with the classification. A network is coupled to the color optical reader and the at least one network element, whereby processed image data is transmitted between the network and the at least one network element.</p>
    <p>Additional features and advantages of the invention will be set forth in the detailed description which follows, and in part will be readily apparent to those skilled in the art from that description or recognized by practicing the invention as described herein, including the detailed description which follows, the claims, as well as the appended drawings.</p>
    <p>It is to be understood that both the foregoing general description and the following detailed description are merely exemplary of the invention, and are intended to provide an overview or framework for understanding the nature and character of the invention as it is claimed. The accompanying drawings are included to provide a further understanding of the invention, and are incorporated in and constitute a part of this specification. The drawings illustrate various embodiments of the invention, and together with the description serve to explain the principles and operation of the invention.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIGS. 1A-1D are perspective views of various embodiments of the optical reader of the present invention;</p>
    <p>FIG. 2 is a block diagram of the electro-optical assembly of the optical reader of the present invention;</p>
    <p>FIG. 3 is an example of a graphical user interface display in accordance with the present invention;</p>
    <p>FIG. 4 is a flow chart showing the processing flow for an automatic mode in accordance with another embodiment of the present invention;</p>
    <p>FIG. 5 is a flow chart showing the processing flow for a semi-automatic mode in accordance with another embodiment of the present invention;</p>
    <p>FIGS. 6A-6C are graphical depictions of the menu symbol used in the bar code processing flows depicted in FIG. <b>4</b> and FIG. 5;</p>
    <p>FIG. 7 is a flow chart showing a method for reading a bar code in accordance with yet another embodiment of the present invention;</p>
    <p>FIG. 8 is a flow chart showing a method for 1D autodiscrimination in accordance with the method depicted in FIG. 7;</p>
    <p>FIG. 9 is a flow chart showing a method for 2D autodiscrimination in accordance with the method depicted in FIG. 7;</p>
    <p>FIG. 10 is a flow chart showing a method for reading text in accordance with yet another embodiment of the present invention;</p>
    <p>FIG. 11 is a flow chart showing a method for performing OCR in accordance with yet another embodiment of the present invention;</p>
    <p>FIG. 12 is a flow chart showing a method for associating consecutive images taken with the color optical reader of the present invention;</p>
    <p>FIG. 13 is an example of image association in accordance with the present invention;</p>
    <p>FIG. 14 is a perspective view of a wireless color optical reader in accordance with yet another embodiment of the present invention;</p>
    <p>FIG. 15 is a flow chart showing a method for transmitting packetized data from a color optical reader to a base station;</p>
    <p>FIGS. 16A and 16B are diagrammatic depictions of packet formats in accordance with yet another embodiment of the present invention;</p>
    <p>FIG. 17 is a flow chart showing a method for performing signature verification in accordance with yet another embodiment of the present invention; and</p>
    <p>FIG. 18 is a diagrammatic depiction of color optical reader network applications in accordance with the present invention.</p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading> <p>Reference will now be made in detail to the present exemplary embodiments of the invention, examples of which are illustrated in the accompanying drawings. Wherever possible, the same reference numbers will be used throughout the drawings to refer to the same or like parts. An exemplary embodiment of the optical reader of the present invention is shown in FIG. 1, and is designated generally throughout by reference numeral <b>10</b>.</p>
    <p>In accordance with the invention, the present invention for an optical reader includes a color imaging assembly for acquiring color imaging data. An image analysis circuit determines if the acquired image includes at least one graphical symbol. A processing circuit processes the imaging data based on the determination of whether the image includes at least one graphical symbol. The present invention allows a user to read graphical symbols, such as bar codes, text, OCR characters or signatures using a color imager. The color optical reader of the present invention is configured to automatically determine whether a color image includes a graphical symbol, or is merely a color photographic image. The optical reader of the present invention also is operative to associate one acquired image with at least one subsequently acquired image.</p>
    <p>As embodied herein, and depicted in FIGS. 1A-1D, perspective views of the optical reader in accordance with various embodiments of the present invention are disclosed. FIG. 1A shows the underside of hand held wireless optical reader <b>10</b>. FIG. 1B shows the top of the optical reader depicted in FIG. <b>1</b>A. Optical reader <b>10</b> includes housing <b>100</b>, antenna <b>102</b>, window <b>104</b> and trigger <b>12</b>. Window <b>104</b> accommodates illumination assembly <b>20</b> and imaging assembly <b>30</b>. As shown in FIG. 1B, the top side of reader <b>10</b> includes function keys <b>14</b>, alphanumeric key pad <b>16</b>, and display <b>60</b>. In one embodiment, function keys <b>14</b> include an enter key and up and down cursor keys. FIG. 1C is also a hand held wireless optical reader <b>10</b>. Reader <b>10</b> includes function keys <b>14</b>, alphanumeric key pad <b>16</b>, writing stylus <b>18</b>, display <b>60</b>, and signature block <b>62</b>. Stylus <b>18</b> is employed by a user to write his signature in signature block <b>62</b>. FIG. 1D shows yet another embodiment of optical reader <b>10</b> of the present invention. In this embodiment, reader <b>10</b> includes a gun-shaped housing <b>100</b>. Display <b>60</b> and keypad <b>16</b> are disposed on a top portion of gun-shaped housing <b>100</b>, whereas trigger <b>12</b> is disposed on the underside of the top portion of housing <b>100</b>. Housing <b>100</b> also includes window <b>104</b> that accommodates illumination assembly <b>20</b> and imaging assembly <b>30</b>. Wire <b>106</b> is disposed at the butt-end of housing <b>100</b>. Wire <b>106</b> provides optical reader <b>10</b> with a hard wired communication link for external devices such as a host processor or other data collection devices.</p>
    <p>As embodied herein and depicted in FIG. 2, a block diagram of the electro-optical assembly of optical reader <b>10</b> of the present invention is disclosed. Optical reader <b>10</b> includes illumination assembly <b>20</b> and color imaging assembly <b>30</b>, connected to processor <b>40</b>. Illumination assembly <b>20</b> includes illumination optics <b>22</b> coupled to light source <b>24</b>. Light source <b>24</b> is coupled to ASIC/FPGA <b>44</b>. ASIC/FPGA <b>44</b> is programmed to drive light source <b>24</b>. Imaging assembly <b>30</b> includes imaging optics <b>32</b> and color imager <b>34</b>. Imaging optics <b>32</b> focuses the illumination light reflected from target T onto color imager <b>34</b>. Color imager <b>34</b> provides color imaging data to ASIC/FPGA <b>44</b>. Color imager <b>34</b> performs several functions. Color imager <b>34</b> generates analog color image signals using an imaging array color filter. The array color filter pattern is a Bayer-pattern. The analog color imaging data is converted into a digital format using an internal A/D converter which also functions as a quantizer. An 8-bit system provides 256 brightness levels, whereas a 12-bit converter provides over 4,000 brightness levels. Digital color imaging data is transmitted from imager <b>34</b> to ASIC/FPGA <b>44</b> and processor <b>42</b>.</p>
    <p>Optical reader <b>10</b> also includes processor <b>40</b>. In the embodiment depicted in FIG. 2, processor <b>40</b> includes microprocessor <b>42</b> and ASIC <b>44</b>. System bus <b>52</b> couples microprocessor <b>40</b>, RAM <b>46</b>, EROM <b>48</b>, I/O circuit <b>50</b> and display <b>60</b>.</p>
    <p>Illumination optics <b>22</b> may be of any suitable type, but there is shown by way of example a lens system for directing light from light source <b>24</b> towards target T. It will be apparent to those of ordinary skill in the pertinent art that modifications and variations can be made to illumination optics <b>22</b> of the present invention depending on the complexity of the target illumination. For example, illumination optics <b>22</b> may include one or more lenses, diffusers, wedges, reflectors or a combination of these elements. In one embodiment, illumination optics <b>22</b> produces an aiming pattern on target T.</p>
    <p>Light source <b>24</b> may be of any suitable type, but there is shown by way of example a plurality of white LEDs. It will be apparent to those of ordinary skill in the pertinent art that modifications and variations can be made to light source <b>24</b> of the present invention depending on the application. For example, illumination assembly <b>20</b> may be eliminated altogether if it is certain that the ambient light level will be high enough to obtain high quality color images. In another embodiment, red LEDs are employed instead of the white LEDs.</p>
    <p>Color imager <b>34</b> may be of any suitable type, but there is shown by way of example, a CMOS color imager having an 640×480 pixel resolution. It will be apparent to those of ordinary skill in the pertinent art that modifications and variations can be made to color imager <b>34</b> of the present invention depending on cost and the resolution required by optical reader <b>10</b>. In another embodiment, color imager <b>34</b> has 800×600 pixels. A typical VGA resolution of 640×480 pixels is adequate for displaying color images on a LCD or a computer monitor. In one megapixel embodiment, color imager <b>34</b> has 1156×864 pixels (almost 1-million pixels). In yet another embodiment, color imager <b>34</b> includes 1536×1024 pixels. One of ordinary skill in the art will recognize that as the resolution of imager <b>34</b> increases, so will the cost. In another embodiment, color imager <b>34</b> is implemented by scanning a linear CCD array. In other embodiments, color imager <b>34</b> is implemented using an area CCD solid state image sensor.</p>
    <p>Processor <b>40</b> may be of any suitable type, but there is shown by way of example a processor which includes microprocessor <b>42</b> and ASIC <b>44</b> coupled to system bus <b>52</b>. In one embodiment, microprocessor <b>42</b> and ASIC are programmable control devices that receive, process, and output data in accordance with an embedded program stored in EROM <b>48</b>. As discussed above, microprocessor <b>42</b> and ASIC <b>44</b> are connected to system bus <b>52</b>, which includes address, data, and control lines.</p>
    <p>In the embodiment depicted in FIG. 2, microprocessor <b>42</b> is an off-the-shelf VLSI integrated circuit (IC) microprocessor. Microprocessor <b>42</b> is tasked with the over-all control of the electro-optics shown in FIG. <b>2</b>. Processor <b>42</b> controls menu operations, command and data received from I/O circuit <b>50</b>, data written to display <b>60</b>, and operating system functions. I/O circuit <b>50</b> controls the information received from keypad <b>14</b> and keypad <b>16</b>. Microprocessor <b>42</b> is also tasked with processing and decoding imaging data stored in RAM <b>46</b> in accordance with the programming instructions stored in EROM <b>48</b>. Thus, microprocessor <b>42</b> performs bar code decoding, optical character recognition, signature verification, and color image processing.</p>
    <p>In the embodiment depicted in FIG. 2, ASIC <b>44</b> is implemented using a programmable logic array (PLA) device. In a similar embodiment, ASIC <b>44</b> is implemented using a field programmable gate array (FPGA) device. ASIC <b>44</b> is tasked with controlling the image acquisition process, and the storage of image data. As part of the image acquisition process, ASIC <b>44</b> performs various timing and control functions including control of light source <b>24</b>, control of color imager <b>34</b>, and control of external interface <b>56</b>. It will be apparent to those of ordinary skill in the pertinent art that modifications and variations can be made to processor <b>40</b> of the present invention depending on the cost, availability, and performance of off-the-shelf microprocessors, and the type of color imager used. In one embodiment, microprocessor <b>42</b> and ASIC <b>44</b> are replaced by a single microprocessor <b>40</b>. In one embodiment, microprocessor <b>40</b> is implemented using a single RISC processor. In yet another embodiment, microprocessor <b>40</b> is implemented using a RISC and DSP hybrid processor.</p>
    <p>It will be apparent to those of ordinary skill in the pertinent art that modifications and variations can be made to the memory configuration of the present invention depending on cost and flexibility considerations. For example, in one embodiment, EROM <b>48</b> is implemented using EPROMs or E2PROMs. In yet another embodiment, FLASH memory is employed. RAM <b>46</b> typically includes at least one volatile memory device, and in some embodiments includes one or more long term non-volatile memory devices.</p>
    <p>It will be apparent to those of ordinary skill in the pertinent art that modifications and variations can be made to I/O unit <b>50</b> of the present invention depending on the application and work environment. Embodiments of I/O unit <b>50</b> include an RS-232 interface, a LAN interface, PAN interface, a serial bus such as USB, an internet interface, and a wireless interface.</p>
    <p>External interface <b>56</b> is used to transmit a discrete signal to control a peripheral device. Typically, the peripheral is an external illuminator. The external illuminator is used in place of light source <b>24</b>.</p>
    <p>It will be apparent to those of ordinary skill in the pertinent art that modifications and variations can be made to the operating system employed by optical reader <b>10</b> depending on the applications and desired operating environment. In one embodiment, a WindowsCE operating system is employed. In other embodiments, LINUX or PalmOS operating systems are employed. As a non-limiting example, application programs can be written using C, C++, Visual Basic, or Visual C++. Other languages can be used as well, depending on the application program. In other embodiments, optical reader <b>10</b> does not employ an operating system. For example, the simple reader depicted in FIG. 1D does not require a complex operating system.</p>
    <p>As embodied herein and depicted in FIG. 3, an example of a graphical user interface in accordance with the present invention is disclosed. Display <b>60</b> provides a plurality of application program icons displayed on graphical user interface (GUI) <b>650</b>. Selections are made by the user via arrow <b>652</b>. For example, GUI <b>650</b> allows a user to select the automatic image capture mode by clicking on automatic mode icon <b>654</b>. GUI <b>650</b> also includes semi-automatic image capture icon <b>656</b>, bar-code scanning icon <b>658</b>, OCR/text capture icon <b>660</b>, signature capture mode icon <b>662</b>, color photography mode icon <b>664</b>, association mode icon <b>668</b>, and additional application program icons <b>666</b>. The application program icon <b>666</b> may allow the user to collect other biometric information such as finger and voice prints. In the WindowsCE environment, start button icon <b>670</b> and tool bars may also be displayed on GUI <b>650</b>. GUI <b>650</b> also displays current application program data <b>672</b>.</p>
    <p>In the Automatic imaging mode, processor <b>40</b> is programmed to analyze the color imaging data to determine if an acquired image includes a graphical symbol or is merely a color photographic image. If it makes the determination that the color image includes a graphical symbol, it further analyzes the acquired image and classifies it as a bar code, OCR symbol, text, or a signature. Based on the classification, optical reader <b>10</b> jumps to the appropriate routine in EROM <b>48</b>. The semi-automatic mode is similar. Thus, in the automatic or semi-automatic modes, the bar code scanning mode, the OCR/text mode, the signature capture mode, the color photography mode, and the association mode are controlled by the application program, not by the user.</p>
    <p>However, the user may manually select any of the above listed modes. If the user clicks on bar code scanning icon <b>658</b>, the bar code scanning application program will run. In this application program, the user may select between a 1D bar code mode, 2D bar code mode or an autodiscrimination mode. Further, the user can manually select and de-select the types of bar codes optical reader <b>10</b> is enabled to read or not read.</p>
    <p>The user may also click on OCR/Text icon <b>660</b>. Clicking icon <b>660</b> provides the user with a check validation mode, a text scanning mode, or a bi-tonal image capture mode. The check validation mode is performed in conjunction with network services.</p>
    <p>Clicking on icon <b>662</b> provides the user with a signature capture mode. In one embodiment, this mode includes a signature verification program wherein the user may select between a static verification or a dynamic verification. In the static mode, the user captures the image of a signature. The captured image is compared with a reference image stored in a remote database. In the dynamic mode, optical reader <b>10</b> uses the stylus and signature block to capture the signature. In this mode, signature block <b>62</b> measures unique dynamic parameters, such as applied pressure, direction and timing of movements, or a combination of these parameters. One of ordinary skill in the art will recognize that this list is not meant to be all-inclusive, but rather, is a representative example. The captured dynamic parameters are compared with a reference data stored in a remote database.</p>
    <p>The user selects the color photography mode by clicking on icon <b>664</b>. This mode allows the user to select an automatic imaging mode wherein optical reader <b>10</b> makes the imaging adjustments(e.g., exposure, etc.) or a manual mode that allows the user to adjust imager settings as he pleases.</p>
    <p>In another embodiment, display <b>60</b> provides the user with a menu listing the main modes of optical reader <b>10</b>. The user employs keypad <b>16</b> to select the desired mode. A cursor key is employed to highlight any of the modes listed above. Upon pressing the enter key, processor <b>40</b> jumps to the appropriate routine stored in EROM <b>48</b>. As discussed above, a user may select between an Automatic Imaging mode, a Semi-Automatic Imaging mode, a bar code scanning mode, an OCR/text mode, a signature capture mode, a color photography mode, or an association mode.</p>
    <p>As embodied herein and depicted in FIG. 4, a flow chart showing the processing flow for the automatic imaging mode in accordance with another embodiment of the present invention is disclosed. After the user pulls the trigger in step <b>400</b>, processor reads the selected mode. In this case the automatic mode has been selected by the user. The processor initializes optical reader <b>10</b> hardware, defines image data memory space, and initializes software mode settings. In step <b>408</b>, optical reader <b>10</b> captures the image by obtaining color imaging data. In some embodiments, processor <b>40</b> may display the acquired image on display <b>60</b> during this step. In step <b>410</b>, processor <b>40</b> determines if the captured image includes a graphical symbol. In one embodiment, processor <b>40</b> uses only a portion of the color imaging data to make this determination. Because there are more green pixels than either red or blue pixels in the Bayer-Pattern, processor <b>40</b> uses the green pixels to look for high energy regions in the acquired image. High energy, e.g. black-white transitions are a good indicator for the presence of a graphical symbol, such as a bar code symbol. A black and white bi-tonal image will consist of green pixels that are in one of two possible value ranges. One narrow range of values is representative of white portions of the image, whereas the other narrow range of values is representative of black portions of the image.</p>
    <p>In another embodiment, step <b>410</b> is performed by considering all of the pixel values. However, the interpretation of the pixel's value is adjusted based on whether it is a red, green, or blue pixel. In another embodiment, processor <b>40</b> creates a gray-scale image to determine whether the image includes a graphical symbol.</p>
    <p>If in step <b>410</b> processor <b>40</b> determines that there is no graphical symbol present in the image, the user is asked in step <b>432</b> if he desires to store the image. If so, the color photographic image is stored in memory in step <b>434</b>. If processor <b>40</b> determines that the image includes a graphical symbol, the process flow moves on to step <b>418</b>. In this step, processor <b>40</b> strikes scanning lines to locate bar code symbol identifiers. If processor <b>40</b> determines that the graphical symbol is a bar code symbol it attempts to decode the symbol in step <b>436</b>. If the decoding is successful, the symbol may be a menu symbol or a data symbol. If it is a data symbol, the decoded value of the bar code symbol is output to the display. If it is a menu symbol, a menuing routine is executed. The menu symbol is discussed in more detail below.</p>
    <p>If processor <b>40</b> does not locate a bar code symbol it moves onto step <b>420</b> and looks for OCR-A or OCR-B characters. If it finds these characters it performs optical character recognition in step <b>422</b>. If it does not, processor evaluates the image for the presence of text. If text is located, the image is cropped, and the text is compressed and stored in steps <b>428</b> and <b>430</b>. If the image does not include text, processor <b>40</b> evaluates the image for the presence of a signature. If one is present, the image is cropped, and the data is compressed and stored in steps <b>428</b> and <b>430</b>. In another embodiment, optical reader <b>10</b> is networked, and processor <b>40</b> communicates with remote network resources to provide signature verification services. If processor <b>40</b> cannot detect a bar code symbol, OCR symbols, text, or a signature, the user is asked in step <b>432</b> if he desires to store the image. If he does, the color photographic image is stored in memory in step <b>434</b>.</p>
    <p>As embodied herein and depicted in FIG. 5, a flow chart showing the processing flow for the semi-automatic mode is disclosed. After the user pulls the trigger in step <b>500</b>, processor reads the selected mode, initializes optical reader <b>10</b> hardware, defines image data memory space, and initializes software mode settings. In step <b>508</b>, optical reader <b>10</b> captures and displays the image.</p>
    <p>In step <b>510</b>, processor <b>40</b> determines if the captured image includes a graphical symbol. Step <b>510</b> in the semi-automatic mode is identical to step <b>410</b> in the automatic mode. If processor <b>40</b> determines that the captured image does not include a graphical symbol, processor <b>40</b> asks the user if she wants to store the color image. If so, the color image is stored in step <b>514</b>. In step <b>516</b>, a prompt asks the user if he desires to associate the color image with another image. This step is not performed in the automatic mode. In step <b>518</b>, if the user answers in the affirmative, the association is made and the processing flow returns to step <b>508</b>.</p>
    <p>In steps <b>520</b>, <b>522</b>, <b>526</b>, and <b>532</b>, the user is given the opportunity to select the type of graphical imaging that is to be performed. The method for performing OCR, text capture, and signature capture and/or verification are discussed above in the automatic mode description with one difference. In the semi-automatic mode, the user is asked in step <b>538</b> if he desires to associate the processed image with a subsequent captured image. If so, process flow is directed back to step <b>508</b> and another image is captured and displayed. The association feature can be used several times to associate multiple images.</p>
    <p>If the user indicates that it is a bar code, an attempt is made to decode the symbol in step <b>540</b>. Referring back to step <b>540</b>, if the decoding attempt is successful, processor <b>40</b> determines in step <b>544</b> if the symbol is a menu symbol. If it is not a menu symbol, processor <b>40</b> displays the decoded bar code information on display <b>60</b>. If it is a menu symbol, processor <b>40</b> executes the appropriate menu routine in step <b>546</b>. In steps <b>552</b> to <b>564</b>, processor <b>40</b> may continue to capture images if the trigger is continuously pulled. In step <b>562</b>, the user is asked if he desires to associate the decoded bar-code with another image. If so, the program flow is directed back to step <b>508</b> and another image is captured and displayed. Processor <b>40</b> links this image to the decoded bar code information.</p>
    <p>As embodied herein and depicted in FIGS. 6A-6C, graphical depictions of the menu symbol used in the bar code processing flows depicted in FIG. <b>4</b> and FIG. 5 are disclosed. A decoded menu symbol includes menu word <b>600</b> which has the format depicted in FIG. <b>6</b>A. Menu word <b>600</b> includes a one byte product ID code <b>600</b>-<b>1</b>, that identifies the type and model of the optical reader. Field <b>600</b>-<b>2</b> of word <b>600</b> specifies the op-code. The op-codes are depicted in FIG. <b>6</b>C. Op-code <b>0</b>, refers to vector processing operations that are listed as A<b>1</b>-A<b>4</b> in FIG. <b>6</b>C. Vector processing allows the user to download, enabled codes, the parameter table, or current software to an external device. Op-codes <b>1</b>-<b>7</b> allow a user to modify a specific portion of the parameter table. These op-codes are used in conjunction with the offset field <b>600</b>-<b>3</b> and data fields <b>600</b>-<b>4</b> to <b>600</b>-<b>7</b>. Offset field <b>600</b>-<b>3</b> is an index relative to the base address of the parameter table in memory that specifies the exact location in the parameter table. The data fields <b>600</b>-<b>4</b> to <b>600</b>-<b>7</b> are used to specify a bit mask that indicates which bits are to be modified. FIG. 6B depicts a second important group of options. For example, reader operating modes are included in F<b>1</b>-F<b>6</b>. These options are identical to the icons displayed on GUI <b>650</b> in FIG. <b>3</b>. Offset field <b>600</b>-<b>3</b> accommodates other optical reader <b>10</b> options as shown.</p>
    <p>As embodied herein and depicted in FIG. 7, a flow chart showing a method for reading a bar code in accordance with yet another embodiment of the present invention is disclosed. In step <b>700</b>, processor <b>40</b> refers to a parameter table stored in EROM <b>48</b>. Specifically, processor <b>40</b> determines if the parameter table is programmed to perform 1D decoding. If the parameter table has enabled 1D processing, 1D autodiscrimination is performed. The parameter table specifies the values of the parameters that define the operational mode of the reader. Examples of these parameters include the size and frame rate of the color imager, codes that are enabled during bar code decoding, I/O communications protocols, OCR options, and others. If 1D decoding is successful, the decoded data is stored or displayed, in accordance with the parameter table settings. If 1D codes are disabled or if 1D decoding is unsuccessful, processor moves on to step <b>708</b>. In this step, processor <b>40</b> determines if any 2D codes are enabled. If the parameter table has all of the 2D codes disabled, processor <b>40</b> exits the bar code decoding routine. If 2D codes are enabled, 2D autodiscrimination is performed in step <b>710</b>. If decoding is successful, the decoded data is either stored or output, depending on the parameters stored in the parameter table. If decoding is unsuccessful, processor exits the routine.</p>
    <p>As embodied herein and depicted in FIG. 8, a flow chart showing a method for performing the 1D autodiscrimination of step <b>702</b> in FIG. 7 is disclosed. In step <b>800</b> processor <b>40</b> calculates the activities of selected image data elements. The activity is defined as a measure of the rate of change of the image data over a small two-dimensional portion of the region surrounding the selected data element. In one embodiment, the activity is calculated along any two arbitrarily selected directions which are orthogonal one to the other. Two mutually perpendicular directions are used because the orientation of the symbol is unknown. In step <b>802</b>, processor <b>40</b> looks for “high activity” regions. These high activity regions are referred to as candidate symbol regions(CSRs). A high activity region indicates a transition from a black region to a white region, or vice-versa. If there is more than one CSR, it may indicate the presence of more than one bar code symbol. In step <b>804</b>, processor <b>40</b> selects the largest CSR. In step <b>806</b>, processor <b>40</b> calculates the centroid of the largest CSR. Subsequently, processor <b>40</b> finds the direction of the highest activity in the largest CSR. In a 1D bar code, this will be the direction perpendicular to the direction of the bars. In steps <b>810</b> and <b>812</b>, processor defines the initial scan line(SC=0), as being the scan line bisecting the centroid of the bar code. Processor calculates the brightness values of sampling points along the initial scan line. These brightness values are converted to digital data in step <b>816</b>. In decoding step <b>818</b>, processor <b>40</b> applies one 1D decoding program after another. If decoding is unsuccessful, processor <b>40</b> checks if the entire CSR has been scanned. If not, it establishes a new scan line, and repeats the decoding process. If in step <b>822</b>, the entire CSR has been scanned, and there are no CSRs remaining to be decoded, processor <b>40</b> exits the routine. If in step <b>820</b>, 1D decoding is successful, processor <b>40</b> determines if the symbol is a 1D stacked symbol. If it is a 1D stacked symbol, processor <b>40</b> scans and decodes the remaining CSRs in the stacked symbol. If it is not a stacked symbol, the decoded 1D data is stored or output to display <b>60</b> in step <b>830</b>. In step <b>838</b>, processor <b>40</b> determines if there any unexamined regions. If there are unexamined regions, the decoding process is repeated. Otherwise, processor <b>40</b> exits the routine.</p>
    <p>As embodied herein and depicted in FIG. 9, a flow chart showing a method for 2D autodiscrimination is disclosed. In step <b>900</b>, processor <b>40</b> converts the image data into a two-state binarized format. In step <b>902</b>, processor <b>40</b> locates all 2D finder patterns and identifies them by type. Pattern types include bulls-eye type patterns, waistband type patterns peripheral patterns, and others. If the number of finder patterns equals zero, processor <b>40</b> exits the routine. If there are finder patterns, processor <b>40</b> locates the finder pattern closest to the center of the field of view in one embodiment of the invention. The closest-to-the-center option has an advantage in that a centrally located image is likely to be a symbol. In step <b>908</b>, processor <b>40</b> attempts to decode the symbol in accordance with the finder type. For example, the Aztec 2D matrix symbol employs a bulls-eye finder pattern. The DataMatrix symbology employs a peripheral finder pattern. If the decoding is successful, the decoded data is either stored or displayed. In step <b>914</b>, processor <b>40</b> determines if there are any other unused finder patterns. If so, the symbols corresponding to those unused patterns are decoded, and the previously described steps are repeated. Otherwise, processor <b>40</b> exits the routine.</p>
    <p>As embodied herein and depicted in FIG. 10, a flow chart showing a method for reading text in accordance with yet another embodiment of the present invention is disclosed. This routine can be accessed in a number of ways as described above. In step <b>1000</b>, a bit-map image of the page is produced. In step <b>1002</b>, the bit mapped image is sampled. In one embodiment, this is performed by analyzing every Nth scan line of the bit mapped image. The value of integer N is dependent on the resolution of the scanned image. In one embodiment the image is sampled every {fraction (1/40)}th of an inch. This provides sufficient resolution to locate and classify the various regions on the page. By sampling every {fraction (1/40)}th of an inch instead of every scan line, the processing and memory requirements of reader <b>10</b> are substantially reduced. In step <b>1004</b>, processor <b>40</b> identifies the page features. Processor <b>40</b> analyzes the page and divides it into blank and non-blank portions. The non-blank portions are analyzed to distinguish text regions from non-text regions. After determining the layout of the page, processor <b>40</b> uses black-to-white transitions to determine degrees of skew. In step <b>1008</b>, horizontal white spaces are identified to separate lines of text. In step <b>1010</b>, vertical white spaces are identified within each line of text to thereby separate individual words and characters from each other. In step <b>1014</b>, a character recognition algorithm is used in an attempt to recognize each individual character. Finally, in step <b>1016</b>, processor <b>40</b> formats the recovered text before storing the text in memory.</p>
    <p>As embodied herein and depicted in FIG. 11, a flow chart showing a method for performing OCR in accordance with yet another embodiment of the present invention is disclosed. In step <b>1100</b>, reader <b>10</b> produces a bit-mapped image of the page. Subsequently, processor <b>40</b> finds lines of text in the image, locates the white spaces in each line, and isolates the characters. In step <b>1108</b>, processor <b>40</b> performs character recognition, either OCR-A or OCR-B, as desired. The decoded characters are stored in memory.</p>
    <p>As embodied herein and depicted in FIG. 12, a flow chart showing a method for associating consecutive images taken with the color optical reader of the present invention is disclosed. This method corresponds to icon <b>668</b> displayed on GUI <b>650</b> in FIG. <b>3</b>. If icon <b>668</b> is not clicked on, processor <b>40</b> assumes that reader <b>10</b> is not operating in association mode. Thus, processor <b>40</b> will process a single image. If reader <b>10</b> is in association mode processor <b>40</b> initializes counter CNTR. In step <b>1206</b> processor <b>40</b> processes the first captured image. In step <b>1208</b>, if CNTR is less than or equal to two, processor <b>40</b> processes image N, and links image N to the first image. In step <b>1216</b>, CNTR is incremented by one. If CNTR is greater than two (step <b>1208</b>), meaning that at least two images have already been linked, processor <b>40</b> asks the user if she desires to link another image. If so, the processing flow returns to step <b>1212</b>. If not, processor <b>40</b> exits the routine.</p>
    <p>As embodied herein and depicted in FIG. 13, an example of image association in accordance with the present invention is disclosed. One or ordinary skill in the art will recognize that associated images <b>1300</b> can be disposed on paper, displayed electronically on display <b>60</b>, or displayed electronically sing other electronic means, such as a computer monitor. In this example, the first image captured is color photograph <b>1302</b> which shows a damaged parcel. The second image captured is bar code <b>1304</b> affixed to the side of the damaged parcel. Processor <b>40</b> decodes bar code <b>1304</b> and associates decoded bar code data <b>1306</b> with color photograph <b>1302</b>. In this example, the user elected to associate a third image, signature <b>1308</b>. Thus, personnel viewing record <b>1300</b> may reasonably conclude that a damaged parcel was delivered to Company XYZ, and that the person signing for the parcel delivery was someone named John W. Smith.</p>
    <p>As embodied herein and depicted in FIG. 14, a perspective view of a wireless color optical reader network <b>1400</b> in accordance with another embodiment of the present invention is disclosed. Network <b>1400</b> includes N-cordless optical scanners <b>10</b> coupled to base terminal <b>202</b> by means of radio link <b>18</b>. Base terminal <b>202</b> is connected to host computer <b>206</b> by communications link <b>204</b>. Cordless optical reader <b>10</b> is of the type described above. It includes antenna <b>102</b>, keypads <b>14</b> and <b>16</b>, and display <b>60</b>. A radio controller is included in both the optical scanner <b>10</b> and the base terminal <b>202</b>. It will be apparent to those of ordinary skill in the pertinent art that radio controller may be of any suitable type, but by way of example, radio controller <b>30</b> provides frequency hopping spread spectrum communications (FHSS) between scanner <b>10</b> and base terminal <b>202</b>. FHSS is a form of spread spectrum radio transmission that produces a narrow band signal that hops among a plurality of frequencies in a prearranged pattern. FHSS is often used in commercial environments because of its ability to minimize errors due to interference or jamming. However, those of ordinary skill in the art will recognize that optical scanner <b>10</b> and base terminal <b>202</b> may communicate using other wireless schemes and other modulation formats based on user requirements and environmental factors. Base terminal <b>202</b> includes antenna <b>208</b>, which is used to transmit and receive messages from optical scanner <b>10</b>. Antenna <b>208</b> is connected to a radio controller disposed inside terminal <b>202</b>. Base terminal <b>202</b> also includes an I/O card, a base terminal processor, and a base terminal memory. The I/O card in base terminal <b>202</b> is coupled to the radio controller and communications link <b>204</b>.</p>
    <p>As embodied herein and depicted in FIG. 15, a flow chart showing a method for transmitting packetized data from a color optical reader to a base station is disclosed. In steps <b>1500</b> and <b>1502</b>, optical reader <b>10</b> captures an image and processes the image as described above. In step <b>1504</b>, the processed image, whether it be a color image, decoded bar codes, a text file, or signature verification information, is assembled into packets. In steps <b>1506</b> and <b>1508</b>, a loop is created wherein packets are sent to the base terminal one-by-one until all packets are sent.</p>
    <p>As embodied herein and depicted in FIG. <b>16</b>A and FIG. 16B, diagrammatic depictions of packet formats in accordance with the present invention are disclosed. In one embodiment of the present invention, each packet can accommodate approximately 200 bytes of decoded data in a 256 byte packet. This is merely a representative example, and one of ordinary skill in the art will recognize that the scope of the present invention should not be limited to data packets of a certain size or format. FIG. 16A shows data packet <b>1600</b> which is used to transmit decoded data from an optical reader to a base terminal when only one data packet is required. Packet <b>1600</b> includes an optical reader address field, sequence number field, a packet length field, an image type field, image data, and an error check field. The optical reader address identifies a particular optical reader. Each packet includes a sequence number disposed in the second field. The next field contains the length of the image data field. After this, the packet contains a field identifying the type of image that was processed. After the image type, the image data payload of the packet is inserted. Finally, packet <b>200</b> includes an error checking field.</p>
    <p>FIG. 16B shows header packet <b>1602</b> and data packet <b>1604</b> used to transmit decoded data from an optical scanner to a base terminal when more than one data packet is required. When more than one packet is required, reader <b>10</b> first transmits header packet <b>1602</b>. After base terminal <b>202</b> acknowledges that it can process the remaining packets, reader <b>10</b> transmits remaining packets <b>1604</b>. If base terminal <b>202</b> cannot process the remaining packets <b>1604</b>, or if there is another problem, base terminal <b>202</b> will transmit an application packet to scanner <b>10</b> indicating the error. The definitions of the scanner address field, the sequence number field, symbol type, length, symbol data, and error check field were described above, and hence, will not be repeated. Header packet <b>1602</b> also includes a header identification field, which identifies the packet as a header packet. In the next field, packet <b>1602</b> includes a total length field, which includes the total length of the data contained in the decoded symbol. The next field includes the total number of packets in the message. The second-to-last field is the packet number. In the header packet, this number is designated as packet number “one.” The remaining packets <b>1604</b> also include a packet number field, which are incremented from 2 to N, depending on the total number of packets being transmitted in the message.</p>
    <p>Packet <b>1600</b>, packet <b>1602</b>, and packet <b>1604</b> as described above may be of any suitable type, and are representative examples representing one embodiment of the present invention. One of ordinary skill in the art will recognize that the packets may be implemented in a variety of ways.</p>
    <p>As embodied herein and depicted in FIG. 17, a flow chart showing a method for performing signature verification is disclosed. In step <b>1700</b>, optical reader <b>10</b> captures the image of the document to thereby generate a bit-map of the image. One of ordinary skill in the art will recognize that in the automatic mode or semi-automatic mode, processor <b>40</b> determines that the image object is a graphical symbol in a subsequent step. Step <b>1202</b> is similar to steps <b>1002</b> and <b>1004</b> of FIG. <b>10</b>. The image is sampled by analyzing every Nth scan line of the bit mapped image. As discussed above, the image must be scanned in such a way so as to provide sufficient resolution to locate and classify the various regions on the document. In the case of a check, the location of the various fields on the instrument are relatively standard. Check sizes may differ somewhat, but the check number, bank code, account number, date, signature block, and etc. are in the same relative locations from check to check. In step <b>1704</b>, document data such as the name, check number, bank code, account number, and date, are extracted from the document using any OCR program and stored in memory. In step <b>1706</b>, the image of the hand writing in the signature block is captured.</p>
    <p>Steps <b>1708</b> and <b>1710</b> are performed using the wireless system <b>1400</b> described above. In other embodiments these steps are performed by a wireline system. For example, in one embodiment, optical reader <b>10</b> is coupled to a host computer via an RS-232 or USB link. In another embodiment, optical reader <b>10</b> is connected to a host computer via a LAN. One of ordinary skill in the art will recognize that the present invention should not be construed as being limited by these examples.</p>
    <p>In steps <b>1712</b> and <b>1714</b>, processor <b>40</b> initializes a counter and begins waiting for a reply from the host computer. In steps <b>1714</b>-<b>1718</b>, if the reply is not received within time limit TL, the counter CNTR is incremented and the message is re-transmitted. After several attempts, if CNTR&gt;N (N being an integer), processor <b>40</b> outputs a fault message. If the reply message is received within time limit TL, processor interprets the reply in step <b>1722</b>. If the extracted data and the signature match information stored in the database accessible by the host computer, an approval message is displayed. If the extracted data and the signature do not match information stored in the database accessible by the host computer, a disapproval message is displayed. The dynamic signature verification embodiment is similar to the static embodiment described immediately above. In the dynamic version, the user provides his signature using stylus <b>18</b> and signature block <b>62</b>, as shown in FIG. <b>1</b>C. Signature block <b>62</b> provides processor <b>40</b> with the dynamic parameters recorded during signature. The dynamic parameters are transmitted to a host processor, as described above.</p>
    <p>As embodied herein and depicted in FIG. 18, an example of a color optical reader network <b>1800</b> in accordance with the present invention is disclosed. Network <b>1800</b> includes wireless system <b>1400</b>, personal computer <b>1802</b>, optical reader <b>10</b>, LAN <b>1820</b>, network servicing center <b>1830</b>, and personal area network (PAN) coupled together via network <b>1810</b>.</p>
    <p>One of ordinary skill in the art will recognize that network <b>1810</b> may be of any suitable type depending on the application, but there is shown by way of example the Internet. However, the present invention should not be construed as being limited to this example. In another embodiment, network <b>1810</b> is a private network. Those of ordinary skill in the art will also recognize that network <b>1810</b> is a wireline network in one embodiment, and a wireless network in another embodiment. Network <b>1810</b> may include circuit switched networks, IP networks, or both.</p>
    <p>LAN <b>1820</b> includes server <b>1822</b>, computer <b>1824</b>, database <b>1826</b>, and a plurality of optical readers <b>10</b>. Database <b>1826</b> is used to store associated images along with other data fields. For example, it would be rather useful to store additional information with the associated images shown in FIG. <b>13</b>. One may want to associate the delivery means, route, driver, and other related information for subsequent analysis. Network <b>1810</b> allows reader <b>10</b>, PAN <b>1850</b>, and wireless system <b>1400</b> a way to store such data in database <b>1826</b>. System analysts can access this information via personal computer <b>1802</b> connected to network <b>1810</b>. In one embodiment, LAN <b>1820</b> includes an Internet website. In this embodiment, users are authenticated before gaining access to database <b>1826</b>.</p>
    <p>Network servicing center <b>1830</b> is coupled to network <b>1810</b> via interface <b>1844</b>. Center <b>1830</b> also includes server <b>1832</b>, computer <b>1834</b>, database <b>1836</b>, signature verification module <b>1838</b>, authentication module <b>1840</b>, coupled together via a LAN. Center <b>1830</b> accommodates any number of useful applications programs <b>1842</b>.</p>
    <p>PAN <b>1850</b> includes at least one color optical reader <b>10</b> coupled to point-of-sale (POS) terminal <b>1854</b>. POS terminal <b>1854</b> is coupled to network <b>1810</b> via interface <b>182</b>. POS terminal <b>1854</b> includes a credit card reader and a signature capture block. In the scenario depicted in FIG. 18, a merchant user of POS terminal <b>1854</b> transmits an associated customer credit card number, signature, and in one embodiment, a color image of the customer, to Center <b>1830</b>. Authentication module <b>1840</b> is used to authenticate the credit card and signature verification module is used to authenticate the signature. In another embodiment, database <b>1836</b> is used to store the customer's image, credit card number, and signature for verification purposes.</p>
    <p>It will be apparent to those skilled in the art that various modifications and variations can be made to the present invention without departing from the spirit and scope of the invention. Thus, it is intended that the present invention cover the modifications and variations of this invention provided they come within the scope of the appended claims and their equivalents.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5091975">US5091975</a></td><td class="patent-data-table-td patent-date-value">Jan 4, 1990</td><td class="patent-data-table-td patent-date-value">Feb 25, 1992</td><td class="patent-data-table-td ">Teknekron Communications Systems, Inc.</td><td class="patent-data-table-td ">Method and an apparatus for electronically compressing a transaction with a human signature</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5420943">US5420943</a></td><td class="patent-data-table-td patent-date-value">Oct 29, 1992</td><td class="patent-data-table-td patent-date-value">May 30, 1995</td><td class="patent-data-table-td ">Mak; Stephen M.</td><td class="patent-data-table-td ">Universal computer input device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5714745">US5714745</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 1, 1996</td><td class="patent-data-table-td patent-date-value">Feb 3, 1998</td><td class="patent-data-table-td ">Metanetics Corporation</td><td class="patent-data-table-td ">Portable data collection device with color imaging assembly</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5804805">US5804805</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 19, 1996</td><td class="patent-data-table-td patent-date-value">Sep 8, 1998</td><td class="patent-data-table-td ">Norand Technology Corporation</td><td class="patent-data-table-td ">Hand-held optical indicia reader having a controlled oscillating system for optimal indicia reading</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5869828">US5869828</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 2, 1996</td><td class="patent-data-table-td patent-date-value">Feb 9, 1999</td><td class="patent-data-table-td ">Braginsky; Philip Yale</td><td class="patent-data-table-td ">Apparatus for conducting mass analysis of ions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5929418">US5929418</a></td><td class="patent-data-table-td patent-date-value">Sep 3, 1996</td><td class="patent-data-table-td patent-date-value">Jul 27, 1999</td><td class="patent-data-table-td ">Welch Allyn, Inc.</td><td class="patent-data-table-td ">Optical reader having improved menuing features</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6070805">US6070805</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 8, 1998</td><td class="patent-data-table-td patent-date-value">Jun 6, 2000</td><td class="patent-data-table-td ">Zebra Technologies Corporation</td><td class="patent-data-table-td ">Distortion resistant double-data correcting color transition barcode and method of generating and using same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6089455">US6089455</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 19, 1998</td><td class="patent-data-table-td patent-date-value">Jul 18, 2000</td><td class="patent-data-table-td ">Scan Technology Co., Ltd.</td><td class="patent-data-table-td ">Code recognition method and system for rotating body</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6108612">US6108612</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 23, 1998</td><td class="patent-data-table-td patent-date-value">Aug 22, 2000</td><td class="patent-data-table-td ">Interval Research Corporation</td><td class="patent-data-table-td ">Coded objects and methods for detecting such coded objects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6375075">US6375075</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 18, 1999</td><td class="patent-data-table-td patent-date-value">Apr 23, 2002</td><td class="patent-data-table-td ">Intermec Ip Corp.</td><td class="patent-data-table-td ">Method and apparatus for reading machine-readable symbols including color symbol elements</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6384907">US6384907</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 29, 2000</td><td class="patent-data-table-td patent-date-value">May 7, 2002</td><td class="patent-data-table-td ">Bae Systems Plc</td><td class="patent-data-table-td ">Optical target and apparatus and method for automatic identification thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0978990A2?cl=en">EP0978990A2</a></td><td class="patent-data-table-td patent-date-value">Apr 9, 1999</td><td class="patent-data-table-td patent-date-value">Feb 9, 2000</td><td class="patent-data-table-td ">Hewlett-Packard Company</td><td class="patent-data-table-td ">Appliance and method for navigating among multiple captured images and functional menus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=ENllBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DGB%26NR%3D2357209A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFi9R4uu5Y5vHP2Cjz9eXDNL6qtvA">GB2357209A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Application No. 10318006, Sep. 11, 1998.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Text String Extraction from Images of Colour-Printed Documents -IEEE Ptroc. -Vis. Image Signal Process., vol. 143, No. 4, Aug. 1996.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6976631">US6976631</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 21, 2003</td><td class="patent-data-table-td patent-date-value">Dec 20, 2005</td><td class="patent-data-table-td ">Tohken Co., Ltd.</td><td class="patent-data-table-td ">Code reader and code reading method for color image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7059525">US7059525</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 26, 2002</td><td class="patent-data-table-td patent-date-value">Jun 13, 2006</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Apparatus processing two dimensional image representations for optical reading</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7175094">US7175094</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 3, 2003</td><td class="patent-data-table-td patent-date-value">Feb 13, 2007</td><td class="patent-data-table-td ">Symbol Technologics, Inc.</td><td class="patent-data-table-td ">Mobile terminal with handle that houses a stylus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7195169">US7195169</a></td><td class="patent-data-table-td patent-date-value">Jul 23, 2003</td><td class="patent-data-table-td patent-date-value">Mar 27, 2007</td><td class="patent-data-table-td ">Symbol Technologies, Inc.</td><td class="patent-data-table-td ">Mobile terminal with ergonomic housing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7287697">US7287697</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 26, 2004</td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Optical reader having a color imager</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7293712">US7293712</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 5, 2004</td><td class="patent-data-table-td patent-date-value">Nov 13, 2007</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">System and method to automatically discriminate between a signature and a dataform</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7303134">US7303134</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 2004</td><td class="patent-data-table-td patent-date-value">Dec 4, 2007</td><td class="patent-data-table-td ">Ehrhart Michael A</td><td class="patent-data-table-td ">Lottery game tickets and methods for making same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7331523">US7331523</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 10, 2004</td><td class="patent-data-table-td patent-date-value">Feb 19, 2008</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Adaptive optical image reader</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7413127">US7413127</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 3, 2006</td><td class="patent-data-table-td patent-date-value">Aug 19, 2008</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Optical reader for classifying an image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7416129">US7416129</a></td><td class="patent-data-table-td patent-date-value">Mar 19, 2007</td><td class="patent-data-table-td patent-date-value">Aug 26, 2008</td><td class="patent-data-table-td ">Symbol Technologies, Inc.</td><td class="patent-data-table-td ">Mobile terminal with ergonomic housing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7460170">US7460170</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 23, 2002</td><td class="patent-data-table-td patent-date-value">Dec 2, 2008</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Computer expansion module having image capture and decoding functionality</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7562824">US7562824</a></td><td class="patent-data-table-td patent-date-value">Jan 4, 2007</td><td class="patent-data-table-td patent-date-value">Jul 21, 2009</td><td class="patent-data-table-td ">Symbol Technologies, Inc</td><td class="patent-data-table-td ">Mobile terminal with ergonomic housing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7609889">US7609889</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 5, 2005</td><td class="patent-data-table-td patent-date-value">Oct 27, 2009</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Web service application based optical character recognition system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7684826">US7684826</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 19, 2008</td><td class="patent-data-table-td patent-date-value">Mar 23, 2010</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Method and system for processing wireless digital multimedia</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7710598">US7710598</a></td><td class="patent-data-table-td patent-date-value">Aug 17, 2005</td><td class="patent-data-table-td patent-date-value">May 4, 2010</td><td class="patent-data-table-td ">Harrison Jr Shelton E</td><td class="patent-data-table-td ">Polychromatic encoding system, method and device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7735731">US7735731</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Jun 15, 2010</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Web-enabled mobile image capturing and processing (MICAP) cell-phone</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7753271">US7753271</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Jul 13, 2010</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Method of and apparatus for an internet-based network configured for facilitating re-labeling of a shipment of packages at the first scanning point employing the capture of shipping document images and recognition-processing thereof initiated from the point of shipment pickup and completed while said shipment is being transported to said first scanning point</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7766230">US7766230</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Aug 3, 2010</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Method of shipping, tracking, and delivering a shipment of packages over an internet-based network employing the capture of shipping document images and recognition-processing thereof initiated from the point of pickup and completed while shipment is being transported to its first scanning point in the network, so as to sort and route packages using the original shipment number assigned to the package shipment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7775431">US7775431</a></td><td class="patent-data-table-td patent-date-value">Jan 17, 2007</td><td class="patent-data-table-td patent-date-value">Aug 17, 2010</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Method of and apparatus for shipping, tracking and delivering a shipment of packages employing the capture of shipping document images and recognition-processing thereof initiated from the point of shipment pickup and completed while the shipment is being transported to its first scanning point to facilitate early customs clearance processing and shorten the delivery time of packages to point of destination</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7798400">US7798400</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Sep 21, 2010</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Method of and apparatus for shipping, tracking, and delivering a shipment of packages employing the capture of shipping document images and recognition-processing thereof initiated from the point of pickup and completed while shipment is being transported to its first scanning point so as to facilitate early billing processing for shipment delivery</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7810724">US7810724</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Oct 12, 2010</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Method of and apparatus for shipping, tracking, and delivering a shipment of packages employing the capture of shipping document images and recognition-processing thereof initiated from the point of shipment pickup and completed while the shipment is being transported to its first scanning point, to shorten the delivery time of packages to point of destination</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7837105">US7837105</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Nov 23, 2010</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Method of and apparatus for translating shipping documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7870999">US7870999</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Jan 18, 2011</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Internet-based shipping, tracking, and delivery network supporting a plurality of mobile digital image capture and processing (MICAP) systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7883013">US7883013</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Feb 8, 2011</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Mobile image capture and processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7886972">US7886972</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Feb 15, 2011</td><td class="patent-data-table-td ">Metrologic Instruments, Inc.</td><td class="patent-data-table-td ">Digital color image capture and processing module</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7920299">US7920299</a></td><td class="patent-data-table-td patent-date-value">Mar 14, 2006</td><td class="patent-data-table-td patent-date-value">Apr 5, 2011</td><td class="patent-data-table-td ">Gtech Rhode Island Corporation</td><td class="patent-data-table-td ">System and method for processing a form</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7932457">US7932457</a></td><td class="patent-data-table-td patent-date-value">Jan 29, 2007</td><td class="patent-data-table-td patent-date-value">Apr 26, 2011</td><td class="patent-data-table-td ">University Of South Florida</td><td class="patent-data-table-td ">Accelerated aging process for acoustic stringed instruments</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7953442">US7953442</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 3, 2010</td><td class="patent-data-table-td patent-date-value">May 31, 2011</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Method and system for processing wireless digital multimedia</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7977555">US7977555</a></td><td class="patent-data-table-td patent-date-value">Aug 5, 2008</td><td class="patent-data-table-td patent-date-value">Jul 12, 2011</td><td class="patent-data-table-td ">University Of South Florida</td><td class="patent-data-table-td ">Method of modifying the frequency response of a wooden article</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8059168">US8059168</a></td><td class="patent-data-table-td patent-date-value">Sep 22, 2008</td><td class="patent-data-table-td patent-date-value">Nov 15, 2011</td><td class="patent-data-table-td ">Gtech Corporation</td><td class="patent-data-table-td ">System and method for scene change triggering</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8072651">US8072651</a></td><td class="patent-data-table-td patent-date-value">Sep 24, 2008</td><td class="patent-data-table-td patent-date-value">Dec 6, 2011</td><td class="patent-data-table-td ">Gtech Corporation</td><td class="patent-data-table-td ">System and process for simultaneously reading multiple forms</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8118226">US8118226</a></td><td class="patent-data-table-td patent-date-value">Feb 11, 2010</td><td class="patent-data-table-td patent-date-value">Feb 21, 2012</td><td class="patent-data-table-td ">Datalogic Scanning, Inc.</td><td class="patent-data-table-td ">High-resolution optical code imaging using a color imager</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8233181">US8233181</a></td><td class="patent-data-table-td patent-date-value">Feb 14, 2011</td><td class="patent-data-table-td patent-date-value">Jul 31, 2012</td><td class="patent-data-table-td ">Gtech Rhode Island Corporation</td><td class="patent-data-table-td ">System and method for processing a form</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8233200">US8233200</a></td><td class="patent-data-table-td patent-date-value">Nov 26, 2008</td><td class="patent-data-table-td patent-date-value">Jul 31, 2012</td><td class="patent-data-table-td ">Gtech Corporation</td><td class="patent-data-table-td ">Curvature correction and image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8292180">US8292180</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 1, 2011</td><td class="patent-data-table-td patent-date-value">Oct 23, 2012</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Optical reader having an imager</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8295601">US8295601</a></td><td class="patent-data-table-td patent-date-value">Aug 12, 2009</td><td class="patent-data-table-td patent-date-value">Oct 23, 2012</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Indicia reading terminal having multiple exposure periods and methods for same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8381984">US8381984</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 2010</td><td class="patent-data-table-td patent-date-value">Feb 26, 2013</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">System operative for processing frame having representation of substrate</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8496177">US8496177</a></td><td class="patent-data-table-td patent-date-value">Jun 28, 2007</td><td class="patent-data-table-td patent-date-value">Jul 30, 2013</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Bar code reading terminal with video capturing mode</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8520080">US8520080</a></td><td class="patent-data-table-td patent-date-value">Jan 31, 2011</td><td class="patent-data-table-td patent-date-value">Aug 27, 2013</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Apparatus, system, and method of use of imaging assembly on mobile terminal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8528818">US8528818</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 26, 2010</td><td class="patent-data-table-td patent-date-value">Sep 10, 2013</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Optical reader having an imager</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8537245">US8537245</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 4, 2011</td><td class="patent-data-table-td patent-date-value">Sep 17, 2013</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Imaging and decoding device with quantum dot imager</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8544737">US8544737</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 14, 2009</td><td class="patent-data-table-td patent-date-value">Oct 1, 2013</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Terminal including imaging assembly</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8599271">US8599271</a></td><td class="patent-data-table-td patent-date-value">Mar 26, 2012</td><td class="patent-data-table-td patent-date-value">Dec 3, 2013</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Apparatus, system, and method of use of imaging assembly on mobile terminal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8646694">US8646694</a></td><td class="patent-data-table-td patent-date-value">Dec 23, 2011</td><td class="patent-data-table-td patent-date-value">Feb 11, 2014</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Indicia reading terminal including frame processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8660355">US8660355</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 23, 2010</td><td class="patent-data-table-td patent-date-value">Feb 25, 2014</td><td class="patent-data-table-td ">Digimarc Corporation</td><td class="patent-data-table-td ">Methods and systems for determining image processing operations relevant to particular imagery</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8662245">US8662245</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2011</td><td class="patent-data-table-td patent-date-value">Mar 4, 2014</td><td class="patent-data-table-td ">University Of South Florida</td><td class="patent-data-table-td ">Frequency response treatment of wood paneling</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8670168">US8670168</a></td><td class="patent-data-table-td patent-date-value">Apr 6, 2012</td><td class="patent-data-table-td patent-date-value">Mar 11, 2014</td><td class="patent-data-table-td ">Search And Social Media Partners Llc</td><td class="patent-data-table-td ">Polychromatic encoding system, method and device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8727223">US8727223</a></td><td class="patent-data-table-td patent-date-value">Jan 7, 2013</td><td class="patent-data-table-td patent-date-value">May 20, 2014</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Indicia reading apparatus having image sensor array</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8783573">US8783573</a></td><td class="patent-data-table-td patent-date-value">Dec 2, 2008</td><td class="patent-data-table-td patent-date-value">Jul 22, 2014</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Indicia reading terminal having plurality of optical assemblies</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100090006">US20100090006</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 14, 2009</td><td class="patent-data-table-td patent-date-value">Apr 15, 2010</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Terminal including imaging assembly</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110244919">US20110244919</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 23, 2010</td><td class="patent-data-table-td patent-date-value">Oct 6, 2011</td><td class="patent-data-table-td ">Aller Joshua V</td><td class="patent-data-table-td ">Methods and Systems for Determining Image Processing Operations Relevant to Particular Imagery</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110284638">US20110284638</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 1, 2011</td><td class="patent-data-table-td patent-date-value">Nov 24, 2011</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Optical reader having an imager</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120224083">US20120224083</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 4, 2011</td><td class="patent-data-table-td patent-date-value">Sep 6, 2012</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Imaging and decoding device with quantum dot imager</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2364026A2?cl=en">EP2364026A2</a></td><td class="patent-data-table-td patent-date-value">Mar 7, 2006</td><td class="patent-data-table-td patent-date-value">Sep 7, 2011</td><td class="patent-data-table-td ">Hand Held Products, Inc.</td><td class="patent-data-table-td ">Digital picture taking optical reader having hybrid monochrome and color image sensor array</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2008109604A2?cl=en">WO2008109604A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 4, 2008</td><td class="patent-data-table-td patent-date-value">Sep 12, 2008</td><td class="patent-data-table-td ">Triage Data Networks</td><td class="patent-data-table-td ">Monitor for measuring vital signs and rendering video images</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc235/defs235.htm&usg=AFQjCNE4qW8wy3R4_i_voHj55rF5UTzd0Q#C235S469000">235/469</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc235/defs235.htm&usg=AFQjCNE4qW8wy3R4_i_voHj55rF5UTzd0Q#C235S462040">235/462.04</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc235/defs235.htm&usg=AFQjCNE4qW8wy3R4_i_voHj55rF5UTzd0Q#C235S462400">235/462.4</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0001000000">H04N1/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0001107000">H04N1/107</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0007100000">G06K7/10</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0007000000">G06T7/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0007400000">G06T7/40</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009200000">G06K9/20</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009220000">G06K9/22</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0001400000">H04N1/40</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/228">G06K9/228</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/107">H04N1/107</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00442">G06K9/00442</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/40062">H04N1/40062</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=ENllBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/0035">H04N1/0035</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N1/107</span>, <span class="nested-value">H04N1/00D</span>, <span class="nested-value">G06K9/00L</span>, <span class="nested-value">H04N1/40L</span>, <span class="nested-value">G06K9/22W</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Sep 23, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 13, 2010</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1, 12, 20, 29, 35, 48 AND 52-54 IS CONFIRMED. CLAIMS 49, 50 AND 51 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 2-11, 13-19, 21-28, 30-34, 36-47 AND 55-83 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 17, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 17, 2007</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">HAND HELD PRODUCTS, INC., NEW YORK</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:WELCH ALLYN DATA COLLECTION, INC.;REEL/FRAME:019974/0200</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20010628</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 10, 2007</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20070525</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 28, 2001</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">WELCH ALLYN DATA COLLECTION, INC., NEW YORK</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:EHRBART, MICHAEL;LONGACRE, JR., ANDREW;REEL/FRAME:012247/0549;SIGNING DATES FROM 20010813 TO 20010816</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">WELCH ALLYN DATA COLLECTION, INC. 4619 JORDAN ROAD</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:EHRBART, MICHAEL /AR;REEL/FRAME:012247/0549;SIGNING DATES FROM 20010813 TO 20010816</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U2GXCvnABSaSr5jTGDr1nEfw4NcfQ\u0026id=ENllBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3Jc7jnEalBM6-WXWF38c2XKwznMA\u0026id=ENllBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U0KUOC9EOgQEmWnGXy1x02ilmnNOQ","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Optical_reader_having_a_color_imager.pdf?id=ENllBAABERAJ\u0026output=pdf\u0026sig=ACfU3U2TQF1H_S7LS8IAElweFBV4z4XBNA"},"sample_url":"http://www.google.com/patents/reader?id=ENllBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>