<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5831669 - Facility monitoring system with image memory and correlation - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Facility monitoring system with image memory and correlation"><meta name="DC.contributor" content="John B. Adrain" scheme="inventor"><meta name="DC.contributor" content="Ericsson Inc" scheme="assignee"><meta name="DC.date" content="1996-7-9" scheme="dateSubmitted"><meta name="DC.description" content="A video image of a space is monitored and compared to a reference image. Correlation of the images indicates presence of unwanted persons or objects or the occurrence of unwanted events. When programmed comparison criteria are met, an alarm is activated, the space is displayed on a monitor, and the image is stored in memory. Reference images are stored during dedicated or ongoing learn modes."><meta name="DC.date" content="1998-11-3" scheme="issued"><meta name="DC.relation" content="US:4185298" scheme="references"><meta name="DC.relation" content="US:4547897" scheme="references"><meta name="DC.relation" content="US:4704694" scheme="references"><meta name="DC.relation" content="US:4728195" scheme="references"><meta name="DC.relation" content="US:4972359" scheme="references"><meta name="DC.relation" content="US:5293428" scheme="references"><meta name="DC.relation" content="US:5367439" scheme="references"><meta name="DC.relation" content="US:5371690" scheme="references"><meta name="DC.relation" content="US:5426509" scheme="references"><meta name="citation_patent_number" content="US:5831669"><meta name="citation_patent_application_number" content="US:08/677,100"><link rel="canonical" href="http://www.google.com/patents/US5831669"/><meta property="og:url" content="http://www.google.com/patents/US5831669"/><meta name="title" content="Patent US5831669 - Facility monitoring system with image memory and correlation"/><meta name="description" content="A video image of a space is monitored and compared to a reference image. Correlation of the images indicates presence of unwanted persons or objects or the occurrence of unwanted events. When programmed comparison criteria are met, an alarm is activated, the space is displayed on a monitor, and the image is stored in memory. Reference images are stored during dedicated or ongoing learn modes."/><meta property="og:title" content="Patent US5831669 - Facility monitoring system with image memory and correlation"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("oFDsU92bKov9oASZqIDIBw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CRI"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("oFDsU92bKov9oASZqIDIBw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CRI"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5831669?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5831669"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=H4tIBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5831669&amp;usg=AFQjCNEE6flXT84VEP4G21Tx3pxuW8MWIQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5831669.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5831669.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5831669" style="display:none"><span itemprop="description">A video image of a space is monitored and compared to a reference image. Correlation of the images indicates presence of unwanted persons or objects or the occurrence of unwanted events. When programmed comparison criteria are met, an alarm is activated, the space is displayed on a monitor, and the image...</span><span itemprop="url">http://www.google.com/patents/US5831669?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5831669 - Facility monitoring system with image memory and correlation</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5831669 - Facility monitoring system with image memory and correlation" title="Patent US5831669 - Facility monitoring system with image memory and correlation"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5831669 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/677,100</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Nov 3, 1998</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jul 9, 1996</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jul 9, 1996</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08677100, </span><span class="patent-bibdata-value">677100, </span><span class="patent-bibdata-value">US 5831669 A, </span><span class="patent-bibdata-value">US 5831669A, </span><span class="patent-bibdata-value">US-A-5831669, </span><span class="patent-bibdata-value">US5831669 A, </span><span class="patent-bibdata-value">US5831669A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22John+B.+Adrain%22">John B. Adrain</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Ericsson+Inc%22">Ericsson Inc</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5831669.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5831669.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5831669.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (9),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (64),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (15),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (8)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5831669&usg=AFQjCNHiO_R_rkRut_bPJafz6b88uoqkmg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5831669&usg=AFQjCNHOBslBBi64WZxwr8fW1P0ONhfm_g">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5831669A%26KC%3DA%26FT%3DD&usg=AFQjCNFQyswTUQGS5E3P4z_7CC1XHaUHvQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54366366" lang="EN" load-source="patent-office">Facility monitoring system with image memory and correlation</invention-title></span><br><span class="patent-number">US 5831669 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37837506" lang="EN" load-source="patent-office"> <div class="abstract">A video image of a space is monitored and compared to a reference image. Correlation of the images indicates presence of unwanted persons or objects or the occurrence of unwanted events. When programmed comparison criteria are met, an alarm is activated, the space is displayed on a monitor, and the image is stored in memory. Reference images are stored during dedicated or ongoing learn modes.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(2)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5831669-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5831669-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5831669-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5831669-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(20)</span></span></div><div class="patent-text"><div mxw-id="PCLM5307832" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A monitoring system comprising:<div class="claim-text">a movably mounted camera adapted for receiving images of a space to be monitored;</div> <div class="claim-text">an interpreter for receiving image data from the camera;</div> <div class="claim-text">a reference memory for storing reference image data;</div> <div class="claim-text">a comparator connected for comparing image data from the interpreter to image data from the reference memory according to selected comparison criteria, wherein the interpreter and comparator cooperate to select recognizable portions of image data among unrecognized portions of image data in the space being monitored, the selected image portions being compared to the image data in the reference memory; and</div> <div class="claim-text">an output interface for reporting results of the image data comparisons performed by the comparator.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. A system according to claim 1 further comprising a programmer for inputting the comparison criteria to the comparator.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. A system according to claim 2 wherein the programmer is connected for inputting analysis criteria to the interpreter and the interpreter is adapted for analyzing the image data according to the analysis criteria.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. A system according to claim 3 wherein the programmer is connected for inputting learn criteria to the interpreter and the interpreter is connected for storing image data from the camera in the reference memory according to the learn and analysis criteria.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. A system according to claim 2 wherein the programmer is connected for inputting learn criteria to the interpreter and the interpreter is connected for storing image data from the camera in the reference memory according to the learn criteria.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. A system according to claim 2 wherein the programmer is connected for inputting utilization criteria, the output interface being adapted for reporting selected comparison results according the utilization criteria.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. A system according to claim 1 wherein the camera is mounted on a vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. A system according to claim 1 wherein the record memory is adapted for storing information associated with the image data stored.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. A system according to claim 1 wherein the interpreter selects images according to analysis criteria so that only the selected images are input to the comparator for comparison to reference images.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. A system according to claim 9 wherein the selected images represent only portions of a larger image.</div>
    </div>
    </div> <div class="claim"> <div num="11" class="claim">
      <div class="claim-text">11. A monitoring system comprising:<div class="claim-text">a movably mounted camera adapted for receiving images of a space to be monitored;</div> <div class="claim-text">an interpreter for receiving image data from the camera;</div> <div class="claim-text">a reference memory for storing reference image data for plural images and a comparator adapted for comparing image data from the interpreter to image data for the plural images from the reference memory according to selected comparison criteria, wherein the interpreter and comparator cooperate to select recognizable portions of image data among unrecognized portions of image data in the space being monitored, the selected image portions being compared to the image data in the reference memory; and</div> <div class="claim-text">an output interface for reporting results of the image data comparisons performed by the comparator.</div> </div>
    </div>
    </div> <div class="claim"> <div num="12" class="claim">
      <div class="claim-text">12. A method of monitoring a space comprising the steps of:<div class="claim-text">receiving a first set of image data from the space representing plural images;</div> <div class="claim-text">identifying and selecting a portion of the information to be stored according to analysis and learn criteria;</div> <div class="claim-text">storing the selected information;</div> <div class="claim-text">receiving a second set of image data from the space;</div> <div class="claim-text">identifying and selecting a portion of the second set of image data to be analyzed according to the analysis criteria, wherein the selected portion represents a recognizable portion of image data among unrecognized portions of image data in the space being monitored;</div> <div class="claim-text">comparing the selected portions of the sets of image data to each other so as to compare the second set of image data to the plural images of the first set and determine a correlation of the images; and</div> <div class="claim-text">indicating whether the correlation of the images meets selected comparison criteria.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. A method according to claim 12 further comprising the step of reporting results of the comparison step according to utilization criteria and augmenting the reporting with identifying information.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. A method according to claim 12 further comprising the step of establishing the analysis and learn criteria.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. A method according to claim 12 further comprising the step of establishing the comparison criteria.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. A method according to claim 12 wherein the image data are sequentially received from different spaces.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. A method according to claim 12 wherein the step of storing data includes establishing baseline image data and subsequently storing changes from the baseline data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. A method according to claim 12 wherein the portions of data selected represent a zone of the space.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. A method according to claim 18 wherein the steps are repeated for selected data representing a different zone of the space and at least one set of the analysis, learn, and comparison criteria is different from the previous criteria.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. A method according to claim 12 wherein the comparison of image data is repeated to distinguish between movements based on a series of sequential images.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67199770" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>This invention relates generally to the field of monitoring and security and specifically to a system that records images and identifies correlation or lack of correlation with the images.</p>
    <p>2. Description of the Related Art</p>
    <p>Video cameras are used for monitoring activity in myriad locations and applications. Commonly, a person views a display showing a scene viewed by the cameras. A single display might receive input from several cameras or each camera might have a dedicated display. Frequently, the person is responsible for monitoring several displays, in addition to other responsibilities. The person cannot give undivided attention to each monitor. Even if the person is responsible only for monitoring a single display, fatigue, boredom, hypnosis, or other factors can cause the person to miss events shown on the display.</p>
    <p>Events recorded by the cameras are frequently stored on tape or by some other memory device for subsequent review. This permits replay and careful review, but monitoring is not automatic and not coincident with the events being recorded.</p>
    <p>Machine vision devices employing digital image processing are used in manufacturing to test proper positioning, assembly and construction of parts and components. Numerous images of parts or assemblies are successively compared to reference images. Correlation and other characteristics of the comparisons are determined. If a part or assembly does not meet selected criteria, it is determined to be defective and is removed from the manufacturing operation. Examples of such devices and associated systems are shown in U.S. Pat. Nos. 4,185,298; 4,704,694; 4,728,195; 4,972,359; 5,293,428; 5,367,439; 5,371,690; 5,426,509.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention provides a monitoring system having a camera adapted for receiving images of a space to be monitored. An interpreter receives image data from the camera, and a reference memory stores reference image data. A comparator is connected for comparing image data from the interpreter to image data from the reference memory according to selected comparison criteria. An output interface reports results of the image data comparisons performed by the comparator.</p>
    <p>A programmer is provided for inputting the comparison criteria to the comparator. The programmer is connected for inputting analysis criteria to the interpreter and the interpreter is adapted for analyzing the image data according to the analysis criteria. The programmer is connected for inputting learn criteria to the interpreter and the interpreter is connected for storing image data from the camera in the reference memory according to the learn and analysis criteria. The programmer is connected for inputting learn criteria to the interpreter and the interpreter is connected for storing image data from the camera in the reference memory according to the learn criteria. The programmer is connected for inputting utilization criteria, the output interface being adapted for reporting selected comparison results according the utilization criteria.</p>
    <p>A record memory is connected for storing image data from the output interface. The record memory is adapted for storing information associated with the image data stored. A video monitor is provided for displaying images from the output interface. A second camera is connected to provide image data to the interpreter, wherein the interpreter derives a three-dimensional image of the space and the reference memory, comparator, and output interface are adapted for processing three-dimensional image data.</p>
    <p>The interpreter is adapted for storing in the reference memory image data from the camera. The interpreter is adapted for periodically storing in the reference memory image data from the camera according to learn criteria. The reference memory is adapted for storing image data for plural images and the comparator is adapted for comparing image data from the interpreter to image data for the plural images from the reference memory according to selected comparison criteria. The camera is mounted to a movable support, such as a vehicle, and the space to be monitored changes according to movement of the support. Alternatively, the camera is mounted to a stationary support. The interpreter is adapted for dividing image data into zones and the comparator is adapted for comparing image data corresponding to the different zones with image data from the reference memory according to different comparison criteria for each zone. The interpreter is adapted for disregarding image data corresponding with a certain zone selected according to selected analysis criteria. The comparator is adapted for sequentially comparing the image data from the different zones and discontinuing comparison of an image upon failure to meet the comparison criteria for the zone being compared. The interpreter is adapted for dividing image data into zones and different criteria are applied to different zones of the image data.</p>
    <p>The invention also provides a method of monitoring a space. Method steps include receiving a first set of image data from the space; identifying and selecting a portion of the information to be stored according to analysis and learn criteria; storing the selected information; receiving a second set of image data from the space; identifying and selecting a portion of the second set of image data to be analyzed according to the analysis criteria; comparing the selected portions of the sets of image data to each other so as to determine a correlation of the images; and indicating whether the correlation of the images meets selected comparison criteria.</p>
    <p>Additional steps include reporting results of the comparison step according to utilization criteria; establishing the analysis and learn criteria; establishing the comparison criteria; and establishing the utilization criteria. The step of indicating includes recording image data according to utilization criteria. Plural sets of image data are stored and the step of comparing the image data comprises comparison of the plural sets of image data to one of the sets of image data. The image data are sequentially received from different spaces. The step of storing data includes establishing baseline image data and subsequently storing changes from the baseline data. The portions of data selected represent a zone of the space. The steps are repeated for selected data representing a different zone of the space and at least one set of the analysis, learn, and comparison criteria is different from the previous criteria.</p>
    <p>The system according to the invention has application in numerous situations where video or human monitoring is presently utilized. In addition, this system has application where video and other forms of monitoring have been ineffective. For example, casinos can use this system for identifying irregularities in the dealing and playing of cards and other games. Commercial facilities can use the system for reliably identifying breaches of security with minimal false alarms. Law enforcement officials can use the system to monitor license plates with mobile or stationary equipment for identifying stolen vehicles.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 shows a block diagram of a monitoring system according to the invention; and</p>
    <p>FIG. 2 shows a schematic diagram of another embodiment of the invention.</p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>Referring to FIG. 1, a monitoring system 10 includes cameras 12, 13 for monitoring a space 14. The space 14 can be a room, an entry, a passage, or any other location. The cameras 12, 13 are mounted on stationary supports, such as walls of the space 14. In one embodiment, the camera 12 is a digital video camera translating visible images into digital electric signals. As discussed below, other cameras are also suitable, such as analog or infrared. A single camera can be used for two dimensional images; Two cameras are used for three-dimensional images, wherein an interpreter derives the three-dimensional image from image data received from the two cameras. Additional cameras can be used for monitoring different spaces or different characteristics of the same space. The cameras are connected to input image data to an interpreter 16. The interpreter 16 selects image data from the cameras 12, 13 according to analysis criteria input from a programmer 18. Programming can be performed directly by user inputs provided at the programmer or remotely, for example by a modem using a computer with a program interface. A reference memory 20 receives data from the interpreter 16 according to storage criteria input to the interpreter by the programmer 18. A comparator 22 receives data from the interpreter 16 and reference memory 20 and compares these data according to comparison criteria input by the programmer 18. The comparator 22 determines a correlation between pixels from the reference memory 20 and pixels from the interpreter 16. If the comparator 22 determines that the correlation falls within or outside of a selected range requiring action, results of the comparison are input to an output interface 24, such as an alarm panel, a memory interface, or a video monitor interface. The output interface 24 reports results of the comparison by selecting comparison data to be stored or otherwise utilized by a record memory 26 or monitor 28, for example, connected to receive data from the output interface according to criteria input by the programmer 18. Preferably, the interpreter 16, programmer 18, reference memory 20, comparator 22, and output interface 24 are integrated in a microcomputer and associated software.</p>
    <p>Using the programmer 18, a user inputs learn criteria, including analysis and storage criteria for reference images to be stored in the reference memory. For example, the user can instruct the interpreter 16 to identify and store in the reference memory 20 a pixel representation of all stationary objects on a shelf in the space 14 at a selected time. The interpreter 16 identifies the object images meeting the programmed criteria, and stores the images in the reference memory 20. The reference memory can be divided into sections for storing different types of data. The reference memory can include an archive section in which baseline image data are stored. After storing the baseline data, subsequent images can be stored by storing only data that have changed from the baseline. According to user programming, the storing of images can be repeated at selected times or continuously according to the learn criteria. For example, the stationary objects can be identified at the same time every day, or when a person whose image data is in the reference memory appears in the space with a new person, the new person's image data is stored in the reference memory. Also, the learn criteria can be automatically revised to create new learn criteria according to image data from the interpreter and the current learn criteria.</p>
    <p>The user also programs analysis criteria for monitoring the space. For example, the interpreter 16 can monitor image data from the camera 12 during certain time periods when the images of the stationary objects are not supposed to be moved.</p>
    <p>The user also inputs comparison criteria. Comparison criteria include selecting the images to be compared and a range of correlation in which the monitored image is sufficiently like the reference image for a particular purpose. For example, stationary object images and monitored images are compared to determine whether any object previously identified as stationary is not in its previous location. Image data from the interpreter and the reference memory are compared by the comparator 22 according to the comparison criteria to determine correlation of the images. For example, if the location of an object in the image data from the interpreter is not the same as the location of the same object in the reference memory, then the comparator sends an alarm signal to the output interface 24 indicating an alarm condition. Sensitivity of the correlation can be adjusted. For example, the alarm condition can occur on any movement of an object or only on complete absence of an object from the space. The comparison criteria can include events or movements as well as stationary patterns. For example, a person's hand would be an acceptable stationary pattern, but a pixel pattern representing sudden movement of the hand, such as striking something, would represent an impermissible event causing an alarm. The alarm signal can include an image of the space, an identification of the space or the object, the time of the signal, or any other signal indicating that the comparison criteria have been met or not met, as is appropriate. The output interface 24 selects and/or translates the appropriate signals and forwards them to output devices. For example, an audible alarm sounds and the monitor 28 shows the video image of the space 14 when the object is moved, and the image, date and time of the movement of the object is recorded in the record memory 26. Multiple monitoring system components can be connected to a single output interface and monitor to monitor different spaces or different parts of a space. When an alarm condition arises in one space, its output is sent to the monitor and can be augmented by other information such as sound from the space being monitored and information about the space or condition.</p>
    <p>Learning and analysis can be performed separately or coincidentally. Learning can be accomplished directly by entering a learn only mode and recording images in the reference memory. Learning can also be accomplished indirectly, for example by association of new images with previously learned images or by receiving new images during permitted learning periods that coincide with monitoring periods.</p>
    <p>Referring to FIG. 2, the camera 12 can be mounted on a mobile support, such as a vehicle 30. The space 14 and objects 32 being monitored change according to movement of the vehicle 30. For example, the camera can be mounted on a police car and programmed to monitor license plate numbers. The reference memory stores license numbers for stolen cars. Analysis is limited to consistently sized characters within a specified boundary, that is the rectangular shape of the license plate. When the object 32 meets the analysis criteria of a license plate, the number is compared to the numbers in the reference memory. When the comparison finds a match, an appropriate alarm indicates discovery of a stolen car to officers in the police car. Information about the car and possible occupants can be displayed as well.</p>
    <p>The invention, as shown for example in FIGS. 1 and 2, can be used in numerous methods of operation. The license plate example utilizes a high degree of correlation between the reference image and the monitored image. Other aspects of the invention, discussed previously and below, utilize lack of correlation between the reference and monitored images to trigger an alarm condition. Combinations of these aspects can also be used for different objects or spaces monitored by the same system.</p>
    <p>A limited access entry or passage, an office or workspace, or a home can be monitored. The learn criteria identify persons permitted to be in the monitored space, image data of their faces being stored in the reference memory. The space monitored is generally consistent so that the analysis criteria ignore the environment and limit the analysis to the faces of persons in the space. The comparison criteria are set to identify unauthorized persons in the space according to comparison of persons in the space with persons in the reference memory. The comparison allows for variations in appearance, such as changes in hair style or facial expressions, by allowing pixel comparisons to vary within a range and by focusing on less changeable parts, such as the nose.</p>
    <p>Sensitivity of the correlation can be varied within a space being monitored. Image data for a space can be divided into zones in which different learn, analysis, comparison, and/or utilization criteria apply. For example, monitoring roads to locate license plates, as described with reference to FIG. 2, can also include monitoring the object vehicles 34. License plate characters are uniform, so close correlation of the reference and object in zone A is desired. The color and general outline of the object vehicle can also be analyzed, however, lesser correlation is desired in zone B because different lighting can affect color and the amount of data required for the comparison can be limited. Also, assuming the license plate characters match, close correlation of the vehicle comparison may not be necessary. An alternative analysis and comparison would identify a license plate match in zone A and then compare the vehicle outline in zone B. If the vehicle outline does not sufficiently correlate with the image data corresponding to the license plate number, the output interface would report that the license plate has been switched from the vehicle on which the plate is supposed to be mounted.</p>
    <p>Images from different zones can be compared sequentially. The results of a comparison in one zone can affect whether and how a subsequent comparison is performed. For example, the results of a comparison in one zone can determine which zone and/or what comparison criteria are used for a subsequent comparison.</p>
    <p>Another method monitors a consistent space, with many different objects and persons. The analysis is limited to specifically defined movements or events possibly within a specified zone. For example, cheating at a casino black jack table is monitored by identifying cards that move outside a selected zone on the table. Also, a person's hand or arm that reaches from the players' side of the table into a forbidden zone will trigger an alarm. However, the dealer's arms and the movement of cards in the playing zone are ignored. Events occurring away from the table are also ignored although they might be recorded for the purpose of identifying the offending player.</p>
    <p>In some applications, all but very specific events can be ignored. For example, bank employees can be trained to make a certain movement during a robbery. To the uninitiated, the signal appears innocuous, but the monitoring system is programmed to recognize the movement and trigger an alarm. Like a password, the movement can be changed and accordingly reprogrammed in the system.</p>
    <p>Data other than visual images can also be analyzed. For example, thermal images can be used to sense overheating of equipment or fires in facilities. Micropower impulse radar (MIR) can be used to monitor spaces through smoke, walls, or other opaque materials. Different types of cameras or cameras collecting different types of image data can be combined. For example, a thermal camera can monitor a space to sense a fire. A radar camera can monitor the same space to sense whether floors or walls have collapsed due to the fire.</p>
    <p>Monitoring can be accomplished in real time or using images collected previously. For example, an amusement park can use cameras located at different points in the park. Analysis of traffic flow can be analyzed in real time based on criteria selected prior to monitoring. Results can be used immediately to correct for unwanted conditions. Alternatively, the cameras can collect image data for storage. At a later time, comparison can be made based on criteria selected at the later time and the comparison results used to establish a statistical database for future planning.</p>
    <p>The present disclosure describes several embodiments of the invention, however, the invention is not limited to these embodiments. Other variations are contemplated to be within the spirit and scope of the invention and appended claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4185298">US4185298</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 12, 1976</td><td class="patent-data-table-td patent-date-value">Jan 22, 1980</td><td class="patent-data-table-td ">Compagnie Industrielle Des Telecommunications Cit-Alcatel S.A.</td><td class="patent-data-table-td ">Process and apparatus for the automatic inspection of patterns</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4547897">US4547897</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 1, 1983</td><td class="patent-data-table-td patent-date-value">Oct 15, 1985</td><td class="patent-data-table-td ">Honeywell Inc.</td><td class="patent-data-table-td ">Image processing for part inspection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4704694">US4704694</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 16, 1985</td><td class="patent-data-table-td patent-date-value">Nov 3, 1987</td><td class="patent-data-table-td ">Automation Intelligence, Inc.</td><td class="patent-data-table-td ">Learned part system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4728195">US4728195</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 19, 1986</td><td class="patent-data-table-td patent-date-value">Mar 1, 1988</td><td class="patent-data-table-td ">Cognex Corporation</td><td class="patent-data-table-td ">Method for imaging printed circuit board component leads</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4972359">US4972359</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 3, 1987</td><td class="patent-data-table-td patent-date-value">Nov 20, 1990</td><td class="patent-data-table-td ">Cognex Corporation</td><td class="patent-data-table-td ">Digital image processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5293428">US5293428</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 28, 1992</td><td class="patent-data-table-td patent-date-value">Mar 8, 1994</td><td class="patent-data-table-td ">Rohm Co., Ltd.</td><td class="patent-data-table-td ">Optical apparatus for use in image recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5367439">US5367439</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 24, 1992</td><td class="patent-data-table-td patent-date-value">Nov 22, 1994</td><td class="patent-data-table-td ">Cognex Corporation</td><td class="patent-data-table-td ">System for frontal illumination</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5371690">US5371690</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 17, 1992</td><td class="patent-data-table-td patent-date-value">Dec 6, 1994</td><td class="patent-data-table-td ">Cognex Corporation</td><td class="patent-data-table-td ">Method and apparatus for inspection of surface mounted devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5426509">US5426509</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 20, 1993</td><td class="patent-data-table-td patent-date-value">Jun 20, 1995</td><td class="patent-data-table-td ">Peplinski; Robert A.</td><td class="patent-data-table-td ">Device and method for detecting foreign material on a moving printed film web</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5982362">US5982362</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 6, 1997</td><td class="patent-data-table-td patent-date-value">Nov 9, 1999</td><td class="patent-data-table-td ">Control Technology Corporation</td><td class="patent-data-table-td ">Video interface architecture for programmable industrial control systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6275954">US6275954</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 25, 1999</td><td class="patent-data-table-td patent-date-value">Aug 14, 2001</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for analyzing data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6400265">US6400265</a></td><td class="patent-data-table-td patent-date-value">Apr 24, 2001</td><td class="patent-data-table-td patent-date-value">Jun 4, 2002</td><td class="patent-data-table-td ">Microstrategy, Inc.</td><td class="patent-data-table-td ">System and method for monitoring security systems by using video images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6400276">US6400276</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 8, 2000</td><td class="patent-data-table-td patent-date-value">Jun 4, 2002</td><td class="patent-data-table-td ">Ncr Corporation</td><td class="patent-data-table-td ">Self-service terminal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6411209">US6411209</a></td><td class="patent-data-table-td patent-date-value">Dec 6, 2000</td><td class="patent-data-table-td patent-date-value">Jun 25, 2002</td><td class="patent-data-table-td ">Koninklijke Philips Electronics N.V.</td><td class="patent-data-table-td ">Method and apparatus to select the best video frame to transmit to a remote station for CCTV based residential security monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6441734">US6441734</a></td><td class="patent-data-table-td patent-date-value">Dec 12, 2000</td><td class="patent-data-table-td patent-date-value">Aug 27, 2002</td><td class="patent-data-table-td ">Koninklijke Philips Electronics N.V.</td><td class="patent-data-table-td ">Intruder detection through trajectory analysis in monitoring and surveillance systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6476858">US6476858</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 12, 1999</td><td class="patent-data-table-td patent-date-value">Nov 5, 2002</td><td class="patent-data-table-td ">Innovation Institute</td><td class="patent-data-table-td ">Video monitoring and security system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6525663">US6525663</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 15, 2001</td><td class="patent-data-table-td patent-date-value">Feb 25, 2003</td><td class="patent-data-table-td ">Koninklijke Philips Electronics N.V.</td><td class="patent-data-table-td ">Automatic system for monitoring persons entering and leaving changing room</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6570498">US6570498</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 22, 2001</td><td class="patent-data-table-td patent-date-value">May 27, 2003</td><td class="patent-data-table-td ">Best Access Systems</td><td class="patent-data-table-td ">Integrated access system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6593852">US6593852</a></td><td class="patent-data-table-td patent-date-value">Jul 11, 2002</td><td class="patent-data-table-td patent-date-value">Jul 15, 2003</td><td class="patent-data-table-td ">Koninklijke Philips Electronics N.V.</td><td class="patent-data-table-td ">Intruder detection through trajectory analysis in monitoring and surveillance systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6641091">US6641091</a></td><td class="patent-data-table-td patent-date-value">Dec 3, 2001</td><td class="patent-data-table-td patent-date-value">Nov 4, 2003</td><td class="patent-data-table-td ">General Electric Company</td><td class="patent-data-table-td ">Highway railroad crossing vehicle detection methods and systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6661340">US6661340</a></td><td class="patent-data-table-td patent-date-value">Apr 24, 2001</td><td class="patent-data-table-td patent-date-value">Dec 9, 2003</td><td class="patent-data-table-td ">Microstrategy Incorporated</td><td class="patent-data-table-td ">System and method for connecting security systems to a wireless device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6690414">US6690414</a></td><td class="patent-data-table-td patent-date-value">Dec 12, 2000</td><td class="patent-data-table-td patent-date-value">Feb 10, 2004</td><td class="patent-data-table-td ">Koninklijke Philips Electronics N.V.</td><td class="patent-data-table-td ">Method and apparatus to reduce false alarms in exit/entrance situations for residential security monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6744049">US6744049</a></td><td class="patent-data-table-td patent-date-value">Mar 13, 2001</td><td class="patent-data-table-td patent-date-value">Jun 1, 2004</td><td class="patent-data-table-td ">Infrared Integrated Systems Limited</td><td class="patent-data-table-td ">Detection of obstacles in surveillance systems using pyroelectric arrays</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6744462">US6744462</a></td><td class="patent-data-table-td patent-date-value">Dec 12, 2000</td><td class="patent-data-table-td patent-date-value">Jun 1, 2004</td><td class="patent-data-table-td ">Koninklijke Philips Electronics N.V.</td><td class="patent-data-table-td ">Apparatus and methods for resolution of entry/exit conflicts for security monitoring systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6816186">US6816186</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 18, 2000</td><td class="patent-data-table-td patent-date-value">Nov 9, 2004</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Automatic zone monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6954859">US6954859</a></td><td class="patent-data-table-td patent-date-value">Oct 8, 1999</td><td class="patent-data-table-td patent-date-value">Oct 11, 2005</td><td class="patent-data-table-td ">Axcess, Inc.</td><td class="patent-data-table-td ">Networked digital security system and methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6990253">US6990253</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 22, 2002</td><td class="patent-data-table-td patent-date-value">Jan 24, 2006</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7242817">US7242817</a></td><td class="patent-data-table-td patent-date-value">Sep 13, 2005</td><td class="patent-data-table-td patent-date-value">Jul 10, 2007</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7310111">US7310111</a></td><td class="patent-data-table-td patent-date-value">Oct 10, 2002</td><td class="patent-data-table-td patent-date-value">Dec 18, 2007</td><td class="patent-data-table-td ">Innovation Institute</td><td class="patent-data-table-td ">Video monitoring and security system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7349581">US7349581</a></td><td class="patent-data-table-td patent-date-value">May 18, 2007</td><td class="patent-data-table-td patent-date-value">Mar 25, 2008</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7349582">US7349582</a></td><td class="patent-data-table-td patent-date-value">May 24, 2007</td><td class="patent-data-table-td patent-date-value">Mar 25, 2008</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7382934">US7382934</a></td><td class="patent-data-table-td patent-date-value">May 23, 2007</td><td class="patent-data-table-td patent-date-value">Jun 3, 2008</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7389000">US7389000</a></td><td class="patent-data-table-td patent-date-value">May 23, 2007</td><td class="patent-data-table-td patent-date-value">Jun 17, 2008</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7391883">US7391883</a></td><td class="patent-data-table-td patent-date-value">May 23, 2007</td><td class="patent-data-table-td patent-date-value">Jun 24, 2008</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7400746">US7400746</a></td><td class="patent-data-table-td patent-date-value">May 23, 2007</td><td class="patent-data-table-td patent-date-value">Jul 15, 2008</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7421148">US7421148</a></td><td class="patent-data-table-td patent-date-value">May 18, 2007</td><td class="patent-data-table-td patent-date-value">Sep 2, 2008</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7428344">US7428344</a></td><td class="patent-data-table-td patent-date-value">May 18, 2007</td><td class="patent-data-table-td patent-date-value">Sep 23, 2008</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7433496">US7433496</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 26, 2002</td><td class="patent-data-table-td patent-date-value">Oct 7, 2008</td><td class="patent-data-table-td ">Yazaki Corportion</td><td class="patent-data-table-td ">In-vehicle image correcting device and night driving view field supporting device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7492964">US7492964</a></td><td class="patent-data-table-td patent-date-value">May 18, 2007</td><td class="patent-data-table-td patent-date-value">Feb 17, 2009</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7504965">US7504965</a></td><td class="patent-data-table-td patent-date-value">Aug 7, 2006</td><td class="patent-data-table-td patent-date-value">Mar 17, 2009</td><td class="patent-data-table-td ">Elsag North America, Llc</td><td class="patent-data-table-td ">Portable covert license plate reader</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7510194">US7510194</a></td><td class="patent-data-table-td patent-date-value">Jun 28, 2005</td><td class="patent-data-table-td patent-date-value">Mar 31, 2009</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Playing cards with separable components</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7575234">US7575234</a></td><td class="patent-data-table-td patent-date-value">Apr 13, 2004</td><td class="patent-data-table-td patent-date-value">Aug 18, 2009</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Wireless monitoring of playing cards and/or wagers in gaming</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7753779">US7753779</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2006</td><td class="patent-data-table-td patent-date-value">Jul 13, 2010</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Gaming chip communication system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7753798">US7753798</a></td><td class="patent-data-table-td patent-date-value">Sep 2, 2004</td><td class="patent-data-table-td patent-date-value">Jul 13, 2010</td><td class="patent-data-table-td ">Bally Gaming International, Inc.</td><td class="patent-data-table-td ">Systems, methods, and devices for monitoring card games, such as baccarat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7761310">US7761310</a></td><td class="patent-data-table-td patent-date-value">Dec 7, 2006</td><td class="patent-data-table-td patent-date-value">Jul 20, 2010</td><td class="patent-data-table-td ">Samarion, Inc.</td><td class="patent-data-table-td ">Methods and systems for monitoring quality and performance at a healthcare facility</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7771272">US7771272</a></td><td class="patent-data-table-td patent-date-value">Apr 14, 2005</td><td class="patent-data-table-td patent-date-value">Aug 10, 2010</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Systems and methods for monitoring activities on a gaming table</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7786874">US7786874</a></td><td class="patent-data-table-td patent-date-value">Dec 7, 2006</td><td class="patent-data-table-td patent-date-value">Aug 31, 2010</td><td class="patent-data-table-td ">Samarion, Inc.</td><td class="patent-data-table-td ">Methods for refining patient, staff and visitor profiles used in monitoring quality and performance at a healthcare facility</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7901285">US7901285</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 8, 2005</td><td class="patent-data-table-td patent-date-value">Mar 8, 2011</td><td class="patent-data-table-td ">Image Fidelity, LLC</td><td class="patent-data-table-td ">Automated game monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7902978">US7902978</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 20, 2008</td><td class="patent-data-table-td patent-date-value">Mar 8, 2011</td><td class="patent-data-table-td ">John C. Pederson</td><td class="patent-data-table-td ">Intelligent observation and identification database system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7911348">US7911348</a></td><td class="patent-data-table-td patent-date-value">Jul 17, 2007</td><td class="patent-data-table-td patent-date-value">Mar 22, 2011</td><td class="patent-data-table-td ">Bee Cave, LLC.</td><td class="patent-data-table-td ">Methods for refining patient, staff and visitor profiles used in monitoring quality and performance at a healthcare facility</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7944469">US7944469</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 14, 2006</td><td class="patent-data-table-td patent-date-value">May 17, 2011</td><td class="patent-data-table-td ">Vigilos, Llc</td><td class="patent-data-table-td ">System and method for using self-learning rules to enable adaptive security monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7952609">US7952609</a></td><td class="patent-data-table-td patent-date-value">Oct 11, 2005</td><td class="patent-data-table-td patent-date-value">May 31, 2011</td><td class="patent-data-table-td ">Axcess International, Inc.</td><td class="patent-data-table-td ">Networked digital security system and methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7967682">US7967682</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2006</td><td class="patent-data-table-td patent-date-value">Jun 28, 2011</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Wireless gaming environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7987069">US7987069</a></td><td class="patent-data-table-td patent-date-value">Nov 11, 2008</td><td class="patent-data-table-td patent-date-value">Jul 26, 2011</td><td class="patent-data-table-td ">Bee Cave, Llc</td><td class="patent-data-table-td ">Monitoring patient support exiting and initiating response</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8144195">US8144195</a></td><td class="patent-data-table-td patent-date-value">Oct 9, 2008</td><td class="patent-data-table-td patent-date-value">Mar 27, 2012</td><td class="patent-data-table-td ">Honda Giken Kogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">Vehicle zone monitoring apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8192283">US8192283</a></td><td class="patent-data-table-td patent-date-value">Nov 17, 2009</td><td class="patent-data-table-td patent-date-value">Jun 5, 2012</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Networked gaming system including a live floor view module</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8194127">US8194127</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 7, 2006</td><td class="patent-data-table-td patent-date-value">Jun 5, 2012</td><td class="patent-data-table-td ">Lg Electronics Inc.</td><td class="patent-data-table-td ">Method and apparatus for masking surveillance video images for privacy protection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8238657">US8238657</a></td><td class="patent-data-table-td patent-date-value">May 18, 2007</td><td class="patent-data-table-td patent-date-value">Aug 7, 2012</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">System and method for detecting obstacle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8285034">US8285034</a></td><td class="patent-data-table-td patent-date-value">Jun 22, 2010</td><td class="patent-data-table-td patent-date-value">Oct 9, 2012</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Apparatus, method and article for evaluating a stack of objects in an image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8366542">US8366542</a></td><td class="patent-data-table-td patent-date-value">May 21, 2009</td><td class="patent-data-table-td patent-date-value">Feb 5, 2013</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Networked gaming system with enterprise accounting methods and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8382584">US8382584</a></td><td class="patent-data-table-td patent-date-value">May 21, 2009</td><td class="patent-data-table-td patent-date-value">Feb 26, 2013</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Networked gaming system with enterprise accounting methods and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8485907">US8485907</a></td><td class="patent-data-table-td patent-date-value">Apr 27, 2010</td><td class="patent-data-table-td patent-date-value">Jul 16, 2013</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Systems, methods, and devices for monitoring card games, such as Baccarat</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8606002">US8606002</a></td><td class="patent-data-table-td patent-date-value">Sep 14, 2012</td><td class="patent-data-table-td patent-date-value">Dec 10, 2013</td><td class="patent-data-table-td ">Bally Gaming, Inc.</td><td class="patent-data-table-td ">Apparatus, method and article for evaluating a stack of objects in an image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8620625">US8620625</a></td><td class="patent-data-table-td patent-date-value">Jul 30, 2010</td><td class="patent-data-table-td patent-date-value">Dec 31, 2013</td><td class="patent-data-table-td ">Hill-Rom Services, Inc.</td><td class="patent-data-table-td ">Above bed sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8631226">US8631226</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 28, 2006</td><td class="patent-data-table-td patent-date-value">Jan 14, 2014</td><td class="patent-data-table-td ">Verizon Patent And Licensing Inc.</td><td class="patent-data-table-td ">Method and system for video monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070106419">US20070106419</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 28, 2006</td><td class="patent-data-table-td patent-date-value">May 10, 2007</td><td class="patent-data-table-td ">Verizon Business Network Services Inc.</td><td class="patent-data-table-td ">Method and system for video monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110069171">US20110069171</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 13, 2009</td><td class="patent-data-table-td patent-date-value">Mar 24, 2011</td><td class="patent-data-table-td ">Hong Fu Jin Precision Industry (Shenzhen) Co., Ltd</td><td class="patent-data-table-td ">Method and system for autonomous video monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110304467">US20110304467</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 9, 2011</td><td class="patent-data-table-td patent-date-value">Dec 15, 2011</td><td class="patent-data-table-td ">Hon Hai Precision Industry Co., Ltd.</td><td class="patent-data-table-td ">Image monitoring device and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130007872">US20130007872</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 28, 2011</td><td class="patent-data-table-td patent-date-value">Jan 3, 2013</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method for contexually interpreting image sequences</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130176450">US20130176450</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 14, 2012</td><td class="patent-data-table-td patent-date-value">Jul 11, 2013</td><td class="patent-data-table-td ">Timothy R. Pryor</td><td class="patent-data-table-td ">Camera based interaction and instruction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130250132">US20130250132</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 26, 2013</td><td class="patent-data-table-td patent-date-value">Sep 26, 2013</td><td class="patent-data-table-td ">Timothy R. Pryor</td><td class="patent-data-table-td ">Camera based interaction and instruction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20140022392">US20140022392</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 20, 2013</td><td class="patent-data-table-td patent-date-value">Jan 23, 2014</td><td class="patent-data-table-td ">Federal Law Enforcement Development Services, Inc.</td><td class="patent-data-table-td ">Intelligent Observation And Identification Database System</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2255533A2?cl=en">EP2255533A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 16, 2009</td><td class="patent-data-table-td patent-date-value">Dec 1, 2010</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Capturing event information using a digital video camera</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S143000">348/143</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348SE07086">348/E07.086</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S159000">348/159</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S159000">382/159</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S156000">348/156</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S155000">348/155</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S161000">348/161</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S156000">382/156</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S152000">348/152</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007180000">H04N7/18</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009000000">G06K9/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00">G06K9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=H4tIBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N7/181">H04N7/181</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N7/18C</span>, <span class="nested-value">G06K9/00</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jun 24, 2014</td><td class="patent-data-table-td ">B2</td><td class="patent-data-table-td ">Reexamination certificate second reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIM 6 IS CONFIRMED.CLAIMS 1 AND 11 WERE PREVIOUSLY CANCELLED.CLAIMS 30-32, 35-39 AND 41-42 ARE CANCELLED.CLAIMS 2-5, 7-10, 12-29, 33-34, 40 AND 43-52 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 16, 2013</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20130530</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 2, 2012</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 21, 2012</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1 AND 11 ARE CANCELLED. CLAIMS 2 AND 7-9 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 3 AND 10, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. NEW CLAIMS 21-52 ARE ADDED AND DETERMINED TO BE PATENTABLE. CLAIMS 4-6 AND 12-20 WERE NOT REEXAMINED. OTHER NEW CLAIMS 53-56 WERE CANCELLED BY THE EXAMINER S AMENDMENT.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 28, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100914</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 17, 2010</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 28, 2002</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1sxKMv3nc3zHAF69mMyWlRWDH7eA\u0026id=H4tIBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3VTJqi-EdVZr2udawR2g3nRNwf_Q\u0026id=H4tIBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U3kKD4buqK11-XI8tOXJfOQz6eVYA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Facility_monitoring_system_with_image_me.pdf?id=H4tIBAABERAJ\u0026output=pdf\u0026sig=ACfU3U1nqNLJ9goVc1_9wYSQNpMDiERZ1Q"},"sample_url":"http://www.google.com/patents/reader?id=H4tIBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>