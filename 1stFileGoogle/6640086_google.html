<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6640086 - Method and apparatus for creating and distributing real-time interactive ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_4ff636b3d23669b7103f3b3a3a18b4cd/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_4ff636b3d23669b7103f3b3a3a18b4cd__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method and apparatus for creating and distributing real-time interactive media content through wireless communication networks and the internet"><meta name="DC.contributor" content="Corbett Wall" scheme="inventor"><meta name="DC.contributor" content="Corbett Wall" scheme="assignee"><meta name="DC.date" content="2001-9-25" scheme="dateSubmitted"><meta name="DC.description" content="Using an apparatus like a cellular telephone, an operator is able to create a message by singing into the apparatus or by pressing buttons on the apparatus as he listens to background music presented by the apparatus. By pressing buttons, the operator is able to generate sounds as if he was playing a musical instrument. A remote server stores a representation of the operator vocal or tactile input, and sends a message to one or more recipients that renders the operator input and background music in a manner that substantially preserves the temporal relationship originally observed by the operator."><meta name="DC.date" content="2003-10-28" scheme="issued"><meta name="DC.relation" content="JP:2001211485" scheme="references"><meta name="DC.relation" content="JP:2001339487" scheme="references"><meta name="DC.relation" content="US:20020188447:A1" scheme="references"><meta name="DC.relation" content="US:20030013483:A1" scheme="references"><meta name="DC.relation" content="US:5588842" scheme="references"><meta name="DC.relation" content="US:5613192" scheme="references"><meta name="DC.relation" content="US:6083009" scheme="references"><meta name="DC.relation" content="US:6331669" scheme="references"><meta name="DC.relation" content="WO:1999012153:A1" scheme="references"><meta name="DC.relation" content="WO:2001093261:A1" scheme="references"><meta name="citation_reference" content="Song-Yi Yi; Heonshik Shin &quot;Design of a real-time trader for mobile objects in open distributed environments&quot; Real-Time Systems, 1996., Proceedings of the Eighth Euromicro Workshop on, Jun. 1996, pp. 212-217."><meta name="citation_patent_number" content="US:6640086"><meta name="citation_patent_application_number" content="US:09/963,348"><link rel="canonical" href="http://www.google.com/patents/US6640086"/><meta property="og:url" content="http://www.google.com/patents/US6640086"/><meta name="title" content="Patent US6640086 - Method and apparatus for creating and distributing real-time interactive media content through wireless communication networks and the internet"/><meta name="description" content="Using an apparatus like a cellular telephone, an operator is able to create a message by singing into the apparatus or by pressing buttons on the apparatus as he listens to background music presented by the apparatus. By pressing buttons, the operator is able to generate sounds as if he was playing a musical instrument. A remote server stores a representation of the operator vocal or tactile input, and sends a message to one or more recipients that renders the operator input and background music in a manner that substantially preserves the temporal relationship originally observed by the operator."/><meta property="og:title" content="Patent US6640086 - Method and apparatus for creating and distributing real-time interactive media content through wireless communication networks and the internet"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("kuPoU7yADYyNyAS85YGIDA"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407291699.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("LUX"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("kuPoU7yADYyNyAS85YGIDA"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407291699.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("LUX"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6640086?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6640086"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=B6hiBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6640086&amp;usg=AFQjCNEnwuu2zZFEaErr9ea5XtxBgvIKkQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6640086.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6640086.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20030027591"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US6640086"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6640086" style="display:none"><span itemprop="description">Using an apparatus like a cellular telephone, an operator is able to create a message by singing into the apparatus or by pressing buttons on the apparatus as he listens to background music presented by the apparatus. By pressing buttons, the operator is able to generate sounds as if he was playing a...</span><span itemprop="url">http://www.google.com/patents/US6640086?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6640086 - Method and apparatus for creating and distributing real-time interactive media content through wireless communication networks and the internet</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6640086 - Method and apparatus for creating and distributing real-time interactive media content through wireless communication networks and the internet" title="Patent US6640086 - Method and apparatus for creating and distributing real-time interactive media content through wireless communication networks and the internet"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6640086 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/963,348</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Oct 28, 2003</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Sep 25, 2001</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">May 15, 2001</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US20030027591">US20030027591</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09963348, </span><span class="patent-bibdata-value">963348, </span><span class="patent-bibdata-value">US 6640086 B2, </span><span class="patent-bibdata-value">US 6640086B2, </span><span class="patent-bibdata-value">US-B2-6640086, </span><span class="patent-bibdata-value">US6640086 B2, </span><span class="patent-bibdata-value">US6640086B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Corbett+Wall%22">Corbett Wall</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Corbett+Wall%22">Corbett Wall</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6640086.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6640086.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6640086.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (10),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (1),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (12),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (15),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (7)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6640086&usg=AFQjCNFlf9ag7KQrJCIE27Q4HpT3OHnylQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6640086&usg=AFQjCNGe6kgr3ReWjjl_HsiUX9wAg9XZ3w">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6640086B2%26KC%3DB2%26FT%3DD&usg=AFQjCNE8oYORT5scM7eXXfK3eamUsnzc6A">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55162380" lang="EN" load-source="patent-office">Method and apparatus for creating and distributing real-time interactive media content through wireless communication networks and the internet</invention-title></span><br><span class="patent-number">US 6640086 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50568221" lang="EN" load-source="patent-office"> <div class="abstract">Using an apparatus like a cellular telephone, an operator is able to create a message by singing into the apparatus or by pressing buttons on the apparatus as he listens to background music presented by the apparatus. By pressing buttons, the operator is able to generate sounds as if he was playing a musical instrument. A remote server stores a representation of the operator vocal or tactile input, and sends a message to one or more recipients that renders the operator input and background music in a manner that substantially preserves the temporal relationship originally observed by the operator.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(4)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6640086B2/US06640086-20031028-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6640086B2/US06640086-20031028-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6640086B2/US06640086-20031028-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6640086B2/US06640086-20031028-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6640086B2/US06640086-20031028-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6640086B2/US06640086-20031028-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6640086B2/US06640086-20031028-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6640086B2/US06640086-20031028-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(34)</span></span></div><div class="patent-text"><div mxw-id="PCLM8565470" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is: </claim-statement> <div class="claim"> <div num="1" id="US-6640086-B2-CLM-00001" class="claim">
      <div class="claim-text">1. A method for using a handheld apparatus having one or more output devices including a rasterized visual display that present output to an operator, one or more input devices including an array of switches that receive input from the operator, a wireless transmitter, and processing circuitry that controls operation of the one or more output devices, the one or more input devices and the wireless transmitter, wherein the method comprises steps that perform the acts of:</div>
      <div class="claim-text">presenting information through the rasterized visual display to the operator that assists the operator in controlling the operation of the handheld apparatus; </div>
      <div class="claim-text">providing through the one or more output devices to the operator a presentation of a representation of first content; </div>
      <div class="claim-text">receiving through the one or more input devices from the operator a second content that overlaps in time the presentation of first content according to a temporal relationship controlled by the operator and an identification of one or more recipients; and </div>
      <div class="claim-text">sending through the wireless transmitter a representation of the second content and identification of one or more recipients to a remote server that is separated in space from the handheld apparatus, and causing the remote server to send to the one or more recipients a message representing the first content and the second content arranged according to the temporal relationship. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6640086-B2-CLM-00002" class="claim">
      <div class="claim-text">2. The method of <claim-ref idref="US-6640086-B2-CLM-00001">claim 1</claim-ref> that comprises receiving by wireless communication a first signal that conveys the representation of first content.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6640086-B2-CLM-00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="US-6640086-B2-CLM-00002">claim 2</claim-ref> wherein the first signal conveys a bandwidth-compressed representation of the first content and the method comprises expanding the bandwidth-compressed representation.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6640086-B2-CLM-00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="US-6640086-B2-CLM-00002">claim 2</claim-ref> wherein the first signal conveys an adaptive bandwidth-compressed representation of the first content having a bandwidth requirement that changes in response to characteristics of the representation of second content sent by the handheld apparatus and the method comprises expanding the adaptive bandwidth-compressed representation.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6640086-B2-CLM-00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="US-6640086-B2-CLM-00001">claim 1</claim-ref> wherein the first content comprises music and the second content comprises vocal sounds received from the operator.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6640086-B2-CLM-00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="US-6640086-B2-CLM-00001">claim 1</claim-ref> that comprises presenting sounds to the operator through the one or more output devices in response to actuation of the array of switches, wherein the second content comprises indications of the actuation of the array of switches by the operator.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" id="US-6640086-B2-CLM-00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="US-6640086-B2-CLM-00006">claim 6</claim-ref> that comprises adapting the sound generated in response to the activation of a particular switch within the array of switches according to characteristics of the first content.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" id="US-6640086-B2-CLM-00008" class="claim">
      <div class="claim-text">8. The method of <claim-ref idref="US-6640086-B2-CLM-00006">claim 6</claim-ref> that comprises adaptively enabling and disabling the handheld device to generate Dual Tone Multiple Frequency (DTMF) signals in response to the activation of the array of switches.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" id="US-6640086-B2-CLM-00009" class="claim">
      <div class="claim-text">9. The method of <claim-ref idref="US-6640086-B2-CLM-00001">claim 1</claim-ref> that comprises causing the remote server to add third content to the message, wherein the third content is controlled by the operator.</div>
    </div>
    </div> <div class="claim"> <div num="10" id="US-6640086-B2-CLM-00010" class="claim">
      <div class="claim-text">10. A system for generating a message, wherein the system comprises:</div>
      <div class="claim-text">(a) a handheld apparatus having one or more output devices including a rasterized visual display that present output to an operator, one or more input devices including an array of switches that receive input from the operator, a first wireless transmitter, and processing circuitry that causes the handheld apparatus to: </div>
      <div class="claim-text">(1) present information to the operator through the rasterized visual display that assists the operator in controlling the operation of the handheld apparatus; </div>
      <div class="claim-text">(2) provide to the operator through the one or more output devices a presentation of first content; </div>
      <div class="claim-text">(3) receive from the operator through the one or more input devices one or more signals representing second content that overlaps in time with the presentation of the first content according to a temporal relationship controlled by the operator and an identification of one or more recipients; and </div>
      <div class="claim-text">(4) send through the first wireless transmitter a representation of the second content and identification of one or more recipients; and </div>
      <div class="claim-text">(b) a server subsystem having a wireless receiver, one or more storage devices, and processing circuitry that causes the server subsystem to: </div>
      <div class="claim-text">(1) receive through the wireless receiver and store by the one or more storage devices the representation of second content and identification of the one or more recipients, and </div>
      <div class="claim-text">(2) send to the one or more recipients a message representing the first content and the second content arranged according to the temporal relationship. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" id="US-6640086-B2-CLM-00011" class="claim">
      <div class="claim-text">11. The system of <claim-ref idref="US-6640086-B2-CLM-00010">claim 10</claim-ref> wherein the server subsystem comprises a second wireless transmitter and the processing circuitry in the server subsystem causes the server subsystem to send through the second wireless transmitter to the handheld apparatus a first signal that conveys the representation of first content.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" id="US-6640086-B2-CLM-00012" class="claim">
      <div class="claim-text">12. The system of <claim-ref idref="US-6640086-B2-CLM-00011">claim 11</claim-ref> wherein the first signal conveys a bandwidth-compressed representation of the first content.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" id="US-6640086-B2-CLM-00013" class="claim">
      <div class="claim-text">13. The system of <claim-ref idref="US-6640086-B2-CLM-00011">claim 11</claim-ref> wherein the processing circuitry in the server subsystem causes the server subsystem to change bandwidth requirements of the first signal in response to characteristics of the representation of second content received from the handheld apparatus.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" id="US-6640086-B2-CLM-00014" class="claim">
      <div class="claim-text">14. The system of <claim-ref idref="US-6640086-B2-CLM-00010">claim 10</claim-ref> wherein the first content comprises music and the second content comprises vocal sounds received from the operator.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" id="US-6640086-B2-CLM-00015" class="claim">
      <div class="claim-text">15. The system of <claim-ref idref="US-6640086-B2-CLM-00010">claim 10</claim-ref> wherein the second content comprises indications of actuation of the array of switches by the operator, and the processing circuitry in the handheld device causes the handheld device to present sounds to the operator through the one or more output devices in response to the actuation of the array of switches.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" id="US-6640086-B2-CLM-00016" class="claim">
      <div class="claim-text">16. The system of <claim-ref idref="US-6640086-B2-CLM-00015">claim 15</claim-ref> wherein the processing circuitry in the handheld device causes the handheld device to adapt the sound generated in response to the activation of a particular switch within the array of switches according to characteristics of the first content.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" id="US-6640086-B2-CLM-00017" class="claim">
      <div class="claim-text">17. The system of <claim-ref idref="US-6640086-B2-CLM-00015">claim 15</claim-ref> wherein the processing circuitry in the handheld device enables and disables the handheld device to generate Dual Tone Multiple Frequency (DTMF) signals in response to the activation of the array of switches.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" id="US-6640086-B2-CLM-00018" class="claim">
      <div class="claim-text">18. The system of <claim-ref idref="US-6640086-B2-CLM-00010">claim 10</claim-ref> wherein the processing circuitry in the server subsystem causes the server subsystem to add third content to the message in response to information received from the handheld apparatus.</div>
    </div>
    </div> <div class="claim"> <div num="19" id="US-6640086-B2-CLM-00019" class="claim">
      <div class="claim-text">19. A server system having a wireless receiver, one or more storage devices, and processing circuitry that causes the server system to:</div>
      <div class="claim-text">(a) receive through the wireless receiver one or more signals from a handheld apparatus that are generated under control of an operator of the handheld apparatus, wherein the one or more signals convey </div>
      <div class="claim-text">(i) an identification of first content, </div>
      <div class="claim-text">(ii) second content that overlaps in time with a presentation by the handheld apparatus of the first content, wherein the overlap is according to a temporal relationship that is controlled by the operator, and </div>
      <div class="claim-text">(iii) an identification of one or more recipients; </div>
      <div class="claim-text">(b) obtain information that identifies the temporal relationship; and </div>
      <div class="claim-text">(c) send to the one or more recipients a message that represents the first content and the second content arranged according to the temporal relationship. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" id="US-6640086-B2-CLM-00020" class="claim">
      <div class="claim-text">20. The system of <claim-ref idref="US-6640086-B2-CLM-00019">claim 19</claim-ref> wherein the server system comprises a wireless transmitter and the processing circuitry in the server system causes the server system to send through the wireless transmitter to the handheld apparatus a first signal that conveys the representation of first content.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" id="US-6640086-B2-CLM-00021" class="claim">
      <div class="claim-text">21. The system of <claim-ref idref="US-6640086-B2-CLM-00020">claim 20</claim-ref> wherein the first signal conveys a bandwidth-compressed representation of the first content.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" id="US-6640086-B2-CLM-00022" class="claim">
      <div class="claim-text">22. The system of <claim-ref idref="US-6640086-B2-CLM-00020">claim 20</claim-ref> wherein the processing circuitry in the server system causes the server subsystem to change bandwidth requirements of the first signal in response to characteristics of the representation of second content received from the handheld apparatus.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" id="US-6640086-B2-CLM-00023" class="claim">
      <div class="claim-text">23. The system of <claim-ref idref="US-6640086-B2-CLM-00019">claim 19</claim-ref> wherein the first content comprises music and the second content comprises vocal sounds received from the operator.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" id="US-6640086-B2-CLM-00024" class="claim">
      <div class="claim-text">24. The system of <claim-ref idref="US-6640086-B2-CLM-00019">claim 19</claim-ref> wherein the first content comprises music and the second content represents actuation of an array of switches in the handheld apparatus by the operator.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" id="US-6640086-B2-CLM-00025" class="claim">
      <div class="claim-text">25. The system of <claim-ref idref="US-6640086-B2-CLM-00019">claim 19</claim-ref> wherein the remote server adds third content to the message in response to information received from the handheld apparatus.</div>
    </div>
    </div> <div class="claim"> <div num="26" id="US-6640086-B2-CLM-00026" class="claim">
      <div class="claim-text">26. A medium readable by a machine embodying a program of instructions for execution by one or more machines to perform a method for using a handheld apparatus having one or more output devices including a rasterized visual display that present output to an operator, one or more input devices including an array of switches that receive input from the operator, a wireless transmitter, and processing circuitry that controls operation of the one or more output devices, the one or more input devices and the wireless transmitter, wherein the method comprises steps that perform the acts of:</div>
      <div class="claim-text">presenting information through the rasterized visual display to the operator that assists the operator in controlling the operation of the handheld apparatus; </div>
      <div class="claim-text">providing through the one or more output devices to the operator a presentation of a representation of first content; </div>
      <div class="claim-text">receiving through the one or more input devices from the operator a second content that overlaps in time the presentation of first content according to a temporal relationship controlled by the operator and an identification of one or more recipients; and </div>
      <div class="claim-text">sending through the wireless transmitter a representation of the second content and identification of one or more recipients to a remote server that is separated in space from the handheld apparatus, and causing the remote server to send to the one or more recipients a message representing the first content and the second content arranged according to the temporal relationship. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" id="US-6640086-B2-CLM-00027" class="claim">
      <div class="claim-text">27. The medium of <claim-ref idref="US-6640086-B2-CLM-00026">claim 26</claim-ref> that comprises receiving by wireless communication a first signal that conveys the representation of first content.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" id="US-6640086-B2-CLM-00028" class="claim">
      <div class="claim-text">28. The medium of <claim-ref idref="US-6640086-B2-CLM-00027">claim 27</claim-ref> wherein the first signal conveys a bandwidth-compressed representation of the first content and the method comprises expanding the bandwidth-compressed representation.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" id="US-6640086-B2-CLM-00029" class="claim">
      <div class="claim-text">29. The medium of <claim-ref idref="US-6640086-B2-CLM-00027">claim 27</claim-ref> wherein the first signal conveys an adaptive bandwidth-compressed representation of the first content having a bandwidth requirement that changes in response to characteristics of the representation of second content sent by the handheld apparatus and the method comprises expanding the adaptive bandwidth-compressed representation.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" id="US-6640086-B2-CLM-00030" class="claim">
      <div class="claim-text">30. The medium of <claim-ref idref="US-6640086-B2-CLM-00026">claim 26</claim-ref> wherein the first content comprises music and the second content comprises vocal sounds received from the operator.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" id="US-6640086-B2-CLM-00031" class="claim">
      <div class="claim-text">31. The medium of <claim-ref idref="US-6640086-B2-CLM-00026">claim 26</claim-ref> that comprises presenting sounds to the operator through the one or more output devices in response to actuation of the array of switches, wherein the second content comprises indications of the actuation of the array of switches by the operator.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="32" id="US-6640086-B2-CLM-00032" class="claim">
      <div class="claim-text">32. The medium of <claim-ref idref="US-6640086-B2-CLM-00031">claim 31</claim-ref> that comprises adapting the sound generated in response to the activation of a particular switch within the array of switches according to characteristics of the first content.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" id="US-6640086-B2-CLM-00033" class="claim">
      <div class="claim-text">33. The medium of <claim-ref idref="US-6640086-B2-CLM-00031">claim 31</claim-ref> that comprises adaptively enabling and disabling the handheld device to generate Dual Tone Multiple Frequency (DTMF) signals in response to the activation of the array of switches.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="34" id="US-6640086-B2-CLM-00034" class="claim">
      <div class="claim-text">34. The medium of <claim-ref idref="US-6640086-B2-CLM-00026">claim 26</claim-ref> that comprises causing the remote server to add third content to the message, wherein the third content is controlled by the operator.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES54006292" lang="EN" load-source="patent-office" class="description">
    <heading>TECHNICAL FIELD</heading> <p>The present invention is related to the generation and distribution of messages using computers and networks, and pertains more specifically to methods and systems that allow an operator to distribute messages having aural or visual content that is generated by the operator using handheld apparatuses such as mobile telephones.</p>
    <heading>BACKGROUND ART</heading> <p>The use of mobile apparatuses like cellular telephones, so called Personal Digital Assistants (PDA) and handheld computers is growing at rates that greatly exceed even the most optimistic predictions of only a few years ago. Cellular telephones have been widely accepted because they are inexpensive and allow individuals to move about freely yet stay in contact with friends and sources of entertainment. Other mobile apparatuses like those that play and record music or moving pictures, for example, also have been widely accepted because they provide entertainment and allow individuals to have fun.</p>
    <p>These mobile apparatuses are used throughout the world by individuals of all ages but they are especially popular among individuals that embrace “pop culture” trends and lifestyles. The pop culture appeals to a large segment of the population, especially among youth, and is readily accepted throughout the world.</p>
    <p>Music and moving pictures that are recorded and distributed by professional sources is an important part of the pop culture. There is, however, a growing interest by individuals to create their own aural or visual content and then share it with friends. Unfortunately, creation and distribution of aural and visual content like music and motion pictures has required the use of apparatuses that are not portable or cannot be carried as easily as a cellular telephone. What is needed is the ability to create and distribute aural and/or visual content using mobile apparatuses like cellular telephones.</p>
    <heading>DISCLOSURE OF INVENTION</heading> <p>An object of the present invention is to provide for the creation and distribution of content like music or motion pictures using mobile apparatuses.</p>
    <p>According to one aspect of the present invention, an operator uses a handheld apparatus to receive instructions and a presentation of a representation of first content, provide via the handheld apparatus an identification of one or more recipients and a second content that overlaps in time with the presentation of first content according to a temporal relationship controlled by the operator, send a representation of the second content and identification of recipients to a remote server, and cause the remote server to send to the one or more recipients a message representing the first content and the second content arranged according to the temporal relationship.</p>
    <p>According to another aspect of the present invention, a system includes a handheld apparatus having a wireless transmitter and processing circuitry that causes the handheld apparatus to provide to the operator output representing instructions and a presentation of first content, receive from the operator input representing an identification of one or more recipients and second content that overlaps in time with the presentation of the first content according to a temporal relationship controlled by the operator, and send through the wireless transmitter a representation of the second content and identification of one or more recipients; and includes a server subsystem that receives and stores the representation of second content and identification of the one or more recipients, and sends to the one or more recipients a message representing the first content and the second content arranged according to the temporal relationship.</p>
    <p>According to yet another aspect of the present invention, a server system that receives one or more signals from a handheld apparatus generated under control of an operator of the handheld apparatus that convey an identification of first content, second content that overlaps in time with a presentation by the handheld apparatus of the first content according to a temporal relationship that is controlled by the operator, and an identification of one or more recipients, obtains information that identifies the temporal relationship, and sends to the one or more recipients a message that represents the first content and the second content arranged according to the temporal relationship.</p>
    <p>The various features of the present invention and its preferred implementations may be better understood by referring to the following discussion and the accompanying drawings in which like reference numerals refer to like elements in the several figures. The contents of the following discussion and the drawings are set forth as examples only and should not be understood to represent limitations upon the scope of the present invention.</p>
    <heading>BRIEF DESCRIPTION OF DRAWINGS</heading> <p>FIG. 1 is a schematic block diagram of a system in which the operator of a handheld telephone may interact with a server that is connected to a variety of networks and communication paths.</p>
    <p>FIG. 2 is a schematic block diagram of major components in one hypothetical implementation of a handheld telephone.</p>
    <p>FIG. 3 illustrates a process that allows an individual to create and distribute messages with aural content using an apparatus like a cellular telephone or PDA.</p>
    <p>FIG. 4 illustrates a process that allows an individual to create and distribute messages with aural content using non-concurrent data and voice communication paths.</p>
    <heading>MODES FOR CARRYING OUT THE INVENTION</heading> <heading>A. Overview</heading> <p>FIG. 1 is a schematic illustration of a system in which the operator of mobile apparatus <b>10</b> may interact with server <b>30</b> to generate messages having a combination of original and pre-existing aural and/or visual content and to control the distribution of these messages to one or more recipients such as recipients <b>42</b>, <b>52</b>, <b>62</b>.</p>
    <p>The following discussion refers more particularly to cellular telephones, the public switched telephone network (PSTN), and the internet. These facilities are important examples of how the present invention may be used, but the present invention may be implemented and used with a much wider range of facilities than just these particular examples. A cellular telephone is merely one example of an apparatus that may be used for apparatus <b>10</b>. Other examples of suitable apparatuses include a PDA, a portable computer including handheld computers, and two-way radios. Teachings of the present invention may also be applied to stationary or desktop telephones and stationary or desktop computers. Cellular technology conforming to either existing or anticipated standards is one type of communication technology that may be used with apparatus <b>10</b>. The internet and PSTN are examples of facilities that may be used to provide communication between system components. Essentially any facility or technology may be used including broadcasting, point-to-point and multi-point communication channels that carry ultrasonic, radio, or optical signals through the air or along transmission media such as wires or optical fibers.</p>
    <heading>1. Applications</heading> <p>Two applications of the present invention are referred to herein as SongMail and MusicDIY (do it yourself). SongMail and Music DIY allow an operator of apparatus <b>10</b> to create a message that includes pre-existing content, such as background music, and additional content provided by the operator, and then send that message to one or more recipients in a form that allows the recipients to hear the content. In the SongMail application, the operator provides acoustic content such as vocal utterances. In the MusicDIY application, the operator provides aural content by actuating one or more input devices of apparatus <b>10</b> in a manner that is similar to playing a musical instrument.</p>
    <p>SongMail and MusicDIY are related to aural content; however, the present invention may be used to create messages that contain representations of essentially any content, including visual content, that can be perceived by the recipients. Furthermore, the SongMail and MusicDIY applications themselves can be extended to include visual content, for example. These applications are discussed below in more detail and are presented only as examples of applications that can be provided by the present invention.</p>
    <heading>2. Communication</heading> <p>Referring to FIG. 1, a system that incorporates various features of the present invention includes communication facilities between server <b>30</b> and apparatus <b>10</b>, and between server <b>30</b> and potential recipients such as computer system <b>42</b>, telephone <b>52</b>, and mobile device <b>62</b>. A system may also include communication facilities between server <b>30</b> and the providers of services or content, which are represented by computer system <b>41</b> and telephone <b>51</b>. For example, server <b>30</b> may obtain pre-existing content from computer system <b>41</b> that is not available from its own content database on storage device <b>33</b>.</p>
    <p>Communication facilities between server <b>30</b> and apparatus <b>10</b> are used by the operator of apparatus <b>10</b> to create and send a message to server <b>30</b>, which subsequently sends the message to one or more recipients. Communication facilities between server <b>30</b> and the recipients are used by the server to distribute that message to the recipients. Communication facilities between server <b>30</b> and the providers of services or content such as pre-recorded music or motion pictures are used by server <b>30</b> to obtain those services or content.</p>
    <p>A wide variety of communication technologies, techniques and protocols can be used. No particular communication facilities are critical; however, it is anticipated that the facilities illustrated in FIG. 1 will be commercially important for many implementations of the present invention.</p>
    <heading>3. Server</heading> <p>Server <b>30</b> may be implemented by conventional hardware including processor <b>31</b>, storage device <b>33</b>, and connections to communication facilities like PSTN <b>50</b>, a cellular telephone system, and network <b>40</b>. Network <b>40</b> may be a global network such as the Internet, or it may be a more limited network such as a company intranet.</p>
    <p>An environment that supports various applications discussed below may be provided by an operating system such as those known as Linux, Unix, or various versions of Windows. No particular software environment is essential to practice the present invention. The representation of server <b>30</b> in FIG. 1 suggests one computer system having a single processor <b>31</b>; however, server <b>30</b> may be implemented by one or more computer systems each having single or multiple processors. These systems may be located in close proximity to one another or they may be widely separated. No particular implementation or configuration is critical.</p>
    <p>Server <b>30</b> provides a number of services that are used to implement the SongMail and MusicDIY applications mentioned above. Examples of some services that may be provided by server <b>30</b> in various implementations of the present invention include electronic mail (e-mail), Interactive Voice Response (IVR), Short Message Services (SMS) or Multimedia Messaging Service (MMS), Wireless Access Protocol (WAP) and Hypertext Transfer Protocol (HTTP). These services are examples of presently known services that are likely to be replaced by corresponding future services that will be more advanced. Server <b>30</b>, according to the teachings of the present invention, may provide or work with existing and future versions of these types of services.</p>
    <p>Storage device <b>33</b>, which may include multiple devices, stores operating system and application system software executed by processor <b>31</b> and stores data used by this software. Three examples of data are operator profiles, a content database, and messages generated by an operator. An operator profile may contain data like accounting information and individual preferences that are associated with a particular operator. An example of an operator preference would be an indication of a favorite type of music or recording artist. An operator profile can also include an “address book” of potential recipients. A content database contains pre-existing content that an operator can select to include in a message with the operator's own content. Preferably, the database is arranged to facilitate selection by artist, title, type or style of content, or the basic message or mood that is conveyed by the content.</p>
    <p>Server <b>30</b> may use essentially any form of communication with other components of the system. In the implementation shown in FIG. 1, server <b>30</b> communicates with mobile apparatuses <b>10</b>, <b>62</b> through radio channels <b>60</b>, communicates with telephones <b>51</b>, <b>52</b> through PSTN <b>50</b>, and communicates with computer systems <b>41</b>, <b>42</b> through network <b>40</b>. Signals are sent and received through radio channels <b>60</b> by receiver <b>35</b> and transmitter <b>36</b>, respectively, which are connected to one or more antennas <b>37</b>, and which are connected to processor <b>31</b> by communication facility <b>34</b>. Receiver <b>35</b> and transmitter <b>36</b> may be located in close proximity to processor <b>31</b> or they may be widely separated. In one implementation, communication facility <b>34</b> provides a connection to a cellular telephone system that includes multiple receivers <b>35</b>, multiple transmitters <b>36</b>, and multiple antennas <b>37</b>.</p>
    <p>For ease of discussion, the following description will refer to an implementation in which server <b>30</b> is implemented by a single computer system having one processor <b>31</b> that is connected to one storage device <b>33</b>, to P STN <b>50</b>, to network <b>40</b>, to receiver <b>35</b> and to transmitter <b>36</b>. Many variations in implementation and configuration are possible.</p>
    <heading>4. Handheld Apparatus</heading> <p>The illustration of mobile apparatus <b>10</b> in FIG. 1 suggests a cellular telephone; however, other types of apparatuses may be used as explained above. In the particular example shown, apparatus <b>10</b> has multiple input devices and multiple output devices. The input devices include an array of switches <b>21</b> such as a keypad that may be activated by an operator, and acoustic input transducer <b>22</b> such as a microphone into which the operator may speak or provide other acoustic input. The output devices include an acoustic output transducer <b>23</b> such as a loudspeaker, and a visual display <b>24</b> such as a liquid crystal display (LCD) panel through which visual information may be presented. In another implementation not shown, apparatus <b>10</b> is a PDA that has an array of switches <b>21</b> for input and a visual display <b>24</b> for output, but may not have any acoustic input or output transducers.</p>
    <p>A hypothetical implementation of apparatus <b>10</b> as a cellular telephone is shown schematically in FIG. <b>2</b>. In this implementation, processor <b>12</b> represents circuitry that provides computing resources. Memory <b>13</b> represents circuitry that provides volatile and non-volatile information storage such as random access memory and various types of read only memory. Input/output control <b>18</b> represents an interface to input and output devices like array of switches <b>21</b> (keypad) and acoustic output transducer <b>26</b> (piezoelectric device). Display control <b>17</b> represents an interface to display device <b>24</b> (LCD panel). Codec <b>16</b> represents circuitry that provides encoding and decoding of audio signals received from acoustic input transducer <b>22</b> (microphone) and sent to acoustic output transducer <b>23</b> (loudspeaker). Communication processor <b>14</b> represents an interface to transmitter <b>15</b> and receiver <b>19</b>, which are coupled to antenna <b>25</b>, that send and receive signals through radio channels <b>60</b>. In the example shown in the figure, various components of apparatus <b>10</b> connect to bus <b>11</b>, which may represent more than one physical bus. Other implementations may be realized using an architecture other than a bus architecture.</p>
    <p>In an alternative implementation of a PDA, for example, various components such as codec <b>16</b>, acoustic input transducer <b>22</b> and acoustic output transducer <b>23</b> may be omitted and other components such as communication processor <b>14</b>, transmitter <b>15</b>, receiver <b>19</b> and antenna <b>25</b> may be provided by an apparatus that is external to and distinct from apparatus <b>10</b>. Many variations are possible.</p>
    <p>The functions of one or more of these components can be implemented in a wide variety of ways including discrete logic components, one or more ASICs and/or program-controlled processors. The type of implementation is not critical.</p>
    <p>Several components that may be important in a practical implementation, such as an antenna duplexor and power management circuitry, are not important in principle to the present invention and are omitted from the drawing to improve illustrative clarity.</p>
    <heading>B. Applications</heading> <p>Many details of implementation for the SongMail and MusicDIY applications depend in part on the characteristics of apparatus <b>10</b> and the communication technologies that are used to link apparatus <b>10</b>, server <b>30</b> and the recipients. This section of the description provides a conceptual overview of each application that omits detailed considerations that may be needed for actual implementations. Additional considerations are discussed below in context with a description of various implementation technologies.</p>
    <heading>1. SongMail</heading> <p>An operator may create a SongMail message using a telephone or other apparatus having acoustic input and output transducers. Preferably, the telephone has an array of switches <b>21</b> that can be actuated by pressing a corresponding array of buttons, an acoustic input transducer <b>22</b> such as a microphone, an acoustic output transducer <b>23</b> such as a loudspeaker, and a rasterized visual display device <b>24</b> such as an LCD panel. The operator initiates a SongMail process by, for example, pressing one or more buttons of apparatus <b>10</b>. Apparatus <b>10</b> uses one or more of its output devices to present prompts or other information that guide the operator through the SongMail process, such as by presenting aural information through acoustic output transducer <b>23</b> or, preferably, presenting visual information through display device <b>24</b>. If apparatus <b>10</b> is a typical mobile telephone, for example, visual display device <b>24</b> may provide only a conventional display of telephone numbers entered by the operator to assist the operator in setting up voice communication paths, as discussed below. In response, the operator uses one or more of the input devices of apparatus <b>10</b> to control the creation and distribution of the message. For example, vocal input could be provided through acoustic input transducer <b>22</b> or, preferably, tactile input could be provided by pressing buttons to actuate one or more switches in the array of switches <b>21</b>.</p>
    <heading>a) Setup</heading> <p>The steps in one conceptual implementation of the SongMail process is shown in FIG. <b>3</b>. In step <b>101</b> of this process, the operator initiates the SongMail application in whatever manner is appropriate for the particular implementation. In step <b>102</b>, the operator selects a language for the system to use in providing prompts or other information to guide the operator through the process. In step <b>103</b>, the operator may choose to: (1) create a new message, (2) listen to a previously created message, (3) delete a previously created message, (4) send a previously created message, or (5) quit. In preferred implementations, the options to listen, delete or send messages are not offered if there are no previously created messages. If the operator elects to create a new message, the process continues with step <b>114</b>. If the operator elects to listen to a previously created message, the process continues with step <b>124</b>. If the operator elects to delete a previously created message, the process continues with step <b>134</b>. If the operator elects to send a previously created message, the process continues with step <b>144</b>. If the operator elects to quit, the process continues with step <b>104</b>, which performs the acts needed to stop the process.</p>
    <heading>b) Create</heading> <p>In step <b>114</b>, the operator selects “background music” for his message. In preferred implementations, the operator is able to select the background music by title, artist, type of music, or the message or mood that is conveyed by the music. The system may also present to the operator only some of the content available in a content database that has been filtered and arranged according to operator preferences stored on storage device <b>33</b>.</p>
    <p>The term “background music” is used to refer to pre-existing content provided by the system as opposed to “operator content” that is provided by the operator. This pre-existing content need not be background music but such music is likely to be a popular choice. In one implementation, server <b>30</b> stores pre-existing content in a database on storage device <b>33</b> and sends operator-selected content to apparatus <b>10</b>. In another implementation, the pre-existing content is stored in apparatus <b>10</b>, such as by a removable solid-state memory device.</p>
    <p>In step <b>115</b>, the system presents a rendition of the selected background music through acoustic output transducer <b>23</b>, and receives operator content from the operator through acoustic input transducer <b>22</b>. Step <b>116</b> allows the operator to sing, for example, while listening to the background music. This allows the operator to provide operator content that overlaps in time with the presentation of the background music and to control the temporal relationship of this overlap.</p>
    <p>Steps <b>115</b> and <b>116</b> reiterate until step <b>117</b> determines that the creation of operator content is complete. The process then continues with step <b>103</b>. Alternatively, the method may continue with steps that allow the operator to identify one or more recipients and to send a message with the just-created operator content to those recipients. One way in which a message may be sent is described below. Preferably, if the method proceeds directly to steps that allow the operator to send a message, a step is provided that allows the operator to refrain from sending the message.</p>
    <p>Preferably, server <b>30</b> stores on storage device <b>30</b> a representation of the message that includes the operator content but does not include the background music selected by the operator. Server <b>30</b> stores only an identification of the selected background music and an indication of the temporal relationship between these two contents. The background music itself is stored elsewhere in a content database. When the message is sent to a recipient or to the operator for review, presentations of background music and operator content are combined in a manner that substantially preserves the temporal relationship between these two contents that was observed by the operator when the operator content was provided.</p>
    <p>When certain technologies like cellular telephone systems are used to send the selected background music to apparatus <b>10</b> for presentation to the operator, and to receive the operator content from apparatus <b>10</b>, significant delays in transmission generally occur. Unless these delays can be determined, server <b>10</b> cannot determine the temporal relationship between the operator content and the presentation of the background music and, therefore, cannot preserve this relationship when the message is sent to a recipient. A few ways in which these delays may be determined are discussed in the following paragraphs. In principle, the way in which these delays are determined is not critical to the present invention.</p>
    <p>If the operator is using a communication service like a cellular telephone service and the provider of that service can furnish an estimate of the transmission delays, then the estimated roundtrip delay can be used to estimate the temporal relationship that the operator perceived when the operator content was provided.</p>
    <p>If the service provider cannot furnish an estimate of transmission delays, then server <b>30</b> can measure the delays by sending a signal to apparatus <b>10</b> that causes some recognizable event to be communicated back to server <b>30</b>. If apparatus <b>10</b> includes some feature that automatically responds to certain signals, then server <b>30</b> can measure the delays without requiring operator participation. Otherwise, server <b>30</b> may measure the delays by observing the interval of time between the transmission of an instruction to apparatus <b>10</b> for the operator to take some action, such as pressing a button, and the reception of some indication from apparatus <b>10</b> that the operator took that action.</p>
    <p>If the delays are not known precisely, then server <b>30</b> cannot precisely determine the temporal relationship perceived by the operator, which may prevent the system from exactly preserving this temporal relationship when the message is sent to a recipient or to the operator for review. If server <b>30</b> can determine the delay with a reasonable degree of accuracy, however, then it can substantially preserve the temporal relationship that was observed by the operator when the operator content was provided.</p>
    <heading>c) Listen</heading> <p>In step <b>124</b>, the operator selects a previously created message for review. In step <b>125</b>, apparatus <b>10</b> presents renditions of the operator content and the background music that was selected for that message. The presentation overlaps the rendition of the operator content with the rendition of the selected background music in such a manner that it substantially preserves the temporal relationship observed by the operator when the operator content was initially provided. This presentation continues until step <b>126</b> determines that the presentation has ended or the operator has requested termination of the presentation, such as by pressing a button. The process then continues with step <b>103</b>.</p>
    <heading>d) Delete</heading> <p>In step <b>134</b>, the operator selects a previously created message to delete. In step <b>135</b>, the operator is requested to confirm the deletion. If the deletion is confirmed, the message is deleted in step <b>136</b> and the process continues with step <b>103</b>. If the deletion is not confirmed, the process continues with step <b>103</b>.</p>
    <heading>e) Send</heading> <p>In step <b>144</b>, the operator selects a previously created message to send. In step <b>145</b>, the operator identifies one or more recipients. In a preferred implementation for use with a cellular telephone, the operator is able to press one or more buttons on the telephone to specify a telephone number or to select a recipient from a list of telephone numbers or e-mail addresses that was previously established by the operator and stored by server <b>30</b> in storage device <b>33</b>. In an alternative implementation, the operator is also able to specify an e-mail address by pressing buttons on the telephone according to known techniques to specify alphanumeric characters. Optional step <b>146</b> allows the operator to identify some additional content to be include with the message, such as text or a visual image that introduces the message to the recipient. The process then continues with step <b>103</b>.</p>
    <p>In step <b>147</b>, server <b>30</b> sends a representation of the message to each recipient identified in step <b>145</b> using a delivery method that is appropriate for each recipient. The representation of the message may be delivered using a variety of methods. A “direct” method delivers the aural content of the message directly to the recipient in much the same way that so called voicemail is delivered to a voicemail subscriber. This direct method is suitable for delivery to conventional telephones or other devices that have an acoustic output transducer and little or no processing capabilities. A “notification” method delivers only a notification with instructions for retrieving the message. The notification method is suitable for delivery to essentially any type of apparatus including conventional telephones, but it is especially suitable for delivery to cellular telephones by way of SMS, for example, and to computers by way of e-mail. Vocal notifications could be sent to conventional or cellular telephones. Operators of the recipient devices can retrieve the actual message content by following the instructions included with the notification. Methods of delivery are discussed below in more detail.</p>
    <p>The delivery method may be expressly specified in step <b>145</b> or in some cases it may be possible to infer the correct method from the recipient's identification. For example, it may be possible to infer the notification method from a recipient e-mail address, or from a telephone number of a mobile apparatus.</p>
    <p>Regardless of the delivery method used, when the recipient ultimately receives the message's aural content, the presentation of that message content includes a rendition of operator content with a rendition of the selected background music in such a manner that it substantially preserves the temporal relationship observed by the operator when the operator content was initially provided.</p>
    <p>Additional considerations are discussed below.</p>
    <heading>2. MusicDIY</heading> <p>An operator may create a MusicDIY message using a telephone, PDA or other apparatus having an array of input devices like switches and an acoustic output transducer. Preferably, the apparatus has an array of switches <b>21</b> that can be actuated by pressing a corresponding array of buttons, an acoustic output transducer <b>23</b> such as a loudspeaker, and a rasterized visual display device <b>24</b> such as an LCD panel. The operator initiates a MusicDIY process by, for example, pressing one or more buttons of apparatus <b>10</b>. Apparatus <b>10</b> uses one or more of its output devices to present prompts or other information that guide the operator through the MusicDIY process, such as by presenting visual information through display device <b>24</b>. If apparatus <b>10</b> is a typical mobile telephone, for example, visual display device <b>24</b> may provide only a conventional display of telephone numbers entered by the operator to assist the operator in setting up voice communication paths, as discussed below. In response, the operator uses one or more of the input devices of apparatus <b>10</b> to control the creation and distribution of the message. Preferably, tactile input is provided by pressing buttons to actuate one or more switches in the array of switches <b>21</b>.</p>
    <p>The method shown in FIG. <b>3</b> and discussed above in connection with SongMail can also be used to explain one conceptual implementation of the MusicDIY process. The description of each step given above for SongMail applies in a corresponding manner to MusicDIY and nothing more need be said except to discuss differences in step <b>115</b>.</p>
    <p>In step <b>115</b>, the system presents a rendition of the selected background music through an acoustic output transducer just as is done for SongMail; however, for MusicDIY the operator does not provide aural content directly through an acoustic input transducer but instead indirectly provides aural content by actuating one or switches in the array of switches <b>21</b> in a manner that is similar to playing a musical instrument. Apparatus <b>10</b> generates a sound in response to the activation of a switch and presents that sound to the operator through acoustic output transducer <b>23</b>. This allows the operator to hear the music that is created with apparatus <b>10</b> and to control the temporal relationship between the presentation of the background music and the music created by the operator.</p>
    <p>Apparatus <b>10</b> may generate a fixed note or sound in response to the activation of a particular switch like that done by conventional musical instruments; however, in a preferred implementation, apparatus <b>10</b> changes the sound that is generated in response to the activation of a particular switch. Preferably, the sound is changed according to characteristics of the background music so that the activation of any switch in the array of switches causes apparatus <b>10</b> to generate a sound that obeys a desired musical rule. In other words, the array of switches are adaptively mapped to sounds so that the overall effect of the operator content combined with the background music will be pleasant regardless which switch is activated. In one implementation, control information is provided with the background music that indicates how and when switch-to-sound mappings are changed. This is discussed in more detail below.</p>
    <heading>C. Communication Facilities</heading> <p>The process shown in FIG. <b>3</b> and discussed above omits some considerations that are pertinent to implementations using various communication technologies. Some of these considerations are discussed below.</p>
    <heading>1. Server-Operator Communications</heading> <p>Although no particular communication facility for apparatus <b>10</b> is critical in principle to the present invention, it is anticipated that communication via cellular telephone systems will be commercially important to many applications. Techniques that can be used with several types of cellular telephone systems are discussed below. It will be apparent that many of these techniques can be used in a wide variety of combinations.</p>
    <heading>a) Sequential use of Data and Voice Communication Facilities</heading> <p>A first technique may be used with one or more communication systems that provide data and voice communication facilities. According to the first technique, the operator sets up an application using a data communication facility, then stops using the data communication facility and uses a voice communication facility to create message content. This first technique may be used with cellular telephone systems, for example, that do not provide concurrent access to data and voice communication facilities.</p>
    <p>One way in which the first technique may be implemented is shown in FIG. <b>4</b>. In step <b>201</b>, an application “session” is established by initiating a data communication path if one is not already available and using this path to convey operator choices like the desired application (such as SongMail or MusicDIY), language, and background music. In an alternative implementation, step <b>201</b> also allows the operator to specify one or more recipients for the message that is soon to be created.</p>
    <p>In step <b>202</b>, use of the data communication path is terminated. Server <b>30</b> stores information on storage device <b>33</b> for the session that preserves any selections or other data provided by the operator during application setup. This information will be used to perform the remainder of the application session.</p>
    <p>In step <b>203</b>, the session continues by initiating a voice communication path if one is not already available. Several examples of how this may be done are described below.</p>
    <p>In a first example, prior to terminating use of the data communication path, server <b>30</b> sends information to apparatus <b>10</b> that includes a code identifying the session and specifying a telephone number for the operator to call. For example, if it is available, SMS may be used to send this information. The voice communication path is established when the operator calls this telephone number. In response to receiving the telephone call, server <b>30</b> asks the operator to enter a session code, perhaps by pressing buttons on the telephone. Alternatively, apparatus <b>10</b> stores information that identifies the session and automatically identifies the session by sending audible signals such as DTMF tones to server <b>30</b>. In either case, server <b>30</b> can obtain the session code from the voice communication channel using IVR, for example. When server <b>30</b> receives a valid session code, it continues the application session using the voice communication path.</p>
    <p>In a second example, prior to terminating use of the data communication path, server <b>30</b> obtains a telephone number to use for calling the operator. This number may be obtained directly from the operator or from profile information stored on storage device <b>33</b> for this operator. Server <b>30</b> may ask the operator to confirm this number. The voice communication path is established when server <b>30</b> reaches the operator using this telephone number. Server <b>30</b> may then ask the operator to enter some code to confirm his or her identity, or to identify a particular session in a manner similar to that described above. When server <b>30</b> successfully contacts the operator, it continues the application session using the voice communication path.</p>
    <p>In a third example, an application executing in apparatus <b>10</b> utilizes services such as those provided through the Wireless Telephony Application Interface (WTAI) to call server <b>30</b>, establish the voice communication path, and identify the session by sending audible signals such as DTMF tones using a protocol such as WAP.</p>
    <p>In a fourth example, prior to terminating use of the data communication path, apparatus <b>10</b> sends information to server <b>30</b> that includes a user identifier. In response to receiving the telephone call that initiates the voice communication path, server <b>30</b> automatically determines the user identifier and identifies the session. For example, if apparatus <b>10</b> is associated with a telephone number, apparatus <b>10</b> may send its associated telephone number to server <b>30</b>, which is stored with other information pertaining to a session. Server <b>30</b> may determine the user identifier automatically by using features of the telephone system such as “caller ID” or automatic number identification (ANI).</p>
    <p>In step <b>204</b>, server <b>30</b> can provide prompts or instructions as desired and it may either automatically begin a presentation of the background music or wait until the operator gives a start command, such as by pressing a button on the telephone.</p>
    <p>In step <b>205</b>, server <b>30</b> receives operator content and stores it on storage device <b>33</b>.</p>
    <p>Steps <b>204</b> and <b>205</b> reiterate to continue presentation of the background music and reception of the operator content until step <b>206</b> determines that the creation process is complete. For example, this may be determined by detecting an interval of no operator input that exceeds some threshold amount of time, by receiving a particular command from the operator such as by pressing a particular button on the telephone, or when the presentation of background music has ended.</p>
    <p>The remainder of the application process in step <b>207</b> may be implemented in a variety of ways. In one implementation, step <b>207</b> sends the created message to the recipients identified during application setup. In another implementation, step <b>207</b> allows the operator to listen to the message and perform other functions in a manner similar to that described below for the technique using only voice communications.</p>
    <p>In yet another implementation, step <b>207</b> terminates usage of the voice communication path and continues the application session by initiating use of a data communication path. The operator may then send the message in a manner similar to that described below for the technique that uses concurrent data and voice communication facilities.</p>
    <p>In an alternative implementation of the first technique, steps <b>202</b> and <b>203</b> are carried out in a different way. In step <b>202</b>, information representing operator choices and selections is stored within apparatus <b>10</b> rather than by server <b>30</b>. In step <b>203</b>, an application executing in apparatus <b>10</b> utilizes services such as those provided through WTAI to call server <b>30</b>, establish the voice communication path, and identify operator choices and selections by sending audible signals such as DTMF tones using a protocol such as WAP.</p>
    <heading>b) Use of Only Voice Communication Facilities</heading> <p>A second technique may be used with any communication system that provides voice communication facilities. According to the second technique, the operator sets up an application and creates message content using only voice communication facilities.</p>
    <p>One way in which the second technique may be implemented is shown in FIG. <b>3</b>. In step <b>101</b>, a voice communication path is established if one is not already available. The remainder of the steps are performed by allowing the operator to make selections and enter commands through the voice communication path. This may be done, for example, by vocal utterances or by pressing buttons on the telephone. Server <b>30</b> may use speech recognition software to interpret vocal utterances. A convenient implementation uses the conventional dual-tone multiple-frequency (DTMF) signals to represent operator selections and commands. Alphanumeric characters may be entered via the buttons by using known techniques.</p>
    <p>If speech recognition is used, this feature should either be suppressed or carefully controlled while the operator is providing operator content for the SongMail application. This may be done, for example, by limiting speech recognition to a limited number of reserved words that are unlikely to be uttered by the operator as operator content. Preferably, speech recognition is suppressed during this phase of the process and only DTMF signals are recognized as commands.</p>
    <p>If DTMF recognition is used, this feature should either be suppressed or carefully controlled while the operator is providing operator content for the MusicDIY application. Preferably, if apparatus <b>10</b> permits it, all DTMF generation is suppressed during the creation phase of MusicDIY; however, one button such as the hash (#) button or star (*) button may be reserved to represent a command for stopping the creation phase. Alternatively, all buttons may be made available for input of operator content and speech recognition is made available to recognize a command to stop this phase.</p>
    <heading>c) Concurrent use of Data and Voice Communication Facilities</heading> <p>A third technique may be used with any communication system that provides concurrent access to data and voice communication facilities. According to the third technique, the operator sets up the use of an application using a data communication facility and then creates message content using a voice communication facility without interrupting use of the data communication facility.</p>
    <p>One way in which the third technique may be implemented is also shown in FIG. <b>3</b>. In step <b>101</b>, data and voice communication paths are established as necessary if either is not already available. The remainder of the steps are performed by allowing the operator to make selections and enter commands through the data communication path, and by receiving background music through the voice communication path.</p>
    <heading>d) Use of Only Data Communication Facilities</heading> <p>A fourth technique uses features such as “voice over IP” that permit sending operator content through a data communication path. This allows both application setup and message creation to be performed using the data communication path.</p>
    <p>One way in which the fourth technique may be implemented is shown in FIG. <b>3</b>. In step <b>101</b>, a data communication path is established if it is not already available. The remainder of the steps are performed by allowing the operator to make selections, enter commands, receive background music, and provide operator content through the data communication path.</p>
    <heading>2. Server-Recipient Communications</heading> <p>Although server <b>30</b> can deliver message content directly to a recipient, it is anticipated that preferred implementations will deliver only a notification of the message instead, which includes instructions for retrieving the message and could also include a an introduction or explanation from the operator who created it. This may be done in a variety of ways. No particular way is critical to the present invention.</p>
    <p>One way to send a notification is by using a messaging service of the telephone system, such as SMS or MMS. The content of SMS messages, for example, are limited in length and can only be text; however, apparatus <b>10</b> may allow a user to mark text in the message, such as a telephone number, and use that marked text to make a telephone call. Other text, such as a message code or session code, could be marked and sent to server <b>30</b> to identify the message to retrieve. These features reduce the effort required to retrieve the message.</p>
    <p>Another way to send a notification is by e-mail, which provides more capabilities than SMS. An e-mail message could include a Uniform Resource Locator (URL) link to a file on network <b>40</b> that contains the message to retrieve. Using a conventional browser or various e-mail software, the recipient could retrieve the message by merely using a pointing device, such as mouse, to click on the URL link. The e-mail message could also include additional content such as a graphical image that was selected by the operator who created the message.</p>
    <p>Yet another way to send notification is by aural information. Using speech synthesis software, for example, server <b>30</b> could generate a notification that could be sent by telephone to a recipient, or could be directly stored in a recipient's voice mailbox. In one implementation, this notification could include a telephone number to call and a code that identifies the message to retrieve. In another implementation, the notification explains to the recipient that the operator, identified by name, has created a message and then asks if the recipient wishes to receive it. If the recipient affirms delivery, server <b>30</b> then delivers the message through the telephone. Server <b>30</b> may also be implemented to allow the recipient to reply to the operator with a voice message, or to forward the message to others.</p>
    <p>The message itself may be stored or conveyed in essentially any format that is capable of representing the content.</p>
    <heading>D. Additional Features</heading> <p>In a preferred implementation of the MusicDIY application, apparatus <b>10</b> is adapted in synchronism with the background music so that the activation of any switch in the array of switches causes apparatus <b>10</b> to generate a sound that obeys a desired musical rule. This feature can be used so that the overall effect of the operator content combined with the background music will be pleasant regardless which switch is activated.</p>
    <p>Apparatus <b>10</b> is adapted by changing a mapping that associates a respective switch in the array of switches with a particular sound or note. One or more mapping relationships, referred to herein as maps, can be stored a priori in apparatus <b>10</b> or they can be obtained from information that is sent with the background music.</p>
    <heading>1. Synchronization</heading> <p>The map that is in effect at a particular time is modified or selected from a set of maps as the background music is presented to the operator. An identification of the map to use and the time at which this map should be used is specified by control information that is received during or prior to the time the background music is received and presented to the operator. Generally, the mapping will be adapted at times that coincide with key changes or chord changes in the background music.</p>
    <p>If the control information is received prior to presentation, it should specify the map to use and when to use it. It may specify the desired map and the corresponding time by associating a map identifier with a time within the background music such as an offset relative to the start of the music. For example, control information specifying 7 @ 37.2 could indicate apparatus <b>10</b> should begin using the seventh map from a previously stored set of maps at a point in time 37.2 seconds after the start of the background music.</p>
    <p>If the control music is received during the presentation of the background music, it may identify only the map to be used because the time is implied by the time when the control information is received.</p>
    <heading>2. Mapping</heading> <p>In preferred implementations, the maps are essentially pre-determined scale structures determined according to standard music theory and based on one of five jazz/pop musical chords: Major, Dominant 7th, Minor (Dorian), Half diminished (Locrian), and Diminished.</p>
    <p>A chord represents a series of tones called a scale. The scales of other chords can be ordered according to their “sound” or level of consonance or dissonance relative to the basic tones of a particular chord. It is not uncommon to have five or more scales that are relatively consonant with any particular chord.</p>
    <p>The following table shows two examples of a particular chord (referred to herein as a “base chord”) and another chord that is consonant with the base chord. The base chord is shown in the first column, which represents a chord that occurs in background music. The notes of the base chord are shown in the second column. Another chord that is consonant with the base chord is shown in the third column. In both examples, the consonant chord is chosen to be identical to the base chord. The notes in the scale of the consonant chord are shown in the fourth column.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="1" colwidth="56pt" align="left"> </colspec> <colspec colname="2" colwidth="42pt" align="left"> </colspec> <colspec colname="3" colwidth="56pt" align="left"> </colspec> <colspec colname="4" colwidth="63pt" align="left"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Base Chord</td>
                <td class="description-td"> </td>
                <td class="description-td">Consonant Scale</td>
              </tr> <tr class="description-tr"> <td class="description-td">Base Chord</td>
                <td class="description-td">Notes</td>
                <td class="description-td">Consonant Scale</td>
                <td class="description-td">Notes</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">C Major</td>
                <td class="description-td">C E G B D</td>
                <td class="description-td">Major</td>
                <td class="description-td">C D E F G A B C</td>
              </tr> <tr class="description-tr"> <td class="description-td">C Dominant 7th</td>
                <td class="description-td">C E G Bb D</td>
                <td class="description-td">Dominant 7th</td>
                <td class="description-td">C D E F G A Bb C</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>Assuming apparatus <b>10</b> is a mobile telephone with a conventional 12-key pad (with buttons that are labeled 1-9, *, 0, #), the two consonant chords can be mapped to the keypad as follows:</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="offset" colwidth="21pt" align="left"> </colspec> <colspec colname="1" colwidth="70pt" align="center"> </colspec> <colspec colname="2" colwidth="126pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">C Major</td>
                <td class="description-td">C Dominant 7th</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="2" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="7"> <colspec colname="offset" colwidth="21pt" align="left"> </colspec> <colspec colname="1" colwidth="14pt" align="center"> </colspec> <colspec colname="2" colwidth="42pt" align="center"> </colspec> <colspec colname="3" colwidth="14pt" align="center"> </colspec> <colspec colname="4" colwidth="56pt" align="center"> </colspec> <colspec colname="5" colwidth="14pt" align="center"> </colspec> <colspec colname="6" colwidth="56pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">C</td>
                <td class="description-td">D</td>
                <td class="description-td">E</td>
                <td class="description-td">C</td>
                <td class="description-td">D</td>
                <td class="description-td">E</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">F</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
                <td class="description-td">F</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">B</td>
                <td class="description-td">C</td>
                <td class="description-td">D</td>
                <td class="description-td">Bb</td>
                <td class="description-td">C</td>
                <td class="description-td">D</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">E</td>
                <td class="description-td">F</td>
                <td class="description-td">G</td>
                <td class="description-td">E</td>
                <td class="description-td">F</td>
                <td class="description-td">G</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="6" align="center" rowsep="1" class="description-td" colspan="7"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>Each time the base chord changes in the background music, the mapping should also change so that no key can create a dissonant sound or “wrong” note.</p>
    <p>For example, suppose the first four chords of the background music are F Major, E Minor 7th (Em7), A 7th, and D Minor 7th (Dm7). Suppose further that the chosen consonant scale for each base chord is the scale of the base chord itself. The keys for these four chords could be mapped as follows:</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="1" colwidth="56pt" align="center"> </colspec> <colspec colname="2" colwidth="56pt" align="center"> </colspec> <colspec colname="3" colwidth="56pt" align="center"> </colspec> <colspec colname="4" colwidth="49pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">F</td>
                <td class="description-td">Em7</td>
                <td class="description-td">A7</td>
                <td class="description-td">Dm7</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="12"> <colspec colname="1" colwidth="21pt" align="center"> </colspec> <colspec colname="2" colwidth="14pt" align="center"> </colspec> <colspec colname="3" colwidth="21pt" align="center"> </colspec> <colspec colname="4" colwidth="21pt" align="center"> </colspec> <colspec colname="5" colwidth="14pt" align="center"> </colspec> <colspec colname="6" colwidth="21pt" align="center"> </colspec> <colspec colname="7" colwidth="21pt" align="center"> </colspec> <colspec colname="8" colwidth="14pt" align="center"> </colspec> <colspec colname="9" colwidth="21pt" align="center"> </colspec> <colspec colname="10" colwidth="21pt" align="center"> </colspec> <colspec colname="11" colwidth="14pt" align="center"> </colspec> <colspec colname="12" colwidth="14pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">F</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
                <td class="description-td">E</td>
                <td class="description-td">F#</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
                <td class="description-td">B</td>
                <td class="description-td">C#</td>
                <td class="description-td">D</td>
                <td class="description-td">E</td>
                <td class="description-td">F</td>
              </tr> <tr class="description-tr"> <td class="description-td">Bb</td>
                <td class="description-td">C</td>
                <td class="description-td">D</td>
                <td class="description-td">A</td>
                <td class="description-td">B</td>
                <td class="description-td">C#</td>
                <td class="description-td">D</td>
                <td class="description-td">E</td>
                <td class="description-td">F#</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
                <td class="description-td">B</td>
              </tr> <tr class="description-tr"> <td class="description-td">E</td>
                <td class="description-td">F</td>
                <td class="description-td">G</td>
                <td class="description-td">D</td>
                <td class="description-td">E</td>
                <td class="description-td">F#</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
                <td class="description-td">B</td>
                <td class="description-td">C</td>
                <td class="description-td">D</td>
                <td class="description-td">E</td>
              </tr> <tr class="description-tr"> <td class="description-td">A</td>
                <td class="description-td">Bb</td>
                <td class="description-td">C</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
                <td class="description-td">B</td>
                <td class="description-td">C#</td>
                <td class="description-td">D</td>
                <td class="description-td">E</td>
                <td class="description-td">F</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="12" align="center" rowsep="1" class="description-td" colspan="12"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>If the maps are changed in this manner as the operator presses only the “1 ” key, a sequence of notes F/E/A/D would be generated.</p>
    <p>Unfortunately, skilled musicians do not work with scales in this manner. Instead, a musician would select the most appropriate series of notes as chords in the background music change according to the chord/scale relationship, rhythmic figures, and note placements. A simple mapping of keys according to chord structure as described above is not enough to give a musically-unskilled operator a comparable performing experience.</p>
    <p>The performing experience can be greatly enhanced by controlling the logical flow from map to map. Two different mapping relationships may be used in combination to achieve this. The first mapping relationship is the chord/scale mapping relationship described above. This mapping is pre-established by a musician. A particular relationship can be chosen by the musician according to what the musician believes is the best fit for a particular song. Alternatively, the musician can establish several relationships according to different musical styles; i.e., jazz, blues, folk, pop, and the operator given the opportunity to select the desired style. This establishes the first chord/scale mapping relationship.</p>
    <p>The second mapping relationship controls the flow of change between different maps. This second flow relationship can also be established by a musician, or it can be automated and provided by server <b>30</b> or by apparatus <b>10</b>.</p>
    <p>Using the example shown above, the chord/scale maps are established for the four chords as explained above. The flow of change between these maps is controlled by adapting the note of each scale that is assigned to the “1” key. The note that is assigned to the “1 ” key for a particular map is the same note, within one-half musical step, that is assigned to the “1” key for the preceding map. This provides the following sequence of maps:</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="4"> <colspec colname="1" colwidth="56pt" align="center"> </colspec> <colspec colname="2" colwidth="56pt" align="center"> </colspec> <colspec colname="3" colwidth="56pt" align="center"> </colspec> <colspec colname="4" colwidth="49pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">F</td>
                <td class="description-td">Em7</td>
                <td class="description-td">A7</td>
                <td class="description-td">Dm7</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="4" align="center" rowsep="1" class="description-td" colspan="4"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="12"> <colspec colname="1" colwidth="21pt" align="center"> </colspec> <colspec colname="2" colwidth="14pt" align="center"> </colspec> <colspec colname="3" colwidth="21pt" align="center"> </colspec> <colspec colname="4" colwidth="21pt" align="center"> </colspec> <colspec colname="5" colwidth="14pt" align="center"> </colspec> <colspec colname="6" colwidth="21pt" align="center"> </colspec> <colspec colname="7" colwidth="21pt" align="center"> </colspec> <colspec colname="8" colwidth="14pt" align="center"> </colspec> <colspec colname="9" colwidth="21pt" align="center"> </colspec> <colspec colname="10" colwidth="21pt" align="center"> </colspec> <colspec colname="11" colwidth="14pt" align="center"> </colspec> <colspec colname="12" colwidth="14pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">F</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
                <td class="description-td">F#</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
                <td class="description-td">F#</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
                <td class="description-td">F</td>
                <td class="description-td">G</td>
                <td class="description-td">A</td>
              </tr> <tr class="description-tr"> <td class="description-td">Bb</td>
                <td class="description-td">C</td>
                <td class="description-td">D</td>
                <td class="description-td">B</td>
                <td class="description-td">C#</td>
                <td class="description-td">D</td>
                <td class="description-td">B</td>
                <td class="description-td">C#</td>
                <td class="description-td">D</td>
                <td class="description-td">B</td>
                <td class="description-td">C</td>
                <td class="description-td">D</td>
              </tr> <tr class="description-tr"> <td class="description-td">E</td>
                <td class="description-td">F</td>
                <td class="description-td">G</td>
                <td class="description-td">E</td>
                <td class="description-td">F#</td>
                <td class="description-td">G</td>
                <td class="description-td">E</td>
                <td class="description-td">F#</td>
                <td class="description-td">G</td>
                <td class="description-td">E</td>
                <td class="description-td">F</td>
                <td class="description-td">G</td>
              </tr> <tr class="description-tr"> <td class="description-td">A</td>
                <td class="description-td">Bb</td>
                <td class="description-td">C</td>
                <td class="description-td">A</td>
                <td class="description-td">B</td>
                <td class="description-td">C#</td>
                <td class="description-td">A</td>
                <td class="description-td">B</td>
                <td class="description-td">C#</td>
                <td class="description-td">A</td>
                <td class="description-td">B</td>
                <td class="description-td">C</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="12" align="center" rowsep="1" class="description-td" colspan="12"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>If the maps are changed in this manner as the operator presses only the “1 ” key, a sequence of notes F/F#/F#/F would be generated. By pressing the “4” key, the operator would create a sequence of notes Bb/B/B/B.</p>
    <p>By controlling the flow of mapping changes, the operator can better anticipate the note that will be generated by pressing a particular key and will create music that corresponds more naturally to the progression of keys that are pressed.</p>
    <p>Alternative relationships can be used to control the flow of change between maps. For example, the third, fifth or seventh note of a chord can be assigned to the “1 ” key for a particular map, and the same note is assigned to the “1” key for succeeding maps within one-half musical step. The operator may also be allowed to choose the mapping flow relationship. For example, if the mapping flow relationship aligns succeeding maps on the fifth key, the maps for the four chords shown above would map the “1” key to the notes C, C#, C# and C.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5588842">US5588842</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 5, 1995</td><td class="patent-data-table-td patent-date-value">Dec 31, 1996</td><td class="patent-data-table-td ">Brother Kogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">Karaoke control system for a plurality of karaoke devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5613192">US5613192</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 1, 1995</td><td class="patent-data-table-td patent-date-value">Mar 18, 1997</td><td class="patent-data-table-td ">Brother Kogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">One-way data transmission device with two-way data transmission function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6083009">US6083009</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 16, 1998</td><td class="patent-data-table-td patent-date-value">Jul 4, 2000</td><td class="patent-data-table-td ">Shinsegi Telecomm Inc</td><td class="patent-data-table-td ">Karaoke service method and system by telecommunication system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6331669">US6331669</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 19, 2000</td><td class="patent-data-table-td patent-date-value">Dec 18, 2001</td><td class="patent-data-table-td ">Shi-Cse Lee</td><td class="patent-data-table-td ">Broadband communication karaoke</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020188447">US20020188447</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 10, 2001</td><td class="patent-data-table-td patent-date-value">Dec 12, 2002</td><td class="patent-data-table-td ">Coon Bradley S.</td><td class="patent-data-table-td ">Generation of grammars from dynamic data structures</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030013483">US20030013483</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 6, 2001</td><td class="patent-data-table-td patent-date-value">Jan 16, 2003</td><td class="patent-data-table-td ">Ausems Michiel R.</td><td class="patent-data-table-td ">User interface for handheld communication device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=B6hiBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2001211485A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHZM8v-6Bl-Gmdq4rEuso9D5kuJIQ">JP2001211485A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=B6hiBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2001339487A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNG1K2vulytPl1FLy0rsDDsbYRI3zg">JP2001339487A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1999012153A1?cl=en">WO1999012153A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 28, 1998</td><td class="patent-data-table-td patent-date-value">Mar 11, 1999</td><td class="patent-data-table-td ">Bj Corp</td><td class="patent-data-table-td ">Portable caption display system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2001093261A1?cl=en">WO2001093261A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 1, 2001</td><td class="patent-data-table-td patent-date-value">Dec 6, 2001</td><td class="patent-data-table-td ">Hanseulsoft Co Ltd</td><td class="patent-data-table-td ">Apparatus and method for providing song accompanying/music playing service using wireless terminal</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Song-Yi Yi; Heonshik Shin "<a href='http://scholar.google.com/scholar?q="Design+of+a+real-time+trader+for+mobile+objects+in+open+distributed+environments"'>Design of a real-time trader for mobile objects in open distributed environments</a>" Real-Time Systems, 1996., Proceedings of the Eighth Euromicro Workshop on, Jun. 1996, pp. 212-217.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7286502">US7286502</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 17, 2000</td><td class="patent-data-table-td patent-date-value">Oct 23, 2007</td><td class="patent-data-table-td ">Rao Raman K</td><td class="patent-data-table-td ">Method and system to interface internet protocol (IP) based wireless devices and wireless networks with optical and other networks for improved flexibility, performance and data transfer rates</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7567525">US7567525</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 9, 2004</td><td class="patent-data-table-td patent-date-value">Jul 28, 2009</td><td class="patent-data-table-td ">Far Eastone Telecommunications Co., Ltd.</td><td class="patent-data-table-td ">Interactive two-way transfer multimedia messaging service method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7761901">US7761901</a></td><td class="patent-data-table-td patent-date-value">Mar 8, 2004</td><td class="patent-data-table-td patent-date-value">Jul 20, 2010</td><td class="patent-data-table-td ">British Telecommunications Plc</td><td class="patent-data-table-td ">Data transmission</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7970618">US7970618</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 31, 2005</td><td class="patent-data-table-td patent-date-value">Jun 28, 2011</td><td class="patent-data-table-td ">Kddi Corporation</td><td class="patent-data-table-td ">Content distribution server for distributing content frame for reproducing music and terminal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7974200">US7974200</a></td><td class="patent-data-table-td patent-date-value">Nov 28, 2001</td><td class="patent-data-table-td patent-date-value">Jul 5, 2011</td><td class="patent-data-table-td ">British Telecommunications Public Limited Company</td><td class="patent-data-table-td ">Transmitting and receiving real-time data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8010088">US8010088</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 5, 2008</td><td class="patent-data-table-td patent-date-value">Aug 30, 2011</td><td class="patent-data-table-td ">Chi Mei Communication Systems, Inc.</td><td class="patent-data-table-td ">System and method for using a mobile phone as a wireless microphone</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8135852">US8135852</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 2003</td><td class="patent-data-table-td patent-date-value">Mar 13, 2012</td><td class="patent-data-table-td ">British Telecommunications Public Limited Company</td><td class="patent-data-table-td ">Data streaming system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8194828">US8194828</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 15, 2008</td><td class="patent-data-table-td patent-date-value">Jun 5, 2012</td><td class="patent-data-table-td ">Pinger, Inc.</td><td class="patent-data-table-td ">Providing voice messages to an intended recipient</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8255693">US8255693</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 22, 2009</td><td class="patent-data-table-td patent-date-value">Aug 28, 2012</td><td class="patent-data-table-td ">Digimarc Corporation</td><td class="patent-data-table-td ">Methods and devices responsive to ambient audio</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8386631">US8386631</a></td><td class="patent-data-table-td patent-date-value">Aug 29, 2008</td><td class="patent-data-table-td patent-date-value">Feb 26, 2013</td><td class="patent-data-table-td ">British Telecommunications Plc</td><td class="patent-data-table-td ">Data streaming system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090117880">US20090117880</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 15, 2008</td><td class="patent-data-table-td patent-date-value">May 7, 2009</td><td class="patent-data-table-td ">Pinger, Inc.</td><td class="patent-data-table-td ">Providing Voice Messages To An Intended Recipient</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100138012">US20100138012</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 22, 2009</td><td class="patent-data-table-td patent-date-value">Jun 3, 2010</td><td class="patent-data-table-td ">Rhoads Geoffrey B</td><td class="patent-data-table-td ">Methods and Devices Responsive to Ambient Audio</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc455/defs455.htm&usg=AFQjCNFL3EGhrZhenbDalCuSOJ_Q_FR4Vw#C455S003040">455/3.04</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc455/defs455.htm&usg=AFQjCNFL3EGhrZhenbDalCuSOJ_Q_FR4Vw#C455S566000">455/566</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc455/defs455.htm&usg=AFQjCNFL3EGhrZhenbDalCuSOJ_Q_FR4Vw#C455S556100">455/556.1</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc455/defs455.htm&usg=AFQjCNFL3EGhrZhenbDalCuSOJ_Q_FR4Vw#C455S466000">455/466</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S014010">348/14.01</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S014020">348/14.02</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04M0011000000">H04M11/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10K0015020000">G10K15/02</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04M0001000000">H04M1/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L12/5855">H04L12/5855</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L12/5895">H04L12/5895</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L51/14">H04L51/14</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=B6hiBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04W4/12">H04W4/12</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04L51/14</span>, <span class="nested-value">H04L12/58G</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jan 7, 2014</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1-7, 9-16, 18-32 AND 34 ARE CANCELLED.CLAIMS 8, 17 AND 33 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 4, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 15, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110111</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 2, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20091203</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 23, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20091201</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 19, 2009</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">WALL WIRELESS LLC, TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:WALL, CORBERT;REEL/FRAME:022127/0908</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20090105</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:WALL, CORBETT;REEL/FRAME:022127/0908</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 27, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_4ff636b3d23669b7103f3b3a3a18b4cd.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0jjy9YQvphiE4Y-z-XbfD8YOVczQ\u0026id=B6hiBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0lQ6FRfYwAxehsYA846A3L5hD9aQ\u0026id=B6hiBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1Z63ppy_UnkFACQ5s9Pey2YtXT4A","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_and_apparatus_for_creating_and_di.pdf?id=B6hiBAABERAJ\u0026output=pdf\u0026sig=ACfU3U2NacdiPf0Y3iqA1AaQhrmUBeXjFw"},"sample_url":"http://www.google.com/patents/reader?id=B6hiBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>