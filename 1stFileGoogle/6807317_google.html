<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6807317 - Method and decoder system for reducing quantization effects of a decoded image - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method and decoder system for reducing quantization effects of a decoded image"><meta name="DC.contributor" content="Reji Mathew" scheme="inventor"><meta name="DC.contributor" content="Jian Zhang" scheme="inventor"><meta name="DC.contributor" content="Motorola, Inc." scheme="assignee"><meta name="DC.date" content="2002-10-25" scheme="dateSubmitted"><meta name="DC.description" content="A method (200) and decoder system (100) for reducing quantization effects or ringing artifacts imposed upon decoded image of hybrid block based coding schemes such as MEPG and H 261. The system (100), in use, and method (200) receive (220) decoded image decoded blocks that were decoded from transform coded blocks quatized by a selected quantization parameter. The system (100) and method (200) then analyze (230) selected pixel values of selected pixels with neighboring pixel values of associated neighboring pixels in the decoded blocks to determine difference values for each of the selected pixels. Potential object edges, of the decoded image represented by the decoded blocks, are then detected (240) to identify the selected pixels as edge pixels, the detecting is effected by comparing the difference values with selected threshold values that are determined with respect to the selected quantization parameter associated with the blocks. The selected threshold values have a non-linear relationship with varying quantization parameter values of the image. The selected pixel values are modified (250) if they are not identified as edge pixels."><meta name="DC.date" content="2004-10-19" scheme="issued"><meta name="DC.relation" content="US:5359676" scheme="references"><meta name="DC.relation" content="US:5489942" scheme="references"><meta name="DC.relation" content="US:5495538" scheme="references"><meta name="DC.relation" content="US:5819035" scheme="references"><meta name="DC.relation" content="US:5844614" scheme="references"><meta name="DC.relation" content="US:6148115" scheme="references"><meta name="DC.relation" content="US:6175596" scheme="references"><meta name="DC.relation" content="US:6317522" scheme="references"><meta name="DC.relation" content="WO:1999022509:A2" scheme="references"><meta name="citation_patent_number" content="US:6807317"><meta name="citation_patent_application_number" content="US:10/280,903"><link rel="canonical" href="http://www.google.com/patents/US6807317"/><meta property="og:url" content="http://www.google.com/patents/US6807317"/><meta name="title" content="Patent US6807317 - Method and decoder system for reducing quantization effects of a decoded image"/><meta name="description" content="A method (200) and decoder system (100) for reducing quantization effects or ringing artifacts imposed upon decoded image of hybrid block based coding schemes such as MEPG and H 261. The system (100), in use, and method (200) receive (220) decoded image decoded blocks that were decoded from transform coded blocks quatized by a selected quantization parameter. The system (100) and method (200) then analyze (230) selected pixel values of selected pixels with neighboring pixel values of associated neighboring pixels in the decoded blocks to determine difference values for each of the selected pixels. Potential object edges, of the decoded image represented by the decoded blocks, are then detected (240) to identify the selected pixels as edge pixels, the detecting is effected by comparing the difference values with selected threshold values that are determined with respect to the selected quantization parameter associated with the blocks. The selected threshold values have a non-linear relationship with varying quantization parameter values of the image. The selected pixel values are modified (250) if they are not identified as edge pixels."/><meta property="og:title" content="Patent US6807317 - Method and decoder system for reducing quantization effects of a decoded image"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("dZbtU7vJEKLMsQTy34KQAg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("ITA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("dZbtU7vJEKLMsQTy34KQAg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("ITA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6807317?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6807317"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=UyNpBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6807317&amp;usg=AFQjCNF8oUjdROFbEUPkVimIrMVTNKYfjQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6807317.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6807317.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20040081368"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US6807317"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6807317" style="display:none"><span itemprop="description">A method (200) and decoder system (100) for reducing quantization effects or ringing artifacts imposed upon decoded image of hybrid block based coding schemes such as MEPG and H 261. The system (100), in use, and method (200) receive (220) decoded image decoded blocks that were decoded from transform...</span><span itemprop="url">http://www.google.com/patents/US6807317?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6807317 - Method and decoder system for reducing quantization effects of a decoded image</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6807317 - Method and decoder system for reducing quantization effects of a decoded image" title="Patent US6807317 - Method and decoder system for reducing quantization effects of a decoded image"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6807317 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 10/280,903</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Oct 19, 2004</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Oct 25, 2002</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Oct 25, 2002</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US20040081368">US20040081368</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2004038648A1">WO2004038648A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2004038648A9">WO2004038648A9</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">10280903, </span><span class="patent-bibdata-value">280903, </span><span class="patent-bibdata-value">US 6807317 B2, </span><span class="patent-bibdata-value">US 6807317B2, </span><span class="patent-bibdata-value">US-B2-6807317, </span><span class="patent-bibdata-value">US6807317 B2, </span><span class="patent-bibdata-value">US6807317B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Reji+Mathew%22">Reji Mathew</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jian+Zhang%22">Jian Zhang</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Motorola,+Inc.%22">Motorola, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6807317.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6807317.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6807317.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (9),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (16),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (14),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (8)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6807317&usg=AFQjCNEbd5isUyD8fsv8ijEO0QnnyCgWBQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6807317&usg=AFQjCNGGAKsNdYldxEq6MB4GQ0pzWcOENA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6807317B2%26KC%3DB2%26FT%3DD&usg=AFQjCNFmRV8QLSZL2FB_LgotytGQlFp_dQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55333128" lang="EN" load-source="patent-office">Method and decoder system for reducing quantization effects of a decoded image</invention-title></span><br><span class="patent-number">US 6807317 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50736824" lang="EN" load-source="patent-office"> <div class="abstract">A method (<b>200</b>) and decoder system (<b>100</b>) for reducing quantization effects or ringing artifacts imposed upon decoded image of hybrid block based coding schemes such as MEPG and H 261. The system (<b>100</b>), in use, and method (<b>200</b>) receive (<b>220</b>) decoded image decoded blocks that were decoded from transform coded blocks quatized by a selected quantization parameter. The system (<b>100</b>) and method (<b>200</b>) then analyze (<b>230</b>) selected pixel values of selected pixels with neighboring pixel values of associated neighboring pixels in the decoded blocks to determine difference values for each of the selected pixels. Potential object edges, of the decoded image represented by the decoded blocks, are then detected (<b>240</b>) to identify the selected pixels as edge pixels, the detecting is effected by comparing the difference values with selected threshold values that are determined with respect to the selected quantization parameter associated with the blocks. The selected threshold values have a non-linear relationship with varying quantization parameter values of the image. The selected pixel values are modified (<b>250</b>) if they are not identified as edge pixels.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(2)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6807317B2/US06807317-20041019-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6807317B2/US06807317-20041019-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6807317B2/US06807317-20041019-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6807317B2/US06807317-20041019-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(9)</span></span></div><div class="patent-text"><div mxw-id="PCLM8749984" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>We claim: </claim-statement> <div class="claim"> <div num="1" id="US-6807317-B2-CLM-00001" class="claim">
      <div class="claim-text">1. A method for reducing quantization effects of a decoded image, the method comprising the steps of:</div>
      <div class="claim-text">receiving at least part of a decoded image comprising decode blocks that were decoded from transform coded blocks quantized by a selected quantization parameter; </div>
      <div class="claim-text">analyzing selected pixel values of selected pixels with neighboring pixel values of associated neighboring pixels in said decoded blocks to determine difference values for each of said selected pixels; </div>
      <div class="claim-text">detecting potential object edges, of the decoded image represented by the decoded blocks, to identify said selected pixels as edge pixels, said detecting being effected by comparing said difference values with selected threshold values that are determined with respect to said selected quantization parameter associated with a selected one of said blocks, said selected threshold values having a non-linear relationship with varying quantization parameter values of said image; and </div>
      <div class="claim-text">modifying said selected pixel values of said selected pixels that are identified as not being edge pixels. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6807317-B2-CLM-00002" class="claim">
      <div class="claim-text">2. The method as claimed in <claim-ref idref="US-6807317-B2-CLM-00001">claim 1</claim-ref>, wherein said analyzing step comprises selecting three by three pixel arrays and comparing only said selected pixel values that are associated with a central pixel of each of said arrays with said neighboring pixel values of only said neighboring pixels that are adjacent to and either aligned directly vertical with or horizontal with said central pixel.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6807317-B2-CLM-00003" class="claim">
      <div class="claim-text">3. The method as claimed in <claim-ref idref="US-6807317-B2-CLM-00002">claim 2</claim-ref>, wherein the detecting step is characterized by said comparing comprising a first comparison with respect to first threshold value, and wherein the detecting step further includes a second comparison with respect to second threshold value wherein pairs of said directly aligned vertical pixels adjacent said central pixel and pairs of said directly aligned horizontal pixels adjacent said central pixel are compared with respect to second threshold value.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6807317-B2-CLM-00004" class="claim">
      <div class="claim-text">4. The method as claimed in <claim-ref idref="US-6807317-B2-CLM-00003">claim 3</claim-ref>, wherein said first threshold value and second threshold value have a non-linear relationship with respect to each other for varying quantization parameter values of said image.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6807317-B2-CLM-00005" class="claim">
      <div class="claim-text">5. The method as claimed in <claim-ref idref="US-6807317-B2-CLM-00001">claim 1</claim-ref>, wherein said selected threshold values are retrieved from a look-up table containing values for respective quantization parameter values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6807317-B2-CLM-00006" class="claim">
      <div class="claim-text">6. The method as claimed in <claim-ref idref="US-6807317-B2-CLM-00002">claim 2</claim-ref>, wherein the modifying step includes modifying at least some of said selected pixel values based on values of at least some of said neighboring pixel values in said three by three array.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" id="US-6807317-B2-CLM-00007" class="claim">
      <div class="claim-text">7. The method as claimed in <claim-ref idref="US-6807317-B2-CLM-00006">claim 6</claim-ref>, wherein said modifying step further includes modifying at least some of said selected pixel values by addition of a value thereto that is related to the selected quantization parameter.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" id="US-6807317-B2-CLM-00008" class="claim">
      <div class="claim-text">8. The method as claimed in <b>4</b> wherein the modifying step comprises:</div>
      <div class="claim-text">calculating a new pixel value for a selected pixel that is identified as not being an edge pixel; and </div>
      <div class="claim-text">limiting a maximum difference between the new pixel value an original value of said selected pixel such that said maximum difference is no greater than said quantization parameter. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" id="US-6807317-B2-CLM-00009" class="claim">
      <div class="claim-text">9. The method as claimed in <b>1</b>, further including a subsequent step of providing to a display said decoded image with pixel values that have been modified by the modifying step.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES54320217" lang="EN" load-source="patent-office" class="description">
    <heading>FIELD OF THE INVENTION</heading> <p>This invention relates to reducing quantization effects of a decoded image. The invention is particularly useful for, but not necessarily limited to, reducing quantization effects of decoded images that were previously coded by Discrete Cosine Transformation (DCT).</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>Most existing image and video coding standards such as H.261, H.263 and MPEG for example are typically based upon hybrid block coding algorithms. These algorithms incorporate transformations (such as the Discrete Cosine Transform (DCT)) and various quantization methods. The lossy nature of the quantization methods employed within a block based coding architecture introduces into a decoded image unwanted artifacts which impinge upon the quality of the reconstructed image.</p>
    <p>Examples of such artifacts which may be introduced are blocking artifacts and ringing artifacts. The blocking artifact is characterized by the appearance of block edge effects and a visible discontinuity between adjacent blocks, especially in areas of low detail within the image. Generally blocking occurs when coarse quantization levels are used to code DCT coefficients. Ringing is generally distortion appearing near strong edges in an image due to the truncation of high spatial frequencies by the Quantization process. In moving images ringing is visible as a slight flickering near the image edges</p>
    <p>There are various techniques to reduce the effects of ringing introduced in block coding schemes. One such example is described in U.S. Pat. No. 5,819,035 to Devaney et al. entitled “Post-Filter for removing ringing artifacts of DCT coding”. The disclosed post-filter primarily uses anisotropic diffusion to remove the ringing artifacts from the decoded data images. The filter processes individual blocks of pixels, assigning an individual edge significance threshold to each block. Noise removal occurs if the edge strength is below the threshold.</p>
    <p>Another example is contained in International Patent Publication No. WO 99/22509 in the name of Samsung Electronics Co., Ltd. entitled “Image data post-processing method for reducing quantization effect, apparatus therefore”. This publication discloses an image data post-processing method for reducing quantization effects such as blocking artifacts, corner outliers and ringing noise, from a decompressed image. The method involves the detection of a semaphore which represents whether or not post-processing is required and only filtering those decoded image blocks for which the corresponding semaphore has been signaled.</p>
    <p>An article in <i>Electronics Letters</i>, vol. 34, no. 22, pp. 2110-2112, October 1998 addressing the use of a de-ringing filter in video communications by Dr André Kaup entitled “Reduction of ringing noise in transform image coding using a simple adaptive filter” discloses a de-ringing filter which is constructed from an adaptive low pass filter where the filter mask varies depending upon the local image characteristics. The filter is adaptive in two ways. First only those neighboring pixels wherein their corresponding grey levels are within a certain confidence interval around the pixel to be filtered are included in the filter mask. Secondly the filter mask is strictly local since only the pixels within a 3×3 window around the current pixel are considered.</p>
    <p>The MPEG-4 Verification Model, as set out in ISO/IEC JTC 1/SC 29/WG 11 N4350, Sydney, July 2001, includes a de-ringing algorithm. This algorithm has heretofore been considered as “best in class” for de-ringing of coded video. The algorithm performs de-ringing at a macro-block level each macro-block needs to be read in from memory and processed in turn.</p>
    <p>Each of above disclose various forms of de-ringing algorithms that employ various object edge detection methods, such as selecting threshold values having a linear relationship with the quantization parameters used during decoding, to determine which pixels require post process filtering to eliminate ringing artifacts.</p>
    <p>In this specification, including the claims, the terms ‘comprises’, ‘comprising’ or similar terms are intended to mean a non-exclusive inclusion, such that a method or apparatus that comprises a list of elements does not include those elements solely, but may well include other elements not listed.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>According to one aspect of the invention there is provided a method for reducing quantization effects of a decoded image, the method comprising the steps of:</p>
    <p>receiving at least part of a decoded image comprising decoded blocks that were decoded from transform coded blocks quantized by a selected quantization parameter;</p>
    <p>analyzing selected pixel values of selected pixels with neighboring pixel values of associated neighboring pixels in said decoded blocks to determine difference values for each of said selected pixels;</p>
    <p>detecting potential object edges, of the decoded image represented by the decoded blocks, to identify said selected pixels as edge pixels, said detecting being effected by comparing said difference values with selected threshold values that are determined with respect to said selected quantization parameter associated with a selected one of said blocks, said selected threshold values having a non-linear relationship with varying quantization parameter values of said image; and</p>
    <p>modifying said selected pixel values of said selected pixels that are identified as not being edge pixels.</p>
    <p>Suitably, the analyzing step may comprise selecting three by three pixel arrays and comparing only said selected pixel values that are associated with a central pixel of each of said arrays with said neighboring pixel values of only said neighboring pixels that are adjacent to and either aligned directly vertical with or horizontal with said central pixel.</p>
    <p>Preferably, the detecting step may be characterized by said comparing comprising a first comparison with respect to first threshold value, and wherein the detecting step further includes a second comparison with respect to second threshold value wherein pairs of said directly aligned vertical pixels adjacent said central pixel and pairs of said directly aligned horizontal pixels adjacent said central pixel are compared with respect to second threshold value.</p>
    <p>The first threshold value and second threshold value may preferably have a non-linear relationship with respect to each other for varying quantization parameter values of said image.</p>
    <p>Suitably, the selected threshold values may be retrieved from a look-up table containing values for respective quantization parameter values.</p>
    <p>Preferably, the modifying step may include modifying at least some of said selected pixel values based on values of at least some of said neighboring pixel values in said three by three array.</p>
    <p>Suitably, the modifying step may further include modifying least some of said selected pixel values by addition of a value thereto that is related to the selected quantization parameter.</p>
    <p>Preferably, the modifying step may comprise:</p>
    <p>calculating a new pixel value for a selected pixel that is identified as not being an edge pixel; and</p>
    <p>limiting a maximum difference between the new pixel value and original value of said selected pixel such that said maximum difference is no greater than said quantization parameter.</p>
    <p>The method may preferably further include a subsequent step of providing to a display said decoded image with pixel values that have been modified by the modifying step.</p>
    <p>Alternatively, according to another form of the invention there is provided a decoder system for reducing quantization effects of a decoded image, the system comprising:</p>
    <p>a receiver module with an output coupled to a decoding module;</p>
    <p>a de-ringing module coupled to an output of the decoding module;</p>
    <p>a processors coupled to the de-ringing modules, wherein in use the de-ringing module receives at least part of a decoded image, decoded by the decoding module, comprising decoded blocks that were decoded from transform coded blocks quantized by a selected quantization parameter; the de-ringing module then analyzes selected pixel values of selected pixels with neighboring pixel values of associated neighboring pixels in said decoded blocks to determine difference values for each of said selected pixels; the de-ringing module then detects potential object edges, of the decoded image represented by the decoded blocks, to identify said selected pixels as edge pixels, said detecting being effected by comparing said difference values with selected threshold values that are determined with respect to said selected quantization parameter associated with a selected one of said blocks, said selected threshold values having a non-linear relationship with varying quantization parameter values of said image; and then the de-ringing module modifies said selected pixel values of said selected pixels that are identified as not being edge pixels.</p>
    <p>Suitably, the de-ringing module can be coupled to an output of the decoding module via a de-blocking module.</p>
    <p>Preferably, the de-ringing module may analyze the selected pixel values by selecting three by three pixel arrays and comparing only said selected pixel values that are associated with a central pixel of each of said arrays with said neighboring pixel values of only said neighboring pixels that are adjacent to and either aligned directly vertical with or horizontal with said central pixel.</p>
    <p>The de-ringing module may, in use, detect potential object edges by a first comparison with respect to first threshold value and a second comparison with respect to second threshold value wherein pairs of said directly aligned vertical pixels adjacent said central pixel and pairs of said directly aligned horizontal pixels adjacent said central pixel are compared with respect to second threshold value.</p>
    <p>Suitably, the first threshold value and second threshold value may have a non-linear relationship with respect to each other for varying quantization parameter values of said image.</p>
    <p>Preferably, the selected threshold values may be retrieved from a look-up table containing values for respective quantization parameter values.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>In order that the invention may be readily understood and put into practical effect, reference will now be made to a preferred embodiment as illustrated with reference to the accompanying drawings in which:</p>
    <p>FIG. 1 is a schematic block diagram of a video decoding system in accordance with the present invention;</p>
    <p>FIG. 2 illustrates a method for reducing quantization effects of a decoded image decoded by the system of FIG. 1; and</p>
    <p>FIG. 3 is a schematic block diagram illustrating a three by three filtering window used in the method of FIG. <b>2</b>.</p>
    <heading>DETAILED DESCRIPTION OF A PREFERRED EMBODIMENT OF THE INVENTION</heading> <p>In the drawings, like numerals on different Figs are used to indicate like elements throughout. Referring to FIG. 1, there is illustrated a video decoding system <b>100</b> comprising a receiver module <b>110</b> with a cable port <b>112</b> for receipt of images through a network and an antenna <b>114</b> for receipt of images by radio communications. Alternatively the images can be received, at port <b>112</b>, via a recorded medium such as a CD-ROM. An output of the receiver module is coupled to a decoding module <b>120</b> that has an output coupled to an input of a de-blocking module <b>130</b>. An output of the de-blocking module <b>130</b> is coupled to an input of a de-ringing module <b>140</b> having an output coupled to a input of a display module <b>150</b>. All of the modules <b>110</b>,<b>120</b>,<b>130</b>,<b>140</b>,<b>150</b> are coupled to a processor <b>160</b> by a common combined data and address bus <b>170</b>.</p>
    <p>In use, the system <b>100</b> receives a coded image stream at either the cable port <b>112</b> or antenna <b>114</b> or via a digitally stored medium. The receiver module <b>110</b> performs demodulation and filtering as required on the coded image stream and the decoding module <b>120</b> decodes the coded image stream to provide a decoded image. The de-blocking module <b>130</b> then performs de-blocking, to reduce the effects of blocking artifacts caused by the decoded image being composed of discrete blocks. The decoded image is then processed by the de-ringing module <b>140</b> to reduce quantization effects (typically ringing artifacts), thereafter the image is displayed by the display module <b>150</b>. The operation of the system <b>100</b> is controlled by the processor <b>160</b>, as will be apparent to a person skilled in the art, and the processor <b>160</b> may include large memory storage capabilities for storing the decoded image after the quantization effects (ringing artifacts) have been reduced by the de-ringing module <b>140</b>. Referring to FIG. 2 there is illustrated a method <b>200</b> for reducing quantization effects of a decoded image decoded by the system <b>100</b>. The method <b>200</b> is performed by the de-ringing module <b>140</b> and it is initiated by the processor <b>160</b> determining that a decoded image is to be processed and thereby a start step <b>210</b> is invoked. After the start step <b>210</b> there is a receiving step <b>220</b> that effects a receiving of at least part of the decoded image comprising decoded blocks that were decoded from transform coded blocks quantized by a selected quantization parameter during coding of the image. An analyzing step <b>230</b> then performs analyzing selected pixel values of selected pixels with neighboring pixel values of associated neighboring pixels in the decoded blocks to determine difference values for each of the selected pixels. The analyzing step <b>230</b> comprises selecting three by three pixel arrays and comparing only the selected pixel values that are associated with a central pixel of each of the arrays with the neighboring pixel values of only the neighboring pixels that are adjacent to and either aligned directly vertical with or horizontal with the central pixel.</p>
    <p>In FIG. 3, there is illustrated an example of a three by three pixel array <b>300</b> comprising pixels A, B, C, D, E, F, G, H and I. The central pixel or selected pixel is pixel B and the neighboring pixels that are aligned directly vertical with the central pixel are pixels A and C. Further, the neighboring pixels that are aligned directly horizontal with the central pixel are pixels D and E.</p>
    <p>Returning to FIG. 2, after step <b>230</b> a detecting step <b>240</b> effects detecting potential object edges, of the decoded image represented by the decoded blocks, to identify the selected pixels as edge pixels. The detecting is effected by comparing difference values with selected threshold values that are determined with respect to the selected quantization parameter associated with a selected one of the blocks. The selected threshold values have a non-linear relationship with varying quantization parameter values of the image. The comparing comprises a first comparison with respect to first threshold value QP<b>1</b>. A second comparison is also performed with respect to second threshold value QP<b>2</b> wherein pairs of the directly aligned vertical pixels adjacent said central pixel and pairs of the directly aligned horizontal pixels adjacent the central pixel are compared with respect to second threshold value QP<b>2</b>. The first threshold value QP<b>1</b> and second threshold value QP<b>2</b> have a non-linear relationship with respect to each other for varying quantization parameter values QP of the image. The selected threshold values QP<b>1</b>, QP<b>2</b> are retrieved from a look-up table containing values for respective quantization parameter values. The look up table is shown in table 1 and shows the non-liner relationships of the threshold values QP<b>1</b>, QP<b>2</b> relative to varying quatization parameter values QP used during coding of the image.</p>
    <p>The edge detection is performed by comparing the difference of the pixel values neighboring pixel B with a threshold. The threshold for each pixel is dependent on the Quantization Parameter value QP corresponding to the pixel. For example the edge detection process for the illustrated array firstly is performed using pixels A, B, C, D and E.</p>
    <p>The check for vertical and horizontal edges is performed in accordance with the following inequalities:</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="203pt" align="left"> </colspec> <thead> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">{Horizontal Edge Detection}</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="189pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">IF |B-A| &gt; QP1 AND |B-C| &gt; QP1 THEN</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="42pt" align="left"> </colspec> <colspec colname="1" colwidth="175pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Edge = 1;</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="189pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">ELSE IF |A-C| &gt; QP2 THEN</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="42pt" align="left"> </colspec> <colspec colname="1" colwidth="175pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Edge = 1;</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="203pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">{Vertical Edge Detection}</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="189pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">IF |B-D| &gt; QP1 AND |B-E| &gt; QP1 THEN</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="42pt" align="left"> </colspec> <colspec colname="1" colwidth="175pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Edge = 1;</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="189pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">ELSE IF |D-E| &gt; QP2 THEN</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="42pt" align="left"> </colspec> <colspec colname="1" colwidth="175pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">Edge = 1.</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="203pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">{|B-A|, |B-C|, |B-D| and |B-E| are the absolute difference</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">values resulting from the analyzing step 230}</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>Where: QP<b>1</b> and QP<b>2</b> are the threshold values dependent on the Quantization Parameter value QP; and ‘Edge’ is a Boolean variable which is set to 1 only if an edge is located (otherwise EDGE is set to 0).</p>
    <p>After the detecting step <b>240</b> there is a modifying step for modifying the selected pixel values of the selected pixels that are identified as not being edge pixels. A providing step <b>260</b> then effects providing to the display module <b>150</b> decoded image with pixel values that have been modified by the modifying step <b>250</b>. The steps <b>220</b> to <b>260</b> are repeated until the processor <b>160</b> determines at a test step <b>270</b> that no decoded image is required to be further processed and the method <b>200</b> therefore terminates at an end step <b>280</b>.</p>
    <p>In the modifying step <b>250</b>, if a selected pixel is determined as being an edge pixel of an object, then no further processing is performed. However if the pixel is not classified as being an edge pixel then it undergoes filtering. The filtering performs a smoothing operation on all the pixels which have been identified as non-edge pixels indicative of edges of objects in the image. The filtering firstly involves calculating a new pixel value B_new for pixel B. Secondly a limiting process is performed to ensure that the maximum difference between the new pixel value B_new and the original pixel value is no greater than QP. The afore mentioned calculation and limitation processes are performed in accordance with the following algorithm:</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="left"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">IF (Edge == 0) THEN  {IF EDGE NOT DETECTED)</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="14pt" align="left"> </colspec> <colspec colname="1" colwidth="203pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">B_new = (4*B + 2*A + 2*C + 2*D + 2*E +F +G +H +I +8)/16;</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="189pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">max_diff = QP;</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">IF (B_new − B &gt; max_diff)</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="42pt" align="left"> </colspec> <colspec colname="1" colwidth="175pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">THEN B = B + max_diff;</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="189pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">ELSE IF (B − B_new &gt; max_diff)</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="42pt" align="left"> </colspec> <colspec colname="1" colwidth="175pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">B = B − max_diff;</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="28pt" align="left"> </colspec> <colspec colname="1" colwidth="189pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">ELSE</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="2"> <colspec colname="offset" colwidth="42pt" align="left"> </colspec> <colspec colname="1" colwidth="175pt" align="left"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td"> </td>
                <td class="description-td">B = B_new.</td>
              </tr> <tr class="description-tr"> <td class="description-td"> </td>
                <td namest="offset" nameend="1" align="center" rowsep="1" class="description-td" colspan="2"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>Color video signals are usually comprised of three color channels, these being one luminance (Y) channel and two chrominance (U, V) channels. Generally the above deringing techinique is only required to be performed on the luminance channel. Performing de-ringing on the chrominance channels (U, V) have no (or little) noticeable effect on the quality of the reconstructed image. The decoded luminance data is read in from a buffer in processor <b>160</b> to the de-ringing module <b>140</b> as a series of three by three pixel arrays wherein the arrays are subjected to the de-ringing process of the present invention. The filtered luminance data is the output back to the buffer before being recombined with the decoded data from the two chrominance channels before being displayed by display module <b>150</b>.</p>
    <p>
      <tables> <table frame="none" colsep="0" rowsep="0" class="description-table"> <tgroup align="left" colsep="0" rowsep="0" cols="1"> <colspec colname="1" colwidth="217pt" align="center"> </colspec> <thead> <tr class="description-tr"> <td namest="1" nameend="1" rowsep="1" class="description-td" colspan="1">TABLE 1</td>
              </tr> </thead> <tbody valign="top"> <tr class="description-tr"> <td namest="1" nameend="1" align="center" rowsep="1" class="description-td" colspan="1"> </td>
              </tr> <tr class="description-tr"> <td class="description-td">Look up table for thresholds values QP1 and QP2 for varying</td>
              </tr> <tr class="description-tr"> <td class="description-td">values of quantiztion parameter QP.</td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="1" colwidth="98pt" align="center"> </colspec> <colspec colname="2" colwidth="21pt" align="center"> </colspec> <colspec colname="3" colwidth="98pt" align="center"> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">QP</td>
                <td class="description-td">QP1</td>
                <td class="description-td">QP2</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="3" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> <tgroup align="left" colsep="0" rowsep="0" cols="3"> <colspec colname="1" colwidth="98pt" align="char" char="."> </colspec> <colspec colname="2" colwidth="21pt" align="char" char="."> </colspec> <colspec colname="3" colwidth="98pt" align="char" char="."> </colspec> <tbody valign="top"> <tr class="description-tr"> <td class="description-td">1</td>
                <td class="description-td">1</td>
                <td class="description-td">2</td>
              </tr> <tr class="description-tr"> <td class="description-td">2</td>
                <td class="description-td">2</td>
                <td class="description-td">4</td>
              </tr> <tr class="description-tr"> <td class="description-td">3</td>
                <td class="description-td">3</td>
                <td class="description-td">6</td>
              </tr> <tr class="description-tr"> <td class="description-td">4</td>
                <td class="description-td">4</td>
                <td class="description-td">8</td>
              </tr> <tr class="description-tr"> <td class="description-td">5</td>
                <td class="description-td">5</td>
                <td class="description-td">10</td>
              </tr> <tr class="description-tr"> <td class="description-td">6</td>
                <td class="description-td">6</td>
                <td class="description-td">12</td>
              </tr> <tr class="description-tr"> <td class="description-td">7</td>
                <td class="description-td">7</td>
                <td class="description-td">14</td>
              </tr> <tr class="description-tr"> <td class="description-td">6</td>
                <td class="description-td">8</td>
                <td class="description-td">16</td>
              </tr> <tr class="description-tr"> <td class="description-td">9</td>
                <td class="description-td">8</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td">10</td>
                <td class="description-td">8</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td">11</td>
                <td class="description-td">8</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td">12</td>
                <td class="description-td">8</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td">13</td>
                <td class="description-td">9</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td">14</td>
                <td class="description-td">9</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td">15</td>
                <td class="description-td">9</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td">16</td>
                <td class="description-td">9</td>
                <td class="description-td">17</td>
              </tr> <tr class="description-tr"> <td class="description-td">17</td>
                <td class="description-td">10</td>
                <td class="description-td">18</td>
              </tr> <tr class="description-tr"> <td class="description-td">18</td>
                <td class="description-td">10</td>
                <td class="description-td">18</td>
              </tr> <tr class="description-tr"> <td class="description-td">19</td>
                <td class="description-td">11</td>
                <td class="description-td">19</td>
              </tr> <tr class="description-tr"> <td class="description-td">20</td>
                <td class="description-td">12</td>
                <td class="description-td">20</td>
              </tr> <tr class="description-tr"> <td class="description-td">21</td>
                <td class="description-td">12</td>
                <td class="description-td">20</td>
              </tr> <tr class="description-tr"> <td class="description-td">22</td>
                <td class="description-td">12</td>
                <td class="description-td">21</td>
              </tr> <tr class="description-tr"> <td class="description-td">23</td>
                <td class="description-td">12</td>
                <td class="description-td">21</td>
              </tr> <tr class="description-tr"> <td class="description-td">24</td>
                <td class="description-td">12</td>
                <td class="description-td">21</td>
              </tr> <tr class="description-tr"> <td class="description-td">25</td>
                <td class="description-td">12</td>
                <td class="description-td">21</td>
              </tr> <tr class="description-tr"> <td class="description-td">26</td>
                <td class="description-td">13</td>
                <td class="description-td">21</td>
              </tr> <tr class="description-tr"> <td class="description-td">27</td>
                <td class="description-td">13</td>
                <td class="description-td">21</td>
              </tr> <tr class="description-tr"> <td class="description-td">28</td>
                <td class="description-td">14</td>
                <td class="description-td">22</td>
              </tr> <tr class="description-tr"> <td class="description-td">29</td>
                <td class="description-td">14</td>
                <td class="description-td">22</td>
              </tr> <tr class="description-tr"> <td class="description-td">30</td>
                <td class="description-td">15</td>
                <td class="description-td">22</td>
              </tr> <tr class="description-tr"> <td class="description-td">31</td>
                <td class="description-td">15</td>
                <td class="description-td">22</td>
              </tr> <tr class="description-tr"> <td class="description-td">32</td>
                <td class="description-td">16</td>
                <td class="description-td">23</td>
              </tr> <tr class="description-tr"> <td namest="1" nameend="3" align="center" rowsep="1" class="description-td" colspan="3"> </td>
              </tr> </tbody> </tgroup> </table> </tables> </p>
    <p>Advantageously, the detecting and modifying (filtering) steps of the present invention reduce memory access overheads in post processing of the decoded image. The present invention enables the de-ring process to be pipelined with a de-blocking function. The de-blocking module accesses memory across block boundaries to remove blocking artifacts from the decoded image. Under certain prior art processing schemes the de-blocked image regions would need to be stored to memory in processor <b>160</b> so that a macro block can be formed before proceeding to the de-ringing module.</p>
    <p>The detailed description provides preferred exemplary embodiments only, and is not intended to limit the scope, applicability, or configuration of the invention. Rather, the detailed description of the preferred exemplary embodiments provides those skilled in the art with an enabling description for implementing a preferred exemplary embodiment of the invention. It should be understood that various changes may be made in the function and arrangement of elements without departing from the spirit and scope of the invention as set forth in the appended claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5359676">US5359676</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 19, 1993</td><td class="patent-data-table-td patent-date-value">Oct 25, 1994</td><td class="patent-data-table-td ">Xerox Corporation</td><td class="patent-data-table-td ">Decompression of standard ADCT-compressed document images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5489942">US5489942</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 21, 1994</td><td class="patent-data-table-td patent-date-value">Feb 6, 1996</td><td class="patent-data-table-td ">Sharp Kabushiki Kaisha</td><td class="patent-data-table-td ">Image compressing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5495538">US5495538</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 8, 1995</td><td class="patent-data-table-td patent-date-value">Feb 27, 1996</td><td class="patent-data-table-td ">Xerox Corporation</td><td class="patent-data-table-td ">Segmentation-based JPEG image artifacts reduction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5819035">US5819035</a></td><td class="patent-data-table-td patent-date-value">Oct 20, 1995</td><td class="patent-data-table-td patent-date-value">Oct 6, 1998</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Apparatus for use in a video signal decoding system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5844614">US5844614</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 11, 1996</td><td class="patent-data-table-td patent-date-value">Dec 1, 1998</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Video signal decoding apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6148115">US6148115</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 6, 1997</td><td class="patent-data-table-td patent-date-value">Nov 14, 2000</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image processing apparatus and image processing method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6175596">US6175596</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 6, 1998</td><td class="patent-data-table-td patent-date-value">Jan 16, 2001</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Picture signal encoding method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6317522">US6317522</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 3, 1998</td><td class="patent-data-table-td patent-date-value">Nov 13, 2001</td><td class="patent-data-table-td ">Philips Electronics North America Corp.</td><td class="patent-data-table-td ">Systems and methods for post-processing decompressed images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1999022509A2?cl=en">WO1999022509A2</a></td><td class="patent-data-table-td patent-date-value">Oct 9, 1998</td><td class="patent-data-table-td patent-date-value">May 6, 1999</td><td class="patent-data-table-td ">Samsung Electronics Co Ltd</td><td class="patent-data-table-td ">Image data post-processing method for reducing quantization effect, apparatus therefor</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6993191">US6993191</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 1, 2002</td><td class="patent-data-table-td patent-date-value">Jan 31, 2006</td><td class="patent-data-table-td ">Pts Corporation</td><td class="patent-data-table-td ">Methods and apparatus for removing compression artifacts in video sequences</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7136536">US7136536</a></td><td class="patent-data-table-td patent-date-value">Dec 13, 2005</td><td class="patent-data-table-td patent-date-value">Nov 14, 2006</td><td class="patent-data-table-td ">Telefonaktiebolaget L M Ericsson (Publ)</td><td class="patent-data-table-td ">Adaptive filter</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7362810">US7362810</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 13, 2003</td><td class="patent-data-table-td patent-date-value">Apr 22, 2008</td><td class="patent-data-table-td ">Sigmatel, Inc.</td><td class="patent-data-table-td ">Post-filter for deblocking and deringing of video data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7463688">US7463688</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 16, 2003</td><td class="patent-data-table-td patent-date-value">Dec 9, 2008</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Methods and apparatus for removing blocking artifacts of MPEG signals in real-time video reception</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7792194">US7792194</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 10, 2003</td><td class="patent-data-table-td patent-date-value">Sep 7, 2010</td><td class="patent-data-table-td ">Lefan Zhong</td><td class="patent-data-table-td ">MPEG artifacts post-processed filtering architecture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8638863">US8638863</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 18, 2011</td><td class="patent-data-table-td patent-date-value">Jan 28, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Apparatus and method for filtering video using extended edge-detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8660182">US8660182</a></td><td class="patent-data-table-td patent-date-value">Jun 9, 2003</td><td class="patent-data-table-td patent-date-value">Feb 25, 2014</td><td class="patent-data-table-td ">Nvidia Corporation</td><td class="patent-data-table-td ">MPEG motion estimation based on dual start points</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8660380">US8660380</a></td><td class="patent-data-table-td patent-date-value">Aug 25, 2006</td><td class="patent-data-table-td patent-date-value">Feb 25, 2014</td><td class="patent-data-table-td ">Nvidia Corporation</td><td class="patent-data-table-td ">Method and system for performing two-dimensional transform on data value array with reduced power consumption</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8666166">US8666166</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 2009</td><td class="patent-data-table-td patent-date-value">Mar 4, 2014</td><td class="patent-data-table-td ">Nvidia Corporation</td><td class="patent-data-table-td ">Method and system for performing two-dimensional transform on data value array with reduced power consumption</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8666181">US8666181</a></td><td class="patent-data-table-td patent-date-value">Dec 10, 2008</td><td class="patent-data-table-td patent-date-value">Mar 4, 2014</td><td class="patent-data-table-td ">Nvidia Corporation</td><td class="patent-data-table-td ">Adaptive multiple engine image motion detection system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8724702">US8724702</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 2006</td><td class="patent-data-table-td patent-date-value">May 13, 2014</td><td class="patent-data-table-td ">Nvidia Corporation</td><td class="patent-data-table-td ">Methods and systems for motion estimation used in video coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8731071">US8731071</a></td><td class="patent-data-table-td patent-date-value">Dec 15, 2005</td><td class="patent-data-table-td patent-date-value">May 20, 2014</td><td class="patent-data-table-td ">Nvidia Corporation</td><td class="patent-data-table-td ">System for performing finite input response (FIR) filtering in motion estimation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8756482">US8756482</a></td><td class="patent-data-table-td patent-date-value">May 25, 2007</td><td class="patent-data-table-td patent-date-value">Jun 17, 2014</td><td class="patent-data-table-td ">Nvidia Corporation</td><td class="patent-data-table-td ">Efficient encoding/decoding of a sequence of data frames</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8767817">US8767817</a></td><td class="patent-data-table-td patent-date-value">Apr 7, 2011</td><td class="patent-data-table-td patent-date-value">Jul 1, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Apparatus and method for coding using parameterized equation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100272191">US20100272191</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 12, 2009</td><td class="patent-data-table-td patent-date-value">Oct 28, 2010</td><td class="patent-data-table-td ">Camilo Chang Dorea</td><td class="patent-data-table-td ">Methods and apparatus for de-artifact filtering using multi-lattice sparsity-based filtering</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100278236">US20100278236</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 22, 2008</td><td class="patent-data-table-td patent-date-value">Nov 4, 2010</td><td class="patent-data-table-td ">Hua Yang</td><td class="patent-data-table-td ">Reduced video flicker</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S266000">382/266</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S233000">382/233</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S251000">382/251</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375S240290">375/240.29</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0009000000">G06T9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0005000000">G06T5/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T5/20">G06T5/20</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T7/0085">G06T7/0085</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T2207/20192">G06T2207/20192</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T2207/20012">G06T2207/20012</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T5/002">G06T5/002</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=UyNpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00909">H04N19/00909</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06T9/00S</span>, <span class="nested-value">G06T5/00D</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Oct 2, 2012</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120622</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">MOTOROLA MOBILITY LLC, ILLINOIS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:029216/0282</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 23, 2012</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 13, 2010</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100731</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">MOTOROLA MOBILITY, INC, ILLINOIS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 26, 2010</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 2-4 AND 6 IS CONFIRMED. CLAIMS 1, 5 AND 9 ARE CANCELLED. CLAIMS 7 AND 8WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 16, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20091223</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 20, 2008</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 24, 2006</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 25, 2002</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">MOTOROLA, INC., ILLINOIS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:MATHEW. REJI;ZHANG, JIAN;REEL/FRAME:013442/0837</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20021017</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U3FmFzCOcRcoGqyoYfaOpXpR7XDxg\u0026id=UyNpBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3YbM6ykztXI9edsZcYw4aFBNJtLg\u0026id=UyNpBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U0pFjRQ3x2g51h55tHTuNHGHLfnSA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_and_decoder_system_for_reducing_q.pdf?id=UyNpBAABERAJ\u0026output=pdf\u0026sig=ACfU3U2EGUBTuZcsEG4yXoZJJgNbKwnbpQ"},"sample_url":"http://www.google.com/patents/reader?id=UyNpBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>