<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7804426 - System and method for selective review of event data - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="System and method for selective review of event data"><meta name="DC.contributor" content="Jamie Etcheson" scheme="inventor"><meta name="DC.contributor" content="Drivecam, Inc." scheme="assignee"><meta name="DC.date" content="2006-12-4" scheme="dateSubmitted"><meta name="DC.description" content="Systems and methods for computer assisted cueing and selective reviewing of driving data in order to save time in the data review process are provided. The method allows identifying essential portions of the data, selecting the essential portions, reviewing the selected data and retrieving additional data leading to the event if necessary. At least one event capture device continuously captures data into a buffer. The data are sent to an event detector communicatively coupled to the event capture device only when the event detector requests them. After receiving the data, the event detector selects and indexes a pre-event portion, during-event portion and post-event portion, combines the portions of captured data into a single driving event record and sends the driving event record to the evaluation server. From the server, the driving event record is sent to the analysis station for review and analysis."><meta name="DC.date" content="2010-9-28" scheme="issued"><meta name="DC.relation" content="US:20030125854:A1" scheme="references"><meta name="DC.relation" content="US:2943141" scheme="references"><meta name="DC.relation" content="US:3781824" scheme="references"><meta name="DC.relation" content="US:3812287" scheme="references"><meta name="DC.relation" content="US:3885090" scheme="references"><meta name="DC.relation" content="US:3992656" scheme="references"><meta name="DC.relation" content="US:4054752" scheme="references"><meta name="DC.relation" content="US:4271358" scheme="references"><meta name="DC.relation" content="US:4280151" scheme="references"><meta name="DC.relation" content="US:4281354" scheme="references"><meta name="DC.relation" content="US:4401976" scheme="references"><meta name="DC.relation" content="US:4409670" scheme="references"><meta name="DC.relation" content="US:4420773" scheme="references"><meta name="DC.relation" content="US:4456931" scheme="references"><meta name="DC.relation" content="US:4489351" scheme="references"><meta name="DC.relation" content="US:4496995" scheme="references"><meta name="DC.relation" content="US:4533962" scheme="references"><meta name="DC.relation" content="US:4558379" scheme="references"><meta name="DC.relation" content="US:4593313" scheme="references"><meta name="DC.relation" content="US:4621335" scheme="references"><meta name="DC.relation" content="US:4625210" scheme="references"><meta name="DC.relation" content="US:4630110" scheme="references"><meta name="DC.relation" content="US:4632348" scheme="references"><meta name="DC.relation" content="US:4638289" scheme="references"><meta name="DC.relation" content="US:4646241" scheme="references"><meta name="DC.relation" content="US:4651143" scheme="references"><meta name="DC.relation" content="US:4758888" scheme="references"><meta name="DC.relation" content="US:4763745" scheme="references"><meta name="DC.relation" content="US:4785474" scheme="references"><meta name="DC.relation" content="US:4789904" scheme="references"><meta name="DC.relation" content="US:4794566" scheme="references"><meta name="DC.relation" content="US:4804937" scheme="references"><meta name="DC.relation" content="US:4806931" scheme="references"><meta name="DC.relation" content="US:4837628" scheme="references"><meta name="DC.relation" content="US:4839631" scheme="references"><meta name="DC.relation" content="US:4843463" scheme="references"><meta name="DC.relation" content="US:4843578" scheme="references"><meta name="DC.relation" content="US:4876597" scheme="references"><meta name="DC.relation" content="US:4883349" scheme="references"><meta name="DC.relation" content="US:4896855" scheme="references"><meta name="DC.relation" content="US:4930742" scheme="references"><meta name="DC.relation" content="US:4936533" scheme="references"><meta name="DC.relation" content="US:4939652" scheme="references"><meta name="DC.relation" content="US:4942464" scheme="references"><meta name="DC.relation" content="US:4945244" scheme="references"><meta name="DC.relation" content="US:4949186" scheme="references"><meta name="DC.relation" content="US:4980913" scheme="references"><meta name="DC.relation" content="US:4987541" scheme="references"><meta name="DC.relation" content="US:4992943" scheme="references"><meta name="DC.relation" content="US:5012335" scheme="references"><meta name="DC.relation" content="US:5027104" scheme="references"><meta name="DC.relation" content="US:5056056" scheme="references"><meta name="DC.relation" content="US:5057820" scheme="references"><meta name="DC.relation" content="US:5096287" scheme="references"><meta name="DC.relation" content="US:5100095" scheme="references"><meta name="DC.relation" content="US:5111289" scheme="references"><meta name="DC.relation" content="US:5140434" scheme="references"><meta name="DC.relation" content="US:5140436" scheme="references"><meta name="DC.relation" content="US:5144661" scheme="references"><meta name="DC.relation" content="US:5178448" scheme="references"><meta name="DC.relation" content="US:5196938" scheme="references"><meta name="DC.relation" content="US:5223844" scheme="references"><meta name="DC.relation" content="US:5262813" scheme="references"><meta name="DC.relation" content="US:5308247" scheme="references"><meta name="DC.relation" content="US:5311197" scheme="references"><meta name="DC.relation" content="US:5321753" scheme="references"><meta name="DC.relation" content="US:5327288" scheme="references"><meta name="DC.relation" content="US:5330149" scheme="references"><meta name="DC.relation" content="US:5343527" scheme="references"><meta name="DC.relation" content="US:5353023" scheme="references"><meta name="DC.relation" content="US:5361326" scheme="references"><meta name="DC.relation" content="US:5387926" scheme="references"><meta name="DC.relation" content="US:5388045" scheme="references"><meta name="DC.relation" content="US:5404330" scheme="references"><meta name="DC.relation" content="US:5408330" scheme="references"><meta name="DC.relation" content="US:5422543" scheme="references"><meta name="DC.relation" content="US:5430431" scheme="references"><meta name="DC.relation" content="US:5430432" scheme="references"><meta name="DC.relation" content="US:5435184" scheme="references"><meta name="DC.relation" content="US:5445024" scheme="references"><meta name="DC.relation" content="US:5445027" scheme="references"><meta name="DC.relation" content="US:5446659" scheme="references"><meta name="DC.relation" content="US:5455625" scheme="references"><meta name="DC.relation" content="US:5455716" scheme="references"><meta name="DC.relation" content="US:5473729" scheme="references"><meta name="DC.relation" content="US:5477141" scheme="references"><meta name="DC.relation" content="US:5495242" scheme="references"><meta name="DC.relation" content="US:5497419" scheme="references"><meta name="DC.relation" content="US:5499182" scheme="references"><meta name="DC.relation" content="US:5504482" scheme="references"><meta name="DC.relation" content="US:5515285" scheme="references"><meta name="DC.relation" content="US:5521633" scheme="references"><meta name="DC.relation" content="US:5523811" scheme="references"><meta name="DC.relation" content="US:5526269" scheme="references"><meta name="DC.relation" content="US:5530420" scheme="references"><meta name="DC.relation" content="US:5537156" scheme="references"><meta name="DC.relation" content="US:5539454" scheme="references"><meta name="DC.relation" content="US:5541590" scheme="references"><meta name="DC.relation" content="US:5544060" scheme="references"><meta name="DC.relation" content="US:5548273" scheme="references"><meta name="citation_reference" content="International Search Report and Written Opinion issued in PCT/US07/68329 on Mar. 3, 2008."><meta name="citation_patent_number" content="US:7804426"><meta name="citation_patent_application_number" content="US:11/566,424"><link rel="canonical" href="http://www.google.com/patents/US7804426"/><meta property="og:url" content="http://www.google.com/patents/US7804426"/><meta name="title" content="Patent US7804426 - System and method for selective review of event data"/><meta name="description" content="Systems and methods for computer assisted cueing and selective reviewing of driving data in order to save time in the data review process are provided. The method allows identifying essential portions of the data, selecting the essential portions, reviewing the selected data and retrieving additional data leading to the event if necessary. At least one event capture device continuously captures data into a buffer. The data are sent to an event detector communicatively coupled to the event capture device only when the event detector requests them. After receiving the data, the event detector selects and indexes a pre-event portion, during-event portion and post-event portion, combines the portions of captured data into a single driving event record and sends the driving event record to the evaluation server. From the server, the driving event record is sent to the analysis station for review and analysis."/><meta property="og:title" content="Patent US7804426 - System and method for selective review of event data"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("OErsU7-zF8XFggSU_4KwDA"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("BRA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("OErsU7-zF8XFggSU_4KwDA"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("BRA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7804426?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7804426"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=h-yRBgABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7804426&amp;usg=AFQjCNGNFJTUlE6dbeeAVSCKLeaIJSg4yQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7804426.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7804426.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20070260361"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US7804426"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7804426" style="display:none"><span itemprop="description">Systems and methods for computer assisted cueing and selective reviewing of driving data in order to save time in the data review process are provided. The method allows identifying essential portions of the data, selecting the essential portions, reviewing the selected data and retrieving additional...</span><span itemprop="url">http://www.google.com/patents/US7804426?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7804426 - System and method for selective review of event data</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7804426 - System and method for selective review of event data" title="Patent US7804426 - System and method for selective review of event data"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7804426 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 11/566,424</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Sep 28, 2010</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Dec 4, 2006</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">May 8, 2006</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/EP2021208A2">EP2021208A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2021208A4">EP2021208A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2067089A2">EP2067089A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2067089A4">EP2067089A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2084612A1">EP2084612A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2084612A4">EP2084612A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7536457">US7536457</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8373567">US8373567</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070257781">US20070257781</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070257782">US20070257782</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070260361">US20070260361</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070260363">US20070260363</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130197774">US20130197774</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">11566424, </span><span class="patent-bibdata-value">566424, </span><span class="patent-bibdata-value">US 7804426 B2, </span><span class="patent-bibdata-value">US 7804426B2, </span><span class="patent-bibdata-value">US-B2-7804426, </span><span class="patent-bibdata-value">US7804426 B2, </span><span class="patent-bibdata-value">US7804426B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jamie+Etcheson%22">Jamie Etcheson</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Drivecam,+Inc.%22">Drivecam, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7804426.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7804426.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7804426.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (100),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (1),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (4),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (21),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (9)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7804426&usg=AFQjCNH4islaLgSCKzEKe5U32el7LDBJkA">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7804426&usg=AFQjCNEMe08jwp309A4W3HJevceu6_X-aA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7804426B2%26KC%3DB2%26FT%3DD&usg=AFQjCNGHKtn4pOM2sDMzFqn4FiJLq1cBVg">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT97908227" lang="EN" load-source="patent-office">System and method for selective review of event data</invention-title></span><br><span class="patent-number">US 7804426 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA80389211" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">Systems and methods for computer assisted cueing and selective reviewing of driving data in order to save time in the data review process are provided. The method allows identifying essential portions of the data, selecting the essential portions, reviewing the selected data and retrieving additional data leading to the event if necessary. At least one event capture device continuously captures data into a buffer. The data are sent to an event detector communicatively coupled to the event capture device only when the event detector requests them. After receiving the data, the event detector selects and indexes a pre-event portion, during-event portion and post-event portion, combines the portions of captured data into a single driving event record and sends the driving event record to the evaluation server. From the server, the driving event record is sent to the analysis station for review and analysis.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(9)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7804426B2/US07804426-20100928-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7804426B2/US07804426-20100928-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7804426B2/US07804426-20100928-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7804426B2/US07804426-20100928-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7804426B2/US07804426-20100928-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7804426B2/US07804426-20100928-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7804426B2/US07804426-20100928-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7804426B2/US07804426-20100928-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7804426B2/US07804426-20100928-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7804426B2/US07804426-20100928-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7804426B2/US07804426-20100928-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7804426B2/US07804426-20100928-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7804426B2/US07804426-20100928-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7804426B2/US07804426-20100928-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7804426B2/US07804426-20100928-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7804426B2/US07804426-20100928-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7804426B2/US07804426-20100928-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7804426B2/US07804426-20100928-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(33)</span></span></div><div class="patent-text"><div mxw-id="PCLM33102814" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A system for selective reviewing of driving event data, comprising: an event detector coupled with a vehicle, configured to capture and store driving events, each said captured and stored driving event having a pre-event time, a trigger time and a post-event time; an evaluation server configured to receive and store a plurality of said driving events from the event detector and provide said driving events for analysis; and an analysis station comprising a data loading module, a data indexing module, a data control module, and a data playing module, wherein the data loading module is configured to receive the captured driving event from the evaluation server and load the captured driving event for review, the data indexing module is configured to cue up the captured driving event at a selected cue time that is prior to the trigger time, and to adjust the cue time within the range between the pre-event time and the trigger time, and the data playing module is configured to play the cued up driving event from the cue time to the post-event time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the data control module is configured to stop the playing of the cued up driving event, request an adjustment of the cue time, and request the playing of the driving event from a new cue time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the captured driving event comprises information collected from inside the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The system method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the captured driving event comprises information collected from outside the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the captured driving event comprises information from an internal vehicle bus about the baseline noise level of the operating vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the captured driving event comprises video data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the video data comprises stilt images.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the video data comprises moving images.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the captured driving event comprises audio data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the captured driving event comprises metadata.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the event detector further comprises at least one event capture device for capturing driving events.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the event capture device comprises a video camera.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the event capture device comprises a still camera.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the event capture device comprises a microphone.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a plurality of event capture devices communicatively coupled with the event detector and configured to capture and store driving event data, the event detector being configured to receive captured data from selected event capture devices on detection of a driving event.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the event capture devices are selected from a group consisting of: image capture devices, audio data capture devices, and meta data capture devices.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the event capture devices comprise at least a video camera, an audio data capture device, and a meta data capture device.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. A method for selective reviewing of driving event data, comprising: capturing and indexing a driving event at an event detector, wherein the event detector is coupled with a vehicle, and wherein the captured driving event has a trigger time; sending the captured driving event from the event detector to an evaluation sewer; receiving and storing a plurality of said driving events at the evaluation server; sending the captured driving event from the evaluation server to an analysis station; receiving the captured driving event at the analysis station and loading the captured driving event for review; cueing up the captured driving event at a cue time set prior to the trigger time; and playing the cued up driving event from the cue time, further comprising adjusting the cue time within the range between a pre-event time and the trigger time, and playing the captured event from a new cue time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text">19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing information collected from inside the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text">20. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing information collected from outside the vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
      <div class="claim-text">21. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing information collected from an internal vehicle bus about the baseline noise level of the operating vehicle.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
      <div class="claim-text">22. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing still images.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
      <div class="claim-text">23. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing moving images.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00024" num="00024" class="claim">
      <div class="claim-text">24. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing metadata.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00025" num="00025" class="claim">
      <div class="claim-text">25. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing audio data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00026" num="00026" class="claim">
      <div class="claim-text">26. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing data from at least one event capture device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00027" num="00027" class="claim">
      <div class="claim-text">27. The method of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing data from a plurality of event capture devices.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00028" num="00028" class="claim">
      <div class="claim-text">28. The method of <claim-ref idref="CLM-00027">claim 27</claim-ref>, wherein capturing and indexing a driving event comprises capturing and indexing data from at least an image recording device, a microphone, and a meta data capture device.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00029" num="00029" class="claim">
      <div class="claim-text">29. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the event detector indexes the captured driving event with an event trigger time, a selected pre-event start time prior to the trigger time, an event end time, and a post-event end time at a predetermined time interval after the event end time, and the captured driving event comprises pre-event data from the pre-event start time to the trigger time, event data from the trigger time to the event end time, and post-event data from the event end time to the post-event end time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00030" num="00030" class="claim">
      <div class="claim-text">30. The method of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the cue time is at a selected time between the pre-event start time and the trigger time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00031" num="00031" class="claim">
      <div class="claim-text">31. The method of <claim-ref idref="CLM-00029">claim 29</claim-ref>, wherein the event detector further indexes the captured driving event with a post-event time, and the post-event time is a selected time between the event end time and the post-event end time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00032" num="00032" class="claim">
      <div class="claim-text">32. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein capturing and indexing a driving event further comprises the steps of: capturing data in buffers; detecting an event start trigger; identifying buffered data received prior to the event start trigger as pre-event data; identifying buffered data received from the event start trigger until detection of an event end trigger as event data; detecting the event end trigger; and identifying buffered data received after the event end trigger as post-event data.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00033" num="00033" class="claim">
      <div class="claim-text">33. The method of <claim-ref idref="CLM-00032">claim 32</claim-ref>, wherein capturing and indexing a driving event further comprises the step of: combining the pr-event data, event data, and post-event data into a single diving event record.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES38399859" lang="EN" load-source="patent-office" class="description">
    <heading>RELATED APPLICATION</heading> <p num="p-0002">The present application is a continuation-in-part of co-pending U.S. patent application Ser. Nos. 11/382,222 and 11/382,239, filed May 8, 2006; and Ser. Nos. 11/382,325 and 11/382,328, filed May 9, 2006, of concurrent ownership, all of which are incorporated herein by reference in their entirety.</p>
    <heading>BACKGROUND</heading> <p num="p-0003">1. Field of the Invention</p>
    <p num="p-0004">The present invention generally relates to reviewing of driving events and more specifically relates to capturing driving event data and selecting essential parts of the data for review.</p>
    <p num="p-0005">2. Related Art</p>
    <p num="p-0006">Typical systems for review of captured driving event data usually require reviewing of a significant amount of raw data. One of the problems with reviewing voluminous raw data is that it involves reviewing essential as well as non-essential data, and separating essential data from non-essential data (e.g. non-essential pre-event data, etc.). Both, the reviewing and separating of the data can be very time consuming. Since watching the non-essential pre-event data by an operator is usually a waste of time, the review process can be inefficient and time consuming.</p>
    <p num="p-0007">Today, there is no system in place that can efficiently shorten the review process by helping to determine which portion of the captured data is essential, selecting the essential portion of data, cueing the selected data for review, and retrieving additional data leading to the event if it is necessary.</p>
    <p num="p-0008">Accordingly, what is needed is an efficient system and method for selective cueing and reviewing of the driving event data that allow to index playback of the captured data just prior to the beginning of the essential event data so the non-essential data can be skipped during the review.</p>
    <heading>SUMMARY</heading> <p num="p-0009">Accordingly, systems and methods for computer assisted cueing and selective reviewing of event data to save time in the data review process are provided.</p>
    <p num="p-0010">In one aspect, the system for selective review of event data comprises at least one event capture device, an event detector, an evaluation server and an analysis station. The event capture device continuously captures driving event data in a buffer. While capturing the data, the event capture device also checks the status of a trigger which can be set by the event detector to either on or off. If the trigger is on, the event capture device sends driving event data to the event detector continuously. If the trigger is off, the event capture device only keeps capturing event data and filling the buffer, and writing over the previously captured data when the buffer is full.</p>
    <p num="p-0011">In one aspect, when a driving event starts, an operator sends an event trigger to the event detector, or a detector configured to detect a driving event which potentially requires evaluation sends a trigger to the event detector. Upon receiving the trigger, the event detector passes the trigger to at least one event capture device. In response to the trigger, the event capture device sends data to the event detector.</p>
    <p num="p-0012">In one aspect, the event detector collects three types of data: pre-event data, event data and post-event data. The event detector then indexes the beginning and end of the pre-event data, event data and post-event data.</p>
    <p num="p-0013">In one aspect, the event detector combines the pre-event data, during-event data and post-event data into a single driving event and stores the events in the evaluation server. From the server, the data are sent to the analysis station where they are cued, reviewed and analyzed.</p>
    <p num="p-0014">Other features and advantages of the present invention will become more readily apparent to those of ordinary skill in the art after reviewing the following detailed description and accompanying drawings.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0015">The details of the present invention, both as to its structure and operation, may be gleaned in part by study of the accompanying drawings, in which like reference numerals refer to like parts, and in which:</p>
      <p num="p-0016"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram illustrating an example event detector in control of a plurality of event capture devices deployed in a vehicle according to an embodiment of the present invention;</p>
      <p num="p-0017"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a block diagram illustrating an example event detector according to an embodiment of the present invention;</p>
      <p num="p-0018"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a block diagram illustrating an example event according to an embodiment of the present invention;</p>
      <p num="p-0019"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a block diagram illustrating an example of captured driving event data according to an embodiment of the present invention;</p>
      <p num="p-0020"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a network diagram illustrating an example system for selective reviewing of driving event data according to an embodiment of the present invention;</p>
      <p num="p-0021"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a block diagram illustrating an example analysis station according to an embodiment of the present invention;</p>
      <p num="p-0022"> <figref idrefs="DRAWINGS">FIG. 7A</figref> is a flow diagram illustrating an example process for capturing driving data according to an embodiment of the present invention;</p>
      <p num="p-0023"> <figref idrefs="DRAWINGS">FIG. 7B</figref> is a flow diagram illustrating an example process for receiving, combining and storing driving data according to an embodiment of the present invention;</p>
      <p num="p-0024"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a flow diagram illustrating an example process for cueing and playing driving event data according to an embodiment of the present invention;</p>
      <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a block diagram illustrating an exemplary wireless communication device that may be used in connection with the various embodiments described herein; and</p>
      <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a block diagram illustrating an exemplary computer system as may be used in connection with various embodiments described herein.</p>
    </description-of-drawings> <heading>DETAILED DESCRIPTION</heading> <p num="p-0027">Certain embodiments as disclosed herein provide for systems and methods for computer assisted cueing and selective reviewing of driving data in order to save time in the review process. For example, the method for selective cueing and reviewing of the driving events allows an operator to select a part of the captured driving event data, review the data and, if it is needed, retrieve more data leading to the event.</p>
    <p num="p-0028">In one embodiment, the system for selective reviewing of driving event data comprises an event detector coupled with a vehicle, an evaluation server, an analysis station and at least one event capture device. The event capture device captures driving event data and sends the data to the event detector upon receiving a request from the event detector. The event detector is configured to receive, index and store driving events. The events data are indexed using a pre-event time index, a trigger time index, and a post-event time index. The evaluation server receives driving events from the event detector, stores them and provides them to the analysis station where the data are cued, reviewed and analyzed.</p>
    <p num="p-0029">In one embodiment, the analysis station comprises a data loading module, a data indexing module, a data control module, and a data playing module. The data loading module is configured to receive the driving event data from the evaluation server and load the data for review. The data indexing module is configured to cue up the driving event at a cue time set substantially close, but prior to the trigger time. The data playing module is configured to play the driving event from the cue time to the post-event time.</p>
    <p num="p-0030">In one embodiment, the method for selective reviewing of driving event data comprises capturing and indexing a driving event at an event detector, sending the driving event from the event detector to an evaluation server, receiving and storing a plurality of driving events at the evaluation server, sending the driving event from the evaluation server to an analysis station, receiving the driving event at the analysis station and loading the driving event for review. Once the driving event data are cued, the data are played from the cue time to the end of the event data (indexed by the post-event time).</p>
    <p num="p-0031">After reading this description it will become apparent to one skilled in the art how to implement the invention in various alternative embodiments and alternative applications. However, although various embodiments of the present invention will be described herein, it is understood that these embodiments are presented by way of example only, and not limitation. As such, this detailed description of various alternative embodiments should not be construed to limit the scope or breadth of the present invention as set forth in the appended claims.</p>
    <p num="p-0032"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram illustrating an example event detector <b>30</b> in control of a plurality of event capture devices <b>20</b> deployed in a vehicle <b>10</b> according to an embodiment of the present invention. In the illustrated embodiment, the event detector <b>30</b> is integrated with the vehicle <b>10</b> and is communicatively coupled with the event capture devices <b>20</b>. The event detector <b>30</b> is also configured with data storage <b>35</b>.</p>
    <p num="p-0033">The event detector <b>30</b> can be any of a variety of types of computing devices with the ability to execute programmed instructions, receive input from various sensors, and communicate with one or more internal or external event capture devices <b>20</b> and other external devices (not shown). An example of a general purpose computing device that may be employed as all or a portion of an event detector <b>30</b> is later described with respect to <figref idrefs="DRAWINGS">FIG. 10</figref>.</p>
    <p num="p-0034">In one embodiment, the event detector <b>30</b> monitors its sensor to detect a driving event. When the event detector <b>30</b> detects a sensor output or trigger indicting the start of a driving event, the event detector <b>30</b> instructs one or more event capture devices <b>20</b> to send pre-event data, during the event data, and post-event data to the event detector <b>30</b>. Then, the event detector <b>30</b> stores the data in the data storage area <b>35</b> as an event. Events may comprise a variety of situations, including automobile accidents, reckless driving, rough driving, or any other type of stationary or moving occurrence that the owner of a vehicle <b>10</b> may desire to know about.</p>
    <p num="p-0035">The vehicle <b>10</b> may have a plurality of event capture devices <b>20</b> placed in various locations around the vehicle <b>10</b>. An event capture device <b>20</b> may comprise a video camera, still camera, microphone, and other types of data capture devices. For example, an event capture device <b>20</b> may include an accelerometer that senses changes in speed or direction. Additional sensors and/or data capture devices may also be incorporated into an event capture device <b>20</b> in order to provide a rich set of information about a detected event.</p>
    <p num="p-0036">The data storage area <b>35</b> can be any sort of internal or external, fixed or removable memory device and may include both persistent and volatile memories. The function of the data storage area <b>35</b> is to maintain data for long term storage and also to provide efficient and fast access to instructions, applications and/or modules that are executed by the event capture device <b>30</b>.</p>
    <p num="p-0037">In one embodiment, the event detector <b>30</b> in combination with the one or more event capture devices <b>20</b> identifies an event and stores certain audio and video data along with related information about the event. For example, related information may include the speed of the vehicle when the event occurred, the direction the vehicle was traveling, the location of the vehicle (e.g., from a global positioning system (GPS) sensor), and other information from sensors located in and around the vehicle or from the vehicle itself (e.g., from a data bus integral to the vehicle such as a J-1850 vehicle bus). This combination of audio, video, and other data is compiled into one event. The event can be stored in data storage <b>35</b> onboard the vehicle for later delivery to an evaluation server.</p>
    <p num="p-0038"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a block diagram illustrating an example event detector <b>30</b> according to an embodiment of the present invention. In the illustrated embodiment, the event detector <b>30</b> comprises an audio/video (AV) module <b>100</b>, a sensor module <b>110</b>, a communication module <b>120</b>, and a control module <b>130</b>. Additional modules may also be employed to carry out the various functions of the event detector <b>30</b>, as will be understood by those having skill in the art.</p>
    <p num="p-0039">In one embodiment, the AV module <b>100</b> is configured to manage the audio and video input from one or more event capture devices and storage of the audio and video input. The sensor module <b>110</b> is configured to manage one or more sensors that can be integral to the event detector <b>30</b> or external from the event detector <b>30</b>. For example, an accelerometer may be integral to the event detector <b>30</b> or it may be located elsewhere in the vehicle. The sensor module <b>110</b> may also manage other types of sensor devices such as a GPS sensor, temperature sensor, moisture sensor, or the like (all not shown).</p>
    <p num="p-0040">The communication module <b>120</b> can be configured to manage communications between the event detector <b>30</b> and other devices and modules. For example, the communication module <b>120</b> may handle communications between the event detector <b>30</b> and the various event capture devices. The communication module <b>120</b> may also handle communications between the event detector <b>30</b> and a memory device, a docking station, or a server such as an evaluation server. The communication module <b>120</b> is configured to communicate with these various types of devices and other types of devices via a direct wire link (e.g., USB cable, firewire cable), a direct wireless link (e.g., infrared, Bluetooth), or a wired or wireless network link such as a local area network (LAN), a wide area network (WAN), a wireless wide area network (WWAN), or an IEEE 802 wireless network such as an IEEE 802.16 (WiFi) network.</p>
    <p num="p-0041">The control module <b>130</b> can be configured to control the actions or remote devices such as the one or more event capture devices. For example, the control module <b>130</b> may be configured to instruct the event capture devices to capture an event and return the data to the event detector when it is informed by the sensor module <b>110</b> that certain trigger criteria have been met that identify an event.</p>
    <p num="p-0042"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a block diagram illustrating an example event <b>150</b> according to an embodiment of the present invention. In the illustrated embodiment, the event <b>150</b> comprises audio data <b>160</b>, video data <b>170</b>, and metadata <b>180</b>. Audio data <b>160</b> can be collected from inside the vehicle, outside the vehicle, and may include information from an internal vehicle bus about the baseline noise level of the operating vehicle, if such information is available. Additional information about baseline noise level, radio noise level, conversation noise level, or external noise level may also be included in audio data <b>160</b>.</p>
    <p num="p-0043">Video data <b>170</b> may include still images or moving video captured by one or more cameras in various locations in and around the vehicle. Video data <b>170</b> may include images or video from inside the vehicle, outside the vehicle, or both. In one particularly advantageous embodiment, still images and moving video that illustrate the entire area inside the vehicle and the entire 360 degree area surrounding the vehicle are captured by a plurality of image capture devices and included in video data <b>170</b>.</p>
    <p num="p-0044">Metadata <b>180</b> may include a variety of additional information that is available to the event detector at the time of an event. Such additional data may include the velocity and direction of the vehicle, the GPS location of the vehicle, elevation, time, temperature, and vehicle engine and electrical component information captured from an internal vehicle bus, just to name a few. Additional information may also be included such as the number of occupants in the vehicle, whether seatbelts were fastened, whether airbags deployed, and whether evasive maneuvering was attempted as determined by the route of the vehicle prior to the event. As will be understood by those skilled in the art, metadata <b>180</b> may include an extremely rich variety of information limited only by the scope and type of information obtained prior to, during, and after an event.</p>
    <p num="p-0045"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a block diagram illustrating an example of captured driving event data or driving event record <b>505</b> according to an embodiment of the present invention. In the illustrated embodiment, the captured event data <b>505</b> comprises audio data <b>160</b>, video data <b>170</b>, and metadata <b>180</b>.</p>
    <p num="p-0046">In one embodiment, the event detector receives buffers of the captured event data <b>505</b>. The length of a buffer may vary. In the illustrated embodiment, the buffer can capture ninety seconds of data.</p>
    <p num="p-0047">The captured event data <b>505</b> may comprise three data segments: pre-event data <b>502</b>, event data <b>504</b> and post-event data <b>506</b>. Although the three data segments are the same length in the illustrated embodiment, they may be of different lengths in other embodiments. The pre-event data <b>502</b> comprises the data captured just before the driving event was triggered. The event data <b>504</b> comprises the driving event data captured from the beginning of the event to the end of the event. The post-event data <b>506</b> comprises the data captured after the driving event ended.</p>
    <p num="p-0048">In one embodiment, the event detector is configured to create metadata tags, and use those tags to index the beginning and the end of the pre-event data, event data and post-event data. For example, the beginning of the pre-event data can be indexed with a pre-event time tag set to the beginning of the pre-event data, whereas the end of the pre-event data can be indexed with a trigger time tag set to the end of the pre-event data. Similarly, the beginning of the event data can be indexed with the trigger time tag set to the beginning of the event data, whereas the end of the event data can be indexed with an end time tag set to the end of the event data. Correspondingly, the beginning of a post-event data can be indexed with the end time tag set to the beginning of the event data, whereas the end of the post-event data can be indexed with a post-event time tag set to the end of the post-event data.</p>
    <p num="p-0049">In one embodiment, the event detector is configured to concatenate a number of data buffers. For example, the event detector can concatenate pre-event data with event data and with post-event data.</p>
    <p num="p-0050">In the embodiment illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>, a captured driving event or driving event record <b>505</b> comprises three consecutive buffers of collected data. Each buffer is indexed using metadata tags and then concatenated to form the event <b>505</b>. More specifically, the pre-event data <b>502</b> was collected during a period of time which started at a pre time (indicated as t<sub>(pre)</sub>) and ended at the trigger time (indicated as t<sub>(trigger)</sub>). Similarly, the event data <b>504</b> was collected during a period of time which started at the trigger time (indicated as t<sub>(trigger)</sub>) and ended at an end time (indicated as t<sub>(end)</sub>). Correspondingly, the post-event data <b>506</b> was collected during a period of time which started at the end time (indicated as t<sub>(end)</sub>) of the event data and ended at a post time (indicated as t<sub>(post)</sub>). Then, the pre-event data <b>502</b> was concatenated with the event data <b>504</b> and with the event data <b>506</b>.</p>
    <p num="p-0051"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a network diagram illustrating an example system for selective reviewing of driving event data in communication via a network according to an embodiment of the present invention. In the illustrated embodiment, the system includes an event detector <b>30</b>, an evaluation server <b>50</b>, and an analysis station <b>60</b>, each communicating with another via a network <b>76</b>, and each coupled with a data storage area <b>35</b>, <b>55</b>, and <b>65</b>, respectively. Additional event detectors <b>30</b>, evaluation servers <b>50</b>, and analysis stations <b>60</b> may also be included.</p>
    <p num="p-0052">The function of the event detector <b>30</b> is to identify and capture a plurality of events and send data structures representing the audio, video, and other related data, collectively called an event, to the evaluation server <b>50</b>. The evaluation server maintains the captured events and provides them to the analysis station <b>60</b> where the events are reviewed. The analysis station <b>60</b> may be configured with certain hardware and software modules that allow an operator to review event data (e.g., audio, video, and metadata) in order to make an analysis related to the event and create summary reports and the like.</p>
    <p num="p-0053">After an event is reviewed, it may be discarded, flagged for follow up, flagged for inclusion in one or more reports, or otherwise maintained for later reporting or analysis. In one embodiment; certain portions of one or more events may be incorporated into a report and then sent to the evaluation server <b>50</b> for storage.</p>
    <p num="p-0054">In one embodiment, an event <b>150</b> is captured by an event detector <b>30</b> and stored until it is provided to the evaluation server <b>50</b>. The means by which an event <b>150</b> can be provided to the evaluation server <b>50</b> can vary. For example, an event <b>150</b> may be provided from event detector <b>30</b> to the evaluation server <b>50</b> by way of a portable media device, a direct wire link, a direct wireless link, an indirect wire link, an indirect wireless link, or any combination of these. Event <b>150</b> may be secured by encryption of the event data structure and/or a secure channel between the event detector <b>30</b> and the evaluation server <b>50</b>.</p>
    <p num="p-0055">For example, a portable media device may include a USB drive, compact disc, thumb drive, media card, or other similar type of device. A direct wire link may include a USB cable, a firewire cable, an RS-232 cable, or the like. A direct wireless link may include an infrared link, a Bluetooth link, or an IEEE 802.11 point-to-point link, just to name a few. An indirect wired link may include a packet switched or circuit switched network connection configured for conveyance of data traffic. An Ethernet network connection is an example of a packet switched indirect wired link and a dial up modem connection is an example of a circuit switched indirect wired link, both of which may be configured for conveyance of data traffic.</p>
    <p num="p-0056">In the illustrated embodiment, the event <b>150</b> travels over the network <b>76</b> from the event detector <b>30</b> to the evaluation server <b>50</b>. The network <b>76</b> may comprise any of a variety of network types and topologies and any combination of such types and topologies. For example, the network <b>76</b> may comprise a plurality of networks including private, public, circuit switched, packet switched, personal area networks (PAN), local area networks (LAN), wide area networks (WAN), metropolitan area networks (MAN), or any combination of these. The network <b>76</b> may also include that particular combination of networks universally known as the Internet.</p>
    <p num="p-0057">The event <b>150</b> may travel to the wireless network <b>76</b> by way of an access point (not shown) and then on to the evaluation server <b>50</b> via the wireless network <b>76</b> in one embodiment. The access point may provide access via many different wireless network protocols as will be well understood by those having skill in the art. The wireless network may be a WWAN or a WiFi network. The link between the event detector <b>30</b> and the access point may be a short range direct link or a wide range direct link. The access point may be a large radio tower device or a small in-home wireless appliance. The wireless network <b>76</b> may include over the air segments and also wired segments. For example, the last mile segments of wireless network may be over the air while internal and back end segments may be wired segments. In one embodiment, the wireless network <b>76</b> may provide a wireless interface to the event detector and then have a wired interface on the back end to the Internet, which in turn connects to the evaluation server <b>50</b>.</p>
    <p num="p-0058">In one embodiment, an event <b>150</b> may be provided from the event detector <b>30</b> to a docking station, (not shown) then to the network <b>76</b>, and then to the evaluation server <b>50</b>. Providing the event <b>150</b> from the event detector <b>30</b> to the docking station can be accomplished via a variety of means as described above, including portable media, direct wired or wireless link, and indirect wired or wireless link. The event detector <b>30</b> may also be physically coupled with the docking station to convey the event <b>150</b> from the event detector <b>30</b> to the docking station. Once the event <b>150</b> is received by the docking station, the event <b>150</b> is sent over the network <b>76</b> to the evaluation server <b>50</b>.</p>
    <p num="p-0059">The network <b>76</b> may be a wired or wireless network or a combination of the two. The network <b>76</b> may also be private or public in whole or in part and may also include the Internet.</p>
    <p num="p-0060">In one embodiment, the evaluation server <b>50</b> is configured to save the event data in a data buffer, create groups of events, and concatenate data from a number of data buffers.</p>
    <p num="p-0061">The event detector <b>30</b> may be configured to create metadata tags and assign them to a variety of points in one embodiment. A metadata tag correlates to a particular moment in time and can be linked to a corresponding portion of a video and/or audio buffer. For example, for a given event, one metadata tag can be assigned to the beginning of the event, and another metadata tag can be assigned to the end of the event.</p>
    <p num="p-0062">In one embodiment, a group of events <b>152</b> traveling from the evaluation server <b>50</b> can be routed to the analysis station <b>60</b>. The means by which the group of events <b>152</b> can be provided to the analysis station <b>60</b> can vary. In various embodiments (or in a single embodiment), the group of events <b>152</b> can be provided by the evaluation server <b>50</b> to the analysis station <b>60</b> via the network <b>76</b>.</p>
    <p num="p-0063">The group of events <b>152</b> may be identified, for example, by searching for all events that pertain to a particular driver. This may be accomplished by associating each event at the time it is captured with a particular driver. For example, the driver of a vehicle may have a unique identifier and that unique identifier may be included as part of the metadata for each event that is captured while that driver is operating the vehicle.</p>
    <p num="p-0064">Groups of events <b>152</b> may also be identified by all events associated with a particular company, a particular shift, a particular supervisor, or other reporting structure or working structure combinations. Such a group of events <b>152</b>, once provided to the analysis station <b>60</b>, can then be analyzed by an operator who reviews each event and identifies those events that need to be reported or shown to the driver.</p>
    <p num="p-0065"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a block diagram illustrating an example analysis station <b>60</b> according to an embodiment of the present invention. In the illustrated embodiment, the analysis station <b>60</b> includes a data control module <b>62</b>, a data loading module <b>64</b>, a data indexing module <b>66</b> and a data playing module <b>68</b>.</p>
    <p num="p-0066">The function of the data control module <b>62</b> is to receive a driving event from the evaluation server, identify a trigger time in the metadata associated with the event and send the driving event to the data loading module <b>64</b>. The data loading module <b>64</b> loads the driving event data to a playing device for review.</p>
    <p num="p-0067">Before the data are played, the data have to be properly cued by the data indexing module <b>66</b>. The data indexing module <b>66</b> determines the cue point for the cueing of the driving event by selecting a cue interval and computing the cue point in time. As a first approximation, the data indexing module <b>66</b> presets the cue interval to a relatively small time interval, such as, e.g. 2 seconds. Then, the data indexing module <b>66</b> determines the cue point by subtracting in time the cue interval from the trigger time.</p>
    <p num="p-0068">In one embodiment, the cue point is adjusted until the playing of the driving event starts at a desired point in time. The adjusting of the cue point time can be an iterative process. It can involve a repetitive adjustment of the cue interval and a repetitive recalculation of the new cue point.</p>
    <p num="p-0069">The main function of the data playing module <b>68</b> is to play the event for review. The data playing module <b>68</b> plays the data from the cue point to the end of event data or until an operator stops the playing.</p>
    <p num="p-0070"> <figref idrefs="DRAWINGS">FIG. 7A</figref> is a flow diagram illustrating an example process for capturing driving data according to an embodiment of the present invention. In the illustrated embodiment, the event capture device continuously captures driving data, puts the data in a buffer, and sends the data to the event detector if the event detector requests that.</p>
    <p num="p-0071">At a step <b>510</b>, the event capture device receives data. The data is captured continuously by filling the data buffer with incoming data starting from the beginning of the buffer to the end of the buffer.</p>
    <p num="p-0072">At a step <b>511</b>, the event capture device monitors a trigger to find out whether the event detector requested the data. As soon as a trigger or request is received from the event detector asking the event capture device to send captured data, the event capture device sends the contents of the buffer to the event detector (step <b>512</b>), and continues to send buffers of captured data to the event capture device until the event detector asks it to stop. If no trigger or request to send data is received and the buffer is full, the event capture device continues to capture data by overwriting the buffer with new data (step <b>510</b>).</p>
    <p num="p-0073">The length of the buffer may vary. In one embodiment, the size of the buffer allows storing of ninety seconds of video data, audio data, or meta data.</p>
    <p num="p-0074">At a step <b>512</b>, the event capture device sends the whole buffer of data to the event detector after receiving a request or trigger. As soon as the buffer is sent, the event capture device proceeds to overwrite the bits and bytes of the buffer with new data, in step <b>510</b>, and sends the next buffer of data to the event detector unless a request to stop sending data is received.</p>
    <p num="p-0075"> <figref idrefs="DRAWINGS">FIG. 7B</figref> is a flow diagram illustrating an example process for receiving, combining and storing driving data at an event detector according to an embodiment of the present invention. In the illustrated embodiment, once the event detector detects a driving event or receives an event trigger, the event detector requests data from at least one event capture device, receives buffers with data from the event capture device, indexes appropriate portions of data as pre-event data, during-event data and post-event data, and concatenates the portions into one event. For example, for a given driving event, the event detector can concatenate pre-event data, during-the-event data and post-event data into a single driving event. The trigger which indicates the start of a driving event which may require analysis may be based on the output of a g-force sensor, audio data, or application of a brake pedal or the like. In one embodiment, the event detector may monitor for a predetermined output or event trigger from a sensor or the like, and on receipt of this output sends a trigger or request to one or more event capture devices to send data captured in their buffers to the event detector, and stores the time of receipt of the trigger as the event trigger time.</p>
    <p num="p-0076">At a step <b>514</b>, the event detector receives a trigger at time t<sub>trigger</sub>. A request is then sent to one or more event capture devices to send captured data (step <b>515</b>). The captured data in the buffer includes pre-event data, i.e. the data that the event capture device had stored in the buffer prior to the trigger time.</p>
    <p num="p-0077">The event detector then receives buffers of captured data from the event capture device (step <b>516</b>), or several event capture devices when the event detector has instructed more than one device to send its captured data. At a step <b>517</b>, the event detector stores its own buffer with pre-event data and assigns a meta tag t<sub>(pre)</sub> to the beginning of the pre-event data and a meta tag t<sub>(trigger)</sub> to the end of the pre-event data.</p>
    <p num="p-0078">At a step <b>518</b>, the event detector stores received event data (i.e. data received from the event capture devices starting at the trigger time t<sub>(trigger)</sub>) and assigns the meta tag t<sub>(trigger)</sub> to the beginning of the event data. While collecting event data, the event detector continuously monitors the trigger status (<b>520</b>), and continues to store event data while the trigger remains on. The trigger state changes to off when the driving event is over (i.e. the trigger conditions are no longer in effect, or a sensor output or end trigger indicates that the event is at an end, or a predetermined time period has expired). The actual event duration may be controlled by an ON and OFF trigger status, i.e. the event detector requests data from event capture devices when the trigger status changes to ON, and assigns an end time to the event when the trigger status changes to OFF. At this point, the event detector assigns a meta tag t<sub>(end)</sub> to the end of the event data, and continues to store and receive post-event data from the or each event capture device for a predetermined time period (step <b>522</b>). In step <b>522</b>, the event detector stores one or more buffers with the post-event data and assigns the meta tag t<sub>(end)</sub> to the beginning of the post-event data and a meta tag t<sub>(post)</sub> to the end of the post-event data. When the desired amount of post event data has been received by the event detector, the event capture device is instructed to stop sending data (step <b>524</b>). This may done by changing a trigger status to OFF. It will be understood that any desired pre-event and post-event time period may be selected for completing the captured driving event</p>
    <p num="p-0079">The data are indexed in steps <b>517</b>, <b>518</b> and <b>522</b> as follows: the beginning and the end of the pre-event data are indexed by meta-tags t<sub>(pre)</sub> and t<sub>(trigger)</sub>, the beginning and the end of the event data are indexed by meta-tags t<sub>(trigger)</sub> and t<sub>(end)</sub>, and the beginning and the end of the post-event data are indexed by meta-tags t<sub>(end)</sub> and t<sub>(post)</sub>.</p>
    <p num="p-0080">At a step <b>526</b>, the event detector combines the pre-event data, during-the-event-data and post-event data with the appropriate metadata tags into a single event record. Then, at a step <b>528</b>, the event detector sends the single event record to the evaluation server. The buffers are concatenated as it was described in <figref idrefs="DRAWINGS">FIG. 4</figref>.</p>
    <p num="p-0081"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a flow diagram illustrating an example process for cueing and playing driving event data according to an embodiment of the present invention. In the illustrated embodiment, an analysis station loads the captured driving event data to a playing device, cues the data and plays the data for review. If necessary, the driving data may be iteratively re-cued and re-played until the review is completed.</p>
    <p num="p-0082">At a step <b>550</b>, the analysis station loads the captured driving event data to a playing device for review. The concatenated captured driving event data may comprise the pre-event data, during-the-event data and post-event data.</p>
    <p num="p-0083">At a step <b>552</b>, the analysis station sets a cue interval. The cue interval is a leading time used to determine how many seconds of pre-event data are going to be played before the playing of the during-the-event data starts. The size of the cue interval depends on the type of the driving event and the circumstances of the review. Usually, at first, the cue interval is ad hoc selected to be a small period of time, and later it is refined to a more accurate time interval. For example, the cue interval may be at first set to two seconds. If the two-second-cue interval is acceptable, the last two seconds of the pre-event data are going to be played before the playing of the event data. In an alternative embodiment, the cue interval may be set to a period of time measured in minutes, etc.</p>
    <p num="p-0084">At a step <b>554</b>, the analysis station determines the cue point for the playing of the captured driving event data. The cue point is computed by subtracting the cue interval from the trigger time. For example, if the cue interval is two seconds, then the cue point is set to two seconds prior to the trigger time.</p>
    <p num="p-0085">At a step <b>556</b>, the analysis station initiates the playing of the captured event data starting from the cue point. Then, if a reviewer requests that the data be backed off (step <b>558</b>), the analysis station increases the cue interval (step <b>570</b>), adjusts the cue point to reflect the new cue interval (step <b>554</b>), and restarts the playback from the new cue point (step <b>556</b>).</p>
    <p num="p-0086">The process of adjusting the cue point and playing back is repeated until further adjustments of the cue point are unnecessary. Once that is achieved, at step <b>560</b>, the playing of the captured driving event data is continued until the end of the driving event or until an operator stops the playing. For example, the operator may want to view at least part of the post-event data <b>506</b> before stopping the playback.</p>
    <p num="p-0087"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a block diagram illustrating an exemplary wireless communication device <b>650</b> that may be used in connection with the various embodiments described herein. For example, the wireless communication device <b>650</b> may be used in conjunction with an event detector previously described with respect to <figref idrefs="DRAWINGS">FIGS. 1-2</figref>, or an evaluation server or an analysis station previously described with respect to <figref idrefs="DRAWINGS">FIGS. 5-6</figref>. However, other wireless communication devices and/or architectures may also be used, as will be clear to those skilled in the art.</p>
    <p num="p-0088">In the illustrated embodiment, wireless communication device <b>650</b> comprises an antenna <b>652</b>, a multiplexor <b>654</b>, a low noise amplifier (LNA) <b>656</b>, a power amplifier (PA) <b>658</b>, a modulation circuit <b>660</b>, a baseband processor <b>662</b>, a speaker <b>664</b>, a microphone <b>666</b>, a central processing unit (CPU) <b>668</b>, a data storage area <b>670</b>, and a hardware interface <b>672</b>. In the wireless communication device <b>650</b>, radio frequency (RF) signals are transmitted and received by antenna <b>652</b>. Multiplexor <b>654</b> acts as a switch, coupling antenna <b>652</b> between the transmit and receive signal paths. In the receive path, received RF signals are coupled from a multiplexor <b>654</b> to LNA <b>656</b>. LNA <b>656</b> amplifies the received RF signal and couples the amplified signal to a demodulation portion of the modulation circuit <b>660</b>.</p>
    <p num="p-0089">Typically modulation circuit <b>660</b> combines a demodulator and modulator in one integrated circuit (IC). The demodulator and modulator can also be separate components. The demodulator strips away the RF carrier signal leaving a base-band receive audio signal, which is sent from the demodulator output to the base-band processor <b>662</b>.</p>
    <p num="p-0090">If the base-band receive audio signal contains audio information, then base-band processor <b>662</b> decodes the signal and converts it to an analog signal. Then the signal is amplified and sent to the speaker <b>664</b>. The base-band processor <b>662</b> also receives analog audio signals from the microphone <b>666</b>. These analog audio signals are converted to digital signals and encoded by the base-band processor <b>662</b>. The base-band processor <b>662</b> also codes the digital signals for transmission and generates a base-band transmit audio signal that is routed to the modulator portion of modulation circuit <b>660</b>. The modulator mixes the base-band transmit audio signal with an RF carrier signal generating an RF transmit signal that is routed to the power amplifier <b>658</b>. The power amplifier <b>658</b> amplifies the RF transmit signal and routes it to the multiplexor <b>654</b> where the signal is switched to the antenna port for transmission by antenna <b>652</b>.</p>
    <p num="p-0091">The baseband processor <b>662</b> is also communicatively coupled with the central processing unit <b>668</b>. The central processing unit <b>668</b> has access to a data storage area <b>670</b>. The central processing unit <b>668</b> is preferably configured to execute instructions (i.e., computer programs or software) that can be stored in the data storage area <b>670</b>. Computer programs can also be received from the baseband processor <b>662</b> and stored in the data storage area <b>670</b> or executed upon receipt. Such computer programs, when executed, enable the wireless communication device <b>650</b> to perform the various functions of the present invention as previously described.</p>
    <p num="p-0092">In this description, the term computer readable medium is used to refer to any media used to provide executable instructions (e.g., software and computer programs) to the wireless communication device <b>650</b> for execution by the central processing unit <b>668</b>. Examples of these media include the data storage area <b>670</b>, microphone <b>666</b> (via the baseband processor <b>662</b>), antenna <b>652</b> (also via the baseband processor <b>662</b>), and hardware interface <b>672</b>. These computer readable mediums are means for providing executable code, programming instructions, and software to the wireless communication device <b>650</b>. The executable code, programming instructions, and software, when executed by the central processing unit <b>668</b>, preferably cause the central processing unit <b>668</b> to perform the inventive features and functions previously described herein.</p>
    <p num="p-0093">The central processing unit is also preferably configured to receive notifications from the hardware interface <b>672</b> when new devices are detected by the hardware interface. Hardware interface <b>672</b> can be a combination electromechanical detector with controlling software that communicates with the CPU <b>668</b> and interacts with new devices.</p>
    <p num="p-0094"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a block diagram illustrating an exemplary computer system <b>750</b> that may be used in connection with the various embodiments described herein. For example, the computer system <b>750</b> may be used in conjunction with an event detector previously described with respect to <figref idrefs="DRAWINGS">FIGS. 1-2</figref>, or an evaluation server or an analysis station previously described with respect to <figref idrefs="DRAWINGS">FIGS. 5-6</figref>. However, other computer systems and/or architectures may be used, as will be clear to those skilled in the art.</p>
    <p num="p-0095">The computer system <b>750</b> preferably includes one or more processors, such as processor <b>752</b>. Additional processors may be provided, such as an auxiliary processor to manage input/output, an auxiliary processor to perform floating point mathematical operations, a special-purpose microprocessor having an architecture suitable for fast execution of signal processing algorithms (e.g., digital signal processor), a slave processor subordinate to the main processing system (e.g., back-end processor), an additional microprocessor or controller for dual or multiple processor systems, or a coprocessor. Such auxiliary processors may be discrete processors or may be integrated with the processor <b>752</b>.</p>
    <p num="p-0096">The processor <b>752</b> is preferably connected to a communication bus <b>754</b>. The communication bus <b>754</b> may include a data channel for facilitating information transfer between storage and other peripheral components of the computer system <b>750</b>. The communication bus <b>754</b> further may provide a set of signals used for communication with the processor <b>752</b>, including a data bus, address bus, and control bus (not shown). The communication bus <b>754</b> may comprise any standard or non-standard bus architecture such as, for example, bus architectures compliant with industry standard architecture (ISA), extended industry standard architecture (EISA), Micro Channel Architecture (MCA), peripheral component interconnect (PCI) local bus, or standards promulgated by the Institute of Electrical and Electronics Engineers (IEEE) including IEEE 488 general-purpose interface bus (GPIB), IEEE 696/S-100, and the like.</p>
    <p num="p-0097">Computer system <b>750</b> preferably includes a main memory <b>756</b> and may also include a secondary memory <b>758</b>. The main memory <b>756</b> provides storage of instructions and data for programs executing on the processor <b>752</b>. The main memory <b>756</b> is typically semiconductor-based memory such as dynamic random access memory (DRAM) and/or static random access memory (SRAM). Other semiconductor-based memory types include, for example, synchronous dynamic random access memory (SDRAM), Rambus dynamic random access memory (RDRAM), ferroelectric random access memory (FRAM), and the like, including read only memory (ROM).</p>
    <p num="p-0098">The secondary memory <b>758</b> may optionally include a hard disk drive <b>760</b> and/or a removable storage drive <b>762</b>, for example a floppy disk drive, a magnetic tape drive, a compact disc (CD) drive, a digital versatile disc (DVD) drive, etc. The removable storage drive <b>762</b> reads from and/or writes to a removable storage medium <b>764</b> in a well-known manner. Removable storage medium <b>764</b> may be, for example, a floppy disk, magnetic tape, CD, DVD, etc.</p>
    <p num="p-0099">The removable storage medium <b>764</b> is preferably a computer readable medium having stored thereon computer executable code (i.e., software) and/or data. The computer software or data stored on the removable storage medium <b>764</b> is read into the computer system <b>750</b> as electrical communication signals <b>778</b>.</p>
    <p num="p-0100">In alternative embodiments, secondary memory <b>758</b> may include other similar means for allowing computer programs or other data or instructions to be loaded into the computer system <b>750</b>. Such means may include, for example, an external storage medium <b>772</b> and an interface <b>770</b>. Examples of external storage medium <b>772</b> may include an external hard disk drive or an external optical drive, or an external magneto-optical drive.</p>
    <p num="p-0101">Other examples of secondary memory <b>758</b> may include semiconductor-based memory such as programmable read-only memory (PROM), erasable programmable read-only memory (EPROM), electrically erasable read-only memory (EEPROM), or flash memory (block oriented memory similar to EEPROM). Also included are any other removable storage units <b>772</b> and interfaces <b>770</b>, which allow software and data to be transferred from the removable storage unit <b>772</b> to the computer system <b>750</b>.</p>
    <p num="p-0102">Computer system <b>750</b> may also include a communication interface <b>774</b>. The communication interface <b>774</b> allows software and data to be transferred between computer system <b>750</b> and external devices (e.g. printers), networks, or information sources. For example, computer software or executable code may be transferred to computer system <b>750</b> from a network server via communication interface <b>774</b>. Examples of communication interface <b>774</b> include a modem, a network interface card (NIC), a communications port, a PCMCIA slot and card, an infrared interface, and an IEEE 1394 fire-wire, just to name a few.</p>
    <p num="p-0103">Communication interface <b>774</b> preferably implements industry promulgated protocol standards, such as Ethernet IEEE 802 standards, Fiber Channel, digital subscriber line (DSL), asynchronous digital subscriber line (ADSL), frame relay, asynchronous transfer mode (ATM), integrated digital services network (ISDN), personal communications services (PCS), transmission control protocol/Internet protocol (TCP/IP), serial line Internet protocol/point to point protocol (SLIP/PPP), and so on, but may also implement customized or non-standard interface protocols as well.</p>
    <p num="p-0104">Software and data transferred via communication interface <b>774</b> are generally in the form of electrical communication signals <b>778</b>. These signals <b>778</b> are preferably provided to communication interface <b>774</b> via a communication channel <b>776</b>. Communication channel <b>776</b> carries signals <b>778</b> and can be implemented using a variety of wired or wireless communication means including wire or cable, fiber optics, conventional phone line, cellular phone link, wireless data communication link, radio frequency (RF) link, or infrared link, just to name a few.</p>
    <p num="p-0105">Computer executable code (i.e., computer programs or software) is stored in the main memory <b>756</b> and/or the secondary memory <b>758</b>. Computer programs can also be received via communication interface <b>774</b> and stored in the main memory <b>756</b> and/or the secondary memory <b>758</b>. Such computer programs, when executed, enable the computer system <b>750</b> to perform the various functions of the present invention as previously described.</p>
    <p num="p-0106">In this description, the term computer readable medium is used to refer to any media used to provide computer executable code (e.g., software and computer programs) to the computer system <b>750</b>. Examples of these media include main memory <b>756</b>, secondary memory <b>758</b> (including hard disk drive <b>760</b>, removable storage medium <b>764</b>, and external storage medium <b>772</b>), and any peripheral device communicatively coupled with communication interface <b>774</b> (including a network information server or other network device). These computer readable mediums are means for providing executable code, programming instructions, and software to the computer system <b>750</b>.</p>
    <p num="p-0107">In an embodiment that is implemented using software, the software may be stored on a computer readable medium and loaded into computer system <b>750</b> by way of removable storage drive <b>762</b>, interface <b>770</b>, or communication interface <b>774</b>. In such an embodiment, the software is loaded into the computer system <b>750</b> in the form of electrical communication signals <b>778</b>. The software, when executed by the processor <b>752</b>, preferably causes the processor <b>752</b> to perform the inventive features and functions previously described herein.</p>
    <p num="p-0108">Various embodiments may also be implemented primarily in hardware using, for example, components such as application specific integrated circuits (ASICs), or field programmable gate arrays (FPGAs). Implementation of a hardware state machine capable of performing the functions described herein will also be apparent to those skilled in the relevant art. Various embodiments may also be implemented using a combination of both hardware and software.</p>
    <p num="p-0109">Furthermore, those of skill in the art will appreciate that the various illustrative logical blocks, modules, circuits, and method steps described in connection with the above described figures and the embodiments disclosed herein can often be implemented as electronic hardware, computer software, or combinations of both. To clearly illustrate this interchangeability of hardware and software, various illustrative components, blocks, modules, circuits, and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled persons can implement the described functionality in varying ways for each particular application, but such implementation decisions should not be interpreted as causing a departure from the scope of the invention. In addition, the grouping of functions within a module, block, circuit or step is for ease of description. Specific functions or steps can be moved from one module, block or circuit to another without departing from the invention.</p>
    <p num="p-0110">Moreover, the various illustrative logical blocks, modules, and methods described in connection with the embodiments disclosed herein can be implemented or performed with a general purpose processor, a digital signal processor (DSP), an ASIC, FPGA or other programmable logic device, discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein. A general-purpose processor can be a microprocessor, but in the alternative, the processor can be any processor, controller, microcontroller, or state machine. A processor can also be implemented as a combination of computing devices, for example, a combination of a DSP and a microprocessor, a plurality of microprocessors, one or more microprocessors in conjunction with a DSP core, or any other such configuration.</p>
    <p num="p-0111">Additionally, the steps of a method or algorithm described in connection with the embodiments disclosed herein can be embodied directly in hardware, in a software module executed by a processor, or in a combination of the two. A software module can reside in RAM memory, flash memory, ROM memory, EPROM memory, EEPROM memory, registers, hard disk, a removable disk, a CD-ROM, or any other form of storage medium including a network storage medium. An exemplary storage medium can be coupled to the processor such that the processor can read information from, and write information to, the storage medium. In the alternative, the storage medium can be integral to the processor. The processor and the storage medium can also reside in an ASIC.</p>
    <p num="p-0112">The above description of the disclosed embodiments is provided to enable any person skilled in the art to make or use the invention. Various modifications to these embodiments will be readily apparent to those skilled in the art, and the generic principles described herein can be applied to other embodiments without departing from the spirit or scope of the invention. Thus, it is to be understood that the description and drawings presented herein represent a presently preferred embodiment of the invention and are therefore representative of the subject matter which is broadly contemplated by the present invention. It is further understood that the scope of the present invention fully encompasses other embodiments that may become obvious to those skilled in the art and that the scope of the present invention is accordingly limited by nothing other than the appended claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US2943141">US2943141</a></td><td class="patent-data-table-td patent-date-value">Jan 7, 1955</td><td class="patent-data-table-td patent-date-value">Jun 28, 1960</td><td class="patent-data-table-td ">Servo Corp Of America</td><td class="patent-data-table-td ">Automatic baseball umpire or the like</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3781824">US3781824</a></td><td class="patent-data-table-td patent-date-value">Nov 20, 1972</td><td class="patent-data-table-td patent-date-value">Dec 25, 1973</td><td class="patent-data-table-td ">Gen Motors Corp</td><td class="patent-data-table-td ">Solid state crash recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3812287">US3812287</a></td><td class="patent-data-table-td patent-date-value">Oct 24, 1972</td><td class="patent-data-table-td patent-date-value">May 21, 1974</td><td class="patent-data-table-td ">J Lemelson</td><td class="patent-data-table-td ">Video detection system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3885090">US3885090</a></td><td class="patent-data-table-td patent-date-value">Mar 20, 1973</td><td class="patent-data-table-td patent-date-value">May 20, 1975</td><td class="patent-data-table-td ">Richard W Rosenbaum</td><td class="patent-data-table-td ">Continuous automatic surveillance system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3992656">US3992656</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 1975</td><td class="patent-data-table-td patent-date-value">Nov 16, 1976</td><td class="patent-data-table-td ">Joy Ivan L</td><td class="patent-data-table-td ">Siren detector</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4054752">US4054752</a></td><td class="patent-data-table-td patent-date-value">Jan 30, 1976</td><td class="patent-data-table-td patent-date-value">Oct 18, 1977</td><td class="patent-data-table-td ">Dennis Jr Clay E</td><td class="patent-data-table-td ">Cash register protection recording and alarm system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4271358">US4271358</a></td><td class="patent-data-table-td patent-date-value">Nov 13, 1979</td><td class="patent-data-table-td patent-date-value">Jun 2, 1981</td><td class="patent-data-table-td ">Frank Schwarz</td><td class="patent-data-table-td ">Selective infrared detector</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4280151">US4280151</a></td><td class="patent-data-table-td patent-date-value">Feb 21, 1979</td><td class="patent-data-table-td patent-date-value">Jul 21, 1981</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">High speed image recording system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4281354">US4281354</a></td><td class="patent-data-table-td patent-date-value">May 17, 1979</td><td class="patent-data-table-td patent-date-value">Jul 28, 1981</td><td class="patent-data-table-td ">Raffaele Conte</td><td class="patent-data-table-td ">Apparatus for magnetic recording of casual events relating to movable means</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4401976">US4401976</a></td><td class="patent-data-table-td patent-date-value">Jan 14, 1981</td><td class="patent-data-table-td patent-date-value">Aug 30, 1983</td><td class="patent-data-table-td ">Stadelmayr Hans G</td><td class="patent-data-table-td ">Multiple sensor interconnected alarm system responsive to different variables</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4409670">US4409670</a></td><td class="patent-data-table-td patent-date-value">Jun 26, 1981</td><td class="patent-data-table-td patent-date-value">Oct 11, 1983</td><td class="patent-data-table-td ">United Technologies Corporation</td><td class="patent-data-table-td ">Solid-state digital flight data recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4420773">US4420773</a></td><td class="patent-data-table-td patent-date-value">Jun 18, 1981</td><td class="patent-data-table-td patent-date-value">Dec 13, 1983</td><td class="patent-data-table-td ">Nippon Kogaku K.K.</td><td class="patent-data-table-td ">Electronic photographic camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4456931">US4456931</a></td><td class="patent-data-table-td patent-date-value">Oct 29, 1981</td><td class="patent-data-table-td patent-date-value">Jun 26, 1984</td><td class="patent-data-table-td ">Nippon Kogaku K.K.</td><td class="patent-data-table-td ">Electronic camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4489351">US4489351</a></td><td class="patent-data-table-td patent-date-value">Sep 17, 1982</td><td class="patent-data-table-td patent-date-value">Dec 18, 1984</td><td class="patent-data-table-td ">Staar S. A.</td><td class="patent-data-table-td ">Image recording device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4496995">US4496995</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 1982</td><td class="patent-data-table-td patent-date-value">Jan 29, 1985</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Down converting a high frame rate signal to a standard TV frame rate signal by skipping preselected video information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4533962">US4533962</a></td><td class="patent-data-table-td patent-date-value">Aug 5, 1982</td><td class="patent-data-table-td patent-date-value">Aug 6, 1985</td><td class="patent-data-table-td ">Decker Ronald R</td><td class="patent-data-table-td ">Vehicle performance detection and recording apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4558379">US4558379</a></td><td class="patent-data-table-td patent-date-value">Jun 25, 1984</td><td class="patent-data-table-td patent-date-value">Dec 10, 1985</td><td class="patent-data-table-td ">Siemens Aktiengesellschaft</td><td class="patent-data-table-td ">Disturbance detection and recording system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4593313">US4593313</a></td><td class="patent-data-table-td patent-date-value">Sep 4, 1984</td><td class="patent-data-table-td patent-date-value">Jun 3, 1986</td><td class="patent-data-table-td ">Olympus Optical Co., Ltd.</td><td class="patent-data-table-td ">Endoscope</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4621335">US4621335</a></td><td class="patent-data-table-td patent-date-value">May 31, 1983</td><td class="patent-data-table-td patent-date-value">Nov 4, 1986</td><td class="patent-data-table-td ">Allied Corporation</td><td class="patent-data-table-td ">Real time recall feature for an engine data processor system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4625210">US4625210</a></td><td class="patent-data-table-td patent-date-value">May 21, 1984</td><td class="patent-data-table-td patent-date-value">Nov 25, 1986</td><td class="patent-data-table-td ">B.E.L-Tronics Limited</td><td class="patent-data-table-td ">Construction for a portable radar detector having a mirror</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4630110">US4630110</a></td><td class="patent-data-table-td patent-date-value">Feb 15, 1984</td><td class="patent-data-table-td patent-date-value">Dec 16, 1986</td><td class="patent-data-table-td ">Supervision Control Systems, Inc.</td><td class="patent-data-table-td ">Surveillance system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4632348">US4632348</a></td><td class="patent-data-table-td patent-date-value">Dec 12, 1985</td><td class="patent-data-table-td patent-date-value">Dec 30, 1986</td><td class="patent-data-table-td ">General Motors Corporation</td><td class="patent-data-table-td ">Mounting arrangement for a mirror</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4638289">US4638289</a></td><td class="patent-data-table-td patent-date-value">Feb 24, 1984</td><td class="patent-data-table-td patent-date-value">Jan 20, 1987</td><td class="patent-data-table-td ">Licentia Patent-Verwaltungs-Gmbh</td><td class="patent-data-table-td ">Accident data recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4646241">US4646241</a></td><td class="patent-data-table-td patent-date-value">Jun 21, 1984</td><td class="patent-data-table-td patent-date-value">Feb 24, 1987</td><td class="patent-data-table-td ">United Technologies Corporation</td><td class="patent-data-table-td ">Solid-state flight data recording system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4651143">US4651143</a></td><td class="patent-data-table-td patent-date-value">Jun 26, 1985</td><td class="patent-data-table-td patent-date-value">Mar 17, 1987</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Security system including a daughter station for monitoring an area and a remote parent station connected thereto</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4758888">US4758888</a></td><td class="patent-data-table-td patent-date-value">Feb 17, 1987</td><td class="patent-data-table-td patent-date-value">Jul 19, 1988</td><td class="patent-data-table-td ">Orbot Systems, Ltd.</td><td class="patent-data-table-td ">Method of and means for inspecting workpieces traveling along a production line</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4763745">US4763745</a></td><td class="patent-data-table-td patent-date-value">May 21, 1986</td><td class="patent-data-table-td patent-date-value">Aug 16, 1988</td><td class="patent-data-table-td ">Toyoda Koki Kabushiki Kaisha</td><td class="patent-data-table-td ">Motor vehicle with driving status detection device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4785474">US4785474</a></td><td class="patent-data-table-td patent-date-value">Jul 31, 1987</td><td class="patent-data-table-td patent-date-value">Nov 15, 1988</td><td class="patent-data-table-td ">Sy/Lert Systems Limited Partnership</td><td class="patent-data-table-td ">Emergency signal warning system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4789904">US4789904</a></td><td class="patent-data-table-td patent-date-value">Feb 13, 1987</td><td class="patent-data-table-td patent-date-value">Dec 6, 1988</td><td class="patent-data-table-td ">Peterson Roger D</td><td class="patent-data-table-td ">Vehicle mounted surveillance and videotaping system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4794566">US4794566</a></td><td class="patent-data-table-td patent-date-value">Feb 10, 1987</td><td class="patent-data-table-td patent-date-value">Dec 27, 1988</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Random access memory apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4804937">US4804937</a></td><td class="patent-data-table-td patent-date-value">May 26, 1987</td><td class="patent-data-table-td patent-date-value">Feb 14, 1989</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Vehicle monitoring arrangement and system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4806931">US4806931</a></td><td class="patent-data-table-td patent-date-value">Jan 25, 1988</td><td class="patent-data-table-td patent-date-value">Feb 21, 1989</td><td class="patent-data-table-td ">Richard W. Clark</td><td class="patent-data-table-td ">Sound pattern discrimination system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4837628">US4837628</a></td><td class="patent-data-table-td patent-date-value">Jul 14, 1987</td><td class="patent-data-table-td patent-date-value">Jun 6, 1989</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Electronic still camera for recording still picture on memory card with mode selecting shutter release</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4839631">US4839631</a></td><td class="patent-data-table-td patent-date-value">Jun 17, 1988</td><td class="patent-data-table-td patent-date-value">Jun 13, 1989</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Monitor control apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4843463">US4843463</a></td><td class="patent-data-table-td patent-date-value">May 23, 1988</td><td class="patent-data-table-td patent-date-value">Jun 27, 1989</td><td class="patent-data-table-td ">Michetti Joseph A</td><td class="patent-data-table-td ">Land vehicle mounted audio-visual trip recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4843578">US4843578</a></td><td class="patent-data-table-td patent-date-value">Jul 27, 1987</td><td class="patent-data-table-td patent-date-value">Jun 27, 1989</td><td class="patent-data-table-td ">Wade Ted R</td><td class="patent-data-table-td ">Vehicle speed monitoring and logging means</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4876597">US4876597</a></td><td class="patent-data-table-td patent-date-value">Aug 18, 1988</td><td class="patent-data-table-td patent-date-value">Oct 24, 1989</td><td class="patent-data-table-td ">Adt Security Systems, Inc.</td><td class="patent-data-table-td ">Video observation systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4883349">US4883349</a></td><td class="patent-data-table-td patent-date-value">Sep 23, 1988</td><td class="patent-data-table-td patent-date-value">Nov 28, 1989</td><td class="patent-data-table-td ">Mittelhaeuser Bernhard</td><td class="patent-data-table-td ">Rear view mirror for motor vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4896855">US4896855</a></td><td class="patent-data-table-td patent-date-value">Nov 21, 1988</td><td class="patent-data-table-td patent-date-value">Jan 30, 1990</td><td class="patent-data-table-td ">Cincinnati Microwave, Inc.</td><td class="patent-data-table-td ">For supporting a radar receiver</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4930742">US4930742</a></td><td class="patent-data-table-td patent-date-value">Mar 25, 1988</td><td class="patent-data-table-td patent-date-value">Jun 5, 1990</td><td class="patent-data-table-td ">Donnelly Corporation</td><td class="patent-data-table-td ">Rearview mirror and accessory mount for vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4936533">US4936533</a></td><td class="patent-data-table-td patent-date-value">Nov 15, 1988</td><td class="patent-data-table-td patent-date-value">Jun 26, 1990</td><td class="patent-data-table-td ">Donnelly Corporation</td><td class="patent-data-table-td ">Mounting assembly for vehicle accessories</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4939652">US4939652</a></td><td class="patent-data-table-td patent-date-value">Mar 14, 1988</td><td class="patent-data-table-td patent-date-value">Jul 3, 1990</td><td class="patent-data-table-td ">Centrodyne Inc.</td><td class="patent-data-table-td ">Vehicle monitoring, recording and analyzing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4942464">US4942464</a></td><td class="patent-data-table-td patent-date-value">Mar 9, 1989</td><td class="patent-data-table-td patent-date-value">Jul 17, 1990</td><td class="patent-data-table-td ">Erhard Milatz</td><td class="patent-data-table-td ">Surveillance device for the protection of an automatic delivery apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4945244">US4945244</a></td><td class="patent-data-table-td patent-date-value">Dec 23, 1988</td><td class="patent-data-table-td patent-date-value">Jul 31, 1990</td><td class="patent-data-table-td ">Castleman Robert D</td><td class="patent-data-table-td ">Electronic infrared detector</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4949186">US4949186</a></td><td class="patent-data-table-td patent-date-value">Dec 5, 1988</td><td class="patent-data-table-td patent-date-value">Aug 14, 1990</td><td class="patent-data-table-td ">Peterson Roger D</td><td class="patent-data-table-td ">Vehicle mounted surveillance system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4980913">US4980913</a></td><td class="patent-data-table-td patent-date-value">Apr 19, 1988</td><td class="patent-data-table-td patent-date-value">Dec 25, 1990</td><td class="patent-data-table-td ">Vindicator Corporation</td><td class="patent-data-table-td ">Security system network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4987541">US4987541</a></td><td class="patent-data-table-td patent-date-value">Dec 29, 1987</td><td class="patent-data-table-td patent-date-value">Jan 22, 1991</td><td class="patent-data-table-td ">Szekely Levente</td><td class="patent-data-table-td ">Method for storing run data of a vehicle in the memory of an electronic tachograph and apparatus for carrying out the method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4992943">US4992943</a></td><td class="patent-data-table-td patent-date-value">Feb 13, 1989</td><td class="patent-data-table-td patent-date-value">Feb 12, 1991</td><td class="patent-data-table-td ">Mccracken Jack J</td><td class="patent-data-table-td ">Apparatus for detecting and storing motor vehicle impact data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5012335">US5012335</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 1988</td><td class="patent-data-table-td patent-date-value">Apr 30, 1991</td><td class="patent-data-table-td ">Alija Cohodar</td><td class="patent-data-table-td ">Observation and recording system for a police vehicle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5027104">US5027104</a></td><td class="patent-data-table-td patent-date-value">Feb 21, 1990</td><td class="patent-data-table-td patent-date-value">Jun 25, 1991</td><td class="patent-data-table-td ">Reid Donald J</td><td class="patent-data-table-td ">Vehicle security device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5056056">US5056056</a></td><td class="patent-data-table-td patent-date-value">Feb 2, 1989</td><td class="patent-data-table-td patent-date-value">Oct 8, 1991</td><td class="patent-data-table-td ">Systems Research Laboratories, Inc.</td><td class="patent-data-table-td ">Data recorder including a recirculating non-volatile memory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5057820">US5057820</a></td><td class="patent-data-table-td patent-date-value">May 1, 1989</td><td class="patent-data-table-td patent-date-value">Oct 15, 1991</td><td class="patent-data-table-td ">Airborne Research Associates, Inc.</td><td class="patent-data-table-td ">Optical warning system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5096287">US5096287</a></td><td class="patent-data-table-td patent-date-value">Mar 15, 1991</td><td class="patent-data-table-td patent-date-value">Mar 17, 1992</td><td class="patent-data-table-td ">Aisin Seiki K.K.</td><td class="patent-data-table-td ">Video camera for an automobile</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5100095">US5100095</a></td><td class="patent-data-table-td patent-date-value">Mar 1, 1991</td><td class="patent-data-table-td patent-date-value">Mar 31, 1992</td><td class="patent-data-table-td ">Donnelly Corporation</td><td class="patent-data-table-td ">Breakaway vehicle accessory mount</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5111289">US5111289</a></td><td class="patent-data-table-td patent-date-value">Apr 27, 1990</td><td class="patent-data-table-td patent-date-value">May 5, 1992</td><td class="patent-data-table-td ">Lucas Gary L</td><td class="patent-data-table-td ">Vehicular mounted surveillance and recording system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5140434">US5140434</a></td><td class="patent-data-table-td patent-date-value">Jan 29, 1990</td><td class="patent-data-table-td patent-date-value">Aug 18, 1992</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Record on command recording in a solid state fast frame recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5140436">US5140436</a></td><td class="patent-data-table-td patent-date-value">Nov 2, 1989</td><td class="patent-data-table-td patent-date-value">Aug 18, 1992</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Pre-event/post-event recording in a solid state fast frame recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5144661">US5144661</a></td><td class="patent-data-table-td patent-date-value">Feb 11, 1991</td><td class="patent-data-table-td patent-date-value">Sep 1, 1992</td><td class="patent-data-table-td ">Robert Shamosh</td><td class="patent-data-table-td ">Security protection system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5178448">US5178448</a></td><td class="patent-data-table-td patent-date-value">Sep 13, 1991</td><td class="patent-data-table-td patent-date-value">Jan 12, 1993</td><td class="patent-data-table-td ">Donnelly Corporation</td><td class="patent-data-table-td ">Rearview mirror with lighting assembly</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5196938">US5196938</a></td><td class="patent-data-table-td patent-date-value">Nov 20, 1989</td><td class="patent-data-table-td patent-date-value">Mar 23, 1993</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Solid state fast frame recorder having independently selectable frame rate and exposure</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5223844">US5223844</a></td><td class="patent-data-table-td patent-date-value">Apr 17, 1992</td><td class="patent-data-table-td patent-date-value">Jun 29, 1993</td><td class="patent-data-table-td ">Auto-Trac, Inc.</td><td class="patent-data-table-td ">Vehicle tracking and security system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5262813">US5262813</a></td><td class="patent-data-table-td patent-date-value">Feb 9, 1993</td><td class="patent-data-table-td patent-date-value">Nov 16, 1993</td><td class="patent-data-table-td ">Scharton Terry D</td><td class="patent-data-table-td ">Impact triggering mechanism for a camera mounted in a vehicle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5308247">US5308247</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 1993</td><td class="patent-data-table-td patent-date-value">May 3, 1994</td><td class="patent-data-table-td ">Dyrdek Robert D</td><td class="patent-data-table-td ">Electrical connector assembly for automobile rearview mirror and light assembly and method of assembling the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5311197">US5311197</a></td><td class="patent-data-table-td patent-date-value">Feb 1, 1993</td><td class="patent-data-table-td patent-date-value">May 10, 1994</td><td class="patent-data-table-td ">Trimble Navigation Limited</td><td class="patent-data-table-td ">Event-activated reporting of vehicle location</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5321753">US5321753</a></td><td class="patent-data-table-td patent-date-value">Jul 8, 1991</td><td class="patent-data-table-td patent-date-value">Jun 14, 1994</td><td class="patent-data-table-td ">The United States Of America As Represented By The United States Department Of Energy</td><td class="patent-data-table-td ">Secure communication of static information by electronic means</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5327288">US5327288</a></td><td class="patent-data-table-td patent-date-value">Sep 13, 1991</td><td class="patent-data-table-td patent-date-value">Jul 5, 1994</td><td class="patent-data-table-td ">Donnelly Corporation</td><td class="patent-data-table-td ">Reduced vibration day/night rearview mirror assembly</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5330149">US5330149</a></td><td class="patent-data-table-td patent-date-value">Jan 28, 1993</td><td class="patent-data-table-td patent-date-value">Jul 19, 1994</td><td class="patent-data-table-td ">Donnelly Corporation</td><td class="patent-data-table-td ">Breakaway accessory mounting for vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5343527">US5343527</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 1993</td><td class="patent-data-table-td patent-date-value">Aug 30, 1994</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Hybrid encryption method and system for protecting reusable software components</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5353023">US5353023</a></td><td class="patent-data-table-td patent-date-value">Jun 25, 1992</td><td class="patent-data-table-td patent-date-value">Oct 4, 1994</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Navigation system for cars</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5361326">US5361326</a></td><td class="patent-data-table-td patent-date-value">Dec 31, 1991</td><td class="patent-data-table-td patent-date-value">Nov 1, 1994</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Enhanced interface for a neural network engine</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5387926">US5387926</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 1992</td><td class="patent-data-table-td patent-date-value">Feb 7, 1995</td><td class="patent-data-table-td ">California Institute Of Technology</td><td class="patent-data-table-td ">High speed digital framing camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5388045">US5388045</a></td><td class="patent-data-table-td patent-date-value">Aug 26, 1993</td><td class="patent-data-table-td patent-date-value">Feb 7, 1995</td><td class="patent-data-table-td ">Nippondenso Co., Ltd.</td><td class="patent-data-table-td ">Self-diagnostic apparatus of vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5404330">US5404330</a></td><td class="patent-data-table-td patent-date-value">Dec 6, 1993</td><td class="patent-data-table-td patent-date-value">Apr 4, 1995</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Word line boosting circuit and control circuit therefor in a semiconductor integrated circuit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5408330">US5408330</a></td><td class="patent-data-table-td patent-date-value">Mar 25, 1991</td><td class="patent-data-table-td patent-date-value">Apr 18, 1995</td><td class="patent-data-table-td ">Crimtec Corporation</td><td class="patent-data-table-td ">Video incident capture system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5422543">US5422543</a></td><td class="patent-data-table-td patent-date-value">Sep 27, 1993</td><td class="patent-data-table-td patent-date-value">Jun 6, 1995</td><td class="patent-data-table-td ">Weinberg; Stanley</td><td class="patent-data-table-td ">Flash monitor alarm system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5430431">US5430431</a></td><td class="patent-data-table-td patent-date-value">Jan 19, 1994</td><td class="patent-data-table-td patent-date-value">Jul 4, 1995</td><td class="patent-data-table-td ">Nelson; Louis J.</td><td class="patent-data-table-td ">Vehicle protection system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5430432">US5430432</a></td><td class="patent-data-table-td patent-date-value">Jul 22, 1994</td><td class="patent-data-table-td patent-date-value">Jul 4, 1995</td><td class="patent-data-table-td ">Camhi; Elie</td><td class="patent-data-table-td ">Automotive warning and recording system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5435184">US5435184</a></td><td class="patent-data-table-td patent-date-value">Oct 29, 1992</td><td class="patent-data-table-td patent-date-value">Jul 25, 1995</td><td class="patent-data-table-td ">Pineroli; Bruno</td><td class="patent-data-table-td ">Device for determining running variables in a motor vehicle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5445024">US5445024</a></td><td class="patent-data-table-td patent-date-value">Sep 7, 1993</td><td class="patent-data-table-td patent-date-value">Aug 29, 1995</td><td class="patent-data-table-td ">Riley, Jr.; Claude R.</td><td class="patent-data-table-td ">Automotive motion recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5445027">US5445027</a></td><td class="patent-data-table-td patent-date-value">Feb 17, 1994</td><td class="patent-data-table-td patent-date-value">Aug 29, 1995</td><td class="patent-data-table-td ">Siemens Aktiengesellschaft</td><td class="patent-data-table-td ">Method and apparatus for detecting and locating defects in a component of a turbine</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5446659">US5446659</a></td><td class="patent-data-table-td patent-date-value">Apr 14, 1994</td><td class="patent-data-table-td patent-date-value">Aug 29, 1995</td><td class="patent-data-table-td ">Awaji Ferryboat Kabushiki Kaisha</td><td class="patent-data-table-td ">Traffic accident data recorder and traffic accident reproduction system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5455625">US5455625</a></td><td class="patent-data-table-td patent-date-value">Sep 23, 1993</td><td class="patent-data-table-td patent-date-value">Oct 3, 1995</td><td class="patent-data-table-td ">Rosco Inc.</td><td class="patent-data-table-td ">Video camera unit, protective enclosure and power circuit for same, particularly for use in vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5455716">US5455716</a></td><td class="patent-data-table-td patent-date-value">Dec 10, 1992</td><td class="patent-data-table-td patent-date-value">Oct 3, 1995</td><td class="patent-data-table-td ">Prince Corporation</td><td class="patent-data-table-td ">Vehicle mirror with electrical accessories</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5473729">US5473729</a></td><td class="patent-data-table-td patent-date-value">Sep 30, 1992</td><td class="patent-data-table-td patent-date-value">Dec 5, 1995</td><td class="patent-data-table-td ">Bryant; David P.</td><td class="patent-data-table-td ">Critical incident recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5477141">US5477141</a></td><td class="patent-data-table-td patent-date-value">Jun 1, 1993</td><td class="patent-data-table-td patent-date-value">Dec 19, 1995</td><td class="patent-data-table-td ">Vdo Kienzle Gmbh</td><td class="patent-data-table-td ">Registration arrangement for motor vehicles with a measured value presentation suitable for evaluating accidents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5495242">US5495242</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 1993</td><td class="patent-data-table-td patent-date-value">Feb 27, 1996</td><td class="patent-data-table-td ">C.A.P.S., Inc.</td><td class="patent-data-table-td ">System and method for detection of aural signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5497419">US5497419</a></td><td class="patent-data-table-td patent-date-value">Apr 19, 1994</td><td class="patent-data-table-td patent-date-value">Mar 5, 1996</td><td class="patent-data-table-td ">Prima Facie, Inc.</td><td class="patent-data-table-td ">Method and apparatus for recording sensor data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5499182">US5499182</a></td><td class="patent-data-table-td patent-date-value">Dec 7, 1994</td><td class="patent-data-table-td patent-date-value">Mar 12, 1996</td><td class="patent-data-table-td ">Ousborne; Jeffrey</td><td class="patent-data-table-td ">Vehicle driver performance monitoring system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5504482">US5504482</a></td><td class="patent-data-table-td patent-date-value">Jun 11, 1993</td><td class="patent-data-table-td patent-date-value">Apr 2, 1996</td><td class="patent-data-table-td ">Rockwell International Corporation</td><td class="patent-data-table-td ">Automobile navigation guidance, control and safety system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5515285">US5515285</a></td><td class="patent-data-table-td patent-date-value">Dec 16, 1993</td><td class="patent-data-table-td patent-date-value">May 7, 1996</td><td class="patent-data-table-td ">Car Trace, Incorporated</td><td class="patent-data-table-td ">System for monitoring vehicles during a crisis situation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5521633">US5521633</a></td><td class="patent-data-table-td patent-date-value">Sep 24, 1993</td><td class="patent-data-table-td patent-date-value">May 28, 1996</td><td class="patent-data-table-td ">Yazaki Corporation</td><td class="patent-data-table-td ">Motor vehicle obstacle monitoring system using optical flow processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5523811">US5523811</a></td><td class="patent-data-table-td patent-date-value">Apr 10, 1995</td><td class="patent-data-table-td patent-date-value">Jun 4, 1996</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Camera device for moving body</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5526269">US5526269</a></td><td class="patent-data-table-td patent-date-value">Jun 20, 1994</td><td class="patent-data-table-td patent-date-value">Jun 11, 1996</td><td class="patent-data-table-td ">Yazaki Corporation</td><td class="patent-data-table-td ">Digital operation recorder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5530420">US5530420</a></td><td class="patent-data-table-td patent-date-value">Dec 27, 1994</td><td class="patent-data-table-td patent-date-value">Jun 25, 1996</td><td class="patent-data-table-td ">Fuji Jukogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">Running guide apparatus for vehicle capable of keeping safety at passing through narrow path and the method thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5537156">US5537156</a></td><td class="patent-data-table-td patent-date-value">Mar 24, 1994</td><td class="patent-data-table-td patent-date-value">Jul 16, 1996</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Video imaging system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5539454">US5539454</a></td><td class="patent-data-table-td patent-date-value">Feb 6, 1995</td><td class="patent-data-table-td patent-date-value">Jul 23, 1996</td><td class="patent-data-table-td ">The United States Of America As Represented By The Administrator, National Aeronautics And Space Administration</td><td class="patent-data-table-td ">Video event trigger and tracking system using fuzzy comparators</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5541590">US5541590</a></td><td class="patent-data-table-td patent-date-value">Jan 19, 1995</td><td class="patent-data-table-td patent-date-value">Jul 30, 1996</td><td class="patent-data-table-td ">Takata Corporation</td><td class="patent-data-table-td ">Vehicle crash predictive and evasive operation system by neural networks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5544060">US5544060</a></td><td class="patent-data-table-td patent-date-value">Mar 30, 1994</td><td class="patent-data-table-td patent-date-value">Aug 6, 1996</td><td class="patent-data-table-td ">Zexel Usa Corporation</td><td class="patent-data-table-td ">Vehicle mounted navigation system with preview function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5548273">US5548273</a></td><td class="patent-data-table-td patent-date-value">Oct 11, 1995</td><td class="patent-data-table-td patent-date-value">Aug 20, 1996</td><td class="patent-data-table-td ">Competition Components International Pty Ltd</td><td class="patent-data-table-td ">Vehicle driving monitor apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030125854">US20030125854</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 23, 2002</td><td class="patent-data-table-td patent-date-value">Jul 3, 2003</td><td class="patent-data-table-td ">Yoshiteru Kawasaki</td><td class="patent-data-table-td ">Vehicle information recording system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">International Search Report and Written Opinion issued in PCT/US07/68329 on Mar. 3, 2008.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8095265">US8095265</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 6, 2008</td><td class="patent-data-table-td patent-date-value">Jan 10, 2012</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Recording, storing, and retrieving vehicle maintenance records</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8503972">US8503972</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2009</td><td class="patent-data-table-td patent-date-value">Aug 6, 2013</td><td class="patent-data-table-td ">Digital Ally, Inc.</td><td class="patent-data-table-td ">Multi-functional remote monitoring system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8520069">US8520069</a></td><td class="patent-data-table-td patent-date-value">Aug 10, 2008</td><td class="patent-data-table-td patent-date-value">Aug 27, 2013</td><td class="patent-data-table-td ">Digital Ally, Inc.</td><td class="patent-data-table-td ">Vehicle-mounted video system with distributed processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120229282">US20120229282</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 6, 2012</td><td class="patent-data-table-td patent-date-value">Sep 13, 2012</td><td class="patent-data-table-td ">Security Identification Systems Corporation a Florida</td><td class="patent-data-table-td ">Maritime Overboard Detection and Tracking System</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc340/defs340.htm&usg=AFQjCNGk_NCDWkt8oMijCQ2jvfqday0GbA#C340S937000">340/937</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S148000">348/148</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc701/defs701.htm&usg=AFQjCNFn25anNrI7_vY4MNK7_80zsoxwdA#C701S033400">701/33.4</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc725/defs725.htm&usg=AFQjCNEqTdrBzYZIjJoruRv4pdIQa0i0Wg#C725S145000">725/145</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc725/defs725.htm&usg=AFQjCNEqTdrBzYZIjJoruRv4pdIQa0i0Wg#C725S093000">725/93</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc725/defs725.htm&usg=AFQjCNEqTdrBzYZIjJoruRv4pdIQa0i0Wg#C725S146000">725/146</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc725/defs725.htm&usg=AFQjCNEqTdrBzYZIjJoruRv4pdIQa0i0Wg#C725S086000">725/86</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc709/defs709.htm&usg=AFQjCNFBXWYqUOVuuxerz7B8cqt9daJk7Q#C709S219000">709/219</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc725/defs725.htm&usg=AFQjCNEqTdrBzYZIjJoruRv4pdIQa0i0Wg#C725S143000">725/143</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc340/defs340.htm&usg=AFQjCNGk_NCDWkt8oMijCQ2jvfqday0GbA#C340S576000">340/576</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc725/defs725.htm&usg=AFQjCNEqTdrBzYZIjJoruRv4pdIQa0i0Wg#C725S094000">725/94</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc340/defs340.htm&usg=AFQjCNGk_NCDWkt8oMijCQ2jvfqday0GbA#C340S439000">340/439</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc725/defs725.htm&usg=AFQjCNEqTdrBzYZIjJoruRv4pdIQa0i0Wg#C725S091000">725/91</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc702/defs702.htm&usg=AFQjCNEwDgPZO8lzVvNBu0VAYuT88y7k4g#C702S188000">702/188</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G08G0001017000">G08G1/017</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G07C5/008">G07C5/008</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G07C5/085">G07C5/085</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G07C5/0858">G07C5/0858</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=h-yRBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G08B23/00">G08B23/00</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G07C5/08R2</span>, <span class="nested-value">G07C5/00T</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Mar 28, 2014</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 29, 2014</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20140124</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNORS:LYTX, INC.;MOBIUS ACQUISITION HOLDINGS, LLC;REEL/FRAME:032134/0756</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">WELLS FARGO BANK, NATIONAL ASSOCIATION, AS AGENT,</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 14, 2014</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:DRIVECAM, INC.;REEL/FRAME:032019/0172</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">LYTX, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20131104</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 26, 2013</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-33 IS CONFIRMED.NEW CLAIMS 34-85 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 23, 2013</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20111229</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">RELEASE BY SECURED PARTY;ASSIGNOR:LEADER VENTURES, LLC;REEL/FRAME:029679/0735</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">DRIVECAM, INC., CALIFORNIA</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 27, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20111103</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 6, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20111011</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 19, 2009</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">LEADER VENTURES, LLC, AS AGENT, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:DRIVECAM, INC.;REEL/FRAME:023119/0059</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20090819</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">WELLS FARGO BANK, NATIONAL ASSOCIATION, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:DRIVECAM, INC.;REEL/FRAME:023107/0841</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">LEADER VENTURES, LLC, AS AGENT,CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:DRIVECAM, INC.;US-ASSIGNMENT DATABASE UPDATED:20100209;REEL/FRAME:23119/59</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">WELLS FARGO BANK, NATIONAL ASSOCIATION,CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:DRIVECAM, INC.;US-ASSIGNMENT DATABASE UPDATED:20100209;REEL/FRAME:23107/841</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:DRIVECAM, INC.;REEL/FRAME:23119/59</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY AGREEMENT;ASSIGNOR:DRIVECAM, INC.;REEL/FRAME:23107/841</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 4, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">DRIVECAM, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:ETCHESON, JAMIE;REEL/FRAME:018579/0569</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20061129</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U2avtURwwkDU8IIuikdauHH5G8z-w\u0026id=h-yRBgABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0FPA-GQq84mLGluiENvmUfu972PQ\u0026id=h-yRBgABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U3YKGfAPL475-ET6VQz5DzZckubag","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/System_and_method_for_selective_review_o.pdf?id=h-yRBgABERAJ\u0026output=pdf\u0026sig=ACfU3U2eOim3jWpsViKd5i20JPkG-dgH1g"},"sample_url":"http://www.google.com/patents/reader?id=h-yRBgABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>