<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7458025 - User interface for presenting media information - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="User interface for presenting media information"><meta name="DC.contributor" content="Daniel N. Crow" scheme="inventor"><meta name="DC.contributor" content="Cary Dean" scheme="inventor"><meta name="DC.contributor" content="Elizabeth Dykstra-Erickson" scheme="inventor"><meta name="DC.contributor" content="J. Peter Hoddie" scheme="inventor"><meta name="DC.contributor" content="Steven P. Jobs" scheme="inventor"><meta name="DC.contributor" content="Timothy E. Wasko" scheme="inventor"><meta name="DC.contributor" content="Apple Inc." scheme="assignee"><meta name="DC.date" content="2006-9-14" scheme="dateSubmitted"><meta name="DC.description" content="A user interface and methods for using a user interface for controlling processing of time-based media files. In one exemplary method, a graphical representation of a time line for a time-based media is displayed along with a graphical representation of a current time along the graphical representation of the time line. A start graphical indicator and a stop graphical indicator is also displayed along the graphical representation of the time line. A portion of the time-based media may be selected for presentation by dragging or positioning at least one of the start graphical indicator and the stop graphical indicator along the graphical representation of the time line. In another aspect of the invention, an exemplary method allows for the adaptive control of a portion of the interface which indicates time relating to a time-based media. An input speed is determined where this input is to change the portion and the rate at which the change to this portion occurs is dependent upon the input speed. Other aspects of the present invention relating to the interface for controlling the processing of time-based media files are also described."><meta name="DC.date" content="2008-11-25" scheme="issued"><meta name="DC.relation" content="US:20020191028:A1" scheme="references"><meta name="DC.relation" content="US:5404316" scheme="references"><meta name="DC.relation" content="US:5495566" scheme="references"><meta name="DC.relation" content="US:5513342" scheme="references"><meta name="DC.relation" content="US:5519828" scheme="references"><meta name="DC.relation" content="US:5611060" scheme="references"><meta name="DC.relation" content="US:5664128" scheme="references"><meta name="DC.relation" content="US:5682326" scheme="references"><meta name="DC.relation" content="US:5726687" scheme="references"><meta name="DC.relation" content="US:5732184" scheme="references"><meta name="DC.relation" content="US:5745096" scheme="references"><meta name="DC.relation" content="US:5758180" scheme="references"><meta name="DC.relation" content="US:5760767" scheme="references"><meta name="DC.relation" content="US:5760772" scheme="references"><meta name="DC.relation" content="US:5874958" scheme="references"><meta name="DC.relation" content="US:5880725" scheme="references"><meta name="DC.relation" content="US:5999173" scheme="references"><meta name="DC.relation" content="US:6026389" scheme="references"><meta name="DC.relation" content="US:6031529" scheme="references"><meta name="DC.relation" content="US:6061062" scheme="references"><meta name="DC.relation" content="US:6072503" scheme="references"><meta name="DC.relation" content="US:6166736" scheme="references"><meta name="DC.relation" content="US:6204840" scheme="references"><meta name="DC.relation" content="US:6332147" scheme="references"><meta name="DC.relation" content="US:6366296" scheme="references"><meta name="DC.relation" content="US:6369835" scheme="references"><meta name="DC.relation" content="US:6456305" scheme="references"><meta name="citation_reference" content="On-Line Definition for &quot;Playback&quot; (American Heritage Dictionary of the English Language, 4&lt;SUP&gt;th &lt;/SUP&gt;Edition, 1 page, 2000)."><meta name="citation_reference" content="PCT International Search Report for PCT Application No. US00/10441, mailed Jul. 11, 2000, 5 pages."><meta name="citation_reference" content="QuickTime Movie Player Ver. 2.1.2.59 screen dump (Current Time Indicator Dragging Operation; 1 page; 1996)."><meta name="citation_reference" content="RealOne Player Version 2.0 screen dumps (4 pages; 2002)."><meta name="citation_reference" content="Windows Media Player for Windows XP Version 8.0 (2 pages, 2001)."><meta name="citation_patent_number" content="US:7458025"><meta name="citation_patent_application_number" content="US:11/521,740"><link rel="canonical" href="http://www.google.com/patents/US7458025"/><meta property="og:url" content="http://www.google.com/patents/US7458025"/><meta name="title" content="Patent US7458025 - User interface for presenting media information"/><meta name="description" content="A user interface and methods for using a user interface for controlling processing of time-based media files. In one exemplary method, a graphical representation of a time line for a time-based media is displayed along with a graphical representation of a current time along the graphical representation of the time line. A start graphical indicator and a stop graphical indicator is also displayed along the graphical representation of the time line. A portion of the time-based media may be selected for presentation by dragging or positioning at least one of the start graphical indicator and the stop graphical indicator along the graphical representation of the time line. In another aspect of the invention, an exemplary method allows for the adaptive control of a portion of the interface which indicates time relating to a time-based media. An input speed is determined where this input is to change the portion and the rate at which the change to this portion occurs is dependent upon the input speed. Other aspects of the present invention relating to the interface for controlling the processing of time-based media files are also described."/><meta property="og:title" content="Patent US7458025 - User interface for presenting media information"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("K0XsU66UKoeksQSfjYGQAg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("GBR"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("K0XsU66UKoeksQSfjYGQAg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("GBR"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7458025?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7458025"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=82hqBQABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7458025&amp;usg=AFQjCNGkdpCk92O5jGMJdHuD3xFAHDKErg" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7458025.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7458025.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20070013609"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US7458025"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7458025" style="display:none"><span itemprop="description">A user interface and methods for using a user interface for controlling processing of time-based media files. In one exemplary method, a graphical representation of a time line for a time-based media is displayed along with a graphical representation of a current time along the graphical representation...</span><span itemprop="url">http://www.google.com/patents/US7458025?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7458025 - User interface for presenting media information</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7458025 - User interface for presenting media information" title="Patent US7458025 - User interface for presenting media information"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7458025 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 11/521,740</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Nov 25, 2008</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Sep 14, 2006</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Apr 15, 1999</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/EP1180253A1">EP1180253A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1180253A4">EP1180253A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2256588A1">EP2256588A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2256589A1">EP2256589A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6262724">US6262724</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6538665">US6538665</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6850256">US6850256</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7111240">US7111240</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7315984">US7315984</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7318196">US7318196</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8196043">US8196043</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20020057287">US20020057287</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20030080991">US20030080991</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20030128227">US20030128227</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20030128228">US20030128228</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20030146927">US20030146927</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070011614">US20070011614</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070013609">US20070013609</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20080072152">US20080072152</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20140033035">US20140033035</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2000063766A1">WO2000063766A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">11521740, </span><span class="patent-bibdata-value">521740, </span><span class="patent-bibdata-value">US 7458025 B2, </span><span class="patent-bibdata-value">US 7458025B2, </span><span class="patent-bibdata-value">US-B2-7458025, </span><span class="patent-bibdata-value">US7458025 B2, </span><span class="patent-bibdata-value">US7458025B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Daniel+N.+Crow%22">Daniel N. Crow</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Cary+Dean%22">Cary Dean</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Elizabeth+Dykstra-Erickson%22">Elizabeth Dykstra-Erickson</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22J.+Peter+Hoddie%22">J. Peter Hoddie</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Steven+P.+Jobs%22">Steven P. Jobs</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Timothy+E.+Wasko%22">Timothy E. Wasko</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Apple+Inc.%22">Apple Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7458025.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7458025.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7458025.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (27),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (5),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (12),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (36),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7458025&usg=AFQjCNHtsJN5RwrGlK5Dq9VmdvsP9Be15Q">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7458025&usg=AFQjCNHHeVA4v3KlQImrsykAmvkTczwzjw">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7458025B2%26KC%3DB2%26FT%3DD&usg=AFQjCNEMoiGW3czV3iWq_A9s0JIEWiSe1A">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT68521528" lang="EN" load-source="patent-office">User interface for presenting media information</invention-title></span><br><span class="patent-number">US 7458025 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA51389564" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">A user interface and methods for using a user interface for controlling processing of time-based media files. In one exemplary method, a graphical representation of a time line for a time-based media is displayed along with a graphical representation of a current time along the graphical representation of the time line. A start graphical indicator and a stop graphical indicator is also displayed along the graphical representation of the time line. A portion of the time-based media may be selected for presentation by dragging or positioning at least one of the start graphical indicator and the stop graphical indicator along the graphical representation of the time line. In another aspect of the invention, an exemplary method allows for the adaptive control of a portion of the interface which indicates time relating to a time-based media. An input speed is determined where this input is to change the portion and the rate at which the change to this portion occurs is dependent upon the input speed. Other aspects of the present invention relating to the interface for controlling the processing of time-based media files are also described.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(26)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00014.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00014.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00015.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00015.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00016.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00016.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00017.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00017.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00018.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00018.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00019.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00019.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00020.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00020.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00021.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00021.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00022.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00022.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00023.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00023.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00024.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00024.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7458025B2/US07458025-20081125-D00025.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7458025B2/US07458025-20081125-D00025.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(10)</span></span></div><div class="patent-text"><div mxw-id="PCLM9486343" lang="EN" load-source="patent-office" class="claims">
  <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
    <div class="claim-text">1. A method for providing a user interface, said user interface providing functionality for processing time-based media, said method comprising:
<div class="claim-text">detecting input to change a portion of a graphical user interface being displayed, wherein said portion indicates information relating to said time-based media;</div>
<div class="claim-text">determining an input speed of said input to change said portion wherein said input comprises a physical motion from which said input speed is determined;</div>
<div class="claim-text">determining a rate at which to change said portion, said rate being dependent on said input speed; and</div>
<div class="claim-text">changing said portion at said rate by scrolling on a line or part thereof by line or part thereof basis wherein a line of information or a part thereof is moved off said portion and for each said line or said part thereof that is moved off said portion, a new line of information or a new part thereof is displayed.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
    <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">displaying in said graphical interface text information indicating a location of said time-based media; and</div>
<div class="claim-text">in response to said input, scrolling through said time-based media at a scroll rate that depends on said input speed.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
    <div class="claim-text">3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said input is from a hand controlled user input device of a portable computer.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
    <div class="claim-text">4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein said hand controlled user input device is a touch pad and/or button.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
    <div class="claim-text">5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein said time-based media comprises one of video data, audio data, visual data, and a combination of audio and video data and wherein the information comprises title information relating to the time-based media.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00006" num="00006" class="claim">
    <div class="claim-text">6. A machine readable medium having stored thereon executable code which causes a machine to perform a method for generating a user interface, said user interface to provide functionality for processing time-based media data, said method comprising:
<div class="claim-text">detecting input to change a portion of a graphical user interface being displayed, wherein said portion indicates information relating to said time-based media;</div>
<div class="claim-text">determining an input speed of said input to change said portion wherein said input comprises a physical motion from which said input speed is determined;</div>
<div class="claim-text">determining a rate at which to change said portion, said rate being dependent on said input speed; and</div>
<div class="claim-text">changing said portion at said rate by scrolling on a line or part thereof by line or part thereof basis wherein a line of information or a part thereof is moved off said portion and for each said line or said part thereof that is moved off said portion, a new line of information or a new part thereof is displayed.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
    <div class="claim-text">7. The machine readable medium of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein said method further comprises:
<div class="claim-text">displaying in said graphical interface text information indicating a location of said time-based media; and</div>
<div class="claim-text">in response to said input, scrolling through said time-based media at a scroll rate that depends on said input speed.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
    <div class="claim-text">8. The machine readable medium of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein said input is from a hand controlled user input device of a portable computer.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
    <div class="claim-text">9. The machine readable medium of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein said hand controlled user input device is a touch pad and/or button.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
    <div class="claim-text">10. The machine readable medium of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein said time-based media comprises one of video data, audio data, and a combination of audio and video data and wherein the information comprises title information relating to the time-based media. </div>
  </div>
</div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES16508887" lang="EN" load-source="patent-office" class="description">
<p num="p-0002">This application is a continuation application of U.S. patent application Ser. No. 10/374,445, filed on Feb. 24, 2003, now U.S. Pat. No. 7,111,240 which is a continuation of U.S. patent application Ser. No. 10/308,315, filed on Dec. 2, 2002, now U.S. Pat. No. 7,315,984 which is a continuation of U.S. patent application Ser. No. 09/293,507, filed on Apr. 15, 1999 now U.S. Pat. No. 6,538,665.</p>
<heading>FIELD OF THE INVENTION</heading> <p num="p-0003">The present invention relates to user interfaces for processing (e.g., generating, storing, transmitting and/or receiving, playing back/displaying, editing, referencing, etc.) media information, such as time-based media data representing video and/or audio. In particular, the present invention provides an interactive digital processing system-controlled graphical user interface that provides functionality for play back or other processing of time-based and still media data.</p>
  <heading>INTRODUCTION AND BACKGROUND</heading> <p num="p-0004">There are a number of file structures used today to store time-based media: audio formats such as AIFF, video formats such as AVI, and streaming formats such as RealMedia. They are different at least in part because of their different focus and applicability. Some of these formats are sufficiently widely accepted, broad in their application, and relatively easy to implement, that they are used not only for content delivery but also as interchange formats such as the QuickTime file format. The QuickTime format is used today by many web sites serving time-based data; in many authoring environments, including professional ones; and on many multimedia CD ROM (e.g., DVD or CD-I) titles.</p>
  <p num="p-0005">The QuickTime media layer supports the relatively efficient display and management of general multimedia data, with an emphasis on time-based material (video, audio, video and audio, motion graphics/animation, etc.). The media layer uses the QuickTime file format as the storage and interchange format for media information. The architectural capabilities of the layer are generally broader than the existing implementations, and the file format is capable of representing more information than is currently demanded by the existing QuickTime implementations. Furthermore, the QuickTime file format has structures to represent the temporal behavior of general time-based streams, a concept which covers the time-based emission of network packets, as well as the time-based local presentation of multimedia data.</p>
  <p num="p-0006">Given the capabilities and flexibility provided by time-based media formats, it is desirable to provide a user interface that provides suitable functionality and flexibility for playback and/or other processing of time-based media in such formats.</p>
  <p num="p-0007">Prior user interfaces for controlling the presentation of time-based media include user interfaces for the RealPlayers from RealNetworks of Seattle, Wash., user interfaces for the QuickTime MoviePlayers from Apple Computer, Inc. of Cupertino, Calif., and user interfaces for the Windows Media Players from Microsoft Corporation of Redmond, Wash. Also, there are a number of time-based media authoring systems which allow the media to be created and edited, such as Premiere from Adobe Systems of San Jose, Calif.</p>
  <p num="p-0008">These prior user interfaces typically use pop-up or pull-down menus to display controls (e.g. controls for controlling playback) or to display a list of favorites or channels which are typically predetermined, selected media (e.g. CNN or another broadcast source which is remotely located or a locally stored media source). While these lists or menus may be an acceptable way of presenting this information, the lists or menus may not be easily alterable and the alteration operations are not intuitive. Further, these lists or menus are separate from any window presenting the media and thus do not appear to be part of such window.</p>
  <p num="p-0009">In some prior user interfaces, the various controls are displayed on a border of the same window which presents the media. For example, a time bar may be displayed on a window with controls for playback on the same window. While these controls are readily visible and available to a user, a large number of controls on a window causes the window to appear complex and tends to intimidate a novice user.</p>
  <p num="p-0010">Some prior user interfaces include the ability to select, for presentation, certain chapters or sections of a media. LaserDisc players typically include this capability which may be used when the media is segmented into chapters or sections. A user may be presented with a list of chapters or sections and may select a chapter or section from the list. When this list contains a large number of chapters or sections, the user may scroll through the list but the speed of scrolling is fixed at a single, predetermined rate. Thus, the user's ability to scroll through a list of chapters is limited in these prior user interfaces.</p>
  <p num="p-0011">Certain prior user interfaces which allow for editing of time-based media may include the ability of selecting a range of time of the media for editing in that selected range. However, these interfaces do not allow for the playback, through a single playback button, of a selected range of a media which has been selected by at least one dragging action of an indicator.</p>
  <heading>SUMMARY OF THE DESCRIPTION</heading> <p num="p-0012">The present invention relates to various aspects for controlling and/or presenting information concerning time-based media, such as a movie.</p>
  <p num="p-0013">In one aspect of the invention, an exemplary method of the invention allows for the selection of a presentation of time-based media. In this method, a graphical representation of a time line for the time-based media is displayed, and a graphical representation of a current time is also displayed along the graphical representation of the time line. A start graphical indicator and a stop graphical indicator is also displayed along the graphical representation of the time line. The start graphical indicator or the stop graphical indicator may be positioned, for example, by dragging, either of the indicator along the graphical representation of the time line to select a portion of the time-based media for presentation. In one typical example of this method, both the start graphical indicator and the stop graphical indicator may be dragged along the time line to select a portion of a movie for presentation.</p>
  <p num="p-0014">According to another aspect of the present invention, a method is provided for generating an interface for display for controlling the processing of time-based media data. A first set of data representing a graphical user interface as a primary window is generated and displayed. A second set of data representing a drawer window is generated and contains objects such as representations (e.g. icons) of favorites or channels media. In a first display state, the drawer window is at least partially overlapped by the primary window, and in a second display state is at least partially viewable. In one embodiment, the drawer window appears to be part of the primary window and slides under the primary window when the drawer window is closed. In one embodiment, when the primary window is moved, the drawer window moves with the primary window as part of the primary window. The drawer window, in one embodiment, provides a plurality of locations which are fixed and predetermined, each for displaying a time-based media icon (e.g. a thumbnail image) associated with a time-based media file. In one embodiment, the thumbnail image represents a favorite or channel time-based media, and the user may drag an icon into the drawer window or out of the drawer window in order to alter the contents of the drawer window.</p>
  <p num="p-0015">According to another aspect of the present invention, a method is provided for generating a graphical user interface for control of processing of time-based media data. In an exemplary method according to this aspect, a first set of data representing the graphical user interface is generated and displayed as a primary window. A second set of data representing an auxiliary drawer window is generated for display. In a first display state, the auxiliary drawer window is at least partially overlapped by the primary window and in a second display state it is at least partially viewable. In one embodiment, the auxiliary drawer window appears to be part of the primary window and slides under the primary window when the auxiliary drawer is closed. When the primary window is moved in one embodiment, the auxiliary drawer window moves with the primary window as part of the primary window. In one embodiment, the auxiliary drawer window provides information relating to a time-based media file or controls for the control of a time-based media file.</p>
  <p num="p-0016">According to another aspect of the present invention, a method is provided for controlling a graphical user interface which processes time-based media information. In one exemplary method of this aspect, input to change a portion of the graphical user interface is detected. This portion indicates time relating to the time-based media. An input speed of the input is determined and a rate at which to change the portion is also determined, where the rate is dependent on the input speed. The information displayed in the portion is changed according to the rate which is dependent upon the input speed. In one particular example according to this aspect of the invention, a chapter selection mechanism allows the user to select different chapters within a movie by causing a chapter display area to have chapters scroll within the area. The speed of scrolling is controlled by the movement of a cursor or other input.</p>
<description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0017">The present invention is illustrated by way of example and not limitation in the figures of the accompanying drawings in which like references indicate similar elements.</p>
    <p num="p-0018"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a diagram of a network of computer systems in which media data may be processed, according to one embodiment of the present invention.</p>
    <p num="p-0019"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a block diagram of a digital processing system which may be used to process time-based media data, in accordance with one embodiment of the present invention.</p>
    <p num="p-0020"> <figref idrefs="DRAWINGS">FIG. 3A</figref> shows a GUI (graphical user interface), and in particular, a time-based media player display window for displaying, controlling, and/or otherwise processing time-based media data, according to one embodiment of the invention.</p>
    <p num="p-0021"> <figref idrefs="DRAWINGS">FIG. 3B</figref> shows an example of an audio-only window for a time-based media player.</p>
    <p num="p-0022"> <figref idrefs="DRAWINGS">FIG. 4</figref> illustrate the time-based media player of <figref idrefs="DRAWINGS">FIG. 3A</figref> depicting a favorite/channel drawer that is partially open (i.e., partially displayed), according to one embodiment of the invention.</p>
    <p num="p-0023"> <figref idrefs="DRAWINGS">FIG. 5A</figref> is a diagram of a time-based media player providing a favorite/channel drawer generated as a GUI, according to one embodiment of the invention.</p>
    <p num="p-0024"> <figref idrefs="DRAWINGS">FIG. 5B</figref> shows an example of a user interface for altering the icons in a drawer of a player window according to one embodiment of the invention.</p>
    <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 6A</figref> is a diagram of time-based media player providing an information panel (or drawer) window generated as GUI, according to one embodiment of the invention.</p>
    <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 6B</figref> is a diagram of a time-based media player providing a control panel (or drawer) window generated as a GUI, according to one embodiment of the invention.</p>
    <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 7A</figref> illustrates a time/chapter display control of a time-based media player generated as a GUI, and in particular, <figref idrefs="DRAWINGS">FIG. 7A</figref> illustrates an adaptive chapter display/control, according to one embodiment of the invention.</p>
    <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 7B</figref> illustrates a time/chapter display control of a time-based media player generated as a GUI, and in particular, <figref idrefs="DRAWINGS">FIG. 7B</figref> illustrates an adaptive chapter display/control, according to one embodiment of the invention.</p>
    <p num="p-0029"> <figref idrefs="DRAWINGS">FIGS. 7C-7J</figref> show the scrolling capabilities of the chapter display area <b>260</b> according to one embodiment of the invention.</p>
    <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 8A</figref> illustrates a GUI mechanism of a time-based media player for selecting a range of time within a time-based media file, according to one embodiment of the invention.</p>
    <p num="p-0031"> <figref idrefs="DRAWINGS">FIG. 8B</figref> illustrates a GUI mechanism of a time-based media player for selecting a range of time within a time-based media file, according to one embodiment of the invention.</p>
    <p num="p-0032"> <figref idrefs="DRAWINGS">FIG. 8C</figref> illustrates a flowchart which shows a method for selecting a range of time for playback of a time-based media file.</p>
    <p num="p-0033"> <figref idrefs="DRAWINGS">FIGS. 8D-8F</figref> show an example of a timecode mode selector interface which may be used with the current time, start and end markers.</p>
    <p num="p-0034"> <figref idrefs="DRAWINGS">FIG. 9A</figref> illustrates an adaptive streaming status message display of a time-based media player generated as a GUI, according to one embodiment of the invention.</p>
    <p num="p-0035"> <figref idrefs="DRAWINGS">FIG. 9B</figref> illustrates an adaptive streaming status message display of a time-based media player generated as a GUI, according to one embodiment of the invention.</p>
    <p num="p-0036"> <figref idrefs="DRAWINGS">FIGS. 9C-9H</figref> show another example of a status message display for a media player according to the present invention.</p>
    <p num="p-0037"> <figref idrefs="DRAWINGS">FIGS. 10A-10C</figref> illustrate resizing a time-based media player generated as a GUI and/or a display window for displaying time-based images, according to one embodiment of the invention. <figref idrefs="DRAWINGS">FIG. 10D</figref> is a flowchart which shows one method for controlling the display of a time-based media player during a resizing operation. <figref idrefs="DRAWINGS">FIGS. 10E and 10F</figref> show examples of resizing operations.</p>
    <p num="p-0038"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a flow diagram illustrating a method for providing a favorite/channel drawer window for a time-based media player generated as a GUI, according to one embodiment of the invention.</p>
    <p num="p-0039"> <figref idrefs="DRAWINGS">FIG. 12A</figref> is a flow diagram illustrating a method for providing adaptive chapter/time selection for play back or other processing of time-based media in a GUI, according to one embodiment of the invention. <figref idrefs="DRAWINGS">FIG. 12B</figref> shows an example of a chapter selection interface which adaptively scrolls a chapter indicator (e.g. a chapter number or name) in response to user input (e.g. speed of cursor movement).</p>
    <p num="p-0040"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a flow diagram illustrating a method for providing auxiliary drawers/panels for a time-based media player generated as a GUI, according to one embodiment of the invention.</p>
    <p num="p-0041"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a block diagram of a machine-readable medium storing executable code and/or other data to provide one or a combination of mechanisms for play back or other processing of time-based media in a GUI, according to one embodiment of the invention.</p>
  </description-of-drawings> <heading>DETAILED DESCRIPTION</heading> <p num="p-0042">Various embodiments and aspects of the invention will be described with reference to details discussed below, and the accompanying drawings will illustrate the various embodiments. The following description and drawings are illustrative of the invention and are not to be construed as limiting the invention. Numerous specific details are described to provide a through understanding of various embodiments of the present invention. However, in certain instances, well-known or conventional details are not described in order to provide a concise discussion of embodiments of the present invention.</p>
  <p num="p-0043">The present invention provides methods and apparatuses for processing media information. In one embodiment of the present invention, a graphical user interface (GUI) is provided that includes a number of features for referencing, playing back, and/or otherwise processing time-based media information (e.g., video, animated graphics, and/or audio, etc.). In one embodiment, the GUI, also sometimes referred to as a media player, provides functionality for processing time-based media in the QuickTime format, such as QuickTime movies, which typically include audio and motion video information. Although the present invention is described with reference to the QuickTime media data format, it will be appreciated that the invention may also be used in a variety of environments, in conjunction with other media data formats, and with various types of data processing systems having a number of different types of architectures. Thus, the invention should not be limited to the systems, media data formats, or architectures disclosed herein, which are meant only to provide an understanding of the invention, whose scope is defined by the claims which follow.</p>
  <heading>Hardware Overview</heading> <p num="p-0044"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a diagram of a network of computer systems in which media data may be processed, according to one embodiment of the present invention. As shown in <figref idrefs="DRAWINGS">FIG. 1</figref>, a network <b>100</b> includes a number of client computer systems that are coupled together through an Internet <b>122</b>. It will be appreciated that the term Internet refers to a network of networks. Such networks may use a variety of protocols for exchange of information, such as TCP/IP, ATM, SNA, SDI, etc. The physical connections of the Internet and the protocols and communication procedures of the Internet are well known to those in the art.</p>
  <p num="p-0045">Access to the Internet <b>122</b> is typically provided by Internet service providers (ISPs), such as the ISP <b>124</b> and the ISP <b>126</b>. Users on client systems, such as the client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>120</b>, generally obtain access to the Internet through Internet service providers, such as ISPs <b>124</b> and <b>126</b>. Access to the Internet may facilitate transfer of information (e.g., email, text files, media files, etc.) between two or more digital processing systems, such as the client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>120</b> and/or a Web server system <b>128</b>. For example, one or more of the client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>120</b> and/or the Web server <b>128</b> may provide media data (e.g., video and audio, or video, or audio) to another one or more of the client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>120</b> and/or the Web server <b>128</b>. For example, in one embodiment of the invention, one or more of the client computer systems <b>102</b>, <b>104</b>, <b>118</b> and <b>120</b> may request play-back of time-based media data that may be stored at a remote location, such as the Web server <b>128</b>. In the case of remote storage, the data may be transferred as a file (e.g. downloaded) and then played back after transferring the file or, if a streaming media system is available, the data may be played back at the client while the transfer occurs. In another embodiment, the requested time-based media data may be stored locally at the client computer system <b>102</b>, <b>104</b>, <b>118</b>, and/or <b>120</b>. In the case of local storage, the client system may play back time-based media using a playback system (e.g. a QuickTime Player) without requiring a network connection.</p>
  <p num="p-0046">The Web server <b>128</b> typically includes at least one computer system to operate with one or more data communication protocols, such as the protocols of the World Wide Web, and as such, is typically coupled to the Internet <b>122</b>. Optionally, the Web server <b>128</b> may be part of an ISP which may provide access to the Internet and/or other network(s) for client computer systems. The client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>120</b> may each, with appropriate web browsing software, access data, such as HTML documents (e.g., Web pages), which may be provided by the Web server <b>128</b>. Such data may provide media, such as QuickTime movies, which may be played back/presented by the client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>120</b>.</p>
  <p num="p-0047">The ISP <b>124</b> provides Internet connectivity to the client computer system <b>102</b> via a modem interface <b>106</b>, which may be considered as part of the client computer system <b>102</b>. The client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>620</b> may be a conventional data processing system, such as a Macintosh computer, a network computer, a handheld/portable computer, a Web TV system, or other types of digital processing systems (e.g., a cellular telephone having digital processing capabilities).</p>
  <p num="p-0048">Similarly, the ISP <b>126</b> provides Internet connectivity for the client computer systems <b>104</b>, <b>118</b> and <b>120</b>. However, as depicted in <figref idrefs="DRAWINGS">FIG. 1</figref>, such connectivity may vary between various client computer systems, such as the client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>120</b>. For example, as shown in <figref idrefs="DRAWINGS">FIG. 1</figref>, the client computer system <b>104</b> is coupled to the ISP <b>126</b> through a modem interface <b>108</b>, while the client computer systems <b>118</b> and <b>120</b> are part of a Local Area Network (LAN). The interfaces <b>106</b> and <b>108</b>, shown as modems <b>106</b> and <b>108</b>, respectively, may represent an analog modem, an ISDN modem, a cable modem, a satellite transmission interface (e.g., Direct PC), a wireless interface, or other interface for coupling a digital processing system, such as a client computer system, to another digital processing system. The client computer systems <b>118</b> and <b>120</b> are coupled to a LAN bus <b>112</b> through network interfaces <b>114</b> and <b>116</b>, respectively. The network interfaces <b>114</b> and <b>116</b> may be an Ethernet-type, Asynchronous Transfer Mode (ATM), or other type of network interface. The LAN bus is also coupled to a gateway digital processing system <b>110</b>, which may provide firewall and other Internet-related services for a LAN. The gateway digital processing system <b>110</b>, in turn, is coupled to the ISP <b>126</b> to provide Internet connectivity to the client computer systems <b>118</b> and <b>120</b>. The gateway digital processing system <b>110</b> may, for example, include a conventional server computer system. Similarly, the Web server <b>128</b> may, for example, include a conventional server computer system.</p>
  <p num="p-0049">The system <b>100</b> may allow one or more of the client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>120</b> and/or the Web server <b>628</b> to provide time-based media data (e.g., video and audio, or video, or audio) to another one or more of the client computer systems <b>102</b>, <b>104</b>, <b>118</b>, and <b>120</b> and/or the Web server <b>128</b>. As described below, the present invention facilitates playing back and other functionality for processing the media data.</p>
  <p num="p-0050"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a block diagram of a digital processing system which may be used to process time-based media data, in accordance with one embodiment of the present invention. For example, the digital processing system <b>150</b> shown in <figref idrefs="DRAWINGS">FIG. 2</figref> may be used as a client computer system (e.g., the client computer system <b>102</b>, <b>104</b>, <b>118</b>, and/or <b>120</b>), a Web server system (e.g., the Web server system <b>128</b>), a conventional server system, etc. Furthermore, the digital processing system <b>150</b> may be used to perform one or more functions of an Internet service provider, such as the ISP <b>124</b> or <b>126</b>. The digital processing system <b>150</b> may be interfaced to external systems through a modem or network interface <b>168</b>. It will be appreciated that the modem or network interface <b>168</b> may be considered as part of the digital processing system <b>150</b>. The modem or network interface <b>168</b> may be an analog modem, an ISDN modem, a cable modem, a token ring interface, a satellite transmission interface, a wireless interface, or other interface(s) for providing a data communication link between two or more digital processing systems.</p>
  <p num="p-0051">The digital processing system <b>150</b> includes a processor <b>152</b>, which may represent one or more processors and may include one or more conventional types of such processors, such as a Motorola PowerPC processor, an Intel Pentium (or x86) processor, etc. A memory <b>154</b> is coupled to the processor <b>152</b> by a bus <b>156</b>. The memory <b>154</b> may be a dynamic random access memory (DRAM) and/or may include static RAM (SRAM). The processor may also be coupled to other types of storage areas/memories (e.g., cache, Flash memory, disk, etc.), which could be considered as part of the memory <b>154</b> or separate from the memory <b>154</b>.</p>
  <p num="p-0052">The bus <b>156</b> further couples the processor <b>152</b> to a display controller <b>158</b>, a mass memory <b>162</b>, the modem or network interface <b>168</b>, and an input/output (I/O) controller <b>164</b>. The mass memory <b>162</b> may represent a magnetic, optical, magneto-optical, tape, and/or other type of machine-readable medium/device for storing information. For example, the mass memory <b>162</b> may represent a hard disk, a read-only or writeable optical CD (e.g., CD ROM, DVD), etc. The display controller <b>158</b> controls in a conventional manner a display <b>160</b>, which may represent a cathode ray tube (CRT) display, a liquid crystal display (LCD), a plasma display, or other type of display device. The I/O controller <b>164</b> controls I/O device(s) <b>166</b>, which may include one or more keyboards, mouse/trackball or other pointing devices, microphones (for speech recognition capabilities), magnetic and/or optical disk drives, printers, scanners, digital cameras, microphones, etc.</p>
  <p num="p-0053">It will be appreciated that the digital processing system <b>150</b> represents only one example of a system, which may have many different configurations and architectures, and which may be employed with the present invention. For example, Macintosh and other systems often have multiple busses, such as a peripheral bus, a dedicated cache bus, etc. On the other hand, a network computer, which may be used as a digital processing device of the present invention, may not include, for example, a hard disk or other mass storage device, but may receive routines and/or data from a network connection, such as the modem or interface <b>168</b>, to be processed by the processor <b>152</b>. Similarly, a Web TV system, which is known in the art, may be considered to be a digital processing system of the present invention, but such a system may not include one or more I/O devices, such as those described above with reference to I/O device(s) <b>166</b>. Additionally, a portable communication and data processing system, which may employ a cellular telephone and/or paging capabilities, may be considered a digital processing system which may be used with the present invention.</p>
  <p num="p-0054">In the system <b>150</b> shown in <figref idrefs="DRAWINGS">FIG. 2</figref>, the mass memory <b>162</b> (and/or the memory <b>154</b>) may store time-based media (e.g., video, audio, movies, etc.) which may be processed according to the present invention. Alternatively, media data may be received by the digital processing system <b>150</b>, for example, via the modem or network interface <b>168</b>, and stored and/or presented by the digital processing system <b>150</b>, for example, via the display <b>160</b> and/or I/O device(s) <b>166</b>, which may include audio speakers, headphones, and/or other media playback output devices. In one embodiment, packetized media data may be transmitted across a data communication network, such as a LAN and/or the Internet, in accordance with the QuickTime format to be processed by the system <b>150</b> in accordance with the present invention. On the other hand, the digital processing system <b>150</b> may locally store time-based media data in the mass memory <b>162</b>, the memory <b>164</b>, and/or another machine-readable medium accessible by the digital processing system <b>150</b>, as well as executable code that provides functionality for processing time-based media data in accordance with the present invention.</p>
  <heading>Overview of One Embodiment of the Invention</heading> <p num="p-0055"> <figref idrefs="DRAWINGS">FIG. 3A</figref> shows a GUI, and in particular, a time-based media player display window for displaying, controlling, and/or otherwise processing time-based media data, according to one embodiment of the invention.</p>
  <p num="p-0056">As shown, a time-based media player (media player) <b>200</b>, which is typically displayed as a window on a display of a computer or other digital processing system, includes a number of display and control functions for processing time-based media data, such as a QuickTime movie. The player window <b>200</b> may be closed using a close box <b>222</b> (e.g. the user may click on this box to close the window by positioning a cursor on the box and depressing and releasing a button, such as a mouse's button while the cursor remains positioned on the close box).</p>
  <p num="p-0057">The media player <b>200</b> includes a movie display window <b>202</b> for displaying a movie or other images associated with time-based media. In addition, a time/chapter display and control region <b>204</b> of the media player <b>200</b> provides functionality for displaying and/or controlling time associated with a particular time-based media file (e.g., a particular movie processed by the player <b>200</b>). As described below, a time-based media file may be sub-indexed into chapters or sections which correspond to time segments of the time-based media file, and which chapters may also be titled. As such, a user may view or select a time from which, or time segment in which, to play back a time-based media file. Such selection, as described below, may be based on a particular chapter name and/or a particular time relative to the time-length of the time-based media file.</p>
  <p num="p-0058">The media player <b>200</b> includes a number of other mechanisms for controlling playback, display, and/or other processing of time-based media. For example, a volume dial <b>220</b> controls the audio output level (e.g., through speakers, headphones, or other audio output device). In one embodiment, a cursor controlled through a pointing device (e.g., a mouse, trackball, touchpad, arrow keys of a keyboard, etc.) or speech recognition enables a user to control the dial <b>220</b>, as well as other features of the media player <b>200</b>. For example, in one embodiment, a user may place the cursor upon the volume dial <b>200</b> using a pointing device, and control the audio output level/volume by holding down the click button of the pointing device (to select or activate the volume dial icon <b>220</b>) and then moving the cursor up or down to change the level/volume up or down, respectively. In one embodiment, a volume level display/control <b>218</b> displays the current volume level by highlighting on the display one or more graphical level lines, wherein when more lines are highlighted, the higher the volume. Thus, as the dial <b>220</b> is turned up to increase the audio output level, more lines will become highlighted, and conversely, when the dial <b>220</b> is turned down to decrease the volume, less lines become highlighted in the volume level display control <b>218</b>. In the embodiment depicted in <figref idrefs="DRAWINGS">FIG. 3A</figref>, the user may also vary the audio output level/volume by placing the cursor on the volume level/display control <b>218</b>, activating the icon (e.g., by pressing and holding a mouse or other pointing device selection/click button), and moving the cursor to the right (to increase the volume) or to the left (to decrease the volume), in which case the dial <b>220</b> will turn up or down, respectively, while the level lines of the volume level/display control <b>218</b> will be highlighted accordingly. Also, in one embodiment, the user may select (e.g. click on) the audio icon <b>217</b> to turn off the audio portion of a presentation. As shown, the media player <b>200</b> also includes a play button <b>216</b> and a pause button <b>212</b>, which allow play back and pausing of a (currently selected) time-based media file.</p>
  <p num="p-0059">As described below, the present invention provides secondary or drawer or panel or tray windows to be opened from the primary or media player <b>200</b> window. As such, the drawer or panel or tray windows, when opened or closed in response to user input, for example, will resemble drawers that open or close from the media player <b>200</b> window, as shown in <figref idrefs="DRAWINGS">FIGS. 4</figref>, <b>5</b>A, <b>6</b>A and <b>6</b>B. These drawer windows (e.g. the favorite/channel drawer window <b>230</b>), in one embodiment, are part of the primary window and are moved with the primary window and are opened or closed with the primary window. That is, when the primary window is moved around the desktop (on the display screen), the drawer window is moved with the primary window and appears attached to the primary window. When the primary window is first opened, the handle portion of the drawer window is opened and is displayed and appears attached to the primary window. When the primary window is closed (e.g. removed from the display screen), the drawer window is closed. The drawer window, in one embodiment, typically includes a handle portion which includes a drawer control (e.g. drawer control <b>214</b>) which may be used to slide the drawer window open (e.g. display favorite/channel icons) or, if the drawer window is opened, to close the drawer window so that only the handle portion, typically attached to the primary window on an edge of the primary window, is displayed. The handle portion of the drawer window may also include other controls, such as a resize control <b>208</b>. In one embodiment, objects, such as icons representing media (e.g. favorites or channels), may be selected from regions outside of the drawer window (e.g. icons on the desktop may be selected) and may be then dragged to a predetermined (e.g. tiled) region inside of the drawer window. This causes the selected object, in one exemplary embodiment, to become a favorite or channel. Similarly, an object (e.g. an icon representing a favorite or channel media) may be selected within the drawer window and dragged outside of the window (e.g. dragged to the desktop or to a folder on the desktop or dragged to an icon representing a trash or waste receptacle or function). This has the effect of either creating an alias or short cut for the selected object (when dragged to a folder) or deleting the object from the drawer window. Thus, the drawer window, in one embodiment, acts as a desktop window into which, and from which, objects (e.g. an icon of a favorite or a channel) may be dragged and it appears as part of a primary window which presents media data (e.g. displays still images or movies or plays back audio only, etc.).</p>
  <p num="p-0060">The drawers or trays of the media player <b>200</b> provide additional functionality or information in association with play back or other processing of a time-based media file. For example, the tray associated with a controls button <b>206</b>, as described below, includes a number of other mechanisms to control play back and other processing of a time-based media file, which mechanisms may include, for instance, audio balance, bass, and treble controls, forward/reverse scan controls, step back/forward controls, etc. As such, a user may activate the controls button <b>206</b> (e.g., by clicking/double clicking with a pointing device while the cursor is on the controls button <b>206</b>), and the control panel will, in one embodiment, slide from the media player <b>200</b> window appearing as if it was a drawer hidden/closed under the media player <b>200</b>. Similarly, a favorite/channel drawer control <b>214</b>, when activated by the user (e.g., using a pointing device), opens a favorite/channel drawer which is described in further detail below. Finally, an information button <b>210</b> opens an information tray <b>250</b> when activated and this tray will, in one embodiment, slide from the media player <b>200</b>, appearing as if it was a drawer hidden/closed under the media player <b>200</b>.</p>
  <p num="p-0061">The size of the media player <b>200</b> and/or the motion video display window <b>202</b> may also be varied by activating a resize control <b>208</b>. In one embodiment, the media player <b>200</b> is displayed at a default minimum size. In this embodiment, when the resize control <b>208</b> is activated, two animated rectangles are displayed: one animated rectangle represents the size of the motion display window <b>202</b> (with any image displayed therein) and the other animated rectangle represents the media player <b>200</b> window. Each animated rectangle represents the currently selected size of one of these two windows, and thus each animated rectangle indicates the size of the window if the currently selected size is ultimately selected by the user. As such, the resize control <b>208</b> may be dragged by the cursor to resize the motion video display window <b>202</b> (and any image displayed thereby) without changing the size of the window <b>200</b> until the size of window <b>202</b> increases to a threshold size, which in one embodiment, corresponds to substantially the edges of the media player <b>200</b> or a window <b>202</b> of dimensions 320240 pixels. When this occurs, an attempt to further enlarge the motion video display window <b>202</b> will enlarge the media player <b>200</b> window and the window <b>202</b> together. In other words, if the outer window rectangle is larger than the minimum (default size), the two rectangles grow and shrink proportionally together. However, if the user attempts to shrink the media player <b>200</b> window's animated rectangle below the minimum size, only the motion video display window <b>202</b> (and its animated rectangle) will shrink, and the size of the media player <b>200</b> window will remain unchanged from the minimum size.</p>
  <p num="p-0062"> <figref idrefs="DRAWINGS">FIG. 3B</figref> shows an example of an audio-only player window. The player window of <figref idrefs="DRAWINGS">FIG. 3B</figref> may include the same controls and drawers as the player of <figref idrefs="DRAWINGS">FIG. 3A</figref> except that only audio media is played back through the player window of <figref idrefs="DRAWINGS">FIG. 3B</figref>.</p>
  <p num="p-0063">It will be appreciated that the media presented through the various interfaces of the invention is not limited to movies with audio, or movies without audio, or audio-only time-based media (e.g. speeches or music), or still images or combinations of these media. It also will be appreciated that the drawers may contain any number of different types of controls or, generally, objects associated with media or control of the presentation of media. These controls in the drawers allow a user to manipulate and design a presentation of media or otherwise control it. A drawer may contain a combination of controls (e.g. control buttons) and favorites or channels of media, although in the embodiment shown in <figref idrefs="DRAWINGS">FIGS. 4</figref>, <b>6</b>A and <b>6</b>B, the controls are displayed in one drawer separately from a drawer containing favorites and/or channels. It will also be appreciated that, in one instance, the favorites are merely preselected media (either locally stored or received from a remote site) which the user (or the system at the user's request or the system on its own) has decided to save for future use by designating the media as a favorite (which is similar to the manner in which a web site is selected as a favorite or is selected as a bookmark in a Web browser such as Microsoft's Internet Explorer or Netscape's Navigator). It will also be appreciated that a player window (e.g. window <b>200</b>) may have multiple drawers for favorites or channels; for example, there may be two separate drawers for favorites and two separate drawers for channels. The controls may also be placed in separate drawers.</p>
  <heading>Favorite/Channel Drawer</heading> <p num="p-0064">Now referring to <figref idrefs="DRAWINGS">FIG. 4</figref>, the time-based media player of <figref idrefs="DRAWINGS">FIG. 3A</figref> is shown depicting a favorite/channel drawer that is partially open, according to one embodiment of the invention. In particular, the media player <b>200</b> is shown along with a favorite/channel drawer <b>230</b>. In one embodiment, in response to a user input with respect to the favorite/channel drawer control <b>214</b>, which may involve activation of the favorite/channel drawer control <b>214</b> by placing a cursor thereon and clicking and holding a pointing device (e.g., a mouse button), the favorite/channel drawer <b>230</b> may be opened as a secondary drawer window with respect to the media player window <b>200</b>, such that it appears to be at least partially overlapped by and attached to the media player <b>200</b>. Prior to being opened as a secondary window, a handle of the secondary window is displayed next to the primary window, and this handle remains attached to the secondary window after the secondary window is opened. By moving the cursor up and down while the favorite/channel drawer control <b>214</b> is activated (e.g. the cursor is placed over the control <b>214</b> and the mouse's button is held depressed), a user may close and open the favorite/channel drawer (window) <b>230</b> to be displayed in various proportions relative to the media player <b>200</b> window. Examples of mechanisms and terminology for display interfaces, cursor control, and drawer user interfaces are described in U.S. Pat. No. 5,745,096, issued on Apr. 28, 1998, and entitled, Desk Drawer User Interface, which is hereby incorporated by reference herein. The favorite/channel drawer <b>230</b> may also be referred to as a media drawer.</p>
  <p num="p-0065">Typically, the media player window <b>200</b> is displayed as a primary window, for example, on a desktop window which may be moved around the desktop (e.g. moved by dragging the window around the desktop). The media player window may include a trigger region, such as the drawer control <b>214</b>, for controlling display of a secondary window, the drawer <b>230</b>. It will be appreciated that while the drawer <b>230</b> is referred to as a secondary window it is effectively, in one embodiment, part of the primary window in that it is attached to the primary window and moves with the primary window as it is moved around the desktop. A cursor control device (sometimes also referred to as a pointing device) may be used to control a cursor position on a display. Alternatively, speech recognition may be used to open and close the favorite/channel drawer. When the cursor is placed on a screen/display region of the trigger region and the region is selected (e.g., by depressing a mouse or other cursor select/activation input device) in a first state of the favorite/channel drawer window, in which state the contents of the drawer window are not displayed (e.g., as shown in <figref idrefs="DRAWINGS">FIG. 3A</figref>), a user may drag the cursor (e.g., in a downward direction) to open or reveal for display the contents of the drawer or a portion thereof, in which case the drawer is in a second (or displayed/open) state. This second state of the drawer window is shown in <figref idrefs="DRAWINGS">FIGS. 4 and 5A</figref>. The drawer may slide open with a sliding (e.g. nearly continuous) animation or may pop open from a closed state. Similarly, the drawer may slide closed with a sliding animation or may pop closed without any sliding animation. The cursor can further be controlled to place time-based media source icons into the drawer (e.g. by dragging an icon from a desktop or folder on the desktop to the drawer), remove time-based media source icons from the drawer, rearrange time-based media source icons between locations in the drawer or other windows, and/or select for playback a media file associated with an icon displayed in the drawer (e.g., by placing the cursor over that icon and activating the icon). As described below, the media player may also include auxiliary drawer windows which may be operated similarly to provide functionality and/or information relating time-based media data that may be processed by the GUI media player of the present invention.</p>
  <p num="p-0066">In <figref idrefs="DRAWINGS">FIG. 4</figref>, the drawer <b>230</b> is shown partially opened to reveal a favorite/channel row <b>244</b> and a portion of a row <b>246</b>. The favorite/channel row <b>244</b> comprises favorite/channel wells <b>232</b>, <b>234</b>, <b>236</b>, <b>238</b>, and <b>240</b>. Each favorite/channel well represents, in one embodiment, a fixed, predetermined, tiled display location within the drawer <b>230</b> that may contain a reference (e.g., a display/cursor activated icon) to particular time-based media source, which in one embodiment may be a particular time-based media file or a particular time-based media channel. For example, as shown in <figref idrefs="DRAWINGS">FIG. 4</figref>, the well <b>234</b> contains a media source icon <b>248</b> and the well <b>238</b> contains a media source icon <b>250</b>, each of which may reference a particular time-based media file or channel or may reference a non-time-based media file. Each row of the drawer includes tiled compartments, each of which is designed to hold one media source icon. The filed compartments have a fixed, predetermined location, thereby preventing placement (in one embodiment) of a media source icon in an arbitrary location. Any attempt to drop an icon in an arbitrary location will result in the icon being placed into an available well (not already occupied by an icon). That is, the placement is restricted to the tiled (e.g. non-overlapping) locations. In one embodiment, the media player <b>200</b> may be generated and displayed on a client computer system, such as one shown in <figref idrefs="DRAWINGS">FIG. 1</figref>, and the media source icon <b>248</b> may reference a particular time-based media file, such as a QuickTime movie, that is stored locally by the client computer system or at a remote location (e.g., a Web server system) that provides the media file for play back (or other forms of presentation) by the media player <b>200</b> in response to a request. In one embodiment, such a play back request is performed by activating the media source icon <b>248</b> (e.g., by pointing the cursor thereon and clicking on it). For example, if the time-based media file comprises motion video, such will be displayed in the display window <b>202</b> after activating the associated media source icon. In one embodiment, when a source icon (e.g. icon <b>248</b>) is activated, a highlighting is displayed around the edges of the well which contains the activated icon.</p>
  <p num="p-0067">In addition, a media source icon, such as the media source icon <b>248</b>, may reference a particular media channel, such as a news provider (e.g., CNN, Fox News, etc.), a major network (e.g., ABC, NBC, CBS, etc.), a shopping network, or another channel. Such channels correspond to sources that typically provide continuous time-based media information/programming via a media source, such as a Web server coupled to the Internet. Such a media source may stream media information into data packets that may transferred across a data processing network, such as the one shown in <figref idrefs="DRAWINGS">FIG. 1</figref>, according to the QuickTime or other media format and such data may not be stored locally (except perhaps for any ephemeral storage required for local playback). The address of such media is associated with the media source icon and is stored for quick access by the user.</p>
  <p num="p-0068">Thus, wells may be filled with icons associated with files from the user's digital processing system (e.g., a file may be dragged from the desktop or other window/directory to a well in the drawer or a file menu associated with the drawer may be used to add an icon to a well in the drawer) or may be filled with icons (which may sometimes also be referred to as bookmarks) associated with streamed time-based media provided by a remote (e.g., Web) system. In one embodiment, a user may subscribe to certain channels, media (Web) servers, etc., which will then provide the icons associated with the subscribed media source(s) into wells in the drawer and/or any other directory associated therewith. Thus, in one embodiment, the drawer may be altered by the user or automatically altered/updated by a remote server or other digital processing system by transferring, rearranging, adding, or deleting time-based media icons therein. In one embodiment, the favorite/channel drawer may contain icons associated with favorite media of the user.</p>
  <p num="p-0069">In one embodiment, media source icons provide a graphical reference to the media source associated therewith. For example, a particular frame of a motion video may be used as a thumbnail to represent the media source (e.g., file, channel, etc.) associated therewith. As such, data (e.g., a frame) from a particular media file or other media source may be used to generate a media source icon in the drawer <b>230</b> to reference that particular media file. On the other hand, a media source icon may include text or symbols or other graphics or images to identify a media file or channel associated therewith. For instance, the logo/symbol associated with a particular news or network channel may be used as a media source icon that references that channel to play back time-based media provided thereby when that icon is activated.</p>
  <p num="p-0070">In one embodiment, a particular time-based media icon may be highlighted graphically when selected (e.g., by placement of the cursor thereon and/or single clicking a pointing device thereon). Such highlighting, in one embodiment, includes providing a border around a selected time-based media icon. It will be appreciated that selection may, but does not always include, activation of the icon, the latter of which runs/loads the media (e.g. file or channel) associated with the icon. For example, in one embodiment, activating a particular time-based media icon is performed by selecting and then clicking that icon, which in turn causes the time-based media player <b>200</b> to play the time-based media file associated with that icon. In one embodiment, the drawer <b>230</b> may slide closed after a source icon in a channel has been selected for presentation (e.g. displaying video and reproducing the associated audio).</p>
  <p num="p-0071"> <figref idrefs="DRAWINGS">FIG. 5A</figref> is a diagram of a time-based media player providing a favorite/channel drawer generated as a GUI, according to one embodiment of the invention. In particular, <figref idrefs="DRAWINGS">FIG. 5A</figref> shows the drawer <b>230</b> opened to a greater extent than shown in <figref idrefs="DRAWINGS">FIG. 4</figref>, for example, to reveal several well rows, including the well rows <b>244</b> and <b>246</b>, the latter of which was partially hidden in the view of the media player <b>200</b> shown in <figref idrefs="DRAWINGS">FIG. 4</figref>. In one embodiment, the amount of the drawer <b>230</b> which is visible is controlled by the user. In one embodiment of the invention, selected wells or well rows, such as the well rows <b>244</b> and/or <b>246</b>, may be reserved for certain media sources, such as certain favorites or channels of media provided by a media server. On the other hand, other wells may be freely utilized to store media icons. In one embodiment, time-based media icons may be transferred as icons and/or file names associated with time-based media sources from other locations/directories (e.g., a desktop or other window) of a digital processing system to a well of the drawer; transferred from one well to another well within a drawer; and/or transferred from a drawer to another location/directory of the digital processing system. In one embodiment, known cursor dragging methods may be employed to facilitate such transfers.</p>
  <p num="p-0072"> <figref idrefs="DRAWINGS">FIG. 5B</figref> shows an example of a graphical user interface according to the present invention which may be displayed on a display screen of a computer system. This interface includes a desktop <b>200</b> <i>b </i>and a menu bar <b>200</b> <i>a </i>having pull down menus, such as pull down menu <b>200</b> <i>h</i>. The desktop <b>200</b> <i>b </i>includes an icon <b>200</b> <i>f </i>for a hard disk and an icon <b>200</b> <i>g </i>for a folder as well as an icon for a media document <b>200</b> <i>d </i>and an icon for a trash can <b>200</b> <i>c</i>. A cursor <b>200</b> <i>e </i>is also displayed on the desktop in the vicinity of the media player <b>200</b>. The media player <b>200</b> includes a close box <b>222</b> and a display window <b>202</b> for showing images. Below the window <b>202</b> is the drawer <b>230</b> which has been opened to show four rows of wells, including rows <b>246</b> and <b>244</b>. Four source media icons are shown in the drawer <b>230</b>. A handle below the rows includes the drawer control <b>214</b> and the resize control <b>208</b>. <figref idrefs="DRAWINGS">FIG. 5B</figref> will now be used to describe various processes for altering the contents of the drawer <b>230</b>. A media source icon may be added to the drawer <b>230</b> by dragging the icon from the desktop or from a folder or from the hard disk icon into a well in the drawer <b>230</b>. For example, the cursor <b>200</b> <i>e </i>may be used to select and drag the icon <b>200</b> <i>d </i>into the well <b>242</b> to thereby relocate the icon <b>200</b> <i>d </i>into the well <b>242</b> of the drawer <b>230</b>. In this manner, if the icon <b>200</b> <i>d </i>represents a movie, this icon will be added to the drawer so the user may select for playback the movie represented by this icon by merely opening the drawer and then selecting this icon in well <b>242</b>. This foregoing process may be reversed to thereby delete an icon from the well <b>230</b>. For example, the cursor <b>200</b> <i>e </i>may be used to select an icon, such as media source icon <b>248</b>, and then to drag this icon from its well out of the drawer <b>230</b> and into the trash can <b>200</b> <i>c</i>. This will cause the icon <b>248</b> to be removed from the drawer <b>230</b> and this icon and its associated media will no longer be a favorite which can be selected by selecting an icon within the drawer <b>230</b>.</p>
  <p num="p-0073">Another way to add a favorite into the drawer <b>230</b> is to open a media, such as a movie, so that it is displayed within the window <b>202</b> (or in the case of an audio file, the audio file is ready to be played). Then, the user can use the pull down menu <b>200</b> <i>h </i>to select the option add favorite which adds the media to the first available well in the drawer <b>230</b>.</p>
  <p num="p-0074">The icons within the drawer <b>230</b> may also be used to create a short cut or alias to the media by dragging an icon from the drawer <b>230</b> to the desktop (except for the trash can).</p>
  <heading>Auxiliary Drawers/Panels</heading> <p num="p-0075"> <figref idrefs="DRAWINGS">FIG. 6A</figref> is a diagram of time-based media player providing an information panel (or drawer) window generated as GUI, according to one embodiment of the invention. In particular, <figref idrefs="DRAWINGS">FIG. 6A</figref> shows the bottom portion of the media player <b>200</b> shown in <figref idrefs="DRAWINGS">FIG. 3A</figref> having opened an information drawer <b>250</b>. The information drawer <b>250</b> also represents a drawer or secondary window that may be revealed (or opened) or hidden relative to the media player <b>200</b> window. In one embodiment, the drawer <b>250</b> behaves relative to window <b>200</b> in the same manner as drawer <b>230</b> behaves relative to window <b>200</b>. For example, the drawer <b>250</b> appears attached to and moves with the window <b>200</b> when the window <b>200</b> is moved around the desktop. The information drawer <b>250</b>, in one embodiment, is primarily utilized to display any one or combination of various types of information associated with a currently selected media. Such information may include, but is not limited to, copyright/trademark information, encryption information, data compression information, other credits, warnings, etc. For example, as shown in <figref idrefs="DRAWINGS">FIG. 6A</figref>, the information drawer <b>250</b> displays the message Compressed with Media Cleaner.</p>
  <p num="p-0076">To view the information displayed by the information drawer <b>250</b> when the media player <b>200</b> window appears as shown in <figref idrefs="DRAWINGS">FIG. 3A</figref> (i.e., with the information drawer <b>250</b> closed), the information button <b>210</b> may be selected (e.g., by placing the cursor over the button <b>210</b> and depressing and releasing a select button, such as a mouse button). In response to selection of the information button <b>210</b>, the information drawer <b>250</b> will open (e.g. by appearing to slide out from under the window <b>200</b>) and reveal information about the current media, for example, as shown in <figref idrefs="DRAWINGS">FIG. 6A</figref>.</p>
  <p num="p-0077"> <figref idrefs="DRAWINGS">FIG. 6B</figref> is a diagram of a time-based media player providing a control drawer window generated as a GUI, according to one embodiment of the invention. In particular, <figref idrefs="DRAWINGS">FIG. 6B</figref> shows the bottom portion of the media player <b>200</b> shown in <figref idrefs="DRAWINGS">FIG. 3</figref> having opened a control drawer <b>252</b>. The control drawer <b>252</b> also represents a drawer or secondary window that may be revealed (or opened) or hidden relative to the media player <b>200</b> window. In one embodiment, the drawer <b>252</b> behaves relative to window <b>200</b> in the same manner as drawer <b>230</b> behaves relative to window <b>200</b>. For example, the drawer <b>252</b> appears attached to and moves with the window <b>200</b> when the window <b>200</b> is moved around the desktop. In one embodiment of the invention, the control drawer <b>252</b> is provided to display additional controls/functionality for play back or other processing of a time-based media by the media player <b>200</b>. As shown in <figref idrefs="DRAWINGS">FIG. 6B</figref> and the control drawer <b>252</b>, such information may include, but is not limited to, audio bass, treble, and balance controls, forward/backward scan, skip, etc.</p>
  <p num="p-0078">To utilize or view the controls/functions provided by the control drawer <b>252</b> when the media player <b>200</b> window appears as shown in <figref idrefs="DRAWINGS">FIG. 3A</figref> (i.e., with the control drawer <b>252</b> closed), the control button <b>206</b> may be selected (e.g., by placing the cursor over the button <b>206</b> and depressing and releasing a select button, such as a mouse button). In response to selection of the control button <b>206</b>, the control drawer <b>252</b> will open (e.g. by appearing to slide out from under the window <b>200</b>) and reveal controls, such as those shown in <figref idrefs="DRAWINGS">FIG. 6A</figref> and described above, to control play back and/or other processing of time-based media.</p>
  <heading>Time/Chapter Selection and Display</heading> <p num="p-0079"> <figref idrefs="DRAWINGS">FIGS. 7A-7B</figref> illustrate a time/chapter display control of a time-based media player generated as a GUI, and in particular, illustrate an adaptive chapter display/control, according to one embodiment of the invention. In one embodiment of the invention, a time-based media file may be indexed into chapters, wherein each chapter marks the beginning (and ending) of a particular time segment in the time-based media file. Such chapters may be predefined for a media file and/or may be determined by a user. Each chapter may be entitled by its index number (e.g., Chapter 2 for the second chapter, and so forth) and/or have a descriptive title (e.g., Wedding scene). Therefore, it will be appreciated that chapters are typically descriptions (e.g. text) that indicate or correspond to a time or time range in a time-based media file. Also, a sequential list of chapters may represent the entire contiguous time of a time-based media file.</p>
  <p num="p-0080">In <figref idrefs="DRAWINGS">FIG. 7A</figref>, the time/chapter display/control <b>204</b> of the media player <b>200</b> is shown, which includes an adaptive chapter display/control <b>260</b> and a time display <b>262</b>, which display the corresponding chapter and current time, respectively, of a time-based media file/channel. The adaptive chapter display/control <b>260</b>, as shown in <figref idrefs="DRAWINGS">FIG. 7A</figref>, is in an idle or unselected state, in which the current chapter (entitled Swim excitedly) is truncated to a predetermined idle state display size, as depicted by Swim excit . . . </p>
  <p num="p-0081">On the other hand, when the adaptive chapter display/control <b>260</b> is in an active state, as shown in <figref idrefs="DRAWINGS">FIG. 7B</figref>, its size adapts, in one embodiment, to display the entire title of the current chapter. In one embodiment, the adaptive chapter display/control <b>260</b> becomes active in response to a user input to change or browse/scroll through chapters. The user input may include, for example, clicking and holding a pointing device (e.g., mouse, trackball, etc.) button while the cursor is over the area <b>260</b>. Alternatively, the user input may include speech commands which are recognized by a digital processing system. The user may then cause the chapter displayed by the adaptive chapter display/control <b>260</b> to change by moving the cursor (via a pointing device such as a mouse, for example) up and down to display the previous or next chapter(s), respectively.</p>
  <p num="p-0082">In one embodiment, the time it takes for the cursor to be moved up or down a specified distance above or below the midlevel or other predefined location of the adaptive chapter display/control <b>260</b> (e.g. the speed of the cursor movement) is used to determine the scrolling speed of the chapter(s) being displayed in the adaptive chapter/display control <b>260</b>. As such, in one embodiment, the faster the cursor movement, the faster the chapters scroll up or down in the display <b>260</b>, and conversely, the slower the cursor movement, the slower the chapters scroll in the area of the adaptive chapter/display control <b>260</b>.</p>
  <p num="p-0083">In one embodiment, as a user scrolls up or down through chapters by moving the cursor over the adaptive chapter display/control <b>260</b>, the times corresponding to the chapters are also scrolled up or down in the time display <b>262</b>. In one embodiment, the time may be directly changed up or down by placing the cursor on the time display <b>262</b>, clicking and holding the pointing device select button, and moving the cursor up or down with the pointing device. In response, the chapter display <b>260</b> will also change to correspond to the time. Thus, the time display <b>262</b> and chapter display <b>260</b> are linked such that selecting a particular time will cause the chapter display <b>260</b> to show the corresponding chapter and visa versa. Furthermore, in one embodiment of the invention, the speed with which the cursor is moved up or down by the user (e.g., using a pointing device, such as a mouse) will determine the scroll speed of the indicators in time and/or chapter display areas <b>262</b> and <b>260</b>. This will be further described below in conjunction with <figref idrefs="DRAWINGS">FIGS. 12A and 12B</figref>.</p>
  <p num="p-0084"> <figref idrefs="DRAWINGS">FIG. 7C</figref> shows an example of the chapter display/control area <b>260</b> which includes the chapter designator <b>260</b> <i>a </i>and an up arrow <b>260</b> <i>b </i>and a down arrow <b>260</b> <i>c</i>. the cursor <b>260</b> <i>d </i>is also shown in the vicinity of the control area <b>260</b> although it is outside, in one embodiment, of the area <b>260</b>. Typically, the area <b>260</b> may be defined by the border <b>260</b> <i>e </i>as shown in <figref idrefs="DRAWINGS">FIG. 7C</figref>. When the cursor <b>260</b> <i>d </i>is within the border <b>260</b> <i>e</i>, then by starting a drag within this border, the scrolling of the chapters may be initiated as described herein. This will be further described in conjunction with <figref idrefs="DRAWINGS">FIGS. 7F-7J</figref>.</p>
  <p num="p-0085"> <figref idrefs="DRAWINGS">FIG. 7D</figref> illustrates the appearance of the chapter area <b>260</b> when the very first chapter or section is selected and displayed within the area <b>260</b>. The chapter designator <b>260</b> <i>a </i>indicates this is the first chapter and the up arrow <b>260</b> <i>b </i>is not highlighted while the down arrow <b>260</b> <i>c </i>is highlighted. This difference in highlighting indicates that a user can only go down into the media rather than also being able to go up in the media. Note that with chapter 2 selected in <figref idrefs="DRAWINGS">FIG. 2C</figref>, the user can go in either direction. As shown in <figref idrefs="DRAWINGS">FIG. 7E</figref>, when the last chapter is indicated by the chapter designator <b>260</b> <i>a </i>in the chapter area <b>260</b>, only the up arrow <b>260</b> <i>b </i>is highlighted while the down arrow <b>260</b> <i>c </i>is not.</p>
  <p num="p-0086"> <figref idrefs="DRAWINGS">FIGS. 7F</figref>, <b>7</b>G, and <b>7</b>H illustrate a scrolling up operation while <figref idrefs="DRAWINGS">FIGS. 7I and 7J</figref> illustrate a scrolling down process. The scroll begins in <figref idrefs="DRAWINGS">FIG. 7F</figref> by positioning the cursor <b>260</b> <i>d </i>within the chapter area <b>260</b> and by moving the cursor in an upwardly direction as shown by the arrow <b>261</b> <i>a</i>. Typically, the cursor is positioned within the area and then the user indicates the dragging of the cursor by pressing a mouse button or other button and holding the button down while moving the cursor. After the beginning of the drag, the up arrow <b>260</b> <i>b </i>becomes highlighted and the down arrow <b>260</b> <i>c </i>is no longer highlighted, indicating the direction of the scroll, which in this case is up from chapter 4 to chapter 2 as shown in <figref idrefs="DRAWINGS">FIG. 7H</figref>. <figref idrefs="DRAWINGS">FIG. 7G</figref> shows an intermediate stage where the cursor <b>260</b> <i>d </i>has moved from approximately a midline point within the chapter display control area <b>260</b> to a point approximately two-thirds of the way up, resulting in chapter 3 being displayed as the chapter designator <b>260</b> <i>a </i>while the up arrow continues to be highlighted during the scroll operation which ends in <figref idrefs="DRAWINGS">FIG. 7H</figref> as the cursor <b>260</b> <i>d </i>is now positioned above the area <b>260</b>. The scroll can continue as long as the mouse button or other button remains depressed, indicating an active drag of the cursor which began in the chapter display area <b>260</b>.</p>
  <p num="p-0087"> <figref idrefs="DRAWINGS">FIGS. 7I and 7J</figref> illustrate scrolling in the opposite direction by positioning the cursor <b>260</b> <i>d </i>within the area <b>260</b> and then dragging it down as shown by the arrow <b>261</b> <i>b</i>. As the cursor <b>260</b> <i>d </i>is dragged downwardly, the chapter designator changes from chapter 3 to chapter 4 as shown in <figref idrefs="DRAWINGS">FIG. 7J</figref>, and the cursor <b>260</b> <i>d </i>is now closer to the lower portion of the area <b>260</b> as shown in <figref idrefs="DRAWINGS">FIG. 7J</figref>.</p>
  <p num="p-0088"> <figref idrefs="DRAWINGS">FIGS. 8A-8B</figref> illustrate a GUI mechanism of a time-based media player for selecting for playback (or other presentations) a range of time within a time-based media file, according to one embodiment of the invention. As shown in <figref idrefs="DRAWINGS">FIGS. 8A and 8B</figref>, in addition to the time display <b>262</b> and the adaptive chapter display/control <b>260</b>, the time/chapter display/control <b>204</b> includes a time bar <b>271</b>. The time bar <b>271</b> represents a time line of the current time-based media file. The position of a current time marker <b>274</b> on the time bar <b>271</b> indicates the current time (e.g., time currently being played back, such as an approximation of the time of the currently displayed frame in window <b>202</b>) of the currently selected media file. A user may drag the position of the current time marker <b>274</b> along the time bar <b>271</b> to change the time-based media file's current time to a currently selected time. In one embodiment, the time display <b>262</b> and the adaptive chapter display/control <b>260</b> are updated (to show the current time and current chapter, respectively) as the current time marker <b>274</b> is moved and a frame at the currently selected time is also displayed in window <b>202</b> to update that window. In one embodiment, when a time-based media file is being played back, the current time marker <b>274</b> moves from the left to the right to indicate how much of the time-based media file (depicted by the entire length of the time bar <b>271</b>) has elapsed or remains.</p>
  <p num="p-0089">In addition, a select start marker <b>270</b> and a select end marker <b>272</b> allow selection of a time range within a time-based media file. This time range, once selected, allows playback (or other presentation) of only a portion of the time-based media file. In <figref idrefs="DRAWINGS">FIG. 8A</figref>, the select start marker <b>270</b> is positioned at the left-most end of the time bar <b>271</b>, which coincides with time zero and the beginning of the current time-based media file. Also in <figref idrefs="DRAWINGS">FIG. 8A</figref>, the select end marker <b>272</b> is positioned at the right-most end of the time bar <b>271</b>, which corresponds to the end of the time-based media file. Thus, if the time-based media file is played back with the markers positioned as shown in <figref idrefs="DRAWINGS">FIG. 8A</figref>, the entire time-based media file will be played back in window <b>202</b> from beginning to end, unless stopped.</p>
  <p num="p-0090">On the other hand, as shown in <figref idrefs="DRAWINGS">FIG. 8B</figref>, the select start marker <b>270</b> is moved to the right relative to its position shown in <figref idrefs="DRAWINGS">FIG. 8A</figref>. Similarly, the select end marker <b>272</b> is shown moved to the left relative to its position shown in <figref idrefs="DRAWINGS">FIG. 8A</figref>. As such, only the time range corresponding to that portion of the time bar between the select start marker <b>270</b> and the select end marker <b>272</b> shown in <figref idrefs="DRAWINGS">FIG. 8B</figref> is selected in <figref idrefs="DRAWINGS">FIG. 8B</figref>. Therefore, a user may select substantially any start or end time to determine a particular range of time for playback in a time-based media file. The selected range may be played back, used for editing (e.g., it may be cut from, added to, etc., to a time-based media file), used for creating a new time-based media file with the selected range and placing a corresponding icon in the favorite/channel drawer, or other purposes.</p>
  <p num="p-0091">In one embodiment, when a user changes or scrolls through the time or chapters of a time-based media file using any of the three mechanisms described with reference to the time/chapter display/control <b>204</b>, the display window <b>202</b> of the media player <b>200</b> also displays the image frame at the corresponding time/chapter dragged by the user.</p>
  <p num="p-0092"> <figref idrefs="DRAWINGS">FIG. 8C</figref> shows a flowchart which represents one particular method for implementing the interface shown in <figref idrefs="DRAWINGS">FIGS. 8A and 8B</figref>. In operation <b>275</b> <i>a </i>a time bar, such as time bar <b>271</b>, is displayed with a current time indicator, such as the time display <b>262</b>. In operation <b>275</b> <i>b</i>, a start marker, such as the select start marker <b>270</b> is positioned on a location along the time bar <b>271</b>. This may be achieved by positioning a cursor over the select start marker <b>270</b> and by dragging the select start marker <b>270</b> along the time bar <b>271</b>. The operation of dragging an icon is well known in the art and may be achieved by positioning a cursor in association with the icon, selecting the icon by depressing a mouse button, and while keeping the mouse button depressed, moving the cursor and thereby also moving the icon in a drag operation. In operation <b>275</b> <i>c</i>, a number of different operations may occur concurrently with the drag operation in <b>275</b> <i>b </i>or at the end of a drag operation. In the preferred embodiment, these operations may be performed during the drag operation rather than at the end. In this manner, feedback is given to the user as to the particular start frame which has been selected as the start select marker <b>270</b> is moved along the time bar <b>271</b>. Some or all of the operations in operation <b>275</b> <i>c </i>may be performed as these drag operations occur. The time display, such as time display <b>262</b>, may be updated (e.g. updated from 00:00:00 to 00:05:05) as the start marker is dragged along the time bar. The time display will be updated to indicate the start time selected at the current location of the start marker <b>270</b> along the time bar <b>271</b>. Also, the display frame which has been selected as the start frame may be displayed within the window <b>202</b>. Further, the time bar itself may be updated to indicate the selected portion of the time-based media. This is shown in <figref idrefs="DRAWINGS">FIGS. 8A and 8B</figref> by the highlighting which occurs in the middle of the time bar <b>271</b> while the ends of the time bar are not highlighted. Dragging the start selector <b>270</b> from left to right will change the amount of highlighting along the time bar, thereby indicating the amount of the movie which has been selected for playback. Also, the current time marker may optionally be moved to coincide with the start time marker. Further, the chapter display may be updated to show the chapter corresponding to the time selected by the start marker's position along the time bar. Of course, if a particular time-based media file has no chapters, there is no need to update the chapter display in the control area <b>260</b>.</p>
  <p num="p-0093">The user may perform a positioning operation on the select end marker <b>272</b> as indicated in operation <b>275</b> <i>d </i>of <figref idrefs="DRAWINGS">FIG. 8C</figref>. In particular, the user may drag the end marker to a location along the time bar <b>271</b> or may position the cursor without a drag operation over a particular location and then click to indicate that location after having previously selected the end marker for a positioning operation. The same type of positioning operation may be performed with the start marker <b>270</b>. As the end marker is dragged along the time bar <b>271</b>, the time display <b>262</b> indicating the end of the movie may be updated and a display area <b>202</b> may also show the currently selected end frame in order to let the user know when the selected portion of the movie will end. Also, the time bar may be highlighted or shaded to indicate the end of the selected portion as shown in <figref idrefs="DRAWINGS">FIG. 8B</figref> and this highlighting or shading may be updated as the select end marker is dragged along the time bar <b>271</b>. Further, the chapter display may be updated during the drag operation or positioning operation of the end marker to show the chapter corresponding to the time selected by the end marker's position along the time bar.</p>
  <p num="p-0094">After positioning one or both of the start and/or end markers, the user may cause the presentation of the selected range/portion of the time-based media by, for example, clicking on the play button <b>216</b>.</p>
  <p num="p-0095"> <figref idrefs="DRAWINGS">FIGS. 8D</figref>, <b>8</b>E, and <b>8</b>F illustrate the display, in one embodiment, of a time display/control area <b>204</b>. This area <b>204</b> includes a time bar <b>271</b> as well as a current time marker <b>274</b> and select start marker <b>270</b> and select end marker <b>272</b>. The display and control area <b>204</b> also includes time display <b>262</b>. As with the embodiment shown in <figref idrefs="DRAWINGS">FIGS. 8A and 8B</figref>, the current time marker shows the current time for the current frame relative to the time bar <b>271</b>. The select start marker <b>270</b> shows the selected start time and the select end marker <b>272</b> shows the selected end time. The markers <b>270</b>, <b>272</b>, and <b>274</b> may be dragged along the time bar <b>271</b> as with the embodiment shown in <figref idrefs="DRAWINGS">FIGS. 8A and 8B</figref> in order to modify the current time or the start time or the end time as described above. Three buttons on the left portion of the control and display area <b>204</b> relate and correspond to the three markers <b>270</b>, <b>272</b>, and <b>274</b>. In particular, the button <b>276</b> <i>a </i>corresponds to the select start marker <b>270</b>, and the marker <b>276</b> <i>b </i>corresponds to the current time marker <b>274</b>, and the select end marker <b>272</b> corresponds to the button <b>276</b> <i>c</i>. Each of these three buttons <b>276</b> <i>a</i>, <b>276</b> <i>b</i>, and <b>276</b> <i>c </i>may be selected (e.g. by positioning a cursor over the button and depressing and releasing a mouse button or another key on the system), and when the particular button is depressed, the time of the corresponding marker is shown in the display time area <b>262</b> and the corresponding marker is also highlighted with its corresponding button. For example, as shown in <figref idrefs="DRAWINGS">FIG. 8D</figref>, the selection of the button <b>276</b> <i>a </i>causes the start marker <b>270</b> to be highlighted and causes the time display <b>262</b> to show the time of the select start marker <b>270</b>. Similarly, <figref idrefs="DRAWINGS">FIG. 8E</figref> shows that when the button <b>276</b> <i>b </i>is selected, it becomes highlighted and the current time marker <b>274</b> becomes highlighted and the time of the current time marker is displayed within the time display <b>262</b>. Similarly, <figref idrefs="DRAWINGS">FIG. 8F</figref> shows that when the button <b>276</b> <i>c </i>is selected, it becomes highlighted and the select end marker <b>272</b> becomes highlighted and the ending time selected by the marker <b>272</b> is shown in the time display <b>262</b>.</p>
  <p num="p-0096">These buttons <b>276</b> <i>a</i>, <b>276</b> <i>b</i>, and <b>276</b> <i>c </i>also provide feedback to a user, indicating which of the three markers is being selected and manipulated by the user. For example, when the select start marker <b>270</b> is selected and is being dragged along the time bar <b>271</b>, the button <b>276</b> <i>a </i>becomes highlighted while the buttons <b>276</b> <i>b </i>and <b>276</b> <i>c </i>are not highlighted. This indicates to the user that the start marker is being manipulated and the time display <b>262</b> is updated to follow the movement of the marker <b>270</b> to show the currently selected start time. Similarly, when the current time marker <b>274</b> is selected for direct manipulation (e.g. a dragging of the marker <b>274</b>) then the button <b>276</b> <i>b </i>is highlighted while the other buttons <b>276</b> <i>a </i>and <b>276</b> <i>c </i>are not highlighted. Similarly, when the marker <b>272</b> is being dragged along the time bar <b>271</b>, the button <b>276</b> <i>c </i>is highlighted while buttons <b>276</b> <i>a </i>and <b>276</b> <i>b </i>are not highlighted as shown in <figref idrefs="DRAWINGS">FIG. 8F</figref>.</p>
  <heading>Streaming Status Message Display</heading> <p num="p-0097"> <figref idrefs="DRAWINGS">FIGS. 9A-9B</figref> illustrate an adaptive streaming status message display of a time-based media player generated as a GUI, according to one embodiment of the invention. This status message display may also be used for non-streaming media.</p>
  <p num="p-0098">In one embodiment, the media player <b>200</b> may play back or otherwise process time-based media received over a network. For example, a QuickTime movie may be streamed by a remote digital processing system, typically a server, to the user's local system, where the user has requested the movie (e.g., by clicking on an icon in the favorite/channel drawer of the media player being executed on the local system, wherein the icon references the movie and/or the server that provides the movie).</p>
  <p num="p-0099">As shown in <figref idrefs="DRAWINGS">FIGS. 9A and 9B</figref>, the time/chapter display/control <b>204</b> provides a mechanism for displaying status information related to streaming of time-based media over a network. In particular, as shown in <figref idrefs="DRAWINGS">FIGS. 9A and 9B</figref>, an adaptive streaming message display <b>280</b> appears in the time/chapter display/control <b>204</b>. The adaptive streaming message display <b>280</b> scrolls in from the right-most portion of the time/chapter display/control <b>204</b> to display status messages such as Connecting . . . , Negotiating . . . , Receiving . . . , Buffering . . . , and/or other status messages. The status messages in the message display <b>280</b> scroll from the right and cover as much of the time/chapter display/control <b>204</b> as needed to display the message.</p>
  <p num="p-0100">In one embodiment, when a currently displayed status message is to change to the next status message (e.g., from Connecting to Negotiating), the current message will scroll out to the right. For example, <figref idrefs="DRAWINGS">FIG. 9A</figref> shows a portion of the message received PLAY response . . .  scrolling in from the right to the left in the adaptive streaming message display <b>280</b>, while <figref idrefs="DRAWINGS">FIG. 9B</figref> shows a larger portion of the same message having been scrolled in from the right to the left. However, if another status message were to follow, the message received PLAY response . . .  would scroll out from the left the right (i.e., in the opposite direction). Thus, in one embodiment of the invention, each status message appears and disappears in a streaming/scrolling fashion.</p>
  <p num="p-0101"> <figref idrefs="DRAWINGS">FIGS. 9C-9H</figref> illustrate an alternative embodiment for a status message display for a media player according to one embodiment of the invention. Each of these figures shows a portion of the display control area <b>204</b>. This portion shown may be the middle of the area, for example, the middle of the area shown in <figref idrefs="DRAWINGS">FIG. 7A</figref>. In this instance, the time bar may not be displayed while these messages scroll through this area. <figref idrefs="DRAWINGS">FIG. 9C</figref> shows the beginning of a sequence of messages which may occur when the media player is receiving a streaming media. It will be appreciated that this embodiment of the present invention may be utilized with live or stored streaming and may be used with non-streaming media; the content of the messages would, of course, be tailored to provide the appropriate information depending on the type of media and the type of connection and whether it is streaming or non-streaming media. As shown in <figref idrefs="DRAWINGS">FIG. 9C</figref>, the first message is Connecting and this message begins to scroll down in the area shown in <figref idrefs="DRAWINGS">FIG. 9C</figref> and the next message scrolls in from the top as the previous message Connecting is scrolling down. <figref idrefs="DRAWINGS">FIG. 9D</figref> shows a particular stage in which the first message Connecting has scrolled down to near the bottom while the second message Negotiating has scrolled into the area and is scrolling down. <figref idrefs="DRAWINGS">FIG. 9E</figref> shows the second message Negotiating has scrolled further down and the first message Connecting has scrolled out of view. This scrolling in a vertical direction from top to bottom continues as the third message Buffering scrolls into view as shown in <figref idrefs="DRAWINGS">FIG. 9F</figref>. The next message may be either that shown in <figref idrefs="DRAWINGS">FIG. 9H</figref> (Live Broadcast in the case of a streaming live media) or the time bar <b>271</b> with its associated markers as shown in <figref idrefs="DRAWINGS">FIG. 9G</figref> in the case of a stored streaming media or other media.</p>
  <p num="p-0102">Thus the interface provided by the embodiment shown in <figref idrefs="DRAWINGS">FIGS. 9C-9H</figref> provides a vertical scrolling of messages through the area <b>204</b> by removing the time bar for a portion of the time.</p>
  <heading>Media Player and Display Window Resizing</heading> <p num="p-0103"> <figref idrefs="DRAWINGS">FIGS. 10A-10C</figref> illustrate resizing a time-based media player generated as a GUI and/or a display window for displaying time-based images, according to one embodiment of the invention. In one embodiment, the size of the media player <b>200</b> again depicted in <figref idrefs="DRAWINGS">FIGS. 10A-10C</figref> and/or the motion video display window <b>202</b> may be varied by dragging the resize control <b>208</b> (e.g., by depressing and holding a mouse button or other pointing select button on the resize control <b>208</b>, and then moving the cursor using the mouse).</p>
  <p num="p-0104">In one embodiment, the media player <b>200</b> is displayed at a default minimum window size, which is shown in <figref idrefs="DRAWINGS">FIGS. 10A and 10B</figref> while the window <b>202</b> within the player <b>200</b> may have different sizes as shown in <figref idrefs="DRAWINGS">FIGS. 10A and 10B</figref>. The video display window <b>202</b> may also have a minimum size, which in one embodiment is equal to 320240. It will be appreciated that alternative embodiments may incorporate various other minimum or default sizes or may not incorporate a minimum size.</p>
  <p num="p-0105">In one embodiment, when the resize control <b>208</b> is dragged, two animated rectangles are displayed: one animated rectangle represents the size of the display window <b>202</b> (any image displayed therein) and the other animated rectangle represents the size of the media player <b>200</b> window (which contains the window <b>202</b>). The resize control <b>208</b> may be dragged by the cursor to resize the motion video display window <b>202</b> (and any image displayed thereby) without resizing the window <b>200</b> until the size of window <b>202</b> increases to a threshold size, which in one embodiment, corresponds to substantially the edges of the media player <b>200</b>, which is shown in <figref idrefs="DRAWINGS">FIG. 10B</figref>. When this occurs, an attempt to further enlarge the motion video display window <b>202</b> will enlarge the media player <b>200</b> window as well, which is shown in <figref idrefs="DRAWINGS">FIG. 10C</figref>. However, if the user attempts to shrink the media player <b>200</b> window below the default minimum size, only the display window <b>202</b> (and its animated rectangle) will shrink, and the size of the media player <b>200</b> window will remain unchanged from the minimum size.</p>
  <p num="p-0106"> <figref idrefs="DRAWINGS">FIG. 10D</figref> is a flowchart which illustrates one method of performing a resizing operation with the two windows included in media player <b>200</b>. <figref idrefs="DRAWINGS">FIGS. 10E and 10F</figref> illustrate examples of these two windows during a shrinking operation (<figref idrefs="DRAWINGS">FIG. 10E</figref>) or an enlarging operation (<figref idrefs="DRAWINGS">FIG. 10F</figref>).</p>
  <p num="p-0107">Operation <b>290</b> <i>a </i>of <figref idrefs="DRAWINGS">FIG. 10D</figref> detects a user input to change the size of a window in the time-based media player <b>200</b>. Typically, this will involve a user positioning the cursor over the resize control <b>208</b> and while selecting that control, moving the cursor while the control remains selected. As long as the control is selected (e.g. keeping the mouse's button depressed down) the user is indicating to the system that the window is to be resized. The system will monitor the user's position of the cursor and control the size of the window in a corresponding manner. Typically, two animated windows are displayed, one corresponding to the currently selected size of the inner window and the other corresponding to the currently selected size of the outer window. The animated windows are animated because they change in size as the resizing operation occurs. In the case of the preferred embodiment, the outer window does not change size unless it is currently selected at a size larger than the predetermined size. This is shown in <figref idrefs="DRAWINGS">FIG. 10E</figref> in which the rectangle <b>291</b> <i>b </i>represents the predetermined size of the outer window, which in this case is the outer perimeter of the player <b>200</b> shown in <figref idrefs="DRAWINGS">FIG. 3A</figref>. The rectangle <b>291</b> <i>e </i>represents the inner window's periphery at the end of a drag of the cursor <b>291</b> <i>a </i>while the rectangle <b>291</b> <i>d </i>represents the inner window's periphery at the start of the drag. The arrow <b>291</b> <i>h </i>represents the direction of the drag starting from one location and inwardly towards the rectangle <b>291</b> <i>e</i>. The rectangle <b>291</b> <i>c </i>is shown within the rectangle <b>291</b> <i>b </i>only for purposes of illustration to separately show the two rectangles. It will be appreciated that the rectangle <b>291</b> <i>c </i>represents the outer window's periphery and that this periphery does not shrink below the predetermined size represented by the rectangle <b>291</b> <i>b</i>. The animated rectangles <b>291</b> <i>f </i>and <b>291</b> <i>g </i>appear during the process of dragging from the beginning position of the cursor to the ending position of the cursor as the inner window is reduced in size. It will be appreciated that there are a number of ways to animate the changing size of a window. In one embodiment, a zooming series of shrinking rectangles may be displayed as the user moves the cursor from one location near the outer window's periphery towards the inner window's periphery. These zooming animated rectangles are well known in the art.</p>
  <p num="p-0108"> <figref idrefs="DRAWINGS">FIG. 10F</figref> represents an expansion of both the inner and outer windows as the user drags the cursor <b>291</b> <i>a </i>along the path <b>291</b> <i>i</i>. In this case, the outer window is dragged beyond the predetermined size shown by rectangle <b>291</b> <i>b </i>to its final size shown by rectangle <b>291</b>L. Similarly, the drag operation enlarges the inner window from its beginning size shown by rectangle <b>291</b> <i>m </i>to its final size shown by rectangle <b>291</b> <i>p</i>. During the dragging operation, several animated rectangles may be displayed for both the inner and outer windows showing the user the size of both windows. This feedback allows the user to be able to determine the size of the outer window and also to determine the size of the inner window while a dragging operation is occurring. Thus, for example, the user can enlarge the inner window to see a bigger picture while at the same time assuring that the outer window is not enlarged too much such that it may obscure background features on a desktop or that it may extend beyond displayable area such that controls on the outer window may not be available.</p>
  <p num="p-0109">Referring back to <figref idrefs="DRAWINGS">FIG. 10D</figref>, the operation, once user input is detected, proceeds to operation <b>290</b> <i>b </i>in which the size of the outer window being changed is compared to a predetermined size such as a predetermined area. If this outer window is being changed below a predetermined size, then processing proceeds to operation <b>290</b> <i>g</i>. This is shown in <figref idrefs="DRAWINGS">FIG. 10E</figref> in which there is a changing outline of the inner window which is animated to indicate the changing size of the inner window but the dragging operation does not affect the size of the outer window as long as the size of the outer window's size remains below the predetermined size. In operation <b>290</b> <i>h</i>, it is determined while dragging whether the size of the outer window is less than the predetermined size. If it is not, processing proceeds to step <b>290</b> <i>i </i>in which it is determined whether dragging has been completed. If, in operation <b>290</b>, it has been determined that the size of the outer window is larger than the predetermined size, then processing proceeds to operation <b>290</b> <i>c</i>. If, in operation <b>290</b> <i>i</i>, it has been determined that dragging has ended, then processing returns back to operation <b>290</b> <i>b</i>, otherwise, if dragging has ended in operation <b>290</b> <i>j</i>, the size of the inner window is changed to the final selected size of the inner window. Typically, this will mean that the periphery of the inner window will be the same size as the periphery of the animated window which was displayed when the drag was ended.</p>
  <p num="p-0110">Operation <b>290</b> <i>c </i>is illustrated in <figref idrefs="DRAWINGS">FIG. 10F</figref> in which both the inner and outer windows have animated zooming rectangles associated with the windows while the user drags the resizing control. Animated rectangles <b>291</b> <i>n </i>and <b>291</b> <i>o </i>are examples of zooming animated rectangles for the inner window, and animated zooming rectangles <b>291</b> <i>j </i>and <b>291</b> <i>k </i>are examples of animated windows for the outer window. In operation <b>290</b> <i>d</i>, it is determined whether the size of the outer window is less than the predetermined size. If it is not, processing proceeds to step <b>290</b> <i>e</i>. If, in fact, the size of the outer window is less than the predetermined size, then processing proceeds to operation <b>290</b> <i>g</i>. In operation <b>290</b> <i>e</i>, if the drag has ended, then processing proceeds to operation <b>290</b> <i>f </i>in which the inner and outer windows are set to the new selected sizes. If the drag has not ended as determined in operation <b>290</b> <i>e</i>, then processing returns back to operation <b>290</b> <i>c. </i> </p>
  <p num="p-0111">In this manner, the size of both the inner and outer window may be determined by looking at the current size of the animating rectangles.</p>
  <p num="p-0112">In alternative embodiments, two separate resize mechanisms may be provided, each to control resizing of one of the media player <b>200</b> and the display window <b>202</b>.</p>
  <heading>Method For Providing a Favorite/Channel Drawer Window</heading> <p num="p-0113"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a flow diagram illustrating a method for providing a favorite/channel drawer window for a time-based media player generated as a GUI, according to one embodiment of the invention. Flow begins at block <b>302</b>.</p>
  <p num="p-0114">At block <b>304</b>, input is detected to open a favorite/channel drawer window relative to a media player window. For example, such input may include dragging a drawer control icon, such as the favorite/channel drawer control <b>214</b> of <figref idrefs="DRAWINGS">FIG. 3A</figref>, in the same direction in which the favorite/channel drawer is to be opened, and doing so until a desired portion of the favorite/channel drawer is displayed. As such, in one embodiment, the size of the drawer window (and how many wells are displayed) is incrementally selectable to the extent that a user drags open or closed the favorite/channel drawer. On the other hand, in an alternative embodiment, the drawer window may be opened (e.g. displayed) at only a predetermined size, such that a user may open the drawer to such size by selecting an icon (e.g. clicking or double-clicking on the icon by positioning a cursor on the icon and depressing a button or by speaking the icon's name in a system with speech recognition capabilities) and may close the drawer window by clicking or double-clicking on the same icon. Alternatively, keyboard commands (e.g. command]) may be used to open and close the drawer window or the selection of a command from a pull down menu may open or close the drawer window.</p>
  <p num="p-0115">At block <b>306</b>, the drawer window is displayed. As mentioned above, the extent to which the drawer window is displayed may be selectable, for example, as determined by the extent the drawer window is dragged open by a user, or may be displayed at a default/non-selectable size or proportion.</p>
  <p num="p-0116">At block <b>308</b>, if input is detected to select an icon in the drawer or to alter the drawer (e.g., to add, delete, rearrange, etc., an icon), flow passes to block <b>314</b>. Otherwise, flow passes to block <b>310</b>. The input may include clicking on an icon in a well of the drawer, dragging an icon to or from a well, etc.</p>
  <p num="p-0117">At block <b>310</b>, if input is detected to close the drawer (e.g., a user dragging the drawer control <b>214</b> up to hide to the drawer or a portion thereof), flow passes to block <b>312</b> where the drawer window is (at least partially) closed. Otherwise flow passes back to block <b>306</b>.</p>
  <p num="p-0118">At block <b>314</b>, if the input detected at block <b>308</b> is directed to playback of time-based media data (e.g., the user clicks an icon in the drawer), flow passes to block <b>316</b>, where the time-based media file is played back by the time-based media player. For example, the user may click on a time-based media icon in the drawer that references a time-based media file, such as a QuickTime movie, that is stored locally or at a remote server. The movie would then be retrieved and played back from local storage or streamed to the user's local system where the media player would display the movie (e.g., in the display window <b>202</b>) and/or playback audio tracks of the movie.</p>
  <p num="p-0119">Otherwise, flow passes to block <b>318</b>, where the drawer window is altered. Such alteration may include dragging an icon or file name from another location in the user's computer system (e.g., the desktop or other directory/location) to a well of the drawer or visa versa; dragging a time-based media icon from one well location to another well location; deleting a time-based media icon from the drawer; etc.</p>
  <heading>Adaptive Chapter/Time Selection</heading> <p num="p-0120"> <figref idrefs="DRAWINGS">FIG. 12A</figref> is a flow diagram illustrating a method for providing adaptive chapter/time selection for play back or other processing of time-based media in a GUI, according to one embodiment of the invention. Flow begins at block <b>330</b>.</p>
  <p num="p-0121">At block <b>332</b>, a time-based media player window, such as the media player <b>200</b> window shown in <figref idrefs="DRAWINGS">FIG. 3A</figref>, is displayed.</p>
  <p num="p-0122">At block <b>334</b>, media time and/or chapter control and/or display mechanisms are displayed. For example, in one embodiment, such mechanisms may include a time display (e.g., the time display <b>262</b> shown in <figref idrefs="DRAWINGS">FIGS. 8A and 8B</figref>), a time bar with selection markers and/or a current time indicator (such as shown in <figref idrefs="DRAWINGS">FIGS. 8A and 8B</figref>), and/or a chapter display/control (e.g., the adaptive chapter display/control <b>260</b> shown in <figref idrefs="DRAWINGS">FIGS. 8A and 8B</figref>).</p>
  <p num="p-0123">At block <b>336</b>, input is detected to alter a time or chapter (which two are typically, but not necessarily linked). For example, such input may include a user placing the cursor in the chapter display/control or the time display and then dragging the cursor up or down to scroll up or down through chapters (or time).</p>
  <p num="p-0124">At block <b>338</b>, based on a characteristic of the input, the time and/or chapter is adaptively changed. In one embodiment, the characteristic includes the speed in which a cursor is dragged over the chapter display/control (or time display). Based on measuring the time in which the cursor covers a specified distance, the cursor dragging speed is determined. Once the drag speed is determined, the speed in which the displayed chapters in the chapter display/control are scrolled is varied in direct proportion to the cursor drag speed. As such, a user can control the speed he/she wishes to scroll through and view chapters or time by using various cursor dragging speeds to obtain directly proportional scrolling speeds.</p>
  <p num="p-0125"> <figref idrefs="DRAWINGS">FIG. 12B</figref> shows a representation of a graphical user interface which may be used with a method shown in <figref idrefs="DRAWINGS">FIG. 12A</figref>. The interface shown in <figref idrefs="DRAWINGS">FIG. 12B</figref> is similar to the adaptive chapter portion of the interface shown in <figref idrefs="DRAWINGS">FIGS. 7A and 7B</figref>. It will be appreciated that the chapter display area <b>339</b> <i>a </i>of <figref idrefs="DRAWINGS">FIG. 12B</figref> may display the names of the chapters (e.g. swim excitedly) rather than the designator chapter with a numeral as shown in <figref idrefs="DRAWINGS">FIG. 12B</figref>. The designator chapter <b>339</b> <i>b </i>may alternatively say sections or other designators to indicate portions of the time-based media. A numeral region <b>339</b> <i>d </i>may display a numeral indicating the chapter number and this area <b>339</b> <i>d </i>may provide for scrolling of numerals within the area in response to selecting the chapter region <b>339</b> <i>a</i>. This selection may be performed by positioning the cursor <b>339</b> <i>c </i>in the chapter area and then dragging the cursor in an up or down direction. The arrows <b>339</b> <i>e </i>and <b>339</b> <i>f </i>represent different velocities of the drag which will in turn cause different scrolling speeds within the numeral area <b>339</b> <i>d</i>. In this manner, the user may control the scrolling speed of the chapter designators (e.g. chapter numerals or titles) by controlling the speed of the cursor during a drag of the cursor over the chapter area <b>339</b> <i>a. </i> </p>
  <heading>Auxiliary Drawer/Tray Windows</heading> <p num="p-0126"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a flow diagram illustrating a method for providing auxiliary drawers/trays for a time-based media player generated as a GUI, according to one embodiment of the invention. Flow begins at block <b>340</b>.</p>
  <p num="p-0127">At block <b>342</b>, a time-based media player window, such as the media player <b>200</b> window shown in <figref idrefs="DRAWINGS">FIG. 3A</figref>, is displayed.</p>
  <p num="p-0128">At block <b>344</b>, input is detected to open one or more auxiliary drawer windows, such as the information drawer <b>250</b> or control drawer <b>252</b>, described above with reference to <figref idrefs="DRAWINGS">FIGS. 6A-6B</figref>. The input may include the selection of a button displayed on the window (e.g. clicking of a pointing device select button (e.g., a mouse button) with the cursor over an icon that controls the auxiliary drawer window to be opened).</p>
  <p num="p-0129">At block <b>346</b>, the auxiliary drawer window is opened for display. In one embodiment, the auxiliary drawer is of a predetermined size. In alternative embodiments, one or more auxiliary drawers may be selectively displayed at various sizes (e.g., under user control), for example, as depicted by the drawer window shown in <figref idrefs="DRAWINGS">FIGS. 4-5A</figref>. The auxiliary drawer may provide information about time-based media and/or provide mechanisms for play back or other processing of time-based media. Such mechanisms may include display and/or control of bass, treble, balance; a graphic equalizer; forward/backward rewind, scan, skip, etc., or other controls for play back or processing of time-based media information such as audio, video, or a combination thereof. Once the auxiliary drawer is displayed, various controls may be modified or selected by the user.</p>
  <heading>Software Overview</heading> <p num="p-0130"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a block diagram of a machine-readable medium storing executable code and/or other data to provide one or a combination of mechanisms for play back or other processing of time-based media in a GUI, according to one embodiment of the invention. The machine-readable storage medium <b>350</b> represents one or a combination of various types of media/devices for storing machine-readable data, which may include machine-executable code or routines. As such, the machine-readable storage medium <b>350</b> could include, but is not limited to one or a combination of a magnetic storage space (e.g., a hard or floppy disk), magneto-optical storage, tape, optical storage (e.g., CD ROM, DVD, etc.), dynamic random access memory (DRAM), static RAM (SRAM), flash memory, etc.</p>
  <p num="p-0131">The medium <b>350</b> is shown storing a time-based media player routine <b>352</b> which, when executed, provides a time-based media player as a GUI such as the player <b>200</b>. The time-based media player routine <b>352</b> includes a number of mechanisms for playing back or otherwise processing time-based media processed by the time-based media player. For example, a drawer routine <b>354</b> generates a drawer window, such as drawer <b>230</b>, for display. The drawer may contain wells for displaying one or more references (icons) to media, such as files/channels, which may be stored locally by a digital processing coupled to the medium <b>350</b>, or by a remote system, such as a time-based media Web server. The drawer routine <b>354</b> may also facilitate altering of the drawer to add, delete, rearrange, select for play back, etc., icons displayed therein. An adaptive time/chapter selection routine <b>356</b> allows adaptively varying the display of time or chapter information (e.g., the speed at which such information is displayed as being scrolled, as described in conjunction with <figref idrefs="DRAWINGS">FIGS. 12A and 12B</figref>) in response to detection of an input characteristic (e.g., cursor drag speed when user input causes such information to be varied). A time bar selection marker routine <b>358</b> provides a time bar for display, as well as select start/end and current time marker functionality, as described, for example, with reference to <figref idrefs="DRAWINGS">FIGS. 8A-8C</figref> or <b>8</b>D-<b>8</b>F. A streaming status message routine <b>360</b> provide streaming of status messages, for example, as described above with reference to <figref idrefs="DRAWINGS">FIGS. 9A-9B</figref> or <b>9</b>C-<b>9</b>H. A player/display window resizing routine allows resizing of a time-based media player window and/or a motion video display window according to one or more of the methods described above, for example, with reference to <figref idrefs="DRAWINGS">FIGS. 10A-10F</figref>. Finally, an auxiliary drawer routine provides display areas in the form of drawers in addition to or in lieu of the favorite/channel drawer, which auxiliary drawers may provide information or additional mechanisms for display and play back or other processing of media.</p>
  <p num="p-0132">The machine readable storage medium may also store an operating system (OS) <b>366</b>, which may provide a graphical window/icon oriented environment; a data communication routine <b>370</b> that facilitates transfer of media and/or other information over a digital processing network; and/or stored/buffered time-based media <b>368</b>.</p>
  <p num="p-0133">It will be appreciated that alternative embodiments of the GUI for processing time-based information may include fewer or more of the functions described herein. Furthermore, the invention may be implemented in any combination of hardware and/or software.</p>
  <heading>Alternative Embodiments</heading> <p num="p-0134">While the invention has been described in terms of several embodiments and illustrative figures, those skilled in the art will recognize that the invention is not limited to the embodiments or figures described. In particular, the invention can be practiced in several alternative embodiments that provide one or a combination of mechanisms for playing back or otherwise processing time-based media information (e.g., QuickTime movies) in a graphical user interface. Furthermore, the icons in a drawer may represent media other than time-based media, such as still images or interactive content or Web page links, etc.</p>
  <p num="p-0135">Therefore, it should be understood that the method and apparatus of the invention can be practiced with modification and alteration within the spirit and scope of the appended claims. The description is thus to be regarded as illustrative instead of limiting on the invention.</p>
</div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5404316">US5404316</a></td><td class="patent-data-table-td patent-date-value">Aug 3, 1992</td><td class="patent-data-table-td patent-date-value">Apr 4, 1995</td><td class="patent-data-table-td ">Spectra Group Ltd., Inc.</td><td class="patent-data-table-td ">Desktop digital video processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5495566">US5495566</a></td><td class="patent-data-table-td patent-date-value">Nov 22, 1994</td><td class="patent-data-table-td patent-date-value">Feb 27, 1996</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Scrolling contents of a window</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5513342">US5513342</a></td><td class="patent-data-table-td patent-date-value">Dec 28, 1993</td><td class="patent-data-table-td patent-date-value">Apr 30, 1996</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Display window layout system that automatically accommodates changes in display resolution, font size and national language</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5519828">US5519828</a></td><td class="patent-data-table-td patent-date-value">Dec 19, 1994</td><td class="patent-data-table-td patent-date-value">May 21, 1996</td><td class="patent-data-table-td ">The Grass Valley Group Inc.</td><td class="patent-data-table-td ">Video editing operator interface for aligning timelines</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5611060">US5611060</a></td><td class="patent-data-table-td patent-date-value">Feb 22, 1995</td><td class="patent-data-table-td patent-date-value">Mar 11, 1997</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Auto-scrolling during a drag and drop operation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5664128">US5664128</a></td><td class="patent-data-table-td patent-date-value">Feb 23, 1995</td><td class="patent-data-table-td patent-date-value">Sep 2, 1997</td><td class="patent-data-table-td ">Apple Computer, Inc.</td><td class="patent-data-table-td ">Object storage apparatus for use with data sets in computer applications</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5682326">US5682326</a></td><td class="patent-data-table-td patent-date-value">Apr 3, 1995</td><td class="patent-data-table-td patent-date-value">Oct 28, 1997</td><td class="patent-data-table-td ">Radius Inc.</td><td class="patent-data-table-td ">Desktop digital video processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5726687">US5726687</a></td><td class="patent-data-table-td patent-date-value">Nov 13, 1996</td><td class="patent-data-table-td patent-date-value">Mar 10, 1998</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">In a computer system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5732184">US5732184</a></td><td class="patent-data-table-td patent-date-value">Oct 20, 1995</td><td class="patent-data-table-td patent-date-value">Mar 24, 1998</td><td class="patent-data-table-td ">Digital Processing Systems, Inc.</td><td class="patent-data-table-td ">Video and audio cursor video editing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5745096">US5745096</a></td><td class="patent-data-table-td patent-date-value">Oct 18, 1996</td><td class="patent-data-table-td patent-date-value">Apr 28, 1998</td><td class="patent-data-table-td ">Apple Computer, Inc.</td><td class="patent-data-table-td ">Desk drawer user interface</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5758180">US5758180</a></td><td class="patent-data-table-td patent-date-value">Apr 15, 1993</td><td class="patent-data-table-td patent-date-value">May 26, 1998</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Block resizing function for multi-media editing which moves other blocks in response to the resize only as necessary</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5760767">US5760767</a></td><td class="patent-data-table-td patent-date-value">Oct 26, 1995</td><td class="patent-data-table-td patent-date-value">Jun 2, 1998</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Method and apparatus for displaying in and out points during video editing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5760772">US5760772</a></td><td class="patent-data-table-td patent-date-value">Aug 30, 1996</td><td class="patent-data-table-td patent-date-value">Jun 2, 1998</td><td class="patent-data-table-td ">Novell, Inc.</td><td class="patent-data-table-td ">Method for automatically resizing a child window</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5874958">US5874958</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 1997</td><td class="patent-data-table-td patent-date-value">Feb 23, 1999</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for accessing information and items across workspaces</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5880725">US5880725</a></td><td class="patent-data-table-td patent-date-value">Aug 5, 1996</td><td class="patent-data-table-td patent-date-value">Mar 9, 1999</td><td class="patent-data-table-td ">Altera Corporation</td><td class="patent-data-table-td ">Computer user interface having tiled and overlapped window areas</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5999173">US5999173</a></td><td class="patent-data-table-td patent-date-value">Apr 3, 1992</td><td class="patent-data-table-td patent-date-value">Dec 7, 1999</td><td class="patent-data-table-td ">Adobe Systems Incorporated</td><td class="patent-data-table-td ">Method and apparatus for video editing with video clip representations displayed along a time line</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6026389">US6026389</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 1997</td><td class="patent-data-table-td patent-date-value">Feb 15, 2000</td><td class="patent-data-table-td ">Kokusai, Denshin, Denwa, Kabushiki Kaisha</td><td class="patent-data-table-td ">Video query and editing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6031529">US6031529</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 1997</td><td class="patent-data-table-td patent-date-value">Feb 29, 2000</td><td class="patent-data-table-td ">Avid Technology Inc.</td><td class="patent-data-table-td ">Graphics design software user interface</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6061062">US6061062</a></td><td class="patent-data-table-td patent-date-value">Aug 9, 1993</td><td class="patent-data-table-td patent-date-value">May 9, 2000</td><td class="patent-data-table-td ">Apple Computer, Inc.</td><td class="patent-data-table-td ">Zooming controller</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6072503">US6072503</a></td><td class="patent-data-table-td patent-date-value">Apr 28, 1997</td><td class="patent-data-table-td patent-date-value">Jun 6, 2000</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Video synchronization processing method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6166736">US6166736</a></td><td class="patent-data-table-td patent-date-value">Aug 21, 1998</td><td class="patent-data-table-td patent-date-value">Dec 26, 2000</td><td class="patent-data-table-td ">Natrificial Llc</td><td class="patent-data-table-td ">Method and apparatus for simultaneously resizing and relocating windows within a graphical display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6204840">US6204840</a></td><td class="patent-data-table-td patent-date-value">Apr 8, 1998</td><td class="patent-data-table-td patent-date-value">Mar 20, 2001</td><td class="patent-data-table-td ">Mgi Software Corporation</td><td class="patent-data-table-td ">Non-timeline, non-linear digital multimedia composition method and system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6332147">US6332147</a></td><td class="patent-data-table-td patent-date-value">Nov 3, 1995</td><td class="patent-data-table-td patent-date-value">Dec 18, 2001</td><td class="patent-data-table-td ">Xerox Corporation</td><td class="patent-data-table-td ">Computer controlled display system using a graphical replay device to control playback of temporal data representing collaborative activities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6366296">US6366296</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 1998</td><td class="patent-data-table-td patent-date-value">Apr 2, 2002</td><td class="patent-data-table-td ">Xerox Corporation</td><td class="patent-data-table-td ">Media browser using multimodal analysis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6369835">US6369835</a></td><td class="patent-data-table-td patent-date-value">May 18, 1999</td><td class="patent-data-table-td patent-date-value">Apr 9, 2002</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method and system for generating a movie file from a slide show presentation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6456305">US6456305</a></td><td class="patent-data-table-td patent-date-value">Mar 18, 1999</td><td class="patent-data-table-td patent-date-value">Sep 24, 2002</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method and system for automatically fitting a graphical display of objects to the dimensions of a display window</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020191028">US20020191028</a></td><td class="patent-data-table-td patent-date-value">Jun 19, 2001</td><td class="patent-data-table-td patent-date-value">Dec 19, 2002</td><td class="patent-data-table-td ">Senechalle David A.</td><td class="patent-data-table-td ">Window manager user interface</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">On-Line Definition for "<a href='http://scholar.google.com/scholar?q="Playback"'>Playback</a>" (American Heritage Dictionary of the English Language, 4&lt;SUP&gt;th &lt;/SUP&gt;Edition, 1 page, 2000).</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">PCT International Search Report for PCT Application No. US00/10441, mailed Jul. 11, 2000, 5 pages.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">QuickTime Movie Player Ver. 2.1.2.59 screen dump (Current Time Indicator Dragging Operation; 1 page; 1996).</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">RealOne Player Version 2.0 screen dumps (4 pages; 2002).</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Windows Media Player for Windows XP Version 8.0 (2 pages, 2001).</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8194037">US8194037</a></td><td class="patent-data-table-td patent-date-value">Dec 14, 2007</td><td class="patent-data-table-td patent-date-value">Jun 5, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Centering a 3D remote controller in a media system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8291346">US8291346</a></td><td class="patent-data-table-td patent-date-value">Nov 7, 2006</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">3D remote control system employing absolute and relative position detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8341544">US8341544</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 14, 2007</td><td class="patent-data-table-td patent-date-value">Dec 25, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Scroll bar with video region in a media system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8422643">US8422643</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 29, 2009</td><td class="patent-data-table-td patent-date-value">Apr 16, 2013</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Playback of media recordings</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8689145">US8689145</a></td><td class="patent-data-table-td patent-date-value">Oct 8, 2012</td><td class="patent-data-table-td patent-date-value">Apr 1, 2014</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">3D remote control system employing absolute and relative position detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8762844">US8762844</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 24, 2008</td><td class="patent-data-table-td patent-date-value">Jun 24, 2014</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Image display apparatus and method of controlling the same via progress bars</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8762882">US8762882</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 1, 2008</td><td class="patent-data-table-td patent-date-value">Jun 24, 2014</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Information processing apparatus, control method for use therein, and computer program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8769409">US8769409</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 27, 2011</td><td class="patent-data-table-td patent-date-value">Jul 1, 2014</td><td class="patent-data-table-td ">Cyberlink Corp.</td><td class="patent-data-table-td ">Systems and methods for improving object detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090116817">US20090116817</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 24, 2008</td><td class="patent-data-table-td patent-date-value">May 7, 2009</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Image display apparatus and method of controlling the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090153389">US20090153389</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 14, 2007</td><td class="patent-data-table-td patent-date-value">Jun 18, 2009</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Scroll bar with video region in a media system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110103560">US20110103560</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 29, 2009</td><td class="patent-data-table-td patent-date-value">May 5, 2011</td><td class="patent-data-table-td ">Cordell Ratzlaff</td><td class="patent-data-table-td ">Playback of media recordings</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120304063">US20120304063</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 27, 2011</td><td class="patent-data-table-td patent-date-value">Nov 29, 2012</td><td class="patent-data-table-td ">Cyberlink Corp.</td><td class="patent-data-table-td ">Systems and Methods for Improving Object Detection</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc715/defs715.htm&usg=AFQjCNEsvPOacMHcG92b6Esmd6a_S2NVkg#C715S723000">715/723</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspcG9B/defsG9B.htm&usg=AFQjCNE1uzWUMUoBoyPG8UViGilZBwVzaQ#CG9BS027051">G9B/27.051</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspcG9B/defsG9B.htm&usg=AFQjCNE1uzWUMUoBoyPG8UViGilZBwVzaQ#CG9BS020009">G9B/20.009</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc715/defs715.htm&usg=AFQjCNEsvPOacMHcG92b6Esmd6a_S2NVkg#C715S830000">715/830</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc715/defs715.htm&usg=AFQjCNEsvPOacMHcG92b6Esmd6a_S2NVkg#C715S786000">715/786</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc715/defs715.htm&usg=AFQjCNEsvPOacMHcG92b6Esmd6a_S2NVkg#C715S973000">715/973</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005760000">H04N5/76</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0003048000">G06F3/048</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0003000000">G06F3/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=Y10S715/974">Y10S715/974</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=Y10S715/973">Y10S715/973</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/048">G06F3/048</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/326">G11B27/326</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/0481">G06F3/0481</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/034">G11B27/034</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/0483">G06F3/0483</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/34">G11B27/34</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/0482">G06F3/0482</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B27/105">G11B27/105</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/0486">G06F3/0486</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/04847">G06F3/04847</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G11B20/10">G11B20/10</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/0485">G06F3/0485</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=82hqBQABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/0484">G06F3/0484</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G11B27/10A1</span>, <span class="nested-value">G11B27/034</span>, <span class="nested-value">G11B27/32C</span>, <span class="nested-value">G06F3/048</span>, <span class="nested-value">G06F3/0482</span>, <span class="nested-value">G06F3/0481</span>, <span class="nested-value">G06F3/0484P</span>, <span class="nested-value">G06F3/0486</span>, <span class="nested-value">G06F3/0483</span>, <span class="nested-value">G06F3/0485</span>, <span class="nested-value">G11B27/34</span>, <span class="nested-value">G11B20/10</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">May 14, 2013</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-10 IS CONFIRMED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 22, 2013</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120914</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 25, 2012</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 23, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100111</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 7, 2007</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">APPLE INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:APPLE COMPUTER, INC., A CALIFORNIA CORPORATION;REEL/FRAME:019281/0694</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20070109</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:APPLE COMPUTER, INC., A CALIFORNIA CORPORATION;REEL/FRAME:19281/694</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">APPLE INC.,CALIFORNIA</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0rSoXwcTEkcInR1o0PLhidsvNAOw\u0026id=82hqBQABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3MwjmUuft5AHRoFENiQOnQMyZVsQ\u0026id=82hqBQABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U3qyN2M4F8ZKwj_OYDSxewt5snT0Q","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/User_interface_for_presenting_media_info.pdf?id=82hqBQABERAJ\u0026output=pdf\u0026sig=ACfU3U2ya-5eyk6vjOOKYDQpcuD9q0c4Fw"},"sample_url":"http://www.google.com/patents/reader?id=82hqBQABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>