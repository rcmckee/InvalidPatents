<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6137498 - Digital composition of a mosaic image - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Digital composition of a mosaic image"><meta name="DC.contributor" content="Robert S. Silvers" scheme="inventor"><meta name="DC.contributor" content="Runaway Technology, Inc." scheme="assignee"><meta name="DC.date" content="1997-10-27" scheme="dateSubmitted"><meta name="DC.description" content="A mosaic image is formed from a database of source images. More particularly, the source images are analyzed, selected and organized to produce the mosaic image. A target image is divided into tile regions, each of which is compared with individual source image portions to determine the best available matching source image by computing red, green and blue channel root-mean square error. The mosaic image is formed by positioning the respective best-matching source images at the respective tile regions."><meta name="DC.date" content="2000-10-24" scheme="issued"><meta name="DC.relation" content="EP:0199573:A2" scheme="references"><meta name="DC.relation" content="EP:0461830:A2" scheme="references"><meta name="DC.relation" content="JP:H07302271" scheme="references"><meta name="DC.relation" content="JP:H0855133" scheme="references"><meta name="DC.relation" content="JP:H10188023" scheme="references"><meta name="DC.relation" content="US:3987558" scheme="references"><meta name="DC.relation" content="US:4398890" scheme="references"><meta name="DC.relation" content="US:4644582" scheme="references"><meta name="DC.relation" content="US:4731743" scheme="references"><meta name="DC.relation" content="US:5150295" scheme="references"><meta name="DC.relation" content="US:5649032" scheme="references"><meta name="DC.relation" content="WO:1995002224:A1" scheme="references"><meta name="citation_reference" content="Knowlton et al., &quot;Computer-Produced Grey Scales&quot; Computer Graphics and Image Processing, 1:1-20 (1972)."><meta name="citation_reference" content="Knowlton et al., Computer Produced Grey Scales Computer Graphics and Image Processing , 1:1 20 (1972)."><meta name="citation_reference" content="Robert Silvers, image on cover of Wired magazine, Nov. 1995."><meta name="citation_patent_number" content="US:6137498"><meta name="citation_patent_application_number" content="US:08/957,833"><link rel="canonical" href="http://www.google.com/patents/US6137498"/><meta property="og:url" content="http://www.google.com/patents/US6137498"/><meta name="title" content="Patent US6137498 - Digital composition of a mosaic image"/><meta name="description" content="A mosaic image is formed from a database of source images. More particularly, the source images are analyzed, selected and organized to produce the mosaic image. A target image is divided into tile regions, each of which is compared with individual source image portions to determine the best available matching source image by computing red, green and blue channel root-mean square error. The mosaic image is formed by positioning the respective best-matching source images at the respective tile regions."/><meta property="og:title" content="Patent US6137498 - Digital composition of a mosaic image"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("0pntU96KNMmNogS_sIDYCg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("JPN"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("0pntU96KNMmNogS_sIDYCg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("JPN"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6137498?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6137498"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=GdJRBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6137498&amp;usg=AFQjCNEDNrYSCqcVLzo4RhqjZU-ke4MXYg" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6137498.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6137498.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6137498" style="display:none"><span itemprop="description">A mosaic image is formed from a database of source images. More particularly, the source images are analyzed, selected and organized to produce the mosaic image. A target image is divided into tile regions, each of which is compared with individual source image portions to determine the best available...</span><span itemprop="url">http://www.google.com/patents/US6137498?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6137498 - Digital composition of a mosaic image</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6137498 - Digital composition of a mosaic image" title="Patent US6137498 - Digital composition of a mosaic image"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6137498 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/957,833</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Oct 24, 2000</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Oct 27, 1997</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jan 2, 1997</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/DE852363T1">DE852363T1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE69720399D1">DE69720399D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE69720399T2">DE69720399T2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0852363A2">EP0852363A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0852363A3">EP0852363A3</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0852363B1">EP0852363B1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08957833, </span><span class="patent-bibdata-value">957833, </span><span class="patent-bibdata-value">US 6137498 A, </span><span class="patent-bibdata-value">US 6137498A, </span><span class="patent-bibdata-value">US-A-6137498, </span><span class="patent-bibdata-value">US6137498 A, </span><span class="patent-bibdata-value">US6137498A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Robert+S.+Silvers%22">Robert S. Silvers</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Runaway+Technology,+Inc.%22">Runaway Technology, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6137498.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6137498.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6137498.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (12),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (52),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (12),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (6)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6137498&usg=AFQjCNFJFUMijTIaAKsJRm21h9rCAuFW4Q">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6137498&usg=AFQjCNHkqiktO8KNISxz4YK9P4FIX1yhKw">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6137498A%26KC%3DA%26FT%3DD&usg=AFQjCNEtIjQbY2x_QJYCC7YkUYcV19SvhQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54673133" lang="EN" load-source="patent-office">Digital composition of a mosaic image</invention-title></span><br><span class="patent-number">US 6137498 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA38143454" lang="EN" load-source="patent-office"> <div class="abstract">A mosaic image is formed from a database of source images. More particularly, the source images are analyzed, selected and organized to produce the mosaic image. A target image is divided into tile regions, each of which is compared with individual source image portions to determine the best available matching source image by computing red, green and blue channel root-mean square error. The mosaic image is formed by positioning the respective best-matching source images at the respective tile regions.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(5)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6137498-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6137498-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6137498-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6137498-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6137498-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6137498-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6137498-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6137498-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US6137498-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US6137498-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(63)</span></span></div><div class="patent-text"><div mxw-id="PCLM5645633" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A method for generating a mosaic image with an appearance that approximates a target image by utilizing a plurality of source images and a computer, comprising the steps of:<div class="claim-text">loading the target image into the computer;</div> <div class="claim-text">dividing the target image into a plurality of tile regions, each tile region representing a distinct locus of the target image, and</div> <div class="claim-text">for each tile region:<div class="claim-text">dividing the tile region into distinct sub-regions;</div> <div class="claim-text">comparing generally complex source images to the tile region to produce a measurement of visual similarity, said comparing step including comparing each sub-region of the tile region with a corresponding portion of each source image to produce the measurement of visual similarity;</div> <div class="claim-text">selecting the source image with the highest measurement of visual similarity to represent the tile region; and</div> <div class="claim-text">positioning the selected source image in the mosaic image at a locus corresponding to the locus of the tile region.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The method of claim 1 including the further step of employing source images having one pixel per respective sub-region.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The method of claim 1 wherein said comparing step includes the further step of computing the average Root-Mean Square error of Red, Green and Blue channels.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The method of claim 1 including the further step of removing source images selected in said selecting step from consideration such that no one source image appears more than once in the mosaic image.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The method of claim 1 including the further step of capturing source images, and storing the captured source images in a database.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The method of claim 5 including the further step of generating modified source images by cropping the source images captured in said capturing step to square.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The method of claim 6 including the further step of, in the case of a captured source image in landscape format, cropping the captured image from center.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The method of claim 7 including the further step of, in the case of a captured source image in portrait format, cropping the captured image from above center.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The method of claim 6 including the further step of categorizing the captured source images within the database.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The method of claim 6 including the further step of storing the captured source images at different levels of resolution.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The method of claim 1 including the further step of deselecting the source image with the highest measurement of visual similarity if it is determined that the source image has a higher measurement of visual similarity to another tile region.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The method of claim 1 including the further step of specifying at least one source image for assured inclusion in the mosaic image, the assured source image being positioned in the mosaic image at a locus corresponding to the locus of the tile region having the highest measure of visual similarity therewith.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The method of claim 1 including the further step of specifying a sub-category of source images for exclusive matching with a predetermined portion of the target image.</div>
    </div>
    </div> <div class="claim"> <div num="14" class="claim">
      <div class="claim-text">14. An apparatus for generating a mosaic image with an appearance that approximates a target image by utilizing a plurality of source images, comprising:<div class="claim-text">A computer workstation that executes mosaic generation software being operative to divide the target image into a plurality of tile regions, each tile region representing a distinct locus of the target image,</div> <div class="claim-text">said mosaic generation software being further operative to operate upon each tile region to:<div class="claim-text">divide the tile region into distinct sub-regions;</div> <div class="claim-text">compare a plurality of generally complex source image portions to the tile region to produce a measurement of visual similarity, the comparing including comparing each sub-region of the tile region with a corresponding portion of each source image to produce the measurement of visual similarity;</div> <div class="claim-text">select the source image with the highest measurement of visual similarity to represent the tile region; and</div> <div class="claim-text">position the selected source image in the mosaic image at a locus corresponding to the locus of the tile region.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. The apparatus of claim 14 wherein the source image employed for comparison with the tile region has one pixel per respective sub-region.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The apparatus of claim 14 wherein the mosaic generation software is further operative to compute the average Root-Mean Square error of Red, Green and Blue channels.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The apparatus of claim 14 wherein the mosaic generation software is further operative to remove selected source images selected from consideration such that no one source image appears more than once in the mosaic image.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. The apparatus of claim 14 further including video equipment selected from the group consisting of a video tape player and a videodisc player, said video equipment being operative to capture source images for storage in a database in the computer workstation.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The apparatus of claim 18 wherein modified source images are generated by cropping and resizing the captured source images to a consistent size.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The apparatus of claim 19 wherein, in the case of a captured source image in landscape format, the captured image is cropped from center.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. The apparatus of claim 20 wherein, in the case of a captured source image in portrait format, the captured image is cropped from above center.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22. The apparatus of claim 19 wherein the captured source images are categorized within the database.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. The apparatus of claim 19 wherein the captured source images are stored at different levels of resolution.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" class="claim">
      <div class="claim-text">24. The apparatus of claim 18 further including an editing computer with software for editing the mosaic image.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25. The apparatus of claim 24 further including a printer for printing the edited mosaic image.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" class="claim">
      <div class="claim-text">26. The apparatus of claim 14 wherein the source image with the highest measurement of visual similarity is deselected if it is determined that the source image has a higher measurement of visual similarity to another tile region.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27. The apparatus of claim 14 wherein at least one source image is assured inclusion in the mosaic image, the assured source image being positioned in the mosaic image at a locus corresponding to the locus of the tile region having the highest measure of visual similarity therewith.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" class="claim">
      <div class="claim-text">28. The apparatus of claim 14 wherein a sub-category of source images is specified for exclusive matching with a predetermined portion of the target image.</div>
    </div>
    </div> <div class="claim"> <div num="29" class="claim">
      <div class="claim-text">29. An article comprising a substrate having a mosaic image thereupon, said mosaic image having an appearance that approximates a target image through use of a plurality of source images, and which mosaic image is generated by a process executed with a computer comprising the steps of:<div class="claim-text">loading the target image into the computer;</div> <div class="claim-text">dividing the target image into a plurality of tile regions, each tile region representing a distinct locus of the target image, and</div> <div class="claim-text">for each tile region:<div class="claim-text">dividing the tile region into distinct sub-regions;</div> <div class="claim-text">comparing generally complex source images to the tile region to produce a measurement of visual similarity, said comparing step including comparing each sub-region of the tile region with a corresponding portion of each source image to produce the measurement of visual similarity;</div> <div class="claim-text">selecting the source image with the highest measurement of visual similarity to represent the tile region; and</div> <div class="claim-text">positioning the selected source image in the mosaic image at a locus corresponding to the locus of the tile region.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" class="claim">
      <div class="claim-text">30. The article of claim 29 wherein the process includes the further step of employing source images having one pixel per respective sub-region.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" class="claim">
      <div class="claim-text">31. The article of claim 29 wherein the process includes the further step of computing the average Root-Mean Square error of Red, Green and Blue channels.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="32" class="claim">
      <div class="claim-text">32. The article of claim 29 wherein the process includes the further step of removing source images selected in said selecting step from consideration such that no one source image appears more than once in the mosaic image.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" class="claim">
      <div class="claim-text">33. The article of claim 29 wherein the process includes the further step of capturing source images, and storing the captured source images in a database.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="34" class="claim">
      <div class="claim-text">34. The article of claim 33 wherein the process includes the further step of generating modified source images by cropping the source images captured in said capturing step to square.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="35" class="claim">
      <div class="claim-text">35. The article of claim 34 wherein the process includes the further step of, in the case of a captured source image in landscape format, cropping the captured image from center.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="36" class="claim">
      <div class="claim-text">36. The article of claim 35 wherein the process includes the further step of, in the case of a captured source image in portrait format, cropping the captured image from above center.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="37" class="claim">
      <div class="claim-text">37. The article of claim 34 wherein the process includes the further step of categorizing the captured source images within the database.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="38" class="claim">
      <div class="claim-text">38. The article of claim 34 wherein the process includes the further step of storing the captured source images at different levels of resolution.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="39" class="claim">
      <div class="claim-text">39. The article of claim 29 wherein the process includes the further step of deselecting the source image with the highest measurement of visual similarity if it is determined that the source image has a higher measurement of visual similarity to another tile region.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="40" class="claim">
      <div class="claim-text">40. The article of claim 29 wherein the process includes the further step of specifying at least one source image for assured inclusion in the mosaic image, the assured source image being positioned in the mosaic image at a locus corresponding to the locus of the tile region having the highest measure of visual similarity therewith.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="41" class="claim">
      <div class="claim-text">41. The article of claim 29 wherein the process includes the further step of specifying a sub-category of source images for exclusive matching with a predetermined portion of the target image.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="42" class="claim">
      <div class="claim-text">42. The article of claim 29 wherein said article includes a printout from a digital printer.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="43" class="claim">
      <div class="claim-text">43. The article of claim 29 wherein said article includes a photograph.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="44" class="claim">
      <div class="claim-text">44. The article of claim 29 wherein said article includes photographic paper.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="45" class="claim">
      <div class="claim-text">45. The article of claim 29 wherein said article includes photographic film.</div>
    </div>
    </div> <div class="claim"> <div num="46" class="claim">
      <div class="claim-text">46. A storage medium for use with a computer comprising a substrate for storing at least one mosaic image having an appearance that approximates a target image through use of a plurality of source images, and which mosaic image is generated by a process comprising the steps of:<div class="claim-text">loading the target image into the computer;</div> <div class="claim-text">dividing the target image into a plurality of tile regions, each tile region representing a distinct locus of the target image, and</div> <div class="claim-text">for each tile region:<div class="claim-text">dividing the tile region into distinct sub-regions;</div> <div class="claim-text">comparing generally complex source images to the tile region to produce a measurement of visual similarity, said comparing step including comparing each sub-region of the tile region with a corresponding portion of each source image to produce the measurement of visual similarity;</div> <div class="claim-text">selecting the source image with the highest measurement of visual similarity to represent the tile region; and</div> <div class="claim-text">positioning the selected source image in the mosaic image at a locus corresponding to the locus of the tile region.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="47" class="claim">
      <div class="claim-text">47. The storage medium of claim 46 wherein said substrate includes a floppy disk.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="48" class="claim">
      <div class="claim-text">48. The storage medium of claim 46 wherein said substrate includes a compact disc.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="49" class="claim">
      <div class="claim-text">49. The storage medium of claim 46 wherein said substrate includes an optical disk.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="50" class="claim">
      <div class="claim-text">50. The storage medium of claim 46 wherein said substrate includes a removable hard disk.</div>
    </div>
    </div> <div class="claim"> <div num="51" class="claim">
      <div class="claim-text">51. A storage medium on which a computer program for generating a mosaic image is stored, the mosaic image to have an appearance that approximates a target image by utilizing a plurality of source images, the computer program being operative to perform a method comprising the steps of:<div class="claim-text">loading the target image into a computer;</div> <div class="claim-text">dividing the target image into a plurality of tile regions, each tile region representing a distinct locus of the target image, and</div> <div class="claim-text">for each tile region:<div class="claim-text">dividing the tile region into distinct sub-regions;</div> <div class="claim-text">comparing generally complex source images to the tile region to produce a measurement of visual similarity, said comparing step including comparing each sub-region of the tile region with a corresponding portion of each source image to produce the measurement of visual similarity;</div> <div class="claim-text">selecting the source image with the highest measurement of visual similarity to represent the tile region; and</div> <div class="claim-text">positioning the selected source image in the mosaic image at a locus corresponding to the locus of the tile region.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="52" class="claim">
      <div class="claim-text">52. The storage medium of claim 51, wherein the method performed by the computer program further comprises the step of employing source images having one pixel per respective sub-region</div>
    </div>
    </div> <div class="claim-dependent"> <div num="53" class="claim">
      <div class="claim-text">53. The storage medium of claim 51, wherein said comparing step includes the further step of computing a form of a Root-Mean Square error of Red, Green and Blue channels.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="54" class="claim">
      <div class="claim-text">54. The storage medium of claim 51, wherein the method performed by the computer program further comprises the step of removing source images selected in said selecting step from consideration such that no one source image appears more than once in the mosaic image.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="55" class="claim">
      <div class="claim-text">55. The storage medium of claim 51, wherein the method performed by the computer program further comprises the steps of capturing source images, and storing the captured source images in a database.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="56" class="claim">
      <div class="claim-text">56. The storage medium of claim 55, wherein the method performed by the computer program further comprises the step of generating modified source images by cropping the source images captured in said capturing step to square.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="57" class="claim">
      <div class="claim-text">57. The storage medium of claim 56, wherein the method performed by the computer program further comprises the step of, in the case of a captured source image in landscape format, cropping the captured image from center.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="58" class="claim">
      <div class="claim-text">58. The storage medium of claim 57, wherein the method performed by the computer program further comprises the step of, in the case of a captured source image in portrait format, cropping the captured image from above center.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="59" class="claim">
      <div class="claim-text">59. The storage medium of claim 56, wherein the method performed by the computer program further comprises the step of categorizing the captured source images within the database.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="60" class="claim">
      <div class="claim-text">60. The storage medium of claim 56, wherein the method performed by the computer program further comprises the step of storing the captured source images at different levels of resolution.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="61" class="claim">
      <div class="claim-text">61. The storage medium of claim 51, wherein the method performed by the computer program further comprises the step of deselecting the source image with the highest measurement of visual similarity if it is determined that the source image has a higher measurement of visual similarity to another tile region.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="62" class="claim">
      <div class="claim-text">62. The storage medium of claim 51, wherein the method performed by the computer program further comprises the step of specifying at least one source image for inclusion in the mosaic image, the assured source image being positioned in the mosaic image at a locus corresponding to the locus of the tile region having the highest measure of visual similarity therewith.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="63" class="claim">
      <div class="claim-text">63. The storage medium of claim 51, wherein the method performed by the computer program further comprises the step of specifying a sub-category of source images for exclusive matching with a predetermined portion of the target image.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67552623" lang="EN" load-source="patent-office" class="description">
    <heading>STATEMENT REGARDING FEDERALLY SPONSORED RESEARCH OR DEVELOPMENT</heading> <p>Not applicable</p>
    <heading>CROSS REFERENCE TO RELATED APPLICATIONS</heading> <p>A claim of priority is made to U.S. Provisional Patent application Ser. No. 60/035,733, filed Jan. 2, 1997, entitled: DIGITAL COMPOSITION OF A MOSAIC IMAGE.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>The present invention is generally related to computerized manipulation of images, and more particularly to generation of an image from a plurality of sub-images.</p>
    <p>Analysis and manipulation of images using computers is well known. For example, computers have been used to analyze images of coins travelling along a conveyor belt to distinguish different types of coins and compute the total value of the coins. Similarly, computers have been used to analyze images of integrated circuits and printed circuit boards in order to detect defects during manufacturing. Manipulation of photographic still images and full motion video images to produce special effects is also well known. However, these known techniques do not produce artistically pleasing mosaic images.</p>
    <heading>BRIEF SUMMARY OF THE INVENTION</heading> <p>In accordance with the present invention, a mosaic image that approximates a target image is produced from a database of source images by analyzing tile portions of the target image, comparing each respective analyzed tile portion of the target image with the source images from the database to provide a best-fit match in accordance with predetermined criteria, and generating a mosaic image comprising the respective best-fit match source images positioned at respective tile portions of the mosaic image which correspond to the respective analyzed tile portions of the target image. In one embodiment the criteria for the best-fit match includes computing a version of Red, Green and Blue ("RGB") Root-Mean Square ("RMS") error. Other matching systems could be employed as long as the goal of finding the source image that is most visually similar to the region of the target image under consideration is met.</p>
    <p>Increased resolution is realized in the mosaic image through sub-region analysis. In particular, each tile portion in the target image is divided into sub-regions which are independently compared with corresponding sub-regions of each source image using, in this example, RGB RMS error analysis. The computed RGB RMS error for each sub-region is summed to provide a sum RGB RMS error for the entire source image. The unallocated image having the lowest sum RGB RMS error is then allocated for use in the corresponding tile portion in the mosaic image. The use of sub-regions even benefits regions without detail and results in more uniform distribution of color by selecting lower contrast images for these areas of little high-frequency detail. Another embodiment employs a second pass to prevent a source image from being placed in a given location in the mosaic if it would have a lower error in another location.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWING</heading> <p>The file of this patent contains at least one drawing executed in color. Copies of this patent with color drawing(s) will be provided by the Patent and Trademark Office upon request and payment of the necessary fee.</p>
    <p>The invention will be more fully understood in view of the following Detailed Description of the Invention, in conjunction with the Drawing, of which:</p>
    <p>FIG. 1 is a block diagram of a mosaic image generating system;</p>
    <p>FIG. 2 is a block diagram of a database of source images;</p>
    <p>FIG. 3 is a flow diagram that illustrates a method of mosaic image generation;</p>
    <p>FIG. 4 is a diagram that illustrates tiles and sub-regions;</p>
    <p>FIG. 5 illustrates the effect of sub-region analysis on source image selection; and</p>
    <p>FIG. 6 illustrates the effect of sub-region analysis on final mosaic image resolution.</p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading> <p>FIG. 1 illustrates apparatus for generating a mosaic image 10 from captured source images 12 to approximate a target image 14. In the disclosed embodiment a VHS video tape player 16 is employed to facilitate capture of source images from video tapes. The video tape player may be employed to single-step through a video tape to capture still images for use as source images. Alternatively, source images can be captured in real-time during playback of a video tape. A computer controllable laserdisc player 18 also can be employed to facilitate capture of source images. Laserdiscs are preferable to video tapes when the desired subject matter is available from both sources because of the higher quality and easy random access to still images available from laserdisc. In the disclosed embodiment a computer workstation 20 with a video input is employed to capture the source images 12 from the video tape player 16 and laserdisc player 18. The computer workstation also accepts the target image 14 as input, and is employed to generate the mosaic image 10 from the target image and source images by executing mosaic software. The mosaic image 10 generated by the mosaic software comprises an array of tiles 22, where each tile 22 is a source image 12, and the overall appearance of the mosaic image 10 approximates the appearance of the target image 14. An editing computer 24 such as a Macintosh (TM), PC or UNIX (TM) based system equipped with image editing software such as Adobe Photoshop (TM) can be employed for editing the mosaic image 22, to produce an edited mosaic image 26. A printer output device 28 may be employed to print the edited mosaic image 26.</p>
    <p>Captured source images 12 can be analyzed and stored in a database 30 that is maintained in the workstation 20. An add<sub>--</sub> images<sub>--</sub> to<sub>--</sub> database program is employed to analyze raw captured source images 12 and create new source images therefrom. More particularly, the add images<sub>--</sub> to<sub>--</sub> database program accepts a list of filesystem directories, an image size, and an output path as input, and operates in response to open each designated directory and search for source images from which to crop and resize to the specified dimensions. The square is subsequently moved to the location specified by the output path. In one embodiment, if the source image is in landscape format, a square image is cropped from the center of the source image. If the source image is in portrait format, a square is cropped from between the center and the top of the source image. As a consequence, the square image is more likely to include the emphasized feature of the source image, such as a person's face, without clipping the edges thereof. The images are then stored in the database 30. The database 30 is a file system which holds the formatted images in directories that are categorized by subject matter and size.</p>
    <p>FIG. 2 illustrates organization of source images 12 within the database 30 (FIG. 1). Source images 12 are categorized and placed under root nodes such as an animals root node 32, a people root node 34 or a places root node 36. To generate a mosaic image from source images of animals, the animals root node 32 is selected for the mosaic software. Directly under the animals root node are subdirectories containing identical image files at different levels of resolution. An originals subdirectory 38 contains uncropped versions of each source image file at full size 40. The originals subdirectory 38 is maintained because source images may be recropped during mosaic creation if the results from the add<sub>--</sub> images<sub>--</sub> to<sub>--</sub> database program are unacceptable. Directories labeled 256×256 (pixels) 42 and 64×64 (pixels) 44 contain large versions of the formatted source images which are used primarily for outputting a final bitmap. In this example, a 32×32 (pixels) 46 directory contains source images which are used for viewing the mosaic image on the screen during the construction process. The 16×16 (pixels) 48, 8×8 (pixels) 50, and 1×1 (pixels) 52 subdirectories contain source images which are preloaded when the mosaic software is initialized. The source images in the 16×16, 8×8, and 1×1 subdirectories are employed for matching source images to target image during mosaic image generation. Directories of source images at other levels of resolution may also be maintained.</p>
    <p>FIG. 3 illustrates a method for generating the mosaic image. Referring now to FIGS. 2, 3 and 4, the target image is selected and loaded as indicated in step 60. A root node of source images in the database is then selected and loaded as indicated in step 62. More particularly, a database path is specified and a mosaic program is executed. The mosaic program reads source images from the section of the database indicated by the specified database path, analyzes the target image and selects a source image for use in each tile of the mosaic image. More particularly, source images having resolution corresponding to the selected number of sub-regions ("sub-region resolution") for the mosaic image are loaded into a linked list of structures:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________struct an<sub>--</sub> image {char *path;   /pathname of file in database/char used;    /whether image has been used/unsigned short *r;         /RGB image data for RMS matching/unsigned short *g;unsigned short *b;struct an<sub>--</sub> image *next;           /pointer to next structure/struct an<sub>--</sub> image *previous;             /pointer to prev structure/} an<sub>--</sub> image;______________________________________</pre>
    
    <p>For example, if each tile in the mosaic image is to contain 8 X-axis sub-regions by 8 Y-axis sub-regions, then 8×8 (pixels) images are loaded from the database. The size of the target image in pixels along each axis is equal to the number of output tiles multiplied by the number of desired sub-regions to be considered during the matching process, i.e., one pixel per sub-region along each respective axis. The respective numbers of tiles which will be employed for the X and Y axes of both the mosaic image and target image is then specified as indicated in step 64.</p>
    <p>The mosaic program executes a matching process once the source and target images have been loaded. When the matching process begins, the target image is divided into "x" by "y" tiles 22, where (x, y) is:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">(target<sub>--</sub> image<sub>--</sub> width/width<sub>--</sub> subsamples, target<sub>--</sub> image<sub>--</sub> height/height<sub>--</sub> subsamples)</pre>
    
    <p>A new tile is loaded as indicated in step 68. A new sub-region 66 is then loaded as indicated in step 70. Loading begins with the upper left sub-region 66 of the tile 22, and moves from left to right through each row, and from top to bottom by row. The source image pixel that corresponds to the loaded sub-region is then loaded as indicated in step 72.</p>
    <p>The matching process analyzes tiles 22 individually on a serial basis. For each tile 22 in the disclosed embodiment, a variation of the average Root-Mean Square ("RMS") error of the Red, Green, and Blue ("RGB") channels of each sub-region 66 is compared to each respective corresponding source image pixel, for each source image in the database that is of proper resolution and is not designated as "used." A RMS error between the loaded pixel and loaded sub-region is computed for RGB channels and kept as a running sum for the tile as indicated in step 74. If unanalyzed sub-regions exist in the tile as indicated in step 76, flow returns to step 70. If all sub-regions have been analyzed, as determined in step 76, then the running sum RGB RMS error is compared to the lowest such error yet computed for a source image and the tile as indicated in step 78. If the error sum is lower than any previously recorded error sum for the tile, the error sum value and an index to the source image are recorded as indicated in step 80.</p>
    <p>When all of the source images have been analyzed for similarity to the tile, the source image with the least computed RGB RMS error is assigned to a tile in the mosaic image corresponding to the tile in the target image, i.e., in the same location in the image. More particularly, if other source images in the database have not been compared with the tile as determined in step 82, a new source image is loaded as indicated in step 84 and flow returns to step 70. If all source images have been compared with the tile as determined in step 82, the source image with the lowest sum error is allocated to the tile and marked as "used" as indicated in step 86. The assigned source image is marked as "used" so that source images do not appear more than once in the mosaic image.</p>
    <p>The matching process is repeated for each and every tile in the target image. Upon completion, a list of source images is written to a text file which is used by a final rendering program to construct a bitmap from the full resolution versions of the source images. More particularly, if all tiles have been examined as determined in step 88, a list of the lowest sum error source images for each tile is written to a text file as indicated in step 90, and the mosaic program reads the list and assembles a bitmap as indicated in step 92. If unexamined tiles still exist as determined in step 88, flow returns to step 68.</p>
    <p>A variation of the matching process, including computation of RMS error, is implemented as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________/* The goal of this routine is to find which sourcephotographs are the most *//* visually similar to a given region (grid-space) of thetarget image. */int find<sub>--</sub> matches(int x, int y)register i, rt, gt, bt;int low, result, ii, the tile;char imagename[256], best<sub>--</sub> path[256];unsigned short rmas[XMAX*YMAX], gmas[XMAX*YMAX], bmas[XMAX*YMAX];the<sub>--</sub> tile = x+(y*sizex);/* For this given grid-location of the target image,clear the list of errors. *//* This list will later contain the computed errors andwill be sorted from best *//* to worst */for(i = 0; i &lt; pixels; i++)  {tiles[the<sub>--</sub> tile].list[i].score=99999999;tiles[the<sub>--</sub> tile].list[i].rank = 0;}strcpy(imagename, filename);  /* Get the name of thetarget image */imagename[strlen(imagename)-3] = `s`; /* Make sure that ithas the proper filename extension */imagename[strlen(imagename)-2] = `g`;imagename[strlen(imagename)-1] = `i`;get<sub>--</sub> grid<sub>--</sub> space(rmas, gmas, bmas, x, y); /* Get the imagedatafor the desired region of the *//* target image and put it into three arrays. */image = head<sub>--</sub> image;   */ Reset the linked-list of sourceimages to the beginning */while(image-&gt;next != NULL) { /* For every source image weare considering */result = 0;/* This is a variation of RGB RMS error. The final square-root has been eliminated to *//* speed up the process. We can do this because we only careabout relative error. *//* HSV RMS error or other matching systems could be usedhere, as long as the goal of *//* finding source images that are visually similar to theportion of the target image *//* under consideration is met. */for(i = 0; i &gt; size; i++) {rt = (int) ((unsigned char)rmas[i] - (unsignedchar)image-&gt;r[i]);gt = (int) ((unsigned char)gmas[i] - (unsigned char)image-&gt;g[i];bt = (int) ((unsigned char)bmas[i] - (unsignedchar)image-&gt;b[i];result += (rt*rt+gt*gt+bt*bt);}i = 0;/* The following code takes the error computed for thelast source image and inserts *//* it into a sorted list of all of the source images.The list is shifted towards the *//* end to make room for this insertion */if (result &lt; tiles[the<sub>--</sub> tile].list[pixels-1].score) {while((result &gt; tiles[the<sub>--</sub> tile].list[i].score)&amp;&amp;(i++ &lt; pixels));for(ii = pixels-1; ii&gt; i; ii--) {tiles[the<sub>--</sub> tile].list[ii}.score = tiles[thetile].list[ii-1].score;tiles[the<sub>--</sub> tile].list[ii].rank = tiles[thetile].list[ii-1].rank;tiles[the<sub>--</sub> tile].list[ii].pointer = tiles[thetile].list]ii-1].pointer;}tiles[the<sub>--</sub> tile].list[i].score = result;tiles[the<sub>--</sub> tile].list[i].rank = i;tiles[the<sub>--</sub> tile].list[i].pointer = image;}/* Now let's move to the next source image and repeatuntil we run out */image = image-&gt;next;} /* while *//* Since the list is sorted from next to worse, we can seethe best tile by looking at *//* the first list entry. */low = tiles[the<sub>--</sub> tile].list[0].score;tiles[the<sub>--</sub> tile].score = tiles[the<sub>--</sub> tile].list[0].score;tiles[the<sub>--</sub> tile].rank = tiles[the<sub>--</sub> tile].list[0].rank;strcpy(best<sub>--</sub> path, tiles[the<sub>--</sub> tile].list[0].pointer-&gt;path);/* Do not let this image get replaced later because it wasspecified as required for the mosaic. */tiles[the<sub>--</sub> tile].required = tiles[the<sub>--</sub> tile].list[0].pointer-&gt;required;strcpy(tiles[the<sub>--</sub> tile].path, best<sub>--</sub> path);sprintf(imagename, "%s/%s", disp<sub>--</sub> version, best<sub>--</sub> path);/* We now have a sorted list of source images from most-visually-similar to least-visually-similar *//* for this grid location of the target image.*/return low;} /* find<sub>--</sub> matches () */______________________________________</pre>
    
    <p>A second routine is used in one embodiment of the invention to take the sorted list from the previous routine and not only ensure that each source image is only used once but also to see that a given source image will not be selected for one region if it is an even lower match in another.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________/* In the first phase of the program (find<sub>--</sub> matches ()),e created a sorted list of source images *//* for each grid-space of the target image. Since wedo not want to repeat source images within *//* the mosaic, each grid-space cannot have its firstchoice source image (a source image may have *//* the lowest match for more than one grid location).The purpose of this routine is to decide which *//* of the grid locations actually gets to use the sourceimage. For example, it will not be placed *//* in one grid location if it an even better match toanother */int optimize ()int i, x, deepest = 0, change, a, step, which;/* For each of the grid-locations in the target image(number of tiles in the final mosaic) *//* This an N 2 algorithm, so we must loop twice toensure that we consider all images for *//* all grid-locations. */for(a = 0; a &lt; pixels; a++) {change = 0;/* For each of the grid-locations in the targetimage (number of tiles in the final mosaic) */for(x = 0; x &lt; pixels; x++) {which = 0;do {step = 0;for(i = 0; i &lt; pixels; i++) {/* If tile is wanted more somewhere else, giveit to them. *//* We do this by going through all the topchoices for the other grid locations. *//* If we see the same source image listed asthe first choice at another grid *//* location, we check to see if it is a bettermatch at the other location. *//* If it is, we move through our sorted listto the next best match for our current *//* grid-location and do this until we find asource image that is not a better match *//* anywhere else. When we find this, we cankeep it. The variable "step" stays as 0 and *//* we exit the do-while loop */if ((tiles[i].rank &lt;= which) &amp;&amp;(!strcmp(tiles[x].list[which].pointer-&gt;patch,tiles[i].path))) {   /* If rank is same, check scores. */   if ((tiles[i].rank == which) &amp;&amp;(tiles[i].score &gt; tiles[x].list[which].score)) continue   if (i == x) continue;   which++;   step = 1,   i - pixels; /* Skip to while. */}}} while (step);if (which &gt; deepest) deepest = which;/* Now that we found the most visually-similar sourceimage that is *not* a better match in another *//* grid location, we se the name of the image asassociated with this grid-location of the target *//* image. */if (strcmp(tiles[x].path, tiles [x].list[which].pointer-&gt;path)) {change++;strcpy(tiles[x].path, tiles[x].list[which].pointer-&gt;path);tiles[x].required = tiles[x].list[which].pointer-&gt;required;tiles[x].score = tiles[x].list[which].score;tiles[x].rank = which;}} /* for *//* If we go through all of the grid-locations and we do notneed to replace any *//* tiles as being a better match in another location, we canexit the routine now. */if (!change) break;fprintf(stderr, "\n%d/%d, %d changes (deepest is%d)\n", a,pixels-1, change, deepest);/* We need to loop back with this for loop as many times asthere are grid-space in the final mosaic. */ } /* for */} /* optimize() */______________________________________</pre>
    
    <p>A rendering program can be employed to produce the mosaic image following the matching process. The rendering program reads the list of the selected tiles, locates the full sized version of each respective corresponding source image in the database, and binds the located source images together to create a bitmap. The tiles in the mosaic image may be separated by a line to discretize them when viewed from close proximity. From a distance, the gridlines should be thin enough to disappear completely to the human eye, so as not to interfere with the seamlessness of the mosaic. The bitmap is then saved in a standard format to be displayed on a monitor or output in printed form.</p>
    <p>The digital mosaic image can be printed in different ways, depending on quality, price and size constraints. Film recording and photographic printing may be employed. An image can be written to photographic film using a film recorder. Once the image is on chrome or negative, it can be printed on normal photographic paper. This option is best for a moderate number of small copies as writing the image onto the film is a one time cost. Direct digital printing potentially produces the highest quality, but each print is expensive. Digital printers employ either continuous-toning or half-toning. Continuous-tone printers deposit an exact color for each pixel in the image. Half toning printers deposit only drops of solid color, forming shades of color by using dots of different sizes or different spacing. Hence, the print will look less photographic. Process color printing is the technique used to reproduce images in magazines and books, and is a good method for producing many (e.g., hundreds of thousands) near-photographic copies.</p>
    <p>The effects of sub-region based analysis on source image selection are illustrated in FIG. 5. A target image 100 was employed to produce first, second and third mosaic images 102, 104, 106, respectively. The target image 100 includes 4×4 tiles. An intermediate "sensed" image representing the average of all pixels in the smallest analyzed portion (tiles in image 108, and sub-regions in images 110 and 112). In the first analysis, resulting in images 108 and 102, sub-regions are not employed. In the second analysis, resulting in images 110 and 104, 4×4 sub-regions per tile are employed. Because some light and dark regions can be sensed within each tile in the second analysis, those sensed regions are taken into consideration when searching the database during the selection process.</p>
    <p>In the third analysis, resulting in images 112 and 106, 16×16 sub-regions are employed. With 16×16 sub-regions, the intermediate image 112 is substantially closer to the target image 100. Further, image 106 shows that when this amount of detail is considered during the selection process, more appropriate matches are selected. For example, the woman in the first row is the same shape as the vertical black bar in the same region of the target image. Further, the lizard in another tile matches the diagonal that it was compared to. This high-degree of shape matching has a powerful effect on the image-forming ability of the final mosaic image as information about the contours and shading in a target image may transcend the boundaries of each mosaic tile.</p>
    <p>In addition to providing improved source image selection, the use of sub-regions results in more uniform distribution of color by selecting lower contrast images for regions of little high-frequency detail. This can be seen in the lower eight tiles of image 106 which are more uniform than those selected for image 104.</p>
    <p>FIG. 6 illustrates the effects of number of sub-regions on mosaic image resolution. First and second mosaic images 144, 116 were generated from a target image 118. The first mosaic image 114 was generated with 2×2 sub-regions within each tile considered during the source image selection process. The second mosaic image 116 was generated with 16×16 sub-regions within each tile considered during the source image selection process. The same collection of source images was employed to produce both the first and second mosaic images. Because of the sub-region analysis, different source images were selected to represent some corresponding tiles in the first and second mosaic images. Further, the second mosaic image 116 bears a stronger resemblance to the target image 118 than the first mosaic image 114. Hence, improved source image selection provided through analysis of more sub-regions generates improved resolution in the resultant mosaic image.</p>
    <p>In an alternative embodiment, semantic content is specified for portions of the mosaic image. More particularly, image sub-categories are specified for use with specified tiles of the target image. Hence, the resultant mosaic image includes tiles or regions of tiles with predetermined categories of images.</p>
    <p>In another alternative embodiment images can be selected for assured selection and inclusion in the mosaic image.</p>
    <p>More particularly, the selected images are placed in the location of greatest visual similarity relative to the target image even if another (unassured) image is determined to have greater visual similarity.</p>
    <p>Having described the preferred embodiments of the invention, other embodiments which incorporate concepts of the invention will now become apparent to one of skill in the art. Therefore, the invention should not be viewed as limited to the disclosed embodiments but rather should be viewed as limited only by the spirit and scope of the appended claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3987558">US3987558</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 19, 1972</td><td class="patent-data-table-td patent-date-value">Oct 26, 1976</td><td class="patent-data-table-td ">Shouji Tsukamoto</td><td class="patent-data-table-td ">Device for producing a block-built picture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4398890">US4398890</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 16, 1981</td><td class="patent-data-table-td patent-date-value">Aug 16, 1983</td><td class="patent-data-table-td ">Knowlton Kenneth C</td><td class="patent-data-table-td ">Representation of designs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4644582">US4644582</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 24, 1984</td><td class="patent-data-table-td patent-date-value">Feb 17, 1987</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Image registration method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4731743">US4731743</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 12, 1985</td><td class="patent-data-table-td patent-date-value">Mar 15, 1988</td><td class="patent-data-table-td ">Combputer Images, Inc.</td><td class="patent-data-table-td ">Method of using a video camera with a computer to create hair style change</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5150295">US5150295</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 22, 1990</td><td class="patent-data-table-td patent-date-value">Sep 22, 1992</td><td class="patent-data-table-td ">Teledyne Industries, Inc.</td><td class="patent-data-table-td ">Computerized system for joining individual maps into a single map product</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5649032">US5649032</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 14, 1994</td><td class="patent-data-table-td patent-date-value">Jul 15, 1997</td><td class="patent-data-table-td ">David Sarnoff Research Center, Inc.</td><td class="patent-data-table-td ">System for automatically aligning images to form a mosaic image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0199573A2?cl=en">EP0199573A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 21, 1986</td><td class="patent-data-table-td patent-date-value">Oct 29, 1986</td><td class="patent-data-table-td ">E.I. Du Pont De Nemours And Company</td><td class="patent-data-table-td ">Electronic mosaic imaging process</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0461830A2?cl=en">EP0461830A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 10, 1991</td><td class="patent-data-table-td patent-date-value">Dec 18, 1991</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Figure editing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=GdJRBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH0855133A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFo7d9F-GTPtjymemtnzQciCQWCyw">JPH0855133A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=GdJRBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH07302271A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFQG-Vvx4i-l7y_rr8YjvC0o4ZSpg">JPH07302271A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=GdJRBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH10188023A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHoecQdYSqGgdkLxFkbXUI25IPJxg">JPH10188023A</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1995002224A1?cl=en">WO1995002224A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 1, 1994</td><td class="patent-data-table-td patent-date-value">Jan 19, 1995</td><td class="patent-data-table-td ">Dror Yoav Ben</td><td class="patent-data-table-td ">Page-makeup system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Knowlton et al., "<a href='http://scholar.google.com/scholar?q="Computer-Produced+Grey+Scales"'>Computer-Produced Grey Scales</a>" Computer Graphics and Image Processing, 1:1-20 (1972).</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Knowlton et al., Computer Produced Grey Scales Computer Graphics and Image Processing , 1:1 20 (1972).</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Robert Silvers, image on cover of Wired magazine, Nov. 1995.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6434280">US6434280</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 9, 1998</td><td class="patent-data-table-td patent-date-value">Aug 13, 2002</td><td class="patent-data-table-td ">Gentech Corporation</td><td class="patent-data-table-td ">System and method for generating super-resolution-enhanced mosaic images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6532312">US6532312</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 14, 1999</td><td class="patent-data-table-td patent-date-value">Mar 11, 2003</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Photoquilt</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6549679">US6549679</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 1999</td><td class="patent-data-table-td patent-date-value">Apr 15, 2003</td><td class="patent-data-table-td ">Arcsoft, Inc.</td><td class="patent-data-table-td ">Automated picture montage method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6633685">US6633685</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 1999</td><td class="patent-data-table-td patent-date-value">Oct 14, 2003</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Method, apparatus, and storage media for image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6665451">US6665451</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 28, 1999</td><td class="patent-data-table-td patent-date-value">Dec 16, 2003</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6687419">US6687419</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 12, 1999</td><td class="patent-data-table-td patent-date-value">Feb 3, 2004</td><td class="patent-data-table-td ">Synoptics Limited</td><td class="patent-data-table-td ">Automatic image montage system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6724946">US6724946</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 21, 2000</td><td class="patent-data-table-td patent-date-value">Apr 20, 2004</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing method, apparatus and storage medium therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6895127">US6895127</a></td><td class="patent-data-table-td patent-date-value">Sep 7, 2000</td><td class="patent-data-table-td patent-date-value">May 17, 2005</td><td class="patent-data-table-td ">Arcsoft, Inc.</td><td class="patent-data-table-td ">Photomontage using multiple layer placement and color variation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6898331">US6898331</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 28, 2002</td><td class="patent-data-table-td patent-date-value">May 24, 2005</td><td class="patent-data-table-td ">Bae Systems Aircraft Controls, Inc.</td><td class="patent-data-table-td ">Image fusion system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6927874">US6927874</a></td><td class="patent-data-table-td patent-date-value">Mar 30, 2000</td><td class="patent-data-table-td patent-date-value">Aug 9, 2005</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing method, apparatus and storage medium therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6972774">US6972774</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 18, 2000</td><td class="patent-data-table-td patent-date-value">Dec 6, 2005</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Image processing system for inserting plurality of images into composite area, and medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7012623">US7012623</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 29, 2000</td><td class="patent-data-table-td patent-date-value">Mar 14, 2006</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7194453">US7194453</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 27, 2001</td><td class="patent-data-table-td patent-date-value">Mar 20, 2007</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image retrieval method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7236182">US7236182</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 28, 2002</td><td class="patent-data-table-td patent-date-value">Jun 26, 2007</td><td class="patent-data-table-td ">Pioneer Corporation</td><td class="patent-data-table-td ">Image processing system and method, and computer-readable recording medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7495676">US7495676</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 24, 2003</td><td class="patent-data-table-td patent-date-value">Feb 24, 2009</td><td class="patent-data-table-td ">Admotion Holdings Pty Ltd.</td><td class="patent-data-table-td ">Process for creation and display of merged digital images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7565028">US7565028</a></td><td class="patent-data-table-td patent-date-value">Sep 29, 2004</td><td class="patent-data-table-td patent-date-value">Jul 21, 2009</td><td class="patent-data-table-td ">Aryan Saed</td><td class="patent-data-table-td ">Digital composition of a mosaic image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7711183">US7711183</a></td><td class="patent-data-table-td patent-date-value">Oct 5, 2004</td><td class="patent-data-table-td patent-date-value">May 4, 2010</td><td class="patent-data-table-td ">Arcsoft, Inc.</td><td class="patent-data-table-td ">Photomontage using multiple layer placement and color variation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7809732">US7809732</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 29, 2003</td><td class="patent-data-table-td patent-date-value">Oct 5, 2010</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Method, apparatus, and storage media for image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8159550">US8159550</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 22, 2006</td><td class="patent-data-table-td patent-date-value">Apr 17, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Presenting images as mosaics</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8307748">US8307748</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 16, 2011</td><td class="patent-data-table-td patent-date-value">Nov 13, 2012</td><td class="patent-data-table-td ">Armorworks Enterprises LLC</td><td class="patent-data-table-td ">Multi-range camouflage design and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8334877">US8334877</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 29, 2004</td><td class="patent-data-table-td patent-date-value">Dec 18, 2012</td><td class="patent-data-table-td ">Aryan Saed</td><td class="patent-data-table-td ">Digital composition of a mosaic motion picture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8340423">US8340423</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 29, 2009</td><td class="patent-data-table-td patent-date-value">Dec 25, 2012</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Enhancing digital image mosaics using region-statistics</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8437542">US8437542</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 20, 2010</td><td class="patent-data-table-td patent-date-value">May 7, 2013</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image processing apparatus, method, and program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8515121">US8515121</a></td><td class="patent-data-table-td patent-date-value">Nov 9, 2010</td><td class="patent-data-table-td patent-date-value">Aug 20, 2013</td><td class="patent-data-table-td ">Digimarc Corporation</td><td class="patent-data-table-td ">Arrangement of objects in images or graphics to convey a machine-readable signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8515137">US8515137</a></td><td class="patent-data-table-td patent-date-value">May 3, 2010</td><td class="patent-data-table-td patent-date-value">Aug 20, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Generating a combined image from multiple images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8599287">US8599287</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 2, 2012</td><td class="patent-data-table-td patent-date-value">Dec 3, 2013</td><td class="patent-data-table-td ">Rakuten, Inc.</td><td class="patent-data-table-td ">Image providing device, image processing method, image processing program, and recording medium for forming a mosaic image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8628087">US8628087</a></td><td class="patent-data-table-td patent-date-value">Jul 5, 2011</td><td class="patent-data-table-td patent-date-value">Jan 14, 2014</td><td class="patent-data-table-td ">Kenneth C. Knowlton</td><td class="patent-data-table-td ">Personalized mosaic puzzle set</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8660307">US8660307</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 2012</td><td class="patent-data-table-td patent-date-value">Feb 25, 2014</td><td class="patent-data-table-td ">The Nielsen Company (Us), Llc</td><td class="patent-data-table-td ">Methods and apparatus to count people in images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8718401">US8718401</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 30, 2010</td><td class="patent-data-table-td patent-date-value">May 6, 2014</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image processing device, method and program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8761442">US8761442</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 2012</td><td class="patent-data-table-td patent-date-value">Jun 24, 2014</td><td class="patent-data-table-td ">The Nielsen Company (Us), Llc</td><td class="patent-data-table-td ">Methods and apparatus to count people in images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8774557">US8774557</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 27, 2010</td><td class="patent-data-table-td patent-date-value">Jul 8, 2014</td><td class="patent-data-table-td ">Rakuten, Inc.</td><td class="patent-data-table-td ">Mosaic image generation device, mosaic image generation method and mosaic image recording medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110050723">US20110050723</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 28, 2010</td><td class="patent-data-table-td patent-date-value">Mar 3, 2011</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image processing apparatus and method, and program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110058057">US20110058057</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 28, 2010</td><td class="patent-data-table-td patent-date-value">Mar 10, 2011</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image capture device and method, image processing device and method, and program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110058736">US20110058736</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 20, 2010</td><td class="patent-data-table-td patent-date-value">Mar 10, 2011</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image processing apparatus, method, and program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110103683">US20110103683</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 30, 2010</td><td class="patent-data-table-td patent-date-value">May 5, 2011</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image processing device, method and program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110193873">US20110193873</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 25, 2011</td><td class="patent-data-table-td patent-date-value">Aug 11, 2011</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Device and method for generating mosaic image including text</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110276643">US20110276643</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 4, 2011</td><td class="patent-data-table-td patent-date-value">Nov 10, 2011</td><td class="patent-data-table-td ">Fischman Marc</td><td class="patent-data-table-td ">Method, system, and apparatus for creating an art form from a data stream</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120132063">US20120132063</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 16, 2011</td><td class="patent-data-table-td patent-date-value">May 31, 2012</td><td class="patent-data-table-td ">Armorworks Enterprises, Llc</td><td class="patent-data-table-td ">Multi-range camouflage design and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120159348">US20120159348</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 21, 2010</td><td class="patent-data-table-td patent-date-value">Jun 21, 2012</td><td class="patent-data-table-td ">Stroomer Jeffrey D</td><td class="patent-data-table-td ">Mosaic generation from user-created content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120250986">US20120250986</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 27, 2010</td><td class="patent-data-table-td patent-date-value">Oct 4, 2012</td><td class="patent-data-table-td ">Rakuten, Inc.</td><td class="patent-data-table-td ">Image generation device, image generation method, image generation program, and recording medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120268488">US20120268488</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 27, 2010</td><td class="patent-data-table-td patent-date-value">Oct 25, 2012</td><td class="patent-data-table-td ">Rakuten, Inc.</td><td class="patent-data-table-td ">Image generation device, image generation method, image generation program, and recording medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130229548">US20130229548</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 2, 2012</td><td class="patent-data-table-td patent-date-value">Sep 5, 2013</td><td class="patent-data-table-td ">Rakuten, Inc.</td><td class="patent-data-table-td ">Image providing device, image processing method, image processing program, and recording medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130259381">US20130259381</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 29, 2012</td><td class="patent-data-table-td patent-date-value">Oct 3, 2013</td><td class="patent-data-table-td ">Venugopal Srinivasan</td><td class="patent-data-table-td ">Methods and apparatus to count people in images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE41447">USRE41447</a></td><td class="patent-data-table-td patent-date-value">Apr 20, 2006</td><td class="patent-data-table-td patent-date-value">Jul 20, 2010</td><td class="patent-data-table-td ">Bae Systems Controls, Inc.</td><td class="patent-data-table-td ">Image fusion system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN100421122C?cl=en">CN100421122C</a></td><td class="patent-data-table-td patent-date-value">Aug 27, 2003</td><td class="patent-data-table-td patent-date-value">Sep 24, 2008</td><td class="patent-data-table-td ">Bae系统航空控制公司</td><td class="patent-data-table-td ">Image fusion system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN100481131C?cl=en">CN100481131C</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td patent-date-value">Apr 22, 2009</td><td class="patent-data-table-td ">英业达股份有限公司</td><td class="patent-data-table-td ">Image editing system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN100511283C?cl=en">CN100511283C</a></td><td class="patent-data-table-td patent-date-value">Oct 25, 2005</td><td class="patent-data-table-td patent-date-value">Jul 8, 2009</td><td class="patent-data-table-td ">英业达股份有限公司</td><td class="patent-data-table-td ">Figure making system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2602762A1?cl=en">EP2602762A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 2, 2012</td><td class="patent-data-table-td patent-date-value">Jun 12, 2013</td><td class="patent-data-table-td ">Rakuten, Inc.</td><td class="patent-data-table-td ">Image providing device, image processing method, image processing program, and recording medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2002056253A1?cl=en">WO2002056253A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 10, 2001</td><td class="patent-data-table-td patent-date-value">Jul 18, 2002</td><td class="patent-data-table-td ">Jho Cheung Woon</td><td class="patent-data-table-td ">Method for representing color paper mosaic using computer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2004021264A1?cl=en">WO2004021264A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 27, 2003</td><td class="patent-data-table-td patent-date-value">Mar 11, 2004</td><td class="patent-data-table-td ">Bae Systems Aircraft Controls</td><td class="patent-data-table-td ">Image fusion system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2009026015A1?cl=en">WO2009026015A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 8, 2008</td><td class="patent-data-table-td patent-date-value">Feb 26, 2009</td><td class="patent-data-table-td ">Edward Acworth</td><td class="patent-data-table-td ">Method and apparatus for making a mosaic</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2010080851A2?cl=en">WO2010080851A2</a></td><td class="patent-data-table-td patent-date-value">Jan 6, 2010</td><td class="patent-data-table-td patent-date-value">Jul 15, 2010</td><td class="patent-data-table-td ">Kondo, Hiroshi</td><td class="patent-data-table-td ">Personalized mosaic puzzle set</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S629000">345/629</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S284000">382/284</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S634000">345/634</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0005000000">G06T5/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0003000000">G06T3/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0005200000">G06T5/20</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005262000">H04N5/262</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0011000000">G06T11/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0001000000">G06T1/00</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T11/00">G06T11/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=GdJRBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06T2200/32">G06T2200/32</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06T11/00</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Apr 24, 2012</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 31, 2010</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1, 14, 29, 46 AND 51 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 2-10, 15-25, 30-45, 47-50 AND 52-60, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. CLAIMS 11-13, 26-28 AND 61-63 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 4, 2008</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20080912</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 20, 2008</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 26, 2004</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 27, 1997</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">RUNAWAY TECHNOLOGY, INC., MASSACHUSETTS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:SILVERS, ROBERT S.;REEL/FRAME:008803/0563</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19971022</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U31tqVv42vzEmKpUYfZFJkZlgr3Rg\u0026id=GdJRBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U2K1HJJ0aovVkBj6jN8wNfDWfwgHg\u0026id=GdJRBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U0ESzJNStqit5sdJOWsh2JOyQ5YlA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Digital_composition_of_a_mosaic_image.pdf?id=GdJRBAABERAJ\u0026output=pdf\u0026sig=ACfU3U2HtORNOsx8prcJ4sJmufeDVg7YvA"},"sample_url":"http://www.google.com/patents/reader?id=GdJRBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>