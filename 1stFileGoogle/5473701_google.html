<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5473701 - Adaptive microphone array - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Adaptive microphone array"><meta name="DC.contributor" content="Juergen Cezanne" scheme="inventor"><meta name="DC.contributor" content="Gary W. Elko" scheme="inventor"><meta name="DC.contributor" content="At&amp;T Corp." scheme="assignee"><meta name="DC.date" content="1993-11-5" scheme="dateSubmitted"><meta name="DC.description" content="The present invention is directed to a method of apparatus of enhancing the signal-to-noise ratio of a microphone array. The array includes a plurality of microphones and has a directivity pattern which is adjustable based on one or more parameters. The parameters are evaluated so as to realize an angular orientation of a directivity pattern null. This angular orientation of the directivity pattern null reduces microphone array output signal level. Parameter evaluation is performed under a constraint that the null be located within a predetermined region of space. Advantageously, the predetermined region of space is a region from which undesired acoustic energy is expected to impinge upon the array, and the angular orientation of a directivity pattern null substantially aligns with the angular orientation of undesired acoustic energy. Output signals of the array microphones are modified based on one or more evaluated parameters. An array output signal is formed based on modified and unmodified microphone output signals. The evaluation of parameters, the modification of output signals, and the formation of an array output signal may be performed a plurality of times to obtain an adaptive army response. Embodiments of the invention include those having a plurality of directivity patterns corresponding to a plurality of frequency subbands. Illustratively, the array may comprise a plurality of cardioid sensors."><meta name="DC.date" content="1995-12-5" scheme="issued"><meta name="DC.relation" content="US:4485484" scheme="references"><meta name="DC.relation" content="US:4536887" scheme="references"><meta name="DC.relation" content="US:4653102" scheme="references"><meta name="DC.relation" content="US:4802227" scheme="references"><meta name="DC.relation" content="US:4956867" scheme="references"><meta name="DC.relation" content="US:5267320" scheme="references"><meta name="citation_reference" content="European Search Report dated Feb. 21, 1995, corresponding European Patent Application 94307855.0."><meta name="citation_reference" content="L. J. Griffiths et al., &quot;An Alternative Approach to Linearly Constrained Adaptive Beamforming,&quot; IEEE Trans. Antennas Propag., vol. AP-30, 27-34 (Jan. 1982)."><meta name="citation_reference" content="L. J. Griffiths et al., An Alternative Approach to Linearly Constrained Adaptive Beamforming, IEEE Trans. Antennas Propag., vol. AP 30, 27 34 (Jan. 1982)."><meta name="citation_reference" content="L. J. Griffiths, &quot;A Simple Adaptive Algorithm for Real-Time Processing in Antenna Arrays,&quot; Proc. IEEE, vol. 57, 1696-1704 (Oct. 1969)."><meta name="citation_reference" content="L. J. Griffiths, A Simple Adaptive Algorithm for Real Time Processing in Antenna Arrays, Proc. IEEE, vol. 57, 1696 1704 (Oct. 1969)."><meta name="citation_reference" content="O. L. Frost III, &quot;An Algorithm for Linearly Constrained Adaptive Array Processing,&quot; Proc. IEEE, vol. 60, 926-935 (Aug. 1972)."><meta name="citation_reference" content="O. L. Frost III, An Algorithm for Linearly Constrained Adaptive Array Processing, Proc. IEEE, vol. 60, 926 935 (Aug. 1972)."><meta name="citation_patent_number" content="US:5473701"><meta name="citation_patent_application_number" content="US:08/148,750"><link rel="canonical" href="http://www.google.com/patents/US5473701"/><meta property="og:url" content="http://www.google.com/patents/US5473701"/><meta name="title" content="Patent US5473701 - Adaptive microphone array"/><meta name="description" content="The present invention is directed to a method of apparatus of enhancing the signal-to-noise ratio of a microphone array. The array includes a plurality of microphones and has a directivity pattern which is adjustable based on one or more parameters. The parameters are evaluated so as to realize an angular orientation of a directivity pattern null. This angular orientation of the directivity pattern null reduces microphone array output signal level. Parameter evaluation is performed under a constraint that the null be located within a predetermined region of space. Advantageously, the predetermined region of space is a region from which undesired acoustic energy is expected to impinge upon the array, and the angular orientation of a directivity pattern null substantially aligns with the angular orientation of undesired acoustic energy. Output signals of the array microphones are modified based on one or more evaluated parameters. An array output signal is formed based on modified and unmodified microphone output signals. The evaluation of parameters, the modification of output signals, and the formation of an array output signal may be performed a plurality of times to obtain an adaptive army response. Embodiments of the invention include those having a plurality of directivity patterns corresponding to a plurality of frequency subbands. Illustratively, the array may comprise a plurality of cardioid sensors."/><meta property="og:title" content="Patent US5473701 - Adaptive microphone array"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("V5vtU--BGsmIogT184LYAg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("JPN"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("V5vtU--BGsmIogT184LYAg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("JPN"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5473701?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5473701"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=BsU9BAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5473701&amp;usg=AFQjCNGRdU-cf0jhgcufSbpBRqR9dSB26Q" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5473701.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5473701.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5473701" style="display:none"><span itemprop="description">The present invention is directed to a method of apparatus of enhancing the signal-to-noise ratio of a microphone array. The array includes a plurality of microphones and has a directivity pattern which is adjustable based on one or more parameters. The parameters are evaluated so as to realize an angular...</span><span itemprop="url">http://www.google.com/patents/US5473701?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5473701 - Adaptive microphone array</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5473701 - Adaptive microphone array" title="Patent US5473701 - Adaptive microphone array"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5473701 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/148,750</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Dec 5, 1995</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Nov 5, 1993</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Nov 5, 1993</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2117931A1">CA2117931A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2117931C">CA2117931C</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE69431179D1">DE69431179D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE69431179T2">DE69431179T2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0652686A1">EP0652686A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0652686B1">EP0652686B1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08148750, </span><span class="patent-bibdata-value">148750, </span><span class="patent-bibdata-value">US 5473701 A, </span><span class="patent-bibdata-value">US 5473701A, </span><span class="patent-bibdata-value">US-A-5473701, </span><span class="patent-bibdata-value">US5473701 A, </span><span class="patent-bibdata-value">US5473701A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Juergen+Cezanne%22">Juergen Cezanne</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Gary+W.+Elko%22">Gary W. Elko</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22At%26T+Corp.%22">At&T Corp.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5473701.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5473701.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5473701.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (6),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (7),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (117),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (9),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (16)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5473701&usg=AFQjCNEmAc3basD2RUh9d_fOzKP1vdX71A">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5473701&usg=AFQjCNEnjjyWQmByLctDDtqHHn1QGY59RA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5473701A%26KC%3DA%26FT%3DD&usg=AFQjCNFGH-vccnC5peOe8sdxRtp5FKlAdQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54009072" lang="EN" load-source="patent-office">Adaptive microphone array</invention-title></span><br><span class="patent-number">US 5473701 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37482788" lang="EN" load-source="patent-office"> <div class="abstract">The present invention is directed to a method of apparatus of enhancing the signal-to-noise ratio of a microphone array. The array includes a plurality of microphones and has a directivity pattern which is adjustable based on one or more parameters. The parameters are evaluated so as to realize an angular orientation of a directivity pattern null. This angular orientation of the directivity pattern null reduces microphone array output signal level. Parameter evaluation is performed under a constraint that the null be located within a predetermined region of space. Advantageously, the predetermined region of space is a region from which undesired acoustic energy is expected to impinge upon the array, and the angular orientation of a directivity pattern null substantially aligns with the angular orientation of undesired acoustic energy. Output signals of the array microphones are modified based on one or more evaluated parameters. An array output signal is formed based on modified and unmodified microphone output signals. The evaluation of parameters, the modification of output signals, and the formation of an array output signal may be performed a plurality of times to obtain an adaptive army response. Embodiments of the invention include those having a plurality of directivity patterns corresponding to a plurality of frequency subbands. Illustratively, the array may comprise a plurality of cardioid sensors.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(6)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5473701-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5473701-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5473701-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5473701-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5473701-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5473701-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5473701-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5473701-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5473701-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5473701-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5473701-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5473701-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(23)</span></span></div><div class="patent-text"><div mxw-id="PCLM4917706" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>We claim:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A method of enhancing the signal-to-noise ratio of a microphone array, the array including a plurality of microphones and having a directivity pattern, the directivity pattern of the array being adjustable based on one or more parameters, the method comprising the steps of:<div class="claim-text">a. evaluating one or more parameters to realize an angular orientation of a directivity pattern null, which angular orientation reduces microphone array output signal level in accordance with a criterion, said evaluation performed under a constraint that the null be precluded from being located within a predetermined region of space which comprises a range of directions about the array, which range reflects a predetermined directional variability of the desired acoustic energy with respect to the array;</div> <div class="claim-text">b. modifying output signals of one or more microphones of the array based on the one or more evaluated parameters; and</div> <div class="claim-text">c. forming an array output signal based on one or more modified output signals and zero or more unmodified microphone output signals.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The method of claim 1 wherein steps a, b, and c, are performed a plurality of times to obtain an adaptive array response.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The method of claim 1 wherein a region of space other than the predetermined region of space includes sources of undesired acoustic energy.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The method of claim 1 wherein undesired acoustic energy impinges on the array from a direction within a region of space other than the predetermined region of space.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The method of claim 1 wherein the array has a plurality of directivity patterns corresponding to a plurality of frequency subbands, one or more of the plurality of directivity patterns including a null.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The method of claim 5 further comprising the step of forming a plurality of subband microphone output signals based on an output signal of a microphone of the array, wherein the step of modifying output signals comprises modifying the subband microphone output signals based on the one or more evaluated parameters.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The method of claim 1 wherein the array comprises a plurality of cardioid sensors.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The method of claim 7 wherein the plurality of cardioid sensors comprises a foreground cardioid sensor and a background cardioid sensor and wherein the step of evaluating comprises determining a parameter reflecting a ratio of (i) a product of output signals of the foreground and background cardioid sensors to (ii) the square of the output signal of the background cardioid sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The method of claim 7 wherein the plurality of cardioid sensors comprises a foreground cardioid sensor and a background cardioid sensor and wherein the step of evaluating comprises determining a scale factor for an output signal of the background cardioid sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The method of claim 9 wherein the scale factor is determined based on an output signal of the background cardioid sensor and the array output signal.</div>
    </div>
    </div> <div class="claim"> <div num="11" class="claim">
      <div class="claim-text">11. An apparatus for enhancing the signal-to-noise ratio of a microphone array, the array including a plurality of microphones and having a directivity pattern, the directivity pattern of the array being adjustable based on one or more parameters, the apparatus comprising:<div class="claim-text">a. means for evaluating one or more parameters to realize an angular orientation of a directivity pattern null, which angular orientation reduces microphone array output signal level in accordance with a criterion, said evaluation performed under a constraint that the null be precluded from being located within a predetermined region of space which comprises a range of directions about the array which range reflects a predetermined directional variability of the desired acoustic energy with respect to the array;</div> <div class="claim-text">b. means for modifying output signals of one or more microphones of the array based on the one or more evaluated parameters; and</div> <div class="claim-text">c. means for forming an array output signal based on one or more modified output signals and zero or more unmodified microphone output signals.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The apparatus of claim 11 wherein a region of space other than the predetermined region of space includes sources of undesired acoustic energy.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The apparatus of claim 11 wherein undesired acoustic energy impinges on the array from a direction within a region of space other than the predetermined region of space.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The apparatus of claim 11 wherein the array has a plurality of directivity patterns corresponding to a plurality of frequency subbands, one or more of the plurality of directivity patterns including a null.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. The apparatus of claim 14 further comprising means for forming a plurality of subband microphone output signals based on an output signal of a microphone of the array, wherein the means for modifying output signals comprises means for modifying the subband microphone output signals based on the one or more evaluated parameters.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The apparatus of claim 14 wherein the means for evaluating comprises a polyphase filterbank.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The apparatus of claim 11 wherein the means for modifying comprises a means for performing fast convolution.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. The apparatus of claim 11 wherein the array comprises a plurality of cardioid sensors.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The apparatus of claim 18 wherein the plurality of cardioid sensors comprises a foreground cardioid sensor and a background cardioid sensor and wherein the means for evaluating comprises means for determining a parameter reflecting a ratio of a (i) product of output signals of the foreground and background cardioid sensors to (ii) the square of the output signal of the background cardioid sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The apparatus of claim 18 wherein the plurality of cardioid sensors comprises a foreground cardioid sensor and a background cardioid sensor and wherein the means for evaluating comprises means for determining a scale factor for an output signal of the background cardioid sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. The apparatus of claim 18 wherein the scale factor is determined based on an output signal of the background cardioid sensor and the array output signal.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22. The apparatus of claim 11 wherein the array comprises a cardioid sensor and a dipole sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. The apparatus of claim 11 wherein the array comprises a omnidirectional sensor and a dipole sensor.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES66735176" lang="EN" load-source="patent-office" class="description">
    <heading>FIELD OF THE INVENTION</heading> <p>This invention relates to microphone arrays which employ directionality characteristics to differentiate between sources of noise and desired sound sources.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>Wireless communication devices, such as cellular telephones and other personal communication devices, enjoy widespread use. Because of their portability, such devices are finding use in very noisy environments. Users of such wireless communication devices often find that unwanted noise seriously detracts from clear communication of their own speech. A person with whom the wireless system user speaks often has a difficult time hearing the user's speech over the noise.</p>
    <p>Wireless devices are not the only communication systems exposed to unwanted noise. For example, video teleconferencing systems and multimedia computer communication systems suffer similar problems. In the cases of these systems, noise within the conference room or office in which such systems sit detract from the quality of communicated speech. Such noise may be due to electric equipment noise (e.g., cooling fan noise), conversations of others, etc.</p>
    <p>Directional microphone arrays have been used to combat the problems of noise in communication systems. Such arrays exhibit varying sensitivity to sources of noise as a function of source angle. This varying sensitivity is referred to as a directivity pattern. Low or reduced array sensitivity at a given source angle (or range of angles) is referred to a directivity pattern null. Directional sensitivity of an array is advantageously focused on desired acoustic signals and ignores, in large part, undesirable noise signals.</p>
    <p>While conventional directional arrays provide a desirable level of noise rejection, they may be of limited usefulness in situations where noise sources move in relation to the array.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention provides a technique for adaptively adjusting the directivity of a microphone array to reduce (for example, to minimize) the sensitivity of the array to background noise.</p>
    <p>In accordance with the present invention, the signal-to-noise ratio of a microphone array is enhanced by orienting a null of a directivity pattern of the array in such a way as to reduce microphone array output signal level. Null orientation is constrained to a predetermined region of space adjacent to the array. Advantageously, the predetermined region of space is a region from which undesired acoustic energy is expected to impinge upon the array. Directivity pattern (and thus null) orientation is adjustable based on one or more parameters. These one or more parameters are evaluated under the constraint to realize the desired orientation. The output signals of one or more microphones of the array are modified based on these to evaluated parameters and the modified output signals are used in forming an array output signal.</p>
    <p>An illustrative embodiment of the invention includes an array having a plurality of microphones. The directivity pattern of the array (i.e., the angular sensitivity of the array) may be adjusted by varying one or more parameters. According to the embodiment, the signal-to-noise ratio of the array is enhanced by evaluating the one or more parameters which correspond to advantageous angular orientations of one or more directivity pattern nulls. The advantageous orientations comprise a substantial alignment of the nulls with sources of noise to reduce microphone array output signal level due to noise. The evaluation of parameters is performed under a constraint that the orientation of the nulls be restricted to a predetermined angular region of space termed the background. The one or more evaluated parameters are used to modify output signals of one or more microphones of the array to realize null orientations which reduce noise sensitivity. An array output signal is formed based on one or more modified output signals and zero or more unmodified microphone output signals.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIGS. 1(a)-1(c) present three representations of illustrative background and foreground configurations.</p>
    <p>FIG. 2 presents an illustrative sensitivity pattern of an array in accordance with the present invention.</p>
    <p>FIG. 3 presents an illustrative embodiment of the present invention.</p>
    <p>FIG. 4 presents a flow diagram of software for implementing a third embodiment of the present invention.</p>
    <p>FIG. 5 presents a third illustrative embodiment of the present invention.</p>
    <p>FIGS. 6(a) and 6(b) present analog circuitry for implementing β saturation of the embodiment of FIG. 5 and its input/output characteristic, respectively.</p>
    <p>FIG. 7 presents a fourth illustrative embodiment of the present invention.</p>
    <p>FIG. 8 presents a polyphase filterbank implementation of a β computer presented in FIG. 7.</p>
    <p>FIG. 9 presents an illustrative window of coefficients for use by the windowing processor presented in FIG. 8.</p>
    <p>FIG. 10 presents a fast convolutional procedure implementing a filterbank and scaling and summing circuits presented in FIG. 7.</p>
    <p>FIG. 11 presents a fifth illustrative embodiment of the present invention.</p>
    <p>FIG. 12 presents a sixth illustrative embodiment of the present invention.</p>
    <heading>DETAILED DESCRIPTION</heading> <p>A. Introduction</p>
    <p>Each illustrative embodiment discussed below comprises a microphone array which exhibits differing sensitivity to sound depending on the direction from which such sound impinges upon the array. For example, for undesired sound impinging upon the array from a selected angular region of space termed the background, the embodiments provide adaptive attenuation of array response to such sound impinging on the array. Such adaptive attenuation is provided by adaptively orienting one or more directivity pattern nulls to substantially align with the angular orientation(s) from which undesired sound impinges upon the array. This adaptive orientation is performed under a constraint that angular orientation of the null(s) be limited to the predetermined background.</p>
    <p>For sound not impinging upon the array from an angular orientation within the background region, the embodiments provide substantially unattenuated sensitivity. The region of space not the background is termed the foreground. Because of the difference between array response to sound in the background and foreground, it is advantageous to physically orient the array such that desired sound impinges on the array from the foreground while undesired sound impinges on the array from the background.</p>
    <p>FIG. 1 presents three representations of illustrative background and foreground configurations in two dimensions. In FIG. 1(a), the foreground is defined by the shaded angular region -45°&lt;θ&lt;45°. The letter "A" indicates the position of the array (i.e., at the origin), the letter "x" indicates the position of the desired source, and letter "y" indicates the position of the undesired noise source. In FIG. 1(b), the foreground is defined by the angular region -90°&lt;θ&lt;90°. In FIG. 1(c), the foreground is defined by the angular region -160°&lt;θ&lt;120°. The foreground/background combination of FIG. 1(b) is used with the illustrative embodiments discussed below. As such, the embodiments are sensitive to desired sound from the angular region -90°&lt;θ&lt;90° (foreground) and can adaptively place nulls within the region 90°&lt;θ&lt;270° to mitigate the effects of noise from this region (background).</p>
    <p>FIG. 2 presents an illustrative directivity pattern of an array shown in two-dimensions in accordance with the present invention. The sensitivity pattern is superimposed on the foreground/background configuration of FIG. 2(b). As shown in FIG. 2, array A has a substantially uniform sensitivity (as a function of θ) in the foreground region to the desired source of sound DS. In the background region, however, the sensitivity pattern exhibits a null at approximately 180°±45°, which is substantially coincident with the two-dimensional angular position of the noise source NS. Because of this substantial coincidence, the noise source NS contributes less to the array output relative to other sources not aligned with the null. The illustrative embodiments of the present invention automatically adjust their directivity patterns to locate pattern nulls in angular orientations to mitigate the effect of noise on array output. This adjustment is made under the constraint that the nulls be limited to the background region of space adjacent to the array. This constraint prevents the nulls from migrating into the foreground and substantially affecting the response of the array to desired sound.</p>
    <p>As stated above, FIG. 2 presents a directivity pattern in two-dimensions. This two-dimensional perspective is a projection of a three-dimensional directivity pattern onto a plane in which the array A lies. Thus, the sources DS and NS may lie in the plane itself or may have two-dimensional projections onto the plane as shown. Also, the illustrative directivity pattern null is shown as a two-dimensional projection. The three-dimensional directivity pattern may be envisioned as a three-dimensional surface obtained by rotating the two-dimensional pattern projection about the 0°-180° axis. In three dimensions, the illustrative null may be envisioned as a cone with the given angular orientation, 180°±45°. While directivity patterns are presented in two-dimensional space, it will be readily apparent to those of skill in the art that the present invention is generally applicable to three-dimensional arrangements of arrays, directivity patterns, and desired and undesired sources.</p>
    <p>In the context of the present invention, there is no requirement that desired sources be located in the foreground or that undesired sources be located in the background. For example, as stated above the present invention has applicability to situations where desired acoustic energy impinges upon the array A from any direction within the foreground region (regardless of the location of the desired source(s)) and where undesired acoustic energy impinges on the array from any direction within the background region (regardless of the location of the undesired source(s)). Such situations may be caused by, e.g., reflections of acoustic energy (for example, a noise source not itself in the background may radiate acoustic energy which, due to reflection, impinges upon the array from some direction within the background). The present invention has applicability to still other situations where, e.g., both the desired source and the undesired source are located in the background (or the foreground). Embodiments of the invention would still adapt null position (constrained to the background) to reduce array output. Such possible configurations and situations notwithstanding, the illustrative embodiments of the present invention are presented in the context of desired sources located in the foreground and undesired sources located in the background for purposes of inventive concept presentation clarity.</p>
    <p>The illustrative embodiments of the present invention are presented as comprising individual functional blocks (including functional blocks labeled as "processors") to aid in clarifying the explanation of the invention. The functions these blocks represent may be provided through the use of either shared or dedicated hardware, including, but not limited to, hardware capable of executing software. For example, the functions of blocks presented in FIGS. 3, 7, 8, 10, 11 and 12 may be provided by a single shared processor. (Use of the term "processor" should not be construed to refer exclusively to hardware capable of executing software.)</p>
    <p>Illustrative embodiments may comprise digital signal processor (DSP) hardware, such as the AT&amp;T DSP16 or DSP32C, read-only memory (ROM) for storing software performing the operations discussed below, and random access memory (RAM) for storing DSP results. Very large scale integration (VLSI) hardware embodiments, as well as custom VLSI circuitry in combination with a general purpose DSP circuit, may also be provided.</p>
    <p>B. A First Illustrative Embodiment</p>
    <p>FIG. 3 presents an illustrative embodiment of the present invention. In this embodiment, a microphone array is formed from back-to-back cardioid sensors. Each cardioid sensor is formed by a differential arrangement of two omnidirectional microphones. The microphone array receives a plane-wave acoustic signal, s(t), incident to the array at angle θ.</p>
    <p>As shown in the Figure, the embodiment comprises a pair of omnidirectional microphones 10, 12 separated by a distance, d. The microphones of the embodiment are Bruel &amp; Kjaer Model 4183 microphones. Distance d is 1.5 cm. Each microphone 10, 12 is coupled to a preamplifier 14,16, respectively. Preamplifier 14, 16 provides 40 dB of gain to the microphone output signal.</p>
    <p>The output of each preamplifier 14, 16 is provided to a conventional analog-to-digital (A/D) converter 20, 25. The A/D converters 20,25 convert analog microphone output signals into digital signals for use in the balance of the embodiment. The sampling rate employed by the A/D converters 20, 25 is 22.05 kHz.</p>
    <p>Delay lines 30, 25 introduce signal delays needed to form the cardioid sensors of the embodiment. Subtraction circuit 40 forms the back cardioid output signal, c<sub>B</sub> (t), by subtracting a delayed output of microphone 12 from an undelayed output of microphone 10. Subtraction circuit 45 forms the front cardioid output signal, c<sub>F</sub> (t), by subtracting a delayed output of microphone 10 from an undelayed output of microphone 12.</p>
    <p>As stated above, the sampling rate of the A/D converters 20, 25 is 22.05 kHz. This rate allows advantageous formation of back-to-back cardioid sensors by appropriately subtracting present samples from previous samples. By setting the sampling period of the A/D converters to d/c, where d is the distance between the omni-directional microphones and c is the speed of sound, successive signal samples needed to form each cardioid sensor are obtained from the successive samples from the A/D converter.</p>
    <p>The output signals from the subtraction circuits 40, 45 are provided to β processor 50. β processor 50 computes a gain β for application to signal c<sub>B</sub> (t) by amplifier 55. The scaled signal, βc<sub>B</sub> (t), is then subtracted from front cardioid output signal, c<sub>F</sub> (t), by subtraction circuit 60 to form array output signal, y(t).</p>
    <p>Output signal y(t) is then filtered by lowpass filter 65. Lowpass filter 65 has a 5 kHz cutoff frequency. Lowpass filter 65 is used to attenuate signals that are above the highest design frequency for the array.</p>
    <p>The forward and backward facing cardioid sensors may be described mathematically with a frequency domain representation as follows: ##EQU1## and the spatial origin is at the array center. Normalizing the array output signal by the input signal spectrum, S(ω), results in the following expression: ##EQU2## C. Determination of β</p>
    <p>As shown in FIG. 3, the illustrative embodiment of the present invention includes a β processor 50 for determining the scale factor β used in adjusting the directivity pattern of the array. To allow the array to advantageously differentiate between desired foreground sources of acoustic energy and undesirable background noise sources, directivity pattern nulls are constrained to be within a defined spatial region. In the illustrative embodiment, the desired source of sound is radiating in the front half-plane of the array (that is, the foreground is defined by -90&lt;θ&lt;90). The undesired noise source is radiating in the rear half-plane of the array (that is, the background is defined by 90&lt;θ&lt;270). β processor 50 first computes a value for β and then constrains β to be 0&lt;β&lt;1 which effectuates a limitation on the placement of a directivity pattern null to be in the rear half-plane. For the first illustrative embodiment, θ<sub>null</sub>, the angular orientation of a directivity pattern null, is related to β as follows: ##EQU3## Note that for β=1, θ<sub>null</sub> =90° and for β=0, θ<sub>null</sub> =180°.</p>
    <p>A value for β is computed by β processor 50 according to any of the following illustrative relationships.</p>
    <p>1. Optimum β</p>
    <p>The optimum value of β is defined as that value of β which minimizes the mean square value of the array output. The output signal of the illustrative back-to-back cardioid embodiment is:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">y(n)=c<sub>F</sub> (n)-βc<sub>B</sub> (n).                        (5)</pre>
    
    <p>The value of β determined by processor 50 which minimizes array output is: ##EQU4## This result for optimum β is a finite time estimate of the optimum Wiener filter for a filter of length one.</p>
    <p>2. Updating β with LMS Adaptation</p>
    <p>Values for β may be obtained using a least mean squares (LMS) adaptive scheme. Given the output expression for the back-to-back cardioid array of FIG. 3,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">y(n)=c<sub>F</sub> (n)-βc<sub>B</sub> (n)                         (7)</pre>
    
    <p>the LMS update expression for β is</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">β(n+1)=β(n)+2μy(n)c<sub>B</sub> (n),                (8)</pre>
    
    <p>where μ is the update step-size (μ&lt;1; the larger the μ the faster the convergence). The LMS update may be modified to include a normalized update step-size so that explicit convergence bounds for μ may be independent of the input power. The LMS update of β with a normalized μ is: ##EQU5## where the brackets indicate a time average, and where if &lt;c<sub>B</sub> <sup>2</sup> (n)&gt; is close to zero, the quotient is not formed and μ is set to zero.</p>
    <p>3. Updating β with Newton's Technique</p>
    <p>Newton's technique is a special case of LMS where μ is a function of the input. The update expression for β is: ##EQU6## where c<sub>B</sub> (n) is not equal to zero. The noise sensitivity of this system may be reduced by introducing a constant multiplier 0≦μ≦1 to the update term, y(n)/c<sub>B</sub> (n).</p>
    <p>D. A Software Implementation of the First Embodiment</p>
    <p>While the illustrative embodiment presented above may be implemented largely in hardware as described, the embodiment may be implemented in software running on a DSP, such as the AT&amp;T DSP32C, as stated above. FIG. 4 presents a flow diagram of software for implementing a second illustrative embodiment of the present invention for optimum β.</p>
    <p>According to step 110 of FIG. 4, the first task for the DSP is to acquire from each channel (i.e., from each A/D converter associated with a microphone) a sample of the microphone signals. These acquired samples (one for each channel) are current samples at time n. These sample are buffered into memory for present and future use (see step 115). Microphone samples previously buffered at time n-1 are made available from buffer memory. Thus, the buffer memory serves as the delay utilized for forming the cardioid sensors.</p>
    <p>Next, both the front and back cardioid output signal samples are formed (see step 120). The front cardioid sensor signal sample, c<sub>F</sub> (n), is formed by subtracting a delayed sample (valid at time n-1) from the back microphone (via a buffer memory) from a current sample (valid at time n) from the front microphone. The back cardioid sensor signal sample, c<sub>B</sub> (n), is formed by subtracting a delayed sample (valid at time n-1) from the front microphone (via a buffer memory) from a current sample (valid at time n) from the back microphone.</p>
    <p>The operations prefatory to the computation of scale factor β are performed at steps 125 and 130. Signals c<sub>B</sub> <sup>2</sup> (n) and c<sub>F</sub> (n)c<sub>B</sub> (n) are first computed (step 125). Each of these signals is then averaged over a block of N samples, where N is illustratively 1,000 samples (step 130). The size of N affects the speed of null adaptation to moving sources of noise. Small values of N can lead to null adaptation jitter, while large values of N can lead to slow adaptation rates. Advantageously, N, should be chosen as large as possible while maintaining sufficient null tracking speed for the given application.</p>
    <p>At step 135, the block average of the cross-product of back and front cardioid sensor signals is divided by the block average of the square of the back cardioid sensor signal. The result is the ratio, β, as described in expression (6). The value of β is then constrained to be within the range of zero and one. This constraint is accomplished by setting β=1 if β is calculated to be a number greater than one, and setting β=0 if β is calculated to be a number less than zero. By constraining β in this way, the null of the array is constrained to be in the rear half-plane of the array's sensitivity pattern.</p>
    <p>The output sample of the array, y(n), is formed (step 140) in two steps. First, the back cardioid signal sample is scaled by the computed and constrained (if necessary) value of β. Second, the scaled back cardioid signal sample is subtracted from the front cardioid signal sample.</p>
    <p>Output signal y(n) is then filtered (step 145) by a lowpass filter having a 5 kHz cutoff frequency. As stated above, the lowpass filter is used to attenuate signals that are above the highest design frequency for the array. The filtered output signal is then provided to a D/A converter (step 150) for use by conventional analog devices. The software process continues (step 155) if there is a further input sample from the A/D converters to process. Otherwise, the process ends.</p>
    <p>E. An Illustrative Analog Embodiment</p>
    <p>The present invention may be implemented with analog components. FIG. 5 presents such an illustrative implementation comprising conventional analog multipliers 510, 530, 540, an analog integrator 550, an analog summer 520, and a non-inverting amplifier circuit 560 shown in FIG. 6(a) having input/output characteristic shown in FIG. 6(b) (wherein the saturation voltage V<sub>L</sub> =β is set by the user to define the foreground/background relationship). Voltage V<sub>L</sub> is controlled by a potentiometer setting as shown. The circuit of FIG. 5 operates in accordance with continuous-time versions of equations (7) and (8), wherein β is determined in an LMS fashion.</p>
    <p>F. A Fourth Illustrative Embodiment</p>
    <p>A fourth illustrative embodiment of the present invention is directed to a subband implementation of the invention. The embodiment may be advantageously employed in situations where there are multiple noise sources radiating acoustic energy at different frequencies. According to the embodiment, each subband has its own directivity pattern including a null. The embodiment computes a value for β (or a related parameter) on a subband-by-subband basis. Parameters are evaluated to provide an angular orientation of a given subband null. This orientation helps reduce microphone array output level by reducing the array response to noise in a given subband. The nulls of the individual subbands are not generally coincident, since noise sources (which provide acoustic noise energy at differing frequencies) may be located in different angular directions. However there is no reason why two or more subband nulls cannot be substantially coincident.</p>
    <p>The fourth illustrative embodiment of the present invention is presented in FIG. 7. The embodiment is identical to that of FIG. 3 insofar as the microphones 10, 12, preamplifiers 14, 16, A/D converters 20, 25, and delays 30, 35 are concerned. These components are not repeated in FIG. 7 so as to clarify the presentation of the embodiment. However, subtraction circuits 40, 45 are shown for purposes of orienting the reader with the similarity of this fourth embodiment to that of FIG. 3.</p>
    <p>As shown in the Figure, the back cardioid sensor output signal, c<sub>B</sub> (n), is provided to a β-processor 220 as well as a filterbank 215. Filterbank 215 resolves the signal c<sub>B</sub> (n) into M/2+1 subband component signals. Each subband component signal is scaled by a subband version of β. The scaled subband component signals are then summed by summing circuit 230. The output signal of summing circuit 230 is then subtracted from a delayed version of the front cardioid sensor output signal, c<sub>F</sub> (n), to form array output signal, y(n). Illustratively, M=32. The delay line 210 is chosen to realize a delay commensurate with the processing delay of the branch of the embodiment concerned with the back cardioid output signal, c<sub>B</sub> (n).</p>
    <p>The β-processor 220 of FIG. 7 comprises a polyphase filterbank as illustrated in FIG. 8.</p>
    <p>As shown in FIG. 8, the back cardioid sensor output signal, c<sub>B</sub> (n), is applied to windowing processor 410. Windowing processor applies a window of coefficients presented in FIG. 9 to incoming samples of c<sub>B</sub> (n) to form the M output signals, p<sub>m</sub> (n), shown in FIG. 8. Windowing processor 410 comprises a buffer for storing 2M-1 samples of c<sub>B</sub> (n), a read-only memory for storing window coefficients, w(n), and a processor for forming the products/sums of coefficients and signals. Windowing processor 410 generates signals p<sub>m</sub> (n) according to the following relationships:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>0</sub> (n)=c<sub>B</sub> (n-M)w(0)</pre>
    
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>1</sub> (n)=c<sub>B</sub> (n-1)w(-M+1)+c<sub>B</sub> (n-M-1)w(1)</pre>
    
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>2</sub> (n)=c<sub>B</sub> (n-2)w(-M+2)+c<sub>B</sub> (n-M-2)w(2)</pre>
    
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">p<sub>M-1</sub> (n)=c<sub>B</sub> (n-M+1)w(-1)+c<sub>B</sub> (n-2M+1)w(m-1). (11)</pre>
    
    <p>The output signals of windowing processor 410, p<sub>m</sub> (n), are applied to Fast Fourier Transform (FFT) processor 420. Processor 420 takes a conventional M-point FFT based on the M signals p<sub>m</sub> (n). What results are M FFT signals. Of these signals, two are real valued signals and are labeled as v<sub>0</sub> (n) and v<sub>M/2</sub> (n). Each of the balance of the signals is complex. Real valued signals, v<sub>1</sub> (n) through v<sub>M/2-1</sub> (n) are formed by the sum of an FFT signal and its complex conjugate, as shown in the FIG. 8.</p>
    <p>Real-valued signals v<sub>0</sub> (n), . . . , v<sub>M/2</sub> (n) are provided to β-update processor 430. β-update processor 430 updates values of β for each subband according to the following relation: ##EQU7## where μ is the update stepsize, illustratively 0.1 (however, μ may be set equal to zero and the quotient not formed when the denominator of (12) is close to zero). The updated value of β<sub>m</sub> (n) is then saturated as discussed above. That is, for 0&lt;m&lt;M/2, ##EQU8## Advantageously, the computations described by expressions (11) through (13) are performed once every M samples to reduce computational load.</p>
    <p>Those components which appear in the filterbank 215 and scaling and summing section 212 of FIG. 7 may be realized by a fast convolution technique illustrated by the block diagram of FIG. 10.</p>
    <p>As shown in FIG. 10, β-processor provides the subband values of β to β-to-γ processor 320. β-to-γ processor 320 generates 4M fast convolution coefficients, γ, which are equivalent to the set of β coefficients from processor 430. The γ coefficients are generated by (i) computing an impulse response (of length 2M-1) of the filter which is block 212 (of FIG. 7) as a function of the values of β and (ii) computing the Fast Fourier Transform (FFT) (of size 4M) of the computed impulse response. The computed FFT coefficients are the 4M γ's. (Alternatively, due to the symmetry of the window used in the computation of the subband β values, there is a symmetry in the values of the γ coefficients which can be exploited to reduce the size of the FFT to 2M.)</p>
    <p>The 4M γ coefficients are applied to a frequency domain representation of the back cardioid sensor signal, c<sub>B</sub> (n). This frequency domain representation is provided by FFT processor 310 which performs a 4M FFT. The 4M γ coefficients are used to scale the 4M FFT coefficients as shown in FIG. 10. The scaled FFT coefficients are then processed by FFT<sup>-1</sup> processor 330. The output of FFT<sup>-1</sup> processor 330 (and block 212) is then provided to the summing circuit 235 for subtraction from the delayed c<sub>F</sub> (n) signal (as shown in FIG. 7). The size of the FFT and FFT<sup>-1</sup> may also be reduced by exploiting the symmetry of the γ coefficients.</p>
    <p>G. Alternative Embodiments</p>
    <p>While the illustrative embodiments presented above concern back-to-back cardioid sensors, those of ordinary skill in the art will appreciate that other array configurations in accordance with the present invention are possible. One such array configuration comprises a combination of an omnidirectional sensor and a dipole sensor to form an adaptive first order differential microphone array. Such a combination is presented in FIG. 11. β is updated according to the following expression:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">β(n+1)=β(n)+2μy(n)(d(n)+o(n)).                (14)</pre>
    
    <p>Another such array configuration comprises a combination of a dipole sensor and a cardioid sensor to again form an adaptive first order differential microphone array. Such a combination is presented in FIG. 12. β is updated according to the following expression:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">β(n+1)=β(n)+2μy(n)(d(n)+c(n)).                (15)</pre>
    
    <p>Although a number of specific embodiments of this invention have been shown and described herein, it is to be understood that these embodiments are merely illustrative of the many possible specific arrangements which can be devised in application of the principles of the invention. Numerous and varied other arrangements can be devised in accordance with these principles by those of ordinary skill in the art without departing from the spirit and scope of the invention.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4485484">US4485484</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 28, 1982</td><td class="patent-data-table-td patent-date-value">Nov 27, 1984</td><td class="patent-data-table-td ">At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Signal processing arrangement for reducing audio interference</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4536887">US4536887</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 7, 1983</td><td class="patent-data-table-td patent-date-value">Aug 20, 1985</td><td class="patent-data-table-td ">Nippon Telegraph &amp; Telephone Public Corporation</td><td class="patent-data-table-td ">Microphone-array apparatus and method for extracting desired signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4653102">US4653102</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 5, 1985</td><td class="patent-data-table-td patent-date-value">Mar 24, 1987</td><td class="patent-data-table-td ">Position Orientation Systems</td><td class="patent-data-table-td ">Directional microphone system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4802227">US4802227</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 3, 1987</td><td class="patent-data-table-td patent-date-value">Jan 31, 1989</td><td class="patent-data-table-td ">American Telephone And Telegraph Company</td><td class="patent-data-table-td ">Noise reduction processing arrangement for microphone arrays</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4956867">US4956867</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 20, 1989</td><td class="patent-data-table-td patent-date-value">Sep 11, 1990</td><td class="patent-data-table-td ">Massachusetts Institute Of Technology</td><td class="patent-data-table-td ">Adaptive beamforming for noise reduction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5267320">US5267320</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 12, 1992</td><td class="patent-data-table-td patent-date-value">Nov 30, 1993</td><td class="patent-data-table-td ">Ricoh Company, Ltd.</td><td class="patent-data-table-td ">Noise controller which noise-controls movable point</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">European Search Report dated Feb. 21, 1995, corresponding European Patent Application 94307855.0.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">L. J. Griffiths et al., "<a href='http://scholar.google.com/scholar?q="An+Alternative+Approach+to+Linearly+Constrained+Adaptive+Beamforming%2C"'>An Alternative Approach to Linearly Constrained Adaptive Beamforming,</a>" IEEE Trans. Antennas Propag., vol. AP-30, 27-34 (Jan. 1982).</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">L. J. Griffiths et al., An Alternative Approach to Linearly Constrained Adaptive Beamforming, IEEE Trans. Antennas Propag., vol. AP 30, 27 34 (Jan. 1982).</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">L. J. Griffiths, "<a href='http://scholar.google.com/scholar?q="A+Simple+Adaptive+Algorithm+for+Real-Time+Processing+in+Antenna+Arrays%2C"'>A Simple Adaptive Algorithm for Real-Time Processing in Antenna Arrays,</a>" Proc. IEEE, vol. 57, 1696-1704 (Oct. 1969).</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">L. J. Griffiths, A Simple Adaptive Algorithm for Real Time Processing in Antenna Arrays, Proc. IEEE, vol. 57, 1696 1704 (Oct. 1969).</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">O. L. Frost III, "<a href='http://scholar.google.com/scholar?q="An+Algorithm+for+Linearly+Constrained+Adaptive+Array+Processing%2C"'>An Algorithm for Linearly Constrained Adaptive Array Processing,</a>" Proc. IEEE, vol. 60, 926-935 (Aug. 1972).</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">O. L. Frost III, An Algorithm for Linearly Constrained Adaptive Array Processing, Proc. IEEE, vol. 60, 926 935 (Aug. 1972).</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5647006">US5647006</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 22, 1995</td><td class="patent-data-table-td patent-date-value">Jul 8, 1997</td><td class="patent-data-table-td ">U.S. Philips Corporation</td><td class="patent-data-table-td ">Mobile radio terminal comprising a speech</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5675655">US5675655</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 10, 1995</td><td class="patent-data-table-td patent-date-value">Oct 7, 1997</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Sound input apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5740256">US5740256</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 11, 1996</td><td class="patent-data-table-td patent-date-value">Apr 14, 1998</td><td class="patent-data-table-td ">U.S. Philips Corporation</td><td class="patent-data-table-td ">Adaptive noise cancelling arrangement, a noise reduction system and a transceiver</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5825898">US5825898</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 27, 1996</td><td class="patent-data-table-td patent-date-value">Oct 20, 1998</td><td class="patent-data-table-td ">Lamar Signal Processing Ltd.</td><td class="patent-data-table-td ">System and method for adaptive interference cancelling</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5886656">US5886656</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 24, 1996</td><td class="patent-data-table-td patent-date-value">Mar 23, 1999</td><td class="patent-data-table-td ">Sgs-Thomson Microelectronics, S.R.L.</td><td class="patent-data-table-td ">Digital microphone device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5933807">US5933807</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 15, 1995</td><td class="patent-data-table-td patent-date-value">Aug 3, 1999</td><td class="patent-data-table-td ">Nitsuko Corporation</td><td class="patent-data-table-td ">Screen control apparatus and screen control method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6072881">US6072881</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 9, 1997</td><td class="patent-data-table-td patent-date-value">Jun 6, 2000</td><td class="patent-data-table-td ">Chiefs Voice Incorporated</td><td class="patent-data-table-td ">Microphone noise rejection system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6094150">US6094150</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 6, 1998</td><td class="patent-data-table-td patent-date-value">Jul 25, 2000</td><td class="patent-data-table-td ">Mitsubishi Heavy Industries, Ltd.</td><td class="patent-data-table-td ">System and method of measuring noise of mobile body using a plurality microphones</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6178248">US6178248</a></td><td class="patent-data-table-td patent-date-value">Apr 14, 1997</td><td class="patent-data-table-td patent-date-value">Jan 23, 2001</td><td class="patent-data-table-td ">Andrea Electronics Corporation</td><td class="patent-data-table-td ">Dual-processing interference cancelling system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6222927">US6222927</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 19, 1996</td><td class="patent-data-table-td patent-date-value">Apr 24, 2001</td><td class="patent-data-table-td ">The University Of Illinois</td><td class="patent-data-table-td ">Binaural signal processing system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6430295">US6430295</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 11, 1997</td><td class="patent-data-table-td patent-date-value">Aug 6, 2002</td><td class="patent-data-table-td ">Telefonaktiebolaget Lm Ericsson (Publ)</td><td class="patent-data-table-td ">Methods and apparatus for measuring signal level and delay at multiple sensors</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6449586">US6449586</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 31, 1998</td><td class="patent-data-table-td patent-date-value">Sep 10, 2002</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Control method of adaptive array and adaptive array apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6549586">US6549586</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 12, 1999</td><td class="patent-data-table-td patent-date-value">Apr 15, 2003</td><td class="patent-data-table-td ">Telefonaktiebolaget L M Ericsson</td><td class="patent-data-table-td ">System and method for dual microphone signal noise reduction using spectral subtraction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6584203">US6584203</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 30, 2001</td><td class="patent-data-table-td patent-date-value">Jun 24, 2003</td><td class="patent-data-table-td ">Agere Systems Inc.</td><td class="patent-data-table-td ">Second-order adaptive differential microphone array</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6600824">US6600824</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 26, 2000</td><td class="patent-data-table-td patent-date-value">Jul 29, 2003</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Microphone array system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6603861">US6603861</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 7, 1998</td><td class="patent-data-table-td patent-date-value">Aug 5, 2003</td><td class="patent-data-table-td ">Phonak Ag</td><td class="patent-data-table-td ">Method for electronically beam forming acoustical signals and acoustical sensor apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6717991">US6717991</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 28, 2000</td><td class="patent-data-table-td patent-date-value">Apr 6, 2004</td><td class="patent-data-table-td ">Telefonaktiebolaget Lm Ericsson (Publ)</td><td class="patent-data-table-td ">System and method for dual microphone signal noise reduction using spectral subtraction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6748086">US6748086</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 19, 2000</td><td class="patent-data-table-td patent-date-value">Jun 8, 2004</td><td class="patent-data-table-td ">Lear Corporation</td><td class="patent-data-table-td ">Cabin communication system without acoustic echo cancellation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6836243">US6836243</a></td><td class="patent-data-table-td patent-date-value">Aug 31, 2001</td><td class="patent-data-table-td patent-date-value">Dec 28, 2004</td><td class="patent-data-table-td ">Nokia Corporation</td><td class="patent-data-table-td ">System and method for processing a signal being emitted from a target signal source into a noisy environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6865275">US6865275</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 3, 2000</td><td class="patent-data-table-td patent-date-value">Mar 8, 2005</td><td class="patent-data-table-td ">Phonak Ag</td><td class="patent-data-table-td ">Method to determine the transfer characteristic of a microphone system, and microphone system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6912289">US6912289</a></td><td class="patent-data-table-td patent-date-value">Oct 9, 2003</td><td class="patent-data-table-td patent-date-value">Jun 28, 2005</td><td class="patent-data-table-td ">Unitron Hearing Ltd.</td><td class="patent-data-table-td ">Hearing aid and processes for adaptively processing signals therein</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6950528">US6950528</a></td><td class="patent-data-table-td patent-date-value">Mar 25, 2004</td><td class="patent-data-table-td patent-date-value">Sep 27, 2005</td><td class="patent-data-table-td ">Siemens Audiologische Technik Gmbh</td><td class="patent-data-table-td ">Method and apparatus for suppressing an acoustic interference signal in an incoming audio signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6978159">US6978159</a></td><td class="patent-data-table-td patent-date-value">Mar 13, 2001</td><td class="patent-data-table-td patent-date-value">Dec 20, 2005</td><td class="patent-data-table-td ">Board Of Trustees Of The University Of Illinois</td><td class="patent-data-table-td ">Binaural signal processing using multiple acoustic sensors and digital filtering</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6987856">US6987856</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 16, 1998</td><td class="patent-data-table-td patent-date-value">Jan 17, 2006</td><td class="patent-data-table-td ">Board Of Trustees Of The University Of Illinois</td><td class="patent-data-table-td ">Binaural signal processing techniques</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7010134">US7010134</a></td><td class="patent-data-table-td patent-date-value">Oct 16, 2003</td><td class="patent-data-table-td patent-date-value">Mar 7, 2006</td><td class="patent-data-table-td ">Widex A/S</td><td class="patent-data-table-td ">Hearing aid, a method of controlling a hearing aid, and a noise reduction system for a hearing aid</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7076072">US7076072</a></td><td class="patent-data-table-td patent-date-value">Apr 9, 2003</td><td class="patent-data-table-td patent-date-value">Jul 11, 2006</td><td class="patent-data-table-td ">Board Of Trustees For The University Of Illinois</td><td class="patent-data-table-td ">Systems and methods for interference-suppression with directional sensing patterns</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7123727">US7123727</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2001</td><td class="patent-data-table-td patent-date-value">Oct 17, 2006</td><td class="patent-data-table-td ">Agere Systems Inc.</td><td class="patent-data-table-td ">Adaptive close-talking differential microphone array</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7133530">US7133530</a></td><td class="patent-data-table-td patent-date-value">Feb 2, 2001</td><td class="patent-data-table-td patent-date-value">Nov 7, 2006</td><td class="patent-data-table-td ">Industrial Research Limited</td><td class="patent-data-table-td ">Microphone arrays for high resolution sound field recording</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7212642">US7212642</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 2003</td><td class="patent-data-table-td patent-date-value">May 1, 2007</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">Microphone system with directional response</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7212643">US7212643</a></td><td class="patent-data-table-td patent-date-value">Feb 10, 2004</td><td class="patent-data-table-td patent-date-value">May 1, 2007</td><td class="patent-data-table-td ">Phonak Ag</td><td class="patent-data-table-td ">Real-ear zoom hearing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7274794">US7274794</a></td><td class="patent-data-table-td patent-date-value">Aug 10, 2001</td><td class="patent-data-table-td patent-date-value">Sep 25, 2007</td><td class="patent-data-table-td ">Sonic Innovations, Inc.</td><td class="patent-data-table-td ">Sound processing system including forward filter that exhibits arbitrary directivity and gradient response in single wave sound environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7280627">US7280627</a></td><td class="patent-data-table-td patent-date-value">Dec 8, 2003</td><td class="patent-data-table-td patent-date-value">Oct 9, 2007</td><td class="patent-data-table-td ">The Johns Hopkins University</td><td class="patent-data-table-td ">Constrained data-adaptive signal rejector</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7340068">US7340068</a></td><td class="patent-data-table-td patent-date-value">Feb 19, 2003</td><td class="patent-data-table-td patent-date-value">Mar 4, 2008</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">Device and method for detecting wind noise</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7363334">US7363334</a></td><td class="patent-data-table-td patent-date-value">Aug 28, 2003</td><td class="patent-data-table-td patent-date-value">Apr 22, 2008</td><td class="patent-data-table-td ">Accoutic Processing Technology, Inc.</td><td class="patent-data-table-td ">Digital signal-processing structure and methodology featuring engine-instantiated, wave-digital-filter componentry, and fabrication thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7386135">US7386135</a></td><td class="patent-data-table-td patent-date-value">Jul 26, 2002</td><td class="patent-data-table-td patent-date-value">Jun 10, 2008</td><td class="patent-data-table-td ">Dashen Fan</td><td class="patent-data-table-td ">Cardioid beam with a desired null based acoustic devices, systems and methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7409068">US7409068</a></td><td class="patent-data-table-td patent-date-value">Mar 6, 2003</td><td class="patent-data-table-td patent-date-value">Aug 5, 2008</td><td class="patent-data-table-td ">Sound Design Technologies, Ltd.</td><td class="patent-data-table-td ">Low-noise directional microphone system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7512448">US7512448</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2003</td><td class="patent-data-table-td patent-date-value">Mar 31, 2009</td><td class="patent-data-table-td ">Phonak Ag</td><td class="patent-data-table-td ">Electrode placement for wireless intrabody communication between components of a hearing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7577266">US7577266</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 11, 2006</td><td class="patent-data-table-td patent-date-value">Aug 18, 2009</td><td class="patent-data-table-td ">The Board Of Trustees Of The University Of Illinois</td><td class="patent-data-table-td ">Systems and methods for interference suppression with directional sensing patterns</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7613309">US7613309</a></td><td class="patent-data-table-td patent-date-value">Nov 7, 2002</td><td class="patent-data-table-td patent-date-value">Nov 3, 2009</td><td class="patent-data-table-td ">Carolyn T. Bilger, legal representative</td><td class="patent-data-table-td ">Interference suppression techniques</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7751575">US7751575</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 25, 2003</td><td class="patent-data-table-td patent-date-value">Jul 6, 2010</td><td class="patent-data-table-td ">Baumhauer Jr John C</td><td class="patent-data-table-td ">Microphone system for communication devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7817805">US7817805</a></td><td class="patent-data-table-td patent-date-value">Jan 12, 2005</td><td class="patent-data-table-td patent-date-value">Oct 19, 2010</td><td class="patent-data-table-td ">Motion Computing, Inc.</td><td class="patent-data-table-td ">System and method for steering the directional response of a microphone to a moving acoustic source</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7848529">US7848529</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 11, 2007</td><td class="patent-data-table-td patent-date-value">Dec 7, 2010</td><td class="patent-data-table-td ">Fortemedia, Inc.</td><td class="patent-data-table-td ">Broadside small array microphone beamforming unit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7889873">US7889873</a></td><td class="patent-data-table-td patent-date-value">Jan 27, 2005</td><td class="patent-data-table-td patent-date-value">Feb 15, 2011</td><td class="patent-data-table-td ">Dpa Microphones A/S</td><td class="patent-data-table-td ">Microphone aperture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7929721">US7929721</a></td><td class="patent-data-table-td patent-date-value">Oct 22, 2007</td><td class="patent-data-table-td patent-date-value">Apr 19, 2011</td><td class="patent-data-table-td ">Siemens Audiologische Technik Gmbh</td><td class="patent-data-table-td ">Hearing aid with directional microphone system, and method for operating a hearing aid</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7945064">US7945064</a></td><td class="patent-data-table-td patent-date-value">Apr 9, 2003</td><td class="patent-data-table-td patent-date-value">May 17, 2011</td><td class="patent-data-table-td ">Board Of Trustees Of The University Of Illinois</td><td class="patent-data-table-td ">Intrabody communication with ultrasound</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8019091">US8019091</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 18, 2003</td><td class="patent-data-table-td patent-date-value">Sep 13, 2011</td><td class="patent-data-table-td ">Aliphcom, Inc.</td><td class="patent-data-table-td ">Voice activity detector (VAD) -based multiple-microphone acoustic noise suppression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8019121">US8019121</a></td><td class="patent-data-table-td patent-date-value">Oct 16, 2009</td><td class="patent-data-table-td patent-date-value">Sep 13, 2011</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">Method and system for processing intensity from input devices for interfacing with a computer program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8035629">US8035629</a></td><td class="patent-data-table-td patent-date-value">Dec 1, 2006</td><td class="patent-data-table-td patent-date-value">Oct 11, 2011</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">Hand-held computer interactive device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8072470">US8072470</a></td><td class="patent-data-table-td patent-date-value">May 29, 2003</td><td class="patent-data-table-td patent-date-value">Dec 6, 2011</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">System and method for providing a real-time three-dimensional interactive environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8085339">US8085339</a></td><td class="patent-data-table-td patent-date-value">Dec 23, 2009</td><td class="patent-data-table-td patent-date-value">Dec 27, 2011</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">Method and apparatus for optimizing capture device settings through depth information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8098844">US8098844</a></td><td class="patent-data-table-td patent-date-value">Nov 5, 2006</td><td class="patent-data-table-td patent-date-value">Jan 17, 2012</td><td class="patent-data-table-td ">Mh Acoustics, Llc</td><td class="patent-data-table-td ">Dual-microphone spatial noise suppression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8139787">US8139787</a></td><td class="patent-data-table-td patent-date-value">Sep 8, 2006</td><td class="patent-data-table-td patent-date-value">Mar 20, 2012</td><td class="patent-data-table-td ">Simon Haykin</td><td class="patent-data-table-td ">Method and device for binaural signal enhancement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8142288">US8142288</a></td><td class="patent-data-table-td patent-date-value">May 8, 2009</td><td class="patent-data-table-td patent-date-value">Mar 27, 2012</td><td class="patent-data-table-td ">Sony Computer Entertainment America Llc</td><td class="patent-data-table-td ">Base station movement detection and compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8188968">US8188968</a></td><td class="patent-data-table-td patent-date-value">Dec 21, 2007</td><td class="patent-data-table-td patent-date-value">May 29, 2012</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">Methods for interfacing with a program using a light input device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8238593">US8238593</a></td><td class="patent-data-table-td patent-date-value">Jun 25, 2007</td><td class="patent-data-table-td patent-date-value">Aug 7, 2012</td><td class="patent-data-table-td ">Gn Resound A/S</td><td class="patent-data-table-td ">Hearing instrument with adaptive directional signal processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8249284">US8249284</a></td><td class="patent-data-table-td patent-date-value">Jul 21, 2006</td><td class="patent-data-table-td patent-date-value">Aug 21, 2012</td><td class="patent-data-table-td ">Phonak Ag</td><td class="patent-data-table-td ">Hearing system and method for deriving information on an acoustic scene</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8287373">US8287373</a></td><td class="patent-data-table-td patent-date-value">Apr 17, 2009</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">Control device for communicating visual information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8310656">US8310656</a></td><td class="patent-data-table-td patent-date-value">Sep 28, 2006</td><td class="patent-data-table-td patent-date-value">Nov 13, 2012</td><td class="patent-data-table-td ">Sony Computer Entertainment America Llc</td><td class="patent-data-table-td ">Mapping movements of a hand-held controller to the two-dimensional image plane of a display screen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8313380">US8313380</a></td><td class="patent-data-table-td patent-date-value">May 6, 2006</td><td class="patent-data-table-td patent-date-value">Nov 20, 2012</td><td class="patent-data-table-td ">Sony Computer Entertainment America Llc</td><td class="patent-data-table-td ">Scheme for translating movements of a hand-held controller into inputs for a system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8323106">US8323106</a></td><td class="patent-data-table-td patent-date-value">Jun 24, 2008</td><td class="patent-data-table-td patent-date-value">Dec 4, 2012</td><td class="patent-data-table-td ">Sony Computer Entertainment America Llc</td><td class="patent-data-table-td ">Determination of controller three-dimensional location using image analysis and ultrasonic communication</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8331582">US8331582</a></td><td class="patent-data-table-td patent-date-value">Aug 11, 2004</td><td class="patent-data-table-td patent-date-value">Dec 11, 2012</td><td class="patent-data-table-td ">Wolfson Dynamic Hearing Pty Ltd</td><td class="patent-data-table-td ">Method and apparatus for producing adaptive directional signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8342963">US8342963</a></td><td class="patent-data-table-td patent-date-value">Apr 10, 2009</td><td class="patent-data-table-td patent-date-value">Jan 1, 2013</td><td class="patent-data-table-td ">Sony Computer Entertainment America Inc.</td><td class="patent-data-table-td ">Methods and systems for enabling control of artificial intelligence game characters</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8358789">US8358789</a></td><td class="patent-data-table-td patent-date-value">Nov 4, 2009</td><td class="patent-data-table-td patent-date-value">Jan 22, 2013</td><td class="patent-data-table-td ">Siemens Medical Instruments Pte. Ltd.</td><td class="patent-data-table-td ">Adaptive microphone system for a hearing device and associated operating method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8368753">US8368753</a></td><td class="patent-data-table-td patent-date-value">Mar 17, 2008</td><td class="patent-data-table-td patent-date-value">Feb 5, 2013</td><td class="patent-data-table-td ">Sony Computer Entertainment America Llc</td><td class="patent-data-table-td ">Controller with an integrated depth camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8393964">US8393964</a></td><td class="patent-data-table-td patent-date-value">May 8, 2009</td><td class="patent-data-table-td patent-date-value">Mar 12, 2013</td><td class="patent-data-table-td ">Sony Computer Entertainment America Llc</td><td class="patent-data-table-td ">Base station for position location</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8494177">US8494177</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 13, 2008</td><td class="patent-data-table-td patent-date-value">Jul 23, 2013</td><td class="patent-data-table-td ">Aliphcom</td><td class="patent-data-table-td ">Virtual microphone array systems using dual omindirectional microphone array (DOMA)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8503691">US8503691</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 13, 2008</td><td class="patent-data-table-td patent-date-value">Aug 6, 2013</td><td class="patent-data-table-td ">Aliphcom</td><td class="patent-data-table-td ">Virtual microphone arrays using dual omnidirectional microphone array (DOMA)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8503692">US8503692</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 13, 2008</td><td class="patent-data-table-td patent-date-value">Aug 6, 2013</td><td class="patent-data-table-td ">Aliphcom</td><td class="patent-data-table-td ">Forming virtual microphone arrays using dual omnidirectional microphone array (DOMA)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8526647">US8526647</a></td><td class="patent-data-table-td patent-date-value">Jun 1, 2010</td><td class="patent-data-table-td patent-date-value">Sep 3, 2013</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">Listening device providing enhanced localization cues, its use and a method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8527657">US8527657</a></td><td class="patent-data-table-td patent-date-value">Mar 20, 2009</td><td class="patent-data-table-td patent-date-value">Sep 3, 2013</td><td class="patent-data-table-td ">Sony Computer Entertainment America Llc</td><td class="patent-data-table-td ">Methods and systems for dynamically adjusting update rates in multi-player network gaming</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8542907">US8542907</a></td><td class="patent-data-table-td patent-date-value">Dec 15, 2008</td><td class="patent-data-table-td patent-date-value">Sep 24, 2013</td><td class="patent-data-table-td ">Sony Computer Entertainment America Llc</td><td class="patent-data-table-td ">Dynamic three-dimensional object mapping for user-defined control device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8547401">US8547401</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 2004</td><td class="patent-data-table-td patent-date-value">Oct 1, 2013</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">Portable augmented reality device and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8568230">US8568230</a></td><td class="patent-data-table-td patent-date-value">Nov 10, 2009</td><td class="patent-data-table-td patent-date-value">Oct 29, 2013</td><td class="patent-data-table-td ">Sony Entertainment Computer Inc.</td><td class="patent-data-table-td ">Methods for directing pointing detection conveyed by user when interfacing with a computer program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8570378">US8570378</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2008</td><td class="patent-data-table-td patent-date-value">Oct 29, 2013</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">Method and apparatus for tracking three-dimensional movements of an object using a depth sensing camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8577055">US8577055</a></td><td class="patent-data-table-td patent-date-value">Jan 22, 2013</td><td class="patent-data-table-td patent-date-value">Nov 5, 2013</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Sound source signal filtering apparatus based on calculated distance between microphone and sound source</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8682018">US8682018</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 30, 2012</td><td class="patent-data-table-td patent-date-value">Mar 25, 2014</td><td class="patent-data-table-td ">Aliphcom</td><td class="patent-data-table-td ">Microphone array with rear venting</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8686939">US8686939</a></td><td class="patent-data-table-td patent-date-value">May 6, 2006</td><td class="patent-data-table-td patent-date-value">Apr 1, 2014</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">System, method, and apparatus for three-dimensional input control</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8693703">US8693703</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 2, 2008</td><td class="patent-data-table-td patent-date-value">Apr 8, 2014</td><td class="patent-data-table-td ">Gn Netcom A/S</td><td class="patent-data-table-td ">Method of combining at least two audio signals and a microphone system comprising at least two microphones</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8781151">US8781151</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 2007</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">Object detection using video input combined with tilt angle information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090003624">US20090003624</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 13, 2008</td><td class="patent-data-table-td patent-date-value">Jan 1, 2009</td><td class="patent-data-table-td ">Burnett Gregory C</td><td class="patent-data-table-td ">Dual Omnidirectional Microphone Array (DOMA)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090175466">US20090175466</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 9, 2007</td><td class="patent-data-table-td patent-date-value">Jul 9, 2009</td><td class="patent-data-table-td ">Mh Acoustics, Llc</td><td class="patent-data-table-td ">Noise-reducing directional microphone array</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100239100">US20100239100</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 19, 2010</td><td class="patent-data-table-td patent-date-value">Sep 23, 2010</td><td class="patent-data-table-td ">Siemens Medical Instruments Pte. Ltd.</td><td class="patent-data-table-td ">Method for adjusting a directional characteristic and a hearing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110044460">US20110044460</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 2, 2008</td><td class="patent-data-table-td patent-date-value">Feb 24, 2011</td><td class="patent-data-table-td ">Martin Rung</td><td class="patent-data-table-td ">method of combining at least two audio signals and a microphone system comprising at least two microphones</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110223997">US20110223997</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 24, 2011</td><td class="patent-data-table-td patent-date-value">Sep 15, 2011</td><td class="patent-data-table-td ">Sony Computer Entertainment Inc.</td><td class="patent-data-table-td ">Method to detect and remove audio disturbances from audio signals captured at video game controllers</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110311064">US20110311064</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Dec 22, 2011</td><td class="patent-data-table-td ">Avaya Inc.</td><td class="patent-data-table-td ">System and method for stereophonic acoustic echo cancellation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120207322">US20120207322</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 30, 2012</td><td class="patent-data-table-td patent-date-value">Aug 16, 2012</td><td class="patent-data-table-td ">Aliphcom</td><td class="patent-data-table-td ">Microphone array with rear venting</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN1669356B?cl=en">CN1669356B</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 18, 2003</td><td class="patent-data-table-td patent-date-value">Sep 8, 2010</td><td class="patent-data-table-td ">索尼爱立信移动通讯股份有限公司</td><td class="patent-data-table-td ">Electronic devices, methods of operating the same, and computer program products for detecting noise in a signal based on a combination of spatial correlation and time correlation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/DE10313330A1?cl=en">DE10313330A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 25, 2003</td><td class="patent-data-table-td patent-date-value">Oct 21, 2004</td><td class="patent-data-table-td ">Siemens Audiologische Technik Gmbh</td><td class="patent-data-table-td ">Suppression of acoustic noise signal in hearing aid, by weighted combination of signals from microphones, normalization and selection of directional microphone signal having lowest interference signal content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/DE10313330B4?cl=en">DE10313330B4</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 25, 2003</td><td class="patent-data-table-td patent-date-value">Apr 14, 2005</td><td class="patent-data-table-td ">Siemens Audiologische Technik Gmbh</td><td class="patent-data-table-td ">Verfahren zur Unterdrückung mindestens eines akustischen Störsignals und Vorrichtung zur Durchführung des Verfahrens</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/DE10331956C5?cl=en">DE10331956C5</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 16, 2003</td><td class="patent-data-table-td patent-date-value">Nov 18, 2010</td><td class="patent-data-table-td ">Siemens Audiologische Technik Gmbh</td><td class="patent-data-table-td ">Hörhilfegerät sowie Verfahren zum Betrieb eines Hörhilfegerätes mit einem Mikrofonsystem, bei dem unterschiedliche Richtcharakteistiken einstellbar sind</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1448016A1?cl=en">EP1448016A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 17, 2003</td><td class="patent-data-table-td patent-date-value">Aug 18, 2004</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">Device and method for detecting wind noise</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2107826A1?cl=en">EP2107826A1</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 2008</td><td class="patent-data-table-td patent-date-value">Oct 7, 2009</td><td class="patent-data-table-td ">Bernafon AG</td><td class="patent-data-table-td ">A directional hearing aid system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2182739A1?cl=en">EP2182739A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 20, 2009</td><td class="patent-data-table-td patent-date-value">May 5, 2010</td><td class="patent-data-table-td ">Siemens Medical Instruments Pte. Ltd.</td><td class="patent-data-table-td ">Adaptive microphone system for a hearing aid and accompanying operating method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2262285A1?cl=en">EP2262285A1</a></td><td class="patent-data-table-td patent-date-value">Jun 2, 2009</td><td class="patent-data-table-td patent-date-value">Dec 15, 2010</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">A listening device providing enhanced localization cues, its use and a method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2306457A1?cl=en">EP2306457A1</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 2009</td><td class="patent-data-table-td patent-date-value">Apr 6, 2011</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">Automatic sound recognition based on binary time frequency units</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2381700A1?cl=en">EP2381700A1</a></td><td class="patent-data-table-td patent-date-value">Apr 20, 2010</td><td class="patent-data-table-td patent-date-value">Oct 26, 2011</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">Signal dereverberation using environment information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2439958A1?cl=en">EP2439958A1</a></td><td class="patent-data-table-td patent-date-value">Oct 6, 2010</td><td class="patent-data-table-td patent-date-value">Apr 11, 2012</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">A method of determining parameters in an adaptive audio processing algorithm and an audio processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2463856A1?cl=en">EP2463856A1</a></td><td class="patent-data-table-td patent-date-value">Dec 9, 2010</td><td class="patent-data-table-td patent-date-value">Jun 13, 2012</td><td class="patent-data-table-td ">Oticon A/s</td><td class="patent-data-table-td ">Method to reduce artifacts in algorithms with fast-varying gain</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2503794A1?cl=en">EP2503794A1</a></td><td class="patent-data-table-td patent-date-value">Mar 24, 2011</td><td class="patent-data-table-td patent-date-value">Sep 26, 2012</td><td class="patent-data-table-td ">Oticon A/s</td><td class="patent-data-table-td ">Audio processing device, system, use and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2519032A1?cl=en">EP2519032A1</a></td><td class="patent-data-table-td patent-date-value">Apr 26, 2011</td><td class="patent-data-table-td patent-date-value">Oct 31, 2012</td><td class="patent-data-table-td ">Oticon A/s</td><td class="patent-data-table-td ">A system comprising a portable electronic device with a time function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2528358A1?cl=en">EP2528358A1</a></td><td class="patent-data-table-td patent-date-value">May 23, 2011</td><td class="patent-data-table-td patent-date-value">Nov 28, 2012</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">A method of identifying a wireless communication channel in a sound system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2541973A1?cl=en">EP2541973A1</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 2011</td><td class="patent-data-table-td patent-date-value">Jan 2, 2013</td><td class="patent-data-table-td ">Oticon A/s</td><td class="patent-data-table-td ">Feedback control in a listening device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2560410A1?cl=en">EP2560410A1</a></td><td class="patent-data-table-td patent-date-value">Aug 15, 2011</td><td class="patent-data-table-td patent-date-value">Feb 20, 2013</td><td class="patent-data-table-td ">Oticon A/s</td><td class="patent-data-table-td ">Control of output modulation in a hearing instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2563044A1?cl=en">EP2563044A1</a></td><td class="patent-data-table-td patent-date-value">Aug 23, 2011</td><td class="patent-data-table-td patent-date-value">Feb 27, 2013</td><td class="patent-data-table-td ">Oticon A/s</td><td class="patent-data-table-td ">A method, a listening device and a listening system for maximizing a better ear effect</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2563045A1?cl=en">EP2563045A1</a></td><td class="patent-data-table-td patent-date-value">Aug 23, 2011</td><td class="patent-data-table-td patent-date-value">Feb 27, 2013</td><td class="patent-data-table-td ">Oticon A/s</td><td class="patent-data-table-td ">A method and a binaural listening system for maximizing a better ear effect</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2574082A1?cl=en">EP2574082A1</a></td><td class="patent-data-table-td patent-date-value">Sep 20, 2011</td><td class="patent-data-table-td patent-date-value">Mar 27, 2013</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">Control of an adaptive feedback cancellation system based on probe signal injection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2584794A1?cl=en">EP2584794A1</a></td><td class="patent-data-table-td patent-date-value">Oct 17, 2011</td><td class="patent-data-table-td patent-date-value">Apr 24, 2013</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">A listening system adapted for real-time communication providing spatial information in an audio stream</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2613566A1?cl=en">EP2613566A1</a></td><td class="patent-data-table-td patent-date-value">Jan 3, 2012</td><td class="patent-data-table-td patent-date-value">Jul 10, 2013</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">A listening device and a method of monitoring the fitting of an ear mould of a listening device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2613567A1?cl=en">EP2613567A1</a></td><td class="patent-data-table-td patent-date-value">Jan 3, 2012</td><td class="patent-data-table-td patent-date-value">Jul 10, 2013</td><td class="patent-data-table-td ">Oticon A/S</td><td class="patent-data-table-td ">A method of improving a long term feedback path estimate in a listening device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000030404A1?cl=en">WO2000030404A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 16, 1999</td><td class="patent-data-table-td patent-date-value">May 22, 2000</td><td class="patent-data-table-td ">Robert C Bilger</td><td class="patent-data-table-td ">Binaural signal processing techniques</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000041436A1?cl=en">WO2000041436A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 5, 2000</td><td class="patent-data-table-td patent-date-value">Jul 13, 2000</td><td class="patent-data-table-td ">Phonak Ag</td><td class="patent-data-table-td ">Method for producing an electric signal or method for boosting acoustic signals from a preferred direction, transmitter and associated device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2001097558A2?cl=en">WO2001097558A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 5, 2001</td><td class="patent-data-table-td patent-date-value">Dec 20, 2001</td><td class="patent-data-table-td ">Gn Resound Corp</td><td class="patent-data-table-td ">Fixed polar-pattern-based adaptive directionality systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2007106399A2?cl=en">WO2007106399A2</a></td><td class="patent-data-table-td patent-date-value">Mar 9, 2007</td><td class="patent-data-table-td patent-date-value">Sep 20, 2007</td><td class="patent-data-table-td ">Mh Acoustics Llc</td><td class="patent-data-table-td ">Noise-reducing directional microphone array</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2011027005A2?cl=en">WO2011027005A2</a></td><td class="patent-data-table-td patent-date-value">Dec 20, 2010</td><td class="patent-data-table-td patent-date-value">Mar 10, 2011</td><td class="patent-data-table-td ">Phonak Ag</td><td class="patent-data-table-td ">Method and system for speech enhancement in a room</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2012010195A1?cl=en">WO2012010195A1</a></td><td class="patent-data-table-td patent-date-value">Jul 19, 2010</td><td class="patent-data-table-td patent-date-value">Jan 26, 2012</td><td class="patent-data-table-td ">Advanced Bionics Ag</td><td class="patent-data-table-td ">Hearing instrument and method of operating the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2012010218A1?cl=en">WO2012010218A1</a></td><td class="patent-data-table-td patent-date-value">Jul 23, 2010</td><td class="patent-data-table-td patent-date-value">Jan 26, 2012</td><td class="patent-data-table-td ">Phonak Ag</td><td class="patent-data-table-td ">Hearing system and method for operating a hearing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2014062152A1?cl=en">WO2014062152A1</a></td><td class="patent-data-table-td patent-date-value">Oct 15, 2012</td><td class="patent-data-table-td patent-date-value">Apr 24, 2014</td><td class="patent-data-table-td ">Mh Acoustics, Llc</td><td class="patent-data-table-td ">Noise-reducing directional microphone array</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc381/defs381.htm&usg=AFQjCNEBGRn0m_HVM1ky04aVpJh2Hb9NhA#C381S092000">381/92</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc381/defs381.htm&usg=AFQjCNEBGRn0m_HVM1ky04aVpJh2Hb9NhA#C381S094700">381/94.7</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04R0003000000">H04R3/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04R0001400000">H04R1/40</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04R3/005">H04R3/005</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04R2430/21">H04R2430/21</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=BsU9BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04R1/406">H04R1/406</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04R3/00B</span>, <span class="nested-value">H04R1/40C</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jul 2, 2013</td><td class="patent-data-table-td ">FPB2</td><td class="patent-data-table-td ">Expired due to reexamination which canceled all claims (2nd reexamination)</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 31, 2012</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120615</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 29, 2011</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AGERE SYSTEMS, INC.;REEL/FRAME:027464/0486</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">ADAPTIVE SONICS LLC, TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20111004</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 30, 2010</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20020829</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AGERE SYSTEMS INC.,PENNSYLVANIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">MERGER;ASSIGNOR:AGERE SYSTEMS GUARDIAN CORP.;REEL/FRAME:024312/0491</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 29, 2010</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AGERE SYSTEMS GUARDIAN CORP.,PENNSYLVANIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:LUCENT TECHNOLOGIES INC.;REEL/FRAME:024305/0315</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20020531</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">LUCENT TECHNOLOGIES INC.,NEW JERSEY</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19960329</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AT&amp;T CORP.;REEL/FRAME:024305/0306</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19950921</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">MERGER;ASSIGNOR:AT&amp;T IPM CORP.;REEL/FRAME:024305/0300</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AT&amp;T CORP.,NEW YORK</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 20, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100113</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 23, 2010</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-23 IS CONFIRMED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 17, 2009</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20081224</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 31, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 26, 2003</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 3, 2003</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 22, 2002</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AGERE SYSTEMS GUARDIAN CORP., FLORIDA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">TERMINATION AND RELEASE OF SECURITY INTEREST IN PATENT RIGHTS;ASSIGNOR:JPMORGAN CHASE BANK (F/K/A THE CHASE MANHATTAN BANK);REEL/FRAME:013372/0662</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20020930</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 5, 2001</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CHASE MANHATTAN BANK, AS ADMINISTRATIVE AGENT, THE</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CONDITIONAL ASSIGNMENT OF AND SECURITY INTEREST IN PATENT RIGHTS;ASSIGNOR:AGERE SYSTEMS GUARDIAN CORP. (DE CORPORATION);REEL/FRAME:011667/0148</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20010402</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CONDITIONAL ASSIGNMENT OF AND SECURITY INTEREST IN PATENT RIGHTS;ASSIGNOR:AGERE SYSTEMS GUARDIAN CORP. (DE CORPORATION) /AR;REEL/FRAME:011667/0148</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 1, 1999</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 7, 1995</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AT&amp;T CORP., NEW YORK</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AMERICAN TELELPHONE AND TELEGRAPH COMPANY;REEL/FRAME:007527/0274</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19940420</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AT&amp;T IPM CORP., FLORIDA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AT&amp;T CORP.;REEL/FRAME:007528/0038</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19950523</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 5, 1993</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">AMERICAN TELEPHONE AND TELEGRAPH COMPANY, NEW YORK</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:CEZANNE, JUERGEN;ELKO, GARY WAYNE;REEL/FRAME:006771/0815</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19931104</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U2yAB_ERSiAj1S-HLybgYOo5l3Unw\u0026id=BsU9BAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3XSBwXe51lDuD5JX9dY9yoYjZM1A\u0026id=BsU9BAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U0Gi73aZHlyHXHxz0uCaTXy5uwRLQ","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Adaptive_microphone_array.pdf?id=BsU9BAABERAJ\u0026output=pdf\u0026sig=ACfU3U1oufG3nu6VciWOtIl2VhI4n36Cgg"},"sample_url":"http://www.google.com/patents/reader?id=BsU9BAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>