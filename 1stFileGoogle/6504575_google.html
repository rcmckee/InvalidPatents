<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6504575 - Method and system for displaying overlay bars in a digital imaging device - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method and system for displaying overlay bars in a digital imaging device"><meta name="DC.contributor" content="Michael A. Ramirez" scheme="inventor"><meta name="DC.contributor" content="Eric C. Anderson" scheme="inventor"><meta name="DC.contributor" content="Flashpoint Technology, Inc." scheme="assignee"><meta name="DC.date" content="1998-2-27" scheme="dateSubmitted"><meta name="DC.description" content="A method and system for displaying an overlay bar on a digital imaging device is disclosed. First, text and graphic information to be displayed on the overlay bar are stored in an overlay bar buffer, and then displayed on a display screen. Thereafter, an image to be viewed is displayed on the display line-by-line. The lines of the image that are to be displayed within the area of an overlay bar are stored in a backstore buffer. Each line in the backstore buffer is then merged with its corresponding lines in the overlay bar buffer and displayed. The merging operation is performed by modifying the luminance value of each pixel of the image data that falls within the area of the overlay bar, and overwriting each pixel of image data that falls under a pixel of text in the overlay bar. This makes the overlay bar appear to the user to be translucent and makes the image appear as though it is sliding beneath the overlay bar as it is being displayed. When the user turns-off the overlay bars, only the portions of the image stored in the backstore buffer need be re-displayed to provide the original image, thus eliminating the need to re-display the entire image."><meta name="DC.date" content="2003-1-7" scheme="issued"><meta name="DC.relation" content="US:5949432" scheme="references"><meta name="DC.relation" content="US:6144362" scheme="references"><meta name="DC.relation" content="US:6310648" scheme="references"><meta name="citation_patent_number" content="US:6504575"><meta name="citation_patent_application_number" content="US:09/032,177"><link rel="canonical" href="http://www.google.com/patents/US6504575"/><meta property="og:url" content="http://www.google.com/patents/US6504575"/><meta name="title" content="Patent US6504575 - Method and system for displaying overlay bars in a digital imaging device"/><meta name="description" content="A method and system for displaying an overlay bar on a digital imaging device is disclosed. First, text and graphic information to be displayed on the overlay bar are stored in an overlay bar buffer, and then displayed on a display screen. Thereafter, an image to be viewed is displayed on the display line-by-line. The lines of the image that are to be displayed within the area of an overlay bar are stored in a backstore buffer. Each line in the backstore buffer is then merged with its corresponding lines in the overlay bar buffer and displayed. The merging operation is performed by modifying the luminance value of each pixel of the image data that falls within the area of the overlay bar, and overwriting each pixel of image data that falls under a pixel of text in the overlay bar. This makes the overlay bar appear to the user to be translucent and makes the image appear as though it is sliding beneath the overlay bar as it is being displayed. When the user turns-off the overlay bars, only the portions of the image stored in the backstore buffer need be re-displayed to provide the original image, thus eliminating the need to re-display the entire image."/><meta property="og:title" content="Patent US6504575 - Method and system for displaying overlay bars in a digital imaging device"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("OJPtU-_ACNDKsASd6YC4DQ"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("IRL"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("OJPtU-_ACNDKsASd6YC4DQ"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("IRL"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6504575?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6504575"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=l7NdBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6504575&amp;usg=AFQjCNEROqVz6bk80qQswV1fB2bYlqUFUQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6504575.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6504575.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6504575" style="display:none"><span itemprop="description">A method and system for displaying an overlay bar on a digital imaging device is disclosed. First, text and graphic information to be displayed on the overlay bar are stored in an overlay bar buffer, and then displayed on a display screen. Thereafter, an image to be viewed is displayed on the display...</span><span itemprop="url">http://www.google.com/patents/US6504575?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6504575 - Method and system for displaying overlay bars in a digital imaging device</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6504575 - Method and system for displaying overlay bars in a digital imaging device" title="Patent US6504575 - Method and system for displaying overlay bars in a digital imaging device"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6504575 B1</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/032,177</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Jan 7, 2003</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Feb 27, 1998</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Feb 27, 1998</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">032177, </span><span class="patent-bibdata-value">09032177, </span><span class="patent-bibdata-value">US 6504575 B1, </span><span class="patent-bibdata-value">US 6504575B1, </span><span class="patent-bibdata-value">US-B1-6504575, </span><span class="patent-bibdata-value">US6504575 B1, </span><span class="patent-bibdata-value">US6504575B1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Michael+A.+Ramirez%22">Michael A. Ramirez</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Eric+C.+Anderson%22">Eric C. Anderson</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Flashpoint+Technology,+Inc.%22">Flashpoint Technology, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6504575.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6504575.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6504575.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (34),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (32),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (7)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6504575&usg=AFQjCNGnZSyiQTAE_hWmteKqB2gMYLtvZA">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6504575&usg=AFQjCNH_Go7JBbWtVTVVE6DhWoYsX5N_bw">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6504575B1%26KC%3DB1%26FT%3DD&usg=AFQjCNHnvPTzXpbYPm-7phg58a2jiaUbWQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55023335" lang="EN" load-source="patent-office">Method and system for displaying overlay bars in a digital imaging device</invention-title></span><br><span class="patent-number">US 6504575 B1</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50432837" lang="EN" load-source="patent-office"> <div class="abstract">A method and system for displaying an overlay bar on a digital imaging device is disclosed. First, text and graphic information to be displayed on the overlay bar are stored in an overlay bar buffer, and then displayed on a display screen. Thereafter, an image to be viewed is displayed on the display line-by-line. The lines of the image that are to be displayed within the area of an overlay bar are stored in a backstore buffer. Each line in the backstore buffer is then merged with its corresponding lines in the overlay bar buffer and displayed. The merging operation is performed by modifying the luminance value of each pixel of the image data that falls within the area of the overlay bar, and overwriting each pixel of image data that falls under a pixel of text in the overlay bar. This makes the overlay bar appear to the user to be translucent and makes the image appear as though it is sliding beneath the overlay bar as it is being displayed. When the user turns-off the overlay bars, only the portions of the image stored in the backstore buffer need be re-displayed to provide the original image, thus eliminating the need to re-display the entire image.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(12)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6504575B1/US06504575-20030107-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6504575B1/US06504575-20030107-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(7)</span></span></div><div class="patent-text"><div mxw-id="PCLM8417096" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is: </claim-statement> <div class="claim"> <div num="1" id="US-6504575-B1-CLM-00001" class="claim">
      <div class="claim-text">1. A method for displaying an overlay bar on a digital imaging device comprising the steps of:</div>
      <div class="claim-text">a) displaying the overlay bar in a predetermined area of a display screen for displaying text information, the overlay bar comprising a plurality of pixels corresponding to the text information; </div>
      <div class="claim-text">b) providing an image to display on the display screen, the image comprising a plurality of pixels having luminance values; and </div>
      <div class="claim-text">c) displaying the image by </div>
      <div class="claim-text">i) modifying the luminance value of each pixel of the image data that falls within the area of the overlay bar, and </div>
      <div class="claim-text">ii) overwriting each pixel of image data that falls under a pixel of text in the overlay bar, </div>
      <div class="claim-text">wherein modifying the luminance values of the image data provides the overlay bar with a translucent appearance thereby enabling a user to see the image through the overlay bar.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6504575-B1-CLM-00002" class="claim">
      <div class="claim-text">2. A method as in <claim-ref idref="US-6504575-B1-CLM-00001">claim 1</claim-ref> wherein step ci) further includes the steps of saving each pixel of the image data that falls within the area of the overlay bar, creating saved image data; and</div>
      <div class="claim-text">in response to the user turning-off the overlay bar, displaying the saved image data on the display screen, thereby eliminating the need to re-display the entire image. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6504575-B1-CLM-00003" class="claim">
      <div class="claim-text">3. A method as in <claim-ref idref="US-6504575-B1-CLM-00002">claim 2</claim-ref> wherein step a) further includes the step of providing the overlay bar with graphic information.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6504575-B1-CLM-00004" class="claim">
      <div class="claim-text">4. A method as in <claim-ref idref="US-6504575-B1-CLM-00003">claim 3</claim-ref> wherein step ci) for modifying the luminance values includes the step of decreasing the luminance values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6504575-B1-CLM-00005" class="claim">
      <div class="claim-text">5. A method as in <claim-ref idref="US-6504575-B1-CLM-00003">claim 3</claim-ref> wherein step ci) for modifying the luminance values includes the step of increasing the luminance values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6504575-B1-CLM-00006" class="claim">
      <div class="claim-text">6. A method as in <claim-ref idref="US-6504575-B1-CLM-00003">claim 3</claim-ref> wherein step c) further includes the step of displaying the image line-by-line.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" id="US-6504575-B1-CLM-00007" class="claim">
      <div class="claim-text">7. A method as in <claim-ref idref="US-6504575-B1-CLM-00003">claim 3</claim-ref> wherein step c) further includes the step of displaying the image block-by-block.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES53857883" lang="EN" load-source="patent-office" class="description">
    <heading>CROSS-REFERENCE TO RELATED APPLICATIONS</heading> <p>This application is related to U.S. patent application Ser. No. 09/082172 entitled “Method And System For Controlling User Interaction In A Digital Imaging Device Using Dynamic Overlay Bars” (P135), and U.S. patent application Ser. No. 09/032659 entitled “Directing Image Capture Sequences In A Digital Imaging Device Using Scripts” (P165), which were filed on the same date as the present application.</p>
    <heading>FIELD OF THE INVENTION</heading> <p>The present invention relates generally to digital imaging devices, including digital cameras, and more particularly to a method and system for displaying overlay bars in a digital imaging device.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>Most digital cameras today are similar in size to and behave like conventional point-and-shoot cameras. Unlike conventional cameras, however, most digital cameras store digital images in an internal flash memory or on external memory cards, and some are equipped with a liquid-crystal display (LCD) screen on the back of the camera. Through the use of the LCD, most digital cameras operate in two modes, record and play, although some only have a record mode.</p>
    <p>In record mode, which is also referred to as capture mode, the LCD acts as a live viewfinder in which the user may view an object or scene before taking a picture, similar to the LCD on a camcorder. When the user presses the shutter button, whatever scene is shown on the LCD is captured as a still image. Besides capturing still images, some digital cameras can be set to capture other image types, such as burst and time-lapse images. A burst image is a series of still images captured in rapid succession, while a time-lapse image is series of still images taken at regular intervals over a longer time period.</p>
    <p>In play mode, the LCD acts as a playback screen for reviewing the previously captured images. Typically, several small images are displayed on the LCD at once, and by selecting one of the images the user may then display the full-sized version of the images in the LCD.</p>
    <p>Although conventional digital cameras are more convenient for the user to use than film cameras due to instant play back of captured images, there are several drawbacks in the user interface that restrict user interaction with the camera. When capturing images, for example, it is often helpful for the user to be informed about the current settings or operational state of the camera, such as whether the flash is on/off, and the current image type setting, for instance.</p>
    <p>In conventional digital cameras, such status information is typically displayed as text blocks or accessed through a status screen or the like. The disadvantage with the text blocks is that they are typically small (10-15 characters in length), and therefore, the amount of status information they can provide is very limited. Typically, text blocks are used to display information such as the current image number. Moreover, when text blocks are displayed with a solid color background, the background obscures that portion of the image. And when text blocks are displayed with no background (only text), the text is difficult to distinguish from the colors comprising the image, making the text hard to read.</p>
    <p>The disadvantage with status screens is that in order to view the status information, the image currently displayed on the LCD must be replaced with the status screen, causing the user to loose sight of the image. Another approach would be to shrink the display area of the LCD and add a black status area in the viewfinder, as done in optical viewfinders of film cameras. This, however, would shrink the size of images displayed in the viewfinder.</p>
    <p>Another drawback with conventional digital cameras is that as technological advances are made, digital cameras are continually provided with more features and functions, which make them more complex for the user to interact with. This is similar to what occurs with PC software, which increasingly grows larger and harder to use. PC developers attempt to alleviate this problem by providing more and larger help menus. Each help menu usually opens in its own window with paragraphs of scrolling text.</p>
    <p>Using PC help menus in a digital camera to guide user interaction through the camera features and functions would be less than ideal because of the limited size of the camera LCD. And assuming help menus were displayed, they would either obscure whatever image was being displayed or otherwise total replace it, which is disadvantageous to the picture taker.</p>
    <p>Accordingly, what is needed is an improved system and method for displaying status information in a manner that does not obscure the display of the current object in the LCD, and for controlling user interaction in a digital imaging device. The present invention addresses such a need.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention provides a method and system for controlling user interaction in a digital imaging device having a display using dynamic overlay bars. The digital imaging device includes at least two operating modes, where each of the operating modes has at least one mode-specific operation that can be performed on images. In response to operating in either of the operating modes, the digital imaging device displays a translucent overlay bar on the display that is dynamically updated with status information and interactive instructions that guide the user through the mode-specific operations.</p>
    <p>In a second aspect of the present invention, the interactive instructions are implemented using a script, which is a text-based program that may be easily written by the user and externally loaded into the camera. Once loaded into the camera, the commands comprising the script are translated and executed one-by-one by a script interpreter to guide the user through the newly provided function.</p>
    <p>A third aspect of the present invention, provides a method and system for displaying overlay bars on the display. First, text and graphic information to be displayed on the overlay bars are stored in an overlay bar buffer, and then displayed on the display. Thereafter, the current image is displayed on the display line-by-line. The lines of the image that will be displayed within the area of an overlay bar are stored in a backstore buffer. Each line in the backstore buffer is merged with its corresponding lines in the overlay bar buffer and displayed. This aspect of the present invention makes the overlay bars appear translucent, and the image appear as though it is sliding beneath the overlay bars as it is being displayed. When the user turns-off the overlay bars, only the portions of the image stored in the backstore buffer need be re-displayed to provide the original image, thus eliminating the need to re-display the entire image.</p>
    <p>Accordingly, the method and system of the present invention provides status information to a user and allows the user to perform complex camera functions and features to the images with minimum effort, while allowing for easy viewing of the images. Displaying interactive instructions on dynamic overlay bars to guide the user through complex tasks in accordance with the present invention eliminates the need for help screens and for the user to remember complicated key sequences, and increases the ease of use and operation of the digital camera. The manner in which the overlay bars and the image is displayed makes the user interface more aesthetically pleasing, while increasing the display speed of the digital imaging device.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is a block diagram of a digital camera that operates in accordance with the present invention.</p>
    <p>FIG. 2 is a block diagram of an example embodiment for the imaging device of FIG. <b>1</b>.</p>
    <p>FIG. 3 is a block diagram of an example embodiment for the computer of FIG. <b>1</b>.</p>
    <p>FIGS. 4 and 5 are diagrams depicting the preferred embodiment of the camera's <b>110</b> user interface.</p>
    <p>FIG. 6 is a flow chart is shown illustrating the process of controlling user interaction in a digital imaging device using dynamic overlay bars in accordance with the present invention.</p>
    <p>FIGS. 7A and 7B are diagrams illustrating the use of dynamic overlay bars on the LCD screen during capture and play modes, respectively.</p>
    <p>FIGS. 8A through 8C are diagrams illustrating how the overlay bars may be used to guide the user through a recording of a sound annotation.</p>
    <p>FIGS. 9A and 9B are diagrams illustrating example directed image capture screens.</p>
    <p>FIG. 10 is a block diagram illustrating the camera software, which is stored in ROM, and DRAM, where the software is executed.</p>
    <p>FIG. 11 is a flow chart illustrating an exemplary process of installing and running a script-based directed image capture in a preferred embodiment of the present invention.</p>
    <p>FIG. 12A is a diagram illustrating a memory buffer organization for displaying overlay bars.</p>
    <p>FIG. 12B is a flow chart illustrating the process of displaying overlay bars on the LCD in accordance with the present invention.</p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading> <p>The present invention relates to an improved method and system for displaying overlay bars in a digital imaging device. The following description is presented to enable one of ordinary skill in the art to make and use the invention and is provided in the context of a patent application and its requirements. Although the present invention will be described in the context of a digital camera, various modifications to the preferred embodiment will be readily apparent to those skilled in the art and the generic principles herein may be applied to other embodiments. That is, any digital imaging device which displays images, icons and/or other items, could incorporate the features described herein below and that device would be within the spirit and scope of the present invention. Thus, the present invention is not intended to be limited to the embodiment shown but is to be accorded the widest scope consistent with the principles and features described herein.</p>
    <p>The present invention is a method and system for displaying dynamic overlay bars in a digital imaging device. According to the present invention, both status information and interactive instructions are displayed on dynamic overlay bars to enable a user to perform complex camera functions and apply features to the images with minimum effort, while allowing for easy viewing of the images.</p>
    <p>Referring now to FIG. 1, a block diagram of a digital camera <b>110</b> is shown for use in accordance with the present invention. Camera <b>110</b> preferably comprises an imaging device <b>114</b>, a system bus <b>116</b> and a computer <b>118</b>. Imaging device <b>114</b> is optically coupled to an object <b>112</b> and electrically coupled via system bus <b>116</b> to computer <b>118</b>. Once a photographer has focused imaging device <b>114</b> on object <b>112</b> and, using a capture button or some other means, instructed camera <b>110</b> to capture an image of object <b>112</b>, computer <b>118</b> commands imaging device <b>114</b> via system bus <b>116</b> to capture raw image data representing object <b>112</b>. The captured raw image data is transferred over system bus <b>116</b> to computer <b>118</b> which performs various image processing functions on the image data before storing it in its internal memory. System bus <b>116</b> also passes various status and control signals between imaging device <b>114</b> and computer <b>118</b>.</p>
    <p>Referring now to FIG. 2, a block diagram of an example embodiment of imaging device <b>114</b> is shown. Imaging device <b>114</b> typically comprises a lens <b>220</b> having an iris, a filter <b>222</b>, an image sensor <b>224</b>, a timing generator <b>226</b>, an analog signal processor (ASP) <b>228</b>, an analog-to-digital (A/D) converter <b>230</b>, an interface <b>232</b>, and one or more motors <b>234</b>.</p>
    <p>In operation, imaging device <b>114</b> captures an image of object <b>112</b> via reflected light impacting image sensor <b>224</b> along optical path <b>236</b>. Image sensor <b>224</b>, which is typically a charged coupled device (CCD), responsively generates a set of raw image data in CCD format representing the captured image <b>112</b>. The raw image data is then routed through ASP <b>228</b>, A/D converter <b>230</b> and interface <b>232</b>. Interface <b>232</b> has outputs for controlling ASP <b>228</b>, motors <b>234</b> and timing generator <b>226</b>. From interface <b>232</b>, the raw image data passes over system bus <b>116</b> to computer <b>118</b>.</p>
    <p>Referring now to FIG. 3, a block diagram of an example embodiment for computer <b>118</b> is shown. System bus <b>116</b> provides connection paths between imaging device <b>114</b>, an optional power manager <b>342</b>, central processing unit (CPU) <b>344</b>, dynamic random-access memory (DRAM) <b>346</b>, input/output interface (I/O) <b>348</b>, non-volatile memory <b>350</b>, and buffers/connector <b>352</b>. Removable memory <b>354</b> connects to system bus <b>116</b> via buffers/connector <b>352</b>. Alternately, camera <b>110</b> may be implemented without removable memory <b>354</b> or buffers/connector <b>352</b>.</p>
    <p>Power manager <b>342</b> communicates via line <b>366</b> with power supply <b>356</b> and coordinates power management operations for camera <b>110</b>. CPU <b>344</b> typically includes a conventional processor device for controlling the operation of camera <b>110</b>. In the preferred embodiment, CPU <b>344</b> is capable of concurrently running multiple software routines to control the various processes of camera <b>110</b> within a multithreaded environment. DRAM <b>346</b> is a contiguous block of dynamic memory which may be selectively allocated to various storage functions. LCD controller <b>390</b> accesses DRAM <b>346</b> and transfers processed image data to LCD screen <b>402</b> for display.</p>
    <p>I/O <b>348</b> is an interface device allowing communications to and from computer <b>118</b>. For example, I/O <b>348</b> permits an external host computer (not shown) to connect to and communicate with computer <b>118</b>. I/O <b>348</b> also interfaces with a plurality of buttons and/or dials <b>404</b>, and an optional status LCD <b>406</b>, which in addition to the LCD screen <b>402</b>, are the hardware elements of the camera's user interface <b>408</b>.</p>
    <p>Non-volatile memory <b>350</b>, which may typically comprise a conventional read-only memory or flash memory, stores a set of computer-readable program instructions to control the operation of camera <b>110</b>. Removable memory <b>354</b> serves as an additional image data storage area and is preferably a non-volatile device, readily removable and replaceable by a camera <b>110</b> user via buffers/connector <b>352</b>. Thus, a user who possesses several removable memories <b>354</b> may replace a full removable memory <b>354</b> with an empty removable memory <b>354</b> to effectively expand the picture-taking capacity of camera <b>110</b>. In the preferred embodiment of the present invention, removable memory <b>354</b> is typically implemented using a flash disk.</p>
    <p>Power supply <b>356</b> supplies operating power to the various components of camera <b>110</b>. In the preferred embodiment, power supply <b>356</b> provides operating power to a main power bus <b>362</b> and also to a secondary power bus <b>364</b>. The main power bus <b>362</b> provides power to imaging device <b>114</b>, I/O <b>348</b>, non-volatile memory <b>350</b> and removable memory <b>354</b>. The secondary power bus <b>364</b> provides power to power manager <b>342</b>, CPU <b>344</b> and DRAM <b>346</b>.</p>
    <p>Power supply <b>356</b> is connected to main batteries <b>358</b> and also to backup batteries <b>360</b>. In the preferred embodiment, a camera <b>110</b> user may also connect power supply <b>356</b> to an external power source. During normal operation of power supply <b>356</b>, the main batteries <b>358</b> provide operating power to power supply <b>356</b> which then provides the operating power to camera <b>110</b> via both main power bus <b>362</b> and secondary power bus <b>364</b>. During a power failure mode in which the main batteries <b>358</b> have failed (when their output voltage has fallen below a minimum operational voltage level) the backup batteries <b>360</b> provide operating power to power supply <b>356</b> which then provides the operating power only to the secondary power bus <b>364</b> of camera <b>110</b>.</p>
    <p>FIGS. 4 and 5 are diagrams depicting the preferred hardware components of the camera's <b>110</b> user interface <b>408</b>. FIG. 4 is back view of the camera <b>110</b> showing the LCD screen <b>402</b>, a four-way navigation control button <b>409</b>, an overlay button <b>413</b>, a menu button <b>414</b>, and a set of programmable soft keys <b>416</b>. FIG. 5 is a top view of the camera <b>110</b> showing a shutter button <b>418</b>, and a mode dial <b>420</b>. The camera may optionally include status LCD <b>406</b>, status LCD scroll and select buttons <b>422</b> and <b>424</b>, a sound record button <b>426</b>, and zoom-in, zoom-out buttons <b>428</b> <i>a </i>and <b>428</b> <i>b. </i> </p>
    <p>The digital camera of the present invention is controlled by graphical-user-interface (GUI) based operating system (OS), which is in contrast to conventional digital cameras that are controlled by proprietary hardware architectures. In the preferred embodiment of the present invention, the OS provides the digital camera with several different operating modes for supporting various camera functions. Although the digital camera may include several different operating modes, the modes relevant to this description are capture mode, and play mode.</p>
    <p>In capture mode, the camera <b>100</b> supports the actions of preparing to capture an image, and capturing an image through the use of either the LCD screen <b>402</b> or the status LCD <b>406</b>. In play mode, the camera <b>110</b> supports the actions of displaying full-sized views of captured images, and play-backing various media types associated with the images, such as sound. The user may switch between the various modes, using the mode dial <b>420</b>. When the camera is placed into a particular mode, that mode's default screen appears in the LCD screen <b>402</b> in which a set of mode-specific items, such as images, icons, and text, are displayed.</p>
    <p>The present invention provides a method and system for controlling user interaction in a digital imaging device using dynamic overlay bars. According to the present invention, the dynamic overlay bars are used to provide the user with both status information and interactive instructions. The interactive instructions are automatically updated in response to normal camera operations to guide the user through predefined operations of the camera, thus making the device extremely easy to use. In addition, the manner in which the dynamic overlay bars are displayed reduces viewing interference with the currently displayed object.</p>
    <p>Referring now to FIG. 6, a flow chart is shown illustrating the process of controlling user interaction in a digital imaging device using dynamic overlay bars in accordance with the present invention. The process begins by displaying an image on the LCD screen <b>402</b> along with at least one overlay bar that provides a dynamic prompt area in a way that minimizes viewing interference with the displayed image in step <b>450</b>.</p>
    <p>In a preferred embodiment, viewing interference is minimized by positioning the overlay bar along an edge of the LCD screen <b>402</b> and by displaying the background of the bar translucently so that the user may see the image through the overlay bar. The overlay bar may also be displayed with a solid color background, but this is less desirable since the bar would overwrite that portion of the image.</p>
    <p>In response to the camera being placed into one of the operating modes, the overlay bar displays mode-specific information for the user in step <b>452</b>. In a preferred embodiment, the mode-specific information displayed on the overlay bar includes a combination of static status information, dynamically updated soft key labels, and interactive instructions pertaining to the particular mode, as described further below. After the mode-specific information is displayed, the mode-specific information is then dynamically updated during the operation of the camera to guide the user through a mode-specific function in step <b>454</b>.</p>
    <p>To more particularly describe the present invention, refer to FIGS. 7A and 7B illustrating the use of dynamic overlay bars on the LCD screen <b>402</b> during two different operating modes of the digital camera <b>110</b>. As shown, in a preferred embodiment of the present invention, two overlay bars <b>430</b> and <b>432</b> are simultaneously displayed on the LCD screen <b>402</b>, rather than one, to strike a balance between the amount of information provided to the user and the amount of screen area consumed by text and/or graphics.</p>
    <p>Overlay bar <b>430</b> may be used primarily to display status information and interactive instructions, while overlay bar <b>432</b> may be used primarily to display soft key labels <b>410</b> corresponding to soft keys <b>412</b>. Both overlay bars <b>430</b> and <b>432</b> may be turned-off in each of the camera operating modes by pressing the overlay “on/off” button <b>413</b> so that users can have an unobstructed view of images it they so choose (off), or extra help in operating the camera (on).</p>
    <p>Referring to FIG. 7A, the display of the overlay bars <b>430</b> and <b>432</b> on the LCD screen <b>402</b> during capture mode is shown. In capture mode, the camera <b>110</b> supports the actions of preparing to capture an image, and capturing an image through the use of either the LCD screen <b>402</b> alone or with the aid of an optional optical viewfinder (not shown).</p>
    <p>Overlay bar <b>430</b> is updated with capture status information during capture mode, which may include a graphic memory gauge, and text indicating the state of the camera (Ready), for example. The memory gauge provides the user with a constant overview of camera memory usage in terms of disk space, and may also show working memory usage. In a preferred embodiment, the memory bar displays disk space usage as segments filling-up, and displays working memory usage as the bar below those segments, which is constantly updated to reflect current memory status. When the working memory buffers are empty, the bottom part of the bar would be clear. When there is the equivalent of storage for only a few pictures left, the storage gauge may flash and the overlay bar <b>430</b> may be updated with a message, such as “Storage Almost Full”. If a user tries to take a picture without adequate storage, then the overlay bar <b>430</b> may be updated to reflect this status by displaying the message “Inadequate Storage,” along with an optional sound from the camera.</p>
    <p>The overlay bar <b>430</b> may also be updated to reflect other types of capture status information and may be expanded into additional lines if needed. The additional capture status information could include the following: 1) Low Battery Indication—when main batteries run low, a battery icon may replace the storage gauge and a overlay bar <b>430</b> may be updated to flash “Battery Low”; 2) Shake Warning Indication—when light level is too low for recommended hand held operation and user has disabled the strobe system “Shake Warning” may be displayed in the overlay bar <b>430</b>; and 3) No Focus Indication—when the focus system cannot adequately focus the camera lens, a “No Focus” may be displayed in the overlay bar <b>430</b>.</p>
    <p>Referring now to FIG. 7B, the display of the overlay bars <b>430</b> and <b>432</b> on the LCD screen <b>402</b> during play mode is shown. In a preferred embodiment, the play screen layout displays one full-sized image at a time and the user may chronologically scroll through the full-sized images in the LCD screen <b>402</b> using the left/right buttons on four-way navigation control button <b>409</b>. Users can also play back various media types, such as time-lapse, bursts and slide show images according to either default or user defined play back rates.</p>
    <p>In the play mode, overlay bar <b>430</b> displays status information relating to the current image being displayed, such as the image name/number, and the date and time of capture. The status information may also include graphical icons indicating what category of images the image belongs to and the image type.</p>
    <p>Referring to both FIGS. 7A and 7B, besides displaying status information, the second use of the dynamic overly bars of the present invention is to display soft key labels <b>410</b> for soft keys <b>412</b>. As described in U.S. patent application Ser. No. 08/939,993 filed on Sept. 26, 1997, entitled “A Method And System For Manipulating Images Stored In A Digital Imaging Device,” assigned to the present assignee and hereby incorporated by reference, soft keys <b>412</b> <i>a</i>, <b>412</b> <i>b</i>, and <b>412</b> <i>c</i>of the user interface <b>400</b> are programmable, i.e., they may be assigned predefined functions. The function currently assigned to a respective soft key <b>412</b> is indicated by the soft key labels <b>410</b> <i>a</i>, <b>410</b> <i>b</i>, and <b>410</b> <i>c </i>displayed in overlay bar <b>432</b>. After a soft key label <b>410</b> has been displayed, the user may then press the corresponding soft key <b>412</b> to have the function indicated by its label applied to the current image.</p>
    <p>Referring to FIG. 7B for example, the function assigned to the soft key <b>412</b> <i>b </i>in during play mode is a “Zoom” function, which allows a user to zoom in and out of a displayed image. When the user zooms-in on an image by pressing the soft key <b>412</b> <i>b</i>, the “Zoom” soft key label <b>410</b> <i>b </i>is changed to “Zoom-out”. While an image is zoomed, the user may pan around the image using the four-way control button <b>406</b>.</p>
    <p>The functions assigned to the soft keys <b>412</b>, and thus the soft key labels <b>410</b>, are changed in response to several different factors. The soft keys <b>412</b> may change automatically either in response to user actions, or based on predetermined conditions existing in the camera, such as the current operating mode, the image type, and so on. The soft keys <b>412</b> may also be changed manually by the user by pressing the menu button <b>415</b>. Providing programmable soft keys <b>412</b> increases the number of functions that may be performed by the camera, while both minimizing the number of buttons required on the user interface, and reducing the need to access hierarchical menus.</p>
    <p>As stated above, in addition to displaying status information and soft key labels, the dynamic overlay bars of the present invention may also be used to display interactive instructions to the user to guide user through camera functions. Basic types of camera functions include reviewing captured images, deleting images, annotating images with sound, and capturing groups of related images. With conventional cameras, the user would have to memorize complicated key sequences in order to perform these functions.</p>
    <p>The present invention, in contrast, uses the dynamic overlay bars to display interactive instructions that guide the user through operations such as adding sound to an image, deleting images and/or sound, and capturing groups of related images. As described in U.S. patent application Ser. No. 08/939,993, for example, after the user has captured an image and the image is displayed for review, the overlay bar <b>432</b> automatically reminds the user that he or she has the option to delete the image. That is, one of the soft key labels <b>410</b> is changed to “Delete” and the user may then delete image by pressing the corresponding “Delete” soft key <b>412</b>.</p>
    <p>Referring now to FIGS. 8A through 8C, diagrams illustrating how the overlay bars may be used to guide the user through a recording of a sound annotation are shown. The user may initiate the sound annotation function by pressing the record button <b>426</b> (see FIG. 5) while an image is displayed. In response, a record indication, such as a microphone icon, is automatically displayed in overlay bar <b>430</b> along with a display of the duration of the recording, as shown in FIG. <b>8</b>A. After the sound annotation is recorded, the soft key labels <b>410</b> may be updated to display three options “Play”, “Delete”, and “Save”; where “Play” plays back the recorded sound, “Delete” deletes the recorded sound, and “Save” saves the recorded sound.</p>
    <p>If the user is reviewing images in play or review modes, it is possible that the displayed image will have a sound annotation attached. Should the user presses the “Delete” soft key <b>412</b>, it is unclear what operation the user wishes to perform: delete the image, delete only the sound, or delete both. Indeed, an inexperienced user may not even consider all three of these possibilities before pressing the “Delete” button. Therefore, to guide the user through this operation, the dynamic overlay bars <b>430</b> and <b>432</b> are updated to prompt the user whether the image or the sound annotation is to be deleted, as shown in FIG. <b>8</b>B. The user may then indicate which is to be deleted by pressing the corresponding soft key <b>412</b>.</p>
    <p>While reviewing images, it is also possible that the user may press the record button <b>426</b>. If the current image already includes a sound annotation, then it is unclear whether the user wishes to record a new sound annotation over the old one, or whether the user is unaware of the existing sound annotation. Therefore, to make sure the user doesn't inadvertently overwrite the existing sound, the overlay bar <b>430</b> is automatically updated to inform the user that sound will not be recorded until the user deletes the existing sound, as shown in FIG. <b>8</b>C. In addition, if the user doesn't recall the contents of the previous sound annotation, the user may listen to it before deleting it by pressing “Play”, or the user may cancel the record operation altogether by pressing “Exit”. Thus, according to the present invention the user is enabled to perform complex tasks in the camera without fumbling through a set of hierarchical menus.</p>
    <p>Another use of displaying interactive instructions in the dynamic overlay bars <b>430</b> and <b>432</b> in accordance with the present invention is to direct the user through image capture sequences. The purpose of directed image capture sequences is to customize the camera's image capture process for a specific application. More specifically, a directed image capture is a camera feature that provides the user with interactive instructions and feedback during capture mode to guide the user through a series of task-oriented image captures.</p>
    <p>Upon initiation of a directed image capture sequence, interactive instructions are displayed the dynamic overlay bars <b>430</b> and <b>432</b> that prompt the user to perform specific operations (capture image or capture sound), and for prompting the user to enter specific input (name and date). Customized directed image captures can be tailored to specific professions, such as insurance claims adjusters and real estate agents, who would benefit from the use of a digital camera to capture groups of related pictures.</p>
    <p>Referring now to FIGS. 9A and 9B, diagrams illustrating example directed image capture screens are shown. The example shown in FIG. 9A may pertain to an insurance-related directed image capture that prompts an insurance claims adjuster to take a series of pictures of a damaged vehicle, or it may pertain to a real estate application that guides a user through taking photos of a house for sale.</p>
    <p>In the insurance example, once the directed image capture has started, the user may be instructed to take various views of the damaged car. The user may also be shown the number of the current image in that sequence, and the total number of images to be captured.</p>
    <p>After the views of the car are taken, the directed image capture may then prompt the user to enter specific information, such as the name of the image, as shown in FIG. <b>9</b>B. The user may then enter text by choosing letters using the four-way control button <b>409</b>. For insurance purposes, the directed image capture may also request the user to input the owner's name, license plate number, claim number, and so on. The sequence of images and corresponding information may then be downloaded from the camera or to a host computer for automated database storage or web page generation.</p>
    <p>In one embodiment of the present invention, one or more directed image capture sequences may be provided in the camera as built-in functions, especially if the camera is tailored for specific industries.</p>
    <p>However, in a second aspect of the present invention, the camera is made more flexible by implementing the directed image capture sequences as a set of program instructions that are externally loaded into the camera. Once loaded in the camera <b>110</b>, the instructions are then preferably executed by the GUI-based system software running on CPU <b>344</b>.</p>
    <p>FIG. 10 is a block diagram illustrating the contents of ROM <b>350</b> where the software is stored, and DRAM <b>346</b> where the software is executed. The software <b>600</b> may include a control application <b>602</b>, a toolbox <b>604</b>, drivers <b>612</b>, a kernel <b>614</b>, and a startup/configuration module <b>616</b>. The control application <b>602</b> is the main program that controls high-level functions of the digital camera and is responsible for interfacing with functions in the toolbox <b>604</b>.</p>
    <p>Toolbox <b>604</b> comprises selected function modules that control how the digital camera captures and manipulates images. The modules may include image processors <b>606</b>, a camera control shell <b>608</b>, and a script interpreter <b>610</b>. Image processors <b>606</b> are programs for enhancing (e.g., adjusting the contrast, sharpening, converting the image to gray-scale, etc.) the digital image received from imaging device <b>114</b>. Camera control shell <b>608</b> receives and processes data structures for controlling camera functions. Script interpreter <b>610</b> translates and executes script statements, which are used to provide the directed image capture sequences and other camera <b>110</b> features, as explained below.</p>
    <p>Drivers <b>612</b> comprise program instructions for controlling various camera <b>110</b> hardware components, such as motor <b>234</b> (FIG. 2) and a flash (not shown). Kernel <b>614</b> comprises program instructions providing basic underlying camera operating system services including synchronization routines, task creation, activation and deactivation routines, resource management routines, etc. Startup/configuration <b>616</b> comprises program instructions for providing initial camera <b>110</b> start-up routines such as the system boot routine and system diagnostics</p>
    <p>When the camera <b>110</b> is first turned on and booted up, the startup/configuration <b>616</b> module begins to execute and loads the drivers <b>612</b>, the kernel <b>614</b>, the control application <b>602</b>, and system files containing configuration information into DRAM <b>346</b>. Thereafter, operation of the camera is passed to the control application <b>602</b>. In an alternative embodiment, the software <b>600</b> may executed out of ROM <b>350</b> in order to reduce the size of DRAM <b>346</b>.</p>
    <p>The directed image capture sequence <b>618</b> may be loaded into the digital camera <b>110</b> from the removable memory <b>354</b> (FIG. <b>3</b>), a host computer, or a network, and stored in DRAM <b>346</b> to run in place of the control application <b>602</b>. In a preferred embodiment, the directed image capture sequence <b>618</b> is implemented using a script, which is a program written with text-based commands that may be easily written by the user. As used herein, a script may be written in any intrepreted language, such as Basic and Lisp, for example.</p>
    <p>Once loaded into the camera, the script may be selected by the user from a menu where it is displayed for selection, and is thereafter executed by the control application <b>602</b> by passing the script to the script interpreter <b>610</b>. The script interpreter <b>610</b> then translates and executes the script instructions comprising the directed image capture sequence <b>618</b> one-by-one.</p>
    <p>In an alternative embodiment, a directed image capture sequence <b>618</b> may be implemented as a traditional application program, rather than a script. However, an application program is typically written by a software developer in a traditional computer language, such as C++, compiled, and stored in machine language, which is a more complicated process than adding new functions to the camera via a text-based interpreted script.</p>
    <p>FIG. 11 is a flow chart illustrating an exemplary process of installing and running a script-based directed image capture in a preferred embodiment of the present invention. The process begins by inserting the removable memory <b>354</b> in step <b>700</b>. When the removable memory <b>354</b> is installed, the removable memory <b>354</b> is mounted by the operating system <b>600</b> in step <b>702</b>. Thereafter, the operating system searches for system files on the removable memory <b>354</b>, which alert the digital camera <b>110</b> to the presence of an external program, in step <b>704</b>.</p>
    <p>Any system files found on the removable memory <b>354</b> and corresponding directed image capture sequences <b>618</b> are then installed and made available to the user for selection via menu choices that appear on the LCD screen <b>402</b> in step <b>706</b>. In a preferred embodiment, steps <b>704</b> and <b>706</b> are implemented as a hot-mount process when the removable memory <b>354</b> is inserted into the camera <b>110</b>, as described in U.S. patent application Ser. No. 09/032385 entitled “Method And System For Dynamically Updating Software Functions In A Digital Capture Device (P149),” filed on Feb. 26, 1998, which is assigned to assignee of the present application and herein incorporated by reference.</p>
    <p>Once the list of available directed image capture sequences <b>618</b> are displayed, the user selects one of the directed image capture sequences <b>618</b> to run in step <b>708</b>. In a preferred embodiment, the list showing the available directed image capture sequences may be categorized in menus for easier selection. For example, assume a real estate agent has three different scripts for capturing images of different types of properties. The agent may name or create categories for the directed image capture sequences called “commercial”, “industrial”, and “residential”, for instance. Selecting the residential category, for example, will cause a list of directed image captures to be displayed that are designed to capture pictures of different types of residential properties, such as one, two, and three bedroom homes. The user may then select a desired script depending on the particular house to be shot.</p>
    <p>In one preferred embodiment, the directed image capture selections displayed in the menus may be erased from the camera by rebooting the camera, or by removing the removable memory <b>354</b> from the camera <b>110</b>.</p>
    <p>After the user selects one of the directed image capture sequences <b>618</b> to run, the script interpreter <b>610</b> begins interpreting the directed image capture sequence <b>618</b> in step <b>710</b>, and control is passed from the control application <b>602</b> to the script. In step <b>712</b>, the script interpreter <b>610</b> fetches the first command comprising the directed image capture sequence <b>618</b>.</p>
    <p>It is then determined whether the fetched command is a script “WaitForShutter” command in step <b>714</b>. This command causes control of the camera <b>110</b> to pass back to the control application <b>602</b> until the user presses the shutter button <b>418</b> to capture an image. The “WaitForShutter” command is preferably called with a quoted string parameter that is used in the dynamic overly bar <b>430</b> as the prompt to the user requesting an image capture (e.g., “Take photo of kitchen”).</p>
    <p>If the command is a “WaitForShutter” command in step <b>714</b>, then control is returned to the script after the user presses the shutter button <b>418</b> in step <b>716</b> to capture an image. If the fetched command is not a “WaitForShutter” command in step <b>714</b>, then the script interpreter <b>610</b> interprets and executes the command in step <b>718</b>.</p>
    <p>After the user presses the shutter button <b>418</b> or after a script command has been executed, it is determined if the end of the script has been reached in step <b>720</b>. If not, then the next command is fetched in step <b>712</b>, and the process continues until the end of the script is reached, at which point control is returned to the control application <b>602</b> in step <b>722</b>.</p>
    <p>Besides the “WaitForShutter” command, scripts may include two other categories of script commands. One category of commands pertain to camera settings, controls and other camera parameters specific to the subject and/or scene being captured. (ie: White Balance Modes, Exposure Modes, and Focus Modes). This category of commands enable users to input “Hints” optimizing the camera's photo systems for specific photographic conditions.</p>
    <p>The other category of commands may pertain to file system operations and image tagging functions specific to the way in which image data is stored in memory. (ie: Guided Capture, Prompted Text/Audio Annotation, and Automated Image Grouping/Cataloging/Indexing.) This category of commands is particularly useful when used in conjunction with desktop computer applications where the hosting application is coordinated to take advantage of the preformatted media organization and tag information. For example, while a directed image capture sequence guides the user though a series of steps to create an image grouping, the script commands comprising the sequence generate appropriate tags and data structures to group the images and text captured during the sequence.</p>
    <p>No matter whether the dynamic overlay bars of the present invention are used to display status information, soft key labels, or interactive instructions, as described herein, one important component affecting the user's experience is the method used to display the overlay bars on the image.</p>
    <p>One approach would be the follow prior art techniques for displaying text (e.g. image name) over an image. This approach typically includes the following steps: 1) fetching the image to be displayed, which is typically stored in JPEG format, 2) decompressing and resizing the image, 3) displaying the decompressed image block-by-block, and then after the image is fully displayed, 4) writing the text on top of the image.</p>
    <p>The problem with this method is that is visually unappealing to the user, and it reduces the performance of camera when the user turns-off the text display while viewing the image. The reason the method reduces camera performance is the following. When text or graphics are displayed over the image, they obscure a portion of the image. And when the text is turned-off, the obscured portions of the image must be displayed so that the original image is seen without the text. In order to do this, however, the entire JPEG image must be fetched and decompressed again so that the obscured portions of the image can be displayed on the LCD, which can be a time consuming operation.</p>
    <p>A third aspect of the present invention overcomes these disadvantages by providing an improved method and system for displaying the overlay bars that not only enhances the visual effect associated with the overlay bars, but also eliminates the need to re-decompress the JPEG image data when the user turns-off the overlay bars, thereby increasing performance of the camera.</p>
    <p>According to this aspect of the present invention, the overlay bars are displayed first, followed by the image, wherein the image is made to appear as though it is sliding underneath the overlay bars as it is being displayed. The image appears as though is it is sliding underneath the overlay bars because the image is displayed on the LCD screen <b>402</b> line-by-line or block-by-block (as used herein, a block may include anywhere from one line to sixteen lines of image data). As the display of the image progresses from the top of the screen <b>402</b>, the image therefore appears to be displayed behind the overlay bars <b>430</b> and <b>432</b> which are already present on the LCD screen <b>402</b>.</p>
    <p>The overlay bars <b>430</b> and <b>432</b> are also provided with a translucent background so that so that the overlay bars <b>430</b> and <b>432</b> themselves do not obscure the image, but the text is easily distinguishable from the colors of the displayed image. The result is that after the image has been displayed, the overlay bars appear as a separate layer over the image. Further, the portions of the original image that intersect with the overlay bars <b>430</b> and <b>432</b> are saved, so that when the user turns-off the overlay bars <b>430</b> and <b>432</b>, only these portions of the image are redisplayed to restore the image. Thus this aspect of the present invention eliminates the need to re-decompress and display the entire image again, thereby increasing system performance.</p>
    <p>Where typically, specialized hardware would be required to achieve the above-described effects, the present invention accomplishes the task through software and the manipulation of several memory buffers, as shown in FIG. <b>12</b>A.</p>
    <p>FIG. 12A is a diagram illustrating a buffer organization for displaying overlay bars, which in a preferred embodiment, resides in DRAM <b>346</b>. The buffer organization includes an overlay bar buffer <b>540</b>, a backstore buffer <b>542</b>, and a display buffer <b>544</b>. According to the present invention, the overlay bar buffer <b>540</b> is used to store the graphics data (graphics and text) that will be displayed in the overlay bars <b>430</b> and <b>432</b>. In a preferred embodiment the overlay bar buffer <b>540</b> is divided into a top and bottom portion, which store twenty lines of data each that correspond to the top and bottom overlay bar <b>430</b> and <b>432</b>, respectively.</p>
    <p>The backstore buffer <b>542</b> is used to store original image data corresponding to the area of the LCD screen <b>402</b> where the overlay bars <b>430</b> and <b>432</b> will be displayed. The backstore buffer <b>542</b> is also divided into a top and bottom portion that are the same size as the top and bottom portions of the overlay bar buffer <b>540</b>.</p>
    <p>As is typical in most rendering systems, the display buffer <b>544</b> is used to store the actual data that is to be displayed on the LCD. The data in the display buffer is accessed by LCD controller <b>390</b> (FIG. 3) and displayed on the LCD.</p>
    <p>FIG. 12B is a flow chart illustrating the process of displaying overlay bars on the LCD in accordance with the present invention. The first step in the process is to preferably receive an input line of decompressed image data from an image processing system in step <b>800</b>. The process may also be modified to receive an input block of decompressed image data. In a preferred embodiment, the image processing system for providing the input data may include an image decompressor for decompressing the image data, and a resizer for resizing the lines of image data to fit the size of LCD screen <b>402</b>.</p>
    <p>Next, it is determined whether the overlay bars <b>430</b> and <b>432</b> are turned-on or off in step <b>802</b>. If the overlay bars are turned-off, then the line of image data is copied directly to the display buffer <b>544</b> in step <b>804</b> for display on the LCD screen <b>402</b> and the process continues. If the overlay bars remain off for the duration of the time it takes to display the image line-by-line or block-by-block, then the entire image is displayed on the LCD screen <b>402</b> using only the display buffer <b>544</b>.</p>
    <p>If the overlay bars are turned-on in step <b>802</b>, then it is determined whether the line of data will be displayed within the area of the LCD screen <b>402</b> that is occupied by an overlay bar in step <b>806</b>. If the line is within an overlay bar, the line is copied into the backstore buffer <b>542</b> in step <b>808</b>. The purpose of copying the line to the backstore buffer <b>542</b> is to save the portion of the image that will be displayed underneath the overlay bars <b>430</b> and <b>432</b>.</p>
    <p>After the current line of image data is copied into the backstore buffer <b>542</b>, the corresponding line stored in the overlay bar buffer <b>540</b> is merged with the current line in the backstore buffer <b>542</b> in step <b>810</b>. The purpose of merging the two lines is to display the background of the overlay bars <b>430</b> and <b>432</b> translucently over the image on the LCD screen <b>402</b>. This is done by halving the luminance value of each pixel of the image data from the backstore buffer <b>542</b> that falls within the bounds of an overlay bar <b>430</b> or <b>432</b>, and overwriting each pixel in the line of image data that falls under a pixel of text or graphic data from the overlay bar buffer <b>540</b>. Halving the luminance value of the image data causes the colors of the image that overlap an overlay bar <b>430</b> or <b>432</b> to be half as bright, thus giving the overlay bar <b>430</b> or <b>432</b> a translucent appearance and allowing the user to see the image through the overlay bar <b>430</b> or <b>432</b>, as shown in FIG. <b>7</b>B. In an alternative embodiment, the translucency of the overlay bars <b>430</b> and <b>432</b> is provided by increasing, rather than decreasing, the luminance value of each image pixel falling within the area of an overlay bar. In this case, the text displayed in the overlay bars <b>430</b> and <b>432</b> is displayed using a dark color.</p>
    <p>As the line from the overlay bar buffer <b>540</b> is merged with the line from the backstore buffer <b>542</b>, the resulting merged line is written into the display buffer <b>544</b> for display in step <b>812</b>. If the current line is the last line of image data in step <b>814</b>, then the process ends. Otherwise the next line of image data is received in step <b>800</b> and the process continues. In an alternate embodiment of the present invention, the determination of whether the overlay bars <b>802</b> are on/off in step <b>802</b> may be performed after copying the input line to the backstore buffer <b>542</b> in step <b>8</b>. In this embodiment, the input line is copied into the backstore buffer <b>542</b> even when the overlay bars <b>430</b> and <b>432</b> are off.</p>
    <p>In a preferred embodiment of present invention, the software <b>600</b> controlling the digital camera <b>110</b> is implemented as event driven software, which responds to input from the user (select menu, press button, etc.) or other applications at unregulated times. When, for example, the user first switches to play mode and/or selects a new image to display, the first steps that are performed in the process are to blank the LCD screen <b>402</b>, fill the overlay bar buffer <b>540</b> with relevant mode-specific information, and then contents of the overlay bar buffer <b>540</b> and the backstore buffer <b>542</b> are merged and written to the display buffer <b>544</b>. In this case, the backstore buffer <b>542</b> may contain black or white pixel values to provide the blank screen. Thereafter, the process proceed as described in FIG. <b>13</b>.</p>
    <p>If the user turns-off the overlay bars <b>430</b> and <b>432</b> while an image is displayed, then the process is interrupted and software <b>600</b> copies the entire contents of the backstore buffer <b>542</b>, which contains the original image data, to the display buffer <b>544</b> for display. This causes the overlay bars to disappear from the LCD screen <b>402</b> and restores the original image without having to re-decompress and display the entire image over again.</p>
    <p>If the user then turns-on the overlay bars <b>430</b> and <b>432</b>, the software <b>600</b> merges the contents of the overlay bar buffer <b>540</b> and the backstore buffer <b>542</b> to provide the translucent bars and text over the image, and then copies the result to the display buffer <b>544</b> for display. This may be done by executing step <b>812</b> and <b>814</b> for each line of the data in the buffers <b>540</b> and <b>542</b>.</p>
    <p>Also, when the overlay bars <b>430</b> and <b>432</b> are on, if the overlay bars <b>430</b> and <b>432</b> are updated by the control application <b>602</b> due to a change in status or instructions, the contents of the overlay bar buffer <b>540</b> and the backstore buffer <b>542</b> are remerged and written into the display buffer <b>544</b> for display.</p>
    <p>A method and system for displaying overlay bars in a digital imaging device has been disclosed. The overlay bars enable a user to apply camera functions and features to images with minimum effort, while allowing for easy viewing of the image. In addition, the overlay bars are used to display interactive instructions to the user in the form of directed image capture to guide the user through complex task, without the need for help screens or for the user to remember complicated key sequences. Finally, the method and system used to display overlay bars eliminates the need to re-decompress and display the image when the user turns-off the overlay bars, which increases the responsiveness of the camera.</p>
    <p>Although the present invention has been described in accordance with the embodiments shown, one of ordinary skill in the art will readily recognize that there could be variations to the embodiments and those variations would be within the spirit and scope of the present invention. For example, the functions assigned to the soft keys, the number of soft keys, and the placement of the soft keys and labels in and around the display may vary. The method and system may also be implemented in digital imaging devices having only two modes, but that have multiple navigation screens within the “play mode” Accordingly, many modifications may be made by one of ordinary skill in the art without departing from the spirit and scope of the appended claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5949432">US5949432</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 11, 1997</td><td class="patent-data-table-td patent-date-value">Sep 7, 1999</td><td class="patent-data-table-td ">Apple Computer, Inc.</td><td class="patent-data-table-td ">Method and apparatus for providing translucent images on a computer display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6144362">US6144362</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 17, 1997</td><td class="patent-data-table-td patent-date-value">Nov 7, 2000</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image displaying and controlling apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6310648">US6310648</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 12, 1997</td><td class="patent-data-table-td patent-date-value">Oct 30, 2001</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">User interface for electronic image viewing apparatus</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6654559">US6654559</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 16, 2002</td><td class="patent-data-table-td patent-date-value">Nov 25, 2003</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6917373">US6917373</a></td><td class="patent-data-table-td patent-date-value">Dec 28, 2000</td><td class="patent-data-table-td patent-date-value">Jul 12, 2005</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Context sensitive labels for an electronic device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7030837">US7030837</a></td><td class="patent-data-table-td patent-date-value">Apr 24, 2000</td><td class="patent-data-table-td patent-date-value">Apr 18, 2006</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Auxiliary display unit for a computer system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7221378">US7221378</a></td><td class="patent-data-table-td patent-date-value">Mar 17, 2004</td><td class="patent-data-table-td patent-date-value">May 22, 2007</td><td class="patent-data-table-td ">Seiko Epson Corporation</td><td class="patent-data-table-td ">Memory efficient method and apparatus for displaying large overlaid camera images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7227511">US7227511</a></td><td class="patent-data-table-td patent-date-value">Dec 28, 2001</td><td class="patent-data-table-td patent-date-value">Jun 5, 2007</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method for activating an application in context on a remote input/output device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7248301">US7248301</a></td><td class="patent-data-table-td patent-date-value">May 2, 2003</td><td class="patent-data-table-td patent-date-value">Jul 24, 2007</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">System and method for providing camera focus feedback</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7265782">US7265782</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 1, 2003</td><td class="patent-data-table-td patent-date-value">Sep 4, 2007</td><td class="patent-data-table-td ">Casio Computer Co., Ltd.</td><td class="patent-data-table-td ">Image recording device with a post-recording function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7327396">US7327396</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 10, 2002</td><td class="patent-data-table-td patent-date-value">Feb 5, 2008</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Smart camera with a plurality of slots for modular expansion capability through a variety of function modules connected to the smart camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7379091">US7379091</a></td><td class="patent-data-table-td patent-date-value">Apr 30, 2003</td><td class="patent-data-table-td patent-date-value">May 27, 2008</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">Method and apparatus for computing an image stability measure</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7397500">US7397500</a></td><td class="patent-data-table-td patent-date-value">Apr 30, 2003</td><td class="patent-data-table-td patent-date-value">Jul 8, 2008</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">Camera shake warning and feedback system that teaches the photographer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7477267">US7477267</a></td><td class="patent-data-table-td patent-date-value">Nov 16, 2005</td><td class="patent-data-table-td patent-date-value">Jan 13, 2009</td><td class="patent-data-table-td ">Fuji Film Corporation</td><td class="patent-data-table-td ">Display apparatus and displaying method for the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7512901">US7512901</a></td><td class="patent-data-table-td patent-date-value">May 20, 2004</td><td class="patent-data-table-td patent-date-value">Mar 31, 2009</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Context sensitive labels for an electronic device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7532249">US7532249</a></td><td class="patent-data-table-td patent-date-value">Sep 18, 2007</td><td class="patent-data-table-td patent-date-value">May 12, 2009</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Smart camera with a plurality of slots for modular expansion capability through a variety of function modules connected to the smart camera</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7545342">US7545342</a></td><td class="patent-data-table-td patent-date-value">Jan 18, 2006</td><td class="patent-data-table-td patent-date-value">Jun 9, 2009</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Auxiliary display unit for a computer system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7602968">US7602968</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 17, 2006</td><td class="patent-data-table-td patent-date-value">Oct 13, 2009</td><td class="patent-data-table-td ">Nik Software, Inc.</td><td class="patent-data-table-td ">Overlaid graphical user interface and method for image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7646414">US7646414</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 10, 2006</td><td class="patent-data-table-td patent-date-value">Jan 12, 2010</td><td class="patent-data-table-td ">Olympus Optical Co., Ltd.</td><td class="patent-data-table-td ">Image pickup apparatus for generating wide dynamic range synthesized image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7755673">US7755673</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 28, 2001</td><td class="patent-data-table-td patent-date-value">Jul 13, 2010</td><td class="patent-data-table-td ">Fujifilm Corporation</td><td class="patent-data-table-td ">Audio file deleting method, apparatus and program and camera with audio reproducing function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7782384">US7782384</a></td><td class="patent-data-table-td patent-date-value">Nov 5, 2004</td><td class="patent-data-table-td patent-date-value">Aug 24, 2010</td><td class="patent-data-table-td ">Kelly Douglas J</td><td class="patent-data-table-td ">Digital camera having system for digital image composition and related method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7786952">US7786952</a></td><td class="patent-data-table-td patent-date-value">Jan 18, 2006</td><td class="patent-data-table-td patent-date-value">Aug 31, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Auxiliary display unit for a computer system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7791671">US7791671</a></td><td class="patent-data-table-td patent-date-value">Apr 19, 2009</td><td class="patent-data-table-td patent-date-value">Sep 7, 2010</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Smart camera with modular expansion capability including a function module that performs image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7882426">US7882426</a></td><td class="patent-data-table-td patent-date-value">Aug 9, 1999</td><td class="patent-data-table-td patent-date-value">Feb 1, 2011</td><td class="patent-data-table-td ">Cognex Corporation</td><td class="patent-data-table-td ">Conditional cell execution in electronic spreadsheets</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7970233">US7970233</a></td><td class="patent-data-table-td patent-date-value">Aug 12, 2010</td><td class="patent-data-table-td patent-date-value">Jun 28, 2011</td><td class="patent-data-table-td ">Nik Software, Inc.</td><td class="patent-data-table-td ">Distortion of digital images using spatial offsets from image reference points</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8004475">US8004475</a></td><td class="patent-data-table-td patent-date-value">Jan 18, 2006</td><td class="patent-data-table-td patent-date-value">Aug 23, 2011</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Auxiliary display unit for a computer system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8023031">US8023031</a></td><td class="patent-data-table-td patent-date-value">Feb 7, 2007</td><td class="patent-data-table-td patent-date-value">Sep 20, 2011</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image pickup apparatus with display apparatus, and display control method for display apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8064725">US8064725</a></td><td class="patent-data-table-td patent-date-value">Oct 10, 2009</td><td class="patent-data-table-td patent-date-value">Nov 22, 2011</td><td class="patent-data-table-td ">Nik Software, Inc.</td><td class="patent-data-table-td ">Distortion of digital images using spatial offsets</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8068162">US8068162</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 21, 2006</td><td class="patent-data-table-td patent-date-value">Nov 29, 2011</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">System and method of processing a digital image for user assessment of an output image product</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8243017">US8243017</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 12, 2006</td><td class="patent-data-table-td patent-date-value">Aug 14, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Menu overlay including context dependent menu icon</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8525787">US8525787</a></td><td class="patent-data-table-td patent-date-value">Aug 8, 2012</td><td class="patent-data-table-td patent-date-value">Sep 3, 2013</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Menu overlay including context dependent menu icon</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8599299">US8599299</a></td><td class="patent-data-table-td patent-date-value">Sep 21, 2011</td><td class="patent-data-table-td patent-date-value">Dec 3, 2013</td><td class="patent-data-table-td ">Intellectual Ventures Fund 83 Llc</td><td class="patent-data-table-td ">System and method of processing a digital image for user assessment of an output image product</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8625925">US8625925</a></td><td class="patent-data-table-td patent-date-value">Oct 12, 2009</td><td class="patent-data-table-td patent-date-value">Jan 7, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Distortion of digital images using spatial offsets from image reference points</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080062127">US20080062127</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 12, 2006</td><td class="patent-data-table-td patent-date-value">Mar 13, 2008</td><td class="patent-data-table-td ">Apple Computer, Inc.</td><td class="patent-data-table-td ">Menu overlay including context dependent menu icon</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN100591097C?cl=en">CN100591097C</a></td><td class="patent-data-table-td patent-date-value">Feb 15, 2007</td><td class="patent-data-table-td patent-date-value">Feb 17, 2010</td><td class="patent-data-table-td ">佳能株式会社</td><td class="patent-data-table-td ">Image pickup apparatus with display apparatus, and display control method for display apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1821520A1?cl=en">EP1821520A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 25, 2007</td><td class="patent-data-table-td patent-date-value">Aug 22, 2007</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image pickup apparatus with display apparatus, and display control method for display apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2487580A1?cl=en">EP2487580A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 7, 2007</td><td class="patent-data-table-td patent-date-value">Aug 15, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Menu overlay including context dependent menu icon</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S333020">348/333.02</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348SE05047">348/E05.047</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348S333110">348/333.11</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348SE05060">348/E05.06</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005278000">H04N5/278</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0001000000">H04N1/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005232000">H04N5/232</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/00384">H04N1/00384</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/0481">G06F3/0481</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/0035">H04N1/0035</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/0044">H04N1/0044</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F2203/04804">G06F2203/04804</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3273">H04N2201/3273</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3214">H04N2201/3214</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N5/278">H04N5/278</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3264">H04N2201/3264</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/00413">H04N1/00413</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2101/00">H04N2101/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3226">H04N2201/3226</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G09G5/377">G09G5/377</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F9/4446">G06F9/4446</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N5/23293">H04N5/23293</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=l7NdBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3215">H04N2201/3215</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N1/00D3D3</span>, <span class="nested-value">H04N1/00D3D4</span>, <span class="nested-value">G06F3/0481</span>, <span class="nested-value">H04N1/00D2K</span>, <span class="nested-value">G06F9/44W2</span>, <span class="nested-value">H04N1/00D</span>, <span class="nested-value">G09G5/377</span>, <span class="nested-value">H04N5/232V</span>, <span class="nested-value">H04N5/278</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jul 7, 2014</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 4, 2011</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-7 IS CONFIRMED. NEW CLAIMS 8-32 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 5, 2010</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 11, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100222</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 5, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20091002</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 7, 2006</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 27, 1998</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">FLASHPOINT TECHNOLOGY, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:RAMIREZ, MICHAEL A.;ANDERSON, ERIC C.;REEL/FRAME:009009/0630;SIGNING DATES FROM 19980226 TO 19980227</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1-VFjBCunj3zL3ZxMdCZNQskt8UA\u0026id=l7NdBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0Ekcjtm-CRAPzD0qfoDPlNXGUs6Q\u0026id=l7NdBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U0FBunugbXRTuZqfbp6hR72JPQk1Q","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_and_system_for_displaying_overlay.pdf?id=l7NdBAABERAJ\u0026output=pdf\u0026sig=ACfU3U1hs9on0_k8hqnYEG5EwMazctSWJw"},"sample_url":"http://www.google.com/patents/reader?id=l7NdBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>