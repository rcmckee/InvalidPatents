<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5434797 - Audio communication system for a computer network - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Audio communication system for a computer network"><meta name="DC.contributor" content="Robert C. Barris" scheme="inventor"><meta name="DC.contributor" content="Barris; Robert C." scheme="assignee"><meta name="DC.date" content="1994-10-20" scheme="dateSubmitted"><meta name="DC.description" content="A two-way audio communication system is designed to allow basic audio communication between two users on a common computer network. The audio communication system of the present invention is designed to work in the background of the computer, so the user can work on other software applications simultaneously. In a half-duplex embodiment (i.e., only one user can talk at a time), if at least two users try to talk at the same time, an arbitration scheme is employed to settle the dispute. The winner of the arbitration can send a message, and the loser&#39;s message is discarded. The communication system reduces the time delay between when a message is sent on one end, and received at the other. In addition, the system provides for high quality audio reproduction of the message on the other end by minimizing the number of audible gaps or other artifacts transmitted along with the message."><meta name="DC.date" content="1995-7-18" scheme="issued"><meta name="DC.relation" content="FR:2642248" scheme="references"><meta name="DC.relation" content="US:4503288" scheme="references"><meta name="DC.relation" content="US:4604686" scheme="references"><meta name="DC.relation" content="US:4987492" scheme="references"><meta name="DC.relation" content="US:5127003" scheme="references"><meta name="DC.relation" content="US:5148154" scheme="references"><meta name="DC.relation" content="US:5262875" scheme="references"><meta name="DC.relation" content="US:5269006" scheme="references"><meta name="citation_reference" content="Ades et al.; &quot;Voice Annotation and Editing in a Workstation Environment&quot;; Xerox Corp 1986."><meta name="citation_reference" content="Ades et al.; Voice Annotation and Editing in a Workstation Environment ; Xerox Corp 1986."><meta name="citation_reference" content="Ahuja et al; &quot;Networking Requirements of the Rapport Multimedia Conferencing System&quot;, IEEE 1988."><meta name="citation_reference" content="Ahuja et al; Networking Requirements of the Rapport Multimedia Conferencing System , IEEE 1988."><meta name="citation_reference" content="Grief et al; &quot;Data Sharing in Group Work&quot;; Laboratory for Computer Science, MIT/LCS/TM-316, 1986."><meta name="citation_reference" content="Grief et al; Data Sharing in Group Work ; Laboratory for Computer Science, MIT/LCS/TM 316, 1986."><meta name="citation_reference" content="Maxemchuk; &quot;An Experimental Speech Storage and Editing System&quot;; Bell System Tech J. vol. 59, No. 8, 1980."><meta name="citation_reference" content="Maxemchuk; An Experimental Speech Storage and Editing System ; Bell System Tech J. vol. 59, No. 8, 1980."><meta name="citation_reference" content="Ruiz; &quot;Voice and Telephony Applications for the Office Workstations&quot;. IEEE 1985."><meta name="citation_reference" content="Ruiz; Voice and Telephony Applications for the Office Workstations . IEEE 1985."><meta name="citation_reference" content="Swinehart et al; &quot;An Experimental Environment for Voice System Development&quot;; Xerox 1987."><meta name="citation_reference" content="Swinehart et al; An Experimental Environment for Voice System Development ; Xerox 1987."><meta name="citation_reference" content="Tannenbaum; &quot;Computer Networks&quot;; Prentice Hall 1981, pp. 292-295."><meta name="citation_reference" content="Tannenbaum; Computer Networks ; Prentice Hall 1981, pp. 292 295."><meta name="citation_reference" content="Terry et al; &quot;Managing Stored Voice in the Etherphone System&quot;; ACM 1987."><meta name="citation_reference" content="Terry et al; Managing Stored Voice in the Etherphone System ; ACM 1987."><meta name="citation_patent_number" content="US:5434797"><meta name="citation_patent_application_number" content="US:08/326,737"><link rel="canonical" href="http://www.google.com/patents/US5434797"/><meta property="og:url" content="http://www.google.com/patents/US5434797"/><meta name="title" content="Patent US5434797 - Audio communication system for a computer network"/><meta name="description" content="A two-way audio communication system is designed to allow basic audio communication between two users on a common computer network. The audio communication system of the present invention is designed to work in the background of the computer, so the user can work on other software applications simultaneously. In a half-duplex embodiment (i.e., only one user can talk at a time), if at least two users try to talk at the same time, an arbitration scheme is employed to settle the dispute. The winner of the arbitration can send a message, and the loser&#39;s message is discarded. The communication system reduces the time delay between when a message is sent on one end, and received at the other. In addition, the system provides for high quality audio reproduction of the message on the other end by minimizing the number of audible gaps or other artifacts transmitted along with the message."/><meta property="og:title" content="Patent US5434797 - Audio communication system for a computer network"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("9aftU7nvDvbDsQSahIHQCg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("NOR"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("9aftU7nvDvbDsQSahIHQCg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("NOR"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5434797?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5434797"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=iLU8BAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5434797&amp;usg=AFQjCNHtOhOBHb6EC-ZYFzOw6W3XL0LK8g" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5434797.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5434797.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5434797" style="display:none"><span itemprop="description">A two-way audio communication system is designed to allow basic audio communication between two users on a common computer network. The audio communication system of the present invention is designed to work in the background of the computer, so the user can work on other software applications simultaneously....</span><span itemprop="url">http://www.google.com/patents/US5434797?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5434797 - Audio communication system for a computer network</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5434797 - Audio communication system for a computer network" title="Patent US5434797 - Audio communication system for a computer network"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5434797 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/326,737</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Jul 18, 1995</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Oct 20, 1994</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jun 15, 1992</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/WO1993025973A1">WO1993025973A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08326737, </span><span class="patent-bibdata-value">326737, </span><span class="patent-bibdata-value">US 5434797 A, </span><span class="patent-bibdata-value">US 5434797A, </span><span class="patent-bibdata-value">US-A-5434797, </span><span class="patent-bibdata-value">US5434797 A, </span><span class="patent-bibdata-value">US5434797A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Robert+C.+Barris%22">Robert C. Barris</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Barris%3B+Robert+C.%22">Barris; Robert C.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5434797.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5434797.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5434797.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (8),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (16),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (34),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (11),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (7)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5434797&usg=AFQjCNGY4s5KVL4J1-45HAE-9gsSbRFI-Q">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5434797&usg=AFQjCNHfMn4pRT8EE4Ut6EOy883qLASnLA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5434797A%26KC%3DA%26FT%3DD&usg=AFQjCNEfb1hb2bUESsQu2_7Z87RERThlWg">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT53976168" lang="EN" load-source="patent-office">Audio communication system for a computer network</invention-title></span><br><span class="patent-number">US 5434797 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37444544" lang="EN" load-source="patent-office"> <div class="abstract">A two-way audio communication system is designed to allow basic audio communication between two users on a common computer network. The audio communication system of the present invention is designed to work in the background of the computer, so the user can work on other software applications simultaneously. In a half-duplex embodiment (i.e., only one user can talk at a time), if at least two users try to talk at the same time, an arbitration scheme is employed to settle the dispute. The winner of the arbitration can send a message, and the loser's message is discarded. The communication system reduces the time delay between when a message is sent on one end, and received at the other. In addition, the system provides for high quality audio reproduction of the message on the other end by minimizing the number of audible gaps or other artifacts transmitted along with the message.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(14)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-7.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-7.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-8.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-8.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-9.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-9.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-10.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-10.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-11.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-11.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-12.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-12.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-13.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-13.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5434797-14.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5434797-14.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(20)</span></span></div><div class="patent-text"><div mxw-id="PCLM4875045" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A computer station of a computer network, said computer station comprising:<div class="claim-text">a computer station network interface;</div> <div class="claim-text">a microphone;</div> <div class="claim-text">a speaker; and</div> <div class="claim-text">an audio communication system, said audio communication system comprising:</div> <div class="claim-text">an audio responsive input unit which accepts analog audio waveform signals from the microphone and digitizes the audio waveform signals;</div> <div class="claim-text">an audio output unit which converts digital audio waveform signals to analog audio waveform signals for audible output by the speaker; and</div> <div class="claim-text">a computer station controller configured to execute application programs of said computer station, said computer station controller coupled to said audio responsive input unit, to said audio output unit, and to said computer station network interface, said computer station controller configured to accept the digitized audio signals from said audio responsive input unit and to provide the signals in audio data packets for transmission via said computer station network interface over the computer network, said computer station controller further configured to accept audio data packets from said network via said computer station network interface and to transfer said audio data packets to said audio output unit, said computer station controller also managing the operations of the audio communication system while other application programs are actively executing in the computer station controller.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The computer station of claim 1, wherein said audio responsive unit comprises a sound activated audio responsive unit activated by audio signals to begin processing the audio data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The computer station of claim 1, wherein said audio responsive input unit further comprises an analog to digital convertor and a compressor, and wherein said audio output unit comprises a digital to analog convertor and an expander.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The computer station of claim 1, wherein said audio responsive input unit comprises a variable sensitivity audio responsive input unit which responds to signals from said controller to vary the sensitivity of the audio responsive unit to audio waveform signals from the microphone.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The computer station of claim 1, wherein said audio output unit comprises a variable volume level audio output unit which responds to signals from said controller to vary the volume level provided by the audio responsive unit to the speaker.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The computer station of claim 1, wherein said packets comprise a status field which contains data which reflects an operative communication state of the computer, an arbitration field which contains data which reflects an arbitration value, and an audio data field which contains compressed digital audio waveform data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The computer station of claim 6, wherein the controller further comprises an arbitration module which determines without handshaking, which of at least two computers in the computer network will continue to transmit audio data when said at least two computers simultaneously begin sending audio data.</div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8. A network computer station on a computer network, said computer station comprising:<div class="claim-text">a computer station controller:</div> <div class="claim-text">an audio output unit;</div> <div class="claim-text">an audio input unit; and</div> <div class="claim-text">an audio communication system, said audio communication system comprising:</div> <div class="claim-text">a user interface having a plurality of user selections;</div> <div class="claim-text">a computer station audio communication state data structure which contains a value indicative of one of a plurality of operative slates of the audio communication system;</div> <div class="claim-text">a main control block operating in said computer station controller which controls the overall operation of the two-way audio communication system, said main control block responsive to said user selections, said main control block further monitoring the state contained in the computer station audio communication state data structure, said main control block configured to operate while other systems are actively executing on said network computer station;</div> <div class="claim-text">a first network communication block which accepts audio data from said audio input hardware and indicates to the network that data is available for transmission; and</div> <div class="claim-text">a second network communication control block which accepts audio data transferred over the network and provides the data to the audio output hardware of the user station.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The computer station of claim 8, further comprising:<div class="claim-text">an audio input control block which accepts audio data from said audio input hardware, compresses the data, combines the data with the operative state of the network computer and provides the data to the first network communication control block; and</div> <div class="claim-text">an audio output control block which accepts audio data from said second network communication control block, wherein the data is compressed audio data, expands the compressed audio data and provides the data to the audio output hardware of the network computer.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The computer station of claim 8, wherein said user selections comprise a dial selection, an answer selection, a hang up selection, a louder selection, a softer selection, a more sensitive selection, a less sensitive selection, and an auto answer selection.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The computer station of claim 9, wherein each control block is an interrupt activated control block.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The computer station of claim 9, wherein each control block operates concurrently, and operates while application programs not associated with the communication system are actively executing in said network computer station.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The computer station of claim 9, wherein the audio input control block is activated upon detection of audio signal from the microphone.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The computer station of claim 9, wherein the compression occurs at a pre-selected ratio, said pre-selected ratio comprising a further user selection.</div>
    </div>
    </div> <div class="claim"> <div num="15" class="claim">
      <div class="claim-text">15. A method of carrying out audio communication between users of at least two computer stations in a computer network, said at least two computer stations having respective computer station controllers coupled to respective computer station network interfaces, said method comprising the steps of:<div class="claim-text">establishing a connection between the at least two computer stations on the network with a first of said at least two computer stations;</div> <div class="claim-text">receiving audio waveform input data at the first computer station via the first computer station network interface;</div> <div class="claim-text">digitizing said audio waveform data to obtain digital audio waveform data;</div> <div class="claim-text">generating a first random arbitration data value;</div> <div class="claim-text">in the first computer station controller, combining said digital audio waveform data with a communication state of the first station and with the random arbitration data value generated by said first station to form a digital audio data packet;</div> <div class="claim-text">transmitting the digital audio data packet over the network via the first computer station network interface to a second of said at least two computers on the network;</div> <div class="claim-text">receiving the audio data packet at said second computer station via the second computer station network interface;</div> <div class="claim-text">converting the digital audio data from the packet to analog form to obtain analog audio waveform data; and</div> <div class="claim-text">transferring the analog audio waveform data to a speaker to generate audible signals.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The method of claim 15, further comprising the steps of:<div class="claim-text">compressing said digital audio waveform data prior to combining said digital audio waveform data with the communication state and the random arbitration value; and</div> <div class="claim-text">expanding the digital audio data at said second computer station prior to converting the digital audio data from said packet to analog form.</div> </div>
    </div>
    </div> <div class="claim"> <div num="17" class="claim">
      <div class="claim-text">17. A computer station, said computer station comprising:<div class="claim-text">a computer station controller coupled to a computer station network interface;</div> <div class="claim-text">a microphone;</div> <div class="claim-text">a speaker; and</div> <div class="claim-text">an audio communication system, said audio communication system comprising:</div> <div class="claim-text">an audio responsive input unit which accepts analog audio waveform signals from the microphone and digitizes the audio waveform signals;</div> <div class="claim-text">an audio output unit which converts digital audio waveform signals to analog audio waveform signals for audible output by the speaker;</div> <div class="claim-text">a data storage system; and</div> <div class="claim-text">a computer station controller in communication with said audio responsive input unit, with said audio output unit, and with said data storage system, said computer station controller configured to accept the digitized audio signals from said audio responsive input unit and to store the digitized audio signals in the data storage system, said computer station controller also managing the operations of the audio communication system while other application programs are actively executing on the computer station.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. The computer station of claim 17, wherein the controller is further configured to retrieve the digitized audio signals from the data storage system and provide the digitized audio signals to the audio output unit.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The computer station of claim 17, wherein said audio responsive unit comprises a sound activated audio responsive unit activated by audio signals to begin processing the audio data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The computer station of claim 17, wherein the computer is a network computer and has a network interface, said controller further in communication with the network interface and configured to provide the audio signals in audio data packets for transmission over the computer network, and further configured to accept audio data packets from said network and to transfer said audio data packets to said audio output unit.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES66692492" lang="EN" load-source="patent-office" class="description">
    <p>This application is a continuation of application Ser. No. 07/898,827, filed Jun. 15, 1992, now abandoned.</p>
    <heading>FIELD OF THE INVENTION</heading> <p>The present invention relates to the field of audio communication, and more particularly to enabling audio communication between at least two users in a computer network.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>With the increased use of computer networks, many different media of communication between computer users are being explored. The most common of these media is a network messaging system such as electronic mail. These messaging systems eliminate some use of office memos, and encourage a paperless office by the more efficient use of the computer.</p>
    <p>These computer messaging systems have several drawbacks when two network users try to actively "communicate" with each other. First, conventional messaging systems require the user to exit his current task and enter the messaging program. Once in the messaging program, the user typically types the message, and sends the message via the network to one or more users. To review a message, the recipient also exits his current task, and enters the messaging program. Moreover, the delay between sending the message and receiving a reply (the reply delay) associated with computer messaging systems does not easily facilitate a "conversation" between two parties.</p>
    <p>Besides electronic mail, messaging systems exist which allow two or more users to connect and type messages to other users. However, typing messages through the computer lacks the personal nature of voice communication.</p>
    <p>Currently, there is software available for the Macintosh® which allows users on a network to speak with one another. However, each user must activate a button to transmit and also to end the transmission. The available software interposes a significant delay between when one user speaks and another user receives the voice communication. Moreover, the existing software requires the user to exit the current task in order to enter the voice communication application.</p>
    <p>Therefore, a need exists for a simple voice communication system for use within a computer network. The voice communication system should enable real-time, gapless audio "conversations" to occur across the computer network.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention comprises a two-way digital data audio communication system using digital data transmission over a shared channel to provide basic audio communication between two users on a common network. In the present embodiment, the communication between the two users is half-duplex (i.e., only one user can talk at a time). The half-duplex operation eliminates the need for echo cancellation and simplifies implementation for systems with audio hardware which is not capable of generating and receiving sound at the same time. Accordingly, in the present embodiment, if two users try to talk at the same time, the invention utilizes an arbitration scheme that does not require request-reply handshaking to occur between the two users' computers to determine which computer may continue transmissions of audio data.</p>
    <p>The communication system of the present invention advantageously utilizes compression of digitized audio data. The invention further provides a significant reduction in the time between the transmission and reception of a message as compared to the prior art. In addition, the system provides high quality audio reproduction of the message on the receiving end by minimizing the number of audible gaps or other artifacts transmitted along with the message. The audio communication system of the present invention is designed to operate as a background application. Thus, the user can execute other software programs simultaneously, yet preserve the necessary bandwidth for gap-free communication.</p>
    <p>In one embodiment, the system also comprises an audio data storage and retrieval feature. With this feature, one user may record audio data using the audio input hardware and store the audio data for later retrieval.</p>
    <p>One aspect of the present invention involves an audio communication system for use in a computer station of a computer network, the computer station having a network interface, a microphone and a speaker. The communication system has an audio responsive input unit which accepts analog audio waveform signals from the microphone and digitizes the audio waveform signals. An audio output unit converts the digital audio waveform signals to analog audio waveform signals for audible output by the speaker. The system has a controller coupled to the audio responsive input unit, to the audio output unit, and to the network interface. The controller is configured to accept the digitized audio signals from the audio input unit and to provide the signals in audio data packets for transmission over the computer network. The controller is further configured to accept audio data packets from the network and to transfer the audio data packets to the audio output unit. The controller manages the operations of the audio communication system without substantially interfering with other application programs operating on the computer. In other words, the system operates as a background application.</p>
    <p>In one embodiment, the audio responsive unit comprises a sound activated audio responsive unit activated by audio signals to begin processing the audio data.</p>
    <p>In a further embodiment, the audio communication system comprises a data storage and retrieval system and the controller is configured to accept the digitized audio signals from the audio input unit and store the audio signals in the data storage and retrieval system. The controller can then retrieve (at a later time) the audio signals from the data storage and retrieval system and transmit them over the network to another station or transfer the audio signals to the audio output unit for playback.</p>
    <p>Another aspect of the present invention involves a method of carrying out audio communication between users of at least two computer stations in a computer network. The method involves a number of steps. A connection is established between at least two computers on the network. Audio waveform input data is received at a first station and the audio waveform data is digitized to obtain digital audio waveform data. A first random arbitration value is generated and combined with the digital audio waveform data and a communication state of the first station to form a digital audio data packet. The digital audio data packet is transmitted over the network to a second of the at least two computers on the network. The audio data packet is received at the second computer station and converted into analog form to obtain analogy audio waveform data. The analog audio waveform data is transferred to a speaker to generate audible signals.</p>
    <p>In one embodiment, the method further involves compressing the digital audio waveform data prior to combining the digital audio waveform data with the communication state and the random arbitration value, and expanding the digital audio data at the second computer station prior to converting the digital audio data from the packet to analog form.</p>
    <p>Advantageously, the method of the present invention is carried out without substantially interfering with other application programs operating on the computers.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is a schematic view illustrating the hardware utilized by the present invention.</p>
    <p>FIG. 2 is a diagram of the audio input and audio output systems and illustrates the data flow for the messaging system.</p>
    <p>FIG. 3 is a flow chart illustrating the initialization operations of the audio communication system of the present invention.</p>
    <p>FIGS. 4-9 are flow charts illustrating the functions of the main control task for the present invention.</p>
    <p>FIG. 10 is a flow chart which illustrates the audio input task of the present invention.</p>
    <p>FIG. 11 is a flow chart which illustrates the audio output task of the present invention.</p>
    <p>FIG. 12 is a flow chart which illustrates the network transmission task of the present invention.</p>
    <p>FIG. 13 is a flow chart which illustrates the network reception task of the present invention.</p>
    <p>FIG. 14 illustrates exemplary menus for the present invention's user interface.</p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>The present invention comprises a two-way audio communication system within a computer network environment. Although the present invention can be used to transmit digital data over any shared channel, it is preferably used in a computer networking environment. Furthermore, although the present invention may be implemented over any type of network such as cabled, radio, cellular or other, the description which follows is for a conventional computer network connected via a cabling system, as is well known in the art. The present embodiment is also described for those Macintosh® computers which include microphones and speakers. However, the invention could be applied in any computer system with appropriate audio input and audio output capabilities. The audio input and audio output hardware need not be internal to the computer, but may be external peripherals as well.</p>
    <p>In the present embodiment, the communication between two parties using the system is half-duplex communication (i.e., only one station transmits at a time). Implementing the system as a half-duplex system eliminates many problems associated with feedback and echoing. In a half-duplex system, simpler audio hardware may be used, because the audio system does not require hardware to receive audio input and generate audio output simultaneously. Moreover, in a half-duplex system, it is not necessary to implement echo canceling and feedback canceling procedures. Simplifying the control of the system assists in maintaining the bandwidth necessary to provide real time communication between at least two computer users on the network.</p>
    <p>In order to provide a half-duplex system, the system control prevents the simultaneous continuous transmission of audio data from at least two different stations. Therefore, the present invention provides an arbitration procedure in the event that two or more users transmit audio data at the same time. The arbitration procedure allows each computer to determine which computer will transmit audio data and which computer will receive the audio data, when both computers begin transmission of audio data at the same time, without a request-reply handshake.</p>
    <heading>System Architecture</heading> <p>The overall system block diagram of the present embodiment is illustrated in FIG. 1. The system comprises at least two network stations 6, 7, 8 connected to a common network 10. Each network station comprises, in general, a CPU 12a, 12b, 12c equipped with a network interface 14a, 14b, 14c, a keyboard 16a, 16b, 16c, a mouse 17a, 17b, 17c, a display 18a, 18b, 18c, and an audio processing system 19a, 19b and 19n. The CPU 12a, 12b, 12c, advantageously comprises system memory (MEM) 13a, 13b, 13c, a mass data storage and retrieval system 15a, 15b, 15c (e.g., a hard disk system), and other conventional circuitry, as is well known in the art. The audio processing system 19, as illustrated in further detail in FIG. 2, comprises and audio input system 20 and audio output system 22. The audio input system 20 further comprises audio input hardware 24, an audio input first-in, first-out buffer (FIFO) 34, a compressor 38 and a network transmission FIFO 36. The audio input hardware 24 further comprises a sound sensitive microphone 22, an analog/digital (A/D) converter 32 and some data buffers 37. The audio output system 22 further comprises a network reception FIFO 42, a digital data expander 40, an audio output FIFO 41, and audio output hardware 26. The audio output hardware 26 further comprises some data buffers 45, a digital/analog (D/A) converter 46 and an audio speaker 20. In the present embodiment, the system utilizes the microphone 22, the A/D converter 32, the digital compressor 38, the digital expander 40, the D/A converter 46, and the speaker 20, provided with many Macintosh® computers. The audio input FIFO 34, the network transmission FIFO 36, the network reception FIFO 42, and the audio output FIFO 41, are advantageously configured in memory of each network station 6, 7, 8.</p>
    <p>In the present embodiment, the network comprises a Macintosh® based networking system. An appropriate network system for the present invention is advantageously capable of transmitting 2 Kbytes/second sustained between two stations. One typical Macintosh® network transmits up to 20 Kbytes/second sustained, which provides the capability of more than two stations (e.g., up to 10 stations) simultaneously utilizing the system of the present invention to carry on communications. Of course, other networking systems and other hardware configurations may also be utilized according to the present invention. In one embodiment, if the network has sufficient bandwidth to allow more than two computer stations to be connected at the same time, the messaging system may comprise a conference feature allowing more than two computers to connect to facilitate an audio conference.</p>
    <heading>The User Interface</heading> <p>Advantageously, the voice communication system is available on every network user station having the appropriate hardware and software. In the present embodiment, to enable the system on a computer, the user selects an icon on the screen which corresponds to the voice communication system of the present invention. This initiates operation of the system. The system may then execute as a background program, allowing the user to execute other application programs actively. Each computer or user station is considered a local station, and the other user stations on the network 10 are considered remote users. Advantageously, the communication system may be initiated at computer start-up so that each user does not have to initiate operation before he can be contacted by another user.</p>
    <p>When the system software of the present invention is executing, a variety of menus as illustrated in FIG. 14 are available to the user on the computer display 18 including a File menu 30, a Network menu 27, a Sound menu 28, and a Preferences menu 29. However, these menus need not appear continually on the screen but may be activated by a key sequence, as a pull-down menu, or by selecting the messaging system application window as the displayed window on the screen, as is well known in the art for application programs which operate as background applications.</p>
    <p>While the system is executing on any given station, it is not necessary for a connection to be present. To initiate a connection with another user, the Network menu is accessed with the appropriate key or menu, and a Dial function is selected. A window with a list of available users who are located at network computers (user stations) currently executing the messaging system appears on the screen. The initiator of the connection selects the name of the desired remote user connection. The messaging system then attempts to establish a connection with the selected remote user station. When the other user answers, conversation may begin. When one user attempts to contact another user, the user to be contacted will be alerted by a tone or by a message on the screen. To answer a connection request, the Preferences menu is accessed, and an Answer option is selected. The messaging system completes the network connection, and conversation may begin.</p>
    <p>If one user desires to eliminate the necessity to answer each time another user tries to establish a connection, the Preferences menu may be accessed, and an Auto Answer option selected. If this option is selected, each time one user tries to connect to another user, the messaging system of the local computer station where the Auto Answer option was selected automatically answers, without requiring that the user manually take the steps necessary to answer the connection request.</p>
    <p>The present invention also provides the capability of adjusting the sensitivity and sound levels of the computer system. This is provided by accessing the Sound menu. When two users initially establish a connection between their stations, the speaker volume and microphone (i.e., audio input hardware 24) sensitivity levels are automatically set to a medium level. The Sound menu provides several options to vary these parameters. The Louder option increases the speaker volume by a predetermined increment each time it is selected. The Softer option decreases the speaker volume by a predetermined increment each time it is selected. In one embodiment, the messaging system may display the current level of the speaker volume on the screen in a bar format when either the Louder or Softer options are selected.</p>
    <p>A Put On Hold option disables the audio input hardware 24 and the audio output hardware 26 for the corresponding station. In other words, the Put On Hold option causes the system to ignore any audio data received by the microphone 22 and to ignore audio data transmitted from the remote station. If the Put On Hold option is selected again, while the system is "on hold, "the hold function is disabled and the audio input and audio output for the station are once again enabled. The system may be configured to return the sensitivity and volume levels to the sensitivity and volume levels selected prior to selection of the Put On Hold option by the user. Alternatively, these levels may return to a medium level.</p>
    <p>The Sensitivity option allows the user to adjust the sensitivity of the audio input hardware 24. This allows a user to adjust the sensitivity to prevent continuous background noise from the surroundings from continually transmitting to a connected remote user. In addition, the sensitivity option allows selection of the sensitivity to meet the typical volume level of the user's voice. A more sensitive selection increases the sensitivity of the audio input hardware 24, so that the system will still transmit soft speech. For instance, a More Sensitive option may be selected when the user is soft spoken. The Less Sensitive option decreases the sensitivity of audio input from the microphone 22 so that the background noises are not processed and transmitted to a remote connection, and only sounds above the desired sensitivity level are transmitted by the system. For instance, the Less Sensitive option may be selected if the background noises in the office are loud. The Less Sensitive option and the More Sensitive option will decrease and increase, respectively, the sensitivity by one predetermined increment each time they are selected. The sensitivity level is advantageously displayed on the screen in a bar format when either of these two options are selected.</p>
    <p>In some instances, a user station may have audio output capabilities but no audio input hardware 24. A user may also not wish to utilize the audio input capabilities of the system. If a station does not have audio input hardware 24, but does have audio output hardware 26, the user may select a Listen Only option in the Preferences menu. This enables the audio output for the station so that the user may receive transmissions from another station.</p>
    <p>In an alternative embodiment, if a user does not wish to utilize the audio capabilities of the system to speak to another user, or does not have audio input hardware 24 available on his computer system, that user may select a Message option (not shown) in the Network menu. Selecting the Message option causes a message box to appear on the screen, and the user can send a typewritten message using the keyboard 16 to input a message on his computer. A message box then appears on the recipient's screen with the typewritten message displayed. The recipient may either answer by speaking or may use the Message option on his computer to reply.</p>
    <p>Once a communication link has been established between two user stations, the communication link remains active regardless of the execution of other programs on the computers. When one user wishes to communicate with the other linked user, the user only needs to begin talking, and the voice alone activates the transfer of audio data by the messaging system.</p>
    <p>When a user wishes to terminate a connection, the user accesses the Network menu and selects a Hang Up option. This terminates the connection, but the messaging system remains operational (ready to institute a connection). While the messaging system remains operational, the user may establish communication with another user without exiting an executing application program by accessing the Network menu, as explained above, and selecting the Dial option.</p>
    <p>To stop the messaging system's operation, (i.e., halt background execution of the system) the File menu is accessed, and a Quit option is selected. The Quit option halts program execution, and removes all messaging system menus from the computer screen. To restart the system software, the icon corresponding to the system software is re-selected as described above.</p>
    <p>In one embodiment, the compression ratio utilized by the messaging system is selectable by the user. For instance, as depicted in FIG. 14, the Preferences menu 29 may include a selection for No Compression, 3:1 (i.e., a three to one compression ratio), and 6:1 (i.e., a six to one compression ratio). Increasing the compression ratio reduces the necessary network bandwidth required by the messaging system, but degrades the sound quality.</p>
    <p>Once a communication link is established between two computers executing the messaging system on the network, the system operates in one of three modes: talking, listening, or idling. Talking indicates that the local computer is transmitting audio data to the remote user station; listening indicates that the user station is listening to messages from the remote user station; and idling means that the computer is waiting for audio input from the local user or waiting for a message from the remote user. The messaging system maintains six operative states which correspond to stages of these three modes: begin idling, idling, begin talking, talking, begin listening, and listening. Each of the possible software states is listed below followed by a corresponding binary value as assigned in the present embodiment. The binary value corresponding to the current state of the computer is stored in the CPU's memory as well as in a status field of audio data packets, as further explained below.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________State        Value      State     Value______________________________________"begin idling"        000        "idling"  001"begin talking"        010        "talking" 011"begin listening"        100        "listening"                             101______________________________________</pre>
    
    <p>As illustrated in the table, the binary values of the "begin" states all end in a zero, and the binary values of all of the active states end in a one. Therefore, to advance the state of the computer from a "begin" state to an active state, the software performs a logical OR of the "begin" state binary value with a 1. The system does not necessarily cycle through the states in a sequential order; rather, the main control of the system determines the subsequent state of the system by checking a number of variables. If a station is in a "begin" state and no variables change during the next iteration of the main control task, the system changes the state to the corresponding active state (by performing the logical OR function described). The main control task of the system is responsible for the transition from one state to another, among many other functions.</p>
    <p>In the present embodiment, the system moves audio data in data packets. A packet of data is a system defined data structure with a given storage capacity. The data packets of this system are defined to contain up to 100 bytes of digital data. Out of the available 100 bytes of data, at least two bytes of data are defined as fields in each data packet to hold status information. The remaining 98 bytes are reserved for digital audio data. In the present embodiment, the first byte of data in the data packet stores the state of the user station which sent the packet (i.e., the state of the station which generated the packet). The second byte of data in the data packet stores an arbitration value which is used to determine which computer will continue to transmit data if both computers attempt to transmit data at the same time.</p>
    <heading>Data Flow In The System</heading> <p>FIG. 2 schematically illustrates the flow of data in the messaging system. As illustrated in FIG. 1, each user has an audio processing system 19 which has audio input hardware 24 and audio output hardware 26. Therefore, each user may transmit or receive a message (packets of data) at any time. Audio input from a first user will be received by the microphone 22 for the station, and forwarded to the analog to digital (A/D) converter 32 to convert the analog microphone input data to digital information. Once the A/D converter 32 processes the data, the digital information is moved through buffers 37 to the audio input FIFO buffer 34. The digital data is then compressed using the compressor 38 to condense the data. In the present embodiment, the compressor 38 is provided with the Macintosh® computer. However, it should be understood that many acceptable compression algorithms, implemented in hardware and/or software, are available which could be used to perform the compression performed by compressor 38.</p>
    <p>Next the compressed information is combined in a packet with the state and arbitration value for the local computer. Each packet is then stored in the network transmission FIFO 36. The network transmission FIFO 36 and the audio input FIFO 34 are advantageously configured in memory of the CPU 12. In the present embodiment, each location of the network transmission FIFO 36 holds enough data for one packet (e.g., 100 bytes in the present invention).</p>
    <p>After a packet is stored in the network transmission FIFO 36, the message system indicates to the network that information is available in the network transmission FIFO 36 for transmission on the network. When the network is ready to move a data packet, the network removes a data packet from the network transmission FIFO 36, places each packet onto the network 10, and delivers the packet to a remote user station.</p>
    <p>Once the data is received by a the remote user station, it is sent through the audio output system 22 of the remote station where it is converted to audio waveforms to be played by the audio speaker 20. As explained above, the audio output system 22 comprises: a network reception FIFO 42, an expander 40, an audio output FIFO 41, Buffers 45, a digital to analog (D/A) converter 46, and an audio speaker 20. When the data packets are received by the audio output system 22, the data packet is stored in the network reception FIFO 42.</p>
    <p>A control task of the present invention periodically checks the network reception FIFO 42. In the present embodiment, the messaging system accumulates at least three or four packets of data in the network reception FIFO 42 before processing the packets. If the system determines that three or more packets are present in the network reception FIFO 42, the system begins processing the packets by expanding the audio data in the packets with the expander 40 and transferring the expanded data into the audio output FIFO 41. The messaging system also checks certain status fields in the packet. The expanded audio data transferred to the audio output FIFO 41 is then transferred, via the buffers 45, to the D/A converter 46. The D/A converter 46 converts the digital information back to analog data to which the speaker 20 responds. The data is then transferred from the D/A converter 46, and played on the audio speaker 20 for the user to hear.</p>
    <heading>System Control</heading> <p>In general, the control of the messaging system of the present invention involves a number of tasks.</p>
    <p>A main control task oversees the operation of each user station, deciding which state the user station is in at any given moment. The main control task also determines when to enable audio input and output, based on the local state of the user station.</p>
    <p>An audio input task periodically transfers successive time-ordered packets of audio waveform data from the input hardware (i.e., the microphone 22, A/D converter 32 and buffers 37) to the audio input FIFO 34 for later analysis and possible transmission. The audio input task would be analogous to a common microphone in an analog system and can be enabled or disabled by the main control task.</p>
    <p>An audio output task is the logical inverse of the audio input task and transfers successive time-ordered packets of audio waveform data from the audio output FIFO 41 to the audio output hardware 26 (i.e., the buffers 45, D/A converter 46 and the speaker 20). This task also can be enabled or disabled by the main control task.</p>
    <p>A network reception task monitors the connection with the remote machine and transfers incoming packets to the network reception FIFO 42 for analysis and possible output if audio data from the remote machine is included in the packet.</p>
    <p>A network transmission task monitors the network transmission FIFO 36 and transmits any packets contained in the transmission FIFO 36 to the remote machine via the established network communication link.</p>
    <p>All packets transmitted contain a copy of the local state and an arbitration value of the station that generated the packet so the remote user station can maintain information with respect to the activity occurring on the local machine. Although these tasks are explained below in sequential order, these tasks may execute concurrently once activated.</p>
    <heading>Initialization</heading> <p>Advantageously, the five principal tasks described above are not initiated until a connection is present between a local station and a remote station. Therefore, these tasks need not utilize computer time unless a connection is present. FIG. 3 illustrates the function of waiting until a connection is present until activating the communication tasks. In the flow chart of FIG. 3, a decision block 48 represents waiting for a connection between two stations. Once a connection is established, the messaging system activates and enables the main control task, the audio output task, the audio input task, the network transmission task and the network reception task, as represented in the action block 49.</p>
    <heading>Main Control Task</heading> <p>The main control task manages most of the functions of the system while a connection is present. The functions of the main control include, in general: determining the current state of the local station and the remote station if a connection is present, verifying that the local and remote stations are in compatible states, advancing the local station to a new state when warranted, and controlling the data flow between the two computers. Once the main control task is activated, it repeats continually until one of the two users terminates the connection.</p>
    <p>An example of the typical functions performed by the main control task are illustrated in the flow charts of FIGS. 4-9. The main control task begins at start block 50 (FIG. 4) and immediately proceeds to a first decision block 52. At the decision block 52, the messaging system verifies that a connection still exists between the local station and a remote station (i.e., verifies that neither of the users have terminated the connection). If a connection is not present, the program de-activates the communication tasks and waits for a connection to be established in the initialization routine of FIG. 3, as represented in an action block 53. Once a connection is verified, the program determines if data packets have been received from the remote user at a decision block 54. If data packets have been received in the network reception FIFO 42, the program processes the data packets at an action block 55. This process packets routine of the main control task is illustrated in additional detail in FIG. 6.</p>
    <p>At an action block 58 (FIG. 6), the remote state is read from the first status field of the newly received data packet and stored in a storage location (i.e., variable). The messaging system, at a decision block 60, then determines if the state of the remote system is "begin talking".</p>
    <p>If the remote system is begin talking, the arbitration value, which is stored in the second status byte of the data packet, is stored in the local system memory at an action block 62. Next, at decision block 64, the system checks to see if the audio output task (FIG. 11) is enabled. In the present embodiment, enabling a task does not mean that the task necessarily begins execution, but that a flag is set indicating to the task to carry forth its operations on the data the task normally operates upon. Likewise, disabling a task does not mean that the task halts execution, but that a flat is set indicating to the task to ignore data that the task would normally operate upon. As explained, the audio output task controls the transmission of the digital data which has been received in a data packet from the remote computer to the audio output hardware 26 of the local computer, and will be described in further detail below. If the audio output task is enabled, control continues to a decision block 68. If the audio output task is not enabled, then the system resets and enables the audio output task at action block 66 and then proceeds to a decision block 68. Resetting the audio output task means that the task ignores any old data and processes only newly incoming audio data.</p>
    <p>At the decision block 68, the system determines if the received data packet contains audio data in the packet. If the packet does not contain audio data, control proceeds to an action block 70 (FIG. 4). If the data packet does contain audio data, the audio data is expanded in the expander 40 and moved to the audio output FIFO 41 at an action block 69. The main control task then continues at the action block 70 (FIG. 4).</p>
    <p>At the action block 70, the state of the local computer is saved in a location of the computer's memory, referred to as the variable "S" for further reference. At an action block 72, the next state of the local computer is determined by ORing the present state with a 1. This will change any "begin" states to the corresponding active state, but will not affect active states.</p>
    <p>At a decision tree 74, the main control task executes different operations depending on the local computer state (S). Thus, at decision tree 74, the system makes a decision based on the state (S) of the local computer. If the local state (S) is "begin idling", the program advances to an action block 76 and disables the audio output task (of FIG. 11) of the local computer. Control then proceeds to an action block 78 where the system enables the audio input task (of FIG. 10) to receive input from the audio input hardware 24. The program then proceeds to the transmission handling operations illustrated in FIG. 9, as further described below.</p>
    <p>If the local state at a decision tree 74 is "begin listening", the program proceeds to the steps illustrated in FIG. 8, via the continuation block 80 (FIG. 8). At an action block 82, the program disables the audio input task (of FIG. 10) of the local computer to prevent an inadvertent attempt by the user to speak and listen at the same time.</p>
    <p>At a decision block 84, the program checks the state of the remote station which was stored in the local computer's memory. If the state of the remote computer is "begin idling", "idling", "begin listening" or "listening", the program proceeds to action block 86. At the action block 86, the main control sets the state of the local computer to "begin idling". The program then proceeds to the transmission handling operations (FIG. 9) discussed below. If at decision block 84, the remote computer is in either the "begin talking" or "talking" state, then control proceeds to a decision block 88. At the decision block 88, the system determines if the network reception FIFO 42 contains three or more packets of data. If the number of packets in the network reception FIFO 42 is less than three, control advances to an action block 89. At the action block 89, the local state is set to "begin listening", and control proceeds to the transmission handling operations of FIG. 9. If the number of packets in the FIFO 42 is three or greater, as determined in the action block 88, then the system enables the audio output task illustrated in FIG. 11, discussed in greater detail below. Control then proceeds to the transmission handling operations of FIG. 9.</p>
    <p>If at decision block 74 (FIG. 4), the local state is "idling", control proceeds to a decision block 92. At the decision block 92, the state of the remote computer (which was in the last packet received by the local computer from the remote computer) is checked. If the state of the remote computer is "begin listening" or "listening", the program proceeds directly to the transmission handling operations of FIG. 9. If the remote computer is in either the "begin idling" or "idling" states, control proceeds to a decision block 94. At the decision block 94, the system determines if there are data packets in the network transmission FIFO 36. If no packets are found in the network transmission FIFO 36, then the main control task proceeds to the transmission handling operations of FIG. 9. If the network transmission FIFO 36 contains data packets, control advances to an action block 96. At the action block 96, the main control task sets the local state to "begin talking", because the audio input hardware 24 of the local computer received audio input while it was "idling". After the local state is set to "begin talking", control proceeds to the transmission handling operations of FIG. 9.</p>
    <p>If at decision block 92, the state of the remote computer is either "begin talking" or "talking", the program advances to an action block 98. At the action block 98, the main control task sets the state of the local computer to "begin listening", because the remote computer sent a message to the local computer while the local computer was "idling" (i.e. waiting for some form of input) as determined at the decision block 74. After the state of the local computer has been set at the action block 98, control proceeds to the transmission handling operations of FIG. 9.</p>
    <p>If at decision block 74, the state of the local computer is "listening", control proceeds to the continuation flow chart of FIG. 5. In a decision block 100, the state of the remote computer is checked. If the state of the remote computer is either "begin talking" or "talking", control proceeds to the transmission handling task of FIG. 9. If at the decision block 100, the status of the remote computer is either "begin listening" or "listening", control proceeds to an action block 102. At the action block 102, the state of the local computer is set to "begin idling", as both the local computer and the remote computer are waiting to receive a message. The main control task then proceeds to the transmission handling operations of FIG. 9.</p>
    <p>If at decision block 100 the state of the remote computer is either "begin idling" or "idling", control proceeds to a decision block 104. At the decision block 104, the system checks to see if the audio output FIFO 41 is empty. If there is still data in the audio output FIFO 41, the program proceeds to the transmission handling operations as illustrated in FIG. 9, in order to process the remaining data. If the audio output FIFO 41 is empty, the local computer has finished processing data received from the remote computer, and the program proceeds to an action block 106. At the action block 106, the state of the local computer is set to "begin idling", and control proceeds to the transmission handling operations of FIG. 9.</p>
    <p>If at the action block 74, the state of the local computer is either "begin talking" or "talking", control advances to the steps illustrated in the continuation flow chart of FIG. 7, via a continuation block 108 (FIG. 7). At a decision block 110 (FIG. 7), the system determines if further data has been generated by the local audio input hardware 24. If no additional data has been generated, the main control task advances to an action block 112. At the action block 112, the local state is set to "begin idling", and the local main control task awaits either additional audio input through the microphone 22 or the receipt of a message from the remote computer. After setting the local state to "begin idling," the program proceeds to the transmission handling operations of FIG. 9.</p>
    <p>If at the decision block 110, further audio input is available from the audio input hardware 24, the program proceeds to a decision block 114. At the decision block 114, the main control task determines if the remote computer is in either the "begin talking" or the "talking" state. If the remote computer is not in either of these states, the local computer may continue to process the audio input from the audio input hardware 24. Control in the main control task then proceeds to the transmission handling task of FIG. 9. The audio input task, which manages audio input from the audio input hardware 24, is illustrated in FIG. 10 and will be described in greater detail below.</p>
    <p>If at decision block 114 (FIG. 7), the state of the remote computer is either "begin talking" or "talking", control proceeds to an action block 118. At the action block 118 the system performs arbitration. Arbitration is performed because the decision blocks have indicated that both the local user station and the remote user station are in the "begin talking" or "talking" states. This indicates that both stations have initiated a transmission of audio data at the same time. In this case, it is advantageous to perform arbitration in the half-duplex system to determine which computer will continue the transmission. However, performing a message-reply handshake would interpose an additional delay into the system. Therefore, the arbitration performed in the system of the present invention does not require a message-reply handshake.</p>
    <p>The arbitration entails the local computer comparing the arbitration value from the remote computer (which was stored when the last packet received the remote computer) to the arbitration value of the local computer (which was stored when the last packet transmitted from the local computer). These arbitration values are random numbers which are stored in each packet created for transmission to another computer. New random numbers are generated by a station whenever the station enters the begin talking state. If the local computer initiated the connection between the two users, then the random number for the local computer is an odd number; the remote random numbers will be generated as even numbers. If the remote computer initiated the connection, the random number for the local computer is an even number; and the remote random number generated will be an odd number. The random number from one machine is chosen to be even and the random number from the other machine is chosen to be odd to eliminate the chance of a tie when the two arbitration values are compared. Accordingly, in the action block 118, the arbitration number from the local computer is compared to the arbitration number from the remote computer. Control then proceeds to a decision block 120.</p>
    <p>If at the decision block 120, the arbitration number of the local computer is greater than the arbitration number from the remote computer, control proceeds to an action block 116, the data from the remote station is discarded by the local station. The main control task then proceeds to the transmission handling operations of FIG. 9. If at the decision block 120, the arbitration number from the remote computer is greater than the arbitration number from the local computer, control proceeds to an action block 122. Because the local computer lost the arbitration, the message that the local computer sent to the remote computer is discarded by the remote station, and the local user will have to try to send a new message, after the remote user finishes talking. At the action block 122, the state of the local computer is set to "begin listening", to enable the continued receipt of packets from by the remote computer. After the action block 122, the main control task advances to the transmission handling operations of FIG. 9.</p>
    <p>Each computer performs the same arbitration because each has received a packet from the other with the other's arbitration value. In that both the local and remote user stations will have the arbitration numbers which were stored in the last packet received and the last packet transmitted, the results of the arbitration will be the same for each user station. Therefore, each user station performs the same arbitration and determines the same answer to the arbitration without having to carry forth any further handshake or communication operation to determine which computer will proceed with further transmission. The user station that loses the arbitration enters the begin listening state, and the computer that wins the arbitration continues transmitting information, but does not process the packet received from the other user station that lost the arbitration. As long as the station that lost the arbitration remains in the listening state, it does not accept audio input from the user (because the audio input task will be disabled), but processes the audio data from the station that won the arbitration. Once the station that won the arbitration changes from the talking state back to the idling state and sends a packet to the station that lost the arbitration, the station that lost the arbitration (in the listening state) returns to the idling state and may again accept audio input from the user (because audio input will be enabled in the action block 78 (FIG. 4)).</p>
    <p>Although the arbitration number is stored in each packet created, as will be further explained below, a new arbitration number is only generated when a station enters the "begin talking" state.</p>
    <p>The transmission handling operations of FIG. 9 begin at a continuation block 124. At a decision block 126, the main control task determines if the local state has changed. If the local state has changed (since the last time through the transmission handling operations), control proceeds to an action block 128. If the local state has not changed, control proceeds to a decision block 130. At the decision block 130, the system determines if the audio input FIFO 34 contains any data. If the audio input FIFO 34 contains data, the main control task proceeds to the action block 128. If the audio input FIFO 34 does not contain data, control proceeds to a decision block 131. At the decision block 131, the system determines if the time elapsed since the last data packet was transmitted is greater than one second. If the time elapsed since transmission of the last data packet was more than one second, control advances to the action block 128. If the time elapsed since the transmission of the last data packet was less than one second, the main control returns to the start block 50 (FIG. 4).</p>
    <p>The decision blocks 126, 130 and 131 essentially provide that a packet will be transmitted if the local station has changed states, the audio input FIFO 34 contains additional audio data or the time elapsed since the last packet transmission is greater than one second. With respect to the last packet transmission being greater than one second, the system of the present invention sends a packet at least once every second from the local user station to the connected remote user station. The packet may contain no audio data, and may send a packet containing only the arbitration value and the local state. The remote computer, executing in the same program, likewise sends at least one packet every second to the local computer. In this manner a local station monitors the state of a connected remote station and will determine if the remote station has terminated the connection because the local station will receive no packets from the remote system for more than one second.</p>
    <p>At the action block 128, a new packet is prepared by configuring a new packet data structure. At an action block 132, the current local state of the computer is stored in the first status field of the new packet. At a decision block 134, the main control branches depending on the local state just stored in the packet. If the local computer is in the "begin talking" state, control advances to an action block 136. At the action block 136, the computer generates a new arbitration number (a random even or odd number). As explained, the arbitration number is used to settle a dispute with the remote computer, in the event that both stations try to send data (i.e., "talk", at the same time). As explained, the arbitration number is a random number that is generated by the local computer. The arbitration number is stored in each packet. The random number that is generated is stored as the current arbitration value, and control proceeds to an action block 140.</p>
    <p>If at decision block 134 the local computer is not in the "begin talking" state, control advances to a decision block 138 where the main control task determines if the local computer is in the "talking" state. If at the decision block 138, it is determined that the computer is not in the "talking" state, then control returns to the start block 50 of (FIG. 4). If the local computer is in the "talking" state, control proceeds to an action block 140. At the action block 140, the computer stores the current arbitration value in the second status field of the data packet. In general, if the local state is talking, a new arbitration value is not generated and the previous arbitration value is stored in the packet. In other words, a new arbitration value is only generated each time the local computer enters the "begin talking" state. That arbitration value remains unchanged until the local station again enters the "begin talking" state.</p>
    <p>At a decision block 142, the system determines if the audio input FIFO 34 is empty. If the audio input FIFO 34 is empty, the control proceeds to an action block 144. If the audio input FIFO 34 is not empty, control proceeds to an action block 146. At the action block 146, a block of audio data from the audio input FIFO 34 is compressed with the compressor 38 and stored in the audio storage portion of the data packet currently being created. The generated packet containing the local state, the local station arbitration value and the audio data, if available, is stored in the network transmission FIFO 36. The network transmission task (FIG. 12), which will be described in greater detail below, will initiate the transfer of the packet over the network. Control then proceeds to the start block 50 (FIG. 4). This cycle continues until at least one of the two users wishes to terminate the connection between the two computers.</p>
    <heading>The Audio Input Task</heading> <p>FIG. 10 illustrates the audio input task beginning at a start block 148. The audio input task is executed to transfer data from the audio input hardware 24 to the audio input FIFO 34. At a decision block 149 the audio input task determines if it is enabled (i.e., a flag indicates it is to process data). If it is not enabled, the audio input task does not process data. If the audio input task is enabled, control proceeds to a decision block 150, and the local computer determines if audio input data is available from the audio input hardware 24. If data is not available, control advances to a return block 158, and the audio input task repeats.</p>
    <p>If audio data is available, control advances to a decision block 152. At the decision block 152, the software verifies that the amplitude of audio input that is received exceeds the minimum amplitude threshold set by the local user. If the threshold was exceeded, the control advances to an action block 154. If the threshold was not exceeded, control proceeds to a decision block 156. At the decision block 156, the system determines if the amplitude threshold was exceeded within the last 0.5 seconds by previous data. If the amplitude threshold was recently exceeded, control advances to the action block 154. If the threshold was not recently exceeded, the data is discarded and control proceeds to the return block 158 and the audio input task repeats. At the action block 154, the audio data from the audio input hardware 24 is transferred to the audio input FIFO 34 for processing. Finally, control proceeds to the subroutine return block 158, and the audio input task repeats.</p>
    <heading>The Audio Output Task</heading> <p>FIG. 11 illustrates that the audio output task transfers data from the audio output FIFO 41 to the audio output hardware 26 (the Buffers 45, the D/A converter 45 and the speaker 20). The audio output task begins at start block 160 and control proceeds to a decision block 161. At the decision block 161, the audio output task determines if it is enabled, (i.e., a flag is set indicating that the task is to process data). If the audio output task is not enabled, it does not process data. If the audio output task is enabled, control proceeds to a decision block 162, and the system determines if the audio output FIFO 41 is empty. If the audio output FIFO 41 is empty, control advances to a return block 168, the audio output task repeats. If the audio output FIFO 41 is not empty, control advances to a decision block 164. At the decision block 164, the system determines if the audio output hardware 26 is ready to receive data. If the audio output hardware is not ready for data, the system proceeds to the return block 168, and the audio output task repeats. If the audio hardware is ready for data, control advances to an action block 166. At the action block 166, data is transferred from the audio output FIFO 41 to the audio output hardware 26. Control than advances to the return block 168, the audio output task repeats.</p>
    <heading>The Network Transmission Task</heading> <p>FIG. 12 illustrates the network transmission task which enables data onto the network. The network transmission task begins at start block 170 and its function is to transfer data packets from the network transmission FIFO 36 to the network. From the start block 170, the network transmission task begins at decision block 172 and determines if the network transmission FIFO 36 is empty. If the network transmission FIFO 36 is empty, control proceeds to a return block 178, and the network transmission task repeats. If the network transmission FIFO 36 is not empty, control advances to an action block 174. At the action block 174, the first data packet in the network transmission FIFO 36 is enabled onto the network 10, and is sent to the remote computer. This occurs by providing an indication to the network of the location of the data, the amount of data to be transferred and the destination. The network then retrieves the data and transfers the data over the network 10 to the destination. The network then provides an indication to the local control program (the network transmission task) that the data has been transferred. The network protocol is defined by the network interface, as is well known in the art. Then, at an action block 176, the packet which was transmitted from the network transmission FIFO 36 is removed from the FIFO 36. The data need not necessarily be removed from the FIFO 36, but an indicator or flag can be set indicating that the location in the FIFO 36 which contains the transmitted packet is available for a new packet. Control then proceeds to the return block 178, and the network transmission task repeats.</p>
    <heading>The Network Reception Task</heading> <p>The network reception task is illustrated in FIG. 13 and begins at the start block 180. The network reception task receives data from the network and transfers the data packets to the network reception FIFO 42 where the packets are maintained for processing. At a decision block 182, the system determines if a packet of data was received from a remote location. In general, the network indicates to the local computer that it has information from a remote location. The local station then accepts this data and the messaging system stores the packet in the network reception FIFO 42. If a data packet was not received from the network, control proceeds to a return block 186, and the network reception task repeats. If a data packet was received, control advances to an action block 184. At the action block 184, the data packet is transferred from the network 10 to the network reception FIFO 42. Control then advances to the return block 186, and the network reception task repeats.</p>
    <p>As explained above, the tasks described above advantageously execute as concurrently operating tasks in one embodiment. These tasks may also each be interrupt driven. For instance, in one embodiment, when the buffer 37 becomes full from audio data from the A/D converter 32, this signals an interrupt which activates the audio input task. An interrupt driven system has the advantage that it will operate effectively in a cooperative multitasking environment.</p>
    <p>Although the present invention has been described as a half-duplex system, the present invention could be implemented as a full-duplex communication system. A full-duplex system is capable of processing audio input from the user and transmitting that data to a remote station simultaneously with receiving data from the remote station and processing the data for output. In a full-duplex system, the arbitration explained above becomes unnecessary in that both stations may transmit and receive at the same time. However, in a full-duplex system, the system further requires additional bandwidth and comprises feedback control to prevent audio data playing on the speaker of one station from being accepted as input data at the same station. Advantageously, the full duplex system would also operate as a background application.</p>
    <p>The audio communication system of the present invention allows basic audio communication between at least two users on a common network. In addition, the audio communication system is designed to execute as a background application while the user works with other applications. The arbitration routine does not require handshaking to determine which user's message will be sent and which will be discarded if both users attempt to talk at the same time. This allows for a reduction in the time delay between when a message is sent from one station and received at another station, since there is no waiting for the receipt of a handshake before the data is sent. The system of the present invention sends the status information along with the data, and allows each computer to formulate an independent decision based on the status fields that are sent rather than using a handshaking architecture. Finally, the system provides for a high quality audio reproduction of the message by minimizing the number of audible gaps or other artifacts transmitted along with the message.</p>
    <p>One embodiment of the present invention may also comprise an audio data storage and retrieval feature. In other words, the audio data input by one user at one user station need not necessarily be played immediately to another connected user, but could be recorded in memory of the computer or on other mass storage media such as a disk storage and retrieval system. This would allow for later retrieval of the audio data by the same user or another user. This feature has uses such as voice mail, dictation, and many others.</p>
    <p>The present invention may be embodied in other specific forms without departing from its spirit or essential characteristics. The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is, therefore, indicated by the appended claims rather than the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4503288">US4503288</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 31, 1981</td><td class="patent-data-table-td patent-date-value">Mar 5, 1985</td><td class="patent-data-table-td ">Novation, Inc.</td><td class="patent-data-table-td ">Intelligent telephone</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4604686">US4604686</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 27, 1984</td><td class="patent-data-table-td patent-date-value">Aug 5, 1986</td><td class="patent-data-table-td ">Martin Marietta Corporation</td><td class="patent-data-table-td ">Associative data access method (ADAM) and its means of implementation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4987492">US4987492</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 28, 1987</td><td class="patent-data-table-td patent-date-value">Jan 22, 1991</td><td class="patent-data-table-td ">Stults Robert A</td><td class="patent-data-table-td ">User interface control for communication system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5127003">US5127003</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 11, 1991</td><td class="patent-data-table-td patent-date-value">Jun 30, 1992</td><td class="patent-data-table-td ">Simpact Associates, Inc.</td><td class="patent-data-table-td ">Digital/audio interactive communication network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5148154">US5148154</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 4, 1990</td><td class="patent-data-table-td patent-date-value">Sep 15, 1992</td><td class="patent-data-table-td ">Sony Corporation Of America</td><td class="patent-data-table-td ">Multi-dimensional user interface</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5262875">US5262875</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 30, 1992</td><td class="patent-data-table-td patent-date-value">Nov 16, 1993</td><td class="patent-data-table-td ">Instant Video Technologies, Inc.</td><td class="patent-data-table-td ">Audio/video file server including decompression/playback means</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5269006">US5269006</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 8, 1992</td><td class="patent-data-table-td patent-date-value">Dec 7, 1993</td><td class="patent-data-table-td ">Micral, Inc.</td><td class="patent-data-table-td ">Method and apparatus for arbitrating access to a microprocessor having real and protected modes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=iLU8BAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DFR%26NR%3D2642248A1%26KC%3DA1%26FT%3DD&amp;usg=AFQjCNEkG1SAOfrKupfTmPfCF9m4ZBiD1w">FR2642248A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Ades et al.; "<a href='http://scholar.google.com/scholar?q="Voice+Annotation+and+Editing+in+a+Workstation+Environment"'>Voice Annotation and Editing in a Workstation Environment</a>"; Xerox Corp 1986.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Ades et al.; Voice Annotation and Editing in a Workstation Environment ; Xerox Corp 1986.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Ahuja et al; "<a href='http://scholar.google.com/scholar?q="Networking+Requirements+of+the+Rapport+Multimedia+Conferencing+System"'>Networking Requirements of the Rapport Multimedia Conferencing System</a>", IEEE 1988.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Ahuja et al; Networking Requirements of the Rapport Multimedia Conferencing System , IEEE 1988.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Grief et al; "<a href='http://scholar.google.com/scholar?q="Data+Sharing+in+Group+Work"'>Data Sharing in Group Work</a>"; Laboratory for Computer Science, MIT/LCS/TM-316, 1986.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Grief et al; Data Sharing in Group Work ; Laboratory for Computer Science, MIT/LCS/TM 316, 1986.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Maxemchuk; "<a href='http://scholar.google.com/scholar?q="An+Experimental+Speech+Storage+and+Editing+System"'>An Experimental Speech Storage and Editing System</a>"; Bell System Tech J. vol. 59, No. 8, 1980.</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Maxemchuk; An Experimental Speech Storage and Editing System ; Bell System Tech J. vol. 59, No. 8, 1980.</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Ruiz; "<a href='http://scholar.google.com/scholar?q="Voice+and+Telephony+Applications+for+the+Office+Workstations"'>Voice and Telephony Applications for the Office Workstations</a>". IEEE 1985.</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Ruiz; Voice and Telephony Applications for the Office Workstations . IEEE 1985.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Swinehart et al; "<a href='http://scholar.google.com/scholar?q="An+Experimental+Environment+for+Voice+System+Development"'>An Experimental Environment for Voice System Development</a>"; Xerox 1987.</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Swinehart et al; An Experimental Environment for Voice System Development ; Xerox 1987.</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Tannenbaum; "<a href='http://scholar.google.com/scholar?q="Computer+Networks"'>Computer Networks</a>"; Prentice Hall 1981, pp. 292-295.</td></tr><tr><td class="patent-data-table-td ">14</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Tannenbaum; Computer Networks ; Prentice Hall 1981, pp. 292 295.</td></tr><tr><td class="patent-data-table-td ">15</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Terry et al; "<a href='http://scholar.google.com/scholar?q="Managing+Stored+Voice+in+the+Etherphone+System"'>Managing Stored Voice in the Etherphone System</a>"; ACM 1987.</td></tr><tr><td class="patent-data-table-td ">16</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Terry et al; Managing Stored Voice in the Etherphone System ; ACM 1987.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5519641">US5519641</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 20, 1994</td><td class="patent-data-table-td patent-date-value">May 21, 1996</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and apparatus for configuring plural multimedia audio cards as a local area network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5572677">US5572677</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 4, 1994</td><td class="patent-data-table-td patent-date-value">Nov 5, 1996</td><td class="patent-data-table-td ">Canon Information Systems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for conversing over a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5592398">US5592398</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 9, 1994</td><td class="patent-data-table-td patent-date-value">Jan 7, 1997</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Multiple channel multiplexing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5745380">US5745380</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 6, 1995</td><td class="patent-data-table-td patent-date-value">Apr 28, 1998</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Priority controlled transmission of multimedia streams via a telecommunication line</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5825771">US5825771</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 10, 1994</td><td class="patent-data-table-td patent-date-value">Oct 20, 1998</td><td class="patent-data-table-td ">Vocaltec Ltd.</td><td class="patent-data-table-td ">Audio transceiver</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5878214">US5878214</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 10, 1997</td><td class="patent-data-table-td patent-date-value">Mar 2, 1999</td><td class="patent-data-table-td ">Synectics Corporation</td><td class="patent-data-table-td ">Computer-based group problem solving method and system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5963217">US5963217</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 18, 1996</td><td class="patent-data-table-td patent-date-value">Oct 5, 1999</td><td class="patent-data-table-td ">7Thstreet.Com, Inc.</td><td class="patent-data-table-td ">Network conference system using limited bandwidth to generate locally animated displays</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6028917">US6028917</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 4, 1997</td><td class="patent-data-table-td patent-date-value">Feb 22, 2000</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Access to extended telephone services via the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6108704">US6108704</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 25, 1995</td><td class="patent-data-table-td patent-date-value">Aug 22, 2000</td><td class="patent-data-table-td ">Netspeak Corporation</td><td class="patent-data-table-td ">Point-to-point internet protocol</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6167033">US6167033</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 15, 1998</td><td class="patent-data-table-td patent-date-value">Dec 26, 2000</td><td class="patent-data-table-td ">Inventec Corp.</td><td class="patent-data-table-td ">Multiple-party network communication system and method of troubleshooting thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6185184">US6185184</a></td><td class="patent-data-table-td patent-date-value">Sep 25, 1996</td><td class="patent-data-table-td patent-date-value">Feb 6, 2001</td><td class="patent-data-table-td ">Netspeak Corporation</td><td class="patent-data-table-td ">Directory server for providing dynamically assigned network protocol addresses</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6226678">US6226678</a></td><td class="patent-data-table-td patent-date-value">Sep 25, 1996</td><td class="patent-data-table-td patent-date-value">May 1, 2001</td><td class="patent-data-table-td ">Netspeak Corporation</td><td class="patent-data-table-td ">Method and apparatus for dynamically defining data communication utilities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6243376">US6243376</a></td><td class="patent-data-table-td patent-date-value">Nov 3, 1997</td><td class="patent-data-table-td patent-date-value">Jun 5, 2001</td><td class="patent-data-table-td ">Mediaring.Com Ltd.</td><td class="patent-data-table-td ">Method and apparatus for making a phone call connection over the internet connection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6278704">US6278704</a></td><td class="patent-data-table-td patent-date-value">Apr 4, 1997</td><td class="patent-data-table-td patent-date-value">Aug 21, 2001</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Extended telephone services via telephone lines shared for standard telephony and internet access</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6332153">US6332153</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 31, 1996</td><td class="patent-data-table-td patent-date-value">Dec 18, 2001</td><td class="patent-data-table-td ">Vocaltec Communications Ltd.</td><td class="patent-data-table-td ">Apparatus and method for multi-station conferencing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6373835">US6373835</a></td><td class="patent-data-table-td patent-date-value">Aug 13, 1997</td><td class="patent-data-table-td patent-date-value">Apr 16, 2002</td><td class="patent-data-table-td ">Ede Phang Ng</td><td class="patent-data-table-td ">Method and apparatus for making a phone call connection over an internet connection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6381320">US6381320</a></td><td class="patent-data-table-td patent-date-value">Apr 14, 1999</td><td class="patent-data-table-td patent-date-value">Apr 30, 2002</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Access to extended telephone services via the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6466550">US6466550</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 11, 1998</td><td class="patent-data-table-td patent-date-value">Oct 15, 2002</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Distributed conferencing system utilizing data networks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6687738">US6687738</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 30, 1999</td><td class="patent-data-table-td patent-date-value">Feb 3, 2004</td><td class="patent-data-table-td ">Netspeak Corporation</td><td class="patent-data-table-td ">Establishing an internet telephone call using e-mail</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6970926">US6970926</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 3, 2000</td><td class="patent-data-table-td patent-date-value">Nov 29, 2005</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Dispatch call server in a packet based communication network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7000106">US7000106</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 26, 1999</td><td class="patent-data-table-td patent-date-value">Feb 14, 2006</td><td class="patent-data-table-td ">Siemens Communications, Inc.</td><td class="patent-data-table-td ">Methods and apparatus for kernel mode encryption of computer telephony</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7124167">US7124167</a></td><td class="patent-data-table-td patent-date-value">Jan 17, 2001</td><td class="patent-data-table-td patent-date-value">Oct 17, 2006</td><td class="patent-data-table-td ">Alberto Bellotti</td><td class="patent-data-table-td ">Computer based system for directing communications over electronic networks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7149208">US7149208</a></td><td class="patent-data-table-td patent-date-value">Sep 25, 1996</td><td class="patent-data-table-td patent-date-value">Dec 12, 2006</td><td class="patent-data-table-td ">Net2Phone, Inc.</td><td class="patent-data-table-td ">Method and apparatus for providing caller identification based responses in a computer telephony environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7216348">US7216348</a></td><td class="patent-data-table-td patent-date-value">Jan 4, 2000</td><td class="patent-data-table-td patent-date-value">May 8, 2007</td><td class="patent-data-table-td ">Net2Phone, Inc.</td><td class="patent-data-table-td ">Method and apparatus for dynamically balancing call flow workloads in a telecommunications system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7945025">US7945025</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 8, 2007</td><td class="patent-data-table-td patent-date-value">May 17, 2011</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Telephony based remote location monitoring</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7983199">US7983199</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 6, 2002</td><td class="patent-data-table-td patent-date-value">Jul 19, 2011</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Voice over internet protocol push-to-talk communication system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE40634">USRE40634</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 2006</td><td class="patent-data-table-td patent-date-value">Feb 10, 2009</td><td class="patent-data-table-td ">Verint Americas</td><td class="patent-data-table-td ">Voice interaction analysis module</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE41534">USRE41534</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 2006</td><td class="patent-data-table-td patent-date-value">Aug 17, 2010</td><td class="patent-data-table-td ">Verint Americas Inc.</td><td class="patent-data-table-td ">Utilizing spare processing capacity to analyze a call center interaction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE43183">USRE43183</a></td><td class="patent-data-table-td patent-date-value">Jun 28, 2006</td><td class="patent-data-table-td patent-date-value">Feb 14, 2012</td><td class="patent-data-table-td ">Cerint Americas, Inc.</td><td class="patent-data-table-td ">Signal monitoring apparatus analyzing voice communication content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE43255">USRE43255</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 2006</td><td class="patent-data-table-td patent-date-value">Mar 20, 2012</td><td class="patent-data-table-td ">Verint Americas, Inc.</td><td class="patent-data-table-td ">Machine learning based upon feedback from contact center analysis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE43324">USRE43324</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 2006</td><td class="patent-data-table-td patent-date-value">Apr 24, 2012</td><td class="patent-data-table-td ">Verint Americas, Inc.</td><td class="patent-data-table-td ">VOIP voice interaction monitor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE43386">USRE43386</a></td><td class="patent-data-table-td patent-date-value">Oct 19, 2006</td><td class="patent-data-table-td patent-date-value">May 15, 2012</td><td class="patent-data-table-td ">Verint Americas, Inc.</td><td class="patent-data-table-td ">Communication management system for network-based telephones</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1998004989A1?cl=en">WO1998004989A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 30, 1997</td><td class="patent-data-table-td patent-date-value">Feb 5, 1998</td><td class="patent-data-table-td ">Vocaltec Communications Ltd</td><td class="patent-data-table-td ">Apparatus and method for multi-station conferencing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1998018238A1?cl=en">WO1998018238A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 15, 1997</td><td class="patent-data-table-td patent-date-value">Apr 30, 1998</td><td class="patent-data-table-td ">David W Mcelvaney</td><td class="patent-data-table-td ">Internet telephony device</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc709/defs709.htm&usg=AFQjCNFBXWYqUOVuuxerz7B8cqt9daJk7Q#C709S204000">709/204</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc709/defs709.htm&usg=AFQjCNFBXWYqUOVuuxerz7B8cqt9daJk7Q#C709S225000">709/225</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04M0009000000">H04M9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04L0012640000">H04L12/64</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L2012/6481">H04L2012/6481</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04M9/001">H04M9/001</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L12/6418">H04L12/6418</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=iLU8BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L12/64">H04L12/64</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04M9/00A</span>, <span class="nested-value">H04L12/64</span>, <span class="nested-value">H04L12/64B</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Sep 2, 2008</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1, 6, 8 AND 17 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 2-5, 7, 9-16 AND 18-20, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. NEW CLAIMS 21-32 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 16, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 28, 2006</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20051025</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 10, 2004</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">2-WAY COMPUTING, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BUNN, DANIEL W.;MONROE, CRAIG L.;REEL/FRAME:015302/0986;SIGNING DATES FROM 20030930 TO 20031008</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">2-WAY COMPUTING, INC. 4660 LA JOLLA VILLAGE DRIVES</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BUNN, DANIEL W. /AR;REEL/FRAME:015302/0986;SIGNING DATESFROM 20030930 TO 20031008</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 14, 2003</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 3, 1998</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 19, 1996</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U2QqnAWEYKog187EtwNjxQCePMkuQ\u0026id=iLU8BAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U2oXBbGMv6YOSDTjoJ1HVkZ3dRq8g\u0026id=iLU8BAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U3vaT8tOgIwvHv_X419IjJA3vR9VA","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Audio_communication_system_for_a_compute.pdf?id=iLU8BAABERAJ\u0026output=pdf\u0026sig=ACfU3U0Il9yAa-FbM_zNyGFrzwBuODnzXA"},"sample_url":"http://www.google.com/patents/reader?id=iLU8BAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>