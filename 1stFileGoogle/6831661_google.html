<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US6831661 - Projection display apparatus, display method for same and image display ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Projection display apparatus, display method for same and image display apparatus"><meta name="DC.contributor" content="Takafumi Itoh" scheme="inventor"><meta name="DC.contributor" content="Shoichi Akaiwa" scheme="inventor"><meta name="DC.contributor" content="Seiko Epson Corporation" scheme="assignee"><meta name="DC.date" content="2000-8-3" scheme="dateSubmitted"><meta name="DC.description" content="The present invention provides a technology that enables related portions of multiple pages of images to be displayed simultaneously. A projection display apparatus comprises: an image extraction section that extracts at least a portion of given first image data as an extraction image; an extraction image memory for storing extraction image data representing the extraction image; an image overlay section that generates overlaid image data by superimposing the extraction image on an original image represented by given second image data; a light modulation unit that is driven responsive to the overlaid image data pixel by pixel; and an optical system for projecting onto the screen the overlaid image obtained by the light modulation unit. A projection display apparatus can display related portions of multiple pages of images simultaneously."><meta name="DC.date" content="2004-12-14" scheme="issued"><meta name="DC.relation" content="JP:H04168478" scheme="references"><meta name="DC.relation" content="JP:H04205476" scheme="references"><meta name="DC.relation" content="JP:H04284495" scheme="references"><meta name="DC.relation" content="JP:H05183853" scheme="references"><meta name="DC.relation" content="JP:H0546135" scheme="references"><meta name="DC.relation" content="JP:H06295339" scheme="references"><meta name="DC.relation" content="JP:H0686165" scheme="references"><meta name="DC.relation" content="JP:H0869271" scheme="references"><meta name="DC.relation" content="JP:S5627195" scheme="references"><meta name="DC.relation" content="JP:S5667445" scheme="references"><meta name="DC.relation" content="JP:S59276" scheme="references"><meta name="DC.relation" content="JP:S60176093" scheme="references"><meta name="DC.relation" content="JP:S60232597" scheme="references"><meta name="DC.relation" content="JP:S62276672" scheme="references"><meta name="DC.relation" content="US:4835532" scheme="references"><meta name="DC.relation" content="US:5003616" scheme="references"><meta name="DC.relation" content="US:5633755" scheme="references"><meta name="DC.relation" content="US:5757980" scheme="references"><meta name="DC.relation" content="US:6097840" scheme="references"><meta name="DC.relation" content="US:6222593" scheme="references"><meta name="DC.relation" content="US:6389155" scheme="references"><meta name="citation_patent_number" content="US:6831661"><meta name="citation_patent_application_number" content="US:09/632,221"><link rel="canonical" href="http://www.google.com/patents/US6831661"/><meta property="og:url" content="http://www.google.com/patents/US6831661"/><meta name="title" content="Patent US6831661 - Projection display apparatus, display method for same and image display apparatus"/><meta name="description" content="The present invention provides a technology that enables related portions of multiple pages of images to be displayed simultaneously. A projection display apparatus comprises: an image extraction section that extracts at least a portion of given first image data as an extraction image; an extraction image memory for storing extraction image data representing the extraction image; an image overlay section that generates overlaid image data by superimposing the extraction image on an original image represented by given second image data; a light modulation unit that is driven responsive to the overlaid image data pixel by pixel; and an optical system for projecting onto the screen the overlaid image obtained by the light modulation unit. A projection display apparatus can display related portions of multiple pages of images simultaneously."/><meta property="og:title" content="Patent US6831661 - Projection display apparatus, display method for same and image display apparatus"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("pIztU8DJMZCSgwTxtoC4BQ"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("GRC"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("pIztU8DJMZCSgwTxtoC4BQ"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("GRC"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us6831661?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US6831661"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS6831661&amp;usg=AFQjCNECj9bH6qmo_CifWb1HH_sK6QybKA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US6831661.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US6831661.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US6831661" style="display:none"><span itemprop="description">The present invention provides a technology that enables related portions of multiple pages of images to be displayed simultaneously. A projection display apparatus comprises: an image extraction section that extracts at least a portion of given first image data as an extraction image; an extraction...</span><span itemprop="url">http://www.google.com/patents/US6831661?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US6831661 - Projection display apparatus, display method for same and image display apparatus</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US6831661 - Projection display apparatus, display method for same and image display apparatus" title="Patent US6831661 - Projection display apparatus, display method for same and image display apparatus"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US6831661 B1</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 09/632,221</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Dec 14, 2004</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Aug 3, 2000</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Feb 3, 1998</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7187391">US7187391</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20050219265">US20050219265</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO1999040564A1">WO1999040564A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">09632221, </span><span class="patent-bibdata-value">632221, </span><span class="patent-bibdata-value">US 6831661 B1, </span><span class="patent-bibdata-value">US 6831661B1, </span><span class="patent-bibdata-value">US-B1-6831661, </span><span class="patent-bibdata-value">US6831661 B1, </span><span class="patent-bibdata-value">US6831661B1</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Takafumi+Itoh%22">Takafumi Itoh</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Shoichi+Akaiwa%22">Shoichi Akaiwa</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Seiko+Epson+Corporation%22">Seiko Epson Corporation</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6831661.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6831661.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6831661.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (21),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (7),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (30),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/6831661&usg=AFQjCNGqa2RDndkiMW_38vUzlJmpPA3RWQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D6831661&usg=AFQjCNGwM4zG4CIU5R_6b5It5xX-TvHd_A">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D6831661B1%26KC%3DB1%26FT%3DD&usg=AFQjCNEnldKkIYeh6SXGb1qkubhpMLzYcg">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55351127" lang="EN" load-source="patent-office">Projection display apparatus, display method for same and image display apparatus</invention-title></span><br><span class="patent-number">US 6831661 B1</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA50762131" lang="EN" load-source="patent-office"> <div class="abstract">The present invention provides a technology that enables related portions of multiple pages of images to be displayed simultaneously. A projection display apparatus comprises: an image extraction section that extracts at least a portion of given first image data as an extraction image; an extraction image memory for storing extraction image data representing the extraction image; an image overlay section that generates overlaid image data by superimposing the extraction image on an original image represented by given second image data; a light modulation unit that is driven responsive to the overlaid image data pixel by pixel; and an optical system for projecting onto the screen the overlaid image obtained by the light modulation unit. A projection display apparatus can display related portions of multiple pages of images simultaneously.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(27)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00014.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00014.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00015.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00015.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00016.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00016.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00017.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00017.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00018.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00018.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00019.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00019.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00020.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00020.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00021.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00021.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00022.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00022.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00023.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00023.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00024.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00024.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00025.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00025.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US6831661B1/US06831661-20041214-D00026.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US6831661B1/US06831661-20041214-D00026.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(11)</span></span></div><div class="patent-text"><div mxw-id="PCLM8777681" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is: </claim-statement> <div class="claim"> <div num="1" id="US-6831661-B1-CLM-00001" class="claim">
      <div class="claim-text">1. A projection display apparatus that projects images onto a screen, comprising:</div>
      <div class="claim-text">a frame memory for storing image data representing an image to be displayed; </div>
      <div class="claim-text">an image display signal generator for generating image display signals based on the image data stored in the frame memory; </div>
      <div class="claim-text">an electro-optical device for emitting light to form images in response to the image display signals; </div>
      <div class="claim-text">a projection optical system for projecting light emitted by the electro-optical device; </div>
      <div class="claim-text">an image extraction section that extracts at least a portion of an extraction target image selected arbitrarily from images given externally as an extraction image; </div>
      <div class="claim-text">an extraction image memory for storing extraction image data representing the extracting image; and </div>
      <div class="claim-text">a specific image display control section that displays a specific image represented by specific image data including the extraction image data stored in the extraction image memory in a specific operating condition, the specific operating condition including at least one of a state in which no image signal is being given to the projection display apparatus and a state in which a prescribed period has not elapsed after the startup of the projection display apparatus. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" id="US-6831661-B1-CLM-00002" class="claim">
      <div class="claim-text">2. A projection display apparatus according to <claim-ref idref="US-6831661-B1-CLM-00001">claim 1</claim-ref>, wherein the image extraction section implements the steps of:</div>
      <div class="claim-text">displaying an extraction image setting screen for setting image extraction conditions comprising at least an extraction area and an extraction magnification factor; </div>
      <div class="claim-text">displaying an extraction area specifying image used in setting the extraction area on the extraction target image; </div>
      <div class="claim-text">when the extraction area is set with the extraction area specifying image, writing into the frame memory selected extraction image data representing a selected extraction image corresponding to the set extraction area; </div>
      <div class="claim-text">when a display magnification factor is set, enlarging or reducing the selected extraction image data based on the magnification factor and writing the enlarged or reduced selected extraction image data into the frame memory; and </div>
      <div class="claim-text">when a desired display magnification factor is determined, storing the selected extraction image data enlarged or reduced based on the desired display magnification factor in the extraction image memory. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" id="US-6831661-B1-CLM-00003" class="claim">
      <div class="claim-text">3. A projection display apparatus according to <claim-ref idref="US-6831661-B1-CLM-00001">claim 1</claim-ref> or <claim-ref idref="US-6831661-B1-CLM-00002">2</claim-ref>, wherein the image extraction section displays a predetermined extraction frame as the extraction area specifying image, the predetermined extraction frame having a first black outline, a second black outline inside the first black outline and a white area between the first and second black outlines.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" id="US-6831661-B1-CLM-00004" class="claim">
      <div class="claim-text">4. A projection display apparatus according to <claim-ref idref="US-6831661-B1-CLM-00001">claim 1</claim-ref>, wherein the extraction image memory stores a plurality of extraction image data representing a plurality of extraction images; and</div>
      <div class="claim-text">the specific image display control section displays a specific image that include at least one extraction image selected from among the plurality of extraction images in the specific operating condition. </div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" id="US-6831661-B1-CLM-00005" class="claim">
      <div class="claim-text">5. A projection display apparatus according to <claim-ref idref="US-6831661-B1-CLM-00004">claim 4</claim-ref>, wherein the specific image display control section selects at least two of the extraction images from among the plurality of extraction images and displays the selected images in order.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" id="US-6831661-B1-CLM-00006" class="claim">
      <div class="claim-text">6. A projection display apparatus according to <claim-ref idref="US-6831661-B1-CLM-00001">claim 1</claim-ref>, further comprising an operating condition judging section that judges if the projection display apparatus is in the specific operating condition, wherein the specific image display control section displays the specific image when the specific operating condition is detected by the operating condition judging section.</div>
    </div>
    </div> <div class="claim"> <div num="7" id="US-6831661-B1-CLM-00007" class="claim">
      <div class="claim-text">7. A projection display apparatus that projects images, comprising:</div>
      <div class="claim-text">a frame memory for storing image data representing an image to be displayed; </div>
      <div class="claim-text">an image display signal generator for generating image display signals based on the image data stored in the frame memory; </div>
      <div class="claim-text">an electro-optical device for emitting light to form images in response to the image display signals; </div>
      <div class="claim-text">a projection optical system for projecting light emitted by the electro-optical device; </div>
      <div class="claim-text">an operating condition judging section that judges if the projection display apparatus is in a specific operating condition, the specific operating condition including at least one of a state in which no image signal is being given to the projection display apparatus and a state in which a prescribed period has not elapsed after the startup of the projection display apparatus; and </div>
      <div class="claim-text">a specific image display control section that displays the specific image represented by the specific image data when the operating condition judging section detects the specific operating condition. </div>
    </div>
    </div> <div class="claim"> <div num="8" id="US-6831661-B1-CLM-00008" class="claim">
      <div class="claim-text">8. An image display apparatus that displays images, comprising:</div>
      <div class="claim-text">a frame memory for storing image data representing an image to be displayed; </div>
      <div class="claim-text">an image display signal generator for generating image display signals based on the image data stored in the frame memory; </div>
      <div class="claim-text">an electro-optical device for emitting light to form images in response to the image display signals; </div>
      <div class="claim-text">an image extraction section that extracts at least a portion of an extraction target image selected arbitrarily from among images given externally as an extraction image; </div>
      <div class="claim-text">an extraction image memory for storing extraction image data representing the extraction image; and </div>
      <div class="claim-text">a specific image display control section that displays a specific images represented by specific image data including the extraction image data stored in the extraction image memory in a specific operating condition, the specific operating condition including at least one of a state in which no image signal is being given to the projection display apparatus and a state in which a prescribed period has not elapsed after the startup of the projection display apparatus. </div>
    </div>
    </div> <div class="claim"> <div num="9" id="US-6831661-B1-CLM-00009" class="claim">
      <div class="claim-text">9. An image display apparatus that displays images, comprising:</div>
      <div class="claim-text">a frame memory for storing image data representing an image to be displayed; </div>
      <div class="claim-text">an image display signal generator for generating image display signals based on the image data stored in the frame memory; </div>
      <div class="claim-text">an electro-optical device for emitting light to form images in response to the image display signals; </div>
      <div class="claim-text">an operating condition judging section that judges if the image display apparatus is in a specific operating condition, the specific operating condition including at least one of a state in which no image signal is being given to the projection display apparatus and a state in which a prescribed period has not elapsed after the startup of the projection display apparatus; and </div>
      <div class="claim-text">a specific image display control section that displays a specific image represented by specific image data when the operating condition judging section detects the specific operating condition. </div>
    </div>
    </div> <div class="claim"> <div num="10" id="US-6831661-B1-CLM-00010" class="claim">
      <div class="claim-text">10. A method of displaying a specific image using a projection display apparatus, comprising the steps of:</div>
      <div class="claim-text">extracting at least a portion of a given extraction target image as an extraction image; </div>
      <div class="claim-text">preparing extraction image data representing the extraction image; and </div>
      <div class="claim-text">displaying a specific image represented by specific image data including the extraction image data in a specific operating condition, the specific operating condition including at least one of a state in which no image signal is being given to the projection display apparatus and a state in which a prescribed period has not elapsed after the startup of the projection display apparatus. </div>
    </div>
    </div> <div class="claim"> <div num="11" id="US-6831661-B1-CLM-00011" class="claim">
      <div class="claim-text">11. A method of displaying a specific image using a projection display apparatus, comprising the steps of:</div>
      <div class="claim-text">judging if the projection display apparatus is in a specific operating condition, the specific operating condition including at least one of a state in which no image signal is being given to the projection display apparatus and a state in which a prescribed period has not elapsed after the startup of the projection display apparatus; </div>
      <div class="claim-text">when it is judged that the projection display apparatus is in the specific operating condition, storing specific image data to a frame memory to display a specific image represented by specific image data.</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES54347914" lang="EN" load-source="patent-office" class="description">
    <p>This application is a continuation of application PCT/JP99/00467 filed on Feb. 3, 1999.</p>
    <heading>TECHNICAL FIELD</heading> <p>The present invention relates to an image display apparatus, and more particularly to a projection display apparatus technology.</p>
    <heading>BACKGROUND ART</heading> <p>The ability of a projection display apparatus to take input images and display them enlarged on a screen has led to the extensive use for presentations. In a presentation a commentary accompanies the images projected onto the screen. Generally, multiple pages of presentation images are used. While each page of presentation images is different, usually a number of the images are interrelated, so it is necessary to cut back and forth between related presentation pages. Therefore, users want to be able to simultaneously display at least some of multiple pages of interrelated presentation images.</p>
    <p>Also, during question and answer sessions or when a short time is needed before a new set of images can be displayed, companies like to display corporate logos, products and other such images (which will also be referred to as specific images) instead of presentation images. In the prior art, specific images were supplied to the projection display apparatus via an image source apparatus such as a computer, video player, TV receiver or the like. Thus, the problem has been that the specific image data has had to be stored beforehand in the image source apparatus connected to the projection display apparatus.</p>
    <p>When no images are being input to the projection display apparatus the screen remains blank. In such situations, in the prior art the projection display apparatus displays a one-color screen image called a blank image. In this situation too, users have expressed a desire to display specific images. However, this has not been possible because normal images are not being input from the image source apparatus. This problem is not limited to the projection display apparatus, but is also shared by image display apparatus that display images supplied externally.</p>
    <heading>DISCLOSURE OF THE INVENTION</heading> <p>This invention was accomplished to overcome the foregoing problems of the prior art. A first object of the invention is to provide a technology that enables related portions of multiple pages of images to be displayed simultaneously. A second object is to provide a technology that enables specific images to be displayed even when the specific images are not supplied externally.</p>
    <p>In accordance with a first aspect of this invention, the above object is attained by a projection display apparatus that comprises: an image extraction section that extracts at least a portion of given first image data as an extraction image; an extraction image memory for storing extraction image data representing the extraction image; an image overlay section that generates overlaid image data by superimposing the extraction image on original image represented by given second image data; a light modulation unit that is driven responsive to the overlaid image data pixel by pixel; and an optical system for projecting onto the screen the overlaid image obtained by the light modulation unit.</p>
    <p>Since this projection display apparatus contains a section for extracting at least a portion of a given image, and an image overlay section for superimposing the extracted image on the original image, it is possible to simultaneously display multiple pages of interrelated image portions.</p>
    <p>It is preferable that the image extraction section can arbitrarily set the portion to be extracted from the first image data, since this makes it easier to produce extraction image data for a particular purpose.</p>
    <p>It should also be possible for the image overlay section to superimpose the extraction image at a desired position on the original image, since that provides more freedom with respect to overlaying extraction images.</p>
    <p>It is also preferable that the extraction image memory stores a plurality of extraction image data representing a plurality of extraction images, and the image overlay section superimposes at least one selected extraction image at each specified position on the original image.</p>
    <p>Doing this makes it possible to select an arbitrary extraction image from among a plurality of extraction images, enabling a desired extraction image to be overlaid on an original image.</p>
    <p>It is preferable for the image overlay section used in the projection display apparatus to be equipped with a synthesizer section that generates the overlaid image data by synthesizing the given second image data and the extraction image data read out from the extraction image memory; and a frame memory for storing the overlaid image data, the frame memory having at least a memory area corresponding to all the pixels of the light modulation unit. In this case, the overlaid image data read out of the frame memory is supplied to the light modulation unit.</p>
    <p>With this configuration, since image data consisting of the extraction images superimposed on the original image is written to a frame memory, the overlaid image can be obtained by reading the overlaid image data from the frame memory.</p>
    <p>Alternatively, It is preferable for the image overlay section used in the projection display apparatus to be equipped with a frame memory for storing the given second image data, the frame memory having at least a memory area corresponding to all the pixels of the light modulation unit; and a synthesizer section that generates the overlaid image data by synthesizing the second image data read out from the frame memory and the extraction image data read out from the extraction image memory, with the overlaid image data synthesized by the synthesizer section being supplied to the light modulation unit.</p>
    <p>This configuration allows the overlaid image data to be obtained in the projection display apparatus. Thus, this projection display apparatus has the same function and advantage as the preceding apparatus. Compared to the preceding configuration in which the overlaid image data is read out of the frame memory and displayed, in this configuration the extraction image is superimposed as the image data is being read out of the frame memory. Therefore, the time taken from the initial overlay command to the display of the overlaid image is shorter.</p>
    <p>In another preferred arrangement, the synthesizer section comprises a data selector that selects either one of the second image data and the extraction image data, pixel by pixel, to produce the overlaid image data.</p>
    <p>With this configuration, since the data selector selects either one of the second image data and the extraction image data, an extraction image can be superimposed on the original image by substituting extraction image data for part of the original image data.</p>
    <p>It is preferable for the synthesizer section to be equipped with a multiplier section that multiplies the second image data and the extraction image data by respective coefficients on a pixel by pixel basis; and an adder section that adds the multiplied second image data and the extraction image data on a pixel by pixel basis.</p>
    <p>With this configuration, the coefficients can be used to adjust the density ratio between the embellishment image and the original image.</p>
    <p>In another preferred configuration, the synthesizer section comprises a coefficient setting section that controls the coefficients in the multiplier section to change a synthesis ratio between the second image data and the extraction image data, thereby adjusting a degree of transparency of the extraction image superimposed on the original image.</p>
    <p>Doing this enables the synthesis ratio between the image data and the extraction image data to be altered by controlling the coefficients of the multiplier section, making it possible an overlay image in which the portion overlaid by an extraction image is transmitted.</p>
    <p>In the above projection display apparatus, also, it is preferable that the coefficient setting section changes the coefficients in the multiplier section with time to change the synthesis ratio between the second image data and the extraction image data, thereby changing the degree of transparency of the extraction image superimposed on the original image with time.</p>
    <p>Doing this makes it possible to change with time the degree of transparency of the portion on which an extraction image is overlaid by changing the coefficients of the multiplier section with time.</p>
    <p>A projection display apparatus according to a second aspect of the invention comprises: a frame memory for storing image data representing an image to be displayed; a image display signal generator for generating image display signals based on the image data stored in the frame memory; a electro-optical device for emitting light to form images responsive to the image display signals; a projection optical system for projecting light emitted by the electro-optical device; an image extraction section that extracts at least a portion of an extraction target image selected arbitrarily from among images given externally as an extraction image; an ex traction image memory for storing extraction image data representing the extraction image; and a specific image display control section that in a specific display condition displays a specific image represented by specific image data including the extraction image data stored in the extraction image memory.</p>
    <p>With this configuration, at least a part of a selected target image can be acquired as the extraction image. In a specific display condition, this makes it possible to display specific image that include arbitrarily extracted image, in place of image given to the projection display apparatus. Thus, desired specific image can be displayed even when specific images are not being supplied from an external source.</p>
    <p>In another preferred configuration, the image extraction section implements the steps of: displaying an extraction image setting screen for setting image extraction conditions comprising at least an extraction area and an extraction magnification factor; displaying an extraction area specifying image used in setting the extraction area on the extraction target image; when the extraction area is set with the extraction area specifying image, writing into the frame memory selected extraction image data representing a selected extraction image corresponding to the set extraction area; when a display magnification factor is set, enlarging or reducing the selected extraction image data based on the magnification factor and writing the enlarged or reduced selected extraction image data into the frame memory; and when a desired display magnification factor is determined, storing the selected extraction image data enlarged or reduced based on the desired display magnification factor in the extraction image memory.</p>
    <p>The extraction image setting screen makes it easier to set the target extraction image area. Also, before a magnification factor is determined, it can be checked by displaying the selected extraction image corresponding to the set extraction area at the selected magnification factor concerned.</p>
    <p>In another preferred arrangement, the image extraction section displays a predetermined extraction frame as the extraction area specifying image, the predetermined extraction frame having a first black outline, a second black outline inside the first black outline and a white area between the first and second black outlines.</p>
    <p>This facilitates setting the extraction area by making it easy to distinguish the extraction area on the extraction target image. Whatever the color of the extraction target image is, black outlines or white image frame can be displayed clearly.</p>
    <p>In another preferred arrangement, the extraction image memory stores a plurality of extraction image data representing a plurality of extraction images; and the specific image display control section displays a specific image that include at least one extraction image selected from among the plurality of extraction images in the specific display condition.</p>
    <p>A specific image display control section can be used that selects at least two of the extraction images from among the plurality of extraction images and displays the selected images in order.</p>
    <p>The ability to choose from among a plurality of extraction images means that more effective specific image can be used.</p>
    <p>In another preferred configuration, the projection display apparatus includes an operating condition judging section that judges if the projection display apparatus is in a specific operating condition, wherein the specific image display control section displays the specific image when the specific operating condition is detected by the operating condition judging section.</p>
    <p>This configuration can automatically determine when the projection display apparatus is in a specific operating condition, and display specific image that includes extraction image extracted by the image extraction section.</p>
    <p>Specifically, the operating condition judging section is configured to detect as the specific operating condition at least one state selected from a state in which no image signal is being given to the projection display apparatus, and another state in which the projection display apparatus is within a prescribed period after startup.</p>
    <p>In each of these states, in which the projection display apparatus cannot perform its normal display function, specific image that include extraction image extracted by the image extraction section can be automatically displayed.</p>
    <p>A projection display apparatus according to a third aspect of the invention comprises: a frame memory for storing image data representing an image to be displayed; a image display signal generator for generating image display signals based on the image data stored in the frame memory; a electro-optical device for emitting light to form images responsive to the image display signals; a projection optical system for projecting light emitted by the electro-optical device; an operating condition judging section that judges if the projection display apparatus is in a specific operating condition; and a specific image display control section that displays the specific image represented by the specific image data when the operating condition judging section detects the specific display condition.</p>
    <p>This configuration can automatically determine when the projection display apparatus is in a specific operating condition, and display specific images at such times.</p>
    <p>For this, preferably the operating condition judging section detects as the specific operating condition at least one state selected from a state in which no image signal is being given, and a state in which the projection display apparatus is within a prescribed period after startup.</p>
    <p>As described above, in each of these states in which the projection display apparatus cannot perform its normal display functions, specific image that include extraction image extracted by the image extraction section can be automatically displayed.</p>
    <p>An image display apparatus according to a fourth aspect of the invention comprises: a frame memory for storing image data representing an image to be displayed; a image display signal generator for generating image display signals based on the image data stored in the frame memory; a electro-optical device for emitting light to form images responsive to the image display signals; an image extraction section that extracts at least a portion of an extraction target image selected arbitrarily from among images given externally as an extraction image; an extraction image memory for storing extraction image data representing the extraction image; and a specific image display control section that in a specific display condition displays the specific images represented by a specific image data including the extraction image data stored in the extraction image memory.</p>
    <p>This image display apparatus has the same function and advantage as the projection display apparatus according to the fourth aspect. In a specific display condition selected by a user, the image display apparatus can display specific image that include arbitrarily extracted image in place of image given to the image display apparatus.</p>
    <p>An image display apparatus according to a fifth aspect of the invention comprises: a frame memory for storing image data representing an image to be displayed; a image display signal generator for generating image display signals based on the image data stored in the frame memory; a electro-optical device for emitting light to form images responsive to the image display signals; an operating condition judging section that judges if the projection display apparatus is in a specific operating condition; and a specific image display control section that displays the specific image represented by the specific image data when the operating condition judging section detects the specific display condition.</p>
    <p>This image display apparatus has the same function and advantage as the projection display apparatus according to the third aspect. It can automatically detect when the image display apparatus is in a specific display condition, and display specific images.</p>
    <p>In accordance with a sixth aspect of the invention, a method of displaying images using a projection display apparatus having a light modulation unit to display an image based on image data given to the projection display apparatus by projecting the image on a screen, which comprises the steps of: extracting at least a portion of given first image data as an extraction image; preparing extraction image data representing the extraction image; generating overlaid image data by superimposing the extraction image on an original image represented by given second image data; driving light modulation unit responsive to the overlaid image data pixel by pixel basis; and projecting onto a screen overlaid images obtained by the light modulation unit.</p>
    <p>This display method has the same function and advantage as the projection display apparatus according to the first aspect, enabling simultaneous display of related portions of multiple pages of images.</p>
    <p>A display method according to a seventh aspect of the invention comprises the steps of: extracting at least a portion of a given extraction target image as an extraction image; preparing extraction image data representing the extraction image; and in a specific display condition, displaying a specific image represented by specific image data including the extraction image data.</p>
    <p>This display method has the same function and advantage as the projection display apparatus according to the second aspect, enabling a specific image to be displayed even when the specific image is not being supplied from an external source.</p>
    <p>A display method according to an eighth aspect of the invention comprises the steps of: judging if the projection display apparatus is in a specific operating condition; when it is judged that there is a specific operating condition, storing specific image data to a frame memory to display a specific image represented by specific image data.</p>
    <p>This display method provides the same function and advantage as the projection display apparatus according to the third aspect, and is able to automatically determine when the projection display apparatus is in a specific operating condition, and display specific images at such times.</p>
    <p>At least part of the functions of the above-described method steps and components of the invention can be implemented by a computer program recorded on computer-readable recording media such as floppy disks, CD-ROMs, opto-magnetic disks, punched cards, bar codes and other such printed symbols, internal storage device (including RAM and ROM) and external storage device.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is a block diagram for schematically illustrating a first embodiment of the general configuration of a projection display apparatus according to a first aspect of the invention.</p>
    <p>FIG. 2 is a block diagram for schematically illustrating the configuration of a video signal conversion circuit <b>10</b>.</p>
    <p>FIG. 3 is a block diagram showing the configuration of the video processor <b>34</b>.</p>
    <p>FIGS. <b>4</b>(<i>a</i>)-(<i>d</i>) are diagrams for explaining the frame memory <b>22</b>, extraction image memory <b>24</b> and extraction image bitmap memory <b>26</b> used in this embodiment.</p>
    <p>FIG. 5 is a block diagram for schematically illustrating the configuration of the extraction image overlay circuit <b>12</b>.</p>
    <p>FIGS. <b>6</b>(<i>a</i>)-(<i>c</i>) are diagrams for explaining the overlay operation with respect to image data stored in the frame memory <b>22</b> and extraction image bitmap data BMD<b>1</b> stored in the extraction image bitmap memory <b>26</b>.</p>
    <p>FIG. 7 is a diagram for explaining the extraction image bitmap data BMD<b>1</b> expanded in the extraction image bitmap memory <b>26</b>.</p>
    <p>FIGS. <b>8</b>(<i>a</i>)-(<i>c</i>) are diagrams for explaining examples of displays on a projection screen <b>104</b> of images input from a personal computer on which extraction images have been superimposed.</p>
    <p>FIG. 9 is another diagram for explaining the display on a projection screen <b>104</b> of an image input from a personal computer on which an extraction image has been superimposed.</p>
    <p>FIG. 10 is a diagram for explaining the extraction image bitmap memory <b>26</b> when the extraction image of FIG. 9 is expanded.</p>
    <p>FIGS. <b>11</b>(<i>a</i>) and <b>11</b>(<i>b</i>) are diagrams for explaining projected images overlaid with transparent extraction images.</p>
    <p>FIG. 12 is a block diagram for schematically illustrating the general configuration of a second embodiment of the projection display apparatus according to a first aspect of the invention.</p>
    <p>FIG. 13 is a block diagram for schematically illustrating the configuration of a video signal conversion circuit <b>60</b>.</p>
    <p>FIG. 14 is a block diagram showing a configuration of the video processor <b>62</b>.</p>
    <p>FIG. 15 is a block diagram for schematically illustrating the general configuration of an embodiment of the projection display apparatus according to a second aspect of the invention.</p>
    <p>FIG. 16 is a block diagram for schematically illustrating the configuration of the video signal processing circuit <b>210</b>.</p>
    <p>FIG. 17 is a block diagram showing a configuration of the video processor <b>234</b>.</p>
    <p>FIG. 18 is a diagram illustrating the extraction image memory <b>224</b>.</p>
    <p>FIG. 19 is a diagram for explaining externally input images displayed on a projection screen <b>104</b>.</p>
    <p>FIG. 20 is a diagram for explaining the projection screen display of a specific image represented by the specific image data SPD<b>1</b> that includes background image data BGD<b>1</b> and extraction image data CPD<b>1</b> stored in extraction image memory <b>224</b>.</p>
    <p>FIGS. <b>21</b>(<i>a</i>)-(<i>c</i>) are diagrams for explaining the display on the projection screen <b>104</b> of sequentially selected extraction images represented by extraction image data CPD<b>1</b> (A), CPD<b>1</b> (B) and CPD<b>1</b> (C).</p>
    <p>FIG. 22 is a diagram to illustrate the procedure for cutting away from an image being input to the projection display apparatus, to a user logo image.</p>
    <p>FIG. 23 is a diagram for explaining the procedure for cutting away from an image being input to the projection display apparatus, to a user logo image.</p>
    <p>FIG. 24 is a diagram for explaining the procedure for cutting away from an image being input to the projection display apparatus, to a user logo image.</p>
    <p>FIG. 25 is a diagram for explaining the procedure for cutting away from an image being input to the projection display apparatus, to a user logo image.</p>
    <p>FIG. 26 is a diagram for explaining the procedure for cutting away from an image being input to the projection display apparatus, to a user logo image.</p>
    <p>FIG. 27 is a diagram for explaining the procedure for cutting away from an image being input to the projection display apparatus, to a user logo image.</p>
    <p>FIG. 28 is a block diagram for schematically illustrating the general configuration of an embodiment of the projection display apparatus according to second and third aspects of the invention.</p>
    <p>FIG. 29 is a block diagram showing the configuration of the operating condition judging section <b>226</b>.</p>
    <p>FIGS. <b>30</b>(<i>a</i>)-(<i>e</i>) are time charts of the operation of the operating condition judging section <b>226</b>.</p>
    <heading>BEST MODES OF CARRYING OUT THE INVENTION</heading> <heading>A. First Embodiment</heading> <p>Some modes for carrying out the present invention are described below as preferred embodiments. FIG. 1 is a block diagram for schematically illustrating a first embodiment of the general configuration of a projection display apparatus according to a first aspect of the invention. The projection display apparatus includes a video signal conversion circuit <b>10</b>, an extraction image overlay circuit <b>12</b>, a liquid crystal display driver circuit <b>14</b>, a liquid crystal display panel <b>16</b>, a frame memory <b>22</b>, an extraction image memory <b>24</b>, an extraction image bitmap memory <b>26</b>, a remote control section <b>28</b>, a CPU <b>20</b>, an illumination optical system <b>100</b> and a projection optical system <b>102</b>. The video signal conversion circuit <b>10</b>, extraction image overlay circuit <b>12</b>, extraction image memory <b>24</b>, remote control section <b>28</b> and CPU <b>20</b> are connected to via a bus <b>1</b>. The liquid crystal display driver circuit <b>14</b> is also connected to the bus <b>1</b>, but this is not shown in FIG. <b>1</b>. The liquid crystal display panel <b>16</b> is uniformly illuminated by the illumination optical system <b>100</b>, and images displayed on the liquid crystal display panel <b>16</b> are projected onto the projection screen <b>104</b> by the projection optical system <b>102</b>. The optical systems <b>100</b> and <b>102</b> are shown in a simplified fashion.</p>
    <p>The video signal conversion circuit <b>10</b> is used to perform analog-digital conversion of analog video signals AV<b>1</b>, write the converted image data into the frame memory <b>22</b> and retrieve image data from the frame memory <b>22</b>. The analog video signal AV<b>1</b> can be an RGB signal S<b>1</b> carrying a computer screen image, or a composite image signal S<b>2</b> from a video recorder, TV or the like.</p>
    <p>FIG. 2 is a block diagram for schematically illustrating the configuration of the video signal conversion circuit <b>10</b>. The video signal conversion circuit <b>10</b> includes a sync separator <b>30</b>, an A-D conversion section <b>32</b> and a video processor <b>34</b>.</p>
    <p>When the analog video signal AV<b>1</b> is a composite image signal S<b>2</b>, the sync separator <b>230</b> separates the signal S<b>2</b> into a sync signal SYNC and a component image signal (analog image signals not including a sync signal) S<b>3</b>. The component image signal S<b>3</b> is comprised of three color signals representing the red, green and blue images. If the analog video signal AV<b>1</b> that is received is an RGB signal S<b>1</b>, there is no need to use the sync separator <b>230</b> since there is a separate sync signal input.</p>
    <p>The A-D conversion section <b>232</b> contains multiple A-D converters for converting RGB signal S<b>1</b> or component image signal (RGB signal) S<b>3</b> output by the sync separator <b>230</b> to image data DV<b>1</b> for each color signal. The conversion timing of the A-D converters is controlled by a dot clock DCLK generated in the video processor <b>234</b>, using the sync signal WSYNC.</p>
    <p>The video processor <b>34</b> is a microprocessor that performs various image processing functions such as controlling the input and output of image data to and from the frame memory <b>22</b>. Image data DV<b>1</b> from the A-D conversion section <b>32</b> is stored in the frame memory <b>22</b> until required.</p>
    <p>FIG. 3 is a block diagram showing the configuration of the video processor <b>34</b>. The video processor <b>34</b> includes a write controller <b>70</b>, a read controller <b>72</b> and an image extraction section <b>74</b>.</p>
    <p>When image data is written to, or read from, the frame memory <b>22</b>, the write controller <b>70</b> and read controller <b>72</b> generate addresses ADD<b>1</b>, ADD<b>2</b> and control signals CTR<b>1</b>, CTR<b>2</b> and supply them to the frame memory <b>22</b>. Thus, the image data is written to the frame memory <b>22</b> in accordance with address ADD<b>1</b> and control signal CTR<b>1</b> generated by the write controller <b>70</b>, and read out of the frame memory <b>22</b> in accordance with address ADD<b>2</b> and control signal CTR<b>2</b> generated by the read controller <b>72</b>. These addresses and control signals are based on sync signals WSYNC and RSYNC.</p>
    <p>The writing of image data to the frame memory <b>22</b> is synchronized by the sync signal WSYNC. The retrieval of image data from the frame memory <b>22</b> and the downstream processing of the image data DV<b>2</b> output by the video processor <b>34</b> are synchronized by the sync signal RSYNC output by the liquid crystal display driver circuit <b>14</b> (FIG. 1) explained below. The first sync signal WSYNC and the second sync signal RSYNC are not mutually synchronized. However, sync signals WSYNC and RSYNC can be used synchronized.</p>
    <p>When image data that has been written into the frame memory <b>22</b> is read out, the image extraction section <b>74</b> (FIG. 3) extracts a specified portion of the image data. The image extraction section <b>74</b> compresses the extracted image data and writes it to the extraction image memory <b>24</b> via the bus <b>1</b>. The extracted image data does not have to be compressed by the image extraction section <b>74</b>. Also, the data can be reduced instead of compressed. The operation of specifying the portion of the image data to be extracted can be done using a remote controller <b>29</b>. When the extraction portion has been specified by the remote controller <b>29</b>, the CPU <b>20</b> outputs an extraction address SADD corresponding to the specified extraction portion. Based on the extraction address SADD and address ADD<b>2</b> that is output from the read controller <b>72</b>, the image extraction section <b>74</b> extracts the pixel data of the extraction portion. By doing this, only pixel data corresponding to specified portion can be extracted.</p>
    <p>The extraction image memory <b>24</b> shown in FIG. 1 is used to store the extraction image data extracted by the image extraction section <b>74</b> of the video processor <b>34</b> (FIG. <b>3</b>). In this embodiment, the extraction image data is stored in compressed form in the extraction image memory <b>24</b> as compressed extraction image data CPD. The data CPD is expanded into extraction image bitmap data BMD<b>1</b>, which is stored in the extraction image bitmap memory <b>26</b>. The extracted image data may also be stored in uncompressed form in the memory <b>26</b>, in which case the extraction image memory <b>24</b> is unnecessary.</p>
    <p>FIGS. <b>4</b>(<i>a</i>)-(<i>d</i>) are diagrams for explaining the frame memory <b>22</b>, extraction image memory <b>24</b> and extraction image bitmap memory <b>26</b> used in this embodiment. FIGS. <b>4</b>(<i>a</i>) and (<i>d</i>) show the memory space in the frame memory <b>22</b>, FIG. <b>4</b>(<i>b</i>) shows the memory space in the extraction image memory <b>24</b>, and FIG. <b>4</b>(<i>c</i>) shows the memory space in the extraction image bitmap memory <b>26</b>.</p>
    <p>With reference to FIG. <b>4</b>(<i>a</i>), the frame memory <b>22</b> contains one frame of the input image data (a picture of a flower) in a bitmap format. The broken line shows the extraction portion, which is defined by the user, extracted and compressed by the image extraction section <b>74</b>, and stored in the extraction image memory <b>24</b> as compressed extraction image data CPD.</p>
    <p>As shown in FIG. <b>4</b>(<i>b</i>), the extraction image memory <b>24</b> contains multiple types of compressed extraction image data CPD and a program for expanding the compressed extraction image data CPD into a bitmap. The program is stored in the memory <b>24</b> starting at memory address 0000. Compressed data A, B and C are stored at starting addresses 0A00, 0B00 and 0C00, respectively.</p>
    <p>The extraction image bitmap memory <b>26</b> shown in FIG. <b>4</b>(<i>c</i>) is used to store extraction image bitmap data BMD<b>1</b> expanded by the program in the extraction image memory <b>24</b>, and coordinate data PD showing the overlay position and extent of the extracted image on the original image data. The extraction image bitmap data BMD<b>1</b> (FIG. <b>4</b>(<i>c</i>)) is expanded starting from address 0000 of the extraction image bitmap memory <b>26</b>. The coordinate data PD is stored starting at address AAAA, and includes two point coordinates (x<b>1</b>, y<b>1</b>), (x<b>2</b>, y<b>2</b>). The first coordinate (x<b>1</b>, y<b>1</b>) denotes the overlay position of the extracted image within the image data, and the two coordinates (x<b>1</b>, y<b>1</b>), (x<b>2</b>, y<b>2</b>) denote the overlay extent (meaning the size) of the extraction image.</p>
    <p>The frame memory <b>22</b> shown in FIG. <b>4</b>(<i>d</i>) contains image data (a picture of a tree) in a bitmap format. The extraction image of FIG. <b>4</b>(<i>c</i>) is overlaid on above image. The coordinates (x<b>1</b>, y<b>1</b>), (x<b>2</b>, y<b>2</b>) shown in FIG. <b>4</b>(<i>d</i>) are based on the address 0000 of the frame memory <b>22</b> being for coordinates (<b>0</b>, <b>0</b>). The coordinates (x<b>1</b>, y<b>1</b>), (x<b>2</b>, y<b>2</b>) correspond to the coordinate data PD of FIG. <b>4</b>(<i>c</i>), in which point a at the upper left of the extraction image bitmap data BMD<b>1</b> corresponds to the coordinates (x<b>1</b>, y<b>1</b>), and point b at the lower right corresponds to the coordinates (x<b>2</b>, y<b>2</b>).</p>
    <p>When a user selects one of the multiple extraction images prepared by extracting image data, it is expanded as extraction image bitmap data BMD<b>1</b>. A user can obtain the coordinate data PD by specifying an overlay position within the image data, or the position and extent of the overlay. If just an overlay position is specified, coordinates (x<b>1</b>, y<b>1</b>) are determined, and the coordinate data (x<b>2</b>, y<b>2</b>) is set based upon predetermined sizes set according to the type of extraction image concerned. The size is determined when the extraction image is extracted. When both position and extent of the overlay are specified, coordinates (x<b>1</b>, y<b>1</b>) are set according to the overlay position specified, and in accordance with the overlay extent (size) specified, coordinates (x<b>2</b>+Δx, y<b>2</b>+Δy) are substituted for (x<b>2</b>, y<b>2</b>). This enables the extraction image to be enlarged or reduced to any desired size. Although in this embodiment the extraction image bitmap data BMD<b>1</b> and coordinate data PD are stored in the extraction image bitmap memory <b>26</b>, they can instead be stored in the extraction image memory <b>24</b>.</p>
    <p>The extraction image overlay circuit <b>12</b> (FIG. 1) overlays input images and extraction images. Specifically, the extraction image overlay circuit <b>12</b> overlays image data DV<b>2</b> output by the video signal conversion circuit <b>10</b> and extraction image bitmap data BMD<b>1</b> expanded in the extraction image bitmap memory <b>26</b> (FIG. <b>4</b>(<i>c</i>)).</p>
    <p>FIG. 5 is a block diagram for schematically illustrating the configuration of the extraction image overlay circuit <b>12</b>. The extraction image overlay circuit <b>12</b> includes two multipliers <b>40</b> and <b>42</b>, an adder <b>44</b> and a coefficient setting section <b>46</b>. The two multipliers <b>40</b> and <b>42</b> and the adder <b>44</b> constitute a configuration that is provided for each of the colors RGB. Image data DV<b>2</b> output by the video processor <b>34</b> is input to the first multiplier <b>40</b>, and the extraction image bitmap data BMD<b>1</b> expanded in the extraction image bitmap memory <b>26</b> is input to the second multiplier <b>42</b>.</p>
    <p>The coefficient setting section <b>46</b> is used to set the coefficients k<b>1</b> and k<b>2</b> of the multipliers <b>40</b> and <b>42</b>. Coefficients k<b>1</b> and k<b>2</b> can each be set to a value ranging from 0 to 1, and generally are set at a value that sums to 1. The coefficients k<b>1</b> and k<b>2</b> are controlled by the coefficient setting section <b>46</b> based on the coordinate data PD (FIG. <b>4</b>(<i>c</i>)).</p>
    <p>The multipliers <b>40</b> and <b>42</b> are used to multiply each pixel data of input image data by a constant factor. In the multiplier <b>40</b>, the image data DV<b>2</b> is converted to signals multiplied by k<b>1</b>. Similarly, extraction image bitmap data BMD<b>1</b> is converted to signals multiplied by k<b>2</b>. The converted data output as image data DV<b>3</b> and extraction image bitmap data BMD<b>2</b> are input to the adder <b>44</b>.</p>
    <p>The function of the adder <b>44</b> is to add the pixel data of two input image signals. Thus, in the adder <b>44</b> the image data DV<b>3</b> and the extraction image bitmap data BMD<b>2</b> are added and output as overlay image data DDV<b>1</b>. The multipliers <b>40</b> and <b>42</b>, adder <b>44</b> and coefficient setting section <b>46</b> correspond to the synthesizer section in the projection display apparatus according to the first aspect of this invention,</p>
    <p>The overlay image data DDV<b>1</b> output by the extraction image overlay circuit <b>12</b> is supplied to the liquid crystal display driver circuit <b>14</b> (FIG. <b>1</b>). The liquid crystal display driver circuit <b>14</b> displays on the liquid crystal display panel <b>16</b> the image with the extracted image overlay corresponding to the overlay image data DDV<b>1</b>. The image displayed on the liquid crystal display panel <b>16</b> is projected onto the screen <b>104</b> by the optical systems <b>100</b> and <b>102</b>. More specifically, the light incident onto the liquid crystal display panel <b>16</b> by the illumination optical system <b>100</b> is modulated in accordance with image data supplied to the liquid crystal display panel <b>16</b>, and the light exiting from the liquid crystal display panel <b>16</b> is projected onto the projection screen <b>104</b> by the projection optical system <b>102</b>. The liquid crystal display panel <b>16</b> corresponds to the light modulation unit in the projection display apparatus according to the first invention.</p>
    <p>The projection display apparatus is controlled by the remote control section <b>28</b> in accordance with commands from the remote controller <b>29</b>. The remote control section <b>28</b> controls mainly processing related to the extraction images. In accordance with commands received from the remote controller <b>29</b>, this includes specifying the portion of an image to be extracted, selecting the type of extraction image and controlling the overlay position and extent of the extraction images, and whether the extraction images are displayed or not.</p>
    <p>Instead of hardware, the functions of the video signal conversion circuit <b>10</b>, extraction image overlay circuit <b>12</b> and remote control section <b>28</b> can be realized by a computer program. The computer program for realizing the functions of these parts can be provided in a format recorded on a computer-readable recording medium such as floppy disk, CD-ROM or the like. The program is read off the recording medium by the computer (projection display apparatus) and transferred to an internal storage device or an external storage device. Alternatively, the computer program may be supplied from a program supply apparatus via a communication route. When realizing the computer functions, a computer program stored in an internal storage device is executed by the computer CPU (microprocessor). A computer program recorded on a recording medium can also be executed directly by the computer.</p>
    <p>As used in this specification, “computer” includes hardware and an operating system, with the hardware being operated under the control of the operating system. If the hardware is operated by an application program having no need of an operating system, then the hardware itself will constitute the computer. The hardware comprises at least a microprocessor like a CPU and means for reading a program recorded on a recording medium. For this purpose, the computer program includes program code for realizing the function of each of the means described in the foregoing. Some of the functions can be implemented by the operating system instead of an application program.</p>
    <p>The recording media in this invention include floppy disks, CD-ROM disks, opto-magnetic disks, IC cards, ROM cartridges, punched cards, bar codes and other such printed symbols, internal storage devices (including RAM and ROM) and external storage devices.</p>
    <p>FIGS. <b>6</b>(<i>a</i>)-(<i>c</i>) are diagrams for explaining the overlay operation with respect to image data stored in the frame memory <b>22</b> and extraction image bitmap data BMD<b>1</b> stored in the extraction image bitmap memory <b>26</b>. FIG. <b>6</b>(<i>a</i>) shows the memory space of the frame memory <b>22</b>, containing image data (text). FIG. <b>6</b>(<i>b</i>) shows the memory space of the extraction image bitmap memory <b>26</b>, containing extraction image bitmap data BMD<b>1</b> (a graph) and coordinate data PD showing the position and extent of the overlay. The (x<b>1</b>, y<b>1</b>), (x<b>2</b>, y<b>2</b>) of this coordinate data PD in FIG. <b>6</b>(<i>b</i>) correspond to the coordinates (x<b>1</b>, y<b>1</b>) and (x<b>2</b>, y<b>2</b>) in FIG. <b>6</b>(<i>a</i>). FIG. <b>6</b>(<i>c</i>) shows the overlay image data DDV<b>1</b> consisting of the original image data overlaid with the extraction image bitmap data BMD<b>1</b>.</p>
    <p>The overlaying of the extraction image bitmap data BMD<b>1</b> on the image data is effected based on the coordinate data PD. In the extraction image overlay circuit <b>12</b> (FIG. <b>5</b>), the stream of image data is input to the first multiplier <b>40</b> while the second multiplier <b>42</b> receives only the extraction image bitmap data BMD<b>1</b> for the portion defined by the coordinates (x<b>1</b>, y<b>1</b>) and (x<b>2</b>, y<b>2</b>), which is the overlay portion. The timing of the input of the extraction image bitmap data BMD<b>1</b> to the multiplier <b>42</b> is controlled by the CPU <b>20</b> based on the coordinate data PD. Simultaneously with the input of the extraction image bitmap data BMD<b>1</b> to the multiplier <b>42</b>, the coefficients k<b>1</b> and k<b>2</b> of the multipliers <b>40</b> and <b>42</b> are adjusted. When extraction image bitmap data BMD<b>1</b> is not being input to the multiplier <b>42</b>, the coefficients k<b>1</b> and k<b>2</b> of the multipliers <b>40</b> and <b>42</b> are set to (<b>1</b>, <b>0</b>). When the extraction image bitmap data BMD<b>1</b> is being input to the multiplier <b>42</b>, the coefficients k<b>1</b> and k<b>2</b> are set to (<b>0</b>, <b>1</b>). As a result, with respect to pixels not in the area defined by the coordinate data (x<b>1</b>, y<b>1</b>) and (x<b>2</b>, y<b>2</b>), the original image data (text) shown in FIG. <b>6</b>(<i>a</i>) is output by the extraction image overlay circuit <b>12</b>, while with respect to the pixels within the area defined by the coordinates (x<b>1</b>, y<b>1</b>), (x<b>2</b>, y<b>2</b>), the extraction image bitmap data BMD<b>1</b> shown in FIG. <b>6</b>(<i>b</i>) is output by the extraction image overlay circuit <b>12</b>. In this way, the extraction image bitmap data BMD<b>1</b> is superimposed on the image data, forming the overlay image data DDV<b>1</b> representing the overlay image shown in FIG. <b>6</b>(<i>c</i>).</p>
    <p>The extraction images can be generated in the extraction image bitmap memory <b>26</b> to correspond with the overlay position within the image data. FIG. 7 is a diagram for explaining the extraction image bitmap data BMD<b>1</b> expanded in the extraction image bitmap memory <b>26</b>. A portion of the extraction image bitmap memory <b>26</b> corresponding to one frame of image data is allocated for developing the extraction image bitmap data BMD<b>1</b>, and the extraction image is expanded at the location defined by the coordinates (x<b>1</b>, y<b>1</b>), (x<b>2</b>, y<b>2</b>). When the expansion takes place, as shown in FIG. 7, pixel data of the image data and the extraction image bitmap data BMD<b>1</b> corresponding to the same position in the image are input simultaneously to the respective multipliers <b>40</b> and <b>42</b>. At this time, for areas outside the area defined by the coordinate data PD coordinates (x<b>1</b>, y<b>1</b>) and (x<b>2</b>, y<b>2</b>), the coefficients (k<b>1</b>, k<b>2</b>) are set to (<b>1</b>, <b>0</b>), while inside the area of the coordinates (x<b>1</b>, y<b>1</b>) and (x<b>2</b>, y<b>2</b>), the coefficients (k<b>1</b>, k<b>2</b>) are set to (<b>0</b>, <b>1</b>). In this way, the original image data can be overlaid with the extraction image bitmap data BMD<b>1</b>, producing the overlay image data DDV<b>1</b> representing the extraction image of FIG. <b>6</b>(<i>c</i>).</p>
    <p>As described above, when an extraction image is expanded as shown in FIG. 7, one frame of memory capacity is required as the memory area for the extraction image bitmap data BMD<b>1</b>, but when it is expanded as shown in FIG. <b>6</b>(<i>b</i>), a memory capacity that is around the same size as the bitmap expanded extraction image is sufficient, so there is the advantage that the memory capacity can be small.</p>
    <p>FIGS. <b>8</b>(<i>a</i>)-(<i>c</i>) are diagrams for explaining examples of displays on a projection screen <b>104</b> of images input from a personal computer on which extraction images have been superimposed. FIG. <b>8</b>(<i>a</i>) shows input image (text) overlaid with two extraction images (pictures of tree). FIG. <b>8</b>(<i>b</i>) shows input image (text) overlaid with-two types of extraction images (pictures of a boat and a tree). FIG. <b>8</b>(<i>c</i>) shows the input image (text) overlaid with enlarged extraction image (picture of a boat) shown in FIG. <b>8</b>(<i>b</i>).</p>
    <p>The extraction images shown in FIGS. <b>8</b>(<i>a</i>) and (<i>b</i>) are overlaid by specifying the overlay position within the projection image. In this case, the coordinate data PD comprises coordinates (x<b>1</b>, y<b>1</b>) showing the specified position, and coordinates (x<b>2</b>, y<b>2</b>) defined by the predetermined size of extraction image. The extraction image shown in FIG. <b>8</b>(<i>c</i>) is overlaid by specifying the overlay position and extent within the projection image. In this case, the coordinate data PD comprises the preset coordinates (x<b>1</b>, y<b>1</b>) and the coordinates (x<b>2</b>, y<b>2</b>) corresponding to the specified size.</p>
    <p>Also, since the extraction image bitmap data BMD<b>1</b> includes the coordinate data PD indicating the overlay position, an extraction image can be displayed at any point that is specified, using the remote controller <b>29</b>. The extraction image bitmap data BMD<b>1</b> and the coordinate data PD are being continually refreshed in sync with the sync signal RSYNC, so the remote controller <b>29</b> can be used to move an extraction image to any point within the projection image, on a realtime basis. Moreover, multiple extraction images can be displayed, as shown in FIG. <b>8</b>(<i>b</i>). A command issued by the remote controller <b>29</b> and received by the remote control section <b>28</b> can be used to execute the program in the extraction image memory <b>24</b> to generate the extraction image bitmap data BMD<b>1</b>.</p>
    <p>The shape of the extraction image extracted by the image extraction section <b>74</b> is not limited to the rectangles shown in FIGS. <b>8</b>(<i>a</i>)-(<i>c</i>). Any shape specified using the remote controller <b>29</b> can be extracted from an original image by the image extraction section <b>74</b>, so the extraction image can be oval, round, star-shaped, or a shape defined by straight lines.</p>
    <p>FIG. 9 is another diagram for explaining the display on a projection screen <b>104</b> of an image input from a personal computer on which an extraction image has been superimposed. As shown in FIG. 9, an oval extraction image (picture of boat) is superimposed on the original image (text).</p>
    <p>In this embodiment, the coordinate data PD includes two point coordinates defining the extraction image overlay position and extent. In the case of FIG. 9, the data is processed so that within the area specified by the coordinates, the portion where there is no extraction image is not overlaid.</p>
    <p>FIG. 10 is a diagram for explaining the extraction image bitmap memory <b>26</b> when the extraction image of FIG. 9 is expanded. In the case of this extraction image bitmap data BMD<b>1</b>, the shaded portion outside the oval is not to be overlaid on the input image, so the pixels of that portion are comprised using specified pixel data. The pixels where there is no extraction image are comprised of specified pixel data, for example, all the bits of the RGB pixel data can be set to 0. In this case, when the extraction image bitmap data BMD<b>1</b> is input to the coefficient setting section <b>46</b>, the coefficient setting section <b>46</b> checks the data to determine whether the pixels contain an extraction image. The system can be set so that when the input image data relates to pixels where there is no extraction image, the coefficients (k<b>1</b>, k<b>2</b>) of the multipliers <b>40</b> and <b>42</b> are changed to (<b>1</b>, <b>0</b>). This makes it possible to ensure that only that portion of the extraction image bitmap data BMD<b>1</b> that contains an extraction image will be overlaid on the original image data. It goes without saying that the coordinate data PD can be comprised of numerous point coordinates around the portion where the extraction image exists, in which case just the said portion containing the extraction image could be overlaid, based just on the coordinate data PD.</p>
    <p>In the examples shown in FIGS. <b>8</b>(<i>a</i>)-(<i>c</i>) and <b>9</b>, the extraction images appear as filled-in images on the original input image. This overlay effect is obtained by the extraction bitmap data being substituted for part of the original image. In the extraction image overlay circuit <b>12</b> (FIG. 5) the multiplier coefficients (k<b>1</b>, k<b>2</b>) are set at (<b>1</b>, <b>0</b>) for those portions where no extraction image is overlaid, while the coefficients (k<b>1</b>, k<b>2</b>) are set at (<b>0</b>, <b>1</b>) for portions where an extraction image is overlaid.</p>
    <p>Transparent extractions can be applied by changing k<b>1</b> and k<b>2</b>. Setting both k<b>1</b> and k<b>2</b> to ½, for example, would produce a transparent effect in the portion where the extraction image is overlaid on the input image.</p>
    <p>FIGS. <b>11</b>(<i>a</i>) and <b>11</b>(<i>b</i>) are diagrams for explaining projected images overlaid with transparent extracted images. FIG. <b>11</b>(<i>a</i>) shows images (graphs <b>1</b> and <b>2</b>) input from a computer. The broken line (graph <b>2</b>) denotes the area specified as the cutout portion. In FIG. <b>11</b>(<i>b</i>), the graph <b>2</b> portion of FIG. <b>11</b>(<i>a</i>) has been extracted and overlaid on graph <b>1</b>, which can be seen through graph <b>2</b>. This shows the type of transparent overlay effect that can be achieved by setting the coefficients k<b>1</b>, k<b>2</b> of the multipliers <b>40</b> and <b>42</b> in the extraction image overlay circuit (FIG. 5) to ½.</p>
    <p>The overlay images shown in FIGS. <b>8</b>(<i>a</i>)-(<i>c</i>), <b>9</b> and <b>11</b>(<i>a</i>),(<i>b</i>) were obtained using the multiplier coefficients k<b>1</b>, k<b>2</b> set at a fixed value such as 0, 1 and ½. However, k<b>1</b> and k<b>2</b> values can be used that change with time. For example, for portions where an extraction image is overlaid, the coefficients (k<b>1</b>, k<b>2</b>) can start at (<b>0</b>, <b>1</b>) and, as time passes, can be gradually changed thus: (<b>0</b>.<b>1</b>, <b>0</b>.<b>9</b>), (<b>0</b>.<b>2</b>, <b>0</b>.<b>8</b>) . . . (<b>1</b>, <b>0</b>). As a result, the extraction image overlay would start out looking solid, then would gradually become transparent and finally vanish. Such overlay effects can be obtained by changing the coefficients K<b>1</b> and K<b>2</b> with time. The coefficients are adjusted by the coefficient setting section <b>46</b> based on commands from the CPU <b>20</b>.</p>
    <p>The extraction image overlay circuit <b>12</b> and frame memory <b>22</b> of this embodiment correspond to the image overlay section according to the first aspect of this invention. Similarly, the extraction image memory <b>24</b> and extraction image bitmap memory <b>26</b> correspond to the extraction image memory of the first aspect of the invention. One of the memories <b>24</b> and <b>26</b> can be omitted.</p>
    <heading>B. Second Embodiment</heading> <p>FIG. 12 is a block diagram for schematically illustrating the general configuration of a second embodiment of the projection display apparatus according to the first aspect of the invention. The projection display apparatus includes a video signal conversion circuit <b>60</b>, a liquid crystal display driver circuit <b>14</b>, a liquid crystal display panel <b>16</b>, a frame memory <b>22</b>, an extraction image memory <b>24</b>, a remote control section <b>28</b>, a CPU <b>20</b>, an illumination optical system <b>100</b> and a projection optical system <b>102</b>. The video signal conversion circuit <b>60</b>, extraction image memory <b>24</b>, remote control section <b>28</b> and CPU <b>20</b> are connected via a bus <b>1</b>. The liquid crystal display driver circuit <b>14</b> is also connected to the bus <b>1</b>, but the connection is not shown in FIG. <b>12</b>.</p>
    <p>The projection display apparatus of this second embodiment does not have the extraction image overlay circuit <b>12</b> or the extraction image bitmap memory <b>26</b> possessed by the first embodiment. In this embodiment, the video signal conversion circuit <b>60</b> is used to overlay extraction images on the original image. Extraction image bitmap data BMD<b>1</b> is stored in the extraction image memory <b>24</b>. Thus, the video signal conversion circuit <b>60</b> and frame memory <b>22</b> correspond to the image overlay section of the first aspect of the invention. In this embodiment, only the extraction image memory <b>24</b> corresponds to the extraction image memory of the first aspect of the invention.</p>
    <p>FIG. 13 is a block diagram for schematically illustrating the configuration of the video signal conversion circuit <b>60</b>. The video signal conversion circuit <b>60</b> includes a sync separator <b>30</b>, an A-D conversion section <b>32</b> and a video processor <b>62</b>. The sync separator <b>30</b> and A-D conversion section <b>32</b> have the same functions as the first embodiment, so further explanation thereof will be omitted.</p>
    <p>The video processor <b>62</b> is a microprocessor that performs overlay processing of the input image data and extraction image bitmap data, and controls the input and output of overlay image data to and from the frame memory <b>22</b>.</p>
    <p>The image data DV<b>1</b> output by the A-D conversion section <b>32</b> and the extraction image bitmap data BMD<b>1</b> expanded in the extraction image memory <b>24</b> are input to the video processor <b>62</b>. In the video processor <b>62</b> the overlay image data is produced by selecting the image data DV<b>1</b> and the extraction image bitmap data BMD<b>1</b>, and written into the frame memory <b>22</b>. A data selector in the video processor <b>62</b> is used for selection of the image data DV<b>1</b> and extraction image bitmap data BMD<b>1</b>.</p>
    <p>FIG. 14 is a block diagram showing the configuration of the video processor <b>62</b>. The video processor <b>62</b> includes a write controller <b>70</b>, a read controller <b>72</b>, an image extraction section <b>74</b> and a data selector <b>76</b>.</p>
    <p>When image data DV<b>1</b> is input to the video processor <b>62</b>, the image extraction section <b>74</b> (FIG. 14) extracts the specified portion of the image data DV<b>1</b>, compresses the data and stores it in the extraction image memory <b>24</b> via the bus <b>1</b>. The extraction image data does not have to be compressed, and it can be reduced instead. The remote controller <b>29</b> can be used to specify the portion of the image data to be extracted. When the extraction portion has been specified, the CPU <b>20</b> outputs a sampling signal SMP corresponding to the extraction portion. Based on the sampling signal SMP, the image extraction section <b>74</b> extracts the pixel data of the specified portion. In this way, it is possible to extract just the data relating to the pixels of the specified area.</p>
    <p>Image data DV<b>1</b> and extraction image bitmap data BMD<b>1</b> expanded in the extraction image memory <b>24</b> are input to the data selector <b>76</b> (FIG. <b>14</b>), along with a selection signal SEL. There is a data selector <b>76</b> for each of the RGB colors. The selection of the image data DV<b>1</b> and extraction image bitmap data BMD<b>1</b> is done on a pixel data by pixel data basis and is controlled by means of the selection signal SEL. Thus, based on the selection signal SEL, the data selector <b>76</b> selects pixel data either one of the image data DV<b>1</b> and the extraction image bitmap data BMD<b>1</b> and writes the data into the frame memory <b>22</b>. This data written into the frame memory <b>22</b> forms the overlay image data comprised of the original image overlaid with the extraction image. The selection signal SEL is generated by the CPU <b>20</b> according to the coordinate data PD.</p>
    <p>In this embodiment the overlay images seem filled in on the original image.</p>
    <p>This corresponds to when, in the first embodiment, the coefficients (k<b>1</b>, k<b>2</b>) of the multipliers <b>40</b> and <b>42</b> of extraction image overlay circuit <b>12</b> (FIG. 5) are set at (<b>0</b>, <b>1</b>) with respect to the extraction image overlay portion.</p>
    <p>When extraction image bitmap data BMD<b>1</b> is expanded as shown in FIG. <b>6</b>(<i>b</i>), only the extraction image bitmap data BMD<b>1</b> for the area defined by the coordinate data PD coordinates (x<b>1</b>, y<b>1</b>) and (x<b>2</b>, y<b>2</b>) is input to the data selector <b>76</b>. The timing of the input of the extraction image bitmap data BMD<b>1</b> to the data selector <b>76</b> is controlled by the CPU <b>20</b>, based on the sync signal WSYNC and the coordinate data PD. The timing of the input of the extraction image bitmap data BMD<b>1</b> is determined by using coordinate data PD of the extraction image bitmap data BMD<b>1</b> to obtain the input timing of the pixel image data DV<b>1</b> for the overlay position. Simultaneously with the input of the extraction image bitmap data BMD<b>1</b>, the extraction image bitmap data BMD<b>1</b> is selected by the selection signal SEL. In this way, a selection between image data DV<b>1</b> and extraction image bitmap data BMD<b>1</b> can be made with respect to each pixel assigned to the same position in the image.</p>
    <p>When the extraction image bitmap data BMD<b>1</b> is expanded as shown in FIG. 7, pixel data of the image data DV<b>1</b> and extraction image bitmap data BMD<b>1</b> corresponding to the same position in the image are input simultaneously to the data selector <b>76</b>. The input pixel data is specified based on the sync signal WSYNC. Thus, pixel data can be assigned to the same position in the original image by synchronizing the readout of the extraction image bitmap data BMD<b>1</b> from the extraction image memory <b>24</b> with the input of the image data DV<b>1</b> to the video processor <b>62</b>. Also, the extraction image can be superimposed on the original image by using the coordinate data PD as a basis for supplying the selection signal SEL to the data selector <b>76</b>.</p>
    <p>When overlay image data is written to, or read from, the frame memory <b>22</b>, the write controller <b>70</b> and read controller <b>72</b> generate addresses ADD<b>1</b>, ADD<b>2</b> and control signals CTR<b>1</b>, CTR<b>2</b>, which are supplied to the frame memory <b>22</b>.</p>
    <p>Overlay image data is written to the frame memory <b>22</b> in accordance with address ADD<b>1</b> and control signal CTR<b>1</b> generated by the write controller <b>70</b>, and read out of the frame memory <b>22</b> in accordance with address ADD<b>2</b> and control signal CTR<b>2</b> generated by the read controller <b>72</b>. These addresses and control signals are based on the sync signals WSYNC and RSYNC.</p>
    <p>The writing of overlay image data to the frame memory <b>22</b> is synchronized with the sync signal WSYNC. The reading of overlay image data from the frame memory <b>22</b> is synchronized with the sync signal RSYNC output by the liquid crystal display driver circuit <b>14</b> (FIG. <b>12</b>). The sync signals WSYNC and RSYNC are not mutually synchronized. However, sync signals WSYNC and RSYNC can be synchronized.</p>
    <p>In this embodiment the overlay image data can be obtained by writing directly to the frame memory <b>22</b>. Overlay image data written to the frame memory <b>22</b> is read out by the video processor <b>62</b>.</p>
    <p>Overlay image data DDV<b>2</b> output by the video signal conversion circuit <b>60</b> (FIG. 12) is supplied to the liquid crystal display driver circuit <b>14</b> (FIG. <b>12</b>). Based on this overlay image data DDV<b>2</b>, the liquid crystal display driver circuit <b>14</b> displays on the liquid crystal display panel <b>16</b> the image overlaid with the extraction image. The image displayed on the liquid crystal display panel <b>16</b> is projected onto the projection screen <b>104</b> by the optical systems <b>100</b> and <b>102</b>.</p>
    <p>In the first and second embodiments described in the foregoing, at least a portion of images input to the projection display apparatus can be extracted as the extraction image internally. It is therefore possible to extract part of one input image and overlay it on another. This means it is possible to extract an image from an image signal input from a personal computer, video recorder or TV and overlay the extracted image on an input image. Moreover, by using the coordinate data PD, an extraction image can be superimposed at any desired point on the input image, and enlarged or reduced.</p>
    <heading>C. Third Embodiment</heading> <p>Embodiments of a second aspect of the invention are described below.</p>
    <p>C-1. Configuration and Operation of the Projection Display Apparatus:</p>
    <p>FIG. 15 is a block diagram for schematically illustrating the general configuration of an embodiment of the projection display apparatus according to a second aspect of the invention. The projection display apparatus includes a video signal processing circuit <b>210</b>, an on-screen display (OSD) controller <b>212</b>, an OSD memory <b>213</b>, a liquid crystal light valve driver circuit <b>214</b>, a liquid crystal light valve <b>216</b>, a frame memory <b>222</b>, an extraction image memory <b>224</b>, a remote control section <b>28</b>, a CPU <b>20</b>, an illumination optical system <b>100</b> and a projection optical system <b>102</b>. The video signal processing circuit <b>210</b>, OSD controller <b>212</b>, extraction image memory <b>224</b>, remote control section <b>28</b> and CPU <b>20</b> are connected by a bus <b>1</b>.</p>
    <p>The video signal processing circuit <b>210</b> is used to perform analog-digital conversion of input analog video signals AV<b>1</b>, write the converted image data into the frame memory <b>222</b> and retrieve image data from the frame memory <b>222</b>. The analog video signal AV<b>1</b> can be an RGB signal S<b>1</b> carrying a computer screen image, or a composite image signal S<b>2</b> from a video recorder, TV or the like.</p>
    <p>FIG. 16 is a block diagram for schematically illustrating the configuration of the video signal processing circuit <b>210</b>. The video signal processing circuit <b>210</b> includes a sync separator <b>230</b>, an A-D conversion section <b>232</b> and a video processor <b>234</b>. The functions of the sync separator <b>230</b> and A-D conversion section <b>232</b> are the same as those of the sync separator <b>30</b> and A-D conversion section <b>32</b> of the first embodiment (FIG. <b>2</b>), so further explanation thereof will be omitted.</p>
    <p>The video processor <b>234</b> is a microprocessor that performs various image processing functions such as controlling the input and output of image data and extraction image data to and from the frame memory <b>222</b> and extraction image memory <b>224</b>. Image data DV<b>1</b> from the A-D conversion section <b>232</b> is input to the video processor <b>234</b>. Specific image data that includes extraction image data CPD<b>1</b> stored in the extraction image memory <b>224</b> and background image data BGD<b>1</b> generated by the CPU <b>20</b> is input to the video processor <b>234</b>, via bus <b>1</b>.</p>
    <p>FIG. 17 is a block diagram showing the configuration of the video processor <b>234</b>. The video processor <b>234</b> includes a write controller <b>270</b>, a read controller <b>272</b>, an extraction controller <b>274</b> and a data selector <b>276</b>. The controllers <b>270</b> and <b>272</b> have the same functions as the controllers <b>70</b> and <b>72</b> of the first embodiment (FIG. <b>3</b>), so further explanation thereof will be omitted.</p>
    <p>Image data DV<b>1</b> and specific image data SPD<b>1</b> that includes extraction image bitmap data BMD<b>1</b> stored in the extraction image memory <b>224</b> and background image data BGD generated by the CPU <b>20</b> are input to the data selector <b>276</b>, along with a selection signal SEL. There is a data selector <b>276</b> for each of the colors RGB. The selection of the image data DV<b>1</b> and specific image data SPD<b>1</b> is controlled by the selection signal SEL. Which data is selected depends on whether the system is in normal display mode or specific image display mode. These modes are discussed below. Based on the selection signal SEL, the data selector <b>276</b> selects either image data DV<b>1</b> or specific image data SPD<b>1</b>. Thus, according to the system mode, either one of image data DV<b>1</b> and specific image data SPD<b>1</b> is written into the frame memory <b>222</b>. When user uses the remote controller <b>29</b> to select the system mode, the selection signal SEL is generated by the CPU <b>20</b>.</p>
    <p>The writing of image data to the frame memory <b>222</b> is synchronized by the sync signal WSYNC when the data to be written to the memory <b>222</b> is input image data DV<b>1</b>. When the data to be written to the memory <b>222</b> is specific image data SPD<b>1</b>, the write operation is controlled by signals supplied to the write controller <b>270</b> by the CPU <b>20</b>. The retrieval of image data from the frame memory <b>222</b> and the downstream processing of image data DV<b>2</b> output by the video processor <b>234</b> are synchronized by the sync signal RSYNC output by the liquid crystal display driver circuit <b>214</b> (FIG. <b>15</b>), discussed below, which is optimized for driving the liquid crystal light valve <b>216</b>. The sync signal RSYNC is produced by a sync signal generator (not shown) in the video processor <b>234</b>. The sync signals WSYNC and RSYNC are not mutually synchronized. However, sync signals WSYNC and RSYNC can be used synchronized. The sync signal generator does not have to be provided in the video processor <b>234</b>, and can instead be provided in the liquid crystal light valve driver circuit <b>214</b>, for example, or can be configured as an independent component.</p>
    <p>When image data that has been written to the frame memory <b>222</b> is read out, the function of the extraction controller <b>274</b> is to extract a specified portion of the image data. The extraction controller <b>274</b> also enlarges or reduces the extraction image data in accordance with the enlarging/reducing factor that has been set. Another function of the extraction controller <b>274</b> is to write the extraction image data CPD<b>1</b> to the extraction image memory <b>224</b> via the bus <b>1</b>. The portion of the image data to be extracted (extraction area) can be specified using the remote controller <b>29</b>. When the extraction area has been specified, the CPU <b>20</b> outputs an extraction address SADD corresponding to the extraction portion. Based on the extraction address SADD and address ADD<b>2</b> read from the read controller <b>272</b>, the extraction controller <b>274</b> extracts the image data of the specified portion. This make it possible to extract only the specified portion of the image data.</p>
    <p>Image data DV<b>1</b> or specific image data SPD<b>1</b> stored in the frame memory <b>222</b> is read out of the frame memory and output from the video processor <b>234</b> as image data DV<b>2</b>. The readout operation is synchronized by the sync signal RSYNC.</p>
    <p>The extraction image memory <b>224</b> shown in FIG. 15 is for storing extraction image data CPD<b>1</b> extracted by the extraction controller <b>274</b> of the video processor <b>234</b> (FIG. <b>17</b>). Extraction image data CPD<b>1</b> is stored in the extraction image memory <b>224</b> in a specific format. There are no particular limitations on the specific format other than it be decided beforehand. For example, it can be compressed data, or bitmap data. If the extraction image data CPD<b>1</b> is specified as compressed data, it is written into the extraction image memory <b>224</b> after being compressed by the CPU <b>20</b> or the extraction controller <b>274</b>. Similarly, when the data is read out of the extraction image memory <b>224</b>, it is expanded by the CPU <b>20</b> or the extraction controller <b>274</b>.</p>
    <p>FIG. 18 is a diagram illustrating the extraction image memory <b>224</b>. The extraction image memory <b>224</b> stores the data for one extraction image. The stored data includes an information ID denoting the content of the extraction image data, and extraction image data CPD<b>1</b>. The extraction image memory <b>224</b> is not limited to storing one set of data, and may instead be used to store multiple sets.</p>
    <p>The OSD controller <b>212</b> shown in FIG. 15 generates OSD image data representing pointer images and menu screens for controlling the functions of each part of the projection display apparatus in accordance with commands received from the remote controller <b>29</b> via the remote control section <b>28</b>. The OSD memory <b>213</b> contains pointer image data and graphics and font data for the menu screens, stored in a specific format. To display the menu screens and pointers images, the OSD controller <b>212</b> reads out the corresponding data from the OSD memory <b>213</b> and generates OSD image data. The OSD controller <b>212</b> combines this OSD image data with image data DV<b>2</b> output by the video signal processing circuit <b>210</b>. The image data DV<b>2</b> and OSD image data could also be combined by providing the OSD controller <b>212</b> with a selector. Alternatively, it could be done by providing two multipliers that multiple the image data DV<b>2</b> and OSD image data by a fixed factor, and an adder that adds the results of the multiplications. Images for specifying the extraction area (extraction area specifying image) are generated by the OSD controller <b>212</b>.</p>
    <p>Image data DV<b>3</b> output by the OSD controller <b>212</b> is input to the liquid crystal light valve driver circuit <b>214</b>. Based on the image data DV<b>3</b>, the illumination light from the illumination optical system <b>100</b> is modulated by the liquid crystal light valve <b>216</b>, and the modulated light is projected onto the screen <b>104</b> by the projection optical system <b>102</b> to display the image. The liquid crystal light valve <b>216</b> corresponds to the electro-optical device of the second aspect of the invention. The liquid crystal light valve driver circuit <b>214</b> corresponds to the image display signal generator of the second aspect of the invention.</p>
    <p>Here, the term projection optical system is used in a broad sense that also encompasses the illumination optical system. The liquid crystal light valve driver circuit <b>214</b> can be formed on the substrate of the liquid crystal light valve <b>216</b> as the electro-optical device, integrating the two components.</p>
    <p>The image data DV<b>3</b> output by the OSD controller <b>212</b> can be enlarged or reduced by an enlarging/reducing circuit (not shown) provided between the OSD controller <b>212</b> and the liquid crystal light valve driver circuit <b>214</b>.</p>
    <p>The projection display apparatus is controlled by the remote control section <b>28</b>, based on commands from the remote controller <b>29</b> (FIG. <b>15</b>). The remote control section <b>28</b> controls mainly processing related to extraction images. In accordance with commands received from the remote controller <b>29</b>, this includes specifying the extraction portion of the image data, and whether extraction images are displayed or not.</p>
    <p>The functions of the video signal processing circuit <b>210</b>, OSD controller <b>212</b> and remote control section <b>28</b> can be implemented by a computer program instead of in hardware.</p>
    <p>When the remote controller <b>29</b> is used to select the normal image display mode, digital image data DV<b>1</b> representing analog image signals AV<b>1</b> externally input to the video signal processing circuit <b>210</b> is stored in the frame memory <b>222</b> and the images can be displayed on the screen <b>104</b>. FIG. 19 is a diagram for explaining externally input images displayed on the projection screen <b>104</b>. When the remote controller <b>29</b> is used to select the specific image display mode, background image data BGD<b>1</b> generated by the CPU <b>20</b> and extraction image data CPD<b>1</b> stored in the extraction image memory <b>224</b> are stored in the frame memory <b>222</b> as specific image data SPD<b>1</b> and the specific images represented by the data SPD<b>1</b> can be displayed on the screen <b>104</b>. FIG. 20 is a diagram for explaining the projection screen display of a specific image represented by the specific image data SPD<b>1</b> that includes background image data BGD<b>1</b> and extraction image data CPD<b>1</b> stored in extraction image memory <b>224</b>.</p>
    <p>When the user selects the specific image display mode, an extraction image an be selected from among those stored in the extraction image memory <b>224</b> and displayed as a specific image. It is also possible to select multiple extraction images from among those stored in the extraction image memory <b>224</b> and have them displayed repeatedly in order. FIGS. <b>21</b>(<i>a</i>)-(<i>c</i>) are diagrams for explaining the display on the projection screen <b>104</b> of sequentially selected extraction images represented by extraction image data CPD<b>1</b> (A), CPD<b>1</b> (B) and CPD<b>1</b> (C).</p>
    <p>During question and answer sessions in a presentation or when a short time is needed before a new set of images can be displayed, the presentation can be enhanced by displaying specific images in the form of corporate logos and product images and the like instead of presentation images.</p>
    <p>The extraction image data CPD<b>1</b> stored in the memory <b>224</b> can be extracted as explained below.</p>
    <p>C-2. Extracting Images:</p>
    <p>FIGS. 22 to <b>27</b> are diagrams illustrating the procedure for cutting away from an image being input to the projection display apparatus, to an extraction image (a user logo image). FIGS. 22 to <b>27</b> shown display images on the projection screen <b>104</b>.</p>
    <p>The remote controller <b>29</b> has a menu key (not shown). When the menu key is pressed, the OSD controller <b>212</b> (FIG. 15) displays a menu screen. Selecting the menu entry “Extraction image setting ” and pressing the enter key on the remote controller <b>29</b> initiates the extraction image setting mode. Below, the term “select” will be used to mean using the remote controller <b>29</b> to select a menu item such as letters and areas and pressing the enter key on the remote controller <b>29</b>. When the extraction image setting mode starts, the writing of data to the frame memory <b>222</b> is stopped. This stop can be done according to starting the extraction image setting mode. A user can use the selection of this mode by using remote controller <b>29</b> as a way of stopping a display of such as moving images.</p>
    <p>When the writing of data to the frame memory <b>222</b> stops, the image in the frame memory <b>222</b> at that point is displayed on the screen, as shown in FIG. <b>22</b>.</p>
    <p>Also, the extraction image setting screen is displayed by the OSD controller <b>212</b>, showing the question “Use part of this image as an extraction image?” It is decided whether or not to extract image from present displayed image. Extracted image is referred to as extraction target image. If “No” is selected, the extraction image setting mode is terminated and the menu screen reappears. If “Yes” is selected, the OSD controller <b>212</b> displays a selecting frame WF of a preset size for selecting the extraction image, as shown in FIG. <b>23</b>. The selecting frame WF comprises two black outlines separated by a white space. This makes the selecting frame WF readily visible on the images. Thus, user can easily select a extraction area. If required, a system configuration can be used that allows the size of the frame to be set by the user. On the remote controller <b>29</b>, a pointing device, such as an arrow-key device, is used to position the selecting frame WF and select the part to be extracted on the extraction target image.</p>
    <p>As shown in FIG. 24, when user selects the part of the extraction target image, the selected image (referred to as selected extraction image) SCPD is then displayed in the center of the screen. A black image is used to mask portions other than the selected extraction image SCPD. The OSD controller <b>212</b> then displays the question “Use this image?” on the extraction image setting screen. It is decided whether or not to use the present image. If “No” is selected, the extraction image setting mode is terminated and the menu screen reappears. If “Yes” is selected, the OSD controller <b>212</b> displays “Please set display magnification,” shown in FIG. <b>25</b>.</p>
    <p>When one of the magnifications displayed on the extraction image setting screen is chosen, the selected extraction image SCPD is displayed at that magnification. If a different magnification is then chosen, the image will be displayed at the new magnification. This enables users to try different settings before making a final selection. Desired magnification is set by pressing the enter key. The system can instead be configured to accept any desired magnification setting.</p>
    <p>When the extraction image and magnification have been selected, the OSD controller <b>212</b> displays “Save this image?” on the extraction image setting screen, as shown in FIG. <b>26</b>. It is decided whether or not to save the image data representing this image in the extraction image memory <b>224</b> (FIG. 15) as extraction image data CPD<b>1</b>. If “No” is selected, the extraction image setting mode is terminated and the menu screen reappears. If “Yes” is selected the extraction image data CPD<b>1</b> is saved in the extraction image memory <b>224</b> (FIG. 15) and the message “The extraction image has been saved” is displayed (FIG. <b>27</b>). During setting above, menu screen reappears by pressing the menu key.</p>
    <p>This procedure enables a user to readily select a desired extraction target image and extract a desired image by following the extraction image setting screens. Also, the image can be saved in the extraction image memory <b>224</b> with a chosen condition (magnification), which can be checked before final selection.</p>
    <p>The video processor <b>234</b>, OSD controller <b>212</b>, remote control section <b>28</b> and CPU <b>20</b> of this embodiment correspond to the image extraction section and specific image display control section according to the second aspect of the invention.</p>
    <heading>D. Fourth Embodiment</heading> <p>FIG. 28 is a block diagram for schematically illustrating the general configuration of an embodiment of the projection display apparatus according to second and third aspects of the invention. Other than the inclusion of an operating condition judging section <b>226</b>, this projection display apparatus has the same configuration as that of the third embodiment, so further explanation thereof will be omitted.</p>
    <p>FIG. 29 is a block diagram showing the configuration of the operating condition judging section <b>226</b>. The operating condition judging section includes an image signal detector <b>242</b>, a system start detector <b>244</b> and a judging section <b>246</b>. The image signal detector <b>242</b> receives the sync signal WSYNC included in the image signal and detects whether an image signal is being input to the projection display apparatus. The system start detector <b>244</b> receives a power supply voltage Vcc and detects whether the projection display apparatus is on and can display an image. Based on the detection signals D<b>1</b> and D<b>2</b> signifying detection by the image signal detector <b>242</b> and system start detector <b>244</b>, the judging section <b>246</b> judges whether an externally input image can be displayed.</p>
    <p>FIGS. <b>30</b>(<i>a</i>)-(<i>e</i>) are time charts of the operation of the operating condition judging section <b>226</b>. FIG. <b>30</b>(<i>a</i>) shows the power supply voltage Vcc, FIG. <b>30</b>(<i>b</i>) shows start detection signal D<b>2</b> output from the system start detector <b>244</b>, FIG. <b>30</b>(<i>c</i>) shows the sync signal WSYNC included in image signals input to the projection display apparatus, FIG. <b>30</b>(<i>d</i>) shows detection signal D<b>1</b> output from the image signal detector <b>242</b>, and FIG. <b>30</b>(<i>e</i>) shows operating condition judging signal SPDMODE.</p>
    <p>When the supply voltage Vcc is high enough for the projection display apparatus to start operating, after a prescribed interval T<b>2</b> the start detection signal D<b>2</b> changes from Low to High. Once the projection display apparatus is provided with a supply voltage, it is ready to display specific images in a relatively short time. However, some time is required as a stabilization period before externally input images can be displayed, to allow such as sync clocks to be generated on which internal circuits are operated. The period T<b>2</b> represents this stabilization period. When the start detection signal D<b>2</b> is Low it signifies that the system is not yet display-operational. At this time, the operating condition judging signal SPDMODE also is Low, signifying that the system is in the specific image display mode in which specific images are displayed. When the start detection signal D<b>2</b> goes High, signal SPDMODE also goes High, signifying the system is in the normal display mode in which input images are displayed.</p>
    <p>The image signal detector <b>242</b> detects whether the sync signal WSYNC is being input at prescribed intervals Tc as shown in FIG. <b>30</b>(<i>c</i>). When the pulse signal is being input at the prescribed intervals Tc, sync detection signal D<b>1</b> goes High as shown in FIG. <b>30</b>(<i>d</i>). When it is detected that pulse signal is not being input at the intervals Tc, after a prescribed period T<b>1</b> the sync detection signal D<b>1</b> goes Low. The prescribed period T<b>1</b> represents a detection margin. When detection signal D<b>1</b> is Low, operating condition judging signal SPDMODE changes to Low, and specific images can be displayed.</p>
    <p>Thus, in this embodiment, after the projection display apparatus has been started the operating condition judging section <b>226</b> detects whether the system state enables images to be displayed, and also detects whether an image signal is being received. The system can then automatically switch between normal display mode in which input images are displayed, and specific image display mode in which specific images (explained in third embodiment) are displayed.</p>
    <p>The operating condition judging section <b>226</b> of this embodiment corresponds to the operating condition judging section of the second and third aspects of the invention. Also, the video processor <b>234</b>, OSD controller <b>212</b> and CPU <b>20</b> correspond to the image extraction section and specific image display control section of the second and third aspects.</p>
    <p>Although the image signal detector <b>242</b> uses the sync signal WSYNC to detect whether image signals are being input, this is not limitative, and various detection methods can be used. For example, color signals or luminance signals could be used, with an image signal staying at black level for a certain time signifying that an image signal is not being received.</p>
    <p>The present invention is in no way limited to the details of the examples and embodiments described in the foregoing but various changes and modifications may be made without departing from the scope. For example, the following modifications are also possible.</p>
    <p>The first to fourth embodiments have been described using a projection display apparatus as an example, but this is not limitative, with the invention being applicable to various other types of image display apparatus.</p>
    <p>In the case of the first embodiment, the data selector <b>76</b> shown in FIG. 14 could be used to superimpose the extraction images instead of the two multipliers and <b>42</b> and the adder <b>44</b> used in the extraction image overlay circuit <b>12</b> (FIG. <b>5</b>). This would enable the extraction images to be given a filled-in effect equivalent to the effect obtained when the coefficients (k<b>1</b>, k<b>2</b>) of the multipliers <b>40</b>, <b>42</b> are set at (<b>1</b>, <b>0</b>) or (<b>0</b>, <b>1</b>).</p>
    <p>With respect again to the multipliers <b>40</b> and <b>42</b> and the adder <b>44</b> used by the circuit <b>12</b> to superimpose extraction images in the first embodiment, if the coefficients k<b>1</b> and k<b>2</b> are both set at ½ to provide transparent images, the multipliers <b>40</b> and <b>42</b> will not be needed. Instead, the same effect can be obtained by effecting a bit shift in the adder <b>44</b> to remove the low-order bit from the data that is added.</p>
    <p>In the second embodiment, the multipliers and adder shown in FIG. 5 can be used instead of the data selector <b>76</b> (FIG. 14) to superimpose extraction images. This would enable transparent as well as filled-in overlay effects to be provided.</p>
    <p>In the first and second embodiments, while memory capacity equivalent to one frame of image data is allocated for expanding extraction images, as shown in FIG. 7, the same effect can be obtained by using flags in place of coordinate data PD. For example, the pixel data of an extraction graphic in the extraction bitmap data could be provided with a one-bit flag that could be used to determine the presence or absence of the graphic. Depending on the presence or absence of the flag, an adjustment could be made to the coefficients k<b>1</b>, k<b>2</b> of the multipliers <b>40</b>, <b>42</b> (FIG. <b>5</b>), in the case of the first embodiment, or to the selection by the data selector <b>76</b> (FIG. <b>14</b>), in the case of the second embodiment. In this way, the same effect could be obtained as when coordinate data is used.</p>
    <p>In the first and second embodiments, extraction image bitmap data BMD<b>1</b> is expanded and stored in the extraction image bitmap memory <b>26</b> or extraction image memory <b>24</b>, but this expansion is not limited to the memories <b>26</b> and <b>24</b> and may be effected in other storage areas prepared for the purpose.</p>
    <p>In the first and second embodiments, the only extraction images stored in the extraction image memory <b>24</b> are those extracted by the extraction controller <b>74</b>, but this is not limitative. Instead, images produced using other devices, such as scanned images and images produced on a computer, can also be stored in the extraction image memory <b>24</b>. Doing this makes it possible to overlay original images with other images in addition to images extracted by the projection display apparatus.</p>
    <p>In the first and second embodiments, moreover, images to be superimposed on input images are maintained in the extraction image memory <b>24</b>, but the invention is not limited to this configuration. Instead, bitmap data of graphics drawn using the remote controller <b>29</b> could be written directly to the extraction image bitmap memory <b>26</b>, enabling drawn images to be used as overlays. This would make it possible for a user using a drawing program to overlay an extraction image of a desired shape, such as a free curve or the like, specified with the remote control <b>29</b>.</p>
    <p>The third and fourth embodiments have been described with reference to writing specific image data SPD<b>1</b> into the frame memory <b>222</b> to display specific images, but the invention is not limited to this. Instead, for example, the specific image data SPD<b>1</b> can be written to the OSD memory <b>213</b> and displayed as OSD images by the OSD controller <b>212</b>.</p>
    <p>The third embodiment, has been described, using as an example, employing the image extraction section according to the second aspect of the invention to display specific images that include arbitrarily extracted images. However, this is not limitative. A projection display apparatus configuration can be used that does not include an image extraction section, with specific images supplied by a computer or from recording media read by a reading apparatus being displayed.</p>
    <p>The operating conditions described with reference to the fourth embodiment are not limited to the operational status of the projection display apparatus or to whether image signals are being received. Various other conditions can be set and associated detection circuits included in the operating condition judging section.</p>
    <p>In the first and second embodiments a liquid crystal display panel <b>16</b> is used as the light modulation unit of the projection display apparatus, but the invention is not limited to this and can use as the light modulation unit any means that is able to modify luminance based on the image data. For example, a light modulation unit can be used that utilizes light reflected by a pixel array of mirror elements, or a CRT or plasma display panel or the like. Note that, usually, a CRT or plasma display panel are not called light modulation unit.</p>
    <p>Similarly, the electro-optical device used in the third and fourth embodiments is not limited to the liquid crystal light valve <b>216</b>. Various other devices that emit light according to image signal are usable as electro-optical device, such as a DMD (digital micromirror device, trademark of Texas Instruments Inc.), CRT or plasma display panel.</p>
    <p>In the described embodiments, part of the configuration implemented by hardware can instead be implemented by software and, conversely, part of the configuration implemented by software can instead by implemented by hardware.</p>
    <heading>Industrial Applicability</heading> <p>The present invention is applicable to a variety of image display apparatuses. The projection display apparatuses of the present invention is applicable to projecting onto a screen images input by such as a computer and a video recorder.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4835532">US4835532</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 29, 1988</td><td class="patent-data-table-td patent-date-value">May 30, 1989</td><td class="patent-data-table-td ">Honeywell Inc.</td><td class="patent-data-table-td ">Nonaliasing real-time spatial transform image processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5003616">US5003616</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 31, 1988</td><td class="patent-data-table-td patent-date-value">Mar 26, 1991</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Image processing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5633755">US5633755</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 5, 1996</td><td class="patent-data-table-td patent-date-value">May 27, 1997</td><td class="patent-data-table-td ">Nikon Corporation</td><td class="patent-data-table-td ">Projection apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5757980">US5757980</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 21, 1994</td><td class="patent-data-table-td patent-date-value">May 26, 1998</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Pattern image adding apparatus for adding a pattern to an end of a designated area</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6097840">US6097840</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 28, 1996</td><td class="patent-data-table-td patent-date-value">Aug 1, 2000</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Profile extracting method and system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6222593">US6222593</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 30, 1997</td><td class="patent-data-table-td patent-date-value">Apr 24, 2001</td><td class="patent-data-table-td ">Olympus Optical Co. Ltd.</td><td class="patent-data-table-td ">Image projecting system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6389155">US6389155</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 16, 1998</td><td class="patent-data-table-td patent-date-value">May 14, 2002</td><td class="patent-data-table-td ">Sharp Kabushiki Kaisha</td><td class="patent-data-table-td ">Image processing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH0546135A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNF0K9onei-wxp94MRLOdad23kQI9w">JPH0546135A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH0686165A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHmVvClVePoHHtYiFme2AN7eXBd3g">JPH0686165A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH0869271A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEIGNXrJLp_VFvUBX1bTTIjTkuc9A">JPH0869271A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH04168478A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFnXmtDYQeSIwVkjSoWvAFP28jtgw">JPH04168478A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH04205476A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNG2IDoeSW0o5O9mOBVH_meK5y6RuQ">JPH04205476A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH04284495A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHCMpgLq_CkQem7FP7-SD9uBT3jXA">JPH04284495A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH05183853A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEt-3Wqmly-IzKlKFhegG4nWPG2gQ">JPH05183853A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH06295339A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNH1MA80YvA5X9L1a7Cye96M-dNxCw">JPH06295339A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DS59276A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNG9WEExLIvXVZYrmY_I5LNo7Y5OpA">JPS59276A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DS5627195A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGuCy1FGAZCE8f9486BTw-VwDD1Aw">JPS5627195A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DS5667445A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEG5HQfrQzHXhmtV0LmdPcwxpV2fQ">JPS5667445A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DS60176093A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNH-EMpyZPbdGBk2b4T2MTlN8WfVPA">JPS60176093A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DS60232597A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHpErBxemcXYRuo8Gbu485HkjF0yQ">JPS60232597A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DS62276672A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFAc0rrtDyFYxaXoHAb9NgXP1VEPA">JPS62276672A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7230628">US7230628</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 5, 2000</td><td class="patent-data-table-td patent-date-value">Jun 12, 2007</td><td class="patent-data-table-td ">Shutterfly, Inc.</td><td class="patent-data-table-td ">Previewing a framed image print</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7253822">US7253822</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 21, 2004</td><td class="patent-data-table-td patent-date-value">Aug 7, 2007</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Picture displaying apparatus, picture displaying method, picture displaying program, and computer readable record medium containing the picture displaying program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7256841">US7256841</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 5, 2004</td><td class="patent-data-table-td patent-date-value">Aug 14, 2007</td><td class="patent-data-table-td ">Mitsubishi Electric Corporation</td><td class="patent-data-table-td ">Projection display apparatus and method for projecting image onto a screen</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7486843">US7486843</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 4, 2005</td><td class="patent-data-table-td patent-date-value">Feb 3, 2009</td><td class="patent-data-table-td ">Nec Electronics Corporation</td><td class="patent-data-table-td ">Image processing overlaying one image on another</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8089647">US8089647</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 18, 2004</td><td class="patent-data-table-td patent-date-value">Jan 3, 2012</td><td class="patent-data-table-td ">Fuji Xerox Co., Ltd.</td><td class="patent-data-table-td ">Information processing device and method, and data communication system for acquiring document data from electronic paper</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080304745">US20080304745</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 4, 2008</td><td class="patent-data-table-td patent-date-value">Dec 11, 2008</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Image display apparatus, image display method, and recording medium containing an image-display-method program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/DE102004041347B4?cl=en">DE102004041347B4</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 26, 2004</td><td class="patent-data-table-td patent-date-value">Apr 16, 2009</td><td class="patent-data-table-td ">Fujitsu Frontech Limited, Inagi</td><td class="patent-data-table-td ">Bildanzeigegerät, Bildanzeigeverfahren, Bildanzeigeprogramm und computerlesbares Aufzeichungsmedium, enthaltend das Bildanzeigeprogramm</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S629000">345/629</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S625000">345/625</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S636000">345/636</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S628000">345/628</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S283000">382/283</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S284000">382/284</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S638000">345/638</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc345/defs345.htm&usg=AFQjCNF0b52M2HqQQp5rThx3mQ75nwjbGg#C345S634000">345/634</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348SE05137">348/E05.137</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348SE05105">348/E05.105</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S173000">382/173</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc382/defs382.htm&usg=AFQjCNEqDOPTZQm3eGeSecvjb7gyEoTppw#C382S282000">382/282</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc348/defs348.htm&usg=AFQjCNHmQdDBdWG-OR5Ys7dyx9RrqLjUZg#C348SE05100">348/E05.1</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09G0005390000">G09G5/39</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005740000">H04N5/74</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09G0003340000">G09G3/34</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G09G0005397000">G09G5/397</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0005445000">H04N5/445</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N5/74">H04N5/74</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G09G3/34">G09G3/34</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N5/44504">H04N5/44504</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G09G2340/12">G09G2340/12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G09G5/39">G09G5/39</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G09G2340/02">G09G2340/02</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G09G5/397">G09G5/397</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Z_JpBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N5/44543">H04N5/44543</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N5/445C</span>, <span class="nested-value">G09G5/39</span>, <span class="nested-value">H04N5/74</span>, <span class="nested-value">H04N5/445M</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">May 16, 2012</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 7, 2011</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIM 10 IS CONFIRMED. CLAIMS 1, 7, 8, 9, AND 11 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 4-6, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. NEW CLAIMS 12-17 ARE ADDED AND DETERMINED TO BE PATENTABLE. CLAIMS 2 AND 3 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 5, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100630</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 30, 2008</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 3, 2000</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SEIKO EPSON CORPORATION, JAPAN</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ITOH, TAKAFUMI;AKAIWA, SHOICHI;REEL/FRAME:010995/0049</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20000724</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0bBRcRjCNVNmA7pZiiZkZxJM_awg\u0026id=Z_JpBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U1phez7KexxQCvukEwi_G0wYdUixw\u0026id=Z_JpBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2R-Nog_vrUdtg2qk6qcu2MNjgH0A","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Projection_display_apparatus_display_met.pdf?id=Z_JpBAABERAJ\u0026output=pdf\u0026sig=ACfU3U0rw0tDE3gaXaUHebFlMS2teGVLvw"},"sample_url":"http://www.google.com/patents/reader?id=Z_JpBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>