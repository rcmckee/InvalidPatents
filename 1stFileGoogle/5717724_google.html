<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5717724 - Voice encoding and voice decoding apparatus - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Voice encoding and voice decoding apparatus"><meta name="DC.contributor" content="Yasushi Yamazaki" scheme="inventor"><meta name="DC.contributor" content="Tomohiko Taniguchi" scheme="inventor"><meta name="DC.contributor" content="Tomonori Sato" scheme="inventor"><meta name="DC.contributor" content="Hisanari Kimura" scheme="inventor"><meta name="DC.contributor" content="Fujitsu Limited" scheme="assignee"><meta name="DC.date" content="1995-8-4" scheme="dateSubmitted"><meta name="DC.description" content="To improve the voice quality of a digital mobile communication system such as a car telephone or portable telephone when outdoor background noises are superimposed on voices. To achieve the above object, a voice decoding apparatus comprises noise superimposed part detecting means for discriminating between a noise part containing only noises and a voice part containing voices from signal encoded at a transmission side, voice decoding means for decoding an encoded signal in the voice part into a waveform signal, noise decoding means for decoding an encoded signal in the noise part into a waveform signal, and noise control means for controlling the frequency characteristic of said noise part by controlling said noise decoding means when said noise superimposed part detecting means judges the noise part."><meta name="DC.date" content="1998-2-10" scheme="issued"><meta name="DC.relation" content="US:5327461" scheme="references"><meta name="DC.relation" content="US:5448679" scheme="references"><meta name="citation_patent_number" content="US:5717724"><meta name="citation_patent_application_number" content="US:08/511,417"><link rel="canonical" href="http://www.google.com/patents/US5717724"/><meta property="og:url" content="http://www.google.com/patents/US5717724"/><meta name="title" content="Patent US5717724 - Voice encoding and voice decoding apparatus"/><meta name="description" content="To improve the voice quality of a digital mobile communication system such as a car telephone or portable telephone when outdoor background noises are superimposed on voices. To achieve the above object, a voice decoding apparatus comprises noise superimposed part detecting means for discriminating between a noise part containing only noises and a voice part containing voices from signal encoded at a transmission side, voice decoding means for decoding an encoded signal in the voice part into a waveform signal, noise decoding means for decoding an encoded signal in the noise part into a waveform signal, and noise control means for controlling the frequency characteristic of said noise part by controlling said noise decoding means when said noise superimposed part detecting means judges the noise part."/><meta property="og:title" content="Patent US5717724 - Voice encoding and voice decoding apparatus"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("uqntU-LRH4PVsQSH8YCwCQ"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("NOR"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("uqntU-LRH4PVsQSH8YCwCQ"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("NOR"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5717724?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5717724"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=DhZFBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5717724&amp;usg=AFQjCNEVatynXFABMXa9cJaOpFb4sekg1g" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5717724.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5717724.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5717724" style="display:none"><span itemprop="description">To improve the voice quality of a digital mobile communication system such as a car telephone or portable telephone when outdoor background noises are superimposed on voices. To achieve the above object, a voice decoding apparatus comprises noise superimposed part detecting means for discriminating between...</span><span itemprop="url">http://www.google.com/patents/US5717724?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5717724 - Voice encoding and voice decoding apparatus</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5717724 - Voice encoding and voice decoding apparatus" title="Patent US5717724 - Voice encoding and voice decoding apparatus"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5717724 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/511,417</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Feb 10, 1998</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Aug 4, 1995</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Oct 28, 1994</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08511417, </span><span class="patent-bibdata-value">511417, </span><span class="patent-bibdata-value">US 5717724 A, </span><span class="patent-bibdata-value">US 5717724A, </span><span class="patent-bibdata-value">US-A-5717724, </span><span class="patent-bibdata-value">US5717724 A, </span><span class="patent-bibdata-value">US5717724A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Yasushi+Yamazaki%22">Yasushi Yamazaki</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Tomohiko+Taniguchi%22">Tomohiko Taniguchi</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Tomonori+Sato%22">Tomonori Sato</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Hisanari+Kimura%22">Hisanari Kimura</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Fujitsu+Limited%22">Fujitsu Limited</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5717724.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5717724.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5717724.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (2),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (11),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (14),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (6)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5717724&usg=AFQjCNHqK8lmwRVsNau3zVtBq5uwRKx6DQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5717724&usg=AFQjCNHULDNxaND5Wv2oNe81jgshgkZB9g">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5717724A%26KC%3DA%26FT%3DD&usg=AFQjCNHuQ6YKZcv8ZgcLuZguGdHYfduaqQ">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54250307" lang="EN" load-source="patent-office">Voice encoding and voice decoding apparatus</invention-title></span><br><span class="patent-number">US 5717724 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37725308" lang="EN" load-source="patent-office"> <div class="abstract">To improve the voice quality of a digital mobile communication system such as a car telephone or portable telephone when outdoor background noises are superimposed on voices. To achieve the above object, a voice decoding apparatus comprises noise superimposed part detecting means for discriminating between a noise part containing only noises and a voice part containing voices from signal encoded at a transmission side, voice decoding means for decoding an encoded signal in the voice part into a waveform signal, noise decoding means for decoding an encoded signal in the noise part into a waveform signal, and noise control means for controlling the frequency characteristic of said noise part by controlling said noise decoding means when said noise superimposed part detecting means judges the noise part.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(13)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-7.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-7.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-8.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-8.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-9.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-9.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-10.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-10.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-11.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-11.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-12.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-12.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5717724-13.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5717724-13.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(8)</span></span></div><div class="patent-text"><div mxw-id="PCLM5185725" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A voice decoding apparatus comprising:<div class="claim-text">noise superimposed part detecting means for detecting information showing the frequency characteristic of voice or noise from a signal encoded at a transmission side and discriminating an encoded signal in a noise part containing only noise from an encoded signal in a voice part containing voice in accordance with the frequency characteristic,</div> <div class="claim-text">voice decoding means for decoding an encoded signal in a voice part into a waveform signal when said noise superimposed part detecting means judges the voice part;</div> <div class="claim-text">noise decoding means for decoding an encoded signal in a noise part into a waveform signal when said noise superimposed part detecting means judges the noise part; and</div> <div class="claim-text">noise control means for controlling the frequency characteristic of said noise part by controlling said noise encoding means when said noise superimposed part detecting means judges a noise part.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The voice decoding apparatus according to claim 1, wherein said noise decoding means is provided with;<div class="claim-text">a code book for storing individual waveform patterns and index information to specify the waveform pattern,</div> <div class="claim-text">a driving sound source for exciting a waveform pattern read out of said code book, and</div> <div class="claim-text">a synthesis filter for filtering an excited signal outputted from said driving sound source in accordance with the frequency characteristic of said noise part; and wherein</div> <div class="claim-text">said noise control means controls the frequency characteristic of said noise part by controlling the filter factor of said synthesis filter.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The voice decoding apparatus according to claim 1, wherein<div class="claim-text">said frequency characteristic includes at least power information for voice or noise, and</div> <div class="claim-text">said noise superimposed part detecting means judges said encoded signal as a signal in a voice part when the power of voice or noise is equal to or more than a preset threshold and judges said encoded signal as a signal in a noise part when said power is less than said threshold.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The voice decoding apparatus according to claim 2, wherein<div class="claim-text">said frequency characteristic includes at least the gain of said code book, and</div> <div class="claim-text">said noise superimposed part detecting means judges the encoded signal as a signal in a voice part when the gain of said encoded signal is equal to or more than a preset threshold and judges the encoded signal as a signal in a noise part when the gain is less than the threshold.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The voice decoding apparatus according to claim 2, wherein<div class="claim-text">a postfilter is included which amplifies the amplitude value of a decoded signal outputted from said synthesis filter, and</div> <div class="claim-text">said postfilter passes the decoded signal inputted from the synthesis filter of said noise decoding means without amplifying the amplitude of the signal.</div> </div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6. A voice encoding apparatus for sending signal to a voice decoding apparatus, said voice encoding apparatus comprising:<div class="claim-text">voice input means for inputting voice signal;</div> <div class="claim-text">noise superimposed part detecting means for discriminating whether a signal inputted from a telephone transmitter is a signal in a voice part containing voice or a signal in a noise part containing only noise;</div> <div class="claim-text">voice encoding means for encoding a voice part when said noise superimposed part detecting means determines the voice part;</div> <div class="claim-text">noise encoding means for encoding a noise part when said noise superimposed part detecting means determines the noise part; and</div> <div class="claim-text">control information generating means for generating control information for controlling a filter factor of a synthesis filter of said voice decoding apparatus according to a frequency characteristic of said noise part and for sending the control information to said voice decoding apparatus.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The voice encoding apparatus according to claim 6, wherein<div class="claim-text">said control information is a positive value of 1 or less to be multiplied with the filter factor of said synthesis filter.</div> </div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8. A voice encoding apparatus comprising:<div class="claim-text">noise superimposed part detecting means for monitoring a voice inputted from a telephone transmitter and judging whether the voice is a voice in a voice part containing only voices or a voice in a noise part containing only noises or a voice in a noise superimposed part in which noises are superimposed on voices;</div> <div class="claim-text">inverse filtering means for computing a linear prediction factor in a noise superimposed part when said noise superimposed part detecting means judges the noise superimposed part and performing inverse filtering by using the linear prediction factor as a filter factor;</div> <div class="claim-text">noise removing means for removing noises from a prediction residue signal outputted from said inverse filtering means;</div> <div class="claim-text">pitch cycle detecting means for computing the auto-correlation operation of the residue signal outputted from said noise removing means and detecting a pitch cycle when the auto-correlation operation has the maximum value; and</div> <div class="claim-text">voice encoding means for encoding a waveform pattern in said noise superimposed part in accordance with the pitch cycle detected by said pitch cycle detecting means.</div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67074785" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p>(1) Field of the Invention</p>
    <p>The present invention relates to an art for improving the encoding quality and the noise-superimposed-voice transmission quality of digital mobile radio communication systems such as a car telephone and a portable telephone when outdoor background noises are superimposed on voices.</p>
    <p>(2) Description of the Prior Art</p>
    <p>In recent years, digital mobile radio communication systems including a car telephone and a portable telephone have been popular because of improvement of the communication art. Therefore, an audio signal processor for efficiently compressing an audio signal has been requested.</p>
    <p>Moreover, it is preferable that a digital mobile radio communication system encodes an audio signal of a 4-kHz band at a bit rate of 4 to 8 kbps in order to effectively use radio frequencies. The CELP system is known as a voice encoding system corresponding to the above system.</p>
    <p>The CELP system analyzes an audio signal in accordance with the linear prediction theory to extract a parameter showing a frequency characteristic. Moveover, the CELP system encodes a driving-sound-source signal as a waveform by means of vector quantization. Furthermore, the CELP system decodes encoded voices transmitted through a transmission line at the reception side in accordance with a procedure opposite to that at the transmission side.</p>
    <p>Furthermore, the CELP system compresses an audio signal to a low bit rate and also performs encoding (band compression) in accordance with a voice generation model in order to maintain the reproduced voice quality. In the case of the above encoding, an unnatural reproduced sound may be outputted when a background-noise-superimposed audio signal is encoded. That is, an existing encoding/decoding apparatus encodes a noise signal with a property different from a voice by assuming that the noise signal has the same property as the voice. Therefore, a signal consisting of only background noises is encoded though it does not have any frequency correlation and reproduced as an unnatural sound.</p>
    <p>Moreover, the existing encoding/decoding apparatus refers to an adaptive code book in accordance with a voice waveform when encoding a voice and detects index information for a waveform pattern similar to the adaptive code book. However, when noises are superimposed on the voice, a waveform pattern similar to the adaptive code book is not present and thus, it is inevitable to select a waveform pattern not very similar to the book. Therefore, there is a problem that the voice is outputted as an unnatural voice when it is decoded.</p>
    <p>When taking air conditioning sounds as background noises, the spectrum of the source of the air conditioning sounds shows an almost flat characteristic as shown in FIG. 13 and has a small time fluctuation. In the case of reproduced air conditioning sounds, however, it is found from FIG. 14 that the peak of spectrum envelopes fluctuates for each frame. The inventor of the present invention noticed that the fluctuation of spectrum envelopes caused audio unnaturalness and clarified the cause of the spectrum fluctuation. That is, because an existing voice decoding apparatus performs decoding by generating an excited signal in accordance with an adaptive code book and a noise code book and passing the excited signal through a synthesis filter, the inventor analyzed whether the spectrum fluctuation was caused by generation of the excited signal or by the synthesis filter. As a result, temporal fluctuation was not found in the spectrum of the excited signal. In the case of the synthesis filter, however, the fluctuation shown in FIG. 15 appeared.</p>
    <heading>BRIEF SUMMARY OF THE INVENTION</heading> <p>It is the first object of the present invention to provide an apparatus for outputting an aurally natural reproduced sound by controlling the characteristic of a synthesis filter when discriminating a signal containing only noises from a signal containing voices, differentiating the encoding from the decoding of the signal containing only noises, and decoding only noises. Moreover, it is the second object of the present invention to provide an art for encoding a signal in which noises are superimposed on voices at a high quality without being affected by noises.</p>
    <p>The outline of the present invention is described below for each object.</p>
    <p>Apparatus for achieving the first object</p>
    <p>When the voice decoding apparatus of the present invention receives a signal encoded at the transmission side, noise superimposed part detecting means judges whether the encoded signal is an encoded signal in a noise part containing only noises or an encoded signal in a voice part containing voices.</p>
    <p>In this case, when the received encoded signal is an encoded signal in the voice part, it is inputted to voice decoding means.</p>
    <p>The voice encoding means encodes the encoded signal into a waveform signal.</p>
    <p>However, when the received encoded signal is an encoded signal in the noise part, it is inputted to noise decoding means.</p>
    <p>Then, the noise decoding means detects a waveform pattern corresponding to index information from a code book and excites the waveform pattern through a driving sound source. Then, an excited signal is inputted to a synthesis filter. At the same time, noise control means multiplies the filter factor of the synthesis filter by a positive value of 1 or less and sends the multiplication result to the synthesis filter. The synthesis filter filters the excited signal in accordance with the filter factor sent from the noise control means and outputs a decoded signal. Thereby, a waveform in the noise part is reproduced without the fact that the frequency characteristic is unnaturally stressed.</p>
    <p>In this case, it is also possible to make the noise decoding means perform processing by setting the gain of the noise part to "0".</p>
    <p>Moreover, it is possible to set a postfilter at the rear stage of the synthesis filter and thereby pass a noise waveform outputted from the synthesis filter through the postfilter without stressing the peak of the noise waveform (without performing any processing).</p>
    <p>Then, a voice encoding apparatus for achieving the first object is described below.</p>
    <p>When the voice encoding apparatus receives a signal from a telephone transmitter, the noise superimposed part detecting means discriminates whether the received signal is a signal in a voice part containing voices or a signal in a noise part containing only noises.</p>
    <p>In this case, when the received signal is a signal in the voice part, the voice encoding means judges a waveform pattern similar to a waveform in the voice part and encodes the waveform pattern into index information to transmit it to the reception side.</p>
    <p>When the received signal is a signal in the noise part, the noise encoding means judges a waveform pattern similar to a waveform in the noise part and encodes the waveform pattern to output index information. At the same time, control information generating means generates control information related to the decoding in the noise part and adds the control information to the above index information. Specifically, control information generating means linear-prediction-analyzes an input signal in the noise part, judges a frequency characteristic, and multiplies an obtained filter factor by a positive value of 1 or less to determine a filter factor of a synthesis filter to be used at the reception side. Then, the means transmits the filter factor to the reception side as control information together with index information.</p>
    <p>Apparatus for achieving the second object</p>
    <p>Then, a voice encoding apparatus for achieving the second object is described below.</p>
    <p>In the case of the voice encoding apparatus, noise superimposed part judging means monitors a signal inputted from a telephone transmitter and judges whether the signal is included in the voice part containing only voices, noise part containing only noises, or noise superimposed part in which noises are superimposed on voices.</p>
    <p>When it is judged that the signal is included in the noise superimposed part, inverse filtering means computes a prediction factor of the noise superimposed part and filters the signal by using the prediction factor as a filter factor. Thereby, a signal outputted from the inverse filtering means serves as a prediction residue signal. The prediction residue signal is inputted to noise removing means in which noises are removed from the signal.</p>
    <p>The prediction residue signal from which noises are removed by the noise removing means is inputted to pitch cycle detecting means.</p>
    <p>The pitch cycle detecting means computes an auto-correlation operation of the prediction residue signal and detects a pitch cycle in which the auto-correlation operation has the maximum value.</p>
    <p>Then, the voice encoding means judges a waveform pattern similar to a waveform in the noise superimposed part in accordance with the pitch cycle detected by the pitch cycle detecting means and decodes the waveform pattern to output index information. Thereby, it is possible to encode a voice signal without being affected by noises.</p>
    <p>The present invention makes it possible to decrease a sense of incompatibility at the time of reproduction by preventing unnatural frequency characteristic from being added to noises with a small change of frequency characteristic.</p>
    <p>Moreover, the present invention makes it possible to encode a signal in which noises are superimposed on voices at a high quality by removing noise components from the signal and detecting an accurate pitch cycle.</p>
    <p>Therefore, it is possible to contribute to improvement of the quality of voices of mobile communication systems such as a portable telephone and a car telephone.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is a schematic block diagram of the voice communication apparatus in embodiment 1;</p>
    <p>FIG. 2 is a block diagram of the structure of the voice encoding apparatus of embodiment 2;</p>
    <p>FIG. 3 is a schematic block diagram of the voice decoding system of embodiment 3;</p>
    <p>FIG. 4 is a block diagram of the internal structure of a voice decoder B;</p>
    <p>FIG. 5 is a schematic block diagram of the voice encoding system of embodiment 4;</p>
    <p>FIG. 6 is a block diagram of the internal structure of a voice encoder B;</p>
    <p>FIG. 7 is a block diagram of the internal structure of the voice encoder B of embodiment 5;</p>
    <p>FIG. 8 is a block diagram of the internal structure of the voice decoder B of embodiment 5;</p>
    <p>FIG. 9 is a schematic block diagram of the voice encoding system of embodiment 6;</p>
    <p>FIG. 10 is a block diagram showing the internal structure of an adaptive code book analyzing section;</p>
    <p>FIG. 11 is a block diagram of the internal structure of an open loop analyzing section;</p>
    <p>FIG. 12 is a spectrum showing the frequency characteristic of a synthesis filter;</p>
    <p>FIG. 13 is an illustration showing the spectrum of an air conditioning sound source;</p>
    <p>FIG. 14 is an illustration showing the spectrum of reproduced air conditioning sounds; and</p>
    <p>FIG. 15 is a spectrum showing the frequency characteristic of a synthesis filter.</p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>Embodiments of the present invention are described below by referring to the accompanying drawings.</p>
    <heading>EMBODIMENT 1</heading> <p>FIG. 1 shows a rough structure of the voice communication system of embodiment 1.</p>
    <p>A voice decoding apparatus is set at the reception side of the voice communication system and a voice encoding apparatus is set at the transmission side of the system.</p>
    <p>First, the voice decoding apparatus is described below.</p>
    <p>(Voice decoding apparatus)</p>
    <p>The voice decoding apparatus comprises a noise superimposed part detecting section 1, a voice decoding section 2, a noise decoding section 3, and a noise controlling section 4.</p>
    <p>The noise superimposed part detecting section 1 monitors a signal encoded at the transmission side to discriminate whether the signal is included in the voice part containing voices or the noise part containing only noises. For example, the noise superimposed part detecting section 1 discriminates the voice part from the noise part by detecting power from the encoded signal and judging whether the power is equal to or more than a preset threshold. That is, the noise superimposed part detecting section 1 judges a section as the voice part when the power of the encoded signal is equal to or more than the threshold and as the noise part when it is less than the threshold. It is also possible to use the gain of the encoded signal instead of the power.</p>
    <p>The voice decoding section 2 decodes the encoded signal in the voice part into a waveform signal when the noise superimposed part detecting section 1 judges the encoded signal.</p>
    <p>The noise decoding section 3 decodes the encoded signal in the noise part into a waveform signal when the noise superimposed part detecting section 1 judges the encoded signal. The noise decoding section 3 comprises a code book 3a, a driving sound source 3b, and a synthesis filter 3c. The code book 3a stores a waveform pattern every piece of index information. The driving sound source 3b excites a waveform pattern read out of the code book 3a. The synthesis filter 3c filters an excited signal outputted from the driving sound source 3b.</p>
    <p>The noise controlling section 4 controls the filter factor of the synthesis filter 3c of the noise decoding section 3 to control the frequency characteristic of noises when the noise superimposed part detecting section 1 judges the encoded signal in the noise part. That is, the noise controlling section 4 determines a positive value of 1 or less to be multiplied with a filter factor and computes a new filter factor by multiplying the filter factor by the positive value.</p>
    <p>Moreover, it is possible to set the postfilter 9 for amplifying the amplitude of a decoded signal outputted from the synthesis filter 3c to the rear stage of the noise decoding section 3 and the voice decoding section 2 respectively. The postfilter 9 directly passes a decoded signal in the noise part outputted from the noise decoding section 3.</p>
    <p>Operations of a voice decoding apparatus are described below.</p>
    <p>(Operations of voice decoding apparatus)</p>
    <p>When receiving an encoded signal, the noise superimposed part detecting section 1 of the voice decoding apparatus judges whether the encoded signal is a signal in the noise part containing only noises or in the voice part containing voices.</p>
    <p>When the received encoded signal is a signal in the voice part, the noise superimposed part detecting section 1 transfers the encoded signal to the voice decoding section 2.</p>
    <p>The voice encoding section 2 encodes the encoded signal into a waveform signal to output it.</p>
    <p>However, when the received encoded signal is a signal in the noise part, the noise superimposed part detecting section 1 transfers the encoded signal to the noise decoding section 3.</p>
    <p>The noise decoding section 3 detects a waveform pattern corresponding to index information out of the code book 3a and excites the waveform pattern through the driving sound source 3b. Then, an excited signal is inputted to the synthesis filter 3c. At the same time, the noise controlling section 4 multiplies the filter factor of the synthesis filter 3c by a positive value of 1 or less and sends the multiplication result to the synthesis filter 3c. The synthesis filter 3c filters the excited signal in accordance with the filter factor sent from the noise controlling section 4 to output a decoded signal. Thereby, the waveform in the noise part is reproduced without the fact that the frequency characteristic is unnaturally stressed.</p>
    <p>(Voice encoding apparatus)</p>
    <p>A voice encoding apparatus is described below.</p>
    <p>The voice encoding apparatus comprises a noise superimposed part detecting section 5, a voice encoding section 6, a noise encoding section 7, and a control information generating section 8.</p>
    <p>The noise superimposed part detecting section 5 has a operation for monitoring a signal encoded at the transmission side and discriminating a signal in the voice part containing voices from a signal in the noise part containing only noises.</p>
    <p>When the noise superimposed part detecting section 5 judges a voice part, the voice encoding section 6 encodes a waveform of the section and outputs index information. The index information is information for specifying a waveform. The voice encoding section 6 has a code book for storing a waveform pattern every piece of index information and performs encoding by using the code book.</p>
    <p>When the noise superimposed part detecting section 5 judges a noise part, the noise encoding section 7 encodes a waveform of the section and outputs index information. The noise encoding section 7, same as the voice encoding section 6, has a code book for storing a waveform pattern every piece of index information and encodes a noise waveform by using the code book.</p>
    <p>When the noise superimposed part detecting section 5 judges a noise part, the control information generating section 8 generates control information for decoding of the noise part and adds the control information to an encoded signal in the noise part. In this case, the control information is information for specifying the filter factor of a synthesis filter used at the reception side and determined in accordance with the waveform characteristic of noises.</p>
    <p>Operations of the voice encoding apparatus are described below.</p>
    <p>(Operations of voice encoding apparatus)</p>
    <p>When receiving a signal from a telephone transmitter, the noise superimposed part detecting section 5 of the voice encoding apparatus discriminates whether the received signal is a signal in the voice part or a signal in the noise part.</p>
    <p>When the signal received from the telephone transmitter is a signal in the voice part, the noise superimposed part detecting section 5 transfers the received signal to the voice encoding section 6.</p>
    <p>The voice encoding section 6 judges a waveform pattern similar to a waveform in the voice part and encodes the waveform pattern to output index information. The index information outputted from the voice encoding section 6 is transmitted to the reception side.</p>
    <p>On the other hand, when the signal received from the telephone transmitter is a signal in the noise part, the noise superimposed part detecting section 5 transfers the received signal to the noise encoding section 7.</p>
    <p>Noise encoding section 7 judges a waveform pattern similar to a waveform in the noise part and encodes the waveform pattern to output index information. In this case, the control information generating section 8 judges a frequency characteristic by linear-prediction-analyzing an input signal in the noise part and computes a filter factor corresponding to the frequency characteristic. Then, the control information generating section 8 multiplies the filter factor by a positive value of 1 or less to determine a new filter factor. Moreover, the control information generating section 8 adds control information to the index information outputted from the noise encoding section 7 to transmit the added information to the reception side.</p>
    <p>Thus, the voice decoding apparatus and the voice encoding apparatus of the embodiments of the present invention make it possible to output an aurally-natural reproduced sound by controlling the characteristic of a synthesis filter when differentiating the encoding from the decoding of the signal containing only noises and decoding only noises.</p>
    <heading>EMBODIMENT 2</heading> <p>Then, the second embodiment of the present invention is described below by referring to the accompanying drawings.</p>
    <p>FIG. 2 is a block diagram showing the structure of the voice encoding apparatus of this embodiment.</p>
    <p>The voice encoding apparatus comprises a noise superimposed part detecting section 10, an inverse filtering section 11, a noise removing section 12, a pitch cycle detecting section 13, and a voice encoding section 14.</p>
    <p>The noise superimposed part detecting section 10 monitors a signal inputted from a telephone transmitter and discriminates between a voice part containing only voices, a noise part containing only noises, and a noise superimposed part in which noises are superimposed on voices.</p>
    <p>When the noise superimposed part detecting section 10 judges a noise superimposed part, the inverse filtering section 11 linear-prediction-analyzes the noise superimposed part to compute a linear prediction factor. Then, the inverse filtering section 11 inversely filters an input signal by using the linear prediction factor as a filter factor and outputs a prediction residue signal.</p>
    <p>The noise removing section 12 removes noises from the prediction residue signal. The noise removing section 12 uses, for example, a low-pass filter.</p>
    <p>The pitch cycle detecting section 13 computes an auto-correlation operation of a residue signal outputted from the noise removing section 12. Then, the pitch cycle detecting section 13 detects a pitch cycle when the auto-correlation operation has the maximum value. That is, the pitch cycle detecting section 13 shifts the prediction residue signal every specific cycle and detects a specific pitch cycle in which the correlation between each prediction residue signal and the original prediction residue signal is maximized as the pitch cycle.</p>
    <p>The voice encoding section 14 encodes a waveform in the noise superimposed part in accordance with pitch cycle detected by the pitch cycle detecting section 13.</p>
    <p>Operations of this embodiment are described below.</p>
    <p>(Operations of voice encoding apparatus)</p>
    <p>The noise superimposed part detecting section 10 of the voice encoding apparatus monitors a signal inputted from a telephone transmitter and judges whether the input signal is a signal in the voice part containing only voices, a signal in the noise part containing only noises, or a signal in the noise superimposed part in which noises are superimposed on voices.</p>
    <p>In this case, when the input signal is a signal in the noise superimposed part, the noise superimposed part detecting section 10 transfers the input signal to the inverse filtering section 11.</p>
    <p>The inverse filtering section 11 computes a prediction factor of the noise superimposed part. Then, the inverse filtering section 11 filters the input signal by using the prediction factor as a filter factor and outputs a prediction residue signal. The prediction residue signal outputted from the inverse filtering section 11 is inputted to the noise removing section 12.</p>
    <p>The noise removing section 12 removes noises from the prediction residue signal and inputs it to the pitch cycle detecting section 13.</p>
    <p>The pitch cycle detecting section 13 computes the auto-correlation operation of the prediction residue signal. Then, the pitch cycle detecting section 13 detects a pitch cycle when the auto-correlation operation of the prediction residue signal has the maximum value and sends it to the voice encoding section 14.</p>
    <p>The voice encoding section 14 judges a waveform pattern similar to a waveform in the noise superimposed part in accordance with the pitch cycle sent from the pitch cycle detecting section 13. Then, the voice encoding section 14 encodes the judged waveform pattern to output index information. The index information outputted from the voice encoding section 14 is transmitted to the reception side.</p>
    <p>Thereby, it Is possible to encode a signal in which noises are superimposed on voices at a high quality without being affected by noises.</p>
    <heading>EMBODIMENT 3</heading> <p>The third embodiment of the present invention is described below by referring to the accompanying drawings.</p>
    <p>FIG. 3 is a block diagram showing the structure of the voice decoding apparatus of this embodiment.</p>
    <p>The voice encoding apparatus of this embodiment comprises a noise superimposition detection judging unit 1 serving as noise superimposed part detecting means, a voice decoder A (2) serving as voice encoding means, a voice decoder B (3) serving as noise decoding means, and a reception code dividing section 15.</p>
    <p>The voice decoders A (2) and B (3) use the CELP system as a decoding system.</p>
    <p>The reception code dividing section 15 has a operation for dividing an encoded signal received from the transmission side into power information, index information, and a synthesis filter factor.</p>
    <p>The noise superimposition detection judging unit 1 has a operation for comparing the power information divided by the reception code dividing section 15 with a preset threshold and judging that the encoded signal is a signal in the voice part when the power information is equal to or larger than the threshold and that the encoded signal is a signal in the noise part when the power information is less than the threshold. Moreover, the noise superimposition detection judging unit 1 has a operation for inputting the encoded signal in the voice part to the voice decoder A (2) and the encoded signal in the noise part to the voice decoder B (3).</p>
    <p>The voice decoder A (2) decodes an encoded signal in the voice part. Specifically, it has the same structure and operation as an existing CELP-system decoder. Therefore, the description of the decoder A (2) is omitted.</p>
    <p>The voice decoder B (3) decodes an encoded signal in the noise part.</p>
    <p>FIG. 4 shows the internal structure and peripheral structure of the voice decoder B (3).</p>
    <p>In FIG. 4, the voice decoder B (3) comprises an adaptive code book 30a, a noise code book 31a, a driving sound source 3b, and a synthesis filter 3c. Moreover, the synthesis filter 3c connects with an LPC factor correcting section 4 serving as noise control means of the present invention.</p>
    <p>The adaptive code book 30a stores waveform patterns of waveform signals having a periodicity and index information and has a operation for updating waveform patterns in accordance with a decoded waveform signal.</p>
    <p>The noise code book 31a stores waveform patterns of waveform signal having no periodicity and index information.</p>
    <p>An amplification factor (gain) of waveform patterns read out of the adaptive code book 30a and the noise code book 31a are specified for the adaptive code book 30a and the noise code book 31a. The driving sound source 3b has a operation for exciting waveform patterns read out of the adaptive code book 30a and the noise code book 31a in accordance with their own gain.</p>
    <p>The synthesis filter 3c filters an excited signal outputted from the driving sound source 3b and decodes it into a waveform signal. The filter factor of the synthesis filter 3c is determined at the transmission side. That is, the transmission side linear-prediction-analyzes the original waveform signal to compute a linear prediction factor and transmits the linear prediction factor to the reception side as a filter factor. Thereby, the voice decoder B (3) detects a filter factor from an encoded signal to use it as the filter factor of the synthesis filter 3c.</p>
    <p>The LPC factor correcting section 4 has a operation for receiving a judgment result of the noise superimposition detection judging unit 1 and correcting the filter factor of the synthesis filter 3c. Specifically, it has a operation for correcting the filter factor of the synthesis filter 3c by multiplying the filter factor by a positive value of 1 or less as shown by the expression below.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">'<sub>i</sub> =g<sup>i</sup> <sub>i</sub> (0.0&lt;g1.0)</pre>
    
    <p>Thereby, it is possible to convert the frequency characteristic of the synthesis filter 3c into an almost flat characteristic (see FIG. 12).</p>
    <p>Operations of the voice decoding apparatus are described below.</p>
    <p>(Operations of voice decoding apparatus)</p>
    <p>In the case of the voice decoding apparatus, the reception code dividing section 15 receives a signal encoded at the reception side.</p>
    <p>The reception code dividing section 15 divides the encoded signal into power information, index information, and a filter factor and inputs the power information to the noise superimposition detection judging unit 1.</p>
    <p>The noise superimposition detection judging unit 1 judges whether the power information is equal to or larger than or less than a threshold. When the power information is equal to or larger than the threshold, the noise superimposition detection judging unit 1 judges that the encoded signal is a signal in the voice part and inputs the power information, index information, and filter factor divided by the reception code dividing section 15 to the voice decoder A (2). The voice decoder A (2) decodes the encoded signal into a voice waveform in accordance with these pieces of information.</p>
    <p>However, when the power information is less than the threshold, the noise superimposition detection judging unit 1 judges the encoded signal is a signal in the noise part and inputs the power information and index information divided by the reception code dividing section 15 to the voice decoder B (3) and also sends the filter factor to the LPC factor correcting section 4.</p>
    <p>The voice decoder B (3) retrieves the adaptive code book 30a or the noise code book 31a in accordance with the index information to detect a necessary waveform pattern. The driving sound source 3b excites the waveform pattern in accordance with the gain in each code book and inputs an excited signal to the synthesis filter 3c.</p>
    <p>In this case, the LPC factor correcting section 4 corrects the filter factor by multiplying the filter factor by a positive value of 1 or less and then, sends the corrected filter factor to the synthesis filter 3c.</p>
    <p>The synthesis filter 3c filters the excited signal outputted from the driving sound source 3b in accordance with the filter factor sent by the LPC factor correcting section 4 and decodes it into a noise waveform. As described above, this embodiment makes it possible to convert the spectrum of the synthesis filter 3c into an almost flat characteristic, prevent the characteristic of the noise waveform from being unnaturally stressed, and control the reproduction of aurally rasping noises by controlling the filter factor when encoding a signal in the noise part. Therefore, It is possible to improve the voice quality of portable mobile communication systems such as a portable telephone and a car telephone.</p>
    <heading>EMBODIMENT 4</heading> <p>In the case of embodiment 4, an embodiment of the voice encoding apparatus of the present invention is described.</p>
    <p>FIG. 5 is a schematic block diagram of the voice encoding apparatus.</p>
    <p>In FIG. 5, the voice encoding apparatus comprises a voice encoder A (6), a voice encoder B (7), and a noise superimposition detection judging unit 5.</p>
    <p>The noise superimposition detection judging unit 5 has a operation for detecting the power of a waveform signal inputted from a telephone transmitter and judging that the signal is a signal in the voice part containing voices when the power is equal to or larger than a threshold and the signal is a waveform signal in the noise part containing noise only when the power is less than the threshold. Moreover, the noise superimposition detection judging unit 5 has a operation for inputting a waveform signal in the voice part to the voice encoder A (6) and a waveform signal in the noise part to the voice encoder B (7).</p>
    <p>The voice encoder A (6) is an existing CELP-system encoder having a operation for encoding a waveform signal in the voice part.</p>
    <p>The voice encoder B (7) has a operation for encoding a waveform signal in the noise part.</p>
    <p>FIG. 6 shows the internal structure and the peripheral structure of the voice encoder B (7).</p>
    <p>In FIG. 6, the voice encoder B (7) comprises an adaptive code book 70a, a noise code book 71a, a driving sound source 7b, a synthesis filter 7c, an LPC analyzing section 7e, and an error minimizing section 7d.</p>
    <p>The adaptive code book 70a stores patterns of waveforms having a periodicity and index information for specifying individual waveform pattern.</p>
    <p>The noise code book 71a stores patterns of waveforms having no periodicity and index information for specifying individual waveform pattern.</p>
    <p>The driving sound source 7b has a operation for exciting a waveform pattern detected from the adaptive code book 70a and a waveform pattern detected from the noise code book 71a in accordance with the gain each code book.</p>
    <p>The synthesis filter 7c has a operation for filtering a waveform signal in the noise part by using the linear prediction factor of the waveform signal as a filter factor.</p>
    <p>The error minimizing section 7d has a operation for comparing a waveform signal outputted from the synthesis filter 7c with the waveform of an input noise signal, optimizing index information and the amplification factor (gain) of a waveform pattern, and updating the contents of the noise code book 71a.</p>
    <p>The LPC analyzing section 7e has a operation for linear-prediction-analyzing an input waveform to compute a linear prediction factor and inputting the input waveform to the synthesis filter 7c by using the linear prediction factor as a filter factor.</p>
    <p>Moreover, the voice decoder B (7) connects with a code transmitting section 16 and an LPC factor correcting section 4.</p>
    <p>The code transmitting section 16 has a operation for transmitting power information, index information, and a filter factor encoded by the voice decoder B (7) to the transmission side.</p>
    <p>The LPC factor correcting section 4 has the same operation as the above embodiment 3 for correcting the filter factor of the synthesis filter 7c used to decode an encoded signal in the noise part. Specifically, the control information generating section 8 corrects the filter factor by multiplying the filter factor by a positive value of 1 or less. It is assumed that the code transmitting section 16 transmits the filter factor corrected by the LPC factor correcting section 4 together with other encoded signal correspondingly to the above operation.</p>
    <p>Operations of the voice encoding apparatus of this embodiment are described below.</p>
    <p>(Operations of voice encoding apparatus)</p>
    <p>When a waveform signal is inputted from a telephone transmitter, the noise superimposition detection judging unit 5 detects the power of the waveform signal and judges whether the signal is equal to or larger than or less than a threshold. When the power of the waveform signal is equal to or larger than the threshold, the noise superimposition detection judging unit 5 judges the waveform signal as a signal in the voice part and inputs the waveform signal to the voice encoder A (6).</p>
    <p>The voice encoder A (6) encodes waveform information into index information, power information, and a filter factor by using a code book and transmits them to the reception side.</p>
    <p>When the power of the input waveform is less than the threshold, the noise superimposition detection judging unit 5 judges that the waveform signal is a waveform signal in the noise part and inputs the waveform to the voice encoder B (7).</p>
    <p>The voice encoder B (7) has a operation for retrieving the adaptive code book 70a and the noise code book 71a in accordance with a waveform in the noise part and detecting similar waveform patterns. Moreover, the voice encoder B (7) inputs a waveform pattern read out of the adaptive code book 70a or the noise code book 71a to the driving sound source 7b.</p>
    <p>The driving sound source 7b excites the waveform pattern to input it to the synthesis filter 7c.</p>
    <p>In this case, the LPC analyzing section 7e linear-prediction-analyzes an inputted waveform signal to compute a linear prediction factor. Then, the LPC analyzing section 7e sends the linear prediction factor to the synthesis filter 7c.</p>
    <p>The synthesis filter 7c filters the excited signal inputted from the driving sound source 7b by using the linear prediction factor as a filter factor.</p>
    <p>The error minimizing section 7d compares a decoded signal outputted from the synthesis filter 7c with an inputted waveform signal and sends the index information optimum to minimize the error between the both signals and the gain of a waveform pattern to the adaptive code book 70a and the noise code book 71a. Then, each code book updates entered contents and gain in accordance with the index information and gain sent from the error minimizing section 7d and sends updated index information to the code transmitting section 16. Moreover, the LPC factor correcting section 4 corrects the linear prediction factor (filter factor) computed by the LPC analyzing section 7e by multiplying the factor by a positive value of 1 or less. Then, the LPC factor correcting section 4 sends the corrected filter factor to the code transmitting section 16.</p>
    <p>The code transmitting section 16 sends the index information and power information sent from the voice encoder B (7) and the filter factor sent from the LPC factor correcting section 4 to the reception side.</p>
    <p>Thereby, it is possible, at the reception side, to convert the spectrum of the synthesis filter into a flat characteristic and prevent a waveform in the noise part from being unnaturally decoded by performing decoding with the corrected filter factor.</p>
    <p>As described above, this embodiment makes it possible to convert the spectrum of a synthesis filter into a flat characteristic, prevent the frequency characteristic of a noise part from becoming unnatural, and control aurally rasping noises when decoding the noise part.</p>
    <heading>EMBODIMENT 5</heading> <p>The fifth embodiment of the present invention is described below by referring to the accompanying drawings.</p>
    <p>FIG. 7 shows the internal structure of the voice encoder B of this embodiment.</p>
    <p>In FIG. 7, the voice encoder B (7) comprises an adaptive code book 70a, a noise code book 71a, a driving sound source 7b, a synthesis filter 7c, an LPC analyzing section 7e, and an error minimizing section 7d, compared to the voice encoder B (7) of the above embodiment 4. Moreover, the voice encoder B (7) connects with a code transmitting section 16.</p>
    <p>The code transmitting section 16 has a operation for transmitting "0" as index information of the adaptive code book 70a when transmitting an encoded signal in a noise part containing only noises. Other structures and operations of this embodiment are the same as those of the above embodiment 4. Therefore, the description of them is omitted.</p>
    <p>FIG. 8 is a block diagram showing the structure of the voice decoder B (3) corresponding to the voice encoder B (7) in FIG. 7.</p>
    <p>The voice decoder B (3) comprises an adaptive code book 30n, a noise code book 31a, a driving sound source 3b, a synthesis filter 3c, and an adaptive postfilter 17, compared to the structure of the above embodiment 3.</p>
    <p>The adaptive postfilter 17 has a operation for amplifying the amplitude of a waveform without changing the cycle of it.</p>
    <p>Moreover, when the adaptive code book 30a receives the index information "0" of the adaptive code book 30a from the transmission side, it decreases the gain of the adaptive code book 30a to "0". Thereby, the adaptive code book 30a has a operation for retrieving the noise code book 31a in accordance with the index information of the noise code book 31a and reading a necessary waveform pattern from the book 31a when a waveform signal in the noise part is inputted. Moreover, when a waveform signal in the noise part is inputted, the adaptive postfilter 17 passes the waveform signal without applying any processing to the signal.</p>
    <p>This embodiment 5 makes it possible to decode a noise signal with a flat characteristic but no periodicity into an aurally natural waveform signal without adding an unnatural periodicity to the noise signal by encoding and decoding a noise waveform with no periodicity in accordance with a noise code book.</p>
    <heading>EMBODIMENT 6</heading> <p>FIG. 9 shows the structure of the voice encoder B of this embodiment. The voice encoder B (7) comprises an adaptive code book analyzing section 18, a noise code book analyzing section 19, a driving sound source generating section 20, and an open-loop pitch analyzing section 21.</p>
    <p>The adaptive code book analyzing section 18 has a operation for filtering a waveform signal detected out of the noise code book 71a by a long-term prediction synthesis filter 72 and performing closed-loop processing for computing a pitch cycle of the waveform signal (see FIG. 10).</p>
    <p>The open-loop pitch analyzing section 21 is started to encode a noise superimposed part in which a noise waveform is superimposed on a voice waveform and comprises a short-term prediction inverted filter 11, a low-pass filter LPF 12, an auto-correlation detecting section 13b, a maximum correlation value detecting section 13c, and a delaying section 13a (see FIG. 11).</p>
    <p>The short-term prediction inverted filter 11 has a operation for performs inverse filtering by using the linear prediction factor of a waveform signal as a filter factor and outputting a prediction residue signal.</p>
    <p>The low-pass filter LPF 12 has a operation for removing noise waveforms from the prediction residue signal.</p>
    <p>The delaying section 13a has a operation for shifting the cycle of the prediction residue signal every certain cycle.</p>
    <p>The auto-correlation detecting section 13b has a operation for detecting a correlation value between the original prediction residue signal and the prediction residue signal whose cycle is shifted by a certain value by the delaying section 13a.</p>
    <p>The maximum correlation value detecting section 13c has a operation for detecting a delay (cycle) when a cycle is shifted every certain value by the delaying section 13a and a correlation value is maximized. The delay is sent to the driving sound source 7b as a pitch cycle. Then, the driving sound source 7b excites a waveform pattern read out of the adaptive code book 70a in accordance with the pitch cycle.</p>
    <p>As described above, this embodiment 6 makes it possible to accurately detect a pitch cycle of a voice waveform on which noises are superimposed, perform high-quality encoding without being affected by noises, and improve the quality of reproduced voices.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5327461">US5327461</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 2, 1992</td><td class="patent-data-table-td patent-date-value">Jul 5, 1994</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Voice communication apparatus using a voice operated transmitter</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5448679">US5448679</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 30, 1992</td><td class="patent-data-table-td patent-date-value">Sep 5, 1995</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and system for speech data compression and regeneration</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5875423">US5875423</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 17, 1997</td><td class="patent-data-table-td patent-date-value">Feb 23, 1999</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Method for selecting noise codebook vectors in a variable rate speech coder and decoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6141639">US6141639</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 5, 1998</td><td class="patent-data-table-td patent-date-value">Oct 31, 2000</td><td class="patent-data-table-td ">Conexant Systems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for coding of signals containing speech and background noise</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6272459">US6272459</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 11, 1997</td><td class="patent-data-table-td patent-date-value">Aug 7, 2001</td><td class="patent-data-table-td ">Olympus Optical Co., Ltd.</td><td class="patent-data-table-td ">Voice signal coding apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7701038">US7701038</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2006</td><td class="patent-data-table-td patent-date-value">Apr 20, 2010</td><td class="patent-data-table-td ">Taiwan Semiconductor Manufacturing Company, Ltd.</td><td class="patent-data-table-td ">High-gain vertex lateral bipolar junction transistor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8115280">US8115280</a></td><td class="patent-data-table-td patent-date-value">Mar 1, 2010</td><td class="patent-data-table-td patent-date-value">Feb 14, 2012</td><td class="patent-data-table-td ">Taiwan Semiconductor Manufacturing Company, Ltd.</td><td class="patent-data-table-td ">Four-terminal gate-controlled LVBJTs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8315863">US8315863</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 15, 2006</td><td class="patent-data-table-td patent-date-value">Nov 20, 2012</td><td class="patent-data-table-td ">Panasonic Corporation</td><td class="patent-data-table-td ">Post filter, decoder, and post filtering method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8324713">US8324713</a></td><td class="patent-data-table-td patent-date-value">Mar 1, 2010</td><td class="patent-data-table-td patent-date-value">Dec 4, 2012</td><td class="patent-data-table-td ">Taiwan Semiconductor Manufacturing Company, Ltd.</td><td class="patent-data-table-td ">Profile design for lateral-vertical bipolar junction transistor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8665914">US8665914</a></td><td class="patent-data-table-td patent-date-value">Mar 10, 2009</td><td class="patent-data-table-td patent-date-value">Mar 4, 2014</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Signal analysis/control system and method, signal control apparatus and method, and program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090216527">US20090216527</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 15, 2006</td><td class="patent-data-table-td patent-date-value">Aug 27, 2009</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Post filter, decoder, and post filtering method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1999063521A1?cl=en">WO1999063521A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 3, 1999</td><td class="patent-data-table-td patent-date-value">Dec 9, 1999</td><td class="patent-data-table-td ">Conexant Systems Inc</td><td class="patent-data-table-td ">Signal decomposition method for speech coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2001088904A1?cl=en">WO2001088904A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 17, 2000</td><td class="patent-data-table-td patent-date-value">Nov 22, 2001</td><td class="patent-data-table-td ">Koninkl Philips Electronics Nv</td><td class="patent-data-table-td ">Audio coding</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375S346000">375/346</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc704/defs704.htm&usg=AFQjCNFXKBc0Q4Cbl6DXC_PCjlN_Rft8Xg#C704SE19035">704/E19.035</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc704/defs704.htm&usg=AFQjCNFXKBc0Q4Cbl6DXC_PCjlN_Rft8Xg#C704S208000">704/208</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04B0014040000">H04B14/04</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0021020000">G10L21/02</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0019000000">G10L19/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0011060000">G10L11/06</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04B0015000000">H04B15/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04B0007260000">H04B7/26</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G10L0019120000">G10L19/12</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L21/0208">G10L21/0208</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L19/12">G10L19/12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=DhZFBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G10L25/93">G10L25/93</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G10L19/12</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jul 8, 2009</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 9, 2008</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 2, 5, 6, 7 AND 8 ARE CANCELLED. CLAIMS 1 AND 4 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIM 3, DEPENDENT ON AN AMENDED CLAIM, IS DETERMINED TO BE PATENTABLE. NEW CLAIMS 9-12 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 13, 2005</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 12, 2005</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20050217</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 19, 2001</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 4, 1995</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">FUJITSU LIMITED, JAPAN</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:YAMAZAKI, YASUSHI;TANIGUCHI, TOMOHIKO;SATO, TOMONORI;ANDOTHERS;REEL/FRAME:007602/0627</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19950727</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0SbppG2iwklmS3_G4omrVP1WtxRA\u0026id=DhZFBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U2FqNnhm_8HFdwAFKu-1xX3uvAPvA\u0026id=DhZFBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U20oILafUXLEWKhH-59063D6n5Vzw","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Voice_encoding_and_voice_decoding_appara.pdf?id=DhZFBAABERAJ\u0026output=pdf\u0026sig=ACfU3U0BAQc-kfX2thQv0g4p1kBqzlk0xA"},"sample_url":"http://www.google.com/patents/reader?id=DhZFBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>