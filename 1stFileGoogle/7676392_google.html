<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7676392 - Electronic toll management - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Electronic toll management"><meta name="DC.contributor" content="Jay E. Hedley" scheme="inventor"><meta name="DC.contributor" content="Neal Patrick Thornburg" scheme="inventor"><meta name="DC.contributor" content="Accenture Global Services Gmbh" scheme="assignee"><meta name="DC.date" content="2006-6-12" scheme="dateSubmitted"><meta name="DC.description" content="Identifying a vehicle in a toll system includes accessing a set of toll transaction entries. Each entry in the set designates a toll transaction between a vehicle and the toll system and includes a transaction descriptor and a transaction time stamp. A series of toll transaction pictures is accessed. The series includes a plurality of pictures, each of which is associated with a picture time stamp. A toll transaction entry is identified from the set as a violation transaction entry based on the transaction descriptor. A toll transaction picture is selected from the series. The transaction time stamp of the violation transaction is compared, using a processing device, with the picture time stamp of the selected toll transaction picture. The selected toll transaction picture is identified as a violation picture corresponding to the violation transaction entry based on a result of the comparison."><meta name="DC.date" content="2010-3-9" scheme="issued"><meta name="DC.relation" content="CA:2163872:A1" scheme="references"><meta name="DC.relation" content="CA:2422187:A1" scheme="references"><meta name="DC.relation" content="DE:10104502:A1" scheme="references"><meta name="DC.relation" content="GB:2344205" scheme="references"><meta name="DC.relation" content="JP:2004213569" scheme="references"><meta name="DC.relation" content="US:20020097178:A1" scheme="references"><meta name="DC.relation" content="US:20020140579:A1" scheme="references"><meta name="DC.relation" content="US:20020198767:A1" scheme="references"><meta name="DC.relation" content="US:20040008368:A1" scheme="references"><meta name="DC.relation" content="US:20040008514:A1" scheme="references"><meta name="DC.relation" content="US:20040167861:A1" scheme="references"><meta name="DC.relation" content="US:20050197976:A1" scheme="references"><meta name="DC.relation" content="US:20070252678:A1" scheme="references"><meta name="DC.relation" content="US:4242661" scheme="references"><meta name="DC.relation" content="US:4963723" scheme="references"><meta name="DC.relation" content="US:5638302" scheme="references"><meta name="DC.relation" content="US:5740230" scheme="references"><meta name="DC.relation" content="US:5745052" scheme="references"><meta name="DC.relation" content="US:5819234" scheme="references"><meta name="DC.relation" content="US:5920338" scheme="references"><meta name="DC.relation" content="US:6042008" scheme="references"><meta name="DC.relation" content="US:6052068" scheme="references"><meta name="DC.relation" content="US:6081206" scheme="references"><meta name="DC.relation" content="US:6121898" scheme="references"><meta name="DC.relation" content="US:6167333" scheme="references"><meta name="DC.relation" content="US:6747687" scheme="references"><meta name="DC.relation" content="US:6922156" scheme="references"><meta name="DC.relation" content="US:6966489" scheme="references"><meta name="DC.relation" content="US:7119674" scheme="references"><meta name="DC.relation" content="US:7407097" scheme="references"><meta name="DC.relation" content="WO:1998014925:A1" scheme="references"><meta name="DC.relation" content="WO:1999066455:A2" scheme="references"><meta name="DC.relation" content="WO:2000046068:A1" scheme="references"><meta name="DC.relation" content="WO:2002063570:A2" scheme="references"><meta name="DC.relation" content="WO:2003003314:A1" scheme="references"><meta name="DC.relation" content="WO:2004042673:A2" scheme="references"><meta name="DC.relation" content="WO:2004075121:A1" scheme="references"><meta name="DC.relation" content="WO:2007030446:A2" scheme="references"><meta name="citation_reference" content="&quot;Automated highways going the right way?&quot;, McLeod Jonah, Electronics, Nov. 28, 1994, 67, 22."><meta name="citation_reference" content="Canadian Office Action of Application No. 2,516,675, dated Jun. 19, 2008, 4 pages."><meta name="citation_reference" content="Canadian Office Action of Application No. 2,516,675, dated Mar. 31, 2009, 6 pages."><meta name="citation_reference" content="China Office Action of Application No. 200680027002.3 dated Jun. 26, 2009, 10 pages."><meta name="citation_reference" content="Examiner&#39;s first report on Australian patent application No. 2004213923."><meta name="citation_reference" content="First Examination Report for Indian Ref No. 2348/CHENP/2005-CNA."><meta name="citation_reference" content="International Preliminary Examination Report and Written Opinion for International Application No. PCT/EP2004/001644."><meta name="citation_reference" content="International Search and Written Opinion, PCT/IB2006/002738, dated Mar. 12, 2007."><meta name="citation_reference" content="International Search Report and Written Opinion for International Application No. PCTIB2006/002435."><meta name="citation_reference" content="International Search Report for International application No. PCT/EP2004/001644."><meta name="citation_reference" content="Notification of the first Office Action in Chinese Application No. 200480010404.3, dated Aug. 1, 2008, 27 pages."><meta name="citation_reference" content="Search Report and Written Opinion of Application No. SG200718336-1 dated Sep. 4, 2009, 8 pages."><meta name="citation_reference" content="Search Report and Written Opinion of Application No. SG200718365-0 dated Jul. 23, 2009, 9 pages."><meta name="citation_reference" content="Smith, L Intelligent Transportation Systems-Electronic Toll Collection [online], 3rd Jan. 2002 [retrieved on Jul. 11, 2006]. Retrieved from the Internet:&lt;URL:http://www.calccit.org/itsdecision/serv-and-tech/Electronic-toll-collection/electronic-toll-collection-rep-print.html &gt;."><meta name="citation_reference" content="Smith, L Intelligent Transportation Systems—Electronic Toll Collection [online], 3rd Jan. 2002 [retrieved on Jul. 11, 2006]. Retrieved from the Internet:&lt;URL:http://www.calccit.org/itsdecision/serv—and—tech/Electronic—toll—collection/electronic—toll—collection—rep—print.html &gt;."><meta name="citation_patent_number" content="US:7676392"><meta name="citation_patent_application_number" content="US:11/423,690"><link rel="canonical" href="http://www.google.com/patents/US7676392"/><meta property="og:url" content="http://www.google.com/patents/US7676392"/><meta name="title" content="Patent US7676392 - Electronic toll management"/><meta name="description" content="Identifying a vehicle in a toll system includes accessing a set of toll transaction entries. Each entry in the set designates a toll transaction between a vehicle and the toll system and includes a transaction descriptor and a transaction time stamp. A series of toll transaction pictures is accessed. The series includes a plurality of pictures, each of which is associated with a picture time stamp. A toll transaction entry is identified from the set as a violation transaction entry based on the transaction descriptor. A toll transaction picture is selected from the series. The transaction time stamp of the violation transaction is compared, using a processing device, with the picture time stamp of the selected toll transaction picture. The selected toll transaction picture is identified as a violation picture corresponding to the violation transaction entry based on a result of the comparison."/><meta property="og:title" content="Patent US7676392 - Electronic toll management"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("LYftU9SnEZHIsATWsILgCw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("GBR"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("LYftU9SnEZHIsATWsILgCw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("GBR"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7676392?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7676392"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=YcZTBgABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7676392&amp;usg=AFQjCNHLepszitdl5Kbv1mA2_q_JdHr_sw" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7676392.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7676392.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20070008179"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US7676392"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7676392" style="display:none"><span itemprop="description">Identifying a vehicle in a toll system includes accessing a set of toll transaction entries. Each entry in the set designates a toll transaction between a vehicle and the toll system and includes a transaction descriptor and a transaction time stamp. A series of toll transaction pictures is accessed....</span><span itemprop="url">http://www.google.com/patents/US7676392?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7676392 - Electronic toll management</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7676392 - Electronic toll management" title="Patent US7676392 - Electronic toll management"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7676392 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 11/423,690</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Mar 9, 2010</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jun 12, 2006</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jun 10, 2005</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2611379A1">CA2611379A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2611637A1">CA2611637A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN100593797C">CN100593797C</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101228557A">CN101228557A</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101228558A">CN101228558A</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101228558B">CN101228558B</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101763662A">CN101763662A</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101763662B">CN101763662B</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101872496A">CN101872496A</a>, </span><span class="patent-bibdata-value"><a href="/patents/CN101872496B">CN101872496B</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1897064A1">EP1897064A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1897064B1">EP1897064B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1897065A2">EP1897065A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP1897065B1">EP1897065B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2472476A1">EP2472476A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2472476B1">EP2472476B1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2518695A1">EP2518695A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP2642453A1">EP2642453A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8548845">US8548845</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8775235">US8775235</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20070008179">US20070008179</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20100228607">US20100228607</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20100228608">US20100228608</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20140074567">US20140074567</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2006134498A2">WO2006134498A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2006134498A3">WO2006134498A3</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO2007007194A1">WO2007007194A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">11423690, </span><span class="patent-bibdata-value">423690, </span><span class="patent-bibdata-value">US 7676392 B2, </span><span class="patent-bibdata-value">US 7676392B2, </span><span class="patent-bibdata-value">US-B2-7676392, </span><span class="patent-bibdata-value">US7676392 B2, </span><span class="patent-bibdata-value">US7676392B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Jay+E.+Hedley%22">Jay E. Hedley</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Neal+Patrick+Thornburg%22">Neal Patrick Thornburg</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Accenture+Global+Services+Gmbh%22">Accenture Global Services Gmbh</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7676392.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7676392.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7676392.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (38),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (15),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (7),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (8),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (6)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=YcZTBgABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7676392&usg=AFQjCNGz2tjexnrlu_8WXj6KQ_sgJiTv7Q">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=YcZTBgABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7676392&usg=AFQjCNFcVcSlkhIiPR5LjURHNnvIXHY4bQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=YcZTBgABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7676392B2%26KC%3DB2%26FT%3DD&usg=AFQjCNFZGcXq6xvPLz5zrt4NfDDsBxcjpw">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT92907720" lang="EN" load-source="patent-office">Electronic toll management</invention-title></span><br><span class="patent-number">US 7676392 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA74021122" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">Identifying a vehicle in a toll system includes accessing a set of toll transaction entries. Each entry in the set designates a toll transaction between a vehicle and the toll system and includes a transaction descriptor and a transaction time stamp. A series of toll transaction pictures is accessed. The series includes a plurality of pictures, each of which is associated with a picture time stamp. A toll transaction entry is identified from the set as a violation transaction entry based on the transaction descriptor. A toll transaction picture is selected from the series. The transaction time stamp of the violation transaction is compared, using a processing device, with the picture time stamp of the selected toll transaction picture. The selected toll transaction picture is identified as a violation picture corresponding to the violation transaction entry based on a result of the comparison.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(22)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00014.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00014.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00015.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00015.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00016.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00016.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00017.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00017.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00018.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00018.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00019.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00019.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00020.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00020.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7676392B2/US07676392-20100309-D00021.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7676392B2/US07676392-20100309-D00021.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(31)</span></span></div><div class="patent-text"><div mxw-id="PCLM29280719" lang="EN" load-source="patent-office" class="claims">
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A method of identifying a vehicle in a toll system, the method comprising:
<div class="claim-text">accessing a set of toll transaction entries, each entry in the set designating a toll transaction between a vehicle and the toll system and including a transaction descriptor and a transaction time stamp;</div>
<div class="claim-text">accessing a series of toll transaction pictures, the series including a plurality of pictures, each of which is associated with a picture time stamp;</div>
<div class="claim-text">identifying a toll transaction entry from the set as a violation transaction entry based on the transaction descriptor;</div>
<div class="claim-text">selecting a toll transaction picture from the series;</div>
<div class="claim-text">comparing, by a processing device, the transaction time stamp of the violation transaction with the picture time stamp of the selected toll transaction picture; and</div>
<div class="claim-text">identifying the selected toll transaction picture as a violation picture corresponding to the violation transaction entry based on a result of the comparison.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the transaction time stamps included in the set of toll transaction entries and the picture time stamps associated with the plurality of pictures are based on independent clocks.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein accessing the set of toll transaction entries comprises receiving the set of toll transaction entries from a lane transaction system.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein accessing the series of toll transaction pictures comprises receiving the series of toll transaction pictures from an imaging system that is independent from the lane transaction system.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the imaging system being independent from the lane transaction system comprises the imaging system not receiving signals from the lane transaction system.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the imaging system being independent from the lane transaction system comprises the imaging system having an internal clock that is independent from an internal clock of the lane transaction system.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the transaction time stamps included in the set of toll transaction entries are generated based on the internal clock of the lane transaction system and the picture time stamps associated with the plurality of pictures are generated based on the internal clock of the imaging system.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein receiving the set of toll transaction entries from the lane transaction system comprises receiving the set of toll transaction entries in an e-mail.</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. A system for identifying a vehicle in a toll system, the system comprising:
<div class="claim-text">an accessing module configured to:
<div class="claim-text">access a set of toll transaction entries, each entry in the set designating a toll transaction between a vehicle and the toll system and including a transaction descriptor and a transaction time stamp, and</div>
<div class="claim-text">access a series of toll transaction pictures, the series including a plurality of pictures, each of which is associated with a picture time stamp;</div>
</div>
<div class="claim-text">a first identification module configured to identify a toll transaction entry from the set as a violation transaction entry based on the transaction descriptor;</div>
<div class="claim-text">a selecting module configured to select a toll transaction picture from the series;</div>
<div class="claim-text">a comparing module including at least one processor configured to compare the transaction time stamp of the violation transaction with the picture time stamp of the selected toll transaction picture; and</div>
<div class="claim-text">a second identification module configured to identify the selected toll transaction picture as a violation picture corresponding to the violation transaction entry based on a result of the comparison.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the accessing module is configured to access the set of toll transaction entries by receiving the set of toll transaction entries from a lane transaction system.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the accessing module is configured to access the series of toll transaction pictures by receiving the series of toll transaction pictures from an imaging system that is independent from the lane transaction system.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The system of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the imaging system being independent from the lane transaction system comprises the imaging system not receiving signals from the lane transaction system.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein:
<div class="claim-text">the picture time stamp includes a time of day at which an imaging system records occurrence of the toll transaction, and</div>
<div class="claim-text">the transaction time stamp includes a time of day at which a lane transaction system records occurrence of the toll transaction.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein accessing the set of toll transaction entries comprises accessing a set of toll transaction entries that includes at least one transaction entry that corresponds to a vehicle that provides for payment for transacting with the toll system at the time of the toll transaction.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein accessing the series of toll transaction pictures comprises accessing a series of toll transaction pictures that includes at least one toll transaction picture of a vehicle that provides for payment for transacting with the toll system at the time of the toll transaction.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, further comprising:
<div class="claim-text">selecting an other toll transaction picture from the series;</div>
<div class="claim-text">accessing the picture time stamp of the other toll transaction picture;</div>
<div class="claim-text">comparing, by a processing device, the transaction time stamp of the violation transaction with the picture time stamp of the selected other toll transaction picture; and</div>
<div class="claim-text">identifying the selected other toll transaction picture as not corresponding to the violation transaction entry based on a result of the comparison.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein accessing the series of toll transaction pictures comprises accessing a chronological sequence of pictures taken by an imaging system of every vehicle on a particular lane of the toll system transacting with a facility of the toll system during a predetermined window of time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein accessing the set of toll transaction entries comprises accessing a chronological sequence of toll transaction entries taken by a lane transaction system of every vehicle on the particular lane of the toll system transacting with the facility of the toll system during the predetermined window of time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text">19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, further comprising:
<div class="claim-text">accessing a first picture time stamp for a first picture in the chronological sequence of pictures;</div>
<div class="claim-text">accessing a first transaction time stamp for a first transaction entry in the chronological sequence of toll transaction entries; and</div>
<div class="claim-text">determining a clock offset between a clock of the imaging system and a clock of the lane transaction system based on the first picture time stamp and the first transaction time stamp.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text">20. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein comparing the transaction time stamp of the violation transaction with the picture time stamp of the selected toll transaction picture comprises:
<div class="claim-text">calculating an adjusted transaction time stamp by adjusting the transaction time stamp of the violation transaction based on the determined clock offset, and</div>
<div class="claim-text">comparing the adjusted transaction time stamp with the picture time stamp of the selected toll transaction picture.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
      <div class="claim-text">21. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein comparing the transaction time stamp of the violation transaction with the picture time stamp of the selected toll transaction picture comprises:
<div class="claim-text">calculating an adjusted picture time stamp by adjusting the picture time stamp of the selected toll transaction picture based on the determined clock offset, and</div>
<div class="claim-text">comparing the transaction time stamp of the violation transaction with the adjusted picture time stamp.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
      <div class="claim-text">22. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein:
<div class="claim-text">the picture time stamp includes a time of day at which an imaging system records occurrence of the toll transaction, and</div>
<div class="claim-text">the transaction time stamp includes a time of day at which a lane transaction system records occurrence of the toll transaction.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
      <div class="claim-text">23. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the accessing module is configured to access the set of toll transaction entries by accessing a set of toll transaction entries that includes at least one transaction entry that corresponds to a vehicle that provides for payment for transacting with the toll system at the time of the toll transaction.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00024" num="00024" class="claim">
      <div class="claim-text">24. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the accessing module is configured to access the series of toll transaction pictures by accessing a series of toll transaction pictures that includes at least one toll transaction picture of a vehicle that provides for payment for transacting with the toll system at the time of the toll transaction.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00025" num="00025" class="claim">
      <div class="claim-text">25. The system of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein
<div class="claim-text">the selecting module is further configured to select an other toll transaction picture from the series;</div>
<div class="claim-text">the accessing module is further configured to access the picture time stamp of the other toll transaction picture;</div>
<div class="claim-text">the comparing module is further configured to compare, by the processing device, the transaction time stamp of the violation transaction with the picture time stamp of the selected other toll transaction picture; and</div>
<div class="claim-text">the second identification module is further configured to identify the selected other toll transaction picture as not corresponding to the violation transaction entry based on a result of the comparison.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00026" num="00026" class="claim">
      <div class="claim-text">26. The system of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the accessing module is configured to access the series of toll transaction pictures by accessing a chronological sequence of pictures taken by an imaging system of every vehicle on a particular lane of the toll system transacting with a facility of the toll system during a predetermined window of time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00027" num="00027" class="claim">
      <div class="claim-text">27. The system of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein the accessing module is configured to access the set of toll transaction entries by accessing a chronological sequence of toll transaction entries taken by a lane transaction system of every vehicle on the particular lane of the toll system transacting with the facility of the toll system during the predetermined window of time.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00028" num="00028" class="claim">
      <div class="claim-text">28. The system of <claim-ref idref="CLM-00027">claim 27</claim-ref>,
<div class="claim-text">wherein the accessing module is further configured to access a first picture time stamp for a first picture in the chronological sequence of pictures and access a first transaction time stamp for a first transaction entry in the chronological sequence of toll transaction entries; and</div>
<div class="claim-text">further comprising a determining module configured to determine a clock offset between a clock of the imaging system and a clock of the lane transaction system based on the first picture time stamp and the first transaction time stamp.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00029" num="00029" class="claim">
      <div class="claim-text">29. The system of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the comparing module is configured to compare the transaction time stamp of the violation transaction with the picture time stamp of the selected toll transaction picture by:
<div class="claim-text">calculating an adjusted transaction time stamp by adjusting the transaction time stamp of the violation transaction based on the determined clock offset, and</div>
<div class="claim-text">comparing the adjusted transaction time stamp with the picture time stamp of the selected toll transaction picture.</div>
</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00030" num="00030" class="claim">
      <div class="claim-text">30. The system of <claim-ref idref="CLM-00028">claim 28</claim-ref>, wherein the comparing module is configured to compare the transaction time stamp of the violation transaction with the picture time stamp of the selected toll transaction picture by:
<div class="claim-text">calculating an adjusted picture time stamp by adjusting the picture time stamp of the selected toll transaction picture based on the determined clock offset, and</div>
<div class="claim-text">comparing the transaction time stamp of the violation transaction with the adjusted picture time stamp.</div>
</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00031" num="00031" class="claim">
      <div class="claim-text">31. An apparatus for identifying a vehicle in a toll system, the apparatus comprising:
<div class="claim-text">means for accessing a set of toll transaction entries, each entry in the set designating a toll transaction between a vehicle and the toll system and including a transaction descriptor and a transaction time stamp;</div>
<div class="claim-text">means for accessing a series of toll transaction pictures, the series including a plurality of pictures, each of which is associated with a picture time stamp;</div>
<div class="claim-text">means for identifying a toll transaction entry from the set as a violation transaction entry based on the transaction descriptor;</div>
<div class="claim-text">means for selecting a toll transaction picture from the series;</div>
<div class="claim-text">means for comparing, by a processing device, the transaction time stamp of the violation transaction with the picture time stamp of the selected toll transaction picture; and</div>
<div class="claim-text">means for identifying the selected toll transaction picture as a violation picture corresponding to the violation transaction entry based on a result of the comparison. </div>
</div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES35744354" lang="EN" load-source="patent-office" class="description">
    <heading>CROSS-REFERENCE TO RELATED APPLICATIONS</heading> <p num="p-0002">This application claims priority to U.S. Provisional Patent Application No. 60/689,050, filed on Jun. 10, 2005, and titled ELECTRONIC TOLL MANAGEMENT, hereby incorporated by reference in its entirety for all purposes.</p>
    <heading>TECHNICAL FIELD</heading> <p num="p-0003">This document relates to electronic toll management.</p>
    <heading>BACKGROUND</heading> <p num="p-0004">Transportation facilities such as roads, bridges, and tunnels produce tolls often representing a major source of income for many states and municipalities. The large number of automobiles, trucks, and buses stopping at tollbooths to pay a toll daily can cause significant problems. For example, such facilities may restrict the flow of traffic causing traffic backups and lane changing, often increasing the likelihood of accidents and even more bottlenecks. In addition, many people may be delayed from reaching their destinations, and goods may be delayed from getting to market and millions of gallons of fuel may be wasted as vehicles idle. Environments may experience an increase in pollution as idling and slow moving vehicles emit pollutants (particularly carbon dioxide and carbon monoxide), which may pose a significant health hazard to motorists as well as to tollbooth operators.</p>
    <p num="p-0005">Some tollbooth systems may have a program requiring that a motorist rent and then attach to the windshield of the vehicle a radio transponder that communicates via radio frequency with receiver units at tollbooth plazas. However, such programs require drivers to seek out the program and to register for the program. These programs may make it mandatory for a motorist to make a credit card deposit and create an automatic debit account arrangement, which may effectively eliminate drivers with credit problems. These programs also may bill participants based on a minimum amount of travel regardless of the actual amount of travel. Thus, many motorists who travel infrequently travel through the toll road may receive little benefit after investing time and money to participate in the program.</p>
    <p num="p-0006">Tollbooth systems typically include a lane transaction system that records each vehicle transaction with the toll facility and an imaging system that takes pictures of each vehicle that passes the toll facility. If the lane transaction system detects a violation, the lane transaction system typically sends a “violation” signal to the imaging system. The imaging system may respond to the “violation” signal by sending the picture associated with the violation transaction to a backend system for vehicle identification and processing. If no “violation” signal is received by the imaging system from the lane transaction system after a picture of a vehicle is taken, the imaging system typically discards the picture. Accordingly, the backend system only receives pictures of vehicles that commit violations. Once a violating vehicle is identified, the backend system typically refers the vehicle to law enforcement and/or attempts to bill or otherwise collect the unpaid toll fees.</p>
    <p num="p-0007">In some cases, a tolling system may include a lane transaction system, but not an imaging system. In such cases, it may be undesirable or impractical to integrate an imaging system directly with the lane system. Integration may put the lane system at risk due to increased demand for system resources (especially real-time or near-real-time messaging to the imaging system). System modifications may reduce reliability of a proven system. The cost of integration to a legacy system may be high.</p>
    <heading>SUMMARY</heading> <p num="p-0008">In one implementation, a toll system enables electronic handling of payment of tolls by vehicles passing a toll facility without requiring the toll system's lane transaction system to directly communicate with the toll system's imaging system (i.e., the lane transaction system is independent from the imaging system and need not send any signals, including “violation” signals, to the imaging system). Accordingly, the toll system is configured to decouple the imaging system from the lane transaction system, and, thereby, minimize or eliminate the need to modify the lane transaction system when installing a new imaging system.</p>
    <p num="p-0009">In one general aspect, identifying a vehicle in a toll system includes accessing a set of toll transaction entries. Each entry in the set designates a toll transaction between a vehicle and the toll system and includes a transaction descriptor and a transaction time stamp. A series of toll transaction pictures is accessed. The series includes a plurality of pictures, each of which is associated with a picture time stamp. A toll transaction entry is identified from the set as a violation transaction entry based on the transaction descriptor. A toll transaction picture is selected from the series. The transaction time stamp of the violation transaction is compared, using a processing device, with the picture time stamp of the selected toll transaction picture. The selected toll transaction picture is identified as a violation picture corresponding to the violation transaction entry based on a result of the comparison.</p>
    <p num="p-0010">Implementations may include one or more of the following features. For example, the transaction time stamps included in the set of toll transaction entries and the picture time stamps associated with the plurality of pictures may be based on independent clocks.</p>
    <p num="p-0011">Accessing the set of toll transaction entries may include receiving the set of toll transaction entries from a lane transaction system. Accessing the series of toll transaction pictures may include receiving the series of toll transaction pictures from an imaging system that is independent from the lane transaction system. The imaging system being independent from the lane transaction system may include the imaging system not receiving signals from the lane transaction system. The imaging system being independent from the lane transaction system may include the imaging system having an internal clock that is independent from an internal clock of the lane transaction system. The transaction time stamps included in the set of toll transaction entries may be generated based on the internal clock of the lane transaction system, and the picture time stamps associated with the plurality of pictures may be generated based on the internal clock of the imaging system.</p>
    <p num="p-0012">Receiving the set of toll transaction entries from the lane transaction system may include receiving the set of toll transaction entries in an e-mail.</p>
    <p num="p-0013">In another general aspect, identifying a vehicle in a toll system includes accessing a set of toll transaction entries. Each entry in the set designates a toll transaction between a vehicle and the toll system and includes a transaction descriptor and a transaction time stamp. A series of toll transaction pictures is accessed. The series includes a plurality of pictures, each of which is associated with a picture time stamp. A toll transaction entry from the set is identified as a violation transaction entry based on the transaction descriptor. A group of toll transaction entries is selected from among the set of toll transaction entries based on the time stamp of the violation transaction entry. A group of toll transaction pictures is selected from the series of toll transaction pictures based on the selected group of toll transaction entries. A toll transaction picture is identified from the group of toll transaction pictures as a violation picture corresponding to the violation transaction entry by associating the group of toll transaction entries with the group of toll transaction pictures.</p>
    <p num="p-0014">Implementations may include one or more of the following features. For example, selecting the group of toll transaction entries from among the set of toll transaction entries may include identifying a first time gap having a predetermined duration of time between the transaction time stamps of chronologically sequential toll transaction entries of the set of toll transaction entries, the chronologically sequential toll transaction entries occurring before the identified violation transaction entry. Selecting the group of toll transaction entries from among the set of toll transaction entries may additionally include adding a toll transaction entry to the group of toll transaction entries if the toll transaction entry includes a transaction time stamp falling within a window of time beginning at a time corresponding to a time stamp of a transaction entry immediately following the identified first time gap and ending at a time corresponding to the transaction time stamp of the identified violation transaction entry. The predetermined duration of time of the first time gap may include a duration of time between six and ten seconds.</p>
    <p num="p-0015">Selecting the group of toll transaction entries from among the set of toll transaction entries may further include adding a toll transaction entry to the group of toll transaction entries if the toll transaction entry includes a transaction time stamp falling within a window of time beginning at a time corresponding to the transaction time stamp of the identified violation transaction entry and ending at a time corresponding to a predetermined amount of time after the transaction time stamp of the identified violation transaction entry. The predetermined amount of time after the transaction time stamp of the identified violation transaction entry may be a time between thirty seconds and one minute.</p>
    <p num="p-0016">Selecting the group of toll transaction pictures may include selecting from the series of toll transaction pictures a toll transaction picture corresponding to the transaction entry immediately following the identified first time gap. A toll transaction picture may be added to the group of toll transaction pictures if the toll transaction picture is associated with a picture time stamp falling within a window of time beginning at a time corresponding to the picture time stamp associated with the selected toll transaction picture and ending at the predetermined time following the transaction time stamp of the identified violation transaction entry.</p>
    <p num="p-0017">Selecting the group of toll transaction entries from among the set of toll transaction entries may further include identifying a second time gap having a predetermined duration of time between the transaction time stamps of chronologically sequential toll transaction entries of the set of toll transaction entries, the chronologically sequential toll transaction entries occurring after the identified violation transaction entry. A toll transaction entry may be added to the group of toll transaction entries if the toll transaction entry includes a transaction time stamp falling within a window of time beginning at a time corresponding to the transaction time stamp of the identified violation transaction entry and ending at a time corresponding to a time stamp of a transaction entry immediately preceding the identified second time gap.</p>
    <p num="p-0018">Selecting the group of toll transaction pictures may include selecting from the series of toll transaction pictures a first toll transaction picture corresponding to the transaction entry immediately following the identified first time gap. A second toll transaction picture corresponding to the transaction entry immediately preceding the identified second time gap is selected from the series of toll transaction pictures. A toll transaction picture may be added to the group of toll transaction pictures if the toll transaction picture is associated with a picture time stamp falling within a window of time beginning at a time corresponding to the picture time stamp associated with the selected first toll transaction picture and ending at a time corresponding to the picture time stamp associated with the selected second toll transaction picture.</p>
    <p num="p-0019">Selecting the group of toll transaction entries from among the set of toll transaction entries may include selecting from the set of toll transaction entries a toll transaction entry designating a toll transaction between the toll system and a vehicle that has been positively identified, the selected toll transaction entry including a transaction time stamp that is earlier in time than the transaction time stamp included in the identified violation transaction entry. A toll transaction entry may be added to the group of toll transaction entries if the toll transaction entry includes a transaction time stamp falling within a window of time beginning at a time corresponding to the time stamp of the selected toll transaction and ending at a time corresponding to the transaction time stamp of the identified violation transaction entry.</p>
    <p num="p-0020">Selecting the group of toll transaction entries from among the set of toll transaction entries may further comprise adding a toll transaction entry to the group of toll transaction entries if the toll transaction entry includes a transaction time stamp falling within a window of time beginning at a time corresponding to the transaction time stamp of the identified violation transaction entry and ending at a predetermined time following the transaction time stamp of the identified violation transaction entry.</p>
    <p num="p-0021">Identifying a toll transaction picture from the group of toll transaction pictures as a violation picture may include associating on a one-to-one basis each toll transaction picture in the group of toll transaction pictures with each toll transaction entry in the group of toll transaction entries. Associating on a one-to-one basis each toll transaction picture with each toll transaction entry may include ordering, in sequential chronological order, the toll transaction entries in the group of toll transaction entries based on the toll transaction time stamps and ordering, in sequential chronological order, the toll transaction pictures in the group of toll transaction pictures based on the picture time stamps. Each toll transaction entry may be associated with a place in the toll transaction entry order and each toll transaction picture may be associated with a place in the toll transaction picture order. A toll transaction entry may be selected and the selected toll transaction entry may be associated with a toll transaction picture conditioned on the toll transaction entry being associated with a place in the toll transaction entry order that corresponds to the place in the toll transaction picture order associated with the toll transaction picture.</p>
    <p num="p-0022">Additional toll transaction entries may be inserted in the group of toll transaction entries if the number of toll transaction entries in the group of toll transaction entries is less than the number of toll transaction pictures in the group of toll transaction pictures. Additional toll transaction pictures may be inserted in the group of toll transaction pictures if the number of toll transaction pictures in the group of toll transaction pictures is less than the number of toll transaction entries in the group of toll transaction entries.</p>
    <p num="p-0023">The selected toll transaction entry and the associated toll transaction picture may be designated as improperly matched conditioned on a difference between the transaction time stamp of the selected toll transaction entry and the picture time stamp of the associated toll transaction picture being greater than a predetermined value. The predetermined value may be one second.</p>
    <p num="p-0024">An interval of time between two transactions may be calculated based on the toll transaction time stamps of two chronologically sequential toll transaction entries. A corresponding interval of time between the two transactions based on the picture time stamps of two chronologically sequential toll pictures also may be calculated, the two chronologically sequential toll pictures being associated with the two chronologically sequential toll transaction entries. The two chronologically sequential toll pictures and the two chronologically sequential toll transaction entries may be designated as improperly matched conditioned on a difference between the interval of time and the corresponding interval of time being greater than a predetermined value. The predetermined value may be four seconds.</p>
    <p num="p-0025">Identifying a toll transaction picture from the group of toll transaction pictures as a violation picture may include designating as the violation picture a toll transaction picture associated with a place in the toll transaction picture order that corresponds to a place in the toll transaction entry order associated with the violation transaction entry.</p>
    <p num="p-0026">The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features will be apparent from the description and drawings, and from the claims.</p>
    <description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram of an implementation of an electronic toll management system.</p>
      <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a flow chart of an implementation of an electronic toll management system related to highlighted vehicle identifier management.</p>
      <p num="p-0029"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a flow chart of an implementation of an electronic toll management system related to payment management.</p>
      <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a flow chart of an implementation of an electronic toll management system related to payment management.</p>
      <p num="p-0031"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a flow chart of an implementation of an electronic toll management system related to mailing address verification.</p>
      <p num="p-0032"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a block diagram of an implementation of an electronic toll management system.</p>
      <p num="p-0033"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a flow chart of an implementation of an electronic toll management system related to vehicle identification.</p>
      <p num="p-0034"> <figref idrefs="DRAWINGS">FIG. 8</figref>. is a flow chart of an implementation of an electronic toll management system related to vehicle identification.</p>
      <p num="p-0035"> <figref idrefs="DRAWINGS">FIGS. 9A-9C</figref> are a flow chart of an implementation of an electronic toll management system related to vehicle identification.</p>
      <p num="p-0036"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a block diagram of an implementation of an electronic toll management system.</p>
      <p num="p-0037"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a group of transaction entries generated by a lane transaction system.</p>
      <p num="p-0038"> <figref idrefs="DRAWINGS">FIG. 12</figref> is an illustration of a group of image/sensor files.</p>
      <p num="p-0039"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a flow chart of an implementation of an electronic toll management system related to selecting groups of transaction entries and corresponding groups of image/sensor files.</p>
      <p num="p-0040"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a flow chart of an implementation of an electronic toll management system related to identifying an image/sensor file for each violation transaction entry.</p>
      <p num="p-0041"> <figref idrefs="DRAWINGS">FIG. 15</figref> is an illustration of the group of transaction entries of <figref idrefs="DRAWINGS">FIG. 11</figref> matched on a one-to-one basis with the group of sensor/files of <figref idrefs="DRAWINGS">FIG. 12</figref>.</p>
      <p num="p-0042"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a flow chart of an implementation of an electronic toll management system.</p>
      <p num="p-0043"> <figref idrefs="DRAWINGS">FIG. 17</figref> is an exemplary user interface.</p>
      <p num="p-0044"> <figref idrefs="DRAWINGS">FIG. 18</figref> is a bar graph showing the interval of time between a lane transaction entry time stamp and a corresponding image time stamp for a transaction.</p>
      <p num="p-0045"> <figref idrefs="DRAWINGS">FIG. 19</figref> is a bar graph showing the interval of time between current and preceding lane transactions according to image time stamps and according to transaction entry time stamps.</p>
    </description-of-drawings> <p num="p-0046">Like reference symbols in the various drawings indicate like elements.</p>
    <heading>DETAILED DESCRIPTION</heading> <p num="p-0047">In one implementation, a toll system enables electronic handling of payment of tolls by vehicles passing a toll facility without requiring the toll system's lane transaction system to directly communicate with the toll system's imaging system Accordingly, the toll system is configured to decouple the imaging system from the lane transaction system, and, thereby, minimize or eliminate the need to modify the lane transaction system when installing a new imaging system.</p>
    <p num="p-0048">The above toll system includes a toll management computer system having an image and lane transaction data acquisition module (ILDM). The ILDM includes a lane transaction system, an image acquisition module, and a video server.</p>
    <p num="p-0049">The lane transaction system is configured to capture transaction-related data for each vehicle that passes through or otherwise transacts with the toll facility. The transaction-related data may include, for example, the type of transaction, the time of the transaction (e.g., the transaction time stamp), vehicle classification data (e.g. the number of axles of the vehicle), the transponder information, if applicable, of the vehicle, and the fare charged. The lane transaction system may be an existing or a conventional lane transaction system. Accordingly, while the lane transaction system may have the ability to send “violation” signals to an imaging system, this ability need not be used. The imaging system or image acquisition module may operate independently from the lane transaction system and, accordingly, need not receive any signals from the lane transaction system or directly from the lane transaction system.</p>
    <p num="p-0050">The lane transaction system is configured to periodically generate and send a lane activity report to the video server. The lane activity report includes lane transaction data for vehicles that have passed through the toll facility during a given window of time (e.g., a day). The lane activity report typically includes a chronological list of lane transaction entries, each of which corresponds to a single vehicle transaction with the toll facility. Alternatively, the lane transaction system may make available a database of transaction data or a copy of such data.</p>
    <p num="p-0051">The image acquisition module uses sensors, such as, for example, laser sensors, to detect passing vehicles typically as they enter or otherwise begin passing through the toll facility. The laser sensors trigger cameras and optionally other sensors, which are configured to capture image/sensor data for each passing vehicle detected by the laser sensors. Notably, unlike conventional toll systems, the image acquisition module need not receive “violation” signals directly from the lane transaction system and need not discard pictures in response to lack of receipt of such signals.</p>
    <p num="p-0052">The image acquisition module may send to the video server an image/sensor file for each vehicle that passes through or transacts with the toll facility. Each image/sensor file may include data corresponding to at least one image or picture of the transacting vehicle (e.g., a picture of the back of the vehicle), may optionally include sensor data, and also may include a time stamp indicating when the image and optional sensor data was captured.</p>
    <p num="p-0053">The video server may receive the lane activity report from the lane transaction system and may receive the image/sensor files from the image acquisition module. The video server synchronizes or matches each lane transaction entry in the lane activity report with a single image/sensor file received from the image acquisition module. Accordingly, the video server determines a one-to-one correspondence between the lane transaction entries in the lane activity report and the image/sensor files.</p>
    <p num="p-0054">The video server typically determines the one-to-one correspondence between the lane transaction entries and the image/sensor files by first parsing the lane activity report into groups of chronologically sequential transaction entries separated by, or bracketed by, transaction entries corresponding to “landmark transactions.” A landmark transaction is a transaction having a transaction entry that typically may be easily related to a readily identifiable captured picture or image. For example, a landmark transaction may be a transaction involving a multi-axle vehicle (i.e., a vehicle having three or more axles). If a lane transaction entry indicates that a transacting vehicle has three or more axles, the corresponding image of the vehicle may be easily selected from among the captured images because typically the majority of the captured images are of cars, which have only two axles.</p>
    <p num="p-0055">Accordingly, the lane transaction data may be parsed into groups of chronologically sequential transaction entries bracketed by landmark transaction entries, and the image/sensor files may be parsed into corresponding groups of chronologically sequential image/sensor files bracketed by image/sensor files having landmark transaction images (i.e., the easily identifiable images that correspond to the landmark transactions.)</p>
    <p num="p-0056">Once the groups of transaction entries and the corresponding groups of image/sensor files have been identified, the video server may match each transaction entry of a given group of transaction entries with an image/sensor file of a corresponding group of image/sensor files. The transaction entry to sensor/file matching may use the landmark transactions as a reference point and may match, in order, each transaction entry following a landmark transaction entry with each image/sensor file that follows the image/sensor file having the corresponding landmark transaction image. Because of the lack of synchronicity between the lane transaction system and the image acquisition module and the imperfect process of capturing transaction-related data and images, the matching process typically includes adding placeholder transaction entries and/or placeholder image/sensor files to ensure that the number of transaction entries in a group is the same as the number of image/sensor files in the corresponding group.</p>
    <p num="p-0057">The video server may be configured to confirm whether the matching process was successful by checking whether the differences between the time stamps of the transaction entries and the time stamps of the matching image/sensor files are within a predetermined tolerance level. The video server also may be configured to check whether the differences between the intervals of time between transactions as determined from transaction entry time stamps and the corresponding intervals of time as determined from the matching image/sensor file time stamps are also within a predetermined tolerance level.</p>
    <p num="p-0058">The video server may send the matched image/sensor files and transaction entries to an image processing module of the toll management computer system. The image processing module processes the image/sensor files to extract vehicle identification data. The toll management computer uses the vehicle identification data to identify the vehicles. After the vehicles have been identified, the toll management computer accesses the matched transaction data entries for the identified vehicles and bills or otherwise enables receipt of payment for the transaction from an individual or entity associated with the identified vehicle.</p>
    <p num="p-0059"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram of an implementation of an electronic toll management system <b>10</b>. The system <b>10</b> is configured to capture a vehicle identifier <b>31</b> of vehicle <b>30</b> interacting with a facility <b>28</b> and to notify external systems <b>34</b> of such interaction. For example, the system <b>10</b> may allow a toll road authority to capture a vehicle identifier <b>31</b>, such as license plate information, from a vehicle <b>30</b> traveling through the toll road and then to notify law enforcement whether the captured vehicle identifier matches a license plate previously highlighted by law enforcement.</p>
    <p num="p-0060">The toll management system <b>10</b> also can manage payment from a party associated with the vehicle <b>32</b> based on the interaction between the vehicle <b>30</b> and the facility <b>28</b>. For example, the system <b>10</b> can capture license plate information from a vehicle <b>30</b> and identify the registered owner of the vehicle. The system would then provide to the owner, over a communications channel such as the Internet, an account for making payment or disputing payment. The toll management system <b>10</b> can send a bill requesting payment from the party <b>32</b> using a mailing address that has been verified against one or more mailing address sources. The system <b>10</b> is capable of automatically capturing an image of the vehicle <b>30</b> triggered by the vehicle interacting with the facility. Such image capturing can be accomplished using image-processing technology without having to install a radio transponder (e.g., RFID device) in a vehicle.</p>
    <p num="p-0061">The electronic toll management system <b>10</b> includes a toll management computer <b>12</b> which can be configured in a distributed or a centralized manner. Although one computer <b>12</b> is shown, one or more computers can be configured to implement the disclosed techniques. The computer <b>12</b> is coupled to a facility <b>28</b> that may charge a fee for interacting with the facility. Examples of a facility <b>28</b> include a toll facility (managed by toll authorities) such as toll road, a toll bridge, a tunnel, parking facility, or other facility. The fee may be based on the interaction between the vehicle <b>30</b> and the facility <b>28</b>. Examples of interactions that may involve a fee include a distance traveled by the vehicle through the facility, a time period the vehicle is present in a facility, the type of vehicle interacting with the facility, the speed at which the vehicle passes through the facility, and the type of interaction between the vehicle and the facility.</p>
    <p num="p-0062">The facility <b>28</b> can process vehicles including automobiles, a truck, buses, or other vehicles. For ease of explanation, the system <b>10</b> shows a single facility <b>28</b> interacting with a single vehicle <b>30</b> and a party associated with the vehicle <b>32</b>. However, in other implementations, the disclosed techniques could be configured to operate with one or more vehicles interacting with one or more facilities spanning different geographic locations.</p>
    <p num="p-0063">The toll management computer <b>12</b> includes an image acquisition module <b>24</b> configured to detect the presence of a vehicle, acquire one or more images of the vehicle, and forward the image(s) to an image-processing module <b>25</b> for further processing. The module <b>24</b> may include image acquisition equipment based on the physical environment in which it is used. For example, for open-road applications, image acquisition equipment may be mounted above the roadway, on existing structures or on purpose-built gantries. Some open-road applications may use equipment mounted in or beside the roadway as well. Lane-based (or tollbooth-style) applications may use equipment mounted on physical structures beside each lane, instead of or in addition to equipment mounted overhead or in the roadway.</p>
    <p num="p-0064">The image acquisition module <b>24</b> may include imaging components such as vehicle sensors, cameras, digitizing systems, or other components. Vehicle sensors can detect the presence of a vehicle and provide a signal that triggers a camera to capture one or more images of the vehicle. Vehicle sensors may include one or more of the following:</p>
    <p num="p-0065">(1) Laser/sonic/microwave devices—these devices, commonly used in Intelligent Transportation Systems (ITS) applications, can recognize the presence of a vehicle and provide information regarding the vehicle's size, classification, and/or speed. These sensors may be configured to provide additional information about the vehicle which can be used in identify the vehicle and its use of the toll facility, including trip time and compliance with traffic laws.</p>
    <p num="p-0066">(2) Loops—these sensors can detect the presence and the vehicle type by recognizing the presence of metal masses using a wire loop embedded in the road. Loops can be used as a backup to more sophisticated sensors. Loops can also be used as a primary source of data to detect vehicles, classify vehicles, trigger cameras, and provide vehicle signature data (e.g., based on use of an array of loops with a smart loop control program such as Diamond Consulting's IDRIS® system of Buckinghamshire, United Kingdom).</p>
    <p num="p-0067">(3) Through-beam sensors—these sensors may emit a continuous beam across the roadway, and detect the presence of a vehicle based upon interruptions in the beam. This type of sensor may be used in installations where traffic is channeled into tollbooth-style lanes.</p>
    <p num="p-0068">(4) Optical sensors—vehicle may be recognized using cameras to continuously monitor images of the roadway for changes indicating the presence of a vehicle. These cameras also can be used to record images for vehicle identification.</p>
    <p num="p-0069">Cameras can be used to capture images of vehicles and their identifying characteristics. For example, they can be used to generate a vehicle identifier such as a vehicle license number based on an image of a license plate. Cameras may be analog or digital, and may capture one or more images of each vehicle.</p>
    <p num="p-0070">Digitizing systems convert images into digital form. If analog cameras are used, the cameras can be connected to separate digitizing hardware. This hardware may include a dedicated processing device for analog-to-digital conversion or may be based on an input device installed in a general-purpose computer, which may perform additional functions such as image processing. Lighting can be employed to provide adequate and consistent conditions for image acquisition. The lighting may include strobes or continuous illumination, and may emit light of light in the visible spectrum or in the infrared spectrum. If strobes are used, they may be triggered by inputs from the vehicle sensor(s). Other sensors such as light sensors may be required to control the image acquisition module <b>24</b> and provide consistent results.</p>
    <p num="p-0071">Once the image acquisition module <b>24</b> has captured images of the vehicles, the images may be forwarded to an image-processing module <b>25</b>. The image-processing module <b>25</b> may be located in the same location as the image acquisition module <b>24</b> and the image computer <b>12</b>, in a remote location, or a combination of these locations. The module <b>25</b> can process a single image for each vehicle or multiple images of each vehicle, depending on the functionality of the image acquisition module <b>24</b> and/or business requirements (e.g., accuracy, jurisdictional requirements). If multiple images are used, each image may be processed, and the results may be compared or combined to enhance the accuracy of the process. For example, more than one image of a rear license plate, or images of both front and rear license plates, may be processed and the results compared to determine the most likely registration number and/or confidence level. Image processing may include identifying the distinguishing features of a vehicle (e.g., the license plate of a vehicle) within the image, and analyzing those features. Analysis may include optical character recognition (OCR), template matching, or other analysis techniques.</p>
    <p num="p-0072">The toll management system <b>10</b> may include other systems capable of substantially real-time processing located at the site where images are acquired to reduce data communication requirements. In an implementation of local image processing, the results may be compared to a list of authorized vehicles. If a vehicle is recognized as authorized, images and/or data may be discarded rather than forwarded for further processing.</p>
    <p num="p-0073">Images and data can be forwarded to a central processing facility such as the image database <b>14</b> operating in conjunction with the billing engine <b>22</b>. This process may involve a computer network, but may also include physical media from another computer located at the image acquisition site (i.e., facility <b>28</b>). Generally, information can be temporarily stored on a computer at the image acquisition site in the event the network is unavailable.</p>
    <p num="p-0074">Images received at the central site may not have been processed. Any unprocessed images can be handled as described above. The data resulting from image processing (remote or central) may be separated into two categories. Data that meets application-specific or jurisdiction-specific criteria for confidence may be sent directly to the billing engine <b>22</b>. On the other hand, data results not meeting required confidence levels may be flagged for additional processing. Additional processing may include, for example, determining whether multiple images of a vehicle are available and independently processing the images and comparing the results. This may include character-by-character comparisons of the results of optical character recognition (OCR) on the license plate image. In another example, the image(s) may be processed by one or more specialized algorithms for recognizing license plates of certain types or styles (such as plates from a particular jurisdiction). These algorithms may consider the validity of characters for each position on the license plate, the anticipated effect of certain design features (such as background images), or other style-specific criteria. The processed image may be forwarded based on preliminary processing results, or may include processing by all available algorithms to determine the highest confidence level.</p>
    <p num="p-0075">Preliminary data may be compared to other data available to increase the confidence level. Such techniques include:</p>
    <p num="p-0076">(1) Comparing OCR processed license plate data against lists of valid license plate numbers within the billing system or at the appropriate jurisdiction's motor vehicle registration authority.</p>
    <p num="p-0077">(2) Comparing other data obtained from sensors at the imaging location (such as vehicle size) to known characteristics of the vehicle registered under the registration number recognized by the system, in the recognized jurisdiction or in multiple jurisdictions.</p>
    <p num="p-0078">(3) Comparing the registration and other data to records from other sites (e.g., records of the same or similar vehicle using other facilities on the same day, or using the same facility at other times).</p>
    <p num="p-0079">(4) Comparing vehicle fingerprint data against stored lists of vehicle fingerprint data. The use of vehicle fingerprint data for vehicle identification is described in more detail below.</p>
    <p num="p-0080">(5) Manually viewing the images or data to confirm or override the results of automated processing.</p>
    <p num="p-0081">If additional processing provides a result with a particular confidence level, the resulting data then can be forwarded to the billing engine <b>22</b>. If the required confidence level cannot be attained, the data may be kept for future reference or discarded.</p>
    <p num="p-0082">The billing engine <b>22</b> processes the information captured during the interaction between the vehicle and the toll facility, including the vehicle identifier as determined by the image processing module <b>25</b> to create a transaction event corresponding to an interaction between the vehicle and the facility. The engine <b>22</b> can store the transaction event in a billing database <b>16</b> for subsequent payment processing. For example, the billing engine <b>22</b>, alone or in combination with a customer management module <b>26</b> (described below), produces payment requests based on the transaction events. The transaction event data may include individual charges based on a vehicle's presence at specific points or facilities, or trip charges based on a vehicle's origin and destination involving a facility. These transaction events can be compiled and billed, for example, by one or more of the following methods:</p>
    <p num="p-0083">(1) Deducting payment from an account established by the vehicle owner or operator. For example, the billing database <b>20</b> can be used to store an account record for each vehicle owner. In turn, each account record can include a reference to one more transaction events. A paper or electronic payment statement may be issued and sent to the registered owner of the vehicle.</p>
    <p num="p-0084">(2) Generating a paper bill and sending it to the owner of the vehicle using a mailing address derived from a vehicle registration record.</p>
    <p num="p-0085">(3) Presenting an electronic bill to a predefined account for the vehicle owner, hosted either by the computer <b>12</b> or a third party.</p>
    <p num="p-0086">(4) Submitting a bill to the appropriate vehicle registration authority or tax authority, permitting payment to be collected during the vehicle registration renewal process or during the tax collection process.</p>
    <p num="p-0087">Billing may occur at regular intervals, or when transactions meet a certain threshold, such as maximum interval of time or maximum dollar amount of outstanding toll charges and other fees. Owners may be able to aggregate billing for multiple vehicles by establishing an account with the computer <b>12</b>.</p>
    <p num="p-0088">The customer management module <b>26</b> can allow a user to interact with the toll management computer <b>12</b> over a communications channel such as a computer network (e.g., Internet, wired, wireless, etc.), a telephone connection, or other channel. The user can include a party associated with a vehicle <b>22</b> (e.g., owner of the vehicle), a public or private authority responsible for management of the facility <b>28</b>, or other user. The customer management module <b>26</b> includes a combination of hardware and software module configured to handle customer interactions such as an account management module <b>26</b> <i>a</i>, a dispute management module <b>26</b> <i>b </i>and a payment processing module <b>26</b> <i>c</i>. The module <b>26</b> employs secure access techniques such as encryption, firewalls, password or other techniques.</p>
    <p num="p-0089">The account management module <b>26</b> <i>a </i>allows users such as motorists to create an account with the system <b>10</b>, associate multiple vehicles with that account, view transactions for the account, view images associated with those transactions, and make payments on the account. In one implementation, a user responsible for the facility can access billing and collection information associated with motorists that have used the facility.</p>
    <p num="p-0090">The dispute management module <b>26</b> <i>b </i>may permit customers to dispute specific transactions on their accounts and to resolve disputes using the computer <b>12</b> or third parties. Disputes may arise during billing situations. The module <b>26</b> <i>b </i>may help resolve such disputes in an automated fashion. The module <b>26</b> <i>b </i>can provide a customer to access an “eResolution” section of a controlling/billing authority website. Customers can file a dispute and download an image of their transaction, the one in question. If there is no match (i.e., the customers automobile is not the automobile in the photo frame), the bill can be forwarded for a third party evaluation such as arbitration. In the far more likely case, the photo will show that the customer's automobile was indeed billed correctly. Dispute management can use encrypted security in which all text and images are sent over a computer network (e.g., the Internet) using high strength encryption. Proof of presence images can be embedded into the dispute resolution communication as an electronic watermark.</p>
    <p num="p-0091">The payment processing module <b>26</b> <i>c </i>provides functionality for processing payments manually or electronically, depending on the remittance received. For example, if payment remittance is in the form of a paper check, then scanning devices could be used to convert the paper information into electronic format for further processing. On the other hand if electronic payment is employed, then standard electronic payment techniques can be used. The payment processing module <b>26</b> <i>c </i>can support billing methods such as traditional mailing, electronic payment (e.g. using a credit card, debit card, smart card, or Automated Clearing House transaction), periodic billing (e.g., send the bill monthly, quarterly, upon reaching a threshold, or other). The payment processing module <b>26</b> <i>c </i>can support discounts and surcharges based on frequency of usage, method of payment, or time of facility usage. The payment processing module <b>26</b> <i>c </i>also can support payment collection methods such as traditional check processing, processing payment during renewal of a vehicle registration (with interest accrued), electronic payment, direct debit bank, credit cards, pre-payment, customer-initiated payments (as often as the customer desires), or provide discounts for different purposes.</p>
    <p num="p-0092">The toll management computer <b>12</b> communicates with external systems <b>34</b> using one or more communications techniques compatible with the communications interfaces of the systems. For example, communications interfaces can include computer networks such as the Internet, electronic data interchange (EDI), batch data file transfers, messaging systems, or other interfaces. In one implementation, external systems <b>34</b> include law enforcement agencies <b>36</b>, postal authorities <b>38</b>, vehicle registration authorities <b>40</b>, insurance companies <b>42</b>, service providers <b>44</b>, financial systems <b>46</b> and a homeland security agency <b>48</b>. The external systems <b>34</b> can involve private or public organizations that span one or more geographic locations such as states, regions, countries, or other geographic locations.</p>
    <p num="p-0093">The toll management computer <b>12</b> can interface and exchange information with law enforcement agencies <b>36</b>. For example, as vehicles are identified, the computer can submit substantially real-time transactions to law enforcement systems, in formats defined by the law enforcement agencies. Transactions also can be submitted for vehicles carrying hazardous materials or violating traffic regulations (e.g. speeding, weight violations, missing plates), if the appropriate sensors are in place (e.g. laser/sonic/microwave detectors as described above, weight sensors, radiation detectors). Alternatively, vehicle records can be compiled and forwarded in batches, based on lists provided by law enforcement agencies.</p>
    <p num="p-0094">The highlighted vehicle identifier database <b>20</b> can be used to store the lists provided by the law enforcement agencies. The term “highlighted” refers to the notion that the law enforcement agencies have provided a list of vehicle identifiers that the agencies have indicated (highlighted) they wish the toll facility to monitor. For example, when a motor vehicle is stolen and reported to police, the police can send a list of highlighted vehicle identifiers to the database <b>20</b>. When the vehicle highlighted by the police travels through facility, the imaging processing module <b>24</b> determines a vehicle identifier associated with the vehicle and determines through certain interfaces that the particular vehicle is being sought by law enforcement. The law enforcement authorities may wish to be instantly notified of the location of the vehicle (and driver), the time it was detected at the location, and the direction it was headed. The computer <b>12</b> can notify in substantially real-time mobile units associated with law enforcement. In addition, law enforcement can automatically highlight vehicles based upon the expiration of a license, occurrence of a traffic court date, or other event. This could, in turn, help keep illegal drivers off the road and increase revenue to the state.</p>
    <p num="p-0095">The toll management computer <b>12</b> can interface and exchange information with postal authorities <b>38</b>. Since the disclosed techniques would require toll authorities to convert from receiving payment by drivers at the time of travel to receiving paying in arrears, it is important that bills be sent to the correct driver/vehicle owner. To minimize the possibility of sending the bill to the wrong person, the computer <b>12</b> supports address reconciliation. For example, before a bill is mailed, the computer <b>12</b> verifies that the address provided by a motor vehicle department matches the address provided by the postal authority. The motor vehicle database can then be updated with the most accurate address information related to the vehicle owner. Since this occurs before the bill is mailed, billing errors can be reduced.</p>
    <p num="p-0096">The toll management computer <b>12</b> can interface and exchange information with vehicle registration authorities <b>40</b>. The registration authorities <b>40</b> provide an interface to exchange information related to the owners of vehicles, the owners' addresses, characteristics of the vehicles, or other information. Alternatively, this information can be accessed through third-party data providers rather than through an interface to public motor vehicle records. The accuracy of records in the various databases used by the computer <b>12</b>, including vehicle ownership and owner addresses, may be verified periodically against third-party databases or government records, including motor vehicle records and address records. This may help ensure the quality of ownership and address records, and reduce billing errors and returned correspondence.</p>
    <p num="p-0097">The toll management computer <b>12</b> can interface and exchange information with insurance companies <b>42</b>. Insurance companies could highlight vehicle identifiers in a manner similar to law enforcement authorities <b>36</b>. For example, the highlighted vehicle identifiers database <b>20</b> can include license plate numbers of vehicles with an expired insurance indicating that such drives would be driving illegally. The computer could notify law enforcement as well as insurance companies whether the highlighted vehicle has been detected using a particular facility.</p>
    <p num="p-0098">The toll management computer <b>12</b> can interface and exchange service providers <b>44</b>. For example, the computer <b>12</b> can support batch or real-time interfaces for forwarding billing and payment collection functions to billing service providers or collection agencies.</p>
    <p num="p-0099">The toll management computer <b>12</b> can interface and exchange information with financial systems <b>46</b>. For example, to handle bill payment and collection, the computer <b>12</b> can interface to credit card processors, banks, and third-party electronic bill presentment systems. The computer <b>12</b> can also exchange information with accounting systems.</p>
    <p num="p-0100">The toll management computer <b>12</b> can interface and exchange information with the homeland security agency <b>48</b>. The office of homeland security can automatically provide a list of individuals for use in the highlighted vehicle identifier database <b>20</b>. For example, registered drivers that are on a visa to this country can be automatically highlighted when that visa expires. The computer <b>12</b> would then notify the office of homeland security <b>48</b> that the highlighted vehicle identifier associated with the person has been detected driving in the country including the time and location information about the vehicle.</p>
    <p num="p-0101">As described above, data captured from the toll site flows into the image database, and is retrieved from the image database by the billing engine. In another implementation, the toll computer detects, for each vehicle, an interaction between the vehicle and a toll facility, captures images and generates a data record. The data record can include date, time, and location of transaction, a reference to the image file, and any other data available from the sensors at the facility (e.g., speed, size). The image can be passed to the image-processing module <b>25</b>, which can generate a vehicle identifier, a state, and a confidence factor for each vehicle.</p>
    <p num="p-0102">This information can be added to the data record. (This process my occur after transmission to the central facility.) The data record and image file can be sent to the central facility. The image can be stored in the image database, and referenced if (a) additional processing is required to identify the vehicle, or (b) someone wishes to verify the transaction. If the confidence level is adequate, the data record can be submitted to the billing engine, which can associate it with an account and store it in the billing database for later billing. If no account exists, the vehicle identifier is submitted to the appropriate state registration authority or a third-party service provider to determine the owner and establish an account. This process may be delayed until enough transactions are collected for the vehicle to justify issuing a bill. If confidence level is not adequate, additional processing may be performed as described elsewhere.</p>
    <p num="p-0103">The techniques described above describe the flow of data based on a single transaction end-to-end, then looping back to the beginning. In another implementation, some of the functions described may be event-driven or scheduled, and may operate independently of one another. For example, there may be no flow of control from back-end processes to vehicle imaging. The imaging process may be initiated by an event, including the presence of a vehicle at the toll site.</p>
    <p num="p-0104">In another implementation, the system may be used to monitor traffic and manage incidents. For example, if a drop in average vehicle speed is detected, the computer can send a message to a highway control facility alerting controllers to the possibility of an incident. Authorized controllers may communicate with the equipment at the toll site to view images from the cameras and determine if a response is required.</p>
    <p num="p-0105">The operation of the toll management system <b>10</b> is explained with reference to <figref idrefs="DRAWINGS">FIGS. 2-5</figref>.</p>
    <p num="p-0106"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a flow chart of an implementation of electronic toll management system related, particularly a process <b>100</b> for managing highlighted vehicle identifiers <b>20</b> provided by external systems <b>34</b>. To illustrate, in one example, it is assumed that law enforcement agencies <b>36</b> generate a list of highlighted vehicle identifiers (e.g., license plate numbers) of drivers being sought by the agencies and that the agencies <b>36</b> wish to be notified when such vehicles have been identified using a toll facility <b>28</b>.</p>
    <p num="p-0107">The computer <b>12</b> obtains (block <b>102</b>) highlighted vehicle identifiers from a party such as law enforcement agencies <b>36</b>. In one implementation, these vehicle identifiers can be stored in the vehicle identifier database <b>20</b> for subsequent processing. The database <b>20</b> can be updated by the agencies with new as well as additional information in real-time and/or in batch mode. The law enforcement agencies accessed by the computer span across multiple jurisdictions such as cities, municipalities, states, regions, countries or other geographic designations. As a result, the computer <b>12</b> can process vehicle information across multiple jurisdictions and on a national scale.</p>
    <p num="p-0108">The computer <b>12</b> captures (block <b>104</b>) an image of a vehicle triggered by a transaction event based on an interaction between the vehicle <b>30</b> and the facility <b>28</b>. For example, the image acquisition module <b>24</b> can be used to acquire one or more images of a vehicle as it travels through a facility such as a toll road. These images can be stored in the image database <b>14</b> for further processing by the image-processing module <b>25</b>. Compression techniques can be applied to the captured images to help reduce the size of the database <b>14</b>.</p>
    <p num="p-0109">The computer <b>12</b> determines (block <b>106</b>) a vehicle identifier based on the captured image. For example, as discussed previously, the image-processing module <b>25</b> can apply image analysis techniques to the raw images in the image database <b>14</b>. These analysis techniques can extract a license number from one or more images of a license plate of the vehicle. The extracted vehicle identifiers can be stored in the vehicle identifier database <b>18</b> for further processing.</p>
    <p num="p-0110">The computer <b>12</b> compares (block <b>108</b>) a captured vehicle identifier with the highlighted vehicle identifier. For example, the computer <b>12</b> can compare a captured license plate number from the vehicle identifier database <b>18</b> with a license number from the highlighted vehicle identifier database <b>20</b>. As discussed above, automatic as well as manual techniques can be applied to check for a match.</p>
    <p num="p-0111">If the computer <b>12</b> detects a match (block <b>110</b>) between the license numbers, then it checks (block <b>112</b>) how the party associated with the highlighted vehicle identifiers wishes to be notified. This information can be stored in the vehicle identifier database <b>20</b> or other storage mechanism. On the other hand, if there is no match, the computer <b>12</b> resumes executing the process <b>100</b> beginning at block <b>102</b>.</p>
    <p num="p-0112">If the party indicates that it wishes to be notified immediately (block <b>114</b>), then the computer notifies (block <b>118</b>) the party upon the occurrence of a match. In this example, the computer can notify law enforcement of the match in substantially real-time using wireless communications techniques or over a computer network.</p>
    <p num="p-0113">On the other hand, if the party does not wish to be notified immediately (block <b>114</b>), then the computer <b>12</b> stores (block <b>116</b>) the match for later notification upon satisfaction of predefined criteria. In one implementation, predefined criteria can include gathering a predefined number of matches and then sending the matches to law enforcement in batch mode.</p>
    <p num="p-0114">Once the party has been notified (block <b>118</b>) of a match or the match has been stored for later notification (block <b>116</b>), the computer <b>12</b> resumes executing process <b>100</b> beginning at block <b>102</b>.</p>
    <p num="p-0115"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a flow chart of an implementation of electronic toll management system <b>10</b>, particularly a process <b>200</b> for managing payment from a party associated with a vehicle that has interacted with a facility. To illustrate, in one example, it is assumed that a toll road authority decides to employ the disclosed techniques to handle payment processing including billing and collecting tolls from vehicles using its toll road.</p>
    <p num="p-0116">The computer <b>12</b> captures (block <b>202</b>) an image of a vehicle triggered by a transaction event based on an interaction between the vehicle and a facility. This function is similar to the process discussed above in reference to block <b>104</b> of <figref idrefs="DRAWINGS">FIG. 2</figref>. For example, the image acquisition module <b>24</b> can be used to acquire one or more images of a vehicle <b>30</b> as it travels through the toll road <b>28</b>. These images can be stored in the image database <b>14</b> for further processing by the image-processing module <b>25</b>.</p>
    <p num="p-0117">The computer <b>12</b> determines (block <b>204</b>) a vehicle identifier based on the captured image. This function is also similar to the process discussed above in reference to block <b>106</b> of <figref idrefs="DRAWINGS">FIG. 2</figref>. For example, the image-processing module <b>25</b> can be used to extract a license number from one or more images of a license plate of the vehicle. These vehicle identifiers can be stored in the vehicle identifier database <b>18</b> for further processing.</p>
    <p num="p-0118">The computer <b>12</b> determines (block <b>206</b>) a party associated with the vehicle identifier by searching a registration authority databases. For example, the computer <b>12</b> can use the vehicle identifier from the vehicle identifier database <b>18</b> to search a database of a vehicle registration authority <b>40</b> to determine the registered owner of the vehicle associated with the vehicle identifier. The computer <b>12</b> is capable of accessing vehicle information from one or more vehicle registration databases across multiple jurisdictions such as cities, municipalities, states, regions, countries or other geographic locations. In one implementation, the computer <b>12</b> can maintain a copy of registration information from multiple registration authorities for subsequent processing. Alternatively, the computer <b>12</b> can access multiple registration authorities and obtain registration information on a demand basis. In either case, these techniques allow the computer <b>12</b> to process vehicle information across multiple jurisdictions, and thus process vehicles on a national scale.</p>
    <p num="p-0119">The computer <b>12</b> checks (block <b>208</b>) whether to request payment from the party associated with the vehicle identifier. The request for payment can depend on payment processing information associated with the registered owner. For example, the registered owner may be sent a bill based on a periodic basis (e.g., monthly basis), when a predefined amount has been reached, or other arrangement.</p>
    <p num="p-0120">If the computer <b>12</b> determines that payment is required (block <b>210</b>), then it requests (block <b>214</b>) payment from the party associated with the vehicle identifier based on the transaction event. As discussed above, a request for payment can be generated using traditional mail service techniques or electronic techniques such as electronic payment. The amount of the bill can depend on information from the transaction event such as the nature of the interaction between the vehicle and the facility. For example, the transaction event can indicate that the vehicle traveled a particular distance defined as a distance between a starting and ending point on the toll road. Accordingly, the amount of the payment requested from the registered owner can be based on the distance traveled.</p>
    <p num="p-0121">On the other hand, if the computer <b>12</b> determines that payment is not required (block <b>210</b>), then it forwards (block <b>212</b>) the transaction event to another party to handle the payment request. For example, the toll authority may have decided that the computer <b>12</b> can handle image processing functions and that toll billing and collection should be handled by a third party such as external systems <b>34</b>. In one implementation, the computer <b>12</b> can interface with service providers <b>44</b> and financial systems <b>48</b> to handle all or part of the billing and payment-processing functionality. Once the transaction event has been forwarded to a third party, the computer <b>12</b> resumes executing the functions of process <b>200</b> beginning at block <b>202</b>.</p>
    <p num="p-0122">If the computer handles payment processing, the computer <b>12</b> processes (block <b>216</b>) a payment response from the party associated with the vehicle identifier. In one implementation, the billing database <b>16</b>, in conjunction with the billing engine <b>22</b> and the customer management module <b>26</b>, can be used to handle billing and collection functions. As discussed above, the payment processing module <b>26</b> <i>c </i>can support electronic or manual payment processing depending on the remittance received. For example, the computer <b>12</b> can provide an account for handling electronic payment processing over a computer network such as the Internet. The computer can also handle traditional payment receipt such as a check.</p>
    <p num="p-0123">Once a payment has been processed (block <b>216</b>), the computer <b>12</b> resumes executing process <b>200</b> beginning at block <b>202</b>.</p>
    <p num="p-0124"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a flow chart of an implementation of electronic toll management system <b>10</b>, particularly process <b>300</b> for managing payment over a communications channel from a party associated with a vehicle that has interacted with a facility. To illustrate, assume a toll authority responsible for a toll road employs the disclosed techniques and that a registered owner wishes to efficiently and automatically make payments for using the toll road.</p>
    <p num="p-0125">The computer <b>12</b> provides (block <b>302</b>) an account for a party associated with the vehicle identifier. In one embodiment, the computer <b>12</b> in conjunction with the account management module <b>26</b> <i>a </i>can provide a website for customers to open an account for making electronic payment over a computer network such as the Internet. The website also can permit the customer to access and update account information such as payment history, payment amount due, preferred payment method, or other information.</p>
    <p num="p-0126">The computer <b>12</b> receives (block <b>304</b>) a request over a communications channel from the party to review a transaction event. For example, the account payment module <b>26</b> <i>a </i>can handle this request by retrieving transaction event information associated with the customer's account from the billing database <b>16</b>. The retrieved information can include image data of a particular transaction involving the customer's vehicle and the tollbooth.</p>
    <p num="p-0127">The computer <b>12</b> sends (block <b>306</b>) the transaction event to the party <b>32</b> over the communications channel. Information related to the transaction event can include images of the vehicle and the vehicle identifier (i.e., license plate). Such data can be encrypted to permit secure transmission over the Internet. Standard communications protocols such as hypertext markup language (HTML) can be used to transmit the information over the Internet.</p>
    <p num="p-0128">The computer <b>12</b> determines (block <b>308</b>) whether the party agrees to make payment. For example, once the customer receives the information related to the transaction event, the customer can review the information to determine whether to make payment based on whether the vehicle shown in the images is the customer's vehicle.</p>
    <p num="p-0129">If the computer <b>12</b> determines (block <b>310</b>) that the party agrees to pay, then it processes (block <b>314</b>) payment from the party by deducting an amount from the account based on the transaction event. For example, if the image information indicates that the transaction event data is accurate, then the customer can authorize payment such as by submitting an electronic payment transaction.</p>
    <p num="p-0130">On the other hand, if the computer <b>12</b> determines (block <b>310</b>) that the party does not agrees to pay, then the computer <b>12</b> processes (block <b>312</b>) a payment dispute request from the party. In one implementation, the dispute management module <b>26</b> <i>b </i>can handle a dispute request submitted by the customer using online techniques. The module <b>26</b> <i>b </i>can handle specific transactions related to the customer's account including involving a third party to resolve the dispute.</p>
    <p num="p-0131">Once a payment has been processed (block <b>314</b>) or a dispute resolved (block <b>312</b>), the computer <b>12</b> resumes executing process <b>300</b> beginning at block <b>304</b>.</p>
    <p num="p-0132"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a flow chart of an implementation of electronic toll management system, particularly a process <b>400</b> for reconciling mailing addresses from different sources. To illustrate, it is assumed that a toll authority has decided to employ the disclosed techniques for processing payment related to the use of toll facility. Since the disclosed techniques involve processing payment some time after the vehicle has traveled through the toll authority, these techniques help ensure that payment is sent to the correct address of the registered owner of the vehicle.</p>
    <p num="p-0133">The computer <b>12</b> determines (block <b>402</b>) that a payment request is to be sent to a party associated with a vehicle identifier. As explained above, for example, payment requests may be generated based on a periodic basis or on an amount threshold basis.</p>
    <p num="p-0134">The computer <b>12</b> accesses (block <b>404</b>) a vehicle registration authority for a mailing address of a party associated with the vehicle identifier. For example, the computer <b>12</b> may access one or more databases associated with vehicle registration authorities <b>40</b> to retrieve information such as the mailing address of the registered owner of the vehicle.</p>
    <p num="p-0135">The computer <b>12</b> accesses (block <b>406</b>) a postal authority for a mailing address of the party associated with the vehicle identifier. For example, the computer <b>12</b> may access one or more databases associated with postal authorities <b>38</b> to retrieve information such as the mailing address of the registered owner of the vehicle.</p>
    <p num="p-0136">The computer <b>12</b> compares (block <b>408</b>) the mailing address from the vehicle registration authority with the mailing address from the postal authority. For example, the computer compares the mailing addresses from the two authorities to determine if there is a discrepancy between the database information.</p>
    <p num="p-0137">If the computer <b>12</b> determines (block <b>410</b>) that the addresses match, then it requests (block <b>414</b>) payment from the party associated with the vehicle identifier using the mailing address accessed from the postal authority. For example, the computer <b>12</b> can use the techniques discussed above to handle payment processing including billing and collecting payment from the registered owner.</p>
    <p num="p-0138">On the other hand, if the computer <b>12</b> determines (block <b>410</b>) that the addresses do not match, it then updates (block <b>412</b>) the vehicle registration authority with the mailing address from the postal authority. For example, the computer <b>12</b> can update databases associated with vehicle registration authorities <b>40</b> with the correct mailing address retrieved from the postal authorities <b>38</b>. Such techniques may help reduce the likelihood of mailing a bill to an incorrect mailing address resulting in an reducing time for payment remittance.</p>
    <p num="p-0139">Once the vehicle registration authority has been updated (block <b>412</b>) or payment requested (block <b>414</b>), the computer <b>12</b> executes process <b>400</b> beginning at block <b>402</b> as explained above.</p>
    <p num="p-0140"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a block diagram of an implementation of an electronic toll management system <b>600</b> that provides vehicle identification by extracting multiple vehicle identifiers for each vehicle that interacts with the toll facility. The toll management system <b>600</b> includes a toll management computer <b>612</b>. The toll management computer includes an image database <b>614</b>, a billing database <b>616</b>, a vehicle identification database <b>618</b>, a highlighted vehicle identifier database <b>620</b>, a billing engine <b>622</b>, an image acquisition module <b>624</b>, an image processing module <b>625</b>, and a customer management module <b>626</b>. The toll management computer <b>612</b> communicates with or is integrated with a toll facility <b>628</b>, which interacts with a vehicle <b>630</b> and a party associated with the vehicle <b>632</b>. The toll management computer <b>612</b> also communicates with external systems <b>634</b>.</p>
    <p num="p-0141">Examples of each element within the toll management system <b>600</b> of <figref idrefs="DRAWINGS">FIG. 6</figref> are described broadly above with respect to <figref idrefs="DRAWINGS">FIG. 1</figref>. In particular, the toll management computer <b>612</b>, the image database <b>614</b>, the billing database <b>616</b>, the vehicle identification database <b>618</b>, the highlighted vehicle identifier database <b>620</b>, the billing engine <b>622</b>, the image acquisition module <b>624</b>, the image processing module <b>625</b>, the customer management module <b>626</b>, and the toll facility <b>628</b> typically have attributes comparable to and illustrate one possible implementation of the toll management computer <b>12</b>, the image database <b>14</b>, the billing database <b>16</b>, the vehicle identification database <b>18</b>, the highlighted vehicle identifier database <b>20</b>, the billing engine <b>22</b>, the image acquisition module <b>24</b>, the image processing module <b>25</b>, the customer management module <b>26</b>, and the toll facility <b>28</b> of <figref idrefs="DRAWINGS">FIG. 1</figref>, respectively. Likewise, the vehicle <b>630</b>, the party associated with the vehicle <b>632</b>, and the external systems <b>634</b> typically have attributes comparable to the vehicle <b>30</b>, the party associated with the vehicle <b>32</b>, and the external systems <b>34</b> of <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
    <p num="p-0142">The vehicle identification database <b>618</b> includes an extracted identifier database <b>6181</b>, a vehicle record database <b>6182</b>, and a read errors database <b>6183</b>. The functions of the databases <b>6181</b>-<b>6183</b> are described in more detail below.</p>
    <p num="p-0143">The system <b>600</b> is similar to system <b>10</b> and is configured to provide, for example, reduced vehicle identification error rates by identifying each vehicle through use of multiple vehicle identifiers. Two such identifiers are designated as <b>631</b>A and <b>631</b>B. A vehicle identifier is preferably an identifier that uniquely or substantially uniquely identifies the vehicle but may be an identifier that helps in the identification process by distinguishing the vehicle from other vehicles without necessarily uniquely identifying the vehicle. Identifiers <b>631</b>A and <b>631</b>B may be part of vehicle <b>630</b>, as suggested by <figref idrefs="DRAWINGS">FIG. 6</figref>, but need not be. For example, identifiers <b>631</b>A and/or <b>631</b>B may be produced by image processing module <b>625</b> based on characteristics of the vehicle <b>630</b>.</p>
    <p num="p-0144">As described previously, one example of a vehicle identifier is license plate information of a vehicle, such as a license plate number and state. The image processing module <b>625</b> may determine the license plate information of a vehicle from an image of the license plate by using OCR, template matching, and other analysis techniques. A license plate number may include any character but is typically restricted to alphanumeric characters. License plate information typically may be used to uniquely identify the vehicle.</p>
    <p num="p-0145">Another example of a vehicle identifier is a vehicle detection tag as described in U.S. Pat. No. 6,747,687, hereby incorporated by reference in its entirety for all purposes. The vehicle detection tag, hereinafter referred to as a vehicle fingerprint, is a distilled set of data artifacts that represent the visual signature of the vehicle. The image processing module <b>625</b> may generate a vehicle fingerprint by processing an image of the vehicle. To save on processing time and storage needs however, the generated vehicle fingerprint typically does not include the normal “picture” information that a human would recognize. Accordingly, it is usually not possible process the vehicle fingerprint to obtain the original vehicle image. Some vehicle fingerprints, however, may include normal picture information. A vehicle fingerprint typically may be used to uniquely identify the vehicle.</p>
    <p num="p-0146">In one implementation, a camera in the image acquisition module <b>624</b> captures a single “still” image of the back of each vehicle that passes the toll facility <b>628</b>. For each vehicle, the image processing module <b>625</b> recognizes the visual cues that are unique to the vehicle and reduces them into a vehicle fingerprint. Because a license plate is a very unique feature, the image processing module <b>625</b> typically maximizes the use of the license plate in creating the vehicle fingerprint. Notably, the vehicle fingerprint also includes other parts of the vehicle in addition to the license plate and, therefore, vehicle identification through matching of vehicle fingerprints is generally considered more accurate than vehicle identification through license plate information matching. The vehicle fingerprint may include, for example, portions of the vehicle around the license plate and/or parts of the bumper and the wheelbase.</p>
    <p num="p-0147">Another example of a vehicle identifier is a vehicle signature generated using a laser scan (hereinafter referred to as a laser signature). The laser signature information that may be captured using a laser scan may include one or more of an overhead electronic profile of the vehicle, including the length, width, and height of the vehicle, an axle count of the vehicle, and a 3D image of the vehicle. In one implementation, the image acquisition module <b>624</b> includes two lasers for a given lane, one that is mounted over the lane and another that is mounted alongside of the lane. The laser mounted above the lane typically scans the vehicle to capture the overhead profile of the vehicle, and the laser mounted alongside or above of the lane typically scans the vehicle to capture the axle count of the vehicle. Together, both lasers are also able to generate a 3D image of the vehicle. A laser signature may be used to uniquely identify some vehicles. For example, vehicles that have been modified to have a distinctive shape may be uniquely identified by a laser signature.</p>
    <p num="p-0148">Another example of a vehicle identifier is a vehicle signature generated using a magnetic scan (hereinafter referred to as an inductive signature). The inductive signature of a vehicle is a parameter that reflects the metal distribution across the vehicle and, therefore, may be used to classify the vehicle and, in some circumstances, to uniquely identify the vehicle (e.g., if the metal distribution of a particular vehicle is unique to that vehicle because of unique modifications to that vehicle). The inductive signature may include information that may be used to determine one or more of the axle count (and likely the number of tires) of the vehicle, the type of engine used in the vehicle, and the type or class of vehicle. In one implementation, the image acquisition module <b>624</b> includes a pair of vehicle detection loops, an axle detection loop, and a camera trigger loop in each lane.</p>
    <p num="p-0149">Once the two or more vehicle identifiers are extracted by the image processing module <b>625</b>, the image processing module <b>625</b> stores the extracted vehicle identifiers in the extracted vehicle identifier database <b>6181</b>. Ideally, the computer <b>612</b> would then be able to uniquely identify the owner of the vehicle by choosing a vehicle identifier that uniquely identifies the vehicle (e.g., license plate information or vehicle fingerprint) and searching one or more internal or external vehicle record databases for a record containing a matching vehicle identifier. Unfortunately, extracting a vehicle identifier is an imperfect process. The extracted vehicle identifier may not correspond to the actual vehicle identifier, and therefore, may not uniquely identify the vehicle. An incorrectly or partially extracted vehicle identifier may not match the vehicle identifier of any vehicle, may match the vehicle identifier of the wrong vehicle, or may match the vehicle identifiers of more than one vehicle. To increase identification accuracy, the computer <b>612</b> of the system <b>600</b> implements a multi-tier identification process using two or more vehicle identifiers.</p>
    <p num="p-0150"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a flow chart of an exemplary two-tier identification process <b>700</b> that may be implemented to increase the accuracy of vehicle identification. Image and/or sensor data is captured for a vehicle that interacts with a toll facility (hereinafter referred to as the “target vehicle”) and two vehicle identifiers are extracted from the captured data (block <b>710</b>). In one implementation, only image data is collected and the two vehicle identifiers extracted are a license plate number and a vehicle fingerprint. In another implementation, image data and inductive sensor data are collected and the vehicle identifiers extracted are the vehicle fingerprint and the inductive signature.</p>
    <p num="p-0151">One of the two extracted vehicle identifiers is designated as the first vehicle identifier and used to identify a set of one or more matching vehicle candidates (block <b>720</b>). Typically, the vehicle identifier that is deemed to be the least able to accurately and/or uniquely identify the target vehicle is designated as the first vehicle identifier. For example, if the two extracted vehicle identifiers were license plate number and vehicle fingerprint, the license plate number would be designated as the first vehicle identifier because of the lower expected accuracy of vehicle identification through license plate matching as compared to fingerprint matching. The one or more matching vehicle candidates may be determined, for example, by accessing a vehicle record database and finding records that contain vehicle identifiers that match or nearly match the first vehicle identifier.</p>
    <p num="p-0152">Once the set of one or more matching vehicle candidates is determined, the target vehicle is identified from the set based on the second vehicle identifier (block <b>730</b>). For example, if 12 vehicle candidates were identified as matching a partially extracted license plate number, the target vehicle is identified by accessing the vehicle fingerprints for each of the 12 vehicle candidates and determining which of the 12 vehicle fingerprints matches the extracted vehicle fingerprint. If no match is found within a predetermined confidence threshold, manual identification of the vehicle may be used. In another implementation, one or more larger sets (e.g., supersets) of matching vehicle candidates are determined successively or concurrently by changing (e.g., loosening) the criteria for matching and additional attempts are made to identify the target vehicle from each of the one or more larger sets prior to resorting to manual identification.</p>
    <p num="p-0153">In some implementations, the toll management system may be purposefully designed to identify a larger set of matching vehicle candidates during operation <b>720</b> to, for example, ensure that the expected lesser accuracy of vehicle identification through the first identifier does not erroneously result in exclusion of the target vehicle from the set of matching vehicle candidates. For example, if the first vehicle identifier is a license plate number, the license plate reading algorithm may be intentionally modified in, for example, two ways: (1) the matching criteria of the license plate reading algorithm may be loosened to enable the algorithm to generate a larger set of matching vehicle candidates and (2) the license plate reading algorithm may be “detuned” by lowering the read confidence threshold used to determine whether a read result is included in the matching candidate set. For instance, the license plate reading algorithm may be loosened to only require a matching vehicle candidate to match a subset or lesser number of the characters in the license plate number extracted for the target vehicle. Additionally or alternatively, the read confidence threshold may be lowered to enable previously suspected incorrect reads (i.e., partial or low confidence reads) to be included in the matching vehicle candidate set.</p>
    <p num="p-0154">The two-tier identification process <b>700</b> provides greater identification accuracy over a single-tier/single identifier identification system by requiring that two vehicle identifiers be successfully matched for successful vehicle identification. Moreover, the process <b>700</b> may provide greater identification speed by limiting the matching of the second vehicle identifier to only those vehicle candidates having records that successfully match the first vehicle identifier. This can provide increased speed if, for example, the extracted second vehicle identifier is time-consuming to match against other such identifiers or if a large number of other such identifiers exists (e.g., millions of identifiers for millions of vehicles in a vehicle database).</p>
    <p num="p-0155">In another implementation, two or more second identifiers are used to identify the target vehicle from among the set of matching vehicle candidates. Each of the second identifiers must match the same candidate vehicle to within a predetermined confidence level for successful vehicle identification. Alternatively, the degree of matching of each of the two or more second identifiers may be weighted and a combined equivalent matching score may be generated. If the combined equivalent matching score is above a predetermined threshold, the identification is deemed successful.</p>
    <p num="p-0156">In one implementation, each second vehicle identifier is assigned a match confidence level number that ranges from 1 to 10, where 1 corresponds to no match and 10 corresponds to an exact match. Each vehicle identifier is also assigned a weight value from 1 to 10, with greater weight values being assigned to vehicle identifiers that are considered more accurate in uniquely identifying vehicles. If, for example, the second vehicle identifiers are a laser signature and license plate information, a weighting of 6 may be assigned to the laser signature and a greater weighting of 9 may be assigned to the license plate information. If a combined equivalent matching score of 100 is necessary for an identification to be deemed successful and the license plate information matches to a confidence level of 7 and the laser signature also matches to a confidence level of 7, the combined equivalent matching score would be 7*6+7*9=105 and the identification would be considered successful.</p>
    <p num="p-0157">In another implementation, two or more first vehicle identifiers are used to identify vehicles in the set of matching vehicle candidates. Each of the first vehicle identifiers for a possible candidate vehicle must match the target vehicle to within a predetermined confidence level for the possible candidate vehicle to be included in the set of matching vehicle candidates. Alternatively, the degree of matching of each of the two or more first identifiers may be weighted and a combined equivalent matching score may be generated. If the combined equivalent matching score is above a predetermined threshold, the possible candidate vehicle is included in the set of matching vehicle candidates.</p>
    <p num="p-0158">In another implementation, the second identifier is not used to uniquely identify the target vehicle from among the vehicles in the set of matching vehicle candidates. Rather, the second identifier is used to generate a new and smaller set of matching vehicle candidates as a subset of the set determined using the first identifier, and a third identifier is then used to uniquely identify the target vehicle from this subset of matching vehicle candidates. In yet another implementation, multiple vehicle identifiers are used to successively reduce the set of matching vehicle candidates and the target vehicle is uniquely identified from the successively reduced subset through use of one or more final vehicle identifiers. In yet another implementation, each of the multiple vehicle identifiers is used to generate its own set of matching vehicle candidates through matching and near matching techniques and the reduced set is the intersection of all of the determined sets. In yet another implementation, the reduced set is determined using a combination of the above-described techniques.</p>
    <p num="p-0159"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a flow chart of an exemplary two-tier identification process <b>800</b> that may be implemented to increase the accuracy and/or automation of vehicle identification. Process <b>800</b> is an implementation of process <b>700</b> wherein the first identifier is a license plate number and the second identifier is a vehicle fingerprint. In particular, process <b>800</b> includes operations <b>810</b>-<b>830</b>, and associated sub-operations, that correspond to and illustrate one possible implementation of operations <b>710</b>-<b>730</b>, respectively. For convenience, particular components described with respect to <figref idrefs="DRAWINGS">FIG. 6</figref> are referenced as performing the process <b>800</b>. However, similar methodologies may be applied in other implementations where different components are used to define the structure of the system, or where the functionality is distributed differently among the components shown by <figref idrefs="DRAWINGS">FIG. 6</figref>.</p>
    <p num="p-0160">The image acquisition module <b>624</b> captures image data for the target vehicle based on an interaction between the target vehicle and the toll facility <b>628</b> (block <b>812</b>). In another implementation, the image acquisition module <b>624</b> additionally or alternatively captures sensor data including, for example, laser scanning and/or loop sensor data. The image processing module <b>625</b> obtains license plate data, including, for example, a complete or partial license plate number and state, for the target vehicle from the captured image data (block <b>814</b>). Optionally, the image processing module <b>625</b> also may determine a vehicle fingerprint for the target vehicle from the image data. In another implementation, the image processing module <b>625</b> may determine other vehicle signature data, such as, for example, laser and/or inductive signature data, from the image data and/or sensor data.</p>
    <p num="p-0161">The computer <b>612</b> stores the captured image data in the image database <b>614</b> and stores the extracted license plate data in the extracted identifier database <b>6181</b>. If applicable, the toll management computer <b>612</b> also stores the extracted vehicle fingerprint and other signature data, such as, for example, the inductive signature and/or laser signature, in the extracted identifier database <b>6181</b>.</p>
    <p num="p-0162">The computer <b>612</b> accesses a set of vehicle identification records from the vehicle record database <b>6182</b> (block <b>822</b>). Each of the vehicle identification records associates an owner/driver of a vehicle with vehicle identifier data. The computer <b>612</b> compares the extracted license plate data with the license plate data in the set of vehicle identification records (block <b>824</b>) and identifies a set of candidate vehicles from the vehicles having records in the set of records (block <b>826</b>). The comparison may be done using matching or near matching techniques.</p>
    <p num="p-0163">The computer <b>612</b> accesses extracted vehicle fingerprint data for the target vehicle (block <b>832</b>). If the vehicle fingerprint has not already been determined/extracted from the captured image data, the computer <b>612</b> calculates the vehicle fingerprint and stores the vehicle fingerprint in the extracted vehicle identifier database <b>6181</b>.</p>
    <p num="p-0164">The computer <b>612</b> accesses vehicle fingerprint data for a vehicle in the set of candidate vehicles by accessing the corresponding vehicle identification record (block <b>834</b>) and compares the vehicle fingerprint data for the target vehicle to the vehicle fingerprint data for the candidate vehicle (block <b>836</b>). The computer <b>612</b> identifies the candidate vehicle as the target vehicle based on the results of the comparison of the vehicle fingerprint data (block <b>838</b>). If the vehicle fingerprint data matches within a predetermined confidence threshold, the candidate vehicle is deemed to be the target vehicle, and the owner/driver of the candidate vehicle is deemed to be the owner/driver of the target vehicle.</p>
    <p num="p-0165"> <figref idrefs="DRAWINGS">FIGS. 9A-9C</figref> are a flow chart of an exemplary two-tier identification process <b>900</b> that may be implemented to increase the accuracy of vehicle identification while minimizing the need for manual identification of vehicles. Process <b>900</b> is another implementation of process <b>700</b> wherein the first identifier is a license plate number and the second identifier is a vehicle fingerprint. In particular, process <b>900</b> includes operations <b>910</b>-<b>930</b>, and associated sub-operations, that correspond to and illustrate one possible implementation of operations <b>710</b>-<b>730</b>, respectively. For convenience, particular components described with respect to <figref idrefs="DRAWINGS">FIG. 6</figref> are referenced as performing the process <b>800</b>. However, similar methodologies may be applied in other implementations where different components are used to define the structure of the system, or where the functionality is distributed differently among the components shown by <figref idrefs="DRAWINGS">FIG. 6</figref>.</p>
    <p num="p-0166">The image acquisition module <b>624</b> captures image and sensor data for the target vehicle (block <b>911</b>). Roadside sensors, for example, trigger cameras that capture front and rear images of the target vehicle. Other sensors may capture additional data used for classification/identification of the vehicle. For example, a laser scan may be used to determine laser signature data including the height, width, length, axle count, and vehicle dimensional profile. Sensors also may be used to determine data related to the transaction between the target vehicle and the toll facility <b>628</b> such as, for example, the weight of the vehicle, the speed of the vehicle, and transponder data associated with the vehicle.</p>
    <p num="p-0167">The image processing module <b>625</b> performs a license plate read on the captured image data, creates a vehicle fingerprint from the captured image data, and optionally determines other vehicle signature/classification data from the captured sensor data (block <b>912</b>). For example, the image processing module <b>625</b> may use an automated license plate read algorithm to read one or more of the captured images. The license plate read algorithm may read the captured images, for example, in a prioritized order based on visibility of the plate and its location in the image. The license plate read results may include one or more of a license plate number, a license plate state, a license plate style, a read confidence score, a plate location in the image, and a plate size. The image processing module <b>625</b> also may apply a visual signature extraction algorithm to generate the vehicle fingerprint for the target vehicle. The visual signature extraction algorithm may be similar to that developed by JAI-PULNiX Inc. of San Jose, Calif. and described in U.S. Pat. No. 6,747,687. The computer <b>612</b> stores the captured images in the image database <b>614</b> and stores the license plate read results, vehicle fingerprint, and other vehicle signature/classification data in the extracted vehicle identifier database <b>6181</b>.</p>
    <p num="p-0168">The image processing module <b>625</b> determines whether the captured images have provided any partial or complete read results for the license plate number and state of the target vehicle (block <b>913</b>). If no partial or complete read results were provided by the captured images, process <b>900</b> proceeds to operation <b>941</b> of the manual identification process <b>940</b>.</p>
    <p num="p-0169">If partial or complete read results for the license plate number and state of the target vehicle were provided by the captured images, computer <b>612</b> searches the vehicle record database <b>6182</b> and read errors database <b>6183</b> for the exact (either partial or complete) license plate number (as read by the license plate reader) (block <b>921</b>).</p>
    <p num="p-0170">The vehicle record database <b>6182</b> includes records for all vehicles previously recognized and potentially includes records for vehicles that are anticipated to be seen. The vehicle record database <b>6182</b> is typically populated through a registration process during which a driver/owner of a vehicle signs the vehicle up for automated toll payment handling. The driver/owner of a vehicle may sign a vehicle up for automated toll payment handling by driving the vehicle through a special registration lane in the toll facility <b>628</b> and providing a customer service representative at the facility <b>628</b> with his or her identity and other contact information. The image acquisition module <b>624</b> and the image processing module <b>625</b> capture the license plate number, the fingerprint, and other identification/classification data (e.g., the vehicle dimensions) of the user's vehicle while the vehicle traverses the facility <b>628</b>. The vehicle and owner identification data is stored in a new vehicle identification record associated with the newly registered vehicle and owner/driver.</p>
    <p num="p-0171">Alternatively, a driver/owner may register a vehicle for automatic toll payment handling by simply driving through the facility <b>628</b>, without stopping. The computer <b>612</b> captures image data and sensor data for the vehicle and attempts to identify the driver/owner by reading the license plate image and looking up the read results in a database of an external system <b>634</b> (e.g., vehicle registration authorities). If an owner/driver is identified, the computer <b>612</b> bills the owner/driver. Once a billing relationship has been successfully setup, the computer <b>612</b> officially registers the vehicle, generates as necessary the vehicle fingerprint data and other signature/classification data from the captured image and sensor data, and stores these in a vehicle identification record associated with the identified owner/driver.</p>
    <p num="p-0172">In another implementation, the computer <b>612</b> is configured to obtain greater accuracy in identifying an unregistered driver/owner by looking up the license plate read results in a database of a vehicle registration authority (or other external system) and requesting a corresponding vehicle identification number (VIN) from the vehicle registration authority (or other external system). The computer <b>612</b> uses the VIN to determine the make, model, and year of the vehicle. The make, model, and year of the vehicle may be used to determine the length, width, and height of the vehicle. The computer <b>612</b> may then determine a successful match of the target vehicle with a vehicle registered with the vehicle registration authority not only by comparing license plate data but also by comparing vehicle dimensions (as captured, for example, in a laser signature and/or an inductive signature). Typically, the computer <b>612</b> will consider a match successful if the license plate read results for the target vehicle match the license plate data for the vehicle registered with the vehicle registration authority to within a predetermined threshold and the vehicle dimensions of both vehicles match within a given tolerance.</p>
    <p num="p-0173">The make, model, and year of a vehicle may be used, for example, to determine the length, width, and height of the vehicle by either accessing this information from a public database or from a 3<sup>rd </sup>party database or, additionally or alternatively, by accessing the vehicle records database <b>6182</b> to retrieve the length, width, and height data from one or more vehicle identification records corresponding to vehicles having the same make, model, and year as the target vehicle. Given that a vehicle's dimensions may change if the vehicle has been modified, the length, width, and height accessed from the vehicle identification records may vary by vehicle. Accordingly, the computer <b>612</b> may need to statistically determine the appropriate dimensions for comparison by, for example, taking the average or median length, width, and height dimensions.</p>
    <p num="p-0174">In one implementation, the computer <b>612</b> identifies a vehicle in part through use of an electronic signature that includes a laser signature and/or an inductive (i.e., magnetic) signature. When a vehicle transacts with the toll system, an electronic signature is captured for the vehicle. The image and measurements of the vehicle created by the laser (i.e., the laser signature) and/or the magnetic scan (i.e., the inductive signature) are compared against known dimensions and images of vehicles based on vehicle identification number (VIN) that were, for example, previously captured by the toll system or by an external system. By comparing the electronic signature image and dimensions to known dimensions of vehicles based on VIN, the search for a matching vehicle and associated VIN may be narrowed. If, for example, an LPR for the vehicle has a low confidence level, but the electronic signature of the vehicle has been captured, the toll system may access a database, as described above, of known dimensions and images for vehicles and associated VINs and cross reference the electronic signature dimensions and images against the database to identify the matching vehicle VIN or identify potential matching vehicle candidates/VINs. The read errors database <b>6183</b> links previous incorrect read results to correct vehicle identification records. For example, when automated vehicle identification fails but manual vehicle identification succeeds, the captured vehicle identification data (e.g., the license plate read result) that led to an “error” (i.e., an identification failure) by the automated system is stored in an error record in the read errors database <b>6183</b> that is linked to the vehicle identification record that was manually identified for the vehicle. Thus, when the same vehicle identification data is captured again at a later date, the computer <b>612</b> may successfully identify the vehicle automatically by accessing the error record in the read errors database <b>6183</b>, which identifies the correct vehicle identification record for the vehicle, without requiring another manual identification of the vehicle.</p>
    <p num="p-0175">An error record also may be generated and stored in the read errors database <b>6183</b> when automated identification of the vehicle succeeds based on a near match of an incorrect license plate read result. For example, if the license plate number “ABC123” is read as “ABC128” and the identified candidate match set is “ABC128,” “ABC123,” “ABG128” and “ABC128” which in turn yields the correct match of “ABC123,” an error record may be created that automatically links a license plate read result of “ABC128” to the vehicle having the license plate number “ABC123.”</p>
    <p num="p-0176">The computer <b>612</b> determines whether any vehicle identification records correspond to the license plate read results for the target vehicle (block <b>922</b>). If no vehicle identification records correspond to the read results, the computer <b>612</b> performs an extended search (block <b>923</b>).</p>
    <p num="p-0177">The computer <b>612</b> performs an extended search by changing or loosening the criteria for a successful match or detuning the license plate read algorithm. For example, the computer <b>612</b> may perform an extended search by one or more of the following: (1) comparing a subset of the license plate number read result with the characters of the license plate numbers stored in the vehicle record database <b>6182</b> (e.g., the last two characters of the license plate number may be omitted such that if the license plate number is “ABC123,” any vehicles having license plate numbers “ABC1**” are deemed matching candidates, wherein “*” is a variable); (2) comparing a subset of the license plate number read result in reverse order with the characters of the license plate numbers stored in the vehicle record database <b>6182</b> in reverse order (e.g., the last two characters of the license plate number in reverse order may be omitted such that if the license plate number is “ABC123”, which is “321CBA” in reverse order, any vehicles having license plate numbers in reverse order of “321C**” are deemed matching candidates, wherein “*” is a variable); and (3) other near match techniques including comparing modified versions of the license plate read result and license plate numbers stored in the vehicle record database <b>6182</b> in which some of either or both are substituted and/or removed to reduce the impact of misread characters. For example, if the OCR algorithm does not indicate a confidence level above a predetermined threshold in a read result of a character on the license plate, that character may be ignored. Additionally or alternatively, if the OCR algorithm indicates that a character on the license plate may be one of two possible different characters, both alternative characters may be used in the extended search.</p>
    <p num="p-0178">The computer <b>612</b> determines whether any vehicle identification records correspond to the read results for the target vehicle after performing the extended search (block <b>924</b>). If no vehicle identification records are found, process <b>900</b> proceeds to operation <b>941</b> of the manual identification process <b>940</b> (block <b>924</b>).</p>
    <p num="p-0179">Referring to <figref idrefs="DRAWINGS">FIG. 9B</figref>, if either the search or the extended search lead to identification of one or more vehicle identification records, the computer <b>612</b> retrieves vehicle fingerprint and optionally other vehicle signature/classification data from the identified vehicle identification records (block <b>931</b>). The computer <b>612</b> compares the retrieved vehicle fingerprint and optionally other vehicle signature/classification data for each matching vehicle candidate with the corresponding data associated with the target vehicle to identify one or more possible matches (block <b>932</b>). The vehicle fingerprint comparison may be performed with a comparison algorithm identical or similar to the one developed by JAI-PULNiX Inc. of San Jose, Calif. and described in U.S. Pat. No. 6,747,687.</p>
    <p num="p-0180">A possible match may be defined, for example, as a vehicle fingerprint match with a confidence score greater than or equal to a predefined threshold and all or some of the other classification/signature data falling within tolerances defined for each data type. For example, if the fingerprint matching algorithm generates a score of 1 to 1000, where 1 is no match and 1000 is a perfect match, then a score greater than or equal to 900 may be required for a successful match. Additionally, if the other classification/signature data includes target vehicle height, width, and length, then the height, width, and length of the vehicle candidate may be required to be within plus or minus four inches of the extracted height, width, and length of the target vehicle for a successful match. One or more vehicle identification records may be deemed to correspond to vehicles that possibly match the target vehicle.</p>
    <p num="p-0181">The computer <b>612</b> determines whether a possible match is sufficient to automatically identify the vehicle without human intervention by determining a combined equivalent matching score for each possible match and comparing the result to a predetermined automated confidence threshold (block <b>933</b>). The computer <b>612</b> may, for example, determine a combined equivalent matching score for each possible match in a manner similar to that described previously with respect to process <b>700</b>. Specifically, the computer <b>612</b> may assign a match confidence level number to the fingerprint matching and, optionally, to the classification/signature data matching, assign a weight to each data type, and calculate a combined equivalent matching score by combining the weighted match confidence level numbers. If the combined equivalent matching score exceeds a predetermined automated confidence threshold, the computer <b>612</b> deems the target vehicle successfully identified and process <b>900</b> proceeds to operation <b>937</b> for recording the transaction event between the identified vehicle and the facility <b>628</b>. If more than one possible match exceeds the automated confidence threshold, the automated identification process may be faulty, and process <b>900</b> may optionally proceed (not shown) to operation <b>941</b> of the manual identification process <b>940</b>.</p>
    <p num="p-0182">If no possible match is deemed sufficient to automatically identify the vehicle without human intervention, the computer <b>612</b> determines whether one or more possible matches satisfy a lower probable match threshold (block <b>934</b>). The computer <b>612</b> may, for example, determine that a possible match satisfies the probable match threshold if the combined equivalent matching score of the possible match is higher than the probable match threshold but lower than the automated confidence threshold.</p>
    <p num="p-0183">If at least one possible match satisfies the probable match threshold, the computer <b>612</b> enables an operator to perform visual match truthing (block <b>935</b>). Visual match truthing is a process in which the computer <b>612</b> presents one or more of the images of the target vehicle to the operator along with one or more of the reference images associated with the vehicle or vehicles that probably match the target vehicle. The operator quickly confirms or rejects each probable match with a simple yes or no indication by, for example, selecting the appropriate buttons on a user interface (block <b>936</b>). The operator also may optionally provide a detailed explanation to support his or her response.</p>
    <p num="p-0184">If the match exceeds the automated confidence threshold or is visually confirmed by the operator through visual match truthing, the computer <b>612</b> creates a record of the event (i.e., a record of the interaction between the positively identified target vehicle and the facility <b>628</b>) as, for example, a billable or non-revenue transaction (block <b>937</b>). If the match was confirmed through visual match truthing, the computer <b>612</b> may optionally update the read errors database <b>6183</b> to include the extracted vehicle identification data and a link that associates the extracted vehicle identification data with the correct vehicle identification record (block <b>938</b>).</p>
    <p num="p-0185">Referring also to <figref idrefs="DRAWINGS">FIG. 9C</figref>, the computer <b>612</b> is configured to enable an operator to manually identify the target vehicle (block <b>941</b>) under the following circumstances: (1) the captured images of the target vehicle do not provide any partial or complete read results for the license plate number and state of the target vehicle (block <b>913</b>); (2) no vehicle identification records are found that correspond to the license plate read results for the target vehicle after performing an extended search (block <b>924</b>); (3) one or more possible matches are found but the confidence level in the one or more possible matches, as reflected by combined equivalent matching scores, fall below both the automated confidence threshold and the probable match threshold (block <b>934</b>); and (4) one or more probable matches are found but a human operator rejects the one or more probable matches through visual match truthing (block <b>936</b>).</p>
    <p num="p-0186">The human operator attempts to manually identify the vehicle by (1) reading the license plate(s), and (2) observing vehicle details captured by the image acquisition module <b>624</b>, and (3) comparing the license plate data and vehicle details with data available from the vehicle records database <b>6182</b>, read errors database <b>6183</b>, and/or databases of external systems <b>634</b>. License plates read by a human operator may be confirmed by comparison with automated license plate reader results and/or multiple entry by multiple human operators.</p>
    <p num="p-0187">The manual identification may be deemed successful if the manually collected data, weighed against definable criteria for a positive vehicle match, exceeds a predetermined identification confidence threshold (block <b>942</b>). This determination may be done by the computer <b>612</b>, the operator that provided the manual data, and/or a more qualified operator.</p>
    <p num="p-0188">In one implementation, if a vehicle cannot be positively identified automatically and no near matches are found, one or more images of the vehicle are displayed to a first human reviewer. The first human reviewer inspects the images and manually specifies the license plate number that the first reviewer believes corresponds to the vehicle based on the images. Because this manual review by the first human reviewer is also subject to error (e.g., perceptual or typographical error), the license plate read by the first human reviewer is compared to an LPR database to determine whether the license plate number specified by the first human reviewer exists. Additionally, if a database record having fingerprint data corresponding to the license plate read exists, a fingerprint comparison also may be performed. If the first human reviewer read result does not match any known LPR result or vehicle, the one or more images of the vehicle may be displayed to a second human reviewer. The second human reviewer inspects the images and manually specifies the license plate number that the second human reviewer believes corresponds to the vehicle based on the images. If the read result by the second human reviewer is different than the read result by the first human reviewer, a read by a third human reviewer, who is typically a more qualified reviewer, may be necessary. In sum, the first human reviewer read is effectively a jumping off point to re-attempt an automated match. If the automated match still fails, multiple human reviewers must show agreement in reading the license plate for the read to be deemed accurate.</p>
    <p num="p-0189">If the vehicle is not successfully identified, the computer <b>612</b> creates a record of the event as an unidentified or unassigned transaction (block <b>943</b>). If the vehicle is successfully identified, the computer <b>612</b> creates a record of the event as, for example, a billable or non-revenue transaction (block <b>937</b>). If the vehicle had never been previously identified, the computer <b>612</b> may create a new vehicle identification record for the vehicle and its owner/driver in the vehicle record database <b>6182</b>. The computer <b>612</b> also may update the read errors database <b>6183</b> to include the extracted vehicle identification data and a link that associates the extracted vehicle identification data with the correct vehicle identification record (block <b>938</b>).</p>
    <p num="p-0190"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a block diagram of an electronic toll management system <b>1000</b> that enables electronic handling of payment of tolls by vehicles passing a toll facility without requiring direct communication between the system's lane transaction system and the system's imaging system. The electronic toll management system <b>1000</b> is merely one implementation and various other implementations are either described below or are apparent to one of ordinary skill. The toll management system <b>1000</b> includes a toll management computer <b>1012</b>. The toll management computer <b>1012</b> includes an image database <b>1014</b>, a billing database <b>1016</b>, a vehicle identification database <b>1018</b>, a highlighted vehicle identifier database <b>1020</b>, a billing engine <b>1022</b>, an image and lane transaction data acquisition module (ILDM) <b>1010</b>, an image processing module <b>1025</b>, and a customer management module <b>1026</b>. The toll management computer <b>1012</b> communicates with or is integrated with a toll facility <b>1028</b>, which interacts with a vehicle <b>1030</b> and a party associated with the vehicle <b>1032</b>. The toll management computer <b>1012</b> also communicates with external systems <b>1034</b>.</p>
    <p num="p-0191">Examples of each element within the toll management system <b>1000</b> of <figref idrefs="DRAWINGS">FIG. 10</figref> are described broadly above with respect to <figref idrefs="DRAWINGS">FIG. 1</figref>. In particular, the toll management computer <b>1012</b>, the image database <b>1014</b>, the billing database <b>1016</b>, the vehicle identification database <b>1018</b>, the highlighted vehicle identifier database <b>1020</b>, the billing engine <b>1022</b>, the image processing module <b>1025</b>, the customer management module <b>1026</b>, and the toll facility <b>1028</b> typically have attributes comparable to and illustrate one possible implementation of the toll management computer <b>12</b>, the image database <b>14</b>, the billing database <b>16</b>, the vehicle identification database <b>18</b>, the highlighted vehicle identifier database <b>20</b>, the billing engine <b>22</b>, the image processing module <b>25</b>, the customer management module <b>26</b>, and the toll facility <b>28</b> of <figref idrefs="DRAWINGS">FIG. 1</figref>, respectively. Likewise, the vehicle <b>1030</b>, the party associated with the vehicle <b>1032</b>, and the external systems <b>1034</b> typically have attributes comparable to the vehicle <b>30</b>, the party associated with the vehicle <b>32</b>, and the external systems <b>34</b> of <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
    <p num="p-0192">The ILDM <b>1010</b> includes a lane transaction system <b>1020</b>, an image acquisition module <b>1024</b>, and a video server <b>1030</b>. The image acquisition module <b>1024</b> typically has attributes comparable to and illustrates one possible implementation of the image acquisition module <b>24</b> of <figref idrefs="DRAWINGS">FIG. 1</figref>. The image acquisition module <b>1024</b> includes a vehicle imaging system (VIS) <b>1024</b>A and a vehicle image capture computer (VIC) <b>1024</b>B.</p>
    <p num="p-0193">The toll management system <b>1000</b> may be configured to automatically identify only transponderless vehicles that are deemed “violators”. A violator is a vehicle that does not provide for payment for transacting with the toll facility <b>1028</b> at the time of the transaction. For example, a violator may be a transponderless vehicle that runs through a toll facility <b>1028</b> without providing for payment of the toll fare by, for example, stopping to pay cash at the toll facility or by having an active financial account that is accessible by the toll facility and that may be debited by the toll facility. The toll management system <b>1000</b> is, nevertheless, still distinct from a conventional toll system in that the lane transaction system <b>1020</b> and the image acquisition module <b>1024</b> need not directly communicate with each other to enable identification of violators. Rather, the video server <b>1030</b> is configured to match each violation transaction identified by the lane transaction system <b>1020</b> with a violation image captured by the image acquisition module <b>1024</b> through use of the matching process described in detail below.</p>
    <p num="p-0194">The lane transaction system <b>1020</b> is a system that includes one or more computers and sensors configured to capture transaction related data for each vehicle <b>1030</b> that passes through the toll facility <b>1028</b>. The transaction related data includes any data relevant to the transaction between the vehicle <b>1030</b> and the toll facility <b>1028</b>, such as, for example, the identifier for the lane used by the vehicle, the type of transaction, the time of the transaction (e.g., the transaction time stamp), vehicle classification data (e.g. the number of axles of the vehicle), the transponder information, if applicable, of the vehicle, the fare charged, and an indication of whether or not the vehicle has committed a violation.</p>
    <p num="p-0195">The lane transaction system <b>1020</b> is configured to periodically send a lane activity report or file to the video server <b>1030</b>. The lane activity report includes a chronologically sequential list of data entries or transaction entries. Each transaction entry includes transaction related data for a transaction between the facility <b>1028</b> and a single vehicle. In one implementation, the lane transaction system <b>1020</b> sends the lane activity report to the video server once a day or multiple times a day as a flat file that is attached to an e-mail.</p>
    <p num="p-0196"> <figref idrefs="DRAWINGS">FIG. 11</figref> shows an extract of an exemplary lane activity report <b>1100</b> generated by lane transaction system <b>1020</b>. The extract <b>1100</b> includes a group of ten chronologically sequential lane transaction entries, each entry corresponding to a vehicle transaction with the toll facility <b>1028</b>. The first and last entries (i.e., entries <b>1110</b> and <b>1130</b>) in the group of transaction entries are “landmark transaction” entries. Landmark transactions and landmark transaction entries are discussed in further detail below.</p>
    <p num="p-0197">Entry <b>1110</b> is an exemplary entry corresponding to a successful transaction (i.e., a non-violating transaction). The entry <b>1110</b> includes various data fields that include transaction-related data. The data fields include: (1) a transaction type data field <b>1110</b> <i>a</i>, which indicates the disposition of a transaction or a lane action (e.g., a violation transaction, a paid transaction, and an unpaid transaction that is, nevertheless, not deemed a violating transaction because, for example, the vehicle is a government car); (2) a location data field <b>1110</b> <i>b</i>, which identifies the location where the lane transaction took place (e.g., an identifying number corresponding to a particular toll plaza where the toll transaction took place); (3) a transaction date data field <b>1110</b> <i>c</i>, which identifies the date at which the transaction took place; (4) a time data field <b>1110</b> <i>d</i>, which identifies the time at which the transaction took place; (5) a vehicle classification data field <b>1110</b> <i>e</i>, which identifies the class of the vehicle, number of axles, and/or dimensions of the vehicle; (6) a fare due data field <b>1110</b> <i>f</i>, which indicates the amount that was charged by the toll facility for the transaction; (7) a fare paid data field <b>1110</b> <i>g</i>, which indicates the amount paid by the vehicle for transacting with the toll facility; (8) a payment method data field <b>1110</b> <i>h</i>, which indicates the method used by the vehicle to pay the fare (e.g., cash payment, credit card payment, and transponder payment); (9) an account issuer data field <b>1110</b> <i>i</i>, which indicates the entity that issued the financial account from which the fare may be withdrawn (e.g., a bank account issuer such as “Bank of America”, a credit card issuer such as “Visa”, a transponder account issuer such as a “Virginia” transponder issuing authority); and (10) an account identifier field <b>1110</b> <i>j</i>, which identifies the financial account from which the fare may be withdrawn (e.g., a credit card number or a transponder number). Entry <b>1120</b> is an exemplary entry corresponding to a violation transaction.</p>
    <p num="p-0198">Referring back to <figref idrefs="DRAWINGS">FIG. 10</figref>, the VIS <b>1024</b>A of the image acquisition module <b>1024</b> is a system that includes both computers and sensors configured to capture image data and optionally sensor data for each vehicle that passes through or transacts with the toll facility <b>1028</b>. The VIS <b>1024</b>A may include any and/or all of the sensors and image capture devices described previously with respect to the image acquisition modules <b>24</b>, <b>624</b>. The VIS <b>1024</b>A is configured to send captured vehicle image and sensor data to the VIC <b>1024</b>B. The vehicle image and sensor data typically includes time stamps (time and date information) indicating when the data was captured by the VIS <b>1024</b>A.</p>
    <p num="p-0199">In one implementation, the VIS <b>1024</b>A includes cameras, light sensors, and lasers. The light sensors continuously monitor ambient lighting and update the cameras multiple times every second to ensure that the cameras optimize picture quality by regularly adjusting as necessary to any changes in ambient light. The lasers detect vehicles as they pass through each lane and trigger the cameras as the vehicles exit the lane. Each lane may have one camera that takes one or more images of the rear of the vehicle as the vehicle passes.</p>
    <p num="p-0200">The VIC <b>1024</b>B is a computer system configured to receive vehicle image data and, optionally, sensor data from the VIS <b>1024</b>A, to compress the images and sensor data to minimize storage needs, and to store the image and sensor data in image/sensor files having associated data. The data may include, for example, a unique image/sensor file identifier, a time stamp indicating when the image and sensor data was captured and a location indicating where the image and sensor data was captured (e.g., a lane identifier).</p>
    <p num="p-0201">After receiving image and sensor data for a passing vehicle and storing it in an image/sensor file, the VIC <b>1024</b>B may send a message to the video server <b>1030</b> informing it that the file is available for delivery. The VIC <b>1024</b>B may send the captured image/sensor file to the video server <b>1030</b> in response to a request received from the video server <b>1030</b>. After the video server <b>1030</b> indicates that it has safely stored the requested image/sensor file, the VIC <b>1024</b>B may optionally delete the image/sensor file from its data stores.</p>
    <p num="p-0202"> <figref idrefs="DRAWINGS">FIG. 12</figref> shows an exemplary set of image/sensor files <b>1200</b> containing image data received by the video server <b>1030</b> from the VIC <b>1024</b>B. The set of image/sensor files <b>1200</b> includes ten files, each of which is represented in <figref idrefs="DRAWINGS">FIG. 12</figref> as a thumbnail of the stored image with an associated unique file name. Each image/sensor file of the set of image/sensor files <b>1200</b> corresponds to a single lane transaction entry of the lane activity report extract <b>1100</b>. For example, the image/sensor file <b>1210</b> corresponds to the landmark transaction entry <b>1110</b>, and the image/sensor file <b>1220</b> corresponds to the landmark transaction entry <b>1130</b>.</p>
    <p num="p-0203">The VIC <b>1024</b>B also is configured both to send messages to and to receive messages from, the video server <b>1030</b>. In particular, the VIC <b>1024</b>B may send status messages to the video server <b>1030</b> that indicate the status of the VIC <b>1024</b>B and/or the various components of the VIS <b>1024</b>A. The VIC <b>1024</b>B may receive management messages from the video server <b>1030</b> that enable administrators interacting with the video server <b>1030</b> to configure or otherwise control the operation of the VIC <b>1024</b>B. The VIC <b>1024</b>B also may receive clock synchronization messages from the video server <b>1030</b> that instruct the VIC <b>1024</b>B to reset its internal clock.</p>
    <p num="p-0204">As described in more detail below, the synchronization or matching of image/sensor data with transaction entries is based in part on the time entries associated with the image/sensor data and the transaction entries. Accordingly, synchronization of the internal clock of the VIC <b>1024</b>B, which assigns a time to the image/sensor data, with the internal clock of the lane transaction system <b>1020</b>, which assigns a time to each transaction is desirable. By periodically resetting the internal clock of the VIC <b>1024</b>B to coincide with the setting of a network clock (not shown) known to be synchronized with the internal clock of the lane transaction system <b>1020</b>, the video server <b>1030</b> is able to minimize the clock offsets between the image time stamps generated by the VIC <b>1024</b>B and the transaction time stamps generated by the lane transaction system <b>1020</b>.</p>
    <p num="p-0205">The video server <b>1030</b> is typically a computer system that is configured to receive a lane activity report from the lane transaction system <b>1020</b> and to receive image/sensor files from the VIC <b>1024</b>B of the image acquisition module <b>1024</b>. In another implementation, the video server <b>1030</b> is configured to receive lane activity reports from more than one lane transaction system and/or receive image/sensor files from more than one VIC.</p>
    <p num="p-0206">The video server <b>1030</b> is typically configured to process the lane activity report by parsing it and assigning unique transaction identifiers to each transaction entry in the report. After the transaction identifiers have been assigned, the video server <b>1030</b> typically synchronizes or matches an image/sensor file with each transaction entry in the lane activity report.</p>
    <p num="p-0207"> <figref idrefs="DRAWINGS">FIGS. 13 and 14</figref> illustrate operations performed by, for example, the video server <b>1030</b> to match transaction entries with image/sensor files. In particular, <figref idrefs="DRAWINGS">FIG. 13</figref> illustrates a process <b>1300</b> for selecting groups of transaction entries and corresponding groups of image/sensor files for each violation transaction entry, and <figref idrefs="DRAWINGS">FIG. 14</figref> illustrates a process <b>1400</b> for identifying a violation image/sensor file for each violation transaction entry.</p>
    <p num="p-0208">Referring to <figref idrefs="DRAWINGS">FIG. 13</figref>, the video server <b>1030</b> identifies the transaction entries in the lane activity report that correspond to violation transactions (“violation transaction entries”) (<b>1310</b>). The video server <b>1030</b> may identify the violation transaction entries as the transaction entries in the lane activity report that meet a predetermined set of criteria.</p>
    <p num="p-0209">For example, a transaction entry in the lane activity report may be identified as a violation transaction entry if it satisfies a set of validation criteria. Notably, multiple sets of different criteria may be concurrently used to define a violation transaction entry.</p>
    <p num="p-0210">After one or more violation transaction entries have been identified based on the set(s) of criteria, the video server <b>1030</b> may validate each identified violation transaction entry by (1) reviewing the purported violation transaction entry for anomalies and (2) by examining for anomalies the transaction entries corresponding to transactions that occurred within a configurable window of time preceding and/or following the purported violation transaction (<b>1320</b>). If any anomalies are found, the purported violation transaction entry may not be valid (i.e., it may be an error).</p>
    <p num="p-0211">The video server <b>1030</b> may review all or a subset of the data fields of a purported violation transaction entry to determine, for example, whether a lane of the lane transaction system <b>1020</b> may be unhealthy and, therefore, may be deeming non-violating vehicles as violators. An unhealthy lane may, for example, generate conflicting data regarding a transaction such as, for example, a detection of a different number of axles during vehicle entry into the lane as that detected during vehicle exit from the lane, or as that indicated by transponder information. Nevertheless, in another implementation, violation transaction entries may be identified simply as transaction entries having violation disposition data fields <b>1120</b> <i>n </i>set to indicate a violation. If such anomalies are found, the purported violation transaction is likely an error, and the video server <b>1030</b> may reject the purported violation transaction as not valid.</p>
    <p num="p-0212">The video server <b>1030</b> also may examine for anomalies the transaction entries corresponding to transactions that occurred within a time window (e.g., 5 minutes) preceding the purported violation transaction. For example, one of the preceding transaction entries may indicate that an early read occurred within the five minutes immediately prior to the purported violation. The video server <b>1030</b> may reject the purported violation transaction entry as not valid because an early read indicates that a transponder read may have been misassociated with a vehicle.</p>
    <p num="p-0213">The video server <b>1030</b> also may examine for anomalies the transaction entries corresponding to transactions that occurred within a time window (e.g., 5 minutes) following the purported violation transaction. For example, one of the following transaction entries may indicate that a lane has reset itself so as to minimize cascades of anomalies.</p>
    <p num="p-0214">After successfully validating the one or more violation transaction entries, the video server <b>1030</b> selects a group of chronologically sequential transaction entries for each validated violation transaction entry (<b>1330</b>). The selected group of transaction entries includes transaction entries corresponding to transactions that both precede and follow the violation transaction, and thereby, enables the violation transaction to be placed in its proper context. Through a matching process discussed later, the selected group of transaction entries may be used to achieve greater accuracy in identifying the image/sensor file that corresponds to or matches the validated violation transaction entry.</p>
    <p num="p-0215">The group of transaction entries, for a validated violation transaction entry, may be selected as all transaction entries starting from the first transaction entry corresponding to a “landmark transaction” (i.e., a landmark transaction entry) that occurred before the validated violation transaction entry and ending at the first landmark transaction entry that occurred after the validated violation transaction entry. Accordingly, the group of transaction entries selected for each validated violation transaction entry typically includes the validated violation transaction entry, two landmark transaction entries, and one or more other transaction entries, where the two landmark transaction entries surround or bracket the validated violation transaction entry and the one or more other transaction entries in the group. <figref idrefs="DRAWINGS">FIG. 11</figref> shows an exemplary group of transaction entries <b>1100</b> that includes two landmark transaction entries <b>1110</b> and <b>1130</b> that bracket or surround the rest of the transaction entries in the group, including the violation transaction entry <b>1120</b>.</p>
    <p num="p-0216">A landmark transaction is a transaction corresponding to a transaction entry that is easily matched or synchronized with an associated image/sensor file. A landmark transaction, for example, may be a transaction that follows a predetermined amount of time during which no transaction occurs (i.e., a “dead” time). For example, if no transaction occurs between a vehicle and the toll facility <b>1028</b> for 10 seconds, the transaction that occurs right after the 10 second interval is a landmark transaction because its transaction entry is easily matched with its corresponding image/sensor file. The landmark transaction is easily matched with its corresponding image/sensor file because both are easily identifiable as the first transaction entry and image/sensor file to be captured following a lengthy 10 second “dead” time. Similarly, the transaction that precedes the lengthy 10 second dead time is also a landmark transaction because its transaction entry and image/sensor file are also similarly easily identifiable as the last transaction entry and image/sensor file preceding the lengthy 10 second “dead” time. Referring to <figref idrefs="DRAWINGS">FIG. 11</figref>, entry <b>1110</b> may be, for example, a landmark transaction because it follows 10 second “dead” time, and entry <b>1130</b> may be, for example, a landmark transaction because it precedes a 10 second “dead” time.</p>
    <p num="p-0217">Other examples of landmark transactions include transactions that involve visually unique vehicles or vehicles that have been positively identified. For example, a transaction involving a multi-axle vehicle (i.e., a vehicle having 3 or more axles), such as a truck, may be a landmark transaction if the majority of vehicles passing through the toll facility are cars having only 2 axles. By searching for an image of a truck from among all of the car images, the image/sensor file having an image that matches the multi-axle transaction entry is easily found. Similarly, a transaction involving a vehicle having a transponder also may be a landmark transaction if the transponder information captured in the transaction entry may be used to identify the vehicle's license plate number. If the vehicle's license plate number is successfully identified from the transponder data, the corresponding image and, therefore, image/sensor file may then be positively identified through use of LPR.</p>
    <p num="p-0218">Notably, the video server <b>1030</b> may not designate a transaction as a landmark transaction if it is preceded by or followed by a violation transaction or another unusual type of transaction (e.g. a lane reset or any transaction that does not meet validation criteria). If two or more validated violation transaction entries occur within a time window defined by a single pair of landmark transaction entries, the video server <b>1030</b> may use the same group of transaction entries for matching purposes for both of the validated violation transaction entries.</p>
    <p num="p-0219">In some implementations, the video server <b>1030</b> may limit the size of the groups of transaction entries by imposing configurable limits on the number of transaction entries and/or the maximum time interval preceding and/or following the validated violation transaction entry. For example, the number of transaction entries may be limited to twenty or one hundred transactions and/or the maximum time interval following the validated violation transaction entry may be limited to one minute or five minutes. If only one landmark transaction occurs within this configurable limit or time interval, then only that landmark transaction is used in the matching process. If no landmark transaction occurs within this configurable limit or time interval, then no landmark transactions are used in the matching process. If no landmark transactions are used in the matching process, then the matching process is accomplished manually by looking for time patterns or identifying info in the images to make a positive associated with the corresponding transactions (e.g., transponder information in the transaction entries may be matched with expected license plate numbers as shown in the images).</p>
    <p num="p-0220">In one implementation, the group of transaction entries for a validated violation transaction entry includes all entries corresponding to transactions immediately following the last 6-10 second gap preceding the violation transaction and all entries corresponding to transactions that occurred up until one minute after the violation transaction. In this implementation, only the beginning transaction entry in the group is a landmark transaction entry (i.e., the entry corresponding to the first transaction after the 6-10 second gap).</p>
    <p num="p-0221">After a group of transaction entries has been identified for each validated violation transaction entry, the video server <b>1030</b> uses the landmark transaction entries of each group of transaction entries to identify corresponding groups of chronologically sequential image/sensor files (<b>1340</b> and <b>1350</b>). The group of image/sensor files for a validated violation transaction typically includes all image/sensor files having time stamps between that of the image/sensor file having a landmark transaction image preceding the violation transaction (i.e., the image corresponding to the landmark transaction preceding the violation transaction) and that of the image/sensor file having a landmark transaction image following the violation transaction (i.e., the image corresponding to the landmark transaction following the violation transaction). Accordingly, the group of image/sensor files for a validated violation transaction is typically a group of image/sensor files surrounded by or bracketed by two image/sensor files having landmark transaction images. Absent any errors, the image/sensor file group includes an image/sensor file having an image corresponding to the validated violation transaction (i.e., a “violation image/sensor file”).</p>
    <p num="p-0222">In the previously described implementation having only one landmark transaction entry, the corresponding group of image/sensor files may be determined as all image/sensor files having time stamps that fall within the window of time between the time stamp of the image/sensor file corresponding to the landmark transaction entry and a time that is approximately one minute after the time stamp of the image/sensor file corresponding to the landmark transaction entry. The video server <b>1030</b> may adjust the landmark transaction “time” and/or the one minute duration to take into account any clock drift or offset (see below) between the clock of the image acquisition module <b>1024</b> and the clock of the lane transaction system <b>1020</b>.</p>
    <p num="p-0223">As an example of a result of operation <b>1340</b>, <figref idrefs="DRAWINGS">FIGS. 11 and 12</figref> show a group of transaction entries <b>1100</b> and a corresponding group of image/sensor files <b>1200</b>, respectively. The group of transaction entries <b>1100</b> include transaction entries bracketed by, that is, surrounded by, landmark transaction entries <b>1110</b> and <b>1130</b>. Similarly, the group of image/sensor files <b>1200</b> include image/sensor files bracketed by or surrounded by image/sensor files <b>1210</b> and <b>1220</b> having landmark transaction images corresponding to the landmark transaction entries <b>1110</b> and <b>1130</b>, respectively.</p>
    <p num="p-0224">After all pairs of groups have been identified, the video server <b>1030</b> may optionally estimate the clock offsets between the internal clock of the lane transaction system <b>1020</b> and the internal clock of the image acquisition module <b>1024</b> for each group pairing (<b>1360</b>). The video server <b>1030</b> may estimate the clock offset for a group pairing, for example, as the difference between the time stamp of a landmark transaction entry and the time stamp of the image/sensor file having a corresponding landmark transaction image. If the groups each include two landmark transactions, the clock offset for the group pairing may be determined, for example, by calculating the average of the differences between the image acquisition module <b>1024</b> and lane transaction system <b>1020</b> time stamps corresponding to each landmark transaction. Determining the clock offsets is useful for determining a one-to-one matching between the lane transaction entries and the image/sensor files as described next. A clock drift also may be calculated by estimating the rate of change in clock offsets based on differences in landmark transaction/image times at either end of a significant interval (e.g., hours, rather than the minute or so within a single group).</p>
    <p num="p-0225">Referring to <figref idrefs="DRAWINGS">FIG. 14</figref>, once the groups of image/sensor files have been identified, the video server <b>1030</b> may be configured to identify a violation image/sensor file corresponding to each validated violation transaction through a matching process <b>1400</b>. The matching process <b>1400</b> identifies the violation image/sensor file by establishing a one-to-one correspondence between each image/sensor file in an image/sensor file group and each transaction entry in a corresponding group of transaction entries. Notably, by using information contained in transaction entries both before and after the violation transaction entry in the matching process, the process <b>1400</b> may be able to identify a violation image/sensor file that matches the violation transaction entry with greater accuracy than is possible through simple time stamp comparisons (i.e., through simply designating an image/sensor file as a violation image/sensor file if its image time stamp is the same or substantially the same as the time stamp of the violation transaction entry).</p>
    <p num="p-0226">Specifically, as shown in <figref idrefs="DRAWINGS">FIG. 14</figref>, a process to identify a violation image/sensor file for a validated violation transaction entry typically begins by matching the beginning landmark transaction entry in the group of transaction entries with the beginning landmark image/sensor file in the corresponding group of image/sensor files (<b>1410</b>). For example, if the group of landmark transaction entries is the group <b>1100</b> of ten entries shown in <figref idrefs="DRAWINGS">FIG. 11</figref> and the group of image/sensor files is the group <b>1200</b> of ten files shown in <figref idrefs="DRAWINGS">FIG. 12</figref>, the landmark transaction entry <b>1110</b> would be matched with the landmark image/sensor file <b>1210</b>.</p>
    <p num="p-0227">Using the beginning landmark transaction as a reference point, the video server <b>1030</b> establishes a one-to-one correspondence between each subsequent transaction entry in the group of landmark transactions and each subsequent image/sensor file in the corresponding group of image/sensor files (<b>1420</b>). For example, the video server <b>1030</b> matches the second landmark transaction entry (i.e., the first entry recorded after the landmark transaction entry) in the group <b>1100</b> with the second image/sensor file (i.e, the first image/sensor file having data captured after the landmark image/sensor file) in the group <b>1200</b>, the third landmark transaction entry in the group <b>1100</b> with the third image/sensor file in the group <b>1200</b>, and so forth.</p>
    <p num="p-0228">If the matching process is successful, the result of the matching process is a one-to-one match between each transaction entry in the group of transaction entries and each image/sensor file in the group of images/sensor files. <figref idrefs="DRAWINGS">FIG. 15</figref> shows an example of a matched group pairing <b>1600</b>. A matched pair is illustrated in the figure by the lines connecting or matching a transaction entry with an image/sensor file.</p>
    <p num="p-0229">As each transaction entry is matched to an image/sensor file, the video server <b>1030</b> updates a data record associated with the violation transaction to indicate a match between the given transaction entry and the image/sensor file. If the video server <b>1030</b> identifies one or more anomalous transaction entries and/or image/sensor files in the groups, the video server <b>1030</b> may update the data record to flag the corresponding entries as anomalous and to indicate why the entries or image/sensor files have been deemed anomalous.</p>
    <p num="p-0230">The video server <b>1030</b> may be configured to confirm whether the matching process was successful (<b>1430</b>) by determining, for example, whether the following criteria are met: (1) the number of transaction entries in the group of transaction entries is equal to the number of image/sensor files in the group of image/sensor files; (2) each transaction entry in the group of transaction entries is matched with each image/sensor file in the corresponding group of image/sensor files; (3) the offset-adjusted time stamp for each transaction entry falls within an expected deviation from the time stamp of the corresponding matched image/sensor file; and (4) the interval of time between transactions as reflected by the time stamps of the transaction entries is within an expected deviation from the interval of time between transactions as reflected by the time stamps of the image/sensor files. Each of these is explained below.</p>
    <p num="p-0231">The video server <b>1030</b> may count the number of image/sensor files and landmark transaction entries in the groups to determine that they are equal in number. If the video server <b>1030</b> determines that the number of image/sensor files is different than the number of transaction entries, the video server <b>1030</b> may insert one or more transaction entry placeholders and/or image/sensor file placeholders as necessary to equalize the number of transaction entries with the number of image/sensor files (<b>1440</b>). The video server <b>1030</b> may insert the placeholders in the groups at a location in time that minimizes deviation between the expected intervals of time between transactions and the expected differences between the image/sensor file time stamps and the transaction entry time stamps. The video server also may determine which image likely does not correspond to a lane transaction by using LPR to obtain license plate data for the vehicles in the images. An image with no license plate present may be assigned a transaction placeholder, rather than associated with a lane transaction. The number of transaction entries may differ from the number of image/sensor files due to, for example, a false triggering of the cameras of the VIS <b>1024</b>A. Such a false triggering may cause an additional image/sensor file to be created that has an image, for example, of a lane with no vehicle present. If the video server <b>1030</b> deems it necessary to add placeholders to the groups associated with a violation transaction, the video server <b>1030</b> typically modifies the data record associated with the violation to indicate that placeholders were inserted and to identify the inserted placeholders.</p>
    <p num="p-0232">The video server <b>1030</b> also may determine the deviation between the time stamps of each transaction entry and the time stamps of each corresponding image/sensor file. Because the internal clocks of the lane transaction system <b>1020</b> and the image acquisition module <b>1024</b> are independent, the clocks, and thus the time stamps generated by the clocks, often indicate different times (e.g., due to a difference in clock resolution, a difference in clock drift, and/or a fixed difference in clock setting). The difference in time between the clocks may be represented as a fixed offset between the clocks and a variable drift. In one implementation, the video server <b>1030</b> may estimate the fixed offset, for example, based on the difference in time stamps of the landmark transaction entry and the corresponding landmark image/sensor file. After estimating the offset between the two clocks, the video server <b>1030</b> may adjust each transaction entry time stamp (or image/sensor file time stamp) by the offset prior to comparing it to the corresponding image/sensor file time stamp (or transaction entry time stamp).</p>
    <p num="p-0233">If the offset-compensated transaction entry time stamp (or image/sensor file time stamp) is significantly different from the image/sensor file time stamp (or transaction entry time stamp), the video server <b>1030</b> may modify the data record associated with the violation to indicate that the transaction entry and corresponding image/sensor file are anomalous and that the matching process was not deemed successful. For example, if the offset-adjusted time stamp of a transaction entry is different than the time stamp of the matching image/sensor file by one second or more, the video server <b>1030</b> may flag the transaction entry and the corresponding image/sensor file as failing to have matching time stamps and may add a note to the data record associated with the violation indicating why the matching process was not successful.</p>
    <p num="p-0234">The video server <b>1030</b> also may determine the deviation between the interval of time between transactions as reflected by the time stamps of the transaction entries and the interval of time between transactions as reflected by the time stamps of the image/sensor files. For example, if the interval of time between a first transaction and a second transaction as reflected by the time stamps of the corresponding transaction entries is eleven seconds and the corresponding interval of time between the same transactions as reflected by the time stamps of the matching image/sensor files is five seconds, the deviation between the intervals of time is six seconds. If the video server <b>1030</b> is configured to indicate a matching failure if transaction intervals differ by more than four seconds, the video server <b>1030</b> may flag both transaction entries and corresponding image/sensor files as failing to provide a consistent interval of time between transactions and may add a note to the data record associated with the violation indicating why the matching process was not successful. Such a difference in intervals of time between transactions may indicate that one or both of the transaction entries (or image/sensor files) is not correctly matched to an image sensor file (or transaction entry).</p>
    <p num="p-0235">After the matching process is completed, the video server <b>1030</b> is able to identify the violation image/sensor file as the image/sensor file that was matched with the violation transaction entry during the matching process (<b>1450</b>). <figref idrefs="DRAWINGS">FIG. 15</figref> shows the violation image/sensor file <b>1510</b> matched with the violation transaction entry <b>1120</b> of <figref idrefs="DRAWINGS">FIG. 11</figref>. The video server <b>1030</b> may repeat operations <b>1410</b>-<b>1450</b> to identify the violation image/sensor file for each valid violation transaction entry and associated group of transaction entries and corresponding group of image/sensor files (<b>1460</b>).</p>
    <p num="p-0236">In another implementation, the video server <b>1030</b> is configured to match each transaction identified by the lane transaction system <b>1020</b> with other sensor data (e.g., magnetic signature data and laser signature data), instead of with image data. In this implementation the video server <b>1030</b> may identify landmark transaction sensor data that corresponds to landmark transaction entries rather than identify landmark transaction images. The landmark transaction sensor data may be matched with corresponding landmark transaction entries to synchronize the sensor data with transaction entries as described previously. In another implementation, the video server <b>1030</b> may match each transaction identified by the lane transaction system <b>1020</b> based on a combination of landmark sensor data and landmark transaction images.</p>
    <p num="p-0237">After the matching process is completed and each violation transaction entry or transaction entry has been associated with a corresponding image/sensor file, the video server typically stores the identified groups of transactions and corresponding groups of image/sensor files, the identified violation or transaction image sensor/files, and the associated lane transaction data in violation records or in transaction records and sends the violation or transaction records to the image processing module <b>1025</b> for vehicle identification and processing. The video server <b>1030</b> typically performs all or most of the above-described functions (e.g., the parsing, the violation entry identification and validation, the grouping, and the matching functions) using a batch application.</p>
    <p num="p-0238">The video server <b>1030</b> also may be configured to perform various other functions, including: receiving status messages from the VIC <b>1024</b>A (and, in some implementations, from other VICs) and forwarding the status messages to the appropriate monitoring system (not shown); providing a web-based interface that allows administrators to create messages and send them to the VIC <b>1024</b>B (and, in some implementations, to other VICs); synchronizing its internal clock to a network time server and periodically setting the internal clock of the VIC <b>1024</b>B (and, in some implementations, the internal clock of other VICs) through an automatically generated management message.</p>
    <p num="p-0239"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a flow chart of an exemplary process <b>1600</b> that identifies and charges violating vehicles for incurred toll fees without requiring the toll system's lane transaction system to directly communicate with the toll system's imaging system. For convenience, particular components described with respect to <figref idrefs="DRAWINGS">FIG. 10</figref> are referenced as performing the process <b>1300</b>. However, similar methodologies may be applied in other implementations where different components are used to define the structure of the system, or where the functionality is distributed differently among the components shown by <figref idrefs="DRAWINGS">FIG. 10</figref>. In one implementation, the process <b>1300</b> is implemented by the toll management system <b>1000</b>.</p>
    <p num="p-0240">The lane transaction system <b>1020</b> captures transaction-related data for each vehicle that transacts with the facility <b>1028</b> (<b>1602</b>). The lane transaction system <b>1020</b> records the transaction-related data in a lane activity report and sends to the video server <b>1030</b> or otherwise enables the video server <b>1030</b> to access the lane activity report at periodic intervals (e.g., once a day)(<b>1604</b>).</p>
    <p num="p-0241">The image acquisition module <b>1024</b> captures vehicle images and optionally other sensor data and stores the image/sensor data in image/sensor files (<b>1606</b>). The image acquisition module <b>1024</b> sends to the video server <b>1030</b> or otherwise enables the video server <b>1030</b> to access the image/sensor files at periodic intervals and/or as the image/sensor data is captured (<b>1608</b>).</p>
    <p num="p-0242">The video server <b>1030</b> receives or accesses the lane activity report (<b>1610</b>) and receives or accesses the image/sensor files (<b>1612</b>). The video server <b>1030</b> processes the received lane activity report and image/sensor files to select a group of transaction entries and a corresponding group of image/sensor files for each violation transaction entry in the lane activity report (<b>1614</b>). <figref idrefs="DRAWINGS">FIG. 13</figref> illustrates an exemplary process <b>1300</b> that may be used by video server <b>1030</b> to perform operation <b>1614</b>.</p>
    <p num="p-0243">After a group of transaction entries and a corresponding group of image/sensor files have been identified for one or more of the validated violation transactions, the video server <b>1030</b> identifies a violation image/sensor file for each validated violation transaction entry by performing a transaction entry and image/sensor file matching process for each group pairing (<b>1616</b>). <figref idrefs="DRAWINGS">FIG. 14</figref> illustrates an exemplary process <b>1400</b> that may be used by video server <b>1030</b> to perform operation <b>1616</b>.</p>
    <p num="p-0244">For each validated violation transaction entry, the video server <b>1030</b> is configured to save one or more of the following in a data record (i.e., “a violation record”) (<b>1618</b>): (1) the group of transaction entries that correspond to and include the validated violation transaction entry; (2) the corresponding group of image/sensor files that include the identified violation image/sensor file; (3) the matching data identifying the matched pairs of transaction entries and image/sensor files; (4) the flags and notes indicating anomalous transaction entries and/or image/sensor files and explaining why they are anomalous; and (5) data indicating whether and why the matching process was determined to be successful or unsuccessful.</p>
    <p num="p-0245">The video server <b>1030</b> is configured to send to the image processing module <b>1025</b> or enable the image processing module <b>1025</b> to access the one or more violation records (<b>1620</b>). The image processing module <b>1025</b> receives or accesses the one or more violation records (<b>1622</b>) and, optionally, may present the information in the violation records to a user for manual confirmation of the matching process and the identified violation image/sensor file (<b>1624</b>).</p>
    <p num="p-0246">The image processing module <b>1025</b> may include a violation review application that allows a user to perform the following tasks: (1) check the association or matching between lane transaction entries and image/sensor files; (2) adjust the matching as necessary (including manually inserting placeholders as necessary); (3) confirm the correct matching of lane transaction entries and image/sensor files based on timing and image content; (4) manually specify a violation image/sensor file; (5) input identifying information for a violating vehicle or owner or entity associated with the violating vehicle; and (6) specify the disposition of a violation transaction and a reason for the disposition.</p>
    <p num="p-0247"> <figref idrefs="DRAWINGS">FIG. 17</figref> shows an exemplary user interface <b>1700</b> that lists matched transaction entries for the ten transactions corresponding to the transaction entries of <figref idrefs="DRAWINGS">FIG. 11</figref> and the image/sensor files of <figref idrefs="DRAWINGS">FIG. 12</figref>. The user interface <b>1700</b> includes a matched transaction entry for each matched transaction entry-image/sensor file pair.</p>
    <p num="p-0248">An exemplary matched transaction entry <b>1710</b> includes a lane identifier <b>1715</b> (e.g., “15 3738”), a lane transaction time stamp <b>1720</b> (e.g., “4:30:39”), a matching image time stamp <b>1725</b> (e.g., “4:30:34”), a transaction type <b>1730</b> (e.g., “STD AVI”), a transaction description <b>1735</b> (e.g., blank if the transaction is not a violation); a transaction disposition <b>1740</b> (e.g., blank if the transaction is not a violation); an interval of time between the last transaction and the current transaction according to the lane transaction time stamps <b>1745</b> (e.g., “2” seconds), and an interval of time between the last transaction and the current transaction according to the matching image time stamps <b>1750</b> (e.g., “2” seconds).</p>
    <p num="p-0249">The user interface <b>1700</b> may be configured to include a button, icon, or other interface element (not shown) selectable to generate a graph that shows the time stamp deviation between the image/sensor file time stamp and the transaction entry time stamp for one or more matched pairs. For example, <figref idrefs="DRAWINGS">FIG. 18</figref> shows an example <b>1800</b> of a bar graph configured to indicate the difference in time between the lane transaction time stamp for a transaction and the time stamp of the corresponding image/sensor file for the same transaction. If the difference in time is above a predetermined threshold, such as, for example, one second, the transaction may be considered poorly matched, problematic, and/or anomalous. The bar graph <b>1800</b> shows that the transaction labeled “transaction <b>4</b>” has a time stamp difference greater than one second, and, therefore, may be deemed anomalous.</p>
    <p num="p-0250">Bar graphs, like the bar graph <b>1800</b>, are particularly useful in that they allow a user to quickly, at a glance, determine the accuracy of the matching process and focus on poorly matched, problematic, and/or anomalous transactions. In some implementations, the graph reflects time differences after compensating for the offsets between the internal clock of the image acquisition module <b>1024</b> and the internal clock of the lane transaction system <b>1020</b>.</p>
    <p num="p-0251">The user interface <b>1700</b> also may be configured to include a button, icon, or other interface element selectable to generate a graph that shows the intervals of time between current and preceding transactions as reflected by image/sensor file time stamps and the intervals of time between current and preceding transactions as reflected by transaction entry time stamps. For example, <figref idrefs="DRAWINGS">FIG. 19</figref> shows an example <b>1900</b> of a bar graph that assigns to each transaction a pair of bars, one having a height reflecting the interval of time between the current and preceding transactions as determined from lane transaction entry time stamps and the other having a height reflecting the interval of time between the current and preceding transactions as determined from image/sensor file time stamps.</p>
    <p num="p-0252">If the difference in the heights of the two bar graphs associated with the same transaction indicates a difference in time above a predetermined threshold, such as, for example, four seconds, the transaction may be considered poorly matched, problematic, and/or anomalous. The bar graph <b>1900</b> does not show any transaction associated with two bars that differ in height by four or more seconds. Rather, it shows differences of 0 seconds, 1 second, 1 second, and 1 second, respectively, for transactions <b>1</b> through <b>4</b>. Accordingly, bar graph <b>1900</b> indicates that all four transactions are properly matched with respect to this criterion. Like the bar graph <b>1800</b>, the bar graph <b>1900</b> enables a user to quickly, at a glance, determine the accuracy of the matching process and focus on poorly matched, problematic, and/or anomalous transactions.</p>
    <p num="p-0253">Referring back to <figref idrefs="DRAWINGS">FIG. 16</figref>, the image processing module <b>1025</b> identifies the violating vehicles from the violation image/sensor files and, optionally, from the transaction-related data in the violation transaction entry (<b>1626</b>). The image processing module <b>1024</b> may perform this identification using any or all of the methods described previously. Once a violating vehicle has been identified for each violation transaction, the image processing module <b>1025</b> sends the identified vehicle and associated transaction-related data to the billing engine <b>1022</b> for processing as described elsewhere (e.g., with respect to FIGS. <b>3</b> and <b>4</b>)(<b>1628</b>).</p>
    <p num="p-0254">The above applications represent illustrative examples and the disclosed techniques disclosed can be employed in other applications. Further, the various aspects and disclosed techniques (including systems and processes) can be modified, combined in whole or in part with each other, supplemented, or deleted to produce additional implementations.</p>
    <p num="p-0255">The systems and techniques described here can be implemented in digital electronic circuitry, or in computer hardware, firmware, software, or in combinations of them. The systems and techniques described here can be implemented as a computer program product, i.e., a computer program tangibly embodied in an information carrier, e.g., in a machine-readable storage device or in a propagated signal, for execution by, or to control the operation of, data processing apparatus, e.g., a programmable processor, a computer, or multiple computers. A computer program can be written in any form of programming language, including compiled or interpreted languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.</p>
    <p num="p-0256">Method steps of the systems and techniques described here can be performed by one or more programmable processors executing a computer program to perform functions of the invention by operating on input data and generating output. Method steps can also be performed by, and apparatus of the invention can be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).</p>
    <p num="p-0257">Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The typical elements of a computer are a processor for executing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. Information carriers suitable for embodying computer program instructions and data include all forms of non-volatile memory, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks such as internal hard disks and removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in special purpose logic circuitry.</p>
    <p num="p-0258">To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor for displaying information to the user and a keyboard and a pointing device such as a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.</p>
    <p num="p-0259">The systems and techniques described here can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or an Web browser through which a user can interact with an implementation of the invention, or any combination of such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.</p>
    <p num="p-0260">The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.</p>
    <p num="p-0261">Other implementations are within the scope of the following claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4242661">US4242661</a></td><td class="patent-data-table-td patent-date-value">Mar 16, 1976</td><td class="patent-data-table-td patent-date-value">Dec 30, 1980</td><td class="patent-data-table-td ">Stifelsen Institutet for Mikrovagsteknik Vid Tekniska Hogskolan i Stockholm</td><td class="patent-data-table-td ">Device for registration of objects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4963723">US4963723</a></td><td class="patent-data-table-td patent-date-value">Nov 10, 1988</td><td class="patent-data-table-td patent-date-value">Oct 16, 1990</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Automatic toll collector for toll roads</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5638302">US5638302</a></td><td class="patent-data-table-td patent-date-value">Feb 26, 1996</td><td class="patent-data-table-td patent-date-value">Jun 10, 1997</td><td class="patent-data-table-td ">Gerber; Eliot S.</td><td class="patent-data-table-td ">System and method for preventing auto thefts from parking areas</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5740230">US5740230</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 31, 1996</td><td class="patent-data-table-td patent-date-value">Apr 14, 1998</td><td class="patent-data-table-td ">Octel Communications Corporation</td><td class="patent-data-table-td ">Directory management system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5745052">US5745052</a></td><td class="patent-data-table-td patent-date-value">Jun 18, 1996</td><td class="patent-data-table-td patent-date-value">Apr 28, 1998</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Parking lot control system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5819234">US5819234</a></td><td class="patent-data-table-td patent-date-value">Jul 29, 1996</td><td class="patent-data-table-td patent-date-value">Oct 6, 1998</td><td class="patent-data-table-td ">The Chase Manhattan Bank</td><td class="patent-data-table-td ">Toll collection system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5920338">US5920338</a></td><td class="patent-data-table-td patent-date-value">Nov 4, 1997</td><td class="patent-data-table-td patent-date-value">Jul 6, 1999</td><td class="patent-data-table-td ">Katz; Barry</td><td class="patent-data-table-td ">Asynchronous video event and transaction data multiplexing technique for surveillance systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6042008">US6042008</a></td><td class="patent-data-table-td patent-date-value">Jul 1, 1997</td><td class="patent-data-table-td patent-date-value">Mar 28, 2000</td><td class="patent-data-table-td ">Denso Corporation</td><td class="patent-data-table-td ">Toll collection system of toll road and in-vehicle unit for the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6052068">US6052068</a></td><td class="patent-data-table-td patent-date-value">Mar 25, 1997</td><td class="patent-data-table-td patent-date-value">Apr 18, 2000</td><td class="patent-data-table-td ">Frederick J. Price</td><td class="patent-data-table-td ">Vehicle identification system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6081206">US6081206</a></td><td class="patent-data-table-td patent-date-value">Mar 6, 1998</td><td class="patent-data-table-td patent-date-value">Jun 27, 2000</td><td class="patent-data-table-td ">Visionary Technology Inc.</td><td class="patent-data-table-td ">Parking regulation enforcement system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6121898">US6121898</a></td><td class="patent-data-table-td patent-date-value">Mar 24, 1998</td><td class="patent-data-table-td patent-date-value">Sep 19, 2000</td><td class="patent-data-table-td ">Moetteli; John B.</td><td class="patent-data-table-td ">Traffic law enforcement system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6167333">US6167333</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1999</td><td class="patent-data-table-td patent-date-value">Dec 26, 2000</td><td class="patent-data-table-td ">Lucent Technologies Inc.</td><td class="patent-data-table-td ">Highway information system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6747687">US6747687</a></td><td class="patent-data-table-td patent-date-value">Jan 11, 2000</td><td class="patent-data-table-td patent-date-value">Jun 8, 2004</td><td class="patent-data-table-td ">Pulnix America, Inc.</td><td class="patent-data-table-td ">System for recognizing the same vehicle at different times and places</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6922156">US6922156</a></td><td class="patent-data-table-td patent-date-value">Jan 28, 2002</td><td class="patent-data-table-td patent-date-value">Jul 26, 2005</td><td class="patent-data-table-td ">Raytheon Company</td><td class="patent-data-table-td ">Vehicle trip determination system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6966489">US6966489</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 2002</td><td class="patent-data-table-td patent-date-value">Nov 22, 2005</td><td class="patent-data-table-td ">Citylink Melbourne Limited</td><td class="patent-data-table-td ">Tolling information exchange method and system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7119674">US7119674</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 21, 2004</td><td class="patent-data-table-td patent-date-value">Oct 10, 2006</td><td class="patent-data-table-td ">Pips Technology, Inc.</td><td class="patent-data-table-td ">Automated site security, monitoring and access control system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7407097">US7407097</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 10, 2005</td><td class="patent-data-table-td patent-date-value">Aug 5, 2008</td><td class="patent-data-table-td ">Rent A Toll, Ltd.</td><td class="patent-data-table-td ">Toll fee system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020097178">US20020097178</a></td><td class="patent-data-table-td patent-date-value">Jan 19, 2001</td><td class="patent-data-table-td patent-date-value">Jul 25, 2002</td><td class="patent-data-table-td ">Thomas Warren J.</td><td class="patent-data-table-td ">System and method to attribute, reconcile and account for automated vehicle identification charges irrespective of vehicle ownership</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020140579">US20020140579</a></td><td class="patent-data-table-td patent-date-value">Jan 28, 2002</td><td class="patent-data-table-td patent-date-value">Oct 3, 2002</td><td class="patent-data-table-td ">Kavner Douglas M.</td><td class="patent-data-table-td ">Vehicle trip determination system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20020198767">US20020198767</a></td><td class="patent-data-table-td patent-date-value">Nov 29, 2001</td><td class="patent-data-table-td patent-date-value">Dec 26, 2002</td><td class="patent-data-table-td ">Kwang-Duck Kim</td><td class="patent-data-table-td ">Fee collecting system and method for motor vehicle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040008368">US20040008368</a></td><td class="patent-data-table-td patent-date-value">Sep 7, 2001</td><td class="patent-data-table-td patent-date-value">Jan 15, 2004</td><td class="patent-data-table-td ">Plunkett Michael K</td><td class="patent-data-table-td ">Mailing online operation flow</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040008514">US20040008514</a></td><td class="patent-data-table-td patent-date-value">Dec 11, 2002</td><td class="patent-data-table-td patent-date-value">Jan 15, 2004</td><td class="patent-data-table-td ">Sang-Jean Lee</td><td class="patent-data-table-td ">Vehicle measuring apparatus and method for toll collection system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20040167861">US20040167861</a></td><td class="patent-data-table-td patent-date-value">Feb 21, 2003</td><td class="patent-data-table-td patent-date-value">Aug 26, 2004</td><td class="patent-data-table-td ">Hedley Jay E.</td><td class="patent-data-table-td ">Electronic toll management</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20050197976">US20050197976</a></td><td class="patent-data-table-td patent-date-value">Jul 12, 2004</td><td class="patent-data-table-td patent-date-value">Sep 8, 2005</td><td class="patent-data-table-td ">Tuton James D.</td><td class="patent-data-table-td ">System and method for processing toll transactions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070252678">US20070252678</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 3, 2004</td><td class="patent-data-table-td patent-date-value">Nov 1, 2007</td><td class="patent-data-table-td ">Javier Garcia Alonso</td><td class="patent-data-table-td ">Method and Apparatus for Tele-Toll Payment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CA2163872A1?cl=en">CA2163872A1</a></td><td class="patent-data-table-td patent-date-value">May 27, 1994</td><td class="patent-data-table-td patent-date-value">Dec 8, 1994</td><td class="patent-data-table-td ">Rune Jonsson</td><td class="patent-data-table-td ">A method and a device for the registration of the movement of a vehicle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CA2422187A1?cl=en">CA2422187A1</a></td><td class="patent-data-table-td patent-date-value">Sep 7, 2001</td><td class="patent-data-table-td patent-date-value">Mar 14, 2002</td><td class="patent-data-table-td ">United States Postal Service</td><td class="patent-data-table-td ">Mailing online operation flow</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/DE10104502A1?cl=en">DE10104502A1</a></td><td class="patent-data-table-td patent-date-value">Jan 31, 2001</td><td class="patent-data-table-td patent-date-value">Aug 14, 2002</td><td class="patent-data-table-td ">Daimler Chrysler Ag</td><td class="patent-data-table-td ">Kontrollverfahren zur Straßengebührenerfassung</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=YcZTBgABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DGB%26NR%3D2344205A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGBrmWoRB4Dk4FFDPfKA0lVRYWUQw">GB2344205A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=YcZTBgABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2004213569A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNF43heNAui921S5Shjpga-EAh3D4g">JP2004213569A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1998014925A1?cl=en">WO1998014925A1</a></td><td class="patent-data-table-td patent-date-value">Oct 3, 1997</td><td class="patent-data-table-td patent-date-value">Apr 9, 1998</td><td class="patent-data-table-td ">Goeran Bostroem</td><td class="patent-data-table-td ">Method and device for registering the outer characteristics of a vehicle in a road toll unit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1999066455A2?cl=en">WO1999066455A2</a></td><td class="patent-data-table-td patent-date-value">May 26, 1999</td><td class="patent-data-table-td patent-date-value">Dec 23, 1999</td><td class="patent-data-table-td ">Ronald Barker</td><td class="patent-data-table-td ">Roadside control device for a toll apparatus installed in a motor vehicle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000046068A1?cl=en">WO2000046068A1</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 2000</td><td class="patent-data-table-td patent-date-value">Aug 10, 2000</td><td class="patent-data-table-td ">Brett Hall</td><td class="patent-data-table-td ">Computerized parking facility management system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2002063570A2?cl=en">WO2002063570A2</a></td><td class="patent-data-table-td patent-date-value">Feb 7, 2002</td><td class="patent-data-table-td patent-date-value">Aug 15, 2002</td><td class="patent-data-table-td ">Vehiclesense Inc</td><td class="patent-data-table-td ">Parking management systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2003003314A1?cl=en">WO2003003314A1</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 2002</td><td class="patent-data-table-td patent-date-value">Jan 9, 2003</td><td class="patent-data-table-td ">Citylink Melbourne Ltd</td><td class="patent-data-table-td ">Tolling information exchange method and system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2004042673A2?cl=en">WO2004042673A2</a></td><td class="patent-data-table-td patent-date-value">Nov 3, 2003</td><td class="patent-data-table-td patent-date-value">May 21, 2004</td><td class="patent-data-table-td ">Imp Vision Ltd</td><td class="patent-data-table-td ">Automatic, real time and complete identification of vehicles</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2004075121A1?cl=en">WO2004075121A1</a></td><td class="patent-data-table-td patent-date-value">Feb 19, 2004</td><td class="patent-data-table-td patent-date-value">Sep 2, 2004</td><td class="patent-data-table-td ">Accenture Global Services Gmbh</td><td class="patent-data-table-td ">Electronic toll management</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2007030446A2?cl=en">WO2007030446A2</a></td><td class="patent-data-table-td patent-date-value">Sep 6, 2006</td><td class="patent-data-table-td patent-date-value">Mar 15, 2007</td><td class="patent-data-table-td ">Rent A Toll Ltd</td><td class="patent-data-table-td ">System, method and computer readable medium for billing tolls</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Automated+highways+going+the+right+way%3F"'>Automated highways going the right way?</a>", McLeod Jonah, Electronics, Nov. 28, 1994, 67, 22.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Canadian Office Action of Application No. 2,516,675, dated Jun. 19, 2008, 4 pages.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Canadian Office Action of Application No. 2,516,675, dated Mar. 31, 2009, 6 pages.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">China Office Action of Application No. 200680027002.3 dated Jun. 26, 2009, 10 pages.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Examiner's first report on Australian patent application No. 2004213923.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">First Examination Report for Indian Ref No. 2348/CHENP/2005-CNA.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">International Preliminary Examination Report and Written Opinion for International Application No. PCT/EP2004/001644.</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">International Search and Written Opinion, PCT/IB2006/002738, dated Mar. 12, 2007.</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">International Search Report and Written Opinion for International Application No. PCTIB2006/002435.</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">International Search Report for International application No. PCT/EP2004/001644.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Notification of the first Office Action in Chinese Application No. 200480010404.3, dated Aug. 1, 2008, 27 pages.</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Search Report and Written Opinion of Application No. SG200718336-1 dated Sep. 4, 2009, 8 pages.</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Search Report and Written Opinion of Application No. SG200718365-0 dated Jul. 23, 2009, 9 pages.</td></tr><tr><td class="patent-data-table-td ">14</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Smith, L Intelligent Transportation Systems-Electronic Toll Collection [online], 3rd Jan. 2002 [retrieved on Jul. 11, 2006]. Retrieved from the Internet:&lt;URL:http://www.calccit.org/itsdecision/serv-and-tech/Electronic-toll-collection/electronic-toll-collection-rep-print.html &gt;.</td></tr><tr><td class="patent-data-table-td ">15</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Smith, L Intelligent Transportation Systems—Electronic Toll Collection [online], 3rd Jan. 2002 [retrieved on Jul. 11, 2006]. Retrieved from the Internet:&lt;URL:http://www.calccit.org/itsdecision/serv—and—tech/Electronic—toll—collection/electronic—toll—collection—rep—print.html &gt;.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8265986">US8265986</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 3, 2008</td><td class="patent-data-table-td patent-date-value">Sep 11, 2012</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method for determining carbon emission-conscious order fulfillment alternatives with multiple supply modes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8458014">US8458014</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 9, 2012</td><td class="patent-data-table-td patent-date-value">Jun 4, 2013</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method for determining carbon emission-conscious order fulfillment alternatives with multiple supply modes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8478518">US8478518</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 24, 2009</td><td class="patent-data-table-td patent-date-value">Jul 2, 2013</td><td class="patent-data-table-td ">Aisin Aw Co., Ltd.</td><td class="patent-data-table-td ">Traffic information processing system, statistical processing device, traffic information processing method, and traffic information processing program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100076801">US20100076801</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 21, 2009</td><td class="patent-data-table-td patent-date-value">Mar 25, 2010</td><td class="patent-data-table-td ">Ebay Gmarket Co., Ltd.</td><td class="patent-data-table-td ">Electronic commerce system and method for preventing fraudulent merchandise</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100088136">US20100088136</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 3, 2008</td><td class="patent-data-table-td patent-date-value">Apr 8, 2010</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method for determining carbon emission-conscious order fulfillment alternatives with multiple supply modes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100174474">US20100174474</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 24, 2009</td><td class="patent-data-table-td patent-date-value">Jul 8, 2010</td><td class="patent-data-table-td ">Aisin Aw Co., Ltd.</td><td class="patent-data-table-td ">Traffic information processing system, statistical processing device, traffic information processing method, and traffic information processing program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120310793">US20120310793</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 9, 2012</td><td class="patent-data-table-td patent-date-value">Dec 6, 2012</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method for determining carbon emission-conscious order fulfillment alternatives with multiple supply modes</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=YcZTBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc705/defs705.htm&usg=AFQjCNFzs2esjESm-KHynrEapHJvKhyIeA#C705S013000">705/13</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=YcZTBgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G07B0015060000">G07B15/06</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=YcZTBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G08G1/0175">G08G1/0175</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=YcZTBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G07B15/06">G07B15/06</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=YcZTBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G07B15/00">G07B15/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=YcZTBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q50/30">G06Q50/30</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G08G1/017A</span>, <span class="nested-value">G07B15/06</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Mar 12, 2013</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 20, 2011</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1-18, 22-27 AND 31 ARE CANCELLED. CLAIMS 19-21 AND 28-30 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 2, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110615</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 26, 2011</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:ACCENTURE GLOBAL SERVICES GMBH;REEL/FRAME:025700/0287</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100901</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">ACCENTURE GLOBAL SERVICES LIMITED, IRELAND</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 15, 2010</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 25, 2006</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">ACCENTURE GLOBAL SERVICES GMBH, SWITZERLAND</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:HEDLEY, JAY E.;THORNBURG, NEAL PATRICK;REEL/FRAME:018175/0441;SIGNING DATES FROM 20060821 TO 20060822</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">ACCENTURE GLOBAL SERVICES GMBH,SWITZERLAND</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:HEDLEY, JAY E.;THORNBURG, NEAL PATRICK;SIGNED BETWEEN 20060821 AND 20060822;US-ASSIGNMENT DATABASE UPDATED:20100309;REEL/FRAME:18175/441</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:HEDLEY, JAY E.;THORNBURG, NEAL PATRICK;SIGNING DATES FROM 20060821 TO 20060822;REEL/FRAME:018175/0441</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0IOPgkdsYyUT3q4ZH99GbRlpAkkQ\u0026id=YcZTBgABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3CQezhE0thjb7NdjvzkgvUvvmcTA\u0026id=YcZTBgABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2BTbn2iUtxTHataPlGx-uGx6Dt7g","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Electronic_toll_management.pdf?id=YcZTBgABERAJ\u0026output=pdf\u0026sig=ACfU3U1C0JMd1joQBQwUPLEboDPPl84pcQ"},"sample_url":"http://www.google.com/patents/reader?id=YcZTBgABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>