<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7693993 - Method and system for providing dynamic hosted service management across ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method and system for providing dynamic hosted service management across disparate accounts/sites"><meta name="DC.contributor" content="Kitrick B. Sheets" scheme="inventor"><meta name="DC.contributor" content="Philip S. Smith" scheme="inventor"><meta name="DC.contributor" content="Stephen J. Engel" scheme="inventor"><meta name="DC.contributor" content="Yuefan Deng" scheme="inventor"><meta name="DC.contributor" content="Joseph Guistozzi" scheme="inventor"><meta name="DC.contributor" content="Alexander Korobka" scheme="inventor"><meta name="DC.contributor" content="Galactic Computing Corporation Bvi/Ibc" scheme="assignee"><meta name="DC.date" content="2004-11-8" scheme="dateSubmitted"><meta name="DC.description" content="A hosted service provider for the Internet is operated so as to provide dynamic management of hosted services across disparate customer accounts and/or geographically distinct sites."><meta name="DC.date" content="2010-4-6" scheme="issued"><meta name="DC.relation" content="US:20030039237:A1" scheme="references"><meta name="DC.relation" content="US:20050076214:A1" scheme="references"><meta name="DC.relation" content="US:20070140242:A1" scheme="references"><meta name="DC.relation" content="US:3764747" scheme="references"><meta name="DC.relation" content="US:5031089" scheme="references"><meta name="DC.relation" content="US:5187710" scheme="references"><meta name="DC.relation" content="US:5247427" scheme="references"><meta name="DC.relation" content="US:5251097" scheme="references"><meta name="DC.relation" content="US:5351286" scheme="references"><meta name="DC.relation" content="US:5460441" scheme="references"><meta name="DC.relation" content="US:5488541" scheme="references"><meta name="DC.relation" content="US:5504894" scheme="references"><meta name="DC.relation" content="US:5537542" scheme="references"><meta name="DC.relation" content="US:5548683" scheme="references"><meta name="DC.relation" content="US:5615329" scheme="references"><meta name="DC.relation" content="US:5696895" scheme="references"><meta name="DC.relation" content="US:5745884" scheme="references"><meta name="DC.relation" content="US:5774668" scheme="references"><meta name="DC.relation" content="US:5794221" scheme="references"><meta name="DC.relation" content="US:5819092" scheme="references"><meta name="DC.relation" content="US:5828737" scheme="references"><meta name="DC.relation" content="US:5832222" scheme="references"><meta name="DC.relation" content="US:5845267" scheme="references"><meta name="DC.relation" content="US:5877938" scheme="references"><meta name="DC.relation" content="US:5899980" scheme="references"><meta name="DC.relation" content="US:5912802" scheme="references"><meta name="DC.relation" content="US:5938732" scheme="references"><meta name="DC.relation" content="US:5946670" scheme="references"><meta name="DC.relation" content="US:5948065" scheme="references"><meta name="DC.relation" content="US:5951694" scheme="references"><meta name="DC.relation" content="US:5956391" scheme="references"><meta name="DC.relation" content="US:5956697" scheme="references"><meta name="DC.relation" content="US:5974462" scheme="references"><meta name="DC.relation" content="US:5978577" scheme="references"><meta name="DC.relation" content="US:5999965" scheme="references"><meta name="DC.relation" content="US:6006259" scheme="references"><meta name="DC.relation" content="US:6014669" scheme="references"><meta name="DC.relation" content="US:6025989" scheme="references"><meta name="DC.relation" content="US:6035281" scheme="references"><meta name="DC.relation" content="US:6035356" scheme="references"><meta name="DC.relation" content="US:6067545" scheme="references"><meta name="DC.relation" content="US:6067580" scheme="references"><meta name="DC.relation" content="US:6070191" scheme="references"><meta name="DC.relation" content="US:6088727" scheme="references"><meta name="DC.relation" content="US:6092178" scheme="references"><meta name="DC.relation" content="US:6094351" scheme="references"><meta name="DC.relation" content="US:6094680" scheme="references"><meta name="DC.relation" content="US:6097882" scheme="references"><meta name="DC.relation" content="US:6108703" scheme="references"><meta name="DC.relation" content="US:6167446" scheme="references"><meta name="DC.relation" content="US:6173322" scheme="references"><meta name="DC.relation" content="US:6185598" scheme="references"><meta name="DC.relation" content="US:6374297" scheme="references"><meta name="DC.relation" content="US:6452809" scheme="references"><meta name="DC.relation" content="US:6463454" scheme="references"><meta name="DC.relation" content="US:6532488" scheme="references"><meta name="DC.relation" content="US:6606253" scheme="references"><meta name="DC.relation" content="US:6625639" scheme="references"><meta name="DC.relation" content="US:6718359" scheme="references"><meta name="DC.relation" content="US:6816903" scheme="references"><meta name="DC.relation" content="US:6816905" scheme="references"><meta name="DC.relation" content="US:6938256" scheme="references"><meta name="DC.relation" content="US:7032241" scheme="references"><meta name="DC.relation" content="US:7185112" scheme="references"><meta name="DC.relation" content="WO:2000004458:A1" scheme="references"><meta name="DC.relation" content="WO:2001067707:A2" scheme="references"><meta name="DC.relation" content="WO:2002008891:A2" scheme="references"><meta name="citation_reference" content="A New Twist On Hosting: Luminate Pitches Its Enterprise Management Services; Chris Gonsalves, PC Week Online, 2 pgs.; Mar. 2000."><meta name="citation_reference" content="ADSM: A Multi-Platform, Scalable, Backup and Archive mass Storage System; Luis-Felipe Cabrera et al.; 1063-6390/95, 1995 IEEE; pp. 420-427."><meta name="citation_reference" content="Brochure: Applicast(TM)., Applicast, Inc.; 6 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: Applicast™., Applicast, Inc.; 6 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: ChatCom&#39;s ChatterBox Products, ChatCom, Inc.; 2 pgs. Undated."><meta name="citation_reference" content="Brochure: ControlIT(TM).-Remote Control Without Boundaries, Computer Associates International, Inc.; 10 pgs.; Copyright 2000."><meta name="citation_reference" content="Brochure: ControlIT™.—Remote Control Without Boundaries, Computer Associates International, Inc.; 10 pgs.; Copyright 2000."><meta name="citation_reference" content="Brochure: Get Connected-Cable &amp; Wireless Enhanced Solutions Provider Program, Cable &amp; Wireless USA, Inc., 4 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: Get Connected—Cable &amp; Wireless Enhanced Solutions Provider Program, Cable &amp; Wireless USA, Inc., 4 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: HP Open View Customer Views 1.0 for Network Node Manager, Hewlett-Packard Company, 4 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: HP Open View, Hewlett-Packard Company, 16 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: Tivol®. Global Enterprise Manager-A Business-focused Approach to Systems Management, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Brochure: Tivol®. Global Enterprise Manager—A Business-focused Approach to Systems Management, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Brochure: Tivoli Cross-Site-Internet Application Management Technical Brief, Tivoli Systems, Inc.; 22 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: Tivoli Cross-Site—Internet Application Management Technical Brief, Tivoli Systems, Inc.; 22 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: Tivoli Problem Management Suite, Tivoli Systems, Inc.; 4 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: Tivoli Technical Brief for Service Providers, Tivoli Systems, Inc., 7 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: Tivoli® Cross-Site for Availability, Tivoli Systems, Inc.; 4 pgs.; Copyright 1999."><meta name="citation_reference" content="Brochure: Tivoli® Cross-Site for Deployment-Using the Internet as a Valuable Deployment Tool, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Brochure: Tivoli® Cross-Site for Deployment—Using the Internet as a Valuable Deployment Tool, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Brochure: Tivoli® Distributed Monitoring-Automated, Consistent Availability Solution, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Brochure: Tivoli® Distributed Monitoring—Automated, Consistent Availability Solution, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Brochure: Tivoli®. Cross-Site for Security, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Excite@Home LauncHes Free Service for Merchants, Andrea Orr, MicroTimes Magazine, plus web site print-out; 3 pgs.; Aug. 2000."><meta name="citation_reference" content="Magazine advertisment : ISP Upgrade, CAIS Software Solutions, 3 pgs.; Copyright 1999."><meta name="citation_reference" content="Management of the Access Network and Service Provisioning, Jani Hursti, Seminar in Networking, Helsinki University of Technology, 20 pgs.; Apr. 1999."><meta name="citation_reference" content="The Landlords of Cyberspace, Christopher Heun, informationweek.com; 3 pgs.; Jul. 2000."><meta name="citation_reference" content="U.S. Appl. No. 09/709,820, filed Nov. 10, 2000, Rex Jackson."><meta name="citation_reference" content="U.S. Appl. No. 09/710,095, filed Nov. 10, 2000, Kitrick Sheets."><meta name="citation_reference" content="U.S. Appl. No. 09/765,766, filed Jan. 18, 2001, Deng Yuefan."><meta name="citation_reference" content="U.S. Appl. No. 09/907,520, filed Jul. 17, 2001, Rex Jackson."><meta name="citation_reference" content="U.S. Appl. No. 10/244,450, filed Sep. 16, 2002, Rex Jackson."><meta name="citation_reference" content="U.S. Appl. No. 11/202,644, filed Aug. 12, 2005, Deng Yuefan."><meta name="citation_reference" content="U.S. PAIR File Wrapper History for U.S. Appl. No. 09/709,820, filed Nov. 10, 2000."><meta name="citation_reference" content="U.S. PAIR File Wrapper History for U.S. Appl. No. 09/710,095, filed Nov. 10, 2000."><meta name="citation_reference" content="U.S. PAIR File Wrapper History for U.S. Appl. No. 09/765,766, filed Jan. 18, 2001."><meta name="citation_reference" content="U.S. PAIR File Wrapper History for U.S. Appl. No. 09/907,520, filed Jul. 17, 2001."><meta name="citation_reference" content="U.S. PAIR File Wrapper History for U.S. Appl. No. 10/244,450, filed Sep. 16, 2002."><meta name="citation_reference" content="U.S. PAIR File Wrapper History for U.S. Appl. No. 11/202,644, filed Aug. 12, 2005."><meta name="citation_reference" content="Web site print-out Epoch Internet Introduces New ‘Pod’ Architecture, An Innovative Approach to Providing Web Hosting Services, epoch.net, Epoch Networks, Inc., 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out Epoch Internet Introduces New &#39;Pod&#39; Architecture, An Innovative Approach to Providing Web Hosting Services, epoch.net, Epoch Networks, Inc., 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out: Ascendant Solutions, Inc. Fact Sheet, Ascendant Solutions, Inc.; 4 pgs.; Copyright 1998-2000."><meta name="citation_reference" content="Web site print-out: ASP Computer Systems Corp.; Data Return Corporation, 3 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out: Cellular MultiProcessing-Breakthrough Architecture for an Open Mainframe, Unisys, 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out: Cellular MultiProcessing—Breakthrough Architecture for an Open Mainframe, Unisys, 4 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out: ClearPath Enterprise Servers-What is HMP?, Unisys, 2 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out: ClearPath Enterprise Servers—What is HMP?, Unisys, 2 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out: Comprehensive Hosting Solution for ISV s, ebaseone Corporation, 3 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out: End to End Scheduling for Tivoli.RTM. Workload Scheduler and Tivoli Operations Planning and Control, Tivoli Systems, Inc., 2 pgs. not dated."><meta name="citation_reference" content="Web site print-out: Frequently Asked Questions-Complex Web Services, USinternetworking, Inc.; 3 pgs.; Copyright 1998-1999."><meta name="citation_reference" content="Web site print-out: Frequently Asked Questions—Complex Web Services, USinternetworking, Inc.; 3 pgs.; Copyright 1998-1999."><meta name="citation_reference" content="Web site print-out: Frequently Asked Questions-Overview of PATROL®., BMC Software, Inc., 4 pgs.; Copyright 2001."><meta name="citation_reference" content="Web site print-out: Frequently Asked Questions—Overview of PATROL®., BMC Software, Inc., 4 pgs.; Copyright 2001."><meta name="citation_reference" content="Web site print-out: HP&#39;S Answer for Portal Performance-A-class Servers; Hewlett-Packard Company, 2 pgs. © 2000."><meta name="citation_reference" content="Web site print-out: HP&#39;S Answer for Portal Performance—A-class Servers; Hewlett-Packard Company, 2 pgs. © 2000."><meta name="citation_reference" content="Web site print-out: Internet Shock Absorber, Cable and Wireless plc., 5 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out: ISP Power Overview, inovaware.com, Inovaware Corporation; 2 pgs.; copyright 1997-2000."><meta name="citation_reference" content="Web site print-out: Lightspeed Systems, Corporate Overview, 3 pgs., Copyright 1999."><meta name="citation_reference" content="Web site print-out: Luminate Introduces Luminate.Net e-Service, Luminate, Inc., 2 pgs.; Copyright 2000."><meta name="citation_reference" content="Web site print-out: PATROL® for Performance Management-Prediction in Action, BMC Software, Inc., 2 pgs.; Copyright 2001."><meta name="citation_reference" content="Web site print-out: PATROL® SRM: The Foundation of Application-Centric Storage Management@, BMC Software, Inc., 2 pgs.; Copyright 2001."><meta name="citation_reference" content="Web site print-out: rackspace.com; 2 pages; Copyright 2000."><meta name="citation_reference" content="Web site print-out: Remedy AR System Integration Module for PATROL, BMC Software, Inc., 2 pages, Copyright 2001."><meta name="citation_reference" content="Web site print-out: Resonate®, Resonate, Inc.; 1 pg.; Copyright 1999."><meta name="citation_reference" content="Web site print-out: table of contents and chapter abstracts for-ISP Survival Guide: Stratetgies for Running a Competitive ISP, Geoff Huston, Wiley Computer Publishing, 16 pgs.; Oct. 1998."><meta name="citation_reference" content="Web site print-out: table of contents and chapter abstracts for—ISP Survival Guide: Stratetgies for Running a Competitive ISP, Geoff Huston, Wiley Computer Publishing, 16 pgs.; Oct. 1998."><meta name="citation_reference" content="Web site print-out: USi Complex Web Hosting Solution and Lattice Communications, Usinternetworking, Inc., 2 pgs.; not dated."><meta name="citation_reference" content="Web site print-out: White Paper: Tivoli Service Provider Solutions, Tivoli Systems, Inc.; 24 pgs.; Copyright 1999."><meta name="citation_reference" content="Web site print-out: XaCCT Offers Multivendor, Multitechnology Billing Model for ISP Consumption, John Morency, Network World Fusion on Network/Systems Management, Network World, Inc.; 3 pgs.; Sep. 1998."><meta name="citation_reference" content="Web site print-out; Coblat RaQ, Cobalt Network Systems; 2 pgs. © 2001."><meta name="citation_reference" content="White paper: IBM Netfinity X-architecture, IBM Corporation; 22 pgs.; © 1998."><meta name="citation_reference" content="White Paper: Stratus ftServers: Enhancing Software Reliability and Availability for Windows 2000, Stratus Computer Systems; 10 pgs.; Copyright 2000."><meta name="citation_reference" content="White Paper: The HP Open View Approach to Change and Configuraton Management, Hewlett-Packard Company, 23 pgs.; Copyright 1999."><meta name="citation_patent_number" content="US:7693993"><meta name="citation_patent_application_number" content="US:10/984,959"><link rel="canonical" href="http://www.google.com/patents/US7693993"/><meta property="og:url" content="http://www.google.com/patents/US7693993"/><meta name="title" content="Patent US7693993 - Method and system for providing dynamic hosted service management across disparate accounts/sites"/><meta name="description" content="A hosted service provider for the Internet is operated so as to provide dynamic management of hosted services across disparate customer accounts and/or geographically distinct sites."/><meta property="og:title" content="Patent US7693993 - Method and system for providing dynamic hosted service management across disparate accounts/sites"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("-kvsU5bkCNL8yQSBpICICw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("CAN"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("-kvsU5bkCNL8yQSBpICICw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("CAN"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7693993?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7693993"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=PG1rBgABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7693993&amp;usg=AFQjCNFshDDSS4GZqXss9v3IBP1VTSnvaw" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7693993.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7693993.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20050182838"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US7693993"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7693993" style="display:none"><span itemprop="description">A hosted service provider for the Internet is operated so as to provide dynamic management of hosted services across disparate customer accounts and/or geographically distinct sites....</span><span itemprop="url">http://www.google.com/patents/US7693993?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7693993 - Method and system for providing dynamic hosted service management across disparate accounts/sites</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7693993 - Method and system for providing dynamic hosted service management across disparate accounts/sites" title="Patent US7693993 - Method and system for providing dynamic hosted service management across disparate accounts/sites"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7693993 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 10/984,959</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Apr 6, 2010</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Nov 8, 2004</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Nov 10, 2000</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6816905">US6816905</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8316131">US8316131</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20050182838">US20050182838</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20100268827">US20100268827</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20130238801">US20130238801</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">10984959, </span><span class="patent-bibdata-value">984959, </span><span class="patent-bibdata-value">US 7693993 B2, </span><span class="patent-bibdata-value">US 7693993B2, </span><span class="patent-bibdata-value">US-B2-7693993, </span><span class="patent-bibdata-value">US7693993 B2, </span><span class="patent-bibdata-value">US7693993B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Kitrick+B.+Sheets%22">Kitrick B. Sheets</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Philip+S.+Smith%22">Philip S. Smith</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Stephen+J.+Engel%22">Stephen J. Engel</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Yuefan+Deng%22">Yuefan Deng</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Joseph+Guistozzi%22">Joseph Guistozzi</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Alexander+Korobka%22">Alexander Korobka</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Galactic+Computing+Corporation+Bvi/Ibc%22">Galactic Computing Corporation Bvi/Ibc</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7693993.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7693993.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7693993.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (67),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (73),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (12),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (12),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (3)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7693993&usg=AFQjCNEIZcDnjkW6HwjyxTNrp8obU4iHkg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7693993&usg=AFQjCNFgzYYH920GNJym_aLVFnzAbqOWOA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7693993B2%26KC%3DB2%26FT%3DD&usg=AFQjCNESiODSc4Yx_3i9-4cfxklWxqZXnw">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT94677080" lang="EN" load-source="patent-office">Method and system for providing dynamic hosted service management across disparate accounts/sites</invention-title></span><br><span class="patent-number">US 7693993 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA76520349" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">A hosted service provider for the Internet is operated so as to provide dynamic management of hosted services across disparate customer accounts and/or geographically distinct sites.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(14)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7693993B2/US07693993-20100406-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7693993B2/US07693993-20100406-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(28)</span></span></div><div class="patent-text"><div mxw-id="PCLM31464543" lang="EN" load-source="patent-office" class="claims">
  <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
    <div class="claim-text">1. A method for automatically allocating computing resources of a rack-and-blade computer assembly comprising:
<div class="claim-text">receiving server performance information from an application server pool disposed in a rack of a rack-and-blade computer assembly;</div>
<div class="claim-text">determining at least one QoS attribute for the application server pool;</div>
<div class="claim-text">determining that the QoS attribute is below a standard; and allocating a blade server from a free server pool for use by the application server pool.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
    <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, additionally comprising selecting, prior to allocating for use, a blade server from a free server pool to obtain a selected blade server.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
    <div class="claim-text">3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, additionally comprising reconfiguring a traffic management device associated with the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
    <div class="claim-text">4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, additionally comprising preparing, prior to allocating for use, the selected blade server for operation with the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
    <div class="claim-text">5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, additionally comprising reconfiguring a traffic management device associated with the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
    <div class="claim-text">6. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, additionally comprising reconfiguring a traffic management device associated with the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
    <div class="claim-text">7. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, additionally comprising provisioning images onto at least one blade server of the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
    <div class="claim-text">8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, additionally comprising monitoring the performance of at least one blade server of the application server pool from information received by a server agent associated with the blade server.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
    <div class="claim-text">9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, additionally comprising removing the use of at least one blade server from the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
    <div class="claim-text">10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, additionally comprising determining a relative performance of another application server pool.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00011" num="00011" class="claim">
    <div class="claim-text">11. A method for automatically allocating computing resources of a rack-and-blade computer assembly comprising:
<div class="claim-text">receiving server performance information from an application server pool disposed in a rack of a rack-and-blade computer assembly;</div>
<div class="claim-text">determining at least one QoS attribute for the application server pool;</div>
<div class="claim-text">determining that the QoS attribute is above a standard; and</div>
<div class="claim-text">removing the use of a blade server from the application server pool.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
    <div class="claim-text">12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, additionally comprising allocating the use of the removed blade server for use by a free server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
    <div class="claim-text">13. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, additionally comprising provisioning images onto at least one blade server of the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
    <div class="claim-text">14. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, additionally comprising monitoring the performance of at least one blade server of the application server pool from information received by a server agent associated with the blade server.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00015" num="00015" class="claim">
    <div class="claim-text">15. A method for automatically allocating computing resources of a rack-and-blade computer assembly comprising:
<div class="claim-text">receiving server performance information from an application server pool disposed in a rack of a rack-and-blade computer assembly;</div>
<div class="claim-text">determining at least one QoS attribute for the application server pool;</div>
<div class="claim-text">determining that the QoS attribute is below a standard;</div>
<div class="claim-text">determining that a free server pool has a blade server for use; and</div>
<div class="claim-text">selecting from the free server pool the available blade server for use by the application server pool.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
    <div class="claim-text">16. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, additionally comprising installing software on the selected available blade server.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
    <div class="claim-text">17. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, additionally comprising configuring the selected available blade server.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
    <div class="claim-text">18. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, additionally comprising readying the selected available blade server for operation.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
    <div class="claim-text">19. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, additionally comprising configuring the selected available blade server.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
    <div class="claim-text">20. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, additionally comprising readying the selected available blade server for operation.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
    <div class="claim-text">21. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, additionally comprising reconfiguring a traffic management device associated with the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
    <div class="claim-text">22. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, additionally comprising provisioning images onto at least one blade server of the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
    <div class="claim-text">23. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, additionally comprising monitoring the performance of at least one blade server of the application server pool from information received by a server agent associated with the blade server.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00024" num="00024" class="claim">
    <div class="claim-text">24. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, additionally comprising removing the use of at least one blade server from the application server pool.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00025" num="00025" class="claim">
    <div class="claim-text">25. The method of <claim-ref idref="CLM-00015">claim 15</claim-ref>, additionally comprising determining a relative performance of another application server pool.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00026" num="00026" class="claim">
    <div class="claim-text">26. An article of manufacture comprising:
<div class="claim-text">a machine-readable storage medium having stored thereon instructions for:
<div class="claim-text">receiving server performance information from an application server pool disposed in a rack of a rack-and-blade computer assembly;</div>
<div class="claim-text">determining at least one QoS attribute for the application server pool;</div>
<div class="claim-text">determining that the QoS attribute is above a standard; and</div>
<div class="claim-text">removing the use of a blade server from the application server pool.</div>
</div>
</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00027" num="00027" class="claim">
    <div class="claim-text">27. An article of manufacture comprising:
<div class="claim-text">a machine-readable storage medium having stored thereon instructions for:
<div class="claim-text">receiving server performance information from an application server pool disposed in a rack of a rack-and-blade computer assembly;</div>
<div class="claim-text">determining at least one QoS attribute for the application server pool;</div>
<div class="claim-text">determining that the QoS attribute is above a standard; and</div>
<div class="claim-text">removing the use of a blade server from the application server pool.</div>
</div>
</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00028" num="00028" class="claim">
    <div class="claim-text">28. An article of manufacture comprising:
<div class="claim-text">a machine-readable storage medium having stored thereon instructions for:
<div class="claim-text">receiving server performance information from an application server pool disposed in a rack of a rack-and-blade computer assembly;</div>
<div class="claim-text">determining at least one QoS attribute for the application server pool;</div>
<div class="claim-text">determining that the QoS attribute is below a standard;</div>
<div class="claim-text">determining that a free server pool has a blade server for use; and</div>
<div class="claim-text">selecting from the free server pool the available blade server for use by the application server pool.</div>
</div>
</div>
  </div>
</div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES36909775" lang="EN" load-source="patent-office" class="description">
<heading>CLAIM TO PRIORITY</heading> <p num="p-0002">The present application is a continuation application of U.S. patent application Ser. No. 09/710,095, filed Nov. 10, 2000, now U.S. Pat. No. 6,816,905 entitled, “Method and System for Providing Dynamic Hosted Service Management Across Disparate Account/Sites,” the contents of which is hereby incorporated by reference in its entirety.</p>
<heading>FIELD OF THE INVENTION</heading> <p num="p-0003">The present invention relates generally to the field of data processing business practices. More specifically, the present invention relates to a method and system for providing dynamic management of hosted services across disparate customer accounts and/or geographically distinct sites.</p>
  <heading>BACKGROUND OF THE INVENTION</heading> <p num="p-0004">The explosive growth of the Internet has been driven to a large extent by the emergence of commercial service providers and hosting facilities, such as Internet Service Providers (ISPs), Application Service Providers (ASPs), Independent Software Vendors (ISVs), Enterprise Solution Providers (ESPs), Managed Service Providers (MSPs) and the like. Although there is no clear definition of the precise set of services provided by each of these businesses, generally these service providers and hosting facilities provide services tailored to meet some, most or all of a customer's needs with respect to application hosting, site development, e-commerce management and server deployment in exchange for payment of setup charges and periodic fees. In the context of server deployment, for example, the fees are customarily based on the particular hardware and software configurations that a customer will specify for hosting the customer's application or website. For purposes of this invention, the term “hosted services” is intended to encompass the various types of these services provided by this spectrum of service providers and hosting facilities. For convenience, this group of service providers and hosting facilities shall be referred to collectively as Hosted Service Providers (HSPs).</p>
  <p num="p-0005">Commercial HSPs provide users with access to hosted applications on the Internet in the same way that telephone companies provide customers with connections to their intended caller through the international telephone network. The computer equipment that HSPs use to host the applications and services they provide is commonly referred to as a server. In its simplest form, a server can be a personal computer that is connected to the Internet through a network interface and that runs specific software designed to service the requests made by customers or clients of that server. For all of the various delivery models that can be used by HSPs to provide hosted services, most HSPs will use a collection of servers that are connected to an internal network in what is commonly referred to as a “server farm,” with each server performing unique tasks or the group of servers sharing the load of multiple tasks, such as mail server, web server, access server, accounting and management server. In the context of hosting websites, for example, customers with smaller websites are often aggregated onto and supported by a single web server. Larger websites, however, are commonly hosted on dedicated web servers that provide services solely for that site. For general background on the Internet and HSPs, refer to Geoff Huston, <i>ISP Survival Guide: Strategies For Running A Competitive ISP</i>, (1999).</p>
  <p num="p-0006">As the demand for Internet services has increased, there has been a need for ever-larger capacity to meet this demand. One solution has been to utilize more powerful computer systems as servers. Large mainframe and midsize computer systems have been used as servers to service large websites and corporate networks. Most HSPs tend not to utilize these larger computer systems because of the expense, complexity, and lack of flexibility of such systems. Instead, HSPs have preferred to utilize server farms consisting of large numbers of individual personal computer servers wired to a common Internet connection or bank of modems and sometimes accessing a common set of disk drives. When an HSP adds a new hosted service customer, for example, one or more personal computer servers are manually added to the HSP server farm and loaded with the appropriate software and data (e.g., web content) for that customer. In this way, the HSP deploys only that level of hardware required to support its current customer level. Equally as important, the HSP can charge its customers an upfront setup fee that covers a significant portion of the cost of this hardware. By utilizing this approach, the HSP does not have to spend money in advance for large computer systems with idle capacity that will not generate immediate revenue for the HSP. The server farm solution also affords an easier solution to the problem of maintaining security and data integrity across different customers than if those customers were all being serviced from a single larger mainframe computer. If all of the servers for a customer are loaded only with the software for that customer and are connected only to the data for that customer, security of that customer's information is insured by physical isolation.</p>
  <p num="p-0007">For HSPs, numerous software billing packages are available to account and charge for these metered services, such as XaCCT from rens.com and HSP Power from inovaware.com. Other software programs have been developed to aid in the management of HSP networks, such as IP Magic from lightspeedsystems.com, Internet Services Management from resonate.com and MAMBA from luminate.com. The management and operation of an HSP has also been the subject of articles and seminars, such as Hursti, Jani, “Management of the Access Network and Service Provisioning,” Seminar in Internetworking, Apr. 19, 1999. An example of a typical HSP offering various configurations of hardware, software, maintenance and support for providing commercial levels of Internet access and website hosting at a monthly rate can be found at rackspace.com.</p>
  <p num="p-0008">Up to now, there have been two approaches with respect to the way in which HSPs built their server farms. One approach is to use an homogenous group of personal computer systems (hardware and software) supplied from a single manufacturer. The other approach is to use personal computer systems supplied from a number of different manufacturers. The homogeneous approach affords the HSP advantages in terms of only having to support a single server platform, but at the same time it restricts the HSP to this single server platform. The heterogeneous approach using systems supplied from different manufacturers is more flexible and affords the HSP the advantage of utilizing the most appropriate server hardware and software platform for a given customer or task, but this flexibility comes at the cost of increased complexity and support challenges associated with maintaining multiple server platforms.</p>
  <p num="p-0009">Regardless of which approach is used to populate a server farm, the actual physical management of such server farms remains generally the same. When a customer wants to increase or decrease the amount of services being provided for their account, the HSP will manually add or remove a server to or from that portion of the HSP server farm that is directly cabled to the data storage and network interconnect of that client's website. In the case where services are to be added, the typical process would be some variation of the following: (a) an order to change service level is received from a hosted service customer, (b) the HSP obtains new server hardware to meet the requested change, (c) personnel for the HSP physically install the new server hardware at the site where the server farm is located, (d) cabling for the new server hardware is added to the data storage and network connections for that site, (e) software for the server hardware is loaded onto the server and personnel for the HSP go through a series of initialization steps to configure the software specifically to the requirements of this customer account, and (f) the newly installed and fully configured server joins the existing administrative group of servers providing hosted service for the customer's account. In either case, each server farm is assigned to a specific customer and must be configured to meet the maximum projected demand for services from that customer account.</p>
  <p num="p-0010">Originally, it was necessary to reboot or restart some or all of the existing servers in an administrative group for a given customer account in order to allow the last step of this process to be completed because pointers and tables in the existing servers would need to be manually updated to reflect the addition of a new server to the administrative group. This requirement dictated that changes in server hardware could only happen periodically in well-defined service windows, such as late on a Sunday night. More recently, software, such as Microsoft Windows 2000®, Microsoft® Cluster Server, Oracles® Parallel Server, Windows® Network Load Balancing Service (NLB), and similar programs have been developed and extended to automatically allow a new server to join an existing administrative group at any time rather than in these well-defined windows.</p>
  <p num="p-0011">An example of how a new server can automatically join an existing administrative group is described in U.S. Pat. No. 5,951,694. In this patent, all of the servers in an administrative group are represented in a mapping table maintained by a gateway server. The mapping table identifies different service groups for the administrative group, such as mail service group, database service group, access server group, etc. The gateway server routes requests for the administrative group to the appropriate service group based on the mapping table. A new server may be added to one of the service groups by loading the appropriate software component on that server, after which the gateway server will recognize the new server and add it to the mapping table and bring the new server up to speed with the rest of the servers in that service group using a transaction log maintained for each service group. Alternatively, if one service group is experiencing a heavy workload and another service group is lightly loaded, it is possible to switch a server from one service group to another. The patent describes a software routine executing on a dedicated administrative server that uses a load balancing scheme to modify the mapping table to ensure that requests for that administrative group are more evenly balanced among the various service groups that make up the administrative group.</p>
  <p num="p-0012">Numerous patents have described techniques for workload balancing among servers in a single cluster or administrative groups. U.S. Pat. No. 6,006,529 describes software clustering that includes security and heartbeat arrangement under control of a master server, where all of the cluster members are assigned a common IP address and load balancing is preformed within that cluster. U.S. Pat. Nos. 5,537,542, 5,948,065 and 5,974,462 describe various workload-balancing arrangements for a multi-system computer processing system having a shared data space. The distribution of work among servers can also be accomplished by interposing an intermediary system between the clients and servers. U.S. Pat. No. 6,097,882 describes a replicator system interposed between clients and servers to transparently redirect IP packets between the two based on server availability and workload.</p>
  <p num="p-0013">Various techniques have also been used to coordinate the operation of multiple computers or servers in a single cluster. U.S. Pat. No. 6,014,669 describes cluster operation of multiple servers in a single cluster by using a lock-step distributed configuration file. U.S. Pat. No. 6,088,727 describes cluster control in a shared data space multi-computer environment. Other patents have described how a single image of the input/output space can be used to coordinate multiple computers. U.S. Pat. No. 5,832,222 describes how a single image of the input/output space can be used to coordinate geographically dispersed computer systems. U.S. Pat. No. 6,067,545 describes a distributed file system with shared metadata management, replicated configuration database and domain load balancing, that allows for servers to fall into and out of a single domain under control of the configuration database.</p>
  <p num="p-0014">While these approaches have improved the management of servers within administrative groups, domains or shared data spaces, there is no capability to extend these techniques beyond the group of servers defined for and linked to a common operating system or common shared data space. Generally, this limitation has not been considered a problem because all of these approaches are directed to larger enterprise computing systems that are managed and implemented within the computer network of a single company. Even though these approaches can be put into use by an HSP to manage the servers assigned to a particular account for a given client or customer, none of these approaches allow an HSP to manage a set of servers providing hosted services to multiple accounts for different clients or customers.</p>
  <p num="p-0015">Systems for managing the operation of larger enterprise computing systems also have been developed, such as OpenView from Hewlett-Packard®, Unicenter TNG® from Computer Associates, Tivoli® from IBM, Mamba from Luminate, and Patrol from BMC Software, Inc. Generally, these systems are focused on inventory management and software deployment control issues encountered with very large numbers of computers operating within a single company or organization. Some of these operation management systems include performance monitoring solutions that query the performance of servers within the organization over the network to determine the need for additional resources or load redistribution. A similar over-the-network approach is also used to provide centralized reporting and management features. A good example of this type of operation management system that is intended to be used by HSPs is the Tivoli Service Delivery Management platform that consists of a user administration module, a software distribution module, an inventory module, an enterprise console, a security module, an enterprise manager module that provides a customizable view of all of the components in a network once they are added to the network, and a workload scheduler that allows workload to be balanced among servers sharing a common data space. All of these modules operate using an over-the-network communication scheme involving agents on the various nodes in the network that collect and report status and incident information to the other modules. Once the hardware components for a new node are physically added to the network, the various modules of the Tivoli Service Delivery Management platform can take over and manage those components on a more automatic basis. However, the process of physically adding hardware for a new node into the network remains essentially a manual process that is accomplished in the same manner as previously described.</p>
  <p num="p-0016">In terms of managing the physical hardware that makes up the computer system, various approaches have been developed to automatically compensate for the failure of a hardware component within a computer network. U.S. Pat. No. 5,615,329 describes a typical example of a redundant hardware arrangement that implements remote data shadowing using dedicated separate primary and secondary computer systems where the secondary computer system takes over for the primary computer system in the event of a failure of the primary computer system. The problem with these types of mirroring or shadowing arrangements is that they can be expensive and wasteful, particularly where the secondary computer system is idled in a standby mode waiting for a failure of the primary computer system. U.S. Pat. No. 5,696,895 describes one solution to this problem in which a series of servers each run their own tasks, but each is also assigned to act as a backup to one of the other servers in the event that server has a failure. This arrangement allows the tasks being performed by both servers to continue on the backup server, although performance will be degraded. Other examples of this type of solution include the Epoch Point of Distribution (POD) server design and the USI Complex Web Service. The hardware components used to provide these services are predefined computing pods that include load-balancing software, which can also compensate for the failure of a hardware component within an administrative group. Even with the use of such predefined computing pods, the physical preparation and installation of such pods into an administrative group can take up to a week to accomplish.</p>
  <p num="p-0017">All of these solutions can work to automatically manage and balance workloads and route around hardware failures within an administrative group based on an existing hardware computing capacity; however, few solutions have been developed that allow for the automatic deployment of additional hardware resources to an administrative group. If the potential need for additional hardware resources within an administrative group is known in advance, the most common solution is to preconfigure the hardware resources for an administrative group based on the highest predicted need for resources for that group. While this solution allows the administrative group to respond appropriately during times of peak demand, the extra hardware resources allocated to meet this peak demand are underutilized at most other times. As a result, the cost of providing hosted services for the administrative group is increased due to the underutilization of hardware resources for this group.</p>
  <p num="p-0018">One solution to the need for additional hosted services is the Internet Shock Absorber (ISA) service offered by Cable &amp; Wireless. The ISA service distributes a customer's static Web content to one or more caching servers located at various Points of Presence (POPs) on the Cable &amp; Wireless Internet backbone. Requests for this static Web content can be directed to be caching servers and the various POP locations to offload this function from the servers in the administrative group providing hosted service for that customer. The caching of static Web content, however, is something that occurs naturally as part of the distribution of information over the Internet. Where a large number of users are requesting static information from a given IP address, it is common to cache this information at multiple locations on the Internet. In essence, the ISA service allows a customer to proactively initiate the caching of static Web content on the Internet. While this solution has the potential to improve performance for delivery of static Web content, this solution is not applicable to the numerous other types of hosted services that involve interactive or dynamic information content.</p>
  <p num="p-0019">Although significant enhancements have been made to the way that HSPs are managed, and although many programs and tools have been developed to aid in the operation of HSP networks, the basic techniques used by HSPs to create and maintain the physical resources of a server farm have changed very little. It would be desirable to provide a more efficient way of operating an HSP that could improve on the way in which physical resources of the server farm are managed.</p>
  <heading>SUMMARY OF THE INVENTION</heading> <p num="p-0020">The present invention is a method and system for operating a hosted service provider for the Internet in such a way as to provide dynamic management of hosted services across disparate customer accounts and/or geographically distinct sites. For each of a plurality of customer accounts, a plurality of individual servers are allocated to a common administrative group defined for that customer account. Each administrative group is configured to access software and data unique to that customer account for providing hosted services to the Internet for that customer account. The system automatically monitors the performance and health of the servers in each administrative group. At least one server from a first administrative group is automatically and dynamically reallocated to a second administrative group in response to the automatic monitoring. The automatic and dynamic reallocation of servers is accomplished by setting initialization pointers for the reallocated servers to access software and data unique to the customer account for the second administrative group, and then reinitializing the reallocated servers such that they join the second administrative group when restarted. Preferably, the performance and health of the servers in each administrative group are monitored over a separate out-of-band communication channel dedicated to interconnecting the servers across administrative groups. Each administrative group includes a local decision software program that communicates with a master decision software program that determines when and how to dynamically reallocate servers to different administrative groups in response to usage demands, available resources and service level agreements with each customer account.</p>
  <p num="p-0021">In one embodiment, a system for providing the dynamic management of hosted services for multiple customer accounts includes at least five servers operably connected to an intranet. Each server includes host management circuitry providing a communication channel with at least one of the other servers that is separate from this intranet. At least four of the servers execute a local decision software program that monitors the server and communicates status information across the communication channel. At least two of the servers are allocated to a first administrative group for a first customer account and configured to access software and data unique to this first customer account, such that hosted services are provided via the Internet for this customer account. At least two of the other servers are allocated to a second administrative group for a second customer account and configured to access software and data unique to this second customer account, such that hosted services are provided via the Internet for this customer account. Preferably, at least one of the servers executes a master decision software program that collects status information from the other servers and dynamically reallocates at least one server from the first administrative group to the second administrative group in response to at least the status information.</p>
  <p num="p-0022">Unlike existing load balancing systems that are limited to working within the context of a single customer account or that require large and expensive computer systems and common operating systems or shared data spaces, the present invention is capable of dynamically reallocating servers across multiple disparate customer accounts to provide hosted services with a more economical and flexible server farm arrangement. The ability of the present invention to support multiple administrative groups for multiple customers allows for an intelligent and dynamic allocation of server resources among different customer accounts.</p>
<description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0023"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a simplified block diagram of a prior art arrangement of a server farm for a hosted service provider.</p>
    <p num="p-0024"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a graphic representation of Internet traffic in relation to server capacity for a prior art server farm hosting multiple customer accounts.</p>
    <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a simplified block diagram of the arrangement of a server farm in accordance with the present invention.</p>
    <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a simplified block diagram similar to <figref idrefs="DRAWINGS">FIG. 3</figref> showing the dynamic reallocation of servers from a first customer account to a second customer account to address a hardware failure.</p>
    <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a simplified block diagram similar to <figref idrefs="DRAWINGS">FIG. 3</figref> showing the dynamic reallocation of servers from a first customer account to a second customer account to address an increased usage demand.</p>
    <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a block diagram of a preferred embodiment of the components of a server farm in accordance with the present invention.</p>
    <p num="p-0029"> <figref idrefs="DRAWINGS">FIG. 7</figref> is an exploded perspective view of a preferred embodiment of the hardware for the server farm in accordance with the present invention.</p>
    <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a block diagram showing the hierarchical relation of the various software layers utilized by the present invention for a given customer account.</p>
    <p num="p-0031"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a block diagram of an embodiment of the present invention implemented across geographically disparate sites.</p>
    <p num="p-0032"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a graphic representation of Internet traffic in relation to server capacity for the server farm of the present invention when hosting multiple customer accounts.</p>
    <p num="p-0033"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a block diagram showing a preferred embodiment of the master decision software program of the present invention.</p>
    <p num="p-0034"> <figref idrefs="DRAWINGS">FIG. 12</figref> is a graphic representation of three different service level agreement arrangements for a given customer account.</p>
    <p num="p-0035"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a graphic representation of Internet traffic in relation to server capacity for a multi-site embodiment of the present invention.</p>
    <p num="p-0036"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a block diagram showing the master decision software program controlling the network switch and storage unit connections.</p>
    <p num="p-0037"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a block diagram of the preferred embodiment of the local decision software program.</p>
    <p num="p-0038"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a graphic representation of the workload measurements from the various measurement modules of the local decision software program under varying load conditions.</p>
    <p num="p-0039"> <figref idrefs="DRAWINGS">FIG. 17</figref> is a graphic representation of a decision surface generated by the local decision software program to request or remove a server from an administrative group.</p>
  </description-of-drawings> <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p num="p-0040">Referring to <figref idrefs="DRAWINGS">FIG. 1</figref>, a simplified functional view of an existing server farm <b>20</b> for a hosted service provider is shown. Such server farms are normally constructed using off-the-shelf hardware and software components statically configured to support the hosted service requirements of a given customer account. In this embodiment, the server farm <b>20</b> for the hosted server provider is supporting hosted services for four different customer accounts. The server farm <b>20</b> is connected to the Internet <b>22</b> by network switches/routers <b>24</b>. The network switches <b>24</b> are in turn connected to internal network switches/routers <b>26</b> that form an intranet among the front-end/content servers <b>28</b> and back-end/compute servers <b>30</b> for a given customer account. All front-end/content servers <b>28</b> and back-end/compute servers <b>30</b> are connected to disk systems <b>32</b> containing data and software unique to that customer account. Depending upon the physical nature of the hardware for the servers <b>28</b>, <b>30</b>, the disk systems <b>32</b> may be included within the server housing, or the disk systems <b>32</b> may be housed in physically separate units directly connected to each of the servers <b>28</b>, <b>30</b> or attached to more than one server <b>28</b>, <b>30</b> as a storage attached network (SAN) or network attached storage (NAS) configuration.</p>
  <p num="p-0041">While this arrangement makes good use of off-the-shelf hardware to construct a server farm <b>20</b> that can provide hosted services for multiple independent customer accounts, there are several significant issues exposed in this type of an arrangement. The most significant of these is the generally static nature of the allocation and deployment of system resources among different customer accounts. In order to configure and manage a single customer account within this complex, an administrator for the HSP needs to dedicate some fixed level of system resources (e.g., servers, disks, network links) to the particular customer account based on projected requirements of that customer's needs.</p>
  <p num="p-0042">For example, assume a relatively simple website has been designed for any given customer account such that under a projected peak load the customer account may require three front-end servers <b>28</b> to handle user requests and a quad processor back-end server <b>30</b> to handle database queries/updates generated by these requests. For this type of website, it is likely that hardware-based technology such as f5® Big-IP®, Cisco Local Director, or Foundry® ServerIron™, or a software-based solution such as Windows® Load Balance Service (WLBS) or equivalent will be used to distribute the user requests evenly across the front-end/content servers <b>28</b>. In addition, the back-end database/compute server <b>30</b> will commonly be clustered to provide some level of fault tolerance. There are a number of software products available, such as Microsoft® Cluster Server, Oracle® Parallel Server, etc., that allow websites with multiple servers to ride through hardware failures that might occur during normal operation. In addition, system monitoring tools such as Tivoli® Enterprise, HP® OpenView, etc., allow administrators to be notified when failures are detected within the server farm <b>20</b>. Although these tools can be adequate for managing the hosted services within a single customer account at a given site, none of these tools allow for the management of hosted services across disparate customer accounts.</p>
  <p num="p-0043">In the context of this example, assume that the website for this customer account is an e-commerce site designed to handle a peak load of 5000 transactions per minute. Further, assume that the websites for the remaining customer accounts in the server farm <b>20</b> have been designed to handle peak loads of 10,000, 15,000 and 5,000 transactions per minute, respectively. As shown in <figref idrefs="DRAWINGS">FIG. 2</figref>, having to design and configure each customer account to handle an anticipated peak load likely results in significant wasted capacity within the overall server farm <b>20</b>. Even though the server farm <b>20</b> handling multiple customer accounts may have excess aggregate capacity, this extra capacity cannot be used to respond to hardware failures or unexpected increases in peak load from one account to the next. Resources configured for a particular customer account are dedicated to that account and to that account only. In the event that one of the front-end servers <b>28</b> for a first customer account experiences a hardware failure, Web traffic will be routed to the remaining front-end servers <b>28</b>. If the customer account was busy before the hardware failure and Web traffic remains constant or increases after the failure, the remaining front-end servers <b>28</b> will quickly become overloaded by servicing their previous workload as well as the additional traffic redirected from the failed server. In a best case scenario, the system management software for the server farm <b>20</b> would notice that a server had failed and send a message to a site manager (via pager and/or e-mail) indicating the server failure. If the site manager receives the message in a timely manner and is located on-site, the site manager can physically remove the failed hardware component, install a spare hardware component that has hopefully been stockpiled for this purpose, recable the new hardware component, configure and install the appropriate software for that customer account, and allow the new hardware component to rejoin the remaining front-end servers <b>28</b>. Hopefully, this process could be accomplished in less than an hour. If the message is not received in a timely manner, if the site manager is not located at the site where the server farm is located, or if there is no stockpiled spare hardware available to replace the failed unit, this process will take even longer. In the meantime, response times for users accessing the customer account are degraded and the customer account becomes increasingly vulnerable to another hardware failure during this period.</p>
  <p num="p-0044">In the event that the customer account experiences an increase in demand above the anticipated peak demand for which that customer account has been configured, there are no resources available to the load balancing facilities for redistributing this increased Web traffic. All of the servers <b>28</b>, <b>30</b> would be operating at peak capacity. The result is significantly degraded response times for the customer account and a possibility of “service unavailable” responses for requests that cannot be handled in a timely manner. While the inability to provide services to consumers in a timely manner is an undesirable, but perhaps manageable, problem for a business in other contexts, the additional problem of generating “service unavailable” messages for a website is that, if such messages continue to persist for whatever reason, the Internet may begin to propagate this information to numerous intermediary nodes in the network. As a result, these intermediary nodes will divert subsequent requests to the website due to their understanding that the website is “unavailable.” Not only are the customers who receive the “service unavailable” message not serviced, but many other customers may never even get to the website once the customer account becomes saturated or overloaded.</p>
  <p num="p-0045">Referring now to <figref idrefs="DRAWINGS">FIG. 3</figref>, a server farm <b>40</b> for providing dynamic management of hosted services to multiple customer accounts will be described. As with existing server farms <b>20</b>, the server farm <b>40</b> includes network switches <b>44</b> to establish interconnection between the server farm <b>40</b> and the Internet <b>22</b>. Unlike existing server farm <b>20</b>, however, a population of servers <b>46</b> are managed under control of an engine group manager <b>48</b>. Each of the servers <b>46</b> is a stateless computing device that is programatically connected to the Internet via the network switches <b>44</b> and to a disk storage system <b>50</b>. In one embodiment, the servers <b>46</b> are connected to the disk storage system <b>50</b> via a Fibre Channel storage area network (SAN). Alternatively, the servers <b>46</b> may be connected to the disk storage system <b>50</b> via a network attached storage (NAS) arrangement, a switchable crossbar arrangement or any similar interconnection technique.</p>
  <p num="p-0046">As shown in <figref idrefs="DRAWINGS">FIGS. 4 and 5</figref>, the engine group manager <b>48</b> is responsible for automatically allocating the stateless servers <b>46</b> among multiple customer accounts and then configuring those servers for the allocated account. This is done by allocating the servers for a given customer account to a common administrative group <b>52</b> defined for that customer account and configured to access software and data unique to that customer account. As will be described, the engine group manager <b>48</b> automatically monitors each administrative group and automatically and dynamically reallocates servers <b>46</b>′ from a first administrative group <b>52</b>-<i>a </i>to a second administrative group <b>52</b>-<i>b </i>in response to the automatic monitoring. This is accomplished by using the engine group manager <b>48</b> to set initialization pointers for the reallocated servers <b>46</b>′ from the first administrative group <b>52</b>-<i>a </i>to access software and data unique to the customer account for the second administrative group <b>52</b>-<i>b</i>, and then reinitializing the reallocated servers <b>46</b>′ such that reallocated servers <b>46</b>′ join the second administrative group <b>52</b>-<i>b</i>. Unlike the existing process for adding or removing hardware resources to a server farm <b>20</b>, the present invention can make a reallocated server <b>46</b>′ available to a new administrative group <b>52</b> in as little as a few minutes. Basically, the only significant time required to bring the reallocated server <b>46</b>′ online will be the time required to reboot the server <b>46</b>′ and any time required for the load-balancing and/or clustering software to recognize this rebooted server. It will be understood that load-balancing software is more typically found in connection with front-end/content servers, whereas clustering software or a combination of clustering software and load-balancing software are more typically used in connection with back-end/compute servers. The term load-balancing software will be used to refer to any of these possible combinations.</p>
  <p num="p-0047">In one embodiment, the reallocated servers <b>46</b>′ automatically join the second administrative group because the software for the second administrative group <b>52</b>-<i>b </i>includes load-balancing software that will automatically add or remove a server from that administrative group in response to the server being brought online (i.e., reset and powered on) or brought off-line (i.e., reset and powered off). As previously described, this kind of load-balancing software is widely known and available today; however, existing load-balancing software is only capable of adding or removing servers from a single administrative group. In this embodiment, the engine group manager <b>48</b> takes advantage of capabilities of currently available commercial load-balancing application software to allow for the dynamic reallocation servers <b>46</b>′ across different administrative groups <b>52</b>. Alternatively, agents or subroutines within the operating system software for the single administrative group could be responsible for integrating a reallocated server <b>46</b>′ into the second administrative group <b>52</b>-<i>b </i>once the reallocated server <b>46</b>′ is brought online. In still another embodiment, the engine group manager <b>48</b> could publish updates to a listing of available servers for each administrative group <b>52</b>.</p>
  <p num="p-0048">Preferably, the engine group manager <b>48</b> will set pointers in each of the servers <b>46</b> for an administrative group <b>52</b> to an appropriate copy of the boot image software and configuration files, including operating system an application programs, that had been established for that administrative group <b>52</b>. When a reallocated server <b>46</b>′ is rebooted, its pointers have been reset by the engine group manager <b>48</b> to point to the boot image software and configuration files for the second administrative group <b>52</b>-<i>b</i>, instead of the boot image software and configuration files for the first administrative group <b>52</b>-<i>a. </i> </p>
  <p num="p-0049">In general, each administrative group <b>52</b> represents the website or similar hosted services being provided by the server farm <b>40</b> for a unique customer account. Although different customer accounts could be paid for by the same business or by a related commercial entity, it will be understood that the data and software associated with a given customer account, and therefore with a given administrative group <b>52</b>, will be unique to that customer account. Unlike service providers which utilize large mainframe computer installations to provide hosted services to multiple customers by using a single common operating system to implement timesharing of the resources of the large mainframe computer system, each administrative group <b>52</b> consists of unique software, including conventional operating system software, that does not extend outside servers <b>46</b> which have been assigned to the administrative group <b>52</b>. This distributed approach of the present invention allows for the use of simpler, conventional software applications and operating systems that can be installed on relatively inexpensive, individual servers. In this way, the individual elements that make up an administrative group <b>52</b> can be comprised of relatively inexpensive commercially available hardware servers and standard software programs.</p>
  <p num="p-0050"> <figref idrefs="DRAWINGS">FIGS. 6 and 7</figref> show a preferred embodiment of the components and hardware for the server farm <b>40</b> in accordance with the present invention. Although the preferred embodiment of the present invention is described with respect to this hardware, it will be understood that the concept of the present invention is equally applicable to a server farm implemented using all conventional servers, including the currently available <b>1</b>U or <b>2</b>U packaged servers, if those servers are provided with the host management circuitry or its equivalent, as will be described.</p>
  <p num="p-0051">Preferably, the hardware for the server farm <b>40</b> is a scalable engine <b>100</b> comprised of a large number of commercially available server boards <b>102</b> each arranged as an engine blade <b>132</b> in a power and space efficient cabinet <b>110</b>. The engine blades <b>132</b> are removably positioned in a front side <b>112</b> of the cabinet <b>110</b> in a vertical orientation. A through plane <b>130</b> in the middle of the cabinet <b>110</b> provides common power and controls peripheral signals to all engine blades <b>132</b>. I/O signals for each engine blade <b>132</b> are routed through apertures in the through plane <b>130</b> to interface cards <b>134</b> positioned in the rear of the cabinet <b>110</b>. The I/O signals will be routed through an appropriate interface card <b>134</b> either to the Internet <b>22</b> via the network switch <b>44</b>, or to the disk storage <b>50</b>. Preferably, separate interface cards <b>134</b> are used for these different communication paths.</p>
  <p num="p-0052">The scalable engine can accommodate different types of server boards <b>102</b> in the same cabinet <b>110</b> because of a common blade carrier structure <b>103</b>. Different types of commercially available motherboards <b>102</b> are mounted in the common blade carrier structure <b>103</b> that provides a uniform mechanical interface to the cabinet <b>110</b>. A specially designed PCI host board <b>104</b> that can plug into various types of motherboards <b>102</b> has connections routed through the through plane <b>130</b> for connecting to the interface cards <b>134</b>. Redundant hot-swappable high-efficiency power supplies <b>144</b> are connected to the common power signals on the through plane <b>130</b>. The host board <b>104</b> includes management circuitry that distributes the power signals to the server board <b>102</b> for that engine blade <b>132</b> by emulating the ATX power management protocol. Replaceable fan trays <b>140</b> are mounted below the engine blades <b>132</b> to cool the engine <b>100</b>. Preferably, the cabinet <b>110</b> accommodates multiple rows of engine blades <b>132</b> in a chassis assembly <b>128</b> that includes a pair of sub-chassis <b>129</b> stacked on top of each other and positioned on top of a power frame <b>146</b> that holds the power supplies <b>144</b>. Preferably, the cabinet <b>110</b> will also include rack mounted Ethernet networks switches <b>44</b> and <b>147</b> and storage switches <b>149</b> attached to disk drives <b>50</b> over a Fibre Channel network.</p>
  <p num="p-0053">It will also be understood that while the present invention is described with respect to single cabinet <b>110</b> housing engine blades <b>132</b> with server boards <b>102</b> that together with the appropriate application software constitute the various servers <b>46</b> that are assigned to a first administrative group <b>52</b>-<i>a</i>, and a second administrative group <b>52</b>-<i>b </i>each having at least two engine blades <b>132</b>, the server farm <b>40</b> can accommodate administrative groups <b>52</b> for any number of customers depending upon the total number of servers <b>46</b> in the server farm <b>40</b>. Preferably, multiple cabinets <b>110</b> can be integrated together to scale the total number of servers <b>46</b> at a given location. As will be discussed, it is also possible to link multiple cabinets <b>110</b> in geographically disparate locations together as part of a single server farm <b>40</b> operating under control of the engine group manager <b>48</b>.</p>
  <p num="p-0054">In the preferred embodiment, the server boards <b>102</b> of each engine blade <b>132</b> can be populated with the most recent processors for Intel®, SPARC® or PowerPC™ designs, each of which can support standard operating system environments such as Windows® NT, Windows® 2000, Linux™ or Solaris. Each engine blade <b>132</b> can accommodate one or more server boards <b>102</b>, and each server board may be either a single or multiprocessor design in accordance with the current ATX form factor or a new form factor that may be embraced by the industry in the future. Preferably, the communication channel <b>106</b> is implemented a Controller Area Network (CAN) bus that is separate from the communication paths for the network switch <b>44</b> or storage switches <b>149</b>. Optionally, a second fault backup communication channel <b>106</b>′ could be provided to allow for fault tolerance and redundant communication paths for the group manager software <b>48</b>.</p>
  <p num="p-0055">In a conventional server, the pointers and startup configuration information would be set by manual switches on the server board or hard-coded into PROM chipsets on the server board or stored at fixed locations on a local hard drive accessible by the server board. The management circuitry on the host board <b>104</b> is designed to have appropriate hooks into the server board <b>102</b> such that the pointers and other startup configuration information are actually supplied by the host management circuitry. Optionally, an engine blade <b>132</b> can include a local hard drive <b>107</b> that is accessed through the host board <b>104</b> such that information stored on that local hard drive <b>107</b> can be configured by the host board via the communication channel <b>106</b>. Additionally, the host board <b>104</b> preferably includes power management circuitry <b>108</b> that enables the use of common power supplies for the cabinet <b>110</b> by emulating the ATX power management sequence to control the application of power to the server board <b>102</b>. Preferably, a back channel Ethernet switch <b>147</b> also allows for communication of application and data information among the various server boards <b>102</b> within the server farm <b>40</b> without the need to route those communications out over the Internet <b>22</b>.</p>
  <p num="p-0056">In a preferred embodiment, each cabinet <b>110</b> can house up to <b>32</b> engine blades <b>132</b>. In this configuration, the networks switches <b>44</b> and <b>147</b> could comprise two <b>32</b> circuit switched Ethernet network routers from Foundry®. Preferably, the networks switches <b>44</b> and <b>147</b> allow a reconfiguration of the connection between a server <b>46</b> and the networks switch <b>44</b> and <b>147</b> to be dynamically adjusted by changing the IP address for the server. With respect to the disk storage units <b>50</b>, two options are available. First, unique hardware and software can be inserted in the form of a crossbar switch <b>149</b> between the engine blades <b>132</b> and the disk storage units <b>50</b> which would abstract way the details of the underlying SAN storage hardware configuration. In this case, the link between the disk storage units <b>50</b> and each blade <b>132</b> would be communicated to the crossbar switch <b>149</b> through set of software APIs. Alternatively, commercially available Fibre Channel switches or RAID storage boxes could be used to build connectivity dynamically between the blades <b>132</b> and disk storage units <b>50</b>. In both alternatives, a layer of software inside the engine group manager <b>48</b> performs the necessary configuration adjustments to the connections between the server blades <b>132</b> and networks switches <b>147</b> and disk storage units <b>50</b> are accomplished. In another embodiment, a portion of the servers <b>46</b> could be permanently cabled to the network switches or disk storage units to decrease switch costs if, for example, the set of customer accounts supported by a given portion of the server farm <b>40</b> will always include a base number of servers <b>46</b> that cannot be reallocated. In this case, the base number of servers <b>46</b> for each administrative group <b>52</b> could be permanently cabled to the associated network switch <b>149</b> and disk storage unit <b>50</b> for that administrative group <b>52</b>.</p>
  <p num="p-0057">Referring again to <figref idrefs="DRAWINGS">FIGS. 4 and 5</figref>, it will be seen that the server farm system <b>40</b> of the present invention can dynamically manage hosted services provided to multiple customer accounts. It will be seen that there are at least five servers <b>46</b> operably connected to an intranet <b>54</b>. Preferably, the intranet is formed over the same network switches <b>44</b> that interconnect the servers <b>46</b> with the Internet <b>22</b> or over similar network switches such as network switches <b>147</b> that interconnect the servers <b>46</b> to each other. Each server <b>46</b> has management circuitry on the host board <b>104</b> that provides a communication channel <b>106</b> with at least one of the other servers <b>46</b> that is separate from the intranet <b>54</b> created by the network switches <b>44</b> and/or <b>147</b>.</p>
  <p num="p-0058">At least four of the servers <b>46</b> are configured to execute a local decision software program <b>70</b> that monitors the server <b>46</b> and communicate status information across the communication channel <b>106</b>. At least two of these servers <b>46</b> are allocated to a first administrative group <b>52</b>-<i>a </i>for a first customer account and configured to access software and data unique to the first customer account to provide hosted services to the Internet for that customer account. At least another two of the servers <b>46</b> are allocated to a second administrative group <b>52</b>-<i>b </i>for a second customer account and configured to access software and data unique to the second customer account to provide hosted services to the Internet for that customer account. At least one of the servers <b>46</b> executes a master decision software program <b>72</b> that collects status information from the local decision software programs <b>70</b> executing on the other servers <b>46</b>. In one embodiment, a pair of servers <b>46</b> are slaved together using fault tolerant coordination software to form a fault tolerant/redundant processing platform for the master decision software program. As will be described, the master decision software program <b>72</b> dynamically reallocates at least one server <b>46</b>′ from the first administrative group <b>52</b>-<i>a </i>to the second administrative group <b>52</b>-<i>b </i>in response to at least the status information collected from the local decision software programs <b>70</b>.</p>
  <p num="p-0059">The servers <b>46</b> for both administrative groups <b>52</b> can be arranged in any configuration specified for a given customer account. As shown in <figref idrefs="DRAWINGS">FIG. 3</figref>, three of the servers <b>46</b> for administrative group <b>52</b>-<i>b </i>are configured as front-end servers with a single server <b>46</b> being configured as the back-end/compute server for this customer account. In response to a significant increase in the peak usage activity for the customer account for the second administrative group <b>52</b>-<i>b</i>, the master decision software program <b>72</b> determines that is necessary to reallocate server <b>46</b>′ from its current usage as a server for the first administrative group <b>52</b>-<i>a </i>to being used as a back-end/compute server for the second administrative group <b>52</b>-<i>b</i>. The preferred embodiment for how this decision is arrived will be described in connection with the description of the operation of the local decision software program <b>72</b>. Following the procedure just described, the master decision software program <b>72</b> directs the dynamic reallocation of reallocated server <b>46</b>′ to the second administrative group <b>52</b>-<i>b </i>as shown in <figref idrefs="DRAWINGS">FIG. 4</figref>.</p>
  <p num="p-0060">Although the preferred embodiment of present invention is described in terms of reallocation of a server <b>46</b>′ from a first administrative group <b>52</b>-<i>a </i>to a second administrative group <b>52</b>-<i>b</i>, it should be understood that the present invention can also be implemented to provide for a common pool of available servers <b>46</b>′ that are not currently assigned to a given administrative group <b>52</b> and may be reallocated without necessarily requiring that they be withdrawn from a working administrative group <b>52</b>. For example, a server farm <b>40</b> having thirty-two servers <b>46</b> could be set up to allocate six servers to each of four different customer accounts, with one server <b>46</b> executing the master decision software program <b>72</b> and a remaining pool <b>56</b> of seven servers <b>46</b> that are initially unassigned and can be allocated to any of the four administrative groups <b>52</b> defined for that server farm. Because the assignment of servers to administrative groups is dynamic during the ongoing operation of the server farm <b>40</b> in accordance with the present invention, the preferred embodiment of the present invention uses this pool <b>56</b> as a buffer to further reduce the time required to bring a reallocated server <b>46</b>′ into an administrative group <b>52</b> by eliminating the need to first remove the reallocated server <b>46</b>′ from its existing administrative group <b>52</b>. In one embodiment, the pool <b>56</b> can have both warm servers and cold servers. A warm server would be a server <b>46</b> that has already been configured for a particular administrative group <b>52</b> and therefore it is not necessary to reboot that warm server to allow it to join the administrative group. A cold server would be a server that is not configured to a particular administrative group <b>52</b> and therefore it will be necessary to reboot that cold server in order for it to join the administrative group.</p>
  <p num="p-0061">It should also be understood that reallocated servers <b>46</b>′ can be allocated to a new administrative group singly or as a group with more than one reallocated server <b>46</b>′ being simultaneously reallocated from a first administrative group <b>52</b>-<i>a </i>to a second administrative group <b>52</b>-<i>b</i>. In the context of how the networks switches <b>44</b>, <b>147</b> and storage switches <b>149</b> are configured to accommodate such dynamic reallocation, it should also be understood that multiple servers <b>46</b> may be reallocated together as a group if it is necessary or desirable to reduce the number of dynamically configurable ports on the networks <b>44</b>, <b>147</b> and/or storage switches <b>149</b>.</p>
  <p num="p-0062">One of the significant advantages of the present invention is that the process of reconfiguring servers from one administrative group <b>52</b>-<i>a </i>to a second administrative group <b>52</b>-<i>b </i>will wipe clean all of the state associated with a particular customer account for the first administrative group from the reallocated server <b>46</b>′ before that server is brought into service as part of the second administrative group <b>52</b>-<i>b</i>. This provides a natural and very efficient security mechanism for precluding intentional or unintentional access to data between different customer accounts. Unless a server <b>46</b> or <b>46</b>′ is a member of a given administrative group <b>52</b>-<i>a</i>, there is no way for that server to have access to the data or information for a different administrative group <b>52</b>-<i>b</i>. Instead of the complex and potentially problematic software security features that must be implemented in a mainframe server or other larger server system that utilizes a shard memory space and/or common operating system to provide hosted services across different customer accounts, the present invention keeps the advantages of the simple physical separation between customer accounts that is found in conventional server farm arrangements, but does this while still allowing hardware to be automatically and dynamically reconfigured in the event of a need or opportunity to make better usage of that hardware. The only point of access for authorization and control of this reconfiguration is via the master decision software program <b>72</b> over the out-of-band communication channel <b>106</b>.</p>
  <p num="p-0063">As shown in <figref idrefs="DRAWINGS">FIG. 14</figref>, preferably each server <b>46</b> is programmatically connected to the Internet <b>22</b> under control of the master decision software program <b>72</b>. The master decision software program <b>72</b> also switches the reallocated server <b>46</b>′ to be operably connected to a portion of the disk storage unit storing software and data unique to the customer account of the second administrative group. The use of an out-of-band communication channel <b>106</b> separate from the intranet <b>54</b> over the network switches <b>44</b> for communicating at least a portion of the status information utilized by the master decision software program <b>72</b> is preferably done for reasons of security, fault isolation and bandwidth isolation. In a preferred embodiment, the communication channel <b>106</b> is a serial Controller Area Network (CAN) bus operating at a bandwidth of 1 Mb/s within the cabinet <b>106</b>, with a secondary backbone also operating at a bandwidth 1 Mb/s between different cabinets <b>106</b>. It will be understood that a separate intranet with communications using Internet Protocol (IP) protocol could be used for the communication channel <b>106</b> instead of a serial management interface such as the CAN bus, although such an embodiment would effectively be over designed for the level and complexity of communications that are required of the communication channel <b>106</b> connected to the host boards <b>104</b>. While it would be possible to implement the communication channel <b>106</b> as part of the intranet <b>54</b>, such an implementation is not preferred because of reasons of security, fault isolation and bandwidth isolation.</p>
  <p num="p-0064"> <figref idrefs="DRAWINGS">FIG. 8</figref> shows a block diagram of the hierarchical relation of one embodiment of the various data and software layers utilized by the present invention for a given customer account. Customer data and databases <b>60</b> form the base layer of this hierarchy. Optionally, a web data management software layer <b>62</b> may be incorporated to manage the customer data <b>60</b> across multiple instances of storage units that comprise the storage system <b>50</b>. Cluster and/or load-balancing aware application software <b>64</b> comprises the top layer of what is conventionally thought of as the software and data for the customer's website. Load-balancing software <b>66</b> groups multiple servers <b>46</b> together as part of the common administrative group <b>52</b>. Multiple instances of conventional operating system software <b>68</b> are present, one for each server <b>46</b>. Alternatively, the load-balancing software <b>66</b> and operating system software <b>68</b> may be integrated as part of a common software package within a single administrative group <b>52</b>. Above the conventional operating system software <b>68</b> is the engine operating software <b>48</b> of the present invention that manages resources across multiple customer accounts <b>52</b>-<i>a </i>and <b>52</b>-<i>b. </i> </p>
  <p num="p-0065">In one embodiment of the present invention as shown in <figref idrefs="DRAWINGS">FIG. 9</figref> the servers <b>46</b> assigned to the first administrative group <b>52</b>-<i>a </i>are located at a first site <b>80</b> and the servers <b>46</b> assigned to the second administrative group <b>52</b>-<i>b </i>are located at a second site <b>82</b> geographically remote from the first site <b>80</b>. In this embodiment, the system further includes an arrangement for automatically replicating at least data for the first administrative group <b>52</b>-<i>a </i>to the second site <b>82</b>. In a preferred embodiment, a communication channel <b>84</b> separate from the network switches <b>44</b> is used to replicate data from the disk storage units <b>50</b>-<i>a </i>at the first site <b>80</b> to the disk storage units <b>50</b>-<i>b </i>at the second site <b>82</b>. The purpose of this arrangement is two-fold. First, replication of the data provides redundancy and backup protection that allows for disaster recovery in the event of a disaster at the first site <b>80</b>. Second, replication of the data at the second site <b>82</b> allows the present invention to include the servers <b>46</b> located in the second site <b>82</b> in the pool of available servers which the master decision software program <b>72</b> may use to satisfy increased demand for the hosted services of the first customer by dynamically reallocating these servers to the first administrative group <b>52</b>-<i>a. </i> </p>
  <p num="p-0066">The coordination between master decision software programs <b>72</b> at the first site <b>80</b> and second site <b>82</b> is preferably accomplished by the use of a global decision software routine <b>86</b> that communicates with the master decision software program <b>72</b> at each site. This modular arrangement allows the master decision software programs <b>72</b> to focus on managing the server resources at a given site and extends the concept of having each site <b>80</b>, <b>82</b> request additional off-site services from the global decision software routine <b>86</b> or offer to make available off-site services in much the same way that the local decision software programs <b>70</b> make requests for additional servers or make servers available for reallocation to the master decision software program <b>70</b> at a given site.</p>
  <p num="p-0067">Preferably, the multi-site embodiment of the present invention utilizes commercially available SAN or NAS storage networking software to implement a two-tiered data redundancy and replication hierarchy. As shown in <figref idrefs="DRAWINGS">FIG. 9</figref>, the working version <b>74</b> of the customer data for the first customer account customer is maintained on the disk storage unit <b>50</b> at the first site <b>80</b>. Redundancy data protection, such as data mirroring, data shadowing or RAID data protection is used to establish a backup version <b>76</b> of the customer data for the first customer account at the first site <b>80</b>. The networking software utilizes the communication channel <b>84</b> to generate a second backup version <b>78</b> of the customer data for the first customer account located at the second site <b>82</b>. The use of a communication channel <b>84</b> that is separate from the connection of the networks switches <b>44</b> to the Internet <b>22</b> preferably allows for redundant communication paths and minimizes the impact of the background communication activity necessary to generate the second backup version <b>78</b>. Alternatively, the backup version <b>78</b> of the customer data for the first customer account located at the second site <b>82</b> could be routed through the network switches <b>44</b> and the Internet <b>22</b>. In another embodiment, additional backup versions of the customer data could be replicated at additional site locations to further expand the capability of the system to dynamically reallocate servers from customer accounts that are underutilizing these resources to customer accounts in need of these resources.</p>
  <p num="p-0068">As shown in <figref idrefs="DRAWINGS">FIG. 10</figref>, the ability of the present invention to dynamically reallocate servers from customer accounts that are underutilizing these resources to customer accounts in need of these resources allows for the resources of the server farm <b>40</b> to be used more efficiently in providing hosted services to multiple customer accounts. For each of the customer accounts <b>91</b>, <b>92</b>, <b>93</b>, <b>94</b> and <b>95</b>, the overall allocation of servers <b>46</b> to each customer account is accomplished such that a relatively constant marginal overcapacity bandwidth is maintained for each customer account. Unlike existing server farms, where changes in hardware resources allocated to a given customer account happen in terms of hours, days or weeks, the present invention allows for up-to-the-minute changes in server resources that are dynamically allocated on an as needed basis. <figref idrefs="DRAWINGS">FIG. 10</figref> also shows the advantages of utilizing multiple geographically distinct sites for locating portions of the server farm <b>40</b>. It can be seen that the peak usages for customer accounts <b>94</b> and <b>95</b> are time shifted from those of the other customer accounts <b>91</b>, <b>92</b> and <b>93</b> due to the difference in time zones between site location <b>80</b> and site location <b>82</b>. The present invention can take advantage of these time shifted differences in peak usages to allocate rolling server capacity to site locations during a time period of peak usage from other site locations which are experiencing a lull in activity.</p>
  <p num="p-0069">In one embodiment of the multi-site configuration of the present invention as shown in <figref idrefs="DRAWINGS">FIG. 13</figref>, at least three separate three separate site locations <b>80</b>, <b>82</b> and <b>84</b> are preferably situated geographically at least <b>24</b> divided by N+1 hours apart from each other, where N represents the number of distinct site locations in the multi-site configuration. In the embodiment having three separate site locations <b>80</b>, <b>82</b> and <b>84</b>, the site locations are preferably eight hours apart from each other. The time difference realized by this geographic separation allows for the usage patterns of customer accounts located at all three sites to be aggregated and serviced by a combined number of servers that is significantly less than would otherwise be required if each of the servers at a given location were not able to utilize servers dynamically reallocated from one or more of the other locations. The advantage of this can be seen when site location <b>80</b> is experiencing nighttime usage levels, servers from this site location <b>80</b> can be dynamically reallocated to site location <b>82</b> that is experiencing daytime usage levels. At the same time, site location <b>84</b> experiences evening usage levels and may or may not be suited to have servers reallocated from this location to another location or vice versa. Generally, a site location is arranged so as to look to borrow capacity first from a site location that is at a later time zone (i.e., to the east of that site) and will look to make extra capacity available to site locations that are at an earlier time zone (i.e., to the west of that site). Other preferences can also be established depending upon past usage and predicted patterns of use.</p>
  <p num="p-0070">Referring now to <figref idrefs="DRAWINGS">FIG. 11</figref>, a preferred embodiment of the master decision software program <b>72</b> will be described. The master decision software program <b>72</b> includes a resource database <b>150</b>, a service level agreement database <b>152</b>, a master decision logic module <b>154</b> and a dispatch module <b>156</b>. The master decision logic module <b>154</b> has access to the resource database <b>150</b> and the service level agreement database <b>152</b> and compares the status information to information in the resource database <b>150</b> and the service level agreement database <b>152</b> to determine whether to dynamically reallocate servers from the first customer account to the second customer account. The dispatch module <b>156</b> is operably linked to the master decision logic module <b>154</b> to dynamically reallocate servers when directed by the master decision logic module <b>154</b> by using the communication channel <b>106</b> to set initialization pointers for the reallocated servers <b>46</b>′ to access software and data unique to the customer account for the second administrative group <b>52</b>-<i>b </i>and reinitializing the reallocated server <b>46</b>′ such that at least one server joins the second administrative group <b>52</b>-<i>b</i>. Preferably, the dispatch module <b>156</b> includes a set of connectivity rules <b>160</b> and a set of personality modules <b>162</b> for each server <b>46</b>. The connectivity rules <b>160</b> providing instructions for connecting a particular server <b>46</b> to a given network switch <b>44</b> or data storage unit <b>50</b>. The personality module <b>162</b> describes the details of the particular software configuration of the server board <b>102</b> to be added to an administrative work group for a customer account. Once the dispatch module <b>146</b> has determined the need to reallocate a server, it will evaluate the set of connectivity rules <b>160</b> and a set of personality modules <b>162</b> to determine how to construct a server <b>46</b> that will be dispatched to that particular administrative group <b>52</b>.</p>
  <p num="p-0071">Another way of looking at how the present invention can dynamically provide hosted service across disparate accounts is to view a portion of the servers <b>46</b> as being assigned to a pool of a plurality of virtual servers that may be selectively configured to access software and data for a particular administrative group <b>52</b>. When the dispatch module <b>146</b> has determined a need to add a server <b>46</b> to a particular administrative group <b>52</b>, it automatically allocates one of the servers from the pool of virtual servers to that administrative group. Conversely, if the dispatch module determines that an administrative group can relinquish one of its servers <b>46</b>, that relinquished server would be added to the pool of virtual servers that are available for reallocation to a different administrative group. When the present invention is viewed from this perspective, it will be seen that the group manager software <b>48</b> operates to “manufacture” or create one or more virtual servers out of this pool of the plurality of virtual servers on a just-in-time or as-needed basis. As previously described, the pool of virtual servers can either be a warm pool or a cold pool, or any combination thereof. The virtual server is manufactured or constructed to be utilized by the desired administrative group in accordance with the set of connectivity rules <b>160</b> and personality modules <b>162</b>.</p>
  <p num="p-0072">In this embodiment, the master decision logic module <b>152</b> is operably connected to a management console <b>158</b> that can display information about the master decision software program and accept account maintenance and update information to processes into the various databases. A billing software module <b>160</b> is integrated into the engine group manager <b>48</b> in order to keep track of the billing based on the allocation of servers to a given customer account. Preferably, a customer account is billed at a higher rate for the hosted services when servers are dynamically reallocated to that customer account based on the customer's service level agreement.</p>
  <p num="p-0073"> <figref idrefs="DRAWINGS">FIG. 12</figref> shows a representation of three different service level agreement arrangements for a given customer account. In this embodiment, the service level agreements are made for providing hosted services for a given period of time, such as a month. In a first level shown at <b>170</b>, the customer account is provided with the capacity to support hosted services for 640,000 simultaneous connections. If the customer account did not need a reallocation of servers to support capacity greater than the committed capacity for the first level <b>170</b>, the customer would be charged to establish rate for that level of committed capacity. In a second level shown at <b>172</b>, customer account can be dynamically expanded to support capacity of double the capacity at the first level <b>172</b>. In a preferred embodiment, once the engine group manager <b>48</b> has dynamically reallocated servers to the customer account in order to support the second level <b>172</b> of capacity to meet a higher than anticipated peak usage, the customer account would be charged a higher rate for the period of time that the additional usage was required. In addition, the customer account could be charged a one-time fee for initiating the higher level of service represented by the second level <b>172</b>. In one embodiment, charges for the second level <b>172</b> of service would be incurred at a rate that is some additional multiple of the rate charged for the first level <b>170</b>. The second level <b>172</b> represents a guaranteed expansion level available to the customer for the given period of time. Finally, a third level <b>174</b> provides an optional extended additional level of service that may be able to be brought to bare to provide hosted services for the customer account. In this embodiment, the third level <b>174</b> provides up to a higher multiple times the level of service as the first level <b>170</b>. In one embodiment, in order to provide this extended additional level of service, the host system makes use of the multi-site arrangement as previously described in order to bring in the required number of servers to meet this level of service. Preferably, the customer account is charged a second higher rate for the period of time that the extended additional service is reallocated to this customer account. In one embodiment, charges for the third level <b>174</b> of service would be incurred at a rate that is an even larger multiple of the first level <b>170</b> for the given period of time that the extended additional third level <b>174</b> of service is provided for this customer account. Again, the customer account may be charged a one-time fee for initiating this third level <b>174</b> of service at any time during the given period. At the end of a given period, the customer may alter the level of service contracted for the given customer account.</p>
  <p num="p-0074">As shown in <figref idrefs="DRAWINGS">FIG. 12</figref>, the service level agreement is increased by 50% from a first period to a second period in response to a higher anticipated peak usage for the given customer account. Preferably, the period for a service level agreement for a given customer account would be a monthly basis, with suggestions been presented to the customer for recommended changes to the service level agreement for the upcoming billing period. Although this example is demonstrated in terms of simultaneous connections, it should be understood that the service level agreement for a given customer account can be generated in terms of a variety of performance measurements, such as simultaneous connections, hits, amount of data transferred, number of transactions, connect time, resources utilized by different application software programs, the revenue generated, or any combination thereof. It will also be understood that the service level agreement may provide for different levels of commitment for different types of resources, such as front-end servers, back-end servers, network connections or disk storage units.</p>
  <p num="p-0075">Referring now to <figref idrefs="DRAWINGS">FIG. 15</figref>, a block diagram of the preferred embodiment of the local decision software program <b>70</b> will be described. A series of measurement modules <b>180</b>, <b>181</b>, <b>182</b>, <b>183</b> and <b>184</b> each performed independent evaluations of the operation of the particular server on which the local decision software program <b>70</b> is executing. Outputs from these measurement modules are provided to an aggregator module <b>190</b> of the local decision software program <b>70</b>. A predictor module <b>192</b> generates expected response times and probabilities for various requests. With priority inputs <b>194</b> supplied by the master decision software program <b>72</b> from the service level agreement database <b>152</b>, a fuzzy inference system <b>196</b> determines whether a request to add an engine blade <b>104</b> for the administrative group <b>52</b> will be made, or whether an offer to give up or remove an engine blade from the administrative group <b>52</b> will be made. The request to add or remove a blade is then communicated over communication channel <b>106</b> to the master decision software program <b>72</b>. In one embodiment, the aggregator module <b>190</b> is executed on each server <b>46</b> within a given administrative group <b>52</b>, and the predictor module <b>192</b> and fuzzy inference module <b>196</b> are executed on only a single server <b>46</b> within the given administrative group <b>52</b> with the outputs of the various measurement modules <b>180</b>-<b>184</b> been communicated to the designated server <b>46</b> across the communication channel <b>106</b>. In another embodiment, the aggregator module <b>190</b>, predictor module <b>192</b> and fuzzy inference module <b>196</b> may be executed on more than one server within a given administrative group for purposes of redundancy or distributed processing of the information necessary to generate the request add or remove a blade. Preferably, the aggregator module <b>190</b> accomplishes a balancing across the various measurement modules <b>180</b>-<b>184</b> in accordance with the formula:
<br> <i>B</i> <sub>k</sub>=[(Σ<i>T</i> <sub>ki</sub> <i>/w</i> <sub>k</sub>)−min<sub>k</sub>]*100/(max<sub>k</sub>-min<sub>k</sub>)-50  Equation (1)<br>i=1 to W<sub>k </sub> </p>
  <p num="p-0076">Where T<sub>ki </sub>is the time take it for the ith request of measurement type k, W<sub>k </sub>is the window size for measurement type k, mink is the minimum time expected for measurement type k, and max<sub>k </sub>is the maximum time to be tolerated for a measurement type k. The balanced request rate B<sub>k </sub>is then passed to the predictor module <b>192</b> and the fuzzy inference module <b>196</b> of the local decision software program <b>70</b>. The window size for the measurement type k would be set to minimize any unnecessary intrusion by the measurement modules <b>180</b>-<b>184</b>, while at the same time allowing for a timely and adequate response to increases in usage demand for the administrative group <b>52</b>.</p>
  <p num="p-0077"> <figref idrefs="DRAWINGS">FIG. 16</figref> shows a sample of the workload measurements from the various measurement modules <b>180</b>-<b>184</b> under varying load conditions. It can be seen that no single workload measurement provides a constantly predictable estimate of the expected response time and probability for that response time. As such, the fuzzy inference module <b>196</b> must consider three fundamental parameters: the predicted response times for various requests, the priority of these requests, and probability of their occurrence. The fuzzy inference module <b>196</b> blends all three of these considerations to make a determination as to whether to request a blade to be added or removed from the administrative group <b>52</b>. An example of a fuzzy inference rule would be:
</p> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0077">if (priority is urgent) and (probability is abundant) and (expected response time is too high) then (make request for additional blade).</li> </ul> </li> </ul> <p num="p-0078">Preferably, the end results of the fuzzy inference module <b>196</b> is to generate a decision surface contouring the need to request an additional server over the grid of the expected response time vs. the probability of that response time for this administrative group <b>52</b>. An example of such a decision surface is shown in <figref idrefs="DRAWINGS">FIG. 17</figref>.</p>
  <p num="p-0079">A portion of the disclosure of this invention is subject to copyright protection. The copyright owner permits the facsimile reproduction of the disclosure of this invention as it appears in the Patent and Trademark Office files or records, but otherwise reserves all copyright rights.</p>
  <p num="p-0080">Although the preferred embodiment of the automated system of the present invention has been described, it will be recognized that numerous changes and variations can be made and that the scope of the present invention is to be defined by the claims.</p>
</div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3764747">US3764747</a></td><td class="patent-data-table-td patent-date-value">Apr 13, 1971</td><td class="patent-data-table-td patent-date-value">Oct 9, 1973</td><td class="patent-data-table-td ">Hitachi Ltd</td><td class="patent-data-table-td ">Billing system in mobile communication</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5031089">US5031089</a></td><td class="patent-data-table-td patent-date-value">Dec 30, 1988</td><td class="patent-data-table-td patent-date-value">Jul 9, 1991</td><td class="patent-data-table-td ">United States Of America As Represented By The Administrator, National Aeronautics And Space Administration</td><td class="patent-data-table-td ">Dynamic resource allocation scheme for distributed heterogeneous computer systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5187710">US5187710</a></td><td class="patent-data-table-td patent-date-value">Dec 19, 1990</td><td class="patent-data-table-td patent-date-value">Feb 16, 1993</td><td class="patent-data-table-td ">At&amp;T Bell Laboratories</td><td class="patent-data-table-td ">Method and apparatus for the billing of value-added communications calls</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5247427">US5247427</a></td><td class="patent-data-table-td patent-date-value">Aug 26, 1992</td><td class="patent-data-table-td patent-date-value">Sep 21, 1993</td><td class="patent-data-table-td ">Data General Corporation</td><td class="patent-data-table-td ">Disk array subsystem having elongated T-shaped guides for use in a data processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5251097">US5251097</a></td><td class="patent-data-table-td patent-date-value">Jun 11, 1990</td><td class="patent-data-table-td patent-date-value">Oct 5, 1993</td><td class="patent-data-table-td ">Supercomputer Systems Limited Partnership</td><td class="patent-data-table-td ">Packaging architecture for a highly parallel multiprocessor system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5351286">US5351286</a></td><td class="patent-data-table-td patent-date-value">Jul 6, 1993</td><td class="patent-data-table-td patent-date-value">Sep 27, 1994</td><td class="patent-data-table-td ">Bell Communications Research, Inc.</td><td class="patent-data-table-td ">Method and system for billing an ISDN data user interconnection to the public switched telephone network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5460441">US5460441</a></td><td class="patent-data-table-td patent-date-value">Nov 1, 1994</td><td class="patent-data-table-td patent-date-value">Oct 24, 1995</td><td class="patent-data-table-td ">Compaq Computer Corporation</td><td class="patent-data-table-td ">Rack-mounted computer apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5488541">US5488541</a></td><td class="patent-data-table-td patent-date-value">Jun 1, 1994</td><td class="patent-data-table-td patent-date-value">Jan 30, 1996</td><td class="patent-data-table-td ">Northern Telecom Limited</td><td class="patent-data-table-td ">VME bus compatible backplane and shelf arrangement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5504894">US5504894</a></td><td class="patent-data-table-td patent-date-value">Apr 30, 1992</td><td class="patent-data-table-td patent-date-value">Apr 2, 1996</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Workload manager for achieving transaction class response time goals in a multiprocessing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5537542">US5537542</a></td><td class="patent-data-table-td patent-date-value">Apr 4, 1994</td><td class="patent-data-table-td patent-date-value">Jul 16, 1996</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Apparatus and method for managing a server workload according to client performance goals in a client/server data processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5548683">US5548683</a></td><td class="patent-data-table-td patent-date-value">May 5, 1994</td><td class="patent-data-table-td patent-date-value">Aug 20, 1996</td><td class="patent-data-table-td ">Grumman Aerospace Corporation</td><td class="patent-data-table-td ">Data fusion neural network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5615329">US5615329</a></td><td class="patent-data-table-td patent-date-value">Feb 22, 1994</td><td class="patent-data-table-td patent-date-value">Mar 25, 1997</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Remote data duplexing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5696895">US5696895</a></td><td class="patent-data-table-td patent-date-value">Jun 19, 1995</td><td class="patent-data-table-td patent-date-value">Dec 9, 1997</td><td class="patent-data-table-td ">Compaq Computer Corporation</td><td class="patent-data-table-td ">Fault tolerant multiple network servers</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5745884">US5745884</a></td><td class="patent-data-table-td patent-date-value">Oct 21, 1996</td><td class="patent-data-table-td patent-date-value">Apr 28, 1998</td><td class="patent-data-table-td ">Mobile Area Networks, Inc.</td><td class="patent-data-table-td ">System and method for billing data grade network use on a per connection basis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5774668">US5774668</a></td><td class="patent-data-table-td patent-date-value">Jun 7, 1995</td><td class="patent-data-table-td patent-date-value">Jun 30, 1998</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">System for on-line service in which gateway computer uses service map which includes loading condition of servers broadcasted by application servers for load balancing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5794221">US5794221</a></td><td class="patent-data-table-td patent-date-value">Jul 7, 1995</td><td class="patent-data-table-td patent-date-value">Aug 11, 1998</td><td class="patent-data-table-td ">Egendorf; Andrew</td><td class="patent-data-table-td ">Internet billing method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5819092">US5819092</a></td><td class="patent-data-table-td patent-date-value">Oct 6, 1997</td><td class="patent-data-table-td patent-date-value">Oct 6, 1998</td><td class="patent-data-table-td ">Vermeer Technologies, Inc.</td><td class="patent-data-table-td ">Online service development tool with fee setting capabilities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5828737">US5828737</a></td><td class="patent-data-table-td patent-date-value">Oct 24, 1995</td><td class="patent-data-table-td patent-date-value">Oct 27, 1998</td><td class="patent-data-table-td ">Telefonaktiebolaget L M Ericsson</td><td class="patent-data-table-td ">In a cellular telephone system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5832222">US5832222</a></td><td class="patent-data-table-td patent-date-value">Jun 19, 1996</td><td class="patent-data-table-td patent-date-value">Nov 3, 1998</td><td class="patent-data-table-td ">Ncr Corporation</td><td class="patent-data-table-td ">Apparatus for providing a single image of an I/O subsystem in a geographically dispersed computer system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5845267">US5845267</a></td><td class="patent-data-table-td patent-date-value">Sep 6, 1996</td><td class="patent-data-table-td patent-date-value">Dec 1, 1998</td><td class="patent-data-table-td ">At&amp;T Corp</td><td class="patent-data-table-td ">System and method for billing for transactions conducted over the internet from within an intranet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5877938">US5877938</a></td><td class="patent-data-table-td patent-date-value">Nov 3, 1997</td><td class="patent-data-table-td patent-date-value">Mar 2, 1999</td><td class="patent-data-table-td ">Sequent Computer Systems, Inc.</td><td class="patent-data-table-td ">Packaging architecture for a data server</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5899980">US5899980</a></td><td class="patent-data-table-td patent-date-value">Aug 11, 1997</td><td class="patent-data-table-td patent-date-value">May 4, 1999</td><td class="patent-data-table-td ">Trivnet Ltd.</td><td class="patent-data-table-td ">Retail method over a wide area network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5912802">US5912802</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 1997</td><td class="patent-data-table-td patent-date-value">Jun 15, 1999</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Ducted opposing bonded fin heat sink blower multi-microprocessor cooling system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5938732">US5938732</a></td><td class="patent-data-table-td patent-date-value">Dec 9, 1996</td><td class="patent-data-table-td patent-date-value">Aug 17, 1999</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">Load balancing and failover of network services</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5946670">US5946670</a></td><td class="patent-data-table-td patent-date-value">Oct 22, 1996</td><td class="patent-data-table-td patent-date-value">Aug 31, 1999</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Data switching device and method of notifying charge information in data switching network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5948065">US5948065</a></td><td class="patent-data-table-td patent-date-value">Mar 28, 1997</td><td class="patent-data-table-td patent-date-value">Sep 7, 1999</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System for managing processor resources in a multisystem environment in order to provide smooth real-time data streams while enabling other types of applications to be processed concurrently</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5951694">US5951694</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 1997</td><td class="patent-data-table-td patent-date-value">Sep 14, 1999</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method of redirecting a client service session to a second application server without interrupting the session by forwarding service-specific information to the second server</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5956391">US5956391</a></td><td class="patent-data-table-td patent-date-value">Feb 10, 1997</td><td class="patent-data-table-td patent-date-value">Sep 21, 1999</td><td class="patent-data-table-td ">Telefonaktiebolaget Lm Ericsson</td><td class="patent-data-table-td ">Billing in the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5956697">US5956697</a></td><td class="patent-data-table-td patent-date-value">Aug 22, 1996</td><td class="patent-data-table-td patent-date-value">Sep 21, 1999</td><td class="patent-data-table-td ">International Scientific Co., Ltd.</td><td class="patent-data-table-td ">Timer-based fee-charging system for internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5974462">US5974462</a></td><td class="patent-data-table-td patent-date-value">Mar 28, 1997</td><td class="patent-data-table-td patent-date-value">Oct 26, 1999</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and apparatus for controlling the number of servers in a client/server system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5978577">US5978577</a></td><td class="patent-data-table-td patent-date-value">Mar 17, 1995</td><td class="patent-data-table-td patent-date-value">Nov 2, 1999</td><td class="patent-data-table-td ">Csg Systems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for transaction processing in a distributed database system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5999965">US5999965</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1997</td><td class="patent-data-table-td patent-date-value">Dec 7, 1999</td><td class="patent-data-table-td ">Netspeak Corporation</td><td class="patent-data-table-td ">Automatic call distribution server for computer telephony communications</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6006259">US6006259</a></td><td class="patent-data-table-td patent-date-value">Nov 20, 1998</td><td class="patent-data-table-td patent-date-value">Dec 21, 1999</td><td class="patent-data-table-td ">Network Alchemy, Inc.</td><td class="patent-data-table-td ">Method and apparatus for an internet protocol (IP) network clustering system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6014669">US6014669</a></td><td class="patent-data-table-td patent-date-value">Oct 21, 1997</td><td class="patent-data-table-td patent-date-value">Jan 11, 2000</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">Highly-available distributed cluster configuration database</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6025989">US6025989</a></td><td class="patent-data-table-td patent-date-value">Apr 21, 1998</td><td class="patent-data-table-td patent-date-value">Feb 15, 2000</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Modular node assembly for rack mounted multiprocessor computer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6035281">US6035281</a></td><td class="patent-data-table-td patent-date-value">Jun 16, 1997</td><td class="patent-data-table-td patent-date-value">Mar 7, 2000</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method of multiparty billing for Web access</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6035356">US6035356</a></td><td class="patent-data-table-td patent-date-value">Apr 21, 1999</td><td class="patent-data-table-td patent-date-value">Mar 7, 2000</td><td class="patent-data-table-td ">Atec Group, Inc.</td><td class="patent-data-table-td ">Cross-platform computer architecture and components thereof</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6067545">US6067545</a></td><td class="patent-data-table-td patent-date-value">Apr 15, 1998</td><td class="patent-data-table-td patent-date-value">May 23, 2000</td><td class="patent-data-table-td ">Hewlett-Packard Company</td><td class="patent-data-table-td ">Resource rebalancing in networked computer systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6067580">US6067580</a></td><td class="patent-data-table-td patent-date-value">Mar 11, 1997</td><td class="patent-data-table-td patent-date-value">May 23, 2000</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Integrating distributed computing environment remote procedure calls with an advisory work load manager</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6070191">US6070191</a></td><td class="patent-data-table-td patent-date-value">Oct 17, 1997</td><td class="patent-data-table-td patent-date-value">May 30, 2000</td><td class="patent-data-table-td ">Lucent Technologies Inc.</td><td class="patent-data-table-td ">Data distribution techniques for load-balanced fault-tolerant web access</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6088727">US6088727</a></td><td class="patent-data-table-td patent-date-value">Oct 17, 1997</td><td class="patent-data-table-td patent-date-value">Jul 11, 2000</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Cluster controlling system operating on a plurality of computers in a cluster system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6092178">US6092178</a></td><td class="patent-data-table-td patent-date-value">Sep 3, 1998</td><td class="patent-data-table-td patent-date-value">Jul 18, 2000</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">System for responding to a resource request</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6094351">US6094351</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1998</td><td class="patent-data-table-td patent-date-value">Jul 25, 2000</td><td class="patent-data-table-td ">Hon Hai Precision Ind. Co., Ltd.</td><td class="patent-data-table-td ">Universal enclosure for different type mother boards</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6094680">US6094680</a></td><td class="patent-data-table-td patent-date-value">Jun 27, 1996</td><td class="patent-data-table-td patent-date-value">Jul 25, 2000</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">System and method for managing distributed resources on networks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6097882">US6097882</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 1995</td><td class="patent-data-table-td patent-date-value">Aug 1, 2000</td><td class="patent-data-table-td ">Digital Equipment Corporation</td><td class="patent-data-table-td ">Method and apparatus of improving network performance and network availability in a client-server network by transparently replicating a network service</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6108703">US6108703</a></td><td class="patent-data-table-td patent-date-value">May 19, 1999</td><td class="patent-data-table-td patent-date-value">Aug 22, 2000</td><td class="patent-data-table-td ">Massachusetts Institute Of Technology</td><td class="patent-data-table-td ">Global hosting system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6167446">US6167446</a></td><td class="patent-data-table-td patent-date-value">Nov 3, 1998</td><td class="patent-data-table-td patent-date-value">Dec 26, 2000</td><td class="patent-data-table-td ">Inca Technology, Inc.</td><td class="patent-data-table-td ">Automatically configuring network-name-services</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6173322">US6173322</a></td><td class="patent-data-table-td patent-date-value">Jun 5, 1997</td><td class="patent-data-table-td patent-date-value">Jan 9, 2001</td><td class="patent-data-table-td ">Silicon Graphics, Inc.</td><td class="patent-data-table-td ">Network request distribution based on static rules and dynamic performance data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6185598">US6185598</a></td><td class="patent-data-table-td patent-date-value">Feb 10, 1998</td><td class="patent-data-table-td patent-date-value">Feb 6, 2001</td><td class="patent-data-table-td ">Digital Island, Inc.</td><td class="patent-data-table-td ">Optimized network resource location</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6374297">US6374297</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 1999</td><td class="patent-data-table-td patent-date-value">Apr 16, 2002</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and apparatus for load balancing of web cluster farms</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6452809">US6452809</a></td><td class="patent-data-table-td patent-date-value">Nov 10, 2000</td><td class="patent-data-table-td patent-date-value">Sep 17, 2002</td><td class="patent-data-table-td ">Galactic Computing Corporation</td><td class="patent-data-table-td ">Scalable internet engine</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6463454">US6463454</a></td><td class="patent-data-table-td patent-date-value">Jun 17, 1999</td><td class="patent-data-table-td patent-date-value">Oct 8, 2002</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method for integrated load distribution and resource management on internet environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6532488">US6532488</a></td><td class="patent-data-table-td patent-date-value">Jan 25, 1999</td><td class="patent-data-table-td patent-date-value">Mar 11, 2003</td><td class="patent-data-table-td ">John J. Ciarlante</td><td class="patent-data-table-td ">Method and system for hosting applications</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6606253">US6606253</a></td><td class="patent-data-table-td patent-date-value">Sep 16, 2002</td><td class="patent-data-table-td patent-date-value">Aug 12, 2003</td><td class="patent-data-table-td ">Galactic Computing Corporation</td><td class="patent-data-table-td ">Scalable internet engine</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6625639">US6625639</a></td><td class="patent-data-table-td patent-date-value">Nov 12, 1999</td><td class="patent-data-table-td patent-date-value">Sep 23, 2003</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Apparatus and method for processing a task in a clustered computing environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6718359">US6718359</a></td><td class="patent-data-table-td patent-date-value">Feb 6, 2001</td><td class="patent-data-table-td patent-date-value">Apr 6, 2004</td><td class="patent-data-table-td ">Radware Ltd.</td><td class="patent-data-table-td ">Load balancing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6816903">US6816903</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 3, 1999</td><td class="patent-data-table-td patent-date-value">Nov 9, 2004</td><td class="patent-data-table-td ">Novell, Inc.</td><td class="patent-data-table-td ">Directory enabled policy management tool for intelligent traffic management</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6816905">US6816905</a></td><td class="patent-data-table-td patent-date-value">Nov 10, 2000</td><td class="patent-data-table-td patent-date-value">Nov 9, 2004</td><td class="patent-data-table-td ">Galactic Computing Corporation Bvi/Bc</td><td class="patent-data-table-td ">Method and system for providing dynamic hosted service management across disparate accounts/sites</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6938256">US6938256</a></td><td class="patent-data-table-td patent-date-value">Jan 18, 2001</td><td class="patent-data-table-td patent-date-value">Aug 30, 2005</td><td class="patent-data-table-td ">Galactic Computing Corporation</td><td class="patent-data-table-td ">System for balance distribution of requests across multiple servers using dynamic metrics</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7032241">US7032241</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 5, 2000</td><td class="patent-data-table-td patent-date-value">Apr 18, 2006</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Methods and systems for accessing networks, methods and systems for accessing the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7185112">US7185112</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 10, 2000</td><td class="patent-data-table-td patent-date-value">Feb 27, 2007</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Network interconnection apparatus for interconnecting a LAN and an ATM network using QoS adjustment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20030039237">US20030039237</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 23, 1998</td><td class="patent-data-table-td patent-date-value">Feb 27, 2003</td><td class="patent-data-table-td ">Jan E Forslow</td><td class="patent-data-table-td ">Common access between a mobile communications network and an external network with selectable packet-switched and circuit-switched services</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20050076214">US20050076214</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 3, 2003</td><td class="patent-data-table-td patent-date-value">Apr 7, 2005</td><td class="patent-data-table-td ">Thomas David Andrew</td><td class="patent-data-table-td ">Method and system for file downloads to portable computing devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070140242">US20070140242</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 16, 2005</td><td class="patent-data-table-td patent-date-value">Jun 21, 2007</td><td class="patent-data-table-td ">Digiorgio Rinaldo S</td><td class="patent-data-table-td ">Reliable multicast operating system (OS) provisioning</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000004458A1?cl=en">WO2000004458A1</a></td><td class="patent-data-table-td patent-date-value">Jul 14, 1999</td><td class="patent-data-table-td patent-date-value">Jan 27, 2000</td><td class="patent-data-table-td ">Massachusetts Inst Technology</td><td class="patent-data-table-td ">Global document hosting system utilizing embedded content distributed ghost servers</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2001067707A2?cl=en">WO2001067707A2</a></td><td class="patent-data-table-td patent-date-value">Mar 2, 2001</td><td class="patent-data-table-td patent-date-value">Sep 13, 2001</td><td class="patent-data-table-td ">Scale Eight Inc</td><td class="patent-data-table-td ">A network storage system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2002008891A2?cl=en">WO2002008891A2</a></td><td class="patent-data-table-td patent-date-value">Jul 16, 2001</td><td class="patent-data-table-td patent-date-value">Jan 31, 2002</td><td class="patent-data-table-td ">Rlx Technologies Inc</td><td class="patent-data-table-td ">Single board web server system and method</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">A New Twist On Hosting: Luminate Pitches Its Enterprise Management Services; Chris Gonsalves, PC Week Online, 2 pgs.; Mar. 2000.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">ADSM: A Multi-Platform, Scalable, Backup and Archive mass Storage System; Luis-Felipe Cabrera et al.; 1063-6390/95, 1995 IEEE; pp. 420-427.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Applicast(TM)., Applicast, Inc.; 6 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Applicast™., Applicast, Inc.; 6 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: ChatCom's ChatterBox Products, ChatCom, Inc.; 2 pgs. Undated.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: ControlIT(TM).-Remote Control Without Boundaries, Computer Associates International, Inc.; 10 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: ControlIT™.—Remote Control Without Boundaries, Computer Associates International, Inc.; 10 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Get Connected-Cable &amp; Wireless Enhanced Solutions Provider Program, Cable &amp; Wireless USA, Inc., 4 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Get Connected—Cable &amp; Wireless Enhanced Solutions Provider Program, Cable &amp; Wireless USA, Inc., 4 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: HP Open View Customer Views 1.0 for Network Node Manager, Hewlett-Packard Company, 4 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: HP Open View, Hewlett-Packard Company, 16 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivol®. Global Enterprise Manager-A Business-focused Approach to Systems Management, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivol®. Global Enterprise Manager—A Business-focused Approach to Systems Management, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">14</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli Cross-Site-Internet Application Management Technical Brief, Tivoli Systems, Inc.; 22 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">15</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli Cross-Site—Internet Application Management Technical Brief, Tivoli Systems, Inc.; 22 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">16</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli Problem Management Suite, Tivoli Systems, Inc.; 4 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">17</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli Technical Brief for Service Providers, Tivoli Systems, Inc., 7 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">18</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli® Cross-Site for Availability, Tivoli Systems, Inc.; 4 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">19</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli® Cross-Site for Deployment-Using the Internet as a Valuable Deployment Tool, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">20</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli® Cross-Site for Deployment—Using the Internet as a Valuable Deployment Tool, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">21</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli® Distributed Monitoring-Automated, Consistent Availability Solution, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">22</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli® Distributed Monitoring—Automated, Consistent Availability Solution, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">23</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Brochure: Tivoli®. Cross-Site for Security, Tivoli Systems, Inc.; 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">24</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Excite@Home LauncHes Free Service for Merchants, Andrea Orr, MicroTimes Magazine, plus web site print-out; 3 pgs.; Aug. 2000.</td></tr><tr><td class="patent-data-table-td ">25</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Magazine advertisment : ISP Upgrade, CAIS Software Solutions, 3 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">26</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Management of the Access Network and Service Provisioning, Jani Hursti, Seminar in Networking, Helsinki University of Technology, 20 pgs.; Apr. 1999.</td></tr><tr><td class="patent-data-table-td ">27</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">The Landlords of Cyberspace, Christopher Heun, informationweek.com; 3 pgs.; Jul. 2000.</td></tr><tr><td class="patent-data-table-td ">28</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. Appl. No. 09/709,820, filed Nov. 10, 2000, Rex Jackson.</td></tr><tr><td class="patent-data-table-td ">29</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. Appl. No. 09/710,095, filed Nov. 10, 2000, Kitrick Sheets.</td></tr><tr><td class="patent-data-table-td ">30</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. Appl. No. 09/765,766, filed Jan. 18, 2001, Deng Yuefan.</td></tr><tr><td class="patent-data-table-td ">31</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. Appl. No. 09/907,520, filed Jul. 17, 2001, Rex Jackson.</td></tr><tr><td class="patent-data-table-td ">32</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. Appl. No. 10/244,450, filed Sep. 16, 2002, Rex Jackson.</td></tr><tr><td class="patent-data-table-td ">33</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. Appl. No. 11/202,644, filed Aug. 12, 2005, Deng Yuefan.</td></tr><tr><td class="patent-data-table-td ">34</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. PAIR File Wrapper History for U.S. Appl. No. 09/709,820, filed Nov. 10, 2000.</td></tr><tr><td class="patent-data-table-td ">35</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. PAIR File Wrapper History for U.S. Appl. No. 09/710,095, filed Nov. 10, 2000.</td></tr><tr><td class="patent-data-table-td ">36</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. PAIR File Wrapper History for U.S. Appl. No. 09/765,766, filed Jan. 18, 2001.</td></tr><tr><td class="patent-data-table-td ">37</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. PAIR File Wrapper History for U.S. Appl. No. 09/907,520, filed Jul. 17, 2001.</td></tr><tr><td class="patent-data-table-td ">38</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. PAIR File Wrapper History for U.S. Appl. No. 10/244,450, filed Sep. 16, 2002.</td></tr><tr><td class="patent-data-table-td ">39</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">U.S. PAIR File Wrapper History for U.S. Appl. No. 11/202,644, filed Aug. 12, 2005.</td></tr><tr><td class="patent-data-table-td ">40</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out Epoch Internet Introduces New ‘Pod’ Architecture, An Innovative Approach to Providing Web Hosting Services, epoch.net, Epoch Networks, Inc., 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">41</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out Epoch Internet Introduces New '<a href='http://scholar.google.com/scholar?q="Pod"'>Pod</a>' Architecture, An Innovative Approach to Providing Web Hosting Services, epoch.net, Epoch Networks, Inc., 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">42</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Ascendant Solutions, Inc. Fact Sheet, Ascendant Solutions, Inc.; 4 pgs.; Copyright 1998-2000.</td></tr><tr><td class="patent-data-table-td ">43</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: ASP Computer Systems Corp.; Data Return Corporation, 3 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">44</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Cellular MultiProcessing-Breakthrough Architecture for an Open Mainframe, Unisys, 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">45</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Cellular MultiProcessing—Breakthrough Architecture for an Open Mainframe, Unisys, 4 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">46</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: ClearPath Enterprise Servers-What is HMP?, Unisys, 2 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">47</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: ClearPath Enterprise Servers—What is HMP?, Unisys, 2 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">48</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Comprehensive Hosting Solution for ISV s, ebaseone Corporation, 3 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">49</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: End to End Scheduling for Tivoli.RTM. Workload Scheduler and Tivoli Operations Planning and Control, Tivoli Systems, Inc., 2 pgs. not dated.</td></tr><tr><td class="patent-data-table-td ">50</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Frequently Asked Questions-Complex Web Services, USinternetworking, Inc.; 3 pgs.; Copyright 1998-1999.</td></tr><tr><td class="patent-data-table-td ">51</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Frequently Asked Questions—Complex Web Services, USinternetworking, Inc.; 3 pgs.; Copyright 1998-1999.</td></tr><tr><td class="patent-data-table-td ">52</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Frequently Asked Questions-Overview of PATROL®., BMC Software, Inc., 4 pgs.; Copyright 2001.</td></tr><tr><td class="patent-data-table-td ">53</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Frequently Asked Questions—Overview of PATROL®., BMC Software, Inc., 4 pgs.; Copyright 2001.</td></tr><tr><td class="patent-data-table-td ">54</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: HP'S Answer for Portal Performance-A-class Servers; Hewlett-Packard Company, 2 pgs. © 2000.</td></tr><tr><td class="patent-data-table-td ">55</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: HP'S Answer for Portal Performance—A-class Servers; Hewlett-Packard Company, 2 pgs. © 2000.</td></tr><tr><td class="patent-data-table-td ">56</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Internet Shock Absorber, Cable and Wireless plc., 5 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">57</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: ISP Power Overview, inovaware.com, Inovaware Corporation; 2 pgs.; copyright 1997-2000.</td></tr><tr><td class="patent-data-table-td ">58</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Lightspeed Systems, Corporate Overview, 3 pgs., Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">59</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Luminate Introduces Luminate.Net e-Service, Luminate, Inc., 2 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">60</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: PATROL® for Performance Management-Prediction in Action, BMC Software, Inc., 2 pgs.; Copyright 2001.</td></tr><tr><td class="patent-data-table-td ">61</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: PATROL® SRM: The Foundation of Application-Centric Storage Management@, BMC Software, Inc., 2 pgs.; Copyright 2001.</td></tr><tr><td class="patent-data-table-td ">62</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: rackspace.com; 2 pages; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">63</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Remedy AR System Integration Module for PATROL, BMC Software, Inc., 2 pages, Copyright 2001.</td></tr><tr><td class="patent-data-table-td ">64</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: Resonate®, Resonate, Inc.; 1 pg.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">65</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: table of contents and chapter abstracts for-ISP Survival Guide: Stratetgies for Running a Competitive ISP, Geoff Huston, Wiley Computer Publishing, 16 pgs.; Oct. 1998.</td></tr><tr><td class="patent-data-table-td ">66</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: table of contents and chapter abstracts for—ISP Survival Guide: Stratetgies for Running a Competitive ISP, Geoff Huston, Wiley Computer Publishing, 16 pgs.; Oct. 1998.</td></tr><tr><td class="patent-data-table-td ">67</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: USi Complex Web Hosting Solution and Lattice Communications, Usinternetworking, Inc., 2 pgs.; not dated.</td></tr><tr><td class="patent-data-table-td ">68</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: White Paper: Tivoli Service Provider Solutions, Tivoli Systems, Inc.; 24 pgs.; Copyright 1999.</td></tr><tr><td class="patent-data-table-td ">69</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out: XaCCT Offers Multivendor, Multitechnology Billing Model for ISP Consumption, John Morency, Network World Fusion on Network/Systems Management, Network World, Inc.; 3 pgs.; Sep. 1998.</td></tr><tr><td class="patent-data-table-td ">70</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Web site print-out; Coblat RaQ, Cobalt Network Systems; 2 pgs. © 2001.</td></tr><tr><td class="patent-data-table-td ">71</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">White paper: IBM Netfinity X-architecture, IBM Corporation; 22 pgs.; © 1998.</td></tr><tr><td class="patent-data-table-td ">72</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">White Paper: Stratus ftServers: Enhancing Software Reliability and Availability for Windows 2000, Stratus Computer Systems; 10 pgs.; Copyright 2000.</td></tr><tr><td class="patent-data-table-td ">73</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">White Paper: The HP Open View Approach to Change and Configuraton Management, Hewlett-Packard Company, 23 pgs.; Copyright 1999.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7844513">US7844513</a></td><td class="patent-data-table-td patent-date-value">Jul 17, 2001</td><td class="patent-data-table-td patent-date-value">Nov 30, 2010</td><td class="patent-data-table-td ">Galactic Computing Corporation Bvi/Bc</td><td class="patent-data-table-td ">Method and system for operating a commissioned e-commerce service prover</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8032620">US8032620</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 24, 2004</td><td class="patent-data-table-td patent-date-value">Oct 4, 2011</td><td class="patent-data-table-td ">Marlin Scott</td><td class="patent-data-table-td ">Method and system for improved in-line management of an information technology network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8126751">US8126751</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 14, 2006</td><td class="patent-data-table-td patent-date-value">Feb 28, 2012</td><td class="patent-data-table-td ">Alexander Mekyska</td><td class="patent-data-table-td ">Method for allocating system costs of the infrastructure of a computer center</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8131843">US8131843</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 31, 2009</td><td class="patent-data-table-td patent-date-value">Mar 6, 2012</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Adaptive computing using probabilistic measurements</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8185624">US8185624</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 9, 2009</td><td class="patent-data-table-td patent-date-value">May 22, 2012</td><td class="patent-data-table-td ">Oracle International Corporation</td><td class="patent-data-table-td ">Efficient on-demand provisioning of servers for specific software sets</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8352607">US8352607</a></td><td class="patent-data-table-td patent-date-value">Dec 7, 2007</td><td class="patent-data-table-td patent-date-value">Jan 8, 2013</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Co-location and offloading of web site traffic based on traffic pattern recognition</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8429049">US8429049</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 27, 2011</td><td class="patent-data-table-td patent-date-value">Apr 23, 2013</td><td class="patent-data-table-td ">Galactic Computing Corporation Bvi/Ibc</td><td class="patent-data-table-td ">Method and system for allocating computing resources</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8538843">US8538843</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 30, 2010</td><td class="patent-data-table-td patent-date-value">Sep 17, 2013</td><td class="patent-data-table-td ">Galactic Computing Corporation Bvi/Bc</td><td class="patent-data-table-td ">Method and system for operating an E-commerce service provider</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8607046">US8607046</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 23, 2007</td><td class="patent-data-table-td patent-date-value">Dec 10, 2013</td><td class="patent-data-table-td ">Netapp, Inc.</td><td class="patent-data-table-td ">System and method for signing a message to provide one-time approval to a plurality of parties</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100228839">US20100228839</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 9, 2009</td><td class="patent-data-table-td patent-date-value">Sep 9, 2010</td><td class="patent-data-table-td ">Oracle International Corporation</td><td class="patent-data-table-td ">Efficient on-demand provisioning of servers for specific software sets</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120137004">US20120137004</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 27, 2011</td><td class="patent-data-table-td patent-date-value">May 31, 2012</td><td class="patent-data-table-td ">Smith Philip S</td><td class="patent-data-table-td ">Method and System for Operating a Commissioned E-Commerce Service Prover</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130238801">US20130238801</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 19, 2012</td><td class="patent-data-table-td patent-date-value">Sep 12, 2013</td><td class="patent-data-table-td ">Galactic Computing Corporation Bvi/Ibc</td><td class="patent-data-table-td ">Method and System for Providing Dynamic Hosted Service Management Across Disparate Accounts/Sites</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc709/defs709.htm&usg=AFQjCNFBXWYqUOVuuxerz7B8cqt9daJk7Q#C709S226000">709/226</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc709/defs709.htm&usg=AFQjCNFBXWYqUOVuuxerz7B8cqt9daJk7Q#C709S229000">709/229</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc718/defs718.htm&usg=AFQjCNHE1_70gbRE8lsQx8Ve_NnzRKoSaA#C718S106000">718/106</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06Q0010000000">G06Q10/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0015160000">G06F15/16</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0012000000">G06F12/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0009500000">G06F9/50</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F9/5061">G06F9/5061</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06Q10/06">G06Q10/06</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=PG1rBgABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04L67/1014">H04L67/1014</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06Q10/06</span>, <span class="nested-value">G06F9/50C</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Oct 7, 2013</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 11, 2012</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 6,17-20 AND 26 ARE CANCELLED. CLAIMS 1, 3-5, 7-11, 13-16, 21-25 AND 27-28 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 2 AND 12, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. NEW CLAIMS 29-37 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 20, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110728</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1jPGmbf-OOLuIFHe70HnzgFSDSZg\u0026id=PG1rBgABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U3s8LBegYrkGp98wT-pIRnvf_3aUg\u0026id=PG1rBgABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1zXSsDvvjDnwjm1PHQKHC8vq5GHg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_and_system_for_providing_dynamic.pdf?id=PG1rBgABERAJ\u0026output=pdf\u0026sig=ACfU3U1ep_Rmz8_Dzn_-gOUnQt7StSKMCQ"},"sample_url":"http://www.google.com/patents/reader?id=PG1rBgABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>