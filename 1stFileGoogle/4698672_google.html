<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US4698672 - Coding system for reducing redundancy - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Coding system for reducing redundancy"><meta name="DC.contributor" content="Wen-Hsiung Chen" scheme="inventor"><meta name="DC.contributor" content="Daniel J. Klenke" scheme="inventor"><meta name="DC.contributor" content="Compression Labs, Inc." scheme="assignee"><meta name="DC.date" content="1986-10-27" scheme="dateSubmitted"><meta name="DC.description" content="The present invention relates to methods and apparatus for processing signals to remove redundant information thereby making the signals more suitable for transfer through a limited-bandwidth medium. The present invention specifically relates to methods and apparatus useful in video compression systems. Typically, the system determines differences between the current input signals and the previous input signals using mean-square difference signals. These mean-square signals are processed and compared with one or more thresholds for determining one of several modes of operation. After processing in some mode, the processed signals are in the form of digital numbers and these digital numbers are coded, using ordered redundancy coding, and transmitted to a receiver."><meta name="DC.date" content="1987-10-6" scheme="issued"><meta name="DC.relation" content="US:4302775" scheme="references"><meta name="DC.relation" content="US:4476495" scheme="references"><meta name="DC.relation" content="US:4520490" scheme="references"><meta name="DC.relation" content="US:4558370" scheme="references"><meta name="DC.relation" content="US:4633325" scheme="references"><meta name="citation_patent_number" content="US:4698672"><meta name="citation_patent_application_number" content="US:06/923,630"><link rel="canonical" href="http://www.google.com/patents/US4698672"/><meta property="og:url" content="http://www.google.com/patents/US4698672"/><meta name="title" content="Patent US4698672 - Coding system for reducing redundancy"/><meta name="description" content="The present invention relates to methods and apparatus for processing signals to remove redundant information thereby making the signals more suitable for transfer through a limited-bandwidth medium. The present invention specifically relates to methods and apparatus useful in video compression systems. Typically, the system determines differences between the current input signals and the previous input signals using mean-square difference signals. These mean-square signals are processed and compared with one or more thresholds for determining one of several modes of operation. After processing in some mode, the processed signals are in the form of digital numbers and these digital numbers are coded, using ordered redundancy coding, and transmitted to a receiver."/><meta property="og:title" content="Patent US4698672 - Coding system for reducing redundancy"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("jaztU_SAOPHKsASHsoHwCw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("PAN"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("jaztU_SAOPHKsASHsoHwCw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("PAN"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us4698672?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US4698672"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=FaImBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS4698672&amp;usg=AFQjCNG0lSSI0n67AdjfnJyaZrwpx_QMag" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US4698672.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US4698672.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US4698672" style="display:none"><span itemprop="description">The present invention relates to methods and apparatus for processing signals to remove redundant information thereby making the signals more suitable for transfer through a limited-bandwidth medium. The present invention specifically relates to methods and apparatus useful in video compression systems....</span><span itemprop="url">http://www.google.com/patents/US4698672?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US4698672 - Coding system for reducing redundancy</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US4698672 - Coding system for reducing redundancy" title="Patent US4698672 - Coding system for reducing redundancy"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US4698672 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 06/923,630</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Oct 6, 1987</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Oct 27, 1986</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Oct 27, 1986</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/DE3789273D1">DE3789273D1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE3789273T2">DE3789273T2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0266049A2">EP0266049A2</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0266049A3">EP0266049A3</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0266049B1">EP0266049B1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">06923630, </span><span class="patent-bibdata-value">923630, </span><span class="patent-bibdata-value">US 4698672 A, </span><span class="patent-bibdata-value">US 4698672A, </span><span class="patent-bibdata-value">US-A-4698672, </span><span class="patent-bibdata-value">US4698672 A, </span><span class="patent-bibdata-value">US4698672A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Wen-Hsiung+Chen%22">Wen-Hsiung Chen</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Daniel+J.+Klenke%22">Daniel J. Klenke</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Compression+Labs,+Inc.%22">Compression Labs, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US4698672.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US4698672.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US4698672.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (5),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (154),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (58),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (11)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/4698672&usg=AFQjCNHg5dLTGkZprUr8tqWBE92OVWwChw">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D4698672&usg=AFQjCNFehcB6zNIEvPgnYcFR8o4vm8KHBQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D4698672A%26KC%3DA%26FT%3DD&usg=AFQjCNFIAw1uOd1aJn7i0olPA75QtDbepA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT53233606" lang="EN" load-source="patent-office">Coding system for reducing redundancy</invention-title></span><br><span class="patent-number">US 4698672 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA36705873" lang="EN" load-source="patent-office"> <div class="abstract">The present invention relates to methods and apparatus for processing signals to remove redundant information thereby making the signals more suitable for transfer through a limited-bandwidth medium. The present invention specifically relates to methods and apparatus useful in video compression systems. Typically, the system determines differences between the current input signals and the previous input signals using mean-square difference signals. These mean-square signals are processed and compared with one or more thresholds for determining one of several modes of operation. After processing in some mode, the processed signals are in the form of digital numbers and these digital numbers are coded, using ordered redundancy coding, and transmitted to a receiver.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(3)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4698672-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4698672-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4698672-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4698672-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US4698672-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US4698672-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(46)</span></span></div><div class="patent-text"><div mxw-id="PCLM58854288" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A method for processing digital signals, where the digital signals have first values, second values and other values, to reduce the amount of data utilized to represent the digital signals and to form statistically coded signals such that the more frequently occurring values of digital signals are represented by shorter code lengths and the less frequently occurring values of digital signals are represented by longer code lengths, comprising,<div class="claim-text">forming first runlength code values representing the number of consecutive first values of said digital signals followed by said second value,</div> <div class="claim-text">forming second runlength code values representing the number of consecutive first values of said digital signals followed by one of said other values.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The method of claim 1 further including the step of amplitude encoding said other values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The method of claim 1 further including the step of encoding said first and second runlength code values with a sign value.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The method of claim 1 wherein said first values have amplitude zero, said second values have absolute amplitude one, and said other values have absolute amplitudes greater than one whereby said first and second runlength codes values are formed representing the number of consecutive zeros.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The method of claim 1 wherein said first values have the highest frequency of occurrence in said digital signals, wherein said second values have the next highest frequency of occurrence in said digital signals, and wherein said other values have the lowest frequency of occurrence in said digital signals.</div>
    </div>
    </div> <div class="claim"> <div num="6" class="claim">
      <div class="claim-text">6. A method for processing input signals to reduce the amount of data utilized to represent the input signals, the steps comprising,<div class="claim-text">processing the input signals to form processed signals where the processed signals are digital numbers having first values, second values, and other values,</div> <div class="claim-text">coding each digital number to form statistically coded signals such that the more frequently occurring values in the digital numbers are represented by shorter code lengths and the less frequently occurring values of coded signals are represented by longer code lengths, said coding including,<div class="claim-text">forming first runlength code values representing the number of consecutive first values followed by said second value in a digital number,</div> <div class="claim-text">forming second runlength code values representing the number of consecutive first values followed by one of said other values in the digital number.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The method of claim 6 wherein said coding step includes the step of amplitude encoding said other values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The method of claim 6 wherein said coding step includes the step of encoding said first and second runlength code values with a sign value.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The method of claim 6 wherein said processing step forms said first values with amplitude zero, forms said second values with absolute amplitude one, and forms said other values with absolute amplitudes greater than one.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The method of claim 6 wherein a table is provided storing a plurality of runlength code values representing a plurality of different numbers of consecutive first values followed by said second value, and storing a plurality of second runlength code values representing a plurality of different numbers of consecutive first values followed by one of said other values, said first runlength code values and said second runlength code values statistically organized in said table such that the statistically more frequently occurring runlength code values are represented by shorter code lengths and the less frequently occurring values are represented by longer code lengths, and wherein<div class="claim-text">said step of forming first runlength code values is performed by table lookup from said table,</div> <div class="claim-text">said step of forming second runlength code values is performed by table lookup from said table.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The method of claim 6 wherein said coding step further includes the step of providing an end code to designate the end of a digital number.</div>
    </div>
    </div> <div class="claim"> <div num="12" class="claim">
      <div class="claim-text">12. A method for processing digital signals, where the digital signals have first values, second values and other values, where the processing reduces the amount of data utilized to represent the digital signals and where the processing forms statistically coded signals such that the more frequently occurring values of digital signals are represented by shorter code lengths and the less frequently occurring values of digital signals are represented by longer code lengths, comprising,<div class="claim-text">forming a first code value representing a set of said first values followed by said second value,</div> <div class="claim-text">forming a second code value representing a set of said first values followed by one or more of said other values.</div> </div>
    </div>
    </div> <div class="claim"> <div num="13" class="claim">
      <div class="claim-text">13. A method for processing digital signals to reduce the amount of data utilized to represent the digital signals, the steps comprising,<div class="claim-text">processing the digital signals to form processed signals where the processed signals are multivalued digital numbers and have first values, second values, . . . , j-values, (j+1)-values, . . . , n-values for j ranging from 1 to n, and have other values,</div> <div class="claim-text">coding said processed signals to form statistically coded signals such that the more frequently occurring values of the processed signals are represented by shorter code lengths and the less frequently occurring values of coded signals are represented by longer code lengths, said coding including,<div class="claim-text">forming j<sup>th</sup> runlength code values representing the number of consecutive processed signals of said first value followed by said j+1 value, for each value of j from 1 to n,</div> <div class="claim-text">forming additional runlength code values representing the number of consecutive processed signals of said first value followed by any of said other values.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The method of claim 13 wherein said coding step includes the step of amplitude encoding said other values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. The method of claim 13 wherein said coding step includes the step of encoding said j runlength code values with a sign value.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The method of claim 13 wherein said processing step with n=2 forms said first values with j=1 equal to amplitude zero, forms said second values with j=2 equal to absolute amplitude one, and forms said other values with absolute amplitudes greater than one.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The method of claim 13 wherein said processing step forms said first values with j=1 equal to amplitude zero, forms said second values with j=2 equal to absolute amplitude one, and forms third values with j=3 equal to absolute amplitude two, and forms other values for n=3 with absolute amplitude greater than 2.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. The method of claim 6 wherein said processing step includes multiple modes of processing said digital signals to form said processed signals, and includes the step of selecting one of said modes based upon differences in said input signals.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The method of claim 6 wherein said input signals represent images and are presented in sequential frames, said processing step including multiple processing modes for processing said input signals to form said processed signals, and including the step of forming the mean-square difference, d<sub>0</sub>, between input signals from the current frame and representations of input signals from the previous frame and includes the step of forming the mean-square error, d<sub>b</sub>, between input signals from the present frame and the best matched representation of input signals from the previous frame, said processing step including the step of comparing the difference, d<sub>0</sub> -d<sub>b</sub>, with a motion threshold T<sub>M</sub>, and selecting one of said modes based on said comparison.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The method of claim 19 including the step of determining when d<sub>0</sub> -d<sub>b</sub> is less than T<sub>M</sub> and further including the step of selecting a non-motion-compensated replenishment mode when d<sub>0</sub> is less than a predetermined threshold T<sub>R</sub> and d<sub>0</sub> -d<sub>b</sub> is less than T<sub>M</sub>.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. The method of claim 19 including the step of determining when d<sub>0</sub> -d<sub>b</sub> is less than T<sub>M</sub> and further including the step of selecting a non-motion-compensated DPCM mode when d<sub>b</sub> is less than a predetermined threshold T<sub>D/I</sub> and d<sub>0</sub> -d<sub>b</sub> is less than T<sub>M</sub>.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22. The method of claim 19 including the step of selecting an intraframe mode when d<sub>0</sub> is greater than a predetermined threshold T<sub>D/I</sub>.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. The method of claim 19 including the step of determining when d<sub>0</sub> -d<sub>b</sub> is greater than T<sub>M</sub> and further including the step of selecting a motion compensated replenishment mode when d<sub>b</sub> is less than predetermined threshold T<sub>D/R</sub> and d<sub>0</sub> -d<sub>b</sub> is greater than T<sub>M</sub>.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" class="claim">
      <div class="claim-text">24. The method of claim 19 including the step of determining when d<sub>0</sub> -d<sub>b</sub> is greater than T<sub>M</sub> and further including the step of selecting a motion compensated DPCM mode whenever d<sub>b</sub> is greater than a predetermined threshold T<sub>D/R</sub> and d<sub>0</sub> -d<sub>b</sub> is greater than T<sub>M</sub>.</div>
    </div>
    </div> <div class="claim"> <div num="25" class="claim">
      <div class="claim-text">25. An apparatus for processing digital signals, where the digital signals have first values, second values and other values, to reduce the amount of data utilized to represent the digital signals and to form statistically coded signals such that the more frequently occurring values of digital signals are represented by shorter code lengths and the less frequently occurring values of digital signals are represented by longer code lengths, comprising,<div class="claim-text">means for forming first runlength code values representing the number of consecutive first values of said digital signals followed by said second value,</div> <div class="claim-text">means for forming second runlength code values representing the number of consecutive first values of said digital signals followed by one of said other values.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" class="claim">
      <div class="claim-text">26. The apparatus of claim 25 further including means for amplitude encoding said other values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27. The apparatus of claim 25 further including means for encoding said first and second runlength code values with a sign value.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" class="claim">
      <div class="claim-text">28. The apparatus of claim 25 wherein said first values have amplitude zero, said second values have absolute amplitude one, and said other values have absolute amplitudes greater than one whereby said first and second runlength codes values are formed representing the number of consecutive zeros.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" class="claim">
      <div class="claim-text">29. The apparatus of claim 25 wherein said first values have the highest frequency of occurrence in said digital signals, wherein said second values have the next highest frequency of occurrence in said digital signals, and wherein said other values have the lowest frequency of occurrence in said digital signals.</div>
    </div>
    </div> <div class="claim"> <div num="30" class="claim">
      <div class="claim-text">30. An apparatus for processing input signals to reduce the amount of data utilized to represent the input signals, the apparatus comprising,<div class="claim-text">means for processing the input signals to form processed signals where the processed signals are digital numbers having first values, second values, and other values,</div> <div class="claim-text">means for coding each digital number to form statistically coded signals such that the more frequently occurring values in the digital numbers are represented by shorter code lengths and the less frequently occurring values in the digital numbers are represented by longer code lengths, said means for coding including,<div class="claim-text">means for forming first runlength code values representing the number of consecutive first values followed by said second value in a digital number,</div> <div class="claim-text">means for forming second runlength code values representing the number of consecutive first values followed by one of said other values in the digital number.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" class="claim">
      <div class="claim-text">31. The apparatus of claim 30 wherein said means for coding includes means for amplitude encoding said other values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="32" class="claim">
      <div class="claim-text">32. The apparatus of claim 30 wherein said means for coding includes means for encoding said first and second runlength code values with a sign value.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" class="claim">
      <div class="claim-text">33. The apparatus of claim 30 wherein said means for processing forms said first values with amplitude zero, forms said second values with absolute amplitude one, and forms said other values with absolute amplitudes greater than one.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="34" class="claim">
      <div class="claim-text">34. The apparatus of claim 30 including an addressable table storing runlength code values representing different numbers of consecutive first values followed by said second value, and storing a plurality of second runlength code values representing different numbers of said first values followed by one of said other values, said first runlength code values and said second runlength code values organized in said table such that the statistically more frequently occurring runlength code values in digital numbers are represented by shorter code lengths and the less frequently occurring values in digital numbers are represented by longer code lengths, and wherein<div class="claim-text">said means for forming first runlength code values includes means for addressing said addressable table with a runlength number representing the runlength of said first value followed by said second value in order to obtain said first runlength code value from said table, and</div> <div class="claim-text">said means for forming second runlength code values includes means for addressing said addressable table with a runlength number representing the runlength of said first value followed by one of said other values in order to obtain said second runlength code value.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="35" class="claim">
      <div class="claim-text">35. The apparatus of claim 30 wherein said means for coding further includes means for providing an end code to designate an end of a digital number.</div>
    </div>
    </div> <div class="claim"> <div num="36" class="claim">
      <div class="claim-text">36. An apparatus for processing digital signals to reduce the amount of data utilized to represent the digital signals, comprising,<div class="claim-text">means for processing the digital signals to form processed signals where the processed signals are multivalued digital numbers and have first values, second values, . . . , j-values, (j+1)-values, . . . , n-values for j ranging from 1 to n, and have other values,</div> <div class="claim-text">means for coding said processed signals to form statistically coded signals such that the more frequently occurring values in the digital numbers are represented by shorter code lengths and the less frequently occurring values in the digital numbers are represented by longer code lengths, said means for coding including,<div class="claim-text">means for forming j<sup>th</sup> runlength code values representing the number of consecutive processed signals of said first value followed by said j+1 value, for each value of j from 1 to n,</div> <div class="claim-text">means for forming additional runlength code values representing the number of consecutive processed signals of said first value followed by any of said other values.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="37" class="claim">
      <div class="claim-text">37. The apparatus of claim 36 wherein said digital signals represent pixels forming images in sequential frames, said means for processing includes multiple mode processing means for processing said digital signals to form said processed signals, and includes means for forming the mean-square difference, d<sub>0</sub>, between digital signals representing pixels of the current frame and digital signals representing pixels of the previous frame and includes means for forming the mean-square error, d<sub>b</sub>, between the digital signals representing pixels in the present frame and digital signals representing the best matched pixels of the previous frame, said means for processing further including means for comparing the difference, d<sub>0</sub> -d<sub>b</sub>, with a motion threshold T<sub>M</sub>, and means for selecting one of said modes based on said comparison.</div>
    </div>
    </div> <div class="claim"> <div num="38" class="claim">
      <div class="claim-text">38. A method for processing digital signals, where the digital signals have first values, second values and other values, where the processing reduces the amount of data utilized to represent the digital signals and where the processing forms statistically coded signals such that the more frequently occurring values of digital signals are represented by shorter code lengths and the less frequently occurring values of digital signals are represented by longer code lengths, where<div class="claim-text">a first code value is formed representing a set of said first values followed by said second value,</div> <div class="claim-text">a second code value is formed representing a set of said first values followed by one or more of said other values</div> <div class="claim-text">comprising,</div> <div class="claim-text">decoding said first code value to form a set of said first values followed by said second value,</div> <div class="claim-text">decoding said second code value to form a set of said first values followed by one or more of said other values.</div> </div>
    </div>
    </div> <div class="claim"> <div num="39" class="claim">
      <div class="claim-text">39. A method for processing digital signals to reduce the amount of data utilized to represent the digital signals, the steps comprising,<div class="claim-text">processing the digital signals to form processed signals where the processed signals are multivalued digital numbers and have first values, second values, . . . , j-values, (j+1)-values, . . . , n-values for j ranging from 1 to n, and have other values,</div> <div class="claim-text">coding said processed signals to form statistically coded signals such that the more frequently occurring values of the processed signals are represented by shorter code lengths and the less frequently occurring values of coded signals are represented by longer code lengths, said coding including,<div class="claim-text">forming j<sup>th</sup> runlength code values representing the number of consecutive processed signals of said first value followed by said j+1 value, for each value of j from 1 to n,</div> <div class="claim-text">forming additional runlength code values representing the number of consecutive processed signals of said first value followed by any of said other values</div> </div> <div class="claim-text">transmitting said j<sup>th</sup> runlength code values and said additional runlength code values to a receiver to form received signal including received j<sup>th</sup> runlength code values and received additional runlength code values,</div> <div class="claim-text">decoding said received signals to form decoded signals, said decoding including,<div class="claim-text">decoding said received j<sup>th</sup> runlength code values to form a number of consecutive decoded signals of said first value followed by said j+1 value, for each value of j from 1 to n,</div> <div class="claim-text">decoding said received additional runlength code values to form a number of consecutive decoded signals of said first value followed by any of said other values.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="40" class="claim">
      <div class="claim-text">40. The method of claim 39 wherein said coding step includes the step of amplitude encoding said other values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="41" class="claim">
      <div class="claim-text">41. The method of claim 39 wherein said coding step includes the step of encoding said j runlength code values with a sign value.</div>
    </div>
    </div> <div class="claim"> <div num="42" class="claim">
      <div class="claim-text">42. An apparatus for processing input signals to reduce the amount of data utilized to represent the input signals, the apparatus comprising,<div class="claim-text">means for processing the input signals to form processed signals where the processed signals are digital numbers having first values, second values, and other values,</div> <div class="claim-text">means for coding each digital number to form statistically coded signals such that the more frequently occurring values in the digital numbers are represented by shorter code lengths and the less frequently occurring values in the digital numbers are represented by longer code lengths, said means for coding including,<div class="claim-text">means for forming first runlength code values representing the number of consecutive first values followed by said second value in a digital number,</div> <div class="claim-text">means for forming second runlength code values representing the number of consecutive first values followed by one of said other values in the digital number,</div> </div> <div class="claim-text">means for transmitting said j<sup>th</sup> runlength code values and said additional runlength code values to a receiver to form received signal including received j<sup>th</sup> runlength code values and received additional runlength code values,</div> <div class="claim-text">means for decoding said received signals to form decoded signals, said means for decoding including,<div class="claim-text">means for decoding said received j<sup>th</sup> runlength code values to form a number of consecutive decoded signals of said first value followed by said j+1 value, for each value of j from 1 to n,</div> <div class="claim-text">means for decoding said received additional runlength code values to form a number of consecutive decoded signals of said first value followed by any of said other values.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="43" class="claim">
      <div class="claim-text">43. The apparatus of claim 42 wherein said means for coding includes means for amplitude encoding said other values.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="44" class="claim">
      <div class="claim-text">44. The apparatus of claim 42 wherein said means for coding includes means for encoding said first and second runlength code values with a sign value.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="45" class="claim">
      <div class="claim-text">45. The apparatus of claim 42 wherein said means for processing forms said first values with amplitude zero, forms said second values with absolute amplitude one, and forms said other values with absolute amplitudes greater than one.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="46" class="claim">
      <div class="claim-text">46. The apparatus of claim 42 including an addressable table storing runlength code values representing different numbers of consecutive first values followed by said second value, and storing a plurality of second runlength code values representing different numbers of said first values followed by one of said other values, said first runlength code values and said second runlength code values organized in said table such that the statistically more frequently occurring runlength code values in digital numbers are represented by shorter code lengths and the less frequently occurring values in digital numbers are represented by longer code lengths, and wherein<div class="claim-text">said means for forming first runlength code values includes means for addressing said addressable table with a runlength number representing the runlength of said first value followed by said second value in order to obtain said first runlength code value from said table, and</div> <div class="claim-text">said means for forming second runlength code values includes means for addressing said addressable table with a runlength number representing the runlength of said first value followed by one of said other values in order to obtain said second runlength code value.</div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES65620324" lang="EN" load-source="patent-office" class="description">
    <heading>CROSS-REFERENCE TO RELATED APPLICATION</heading> <p>Title: A COMBINED INTRAFRAME AND INTERFRAME TRANSFORM CODING SYSTEM</p>
    <p>Ser. No.: 479,766 Filed: 83/03/28 (now abandoned)</p>
    <p>Inventors: Wen-hsiung Chen, James Parker Elliott, Robert Edwin George Newell, Ralph Emerson Nichols, Albert Edwards Rackett</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>The present invention relates to methods and apparatus for processing signals to remove redundant information thereby making the signals more suitable for transfer through a limited-bandwidth medium. The present invention specifically relates to methods and apparatus useful in video compression systems.</p>
    <p>Many signal processing techniques useful in video compression systems are known. For example, digital encoding is often employed in processing television signals which are to be transferred over transmission channels since digital data streams are more immune to noise degradation.</p>
    <p>In order to digitally encode a television signal, a signficant number of bits, 4 or more, may be required to provide for an acceptable range of gray scale for each of the hundreds of thousands of separate picture elements (pixels) which form an image. Consequently, data rates for unprocessed digitalized television signals typically require a bandwidth greater than 40 megabits per second. If the communications link is an earth satellite, an unprocessed video signal typically occupies nearly the entire bandwidth of the satellite, with very few channels, if any, left over for other uses. A T1 communication channel is typical and has only a 1.5 megabit per second bandwidth. A practical yet effective way to reduce the bandwidth of digitalized television signals is needed so that fewer channels are required for transmission over a communications path and so that the quality of transmitted signals is maintained even when reduced bandwidth transmission is employed.</p>
    <p>U.S. Pat. No. 4,302,775, assigned to the same assignee as the present invention, describes a scene adaptive coding technique which eliminates redundant information and thereby reduces the bandwidth.</p>
    <p>The patent describes a single-pass digital video compression system which implements a two-dimensional cosine transform with intraframe block-to-block comparisons of transform coefficients without need for preliminary statistical matching or preprocessing.</p>
    <p>Each frame of the video image is divided into a predetermined matrix of spatial subframes or blocks. The system performs a spatial domain to transform domain transformation of the picture elements of each block to provide transform coefficients for each block. The system adaptively normalizes the transform coefficients so that the system generates data at a rate determined adaptively as a function of the fullness of a transmitter buffer. The transform coefficient data thus produced is encoded in accordance with amplitude Huffman codes and zero-coefficient runlength Huffman codes which are stored asynchronously in the transmitter buffer. The encoded data is output from the buffer at a synchronous rate for transmission through a limited-bandwidth medium. The system determines the buffer fullness and adaptively controls the rate at which data is generated so that the buffer is never completely emptied and never completely filled.</p>
    <p>In the system receiver, the transmitted data is stored in a receiver buffer at the synchronous data rate of the limited-bandwidth medium. The data is then output from the receiver buffer asynchronously and is decoded in accordance with an inverse of the encoding in the transmitter. The decoded data is inversely normalized and inversely transformed to provide a representation of the original video image.</p>
    <p>The U.S. Pat. No. 4,302,775 patents reduces redundancy by employing intraframe coding techniques utilizing intraframe comparisons of cosine transform coefficients. While the patent provides significant improvement over other techniques, there is a need for even greater compression.</p>
    <p>In addition to intraframe coding techniques, interframe coding techniques have been used to reduce the rate required for video transmission as described, for example, in the above-identified application. Typically, each video frame is held in memory at both the transmitter and the receiver and only frame-to-frame changes are transmitted over the communication link. In contrast to intraframe coding schemes in which the quality of coded images is dependent upon the amount of detail in each single image frame, the quality of the coded image in interframe coding is dependent upon the differences from frame to frame. Frame-to-frame differences are often referred to as "motion".</p>
    <p>Interframe coding techniques are broadly classified into two categories, namely, spatial domain coding and transform domain coding. In real-time interframe spatial-domain coding systems, spatial domain data can be threshold processed to obtain and store frame difference signals in a transmitter buffer. The threshold value can be adaptively determined as a function of the transmitter buffer fullness. In order to eliminate the image breakdown, both spatial and temporal subsampling has been proposed.</p>
    <p>The above-identified U.S. patent application entitled "A Combined Intraframe and Interframe Transform Coding System" employs intraframe and interframe variable prediction transform coding. Images are represented by sequential frames of two-dimensional arrays of digital signals. The digital signals are transformed to form transform coefficients for each frame. Predicted transform coefficients are formed using sets of variable prediction factors. The predicted transform coefficients for each frame are compared with corresponding actual transform coefficients for the frame to form transform coefficient difference signals. The difference signals are processed to control their range of values. The processed difference signals are statistically coded such that the more frequently occurring values are represented by shorter code lengths and the less frequently occurring values are represented by longer code lengths. The coded signals are stored in a buffer memory for transmission. The coded signals in the buffer memory are transmitted, over a limited-bandwidth medium, to the receiver along with processing information. The processing information includes codes identifying the set of variable prediction factors utilized in the transmitter. The same set of variable prediction factors is utilized in the receiver to reconstruct predicted transform coefficients which in turn are used to reconstruct representations of the original images in the transmitter.</p>
    <p>The extension of the Scene Adaptive Coding of U.S. Pat. No. 4,302,775 from intraframe coding to interframe coding has proven very significant in terms of improving image quality and reducing bandwidth. These improvements, however, have created a need for improved coding systems for reducing redundancy and there continues to be a need for improved signal processing methods and apparatus for data compression systems.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention is a signal processor and method for efficiently processing signals using ordered redundancy (OR) coding and any one of a number of different modes.</p>
    <p>The signals to be coded are typically multiple values where the multivalued digital numbers, X(k) are typically the integers 0, 1, 2, 3, 4, . . . , and so on arranged in any order. Frequently, some values are repeated in forming digital numbers and hence the probable frequency of occurrence of some values is different than for other values. In one example of digital numbers, the highest frequency of occurrence is the value 0, the next highest frequency of occurrence is the value 1 and the other values greater than 1 (namely 2, 3, 4, 5, and so on) occur least frequently. With such order to the frequency of occurrence of values to be coded, the ordered redundancy coding of the present invention is most efficient.</p>
    <p>Using ordered redundancy coding, the system codes the highest most frequently occurring values (0's in the usual example) using runlength coding. In the most preferable example, the runlength encoding is of two types, R and R'. The first type, R, is utilized when a runlength of consecutive zeros (0's) is followed by the next most frequently occurring value (1 in the usual case) and the other type, R', is utilized when the runlength of consecutive zeros (0's) is followed by some other value, one of the least frequently occurring values (usually greater than 1 such as 2, 3, and so on). Whenever the second type, R', of runlength coding is employed, the runlength code is typically followed by an amplitude code which explicitly encodes the actual amplitude (2, 3, . . . ) of the following other value. Whenever the first type, R, of runlength coding is employed, no coding of the second value (usually 1) is required because an amplitude of 1 is implied simply by the use of the first type, R, of runlength coding.</p>
    <p>The ordered redundancy coding of the present invention is typically utilized in a system that processes input signals, such as spatial domain image signals occurring in successive frames, to form processed signals for each frame. Any number of different processing modes are possible. The processed signals are in the form of a plurality of multivalued digital numbers, X(k), typically one number, X(k), for each frame.</p>
    <p>In one particular embodiment, the processing modes include two replenishment modes (one with motion compensation and one without), two DPCM modes (one with motion compensation and one without) and one intraframe mode. The decision as to which mode to select is made based upon an analysis of the frame-to-frame differences (motion) between the current input signals and the previous input signals.</p>
    <p>Typically, the system determines differences between the current input signals and the previous input signals using mean-square difference signals. These mean-square signals are processed and compared with one or more thresholds for determining one of several modes of operation. After processing in some mode, the processed signals are in the form of digital numbers and these digital numbers are coded, using ordered redundancy coding, and transmitted to a receiver.</p>
    <p>After transmission of the coded signals, the received signals are decoded and processed in reverse of the particular one of the modes by which the signals were processed in the transmitter.</p>
    <p>In accordance with the above summary, the present invention achieves the objective of providing an improved signal processor for reducing redundancy using ordered redundancy coding.</p>
    <p>The foregoing and other objects, features and advantages of the invention will be apparent from the following detailed description in conjunction with the drawings.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 depicts a block diagram of a transmitter and receiver system.</p>
    <p>FIG. 2 depicts further details of the transmitter of the FIG. 1 system.</p>
    <p>FIG. 3 depicts further details of the coder used in the FIG. 2 transmitter.</p>
    <p>FIG. 4 depicts further details of the decoder used in the receiver.</p>
    <heading>DETAILED DESCRIPTION</heading> <p>Overall System--FIG. 1</p>
    <p>In FIG. 1, a block diagram of a transmitter and a receiver in accordance with the present invention is shown. Digital signals to be processed are input on lines 5 to the transmitter 2. The input signals on lines 5 are processed in one of a number of different modes so as to efficiently compress the data input signals to form processed signals for transmission to a receiver. The processed signals are coded and output on lines 45 from the transmitter 2 and are transmitted to the receiver 3.</p>
    <p>The transmitter 2 includes a forward processor 52 and a feedback (reverse) processor 51. Typically, the input signals on lines 5 represent images and are presented in the space domain as frames in accordance with well known techniques. The forward processor 52 typically processes the spatial domain input signals to form processed signals which typically are transform domain signals arranged in blocks of transform domain coefficients. The forward processor 52 processes the current input signals from the most current frame.</p>
    <p>The reverse processor 51 typically inverse processes signals from transform domain to spatial domain. Processor 51 stores signals representing the previous frame of data and also receives the current input signals so as to enable a comparison to be made between the previous inverse processed input signals and the current input signals. When the current input signals have been transformed from the spatial domain to the transform domain, the reverse processor performs an inverse transform to convert the transform domain signals back to spatial domain signals and stores those spatial domain signals for comparison with the current input spatial domain signals.</p>
    <p>The reverse processor 51 determines changes between the current signals and the previous signals. Typically, these differences are determined using mean-square signals, d<sub>0</sub> and d<sub>b</sub>, hereinafter defined. These mean-square signals are processed and compared with one or more thresholds for determining one of several modes of operation for the system of FIG. 1.</p>
    <p>Any number of different modes are possible. In one particular embodiment, two replenishment modes (one with motion compensation and one without), two DPCM modes (one with motion compensation and one without) and one intraframe mode are employed. The decision as to which mode to select is made based upon an analysis of the frame-to-frame differences (motion) of the input data. After the processing by the processor 52 and the processor 51, the processed signals are input to the coder 14.</p>
    <p>The coder 14 encodes the processed signals using statistical frequency coding. With satistical frequency coding, signals with a statistically higher frequency of occurrence are encoded with a shorter code length than signals with a statistically lower frequency of occurrence. Additionally, the coder 14 utilizes a novel ordered redundancy (OR) coding technique. In the ordered redundancy coding, the processed signals to be coded have multiple values. For example, values are typically 0, 1, 2, 3, 4, . . . , and so on. Typically, the statistical frequencies of the values to be coded have an order. Particularly, that order is based upon the probable frequency of occurrence of the different values. The highest frequency of occurrence is typically the value 0, the next most frequently occurring value is 1 and the other values greater than 1 (2, 3, 4, 5, and so on) occur least frequently. With such order to the signals to be coded, the ordered redundancy coding of the present invention is most efficient.</p>
    <p>Using OR coding, the coder 14 of FIG. 1 codes the highest most frequently occurring values (0's in the usual example) using runlength coding. In the most preferable example, the runlength encoding is of two types, R and R'. The first type, R, is utilized when the runlength of 0's is followed by the next most frequently occurring value (1 in the usual case) and the other type, R', is employed when the runlength of 0's is followed by some other value of the least frequently occurring type (usually greater than 1 such as 2, 3, and so on). Whenever the R' type of runlength coding is employed, the runlength code is typically followed by an amplitude code which explicitly encodes the actual amplitude of the other value. Whenever the first type, R, of runlength coding is employed, no coding of the second value (usually 1) is required because an amplitude of 1 is implied simply by the use of the first type, R, of runlength coding.</p>
    <p>After the ordered redundancy coding in coder 14, data is transferred to the transmitter buffer 15. The buffer 15 provides a feedback signal on line 25 to control the forward processor 52 data rate.</p>
    <p>In FIG. 1, the data from line 45 is input on line 68 after transmission over some conventional transmission medium to the receiver 3. In the receiver 3, a receiver buffer 53 stores the received data. A decoder 54 decodes the received data. Thereafter, the decoded data is processed in reverse of the particular one of the modes by which the data was processed in the transmitter 2. The reconstituted data appears on output line 69.</p>
    <p>Transmitter--FIG. 2</p>
    <p>FIG. 2 is a block diagram of a transmitter for motion compensated combined interframe and intraframe coding system of FIG. 1. Motion compensation is incorporated into a combined interframe and intraframe coding system using the spatial pixels in the inverse loop 9. In operation, the original spatial image on input lines 5 is compared to the reconstructed spatial image on lines 6 of the previous frame on a block-by-block basis through a motion detector 7. The reconstructed spatial image is obtained from the memory 18 of the feedback DPCM loop 9.</p>
    <p>The feedback loop 9 includes the inverse normalizer 16, inverse transformer 17, the sum unit 20, the delay (memory) 18, the prediction unit 19, and the motion detector and compensator 7. If the motion detector 7 determines that there is little difference between the blocks, a "replenishment mode" is selected. On the other hand, if enough difference is detected, the block in the current frame is compared to the neighborhood of the corresponding reconstructed block in the previous frame to find the best match of the block. For the purpose of increasing the system performance a sub-pixel match is employed. If the difference between the current block and its best matched block does not result in a reasonable improvement over the difference between the current block and its original counterpart, a motion compensation is not justified. In this case, a "DPCM mode" with variable predictions is selected to handle the block difference. On the other hand, if the difference between the current block and its best matched block is reasonably smaller than the difference between the current block and its original counterpart, a motion compensation is initiated. In this case, the difference between the current block and its best matched block is screened to determine if the block belongs to a "motion compensated replenishment" block or a "motion compensated DPCM" block. The forward loop of the DPCM system encodes the "DPCM" or "motion compensated DPCM" data in the transform domain. Statistical frequency coding is employed to improve the efficiency. The feedback loop of the DPCM system is operated in the spatial domain with variable predictions.</p>
    <p>Motion Detection and Compensation</p>
    <p>The motion detection serves two purposes. It compares the block pixels in the present frame to the neighborhood pixels of the corresponding block in the previous frame to find the sub-pixel displacement of the block that gives the best match. It also tracks the displacement vectors and the degree of differences during the matching process for a subsequent modification of the DPCM frame memory and controlling of the predictor parameters in the feedback DPCM loop. Three basic types of modes (replenishment modes, intraframe mode, and DPCM modes) are determined from the motion detection. A decision process among the modes is employed. The decision process relies in part on a determination as to whether motion-compensation or non-motion-compensation is to be employed. Motion compensation is determined using the mean-square difference, d<sub>0</sub>, and the mean square error, d<sub>b</sub>.</p>
    <p>The mean-square difference, d<sub>0</sub>, is formed as follows: ##EQU1## where f(j,k) are spatial pixels (on lines 5 of FIG. 2) of the current frame and f(j,k) are the corresponding pixels (on line 6 of FIG. 2) of the reconstructed previous frame. N is the transform block size.</p>
    <p>The mean-square error, d<sub>b</sub>, is formed as follows: ##EQU2## where f(j,k) are the block pixels in the present frame and f(j+Δj,k+Δk) are the best matched pixels in the previously reconstructed frame where Δj,Δk are the displacement (vector) for the best match.</p>
    <p>Replenishment Modes</p>
    <p>The replenishment modes are either motion-compensated or non-motion-compensated. The decision process selects compensation or non-compensation based upon motion detection. The motion detection unit 7 of FIG. 2 determines the difference between the incoming spatial pixels of a block and the reconstructed spatial pixels of the corresponding block in the previous frame. If the motion detection process determines that there is little frame-to-frame difference between corresponding blocks, a non-motion-compensated replenishment mode is selected and a code word is sent on line 21 from unit 7 of FIG. 2 to the encoder 14 to identify the mode.</p>
    <p>If the motion detection process determines that the frame-to-frame block difference is great enough then, under some circumstances, a motion-compensated replenishment mode is selected. The detection process typically uses the mean-square difference, d<sub>0</sub>, and compares it to a predetermined non-motion-compensated replenishment threshold, T<sub>R</sub>. This process is written as follows:</p>
    <p>if (d<sub>0</sub> -d<sub>b</sub>)&lt;T<sub>M</sub> and d<sub>0</sub> &lt;T<sub>R</sub>, select non-motion-compensated replenishment mode.</p>
    <p>The detection process compares the mean square error, d<sub>b</sub>, with a predetermined motion-compensated replenishment threshold, T<sub>D/R</sub>, as follows:</p>
    <p>if (d<sub>0</sub> -d<sub>b</sub>)&gt;T<sub>M</sub> and d<sub>b</sub> &lt;T<sub>D/R</sub>, select motion-compensated replenishment mode.</p>
    <p>The identification code words for the replenishment modes are typically Huffman coded. Typically, a one-bit code (0), on line 21 of FIG. 2 is used if the non-motion-compensated replenishment mode appears most frequently statistically. Once this code word is identified at the receiver, the reconstructed block pixels in the previous frame are repeated to form the present block in the receiver.</p>
    <p>For the motion compensated replenishment block, typically a four-bit code (1111) is used, along with the displacement vector representing the best match, and appears on line 67 in FIG. 2. At the receiver, the vector uses the compensated block pixels from the reconstructed previous frame to form the presently reconstructed block.</p>
    <p>DPCM Modes</p>
    <p>The DPCM modes are either non-motion-compensated or motion-compensated. Selection of the compensation or non-compensation DPCM modes is dependant in part on motion detection. The motion detection searches for the best matched block pixels from the reconstructed previous frame. The difference, d<sub>b</sub>, between the present block pixels and the best matched block pixels is then computed. If this difference is smaller than the motion threshold, T<sub>M</sub>, no motion compensation is justified due to the necessity of sending the displacement vector as coding overhead. In this case, the difference, d<sub>0</sub>, is compared to a DPCM threshold, T<sub>D/I</sub>, to determine if the block belongs to a DPCM mode. The decision process is given as follows:</p>
    <p>if (d<sub>0</sub> -d<sub>b</sub>)&lt;T<sub>M</sub> and d<sub>0</sub> &lt;T<sub>D/I</sub>, select non-motion-compensated DPCM mode.</p>
    <p>If a non-motion-compensated DPCM mode is selected, the predictor in the feedback loop is enabled and the difference is sent to the discrete cosine transformer for subsequent encoding. Again, the mode identification is Huffman coded. Typically, a two-bit code (10) used for the non-motion-compensated DPCM mode and appears on line 66 in FIG. 2.</p>
    <p>At the receiver, the DPCM data are inversely transformed and added onto the block pixels from the reconstructed previous frame to form the present block pixels.</p>
    <p>For the motion-compensated DPCM mode, the difference, d<sub>b</sub>, between the current block pixels and the best matched block pixels is compared to a predetermined motion-compensated replenishment threshold, T<sub>D/R</sub>. If d<sub>b</sub> is larger than the threshold, a motion-compensated DPCM mode is selected to handle the pixel differences.</p>
    <p>The decision processs is given as follows:</p>
    <p>If (d<sub>0</sub> -d<sub>b</sub>)&gt;T<sub>M</sub> and d<sub>b</sub> &gt;T<sub>D/R</sub>, select motion-compensated DPCM mode.</p>
    <p>For the motion compensated DPCM blocks, typically a three-bit code (110) is used together with the displacement vector representing the best match of the block along with the motion compensated DPCM data (transform coefficient differences between the present block and the best matched block from the reconstructed previous frame). The mode ID and vector appear on line 65 in FIG. 2. At the receiver, these DPCM data are inverse transformed and added onto the compensated block pixels from the reconstructed previous frame to form the present block pixels.</p>
    <p>Intraframe Mode</p>
    <p>The intraframe mode is selected when neither the motion-compensated mode nor the DPCM mode is justified. The difference, d<sub>0</sub>, between the current block pixels and the reconstructed previous block pixels is compared with the predetermined DPCM threshold, T<sub>D/I</sub>. The decision process is as follows:</p>
    <p>If (d<sub>0</sub> -d<sub>b</sub>)&lt;T<sub>M</sub> and d<sub>0</sub> &gt;T<sub>D/I</sub>, select intraframe mode.</p>
    <p>If the intraframe mode is selected, the predictor is disabled and the current block pixels are sent to the transformer with unit 11 of FIG. 2. Typically, a four-bit code (1110) appearing on line 66 in FIG. 2 is used to identify the "intraframe mode". The intraframe data in the receiver are inversely transformed to form the present block pixels.</p>
    <p>Compensation Range and Resolution</p>
    <p>The performance of the motion compensated system is dependent upon the range and resolution of the matching process. The larger the range and the finer the resolution, the better the system performs. However, due to the necessity of encoding the vector information as system overhead, the range and resolution of the searching process is somewhat limited.</p>
    <p>Searching Algorithm</p>
    <p>The search for the best matched position is a very time consuming process. As one example, a simple binary search algorithm for a maximum range of 1.75 can be employed. Using such an algorithm, the nine whole-pixel positions centered around the position of the present block are first examined to find the best match. Next, the eight half-pixel neighborhood positions centered around the best matched whole-pixel position are examined. The process continues until the best matched quarter-pixel position is located. The horizontal and vertical addresses of this location are then recorded as a vector and encoded accordingly. The number of steps required for a binary search is many times lower than that of a brute force search.</p>
    <p>Subpixel translation is done by performing bilinear interpolation taking weighted averages of the four nearest values at integral pixel positions surrounding the subpixel location. The weighting factors that are used are linear functions of the horizontal and vertical distance of the fractional displacement from the integral pixel positions. As an example, a displacement of 1.25 horizontally, and 0.75 vertically is performed as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">f(j+1.25,k-0.75)=w<sub>1</sub> f(j+1,k)+w<sub>2</sub> f(j+1,k-1)+w<sub>3</sub> f(j+2,k)+w<sub>4</sub> f(j+2,k-1)                               Eq. (3)</pre>
    
    <p>where w<sub>1</sub> =(0.75) (0.25), w<sub>2</sub> =(0.75) (0.75), w<sub>3</sub> =(0.25) (0.25), and w<sub>4</sub> =(0.25) (0.75)</p>
    <p>DPCM Loop</p>
    <p>Referring to FIG. 2, the Differential Pulse Code Modulated (DPCM) loop consists of a cosine transform unit 11, a normalization unit 12, a quantization unit 13, an inverse normalization unit 16, an inverse transform unit 17, a delay memory 18, and a prediction unit 19. In operation, an input pixel block on lines 5 from the present frame is first subtracted in subtractor 10 by its estimation from the previous frame on line 23 on a pixel-by-pixel basis to generate block differences. These differences are then cosine transformed in transform unit 11 to form the coefficient differences on lines 24. The coefficient differences are next scaled in normalizer unit 12 according to a feedback parameter on lines 25 from the output rate buffer 15. The scaled coefficient difference on lines 26 are then quantized in unit 13 and fed into both the coder unit 14 and the inverse DPCM loop 9. In the inverse DPCM loop 9, the quantized and scaled data are inversely normalized in unit 16 and inversely transformed in unit 17, to form the quantized coefficient differences on lines 27. These differences are then added in adder 20 to the motion compensated estimation on lines 3 to form the reconstructed pixel block in the frame memory 18. After a single-frame delay, in memory 18, the motion detector 7 uses the motion compensated block from the memory 18, multiplies it by a prediction weighting factor, and is ready for the next frame of operation. At the receiver, the received data follows the inverse DPCM loop to reconstruct the spatial pixels in the output block.</p>
    <p>Cosine Transform</p>
    <p>The coefficient differences between the input pixels from the present frame on lines 5 and the estimations from the previously reconstructed frame on lines 3 are formed by the difference circuit 10 on lines 23 and are expressed as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">e<sub>n</sub> (j,k)=f<sub>n</sub> (j,k)-ρ(j,k)f<sub>N-1</sub> (j+Δj,k+Δk) Eq. (4)</pre>
    
    <p>where Δj and Δk represent the vector values for the best match determined by the motion detector and where ρ(j,k) represents the estimation. These differences within a N×N block are cosine transformed in transformer 11 to form the coefficient differences on lines 24. The cosine transform is defined as follows: ##EQU3## where w=u or v where (j,k) and (u,v) represent indices in the horizontal and vertical directions for the pixel difference and coefficient difference blocks, respectively, and where C(w) represents C(u) or C(v). The cosine transform restructures the spatial domain data into the coefficient domain such that it will be beneficial to the subsequent coding and redundancy removal processes.</p>
    <p>Normalization</p>
    <p>The coefficient differences, E<sub>n</sub> (u,v), are scaled according to a feedback normalization factor, D, on lines 25, from the output rate buffer 15 according to the relation,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">I<sub>n</sub> (u,v)=E<sub>n</sub> (u,v)/D                              Eq. (6)</pre>
    
    <p>The scaling process adjusts the range of the coefficient differences such that a desired number of code bits can be used during the coding process.</p>
    <p>Quantization</p>
    <p>The quantization process in unit 13 is any conventional linear or non-linear quantization. The quantization process will set some of the differences to zeros and leave a limited number of significant other differences to be coded. The quantized coefficient differences on lines 28 are represented as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">I<sub>n</sub> (u,v)=Q[I<sub>n</sub> (u,v)]                             Eq. (7)</pre>
    
    <p>where Q[ ] is a quantization function.</p>
    <p>It should be noted that a lower bound is determined for the normalization factor in order to introduce meaningful coefficient differences to the coder. Generally speaking, setting the minimum value of D to one is sufficient for a low rate compression applications involving transform blocks of 16 by 16 pixels. In this case the worst mean square quantization error is less than 0.083. This mean square error corresponds to a peak signal-to-quantization-noise ratio of 40.86 db which is relatively insignificant for low rate applications.</p>
    <p>Inverse Normalization</p>
    <p>The process of inverse normalization in unit 16 produces the quantized coefficient differences on lines 29 in the inverse DPCM loop 9. This process is represented as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">E<sub>n</sub> (u,v)=I<sub>n</sub> (u,v)D                               Eq. (8)</pre>
    
    <p>Inverse Cosine Transform</p>
    <p>The inverse cosine transform process in unit 17 in the inverse DPCM loop 9 converts the quantized coefficient differences on lines 29 back to the spatial domain pixel differences on lines 27. This process is defined as follows: ##EQU4##</p>
    <p>Frame Memory</p>
    <p>The frame memory 18 contains the reconstructed input pixels in the inverse DPCM loop. The quantized pixel differences from the inverse cosine transformer on lines 27 and the motion compensated estimations from the previously reconstructed frame on lines 3 are added together in adder 20 to form the reconstructed pixels, f<sub>n</sub> (j,k), which replace the block pixels in the memory 18. This process is represented as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">f<sub>n</sub> (j,k)=e<sub>n</sub> (j,k)+ρ(j,k)f<sub>n-1</sub> (j+Δj,k+Δk) Eq. (10)</pre>
    
    <p>Prediction</p>
    <p>The prediction process in unit 19 finds an estimation of a datum from its surrounding data. By way of example for a simple predictor that uses the previous frame as a base for the estimation, the estimated value is termed as the correlation coefficient, ρ(j,k), given as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">ρ(j,k)=E[e<sub>n</sub> (j,k)e<sub>n-1</sub> (j+Δj,k+Δk)]/σ<sup>2</sup> (j,k)                                                     Eq. (11)</pre>
    
    <p>where E represents expected value and σ<sup>2</sup> (j,k) represents the variance of e<sub>n</sub> (j,k). The correlation coefficient, termed as leak factor, ranges from 0 to 1 depending on the frame-to-frame pixel differences. The value is very close to 1 for a limited motion sequence. However, during a scene cut or a rapid zooming sequence, the value is way below the value of 1. Because different leak factors have to be identified in the encoding of the DPCM process, it represents a significant overhead for the low rate system if too many values are to be identified. In one embodiment, only two leak factor values are used for the five-mode motion detection system: 1 for the non-motion-compensated DPCM and motion compensated DPCM modes and 0 for the intraframe mode.</p>
    <p>Coding</p>
    <p>In order to minimize overhead code bits, in one typical example the encoding process in unit 14 for the FIG. 2 system is performed on a frame by frame bases. The coded bit stream includes sync, header, scaling factor (NF), and variable-length data as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">              TABLE 1______________________________________                variable______________________________________SYNC     HEADER         NF     DATA______________________________________</pre>
    
    <p>In the header, at least one bit is reserved for the identification of full motion and graphic operations. The data portion includes the block-to-block mode identifiers, the vector values, DPCM and intraframe data. The bit allocations are dependent upon each individual block which is illustrated in TABLE 2.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">              TABLE 2______________________________________MODEReplenishment Block4        8MODE     VECTORReplenishment of Motion Compensated Block2        variableMODE     DPCM             EOBDPCM of Non-motion Compensated Block4        variableMODE     INTRAFRAME       EOBIntraframe of Non-motion Compensated Block3        8                variableMODE     VECTOR           DPCM      EOBDPCM of Motion Compensated Block______________________________________</pre>
    
    <p>DPCM Encoding</p>
    <p>The Scene Adaptive Coding (SAC) is very efficient in terms of coding the intraframe transform coefficients. When this scheme is applied to a coding system involving intraframe, interframe and motion compensation, the coding efficiency is somewhat reduced due to the structure of coefficient differences or motion compensated coefficient differences caused by the additional removal of redundancies. One observation that can be made in the motion compensated coefficient differences (non-zero after normalization and quantization) and, to a certain degree, the interframe coefficient differences (non-zero differences) is that most of these differences are sparsely distributed with an overwhelming majority of them having an absolute value of one. Also, within these differences of ones, a significant portion of them are isolated (surrounded by zero-valued coefficients) along the path of a scanning. It is wasteful to use one amplitude code word to code each of these isolated ones in addition to using one runlength code word to identify their address (Runlength alone should be enough).</p>
    <p>Ordered Redundancy Coding</p>
    <p>A new Ordered Redundancy (OR) coding algorithm is specifically designed to code multi-valued digital numbers where the statistical frequency of occurrence of some values in the series of values forming the digital number is greater than the statistical frequency of occurrence for other values in the series of values forming the digital number. The values forming the digital numbers are generally the integers 0, 1, 2, 3, . . . and so on.</p>
    <p>In general, a K-valued digital number, X(k), is formed by a series of K values, x(k), as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">X(k)=x(1), x(2), x(3), . . . x(k), . . . , x(K)</pre>
    
    <p>where 1≦k≦K. Each value, x(k), has some value, V<sub>j</sub>, from the set of J values,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">V<sub>1</sub>, V<sub>2</sub>, V<sub>3</sub>, . . . , V<sub>j</sub>, . . . , V<sub>J</sub> </pre>
    
    <p>where 1≦j≦J.</p>
    <p>The occurrence of i consecutive values, V<sub>j</sub>, within the series X(k) is the runlength of such values denoted by V<sub>j</sub> <sup>i</sup>.</p>
    <p>In a first example with k=1, . . . , 14, if the digital number X<sub>1</sub> (k)=01000000100021, V<sub>0</sub> =0, V<sub>1</sub> =1 and V<sub>2</sub> =2 then X<sub>1</sub> (k)=V<sub>0</sub> <sup>1</sup>, V<sub>1</sub> <sup>1</sup>, V<sub>0</sub> <sup>6</sup>, V<sub>1</sub> <sup>1</sup>, V<sub>0</sub> <sup>3</sup>, V<sub>2</sub> <sup>1</sup>, V<sub>1</sub> <sup>1</sup>. In the series values forming X<sub>1</sub> (k), the first value V<sub>0</sub> =0 occurs most frequently, the second value V<sub>1</sub> =1 occurs next most frequently, and the other value V<sub>2</sub> =2 occurs least frequently.</p>
    <p>In a second example with k=1, . . . , 14, if the digital number X<sub>2</sub> (k)=02111110001130, and V<sub>0</sub> =1, V<sub>1</sub> =0, V<sub>2</sub> =2, and V<sub>3</sub> =3; then X<sub>2</sub> (k)=V<sub>1</sub> <sup>1</sup>, V<sub>2</sub> <sup>1</sup>, V<sub>0</sub> <sup>5</sup>, V<sub>1</sub> <sup>3</sup>, V<sub>0</sub> <sup>2</sup>, V<sub>3</sub> <sup>1</sup>, V<sub>1</sub> <sup>1</sup>. In the series of values forming X<sub>2</sub> (k), the first value, V<sub>0</sub> =1, occurs most frequently, the seond value V<sub>1</sub> =0 occurs next most frequently, and the other values, V<sub>2</sub> =2 and V<sub>3</sub> =3, occur next most frequently.</p>
    <p>Digital numbers formed with such frequencies of occurrence of values such as for X<sub>1</sub> (k) and X<sub>2</sub> (k) above, are defined as having ordered redundancy. In the typical example described for X<sub>1</sub> (k), 0's are most redundant, 1's are next most redundant, and so on. The frequency of occurrence order of values 0, 1, 2, . . . and so on described is merely one typical example. Any frequency of occurrence order is possible, for example, the 2's may occur more frequently than 1's and 0's may occur more frequently than 2's.</p>
    <p>Digital numbers, X(k), will often have ordered redundancy of the values, V<sub>j</sub>, forming the number. Ordered redundancy means that the frequency of occurrence of some of the values, V<sub>j</sub>, formng the number (or groups of such values) is greater than that for other values (or other groups of such values) forming the number and that such frequencies of occurrence are predictable for a number of digital numbers, X(k).</p>
    <p>When such ordered redundancy occurs, the ordered redundancy coding of the present invention is useful in making the coding more efficient. In the present invention, the presence of a first value (or a first set of values) is used to imply the existence of a second value (or a second set of values) thereby eliminating the need to code the second value (or second set of values).</p>
    <p>By way of example, the coding of the digital number X<sub>1</sub> (k) above is achieved as follows. Assume that when the first value, V<sub>0</sub>, is followed by the second value, V<sub>1</sub>, that the second value is implied and such code is denoted C<sub>01</sub> <sup>i</sup> where i represents the number of consecutive first values V<sub>0</sub> preceding the implied second value, V<sub>1</sub>. Assume that when the first value V<sub>0</sub>, is not followed by the second value, V<sub>1</sub>, such code is denoted C<sub>01</sub> <sup>i</sup>. Assume that any other value is amplitude coded with A<sub>2</sub> =2 and A<sub>3</sub> =3. With such a notation, X<sub>1</sub> (k)=C<sub>01</sub> <sup>1</sup>, C<sub>01</sub> <sup>6</sup>, C<sub>01</sub> <sup>3</sup>, A<sub>3</sub>, C<sub>01</sub> <sup>0</sup>.</p>
    <p>By way of the second example, X<sub>2</sub> (k) above, the first value, V<sub>0</sub> -1 implies the second value, V<sub>1</sub> =0 such that X<sub>2</sub> (k)=C<sub>01</sub> <sup>0</sup>, C<sub>01</sub> <sup>3</sup>, A<sub>2</sub>, C<sub>01</sub> <sup>5</sup>, C<sub>01</sub> <sup>0</sup>, C<sub>01</sub> <sup>0</sup>, C<sub>01</sub> <sup>0</sup>, C<sub>01</sub> <sup>2</sup>, A<sub>3</sub>, C<sub>10</sub> <sup>0</sup>.</p>
    <p>In order to code X<sub>1</sub> (k)=C<sub>01</sub> <sup>1</sup>, C<sub>01</sub> <sup>6</sup>, C<sub>01</sub> <sup>3</sup>, A<sub>3</sub>, C<sub>01</sub> <sup>0</sup>, each of the values C<sub>01</sub> <sup>1</sup>, C<sub>01</sub> <sup>6</sup> and so forth are represented by a unique statistical code (typically a binary code) from a runlength table such that the statistically more frequently occurring values have shorter code lengths and the statistically less frequently occurring values have longer code lengths.</p>
    <p>A series of values in digital numbers having a large percentage of zeros (0's) followed by ones (1's) is termed "One's Redundancy". One's Redundancy Coding is one example of Ordered Redundancy (OR) coding. The OR coding procedures for One's Redundancy appear in TABLE 3 and are based upon 16×16 transform blocks of values where each such block gives rise to a digital number, X(k), having 256 values. Of course, any size blocks (N×M) of digital values can be selected. Also, the digital values can be in block form representing transform coefficients or can be multi-valued digital signals, X(k), of any form.</p>
    <p>In order to identify the beginning or end of the values forming a number, X(k), a special "End of Block" signal, EOB, is utilized. When a plurality of numbers X<sub>1</sub> (k), X<sub>2</sub> (k), X<sub>3</sub> (k), . . . and so on are to be coded and transmitted, the EOB code is inserted between the numbers, usually once after each number.</p>
    <p>The TABLE 3 example is premised upon digital signals having first values V<sub>1</sub> =0, second values V<sub>2</sub> =1, and a set of other values, V<sub>2</sub>, greater than 1 (2, 3, 4, . . . ). Also, TABLE 3 has a runlength table partitioned into first and second parts, a first part, R (or C<sub>01</sub>), and a second part, R' (or C<sub>01</sub>). The first part, R, implies that a runlength of 0's is followed by a 1. The second part, R', implies that a runlength of 0's is followed by another value greater than 1 (2, 3, 4, . . . ). The TABLE 3 formulation is for one preferred embodiment of the ordered redundancy coding. Many variations, some hereinafter described, are possible.</p>
    <heading>TABLE 3</heading> <p>1. From the magnitude (without sign) of quantized coefficient difference, form the following sets of histograms</p>
    <p>a. Runlength of consecutive zero-value coefficient differences (including runlength of zero length) with absolute amplitude value of one at the end of the runlength.</p>
    <p>b. Runlength of consecutive zero-valued coefficient differences (including runlength of zero length) with absolute amplitude value of greater than one at the end of the runlength.</p>
    <p>c. Occurrence of end of blocks (EOB, all 0's)</p>
    <p>2. Get runlength Huffman code table from the histogram of 1 above. The entries of this table can be represented as R<sub>0</sub>, R<sub>1</sub>, R<sub>2</sub>, . . . , R<sub>255</sub>, R'<sub>0</sub>, R'<sub>1</sub>, R'<sub>2</sub>, . . . , R'<sub>255</sub>, EOB.</p>
    <p>3. From case b of 1, get the histogram of the amplitudes (with values greater than one) at the end of the runlength.</p>
    <p>4. Get amplitude Huffman code table from the histogram of 3 above. The entries of this table can be represented as A<sub>2</sub>, A<sub>3</sub>, A<sub>4</sub>, . . . , A<sub>510</sub>.</p>
    <p>5. Encode the coefficient differences along the zig-zag path from the Huffman tables generated from 2 and 4 in the following fashion.</p>
    <p>a. Coefficient differences of one at the end of the consecutive zeros--encode with R+SIGN, n=1, 2, 3, . . . , , 255.</p>
    <p>b. Coefficient differences of greater than one at the end of consecutive zeros--encode with R'+A<sub>m</sub> +SIGN, n=1, 2, 3, . . . , 255 and m=2, 3, 4, . . . , 510.</p>
    <p>6. Encode with EOB at the end of each block.</p>
    <p>As can be seen from TABLE 3, two Huffman tables or equivalent statistical coding tables are specified in the "One's Redundancy" (OR) coding. The runlength table (including EOB) consists of two parts, R and R', with a total of 513 entries (256 each for the first part R and the second part R' and 1 for EOB). The amplitude table consists of 509 entries (amplitude values of 2 to 510). In a practical implementation, these two tables can be shortened with little performance degradation.</p>
    <p>Specific examples of the two tables specified in accordance with TABLE 3 appear as the following TABLES 6 and 7. TABLE 6 is a runlength table of the two part example (R and R' or R<sub>1</sub> and R<sub>2</sub>) where R implies a runlength of 0's followed by a 1. TABLES 6 and 7 are derived based upon the hardware constraints (which are intended to be representative of a practical system, but are not intended to be limiting) of the following TABLE 4:</p>
    <heading>TABLE 4</heading> <p>1. Every code word must belong to part of a complete "tree".</p>
    <p>2. The longest code word (including runlength escape, runlength code and sign, or amplitude escape and amplitude code) must not exceed 16 bits in length.</p>
    <p>3. The maximum number of entries for each runlength or amplitude table must not exceed 32.</p>
    <p>TABLE 5 gives four comparative examples for coding digital numbers using Scene Adaptive Coding (SAC) and One's Redundancy (OR) coding. The One's Rendundancy coding examples utilize TABLES 6 and 7 and the Scene Adaptive Coding examples utilize TABLES 8 and 9. As can be seen from TABLE 5, the OR coding is considerably shorter than the SAC coding and hence OR coding is more efficient.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">              TABLE 5______________________________________COMPARISON OF "OR" AND "SAC" CODING______________________________________1.  CO     00000000000000000001 EOB    SAC    RLP+R<sub>19</sub> + A<sub>1</sub> +S + EOB      01/1110111/11/0/100001    OR     R<sub>19</sub> +S+EOB      0001000/0/00102.  CO     001-1000001000-1 EOB    SAC    RLP+R<sub>2</sub> +A<sub>1</sub> +S+A<sub>1</sub> +-S+RLP+R<sub>5</sub> +A<sub>1</sub>      +S+RLP+      R<sub>3</sub> +A<sub>1</sub> +-S+EOB      01/1111/11/0/11/1/01/11010/11/0/01/1011/11/1/      100001    OR     R<sub>2</sub> +S+R<sub>0</sub> +-S+R<sub>5</sub> +S+R<sub>3</sub> +-S+EOB      1110/0/10/1/00011/0/0000/1/00103.  CO     20000000-1 EOB    SAC    A<sub>2</sub> +S+RLP+R<sub>7</sub> +A<sub>1</sub> +-S+EOB      101/0/01/110011/11/1/100001    OR     R<sub>0</sub> '+A<sub>2</sub> +S+R<sub>7</sub> +-S+EOB      110/1/0/011110/1/00104.  CO     1001-200001 EOB    SAC    A<sub>1</sub> +S+R<sub>2</sub> +A<sub>1</sub> +S+A<sub>2</sub> +-S+R<sub>4</sub> +A<sub>1</sub>      +S+EOB      11/0/1111/11/0/101/1/11100/11/0/10001    OR     R<sub>0</sub> +S+R<sub>2</sub> +S+R<sub>0</sub> '+A<sub>2</sub> +-S+R<sub>4</sub> +S+EOB      10/0/1110/0/11011/01101/0/0010______________________________________</pre>
    
    <p>where,</p>
    <p>R=runlength, A=amplitude, S=positive sign,</p>
    <p>S=negative sign, RLP=Run Length Prefix (01),</p>
    <p>EOP=End Of Block, CO=digital number to be coded</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">              TABLE 6______________________________________RUN LENGTH CODE TABLE FOR THE"ONE'S REDUNDANCY" CODINGRUN LENGTH CODES FOR DPCM MODET   L      FREQ     # of BITS                       CODE   OCTAL EQUIV______________________________________R   0      26644.   2       10     2R'  0      15621.   3       110    6R   1      12324.   3       010    2R   2      7148.    4       1110   16R   3      4610.    4       0000   0R   4      3384.    5       01101  15R'  1      3143.    5       01100  14R   5      2577.    5       00011  3R   6      1967.    6       111100 74R   7      1764.    6       011110 36R   8      1452.    6       001111 17R   9      1327.    6       001101 15R   10     1089.    6       000101 5R'  2      1013.    7       1111011                              173R   11     994.     7       1111010                              172R   12     884.     7       0111011                              73R   13     876.     7       0111010                              72R   14     861.     7       0011100                              71R   15     687.     7       0011100                              34R   16     673.     7       0011001                              31R   17     602.     7       0011000                              30R   18     550.     7       0001001                              11R   19     496.     7       0001000                              10R   20     485.     8       01111101                              175R   21     455.     8       01111100                              174R   22     413.     8       01110001                              161R'  3      402.     8       01110000                              160R   23     370.     8       00111011                              73R   24     345.     8       00111010                              72R   ESC    4599.    5       11111  37R'  ESC    982.     7       0111111                              77EOB    5047.    4         0010   2______________________________________</pre>
    
    <p>where,</p>
    <p>R ESC=code used whenever R-type value not in table</p>
    <p>R' ESC=code used when R'-type value not in table.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">              TABLE 7______________________________________ AMPLITUDE CODE TABLE FOR THE"ONE'S REDUNDANCY" CODINGAMPLITUDE CODES FOR DPCM MODEA      FREQ    # of BITS CODE     OCTAL EQUIV______________________________________A    2     11076.  1       1        1A    3     3846.   2       00       0A    4     1751.   4       0110     6A    5     982.    5       01111    17A    6     663.    5       01010    12A    7     435.    6       01100    34A    8     347.    6       010011   23A    9     277.    6       010001   21A   10     173.    7       0101100  54A   11     178.    7       0101101  55A   12     137.    7       0100100  44A   13     113.    8       01110101 165A   14     116.    8       01110110 166A   15     79.     8       01001010 112A   16     68.     8       01000011 103A   17     67.     8       01000010 102A   18     58.     9       011101110                               356A   19     49.     9       011101000                               350A   20     50.     9       011101001                               351A   21     30.     10      0111011111                               737A   22     32.     9       010000010                               202A   23     33.     9       010000011                               203A   24     20.     10      0100101100                               454A   25     31.     9       010000001                               201A   26     22.     10      0100101101                               455A   27     30.     9       010000000                               200A   28     23.     10      0100101110                               456A   29     14.     11      01001011111                               1137A   30     14.     11      01110111100                               1674A   31     10.     11      01001011110                               1136A   32     14.     11      01110111101                               1675A   ESC    423.    6       010111   27______________________________________</pre>
    
    <p>where,</p>
    <p>ESC=code used when amplitude value not in table.</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">              TABLE 8______________________________________RUN-LENGTH CODES FOR "SCENE ADAPTIVECODING"VALUE     LENGTH         HUFFMAN CODE______________________________________ 1        1              0 2        4              1111 3        4              1011 4        5              11100 5        5              11010 6        5              10000 7        6              110011 8        6              110010 9        6              11000110        6              11000011        6              10101112        6              10100113        6              10100014        6              10011115        6              10011016        6              10010117        6              10010018        6              10001019        7              111011120        7              111011021        7              110111122        7              110111023        7              110110124        7              110110025        7              101010126        7              100011127        7              100011028        8              1010100029        9              10101001130        9              101010010RL-ESC    6              111010______________________________________</pre>
    
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">              TABLE 9______________________________________AMPLITUDE CODES FOR SCENE ADAPTIVE CODINGVALUE      LENGTH        HUFFMAN CODE______________________________________ 1         2             11 2         3             101 3         3             000 4         4             0011 5         5             10001 6         5             00100 7         6             100101 8         6             100000 9         7             100111010         7             100110011         7             001011112         8             1001111113         8             1001101114         8             1001001115         8             1001000116         8             0010110117         9             10011110118         9             10011010119         9             10011010020         9             10010010021         9             10010000022         9             00101100123         9             00101100024         10            100111100125         10            100111100026         10            100100101127         10            100100101028         10            100100001129         10            1001000010AMP-ESC    6             001010EOB        6             100001RL-PREFIX  2             01______________________________________</pre>
    
    <p>Ordered Redundancy Variations</p>
    <p>Additional variations are possible, for example, three or more parts or their equivalent may be used in the runlength table. A typical example with three parts (R, R' and R") is as follows. Runlengths of consecutive first values (V<sub>1</sub> =0) are runlength encoded with three different parts (R<sub>1</sub>, R<sub>2</sub>, or R<sub>3</sub>) depending upon the value following the runlength of 0's. If the following value is a second value (such as V<sub>2</sub> =1), then R<sub>1</sub> is selected for encoding the runlength of the first value (0's in this case). If the following value is a third value (such as V<sub>3</sub> =2), then R<sub>2</sub> is selected for encoding the runlength of the first value (0's in this case). If the following value is another value (greater than 2 such as 3, 4, 5, . . . ), then R<sub>3</sub> is selected for encoding the runlength of the first value (0's in this case). If R<sub>3</sub> is selected, then R<sub>3</sub> is followed by an amplitude code to specify the exact value (3, 4, 5, . . . ) following the runlength of first values (0's).</p>
    <p>The runlength table utilized with ordered redundancy coding can be of two parts (R and R'), three parts (R<sub>1</sub>, R<sub>2</sub>, and R<sub>3</sub>), or more generally of "n" parts (R<sub>1</sub>, R<sub>2</sub>, . . . , R<sub>n</sub>), where n is equal to or greater than 2.</p>
    <p>The TABLES 6 and 7 were formed based upon the assumption that a separate sign bit, S or S, not in the tables is to be used to indicate the sign of each value coded in the manner indicated in TABLE 5. Alternatively, the sign information can be encoded into TABLE 6 or TABLE 7. For example, a table like TABLE 6 can be used to represent runlengths of 0's that are followed both by positive and by negative non-zero numbers. Such a table would be greater in length than TABLE 6 (expanded essentially to double the length) to provide entries for runlengths of 0's followed by both negative and positive non-zero numbers. Of course, such a table would be ordered in accordance with the statistical frequency of both positive and negative numbers.</p>
    <p>The two tables, TABLES 6 and 7, were formed based upon the assumption that the values to be coded were categorized into three basic groups or values, namely a first value, V<sub>1</sub>, a second value, V<sub>2</sub>, and all other values. In the particular example of coding, the first value V<sub>1</sub> is 0, the second value V<sub>2</sub> is 1, and the third value is one within the set of all values greater than 1. It often occurs that in a block of values to be coded, the value 0 (the first value) occurs statistically most frequently, the value 1 (the second value) occurs statistically second most frequently, and the other values (the third values) the least frequently.</p>
    <p>With such a distribution having ordered redundancy, the coding of the second value (1's in this case) is avoided because the first value (0's in this case) is runlength coded in two parts, one part that implies that the number following the runlength of 0's is the second value (1 in this case) and the other part that indicates that the number following the runlength of 0's is within the set of third values (values greater than 1 in this case).</p>
    <p>Alternative formulations are possible. For example, rather than categorizing the values to be coded into three groups as done in connection with TABLE 6, four or more groups are possible. For four groups, the first value (for example V<sub>1</sub> =0) is coded in three parts, namely, a first part for implying a second value (for example V<sub>2</sub> =1), a second part for implying a third value (for example V<sub>3</sub> =2) and a third part for indicating a set of fourth values (values greater than 2).</p>
    <p>In general, a multivalued digital number, X(k), to be coded with n-1 implied values has a first value, V<sub>1</sub>, a second value, V<sub>2</sub>, . . . , a j-value, V<sub>j</sub>, a (J+1)-value, V<sub>j+1</sub>, . . . , a n-value, V<sub>n</sub>, for j ranging from 1 to n, and has other values. The digital signals are coded with n-1 implied values to form statistically coded signals such that the more frequently occurring values of the digital signals are represented by shorter code lengths and the less frequently occurring values of coded signals are represented by longer code lengths. The coding includes, for each value, V<sub>j</sub>, for j from 1 to n, forming j<sup>th</sup> runlength code values representing the number of consecutive first values followed by the j+1 value, forming additional runlength code values representing the number of consecutive first values followed by any of said other values.</p>
    <p>While the embodiments described have used one code (such as R) based upon the existence of a runlength of a first value to imply a second value, the implied code is not limited to a single value but can be itself multivalued. For example, a runlength of 0's followed by two 1's can be implied by a code R".</p>
    <p>While the implied coding of the second value was typically as a result of runlength coding the first value, other types of coding of the first value are included within the present invention.</p>
    <p>As another alternative, the statistically most frequent value is not necessarily the value that is runlength encoded. Where three groups of values are employed (such as 0's, 1's and greater than 1's), the second value (1's in this case) can be runlength encoded to imply the first value (0's in this case) or to specify the third values (numbers greater than 1 in this case).</p>
    <p>In an example where the number of values V<sub>j</sub>, are limited, the need for amplitude coding can be eliminated. For example, if only the values V<sub>1</sub> =0 and V<sub>2</sub> =1 are present in the number X(k), then no amplitude coding is required since the V<sub>1</sub> =0 values can be runlength coded and the values of V<sub>1</sub> =1 can be implied. Similarly, for an example with only the values V<sub>1</sub> =0, V<sub>2</sub> =1, and V<sub>3</sub> =2, the values of V<sub>1</sub> =0 can be runlength coded while both V<sub>2</sub> =1, and V<sub>3</sub> =2, are implied using a two-part runlength table as previously described.</p>
    <p>In an example where all of the values have the same sign, the sign coding can be eliminated.</p>
    <p>Coder Details--FIG. 3</p>
    <p>In FIG. 3, further details of the coder 14 of FIG. 2 are shown. In FIG. 3, each digital value, V<sub>j</sub>, of a digital number, X(k), to be coded is input to the CO register 76. Typically, the register 76 is a 16-bit register for storing 16-bit values where the digital number, X(k), is formed of K 16-bit values, each value clocked into register 76 in sequence and one at a time. The comparator 77 compares the absolute value of each value in register 76 to determine if that absolute value is less than 1, equal to 1, or greater than 1. Comparator 78 provides a less-than-1 output signal on line 78, an equal-to-1 signal on line 79, and a greater-than-1 signal on line 80 as a function of the value in register 76. The less-than-1 signal on line 78 indicates an equal-to-0 condition. The control 81 receives the three control values on line 78, 79 and 80 from comparator 77 and controls, in a conventional manner, the coder operations.</p>
    <p>The "zero" counter 82 counts the runlength of consecutive zeros detected by the comparator 77. Line 86 from control 81 causes counter 82 to be set to a counting mode for counting consecutive 0 values in register 76. Line 86 causes counter 82 to be reset after each runlength of zeros is counted. After being reset and with line 86 setting counter 82 to the counting mode, counter 82 will count zeros until a non-zero value is detected in register 76. If a non-zero value is detected, either a equal-to-1 signal on line 79 or a greater-than-1 signal on line 80 is enabled and detected by control 81. If an equal-to-1 signal is detected, control 81 asserts the line 87 to specify the R type of operation. The enable line 87 together with the runlength count from counter 82 addresses the runlength table 84. Runlength table 84 is typically a random access memory or a read only memory storing coded runlength values like those of TABLE 6. The 0 runlength output on line 95 from counter 82 together with the 1-bit on line 87 address the table 84 to provide a runlength coded value output on lines 93. The output from table 84 is under control of the signal on line 89 from control 81 and loads the code register 85 with the runlength coded value from the CODE column of TABLE 6. The runlength coded value implies that a runlength of zeros is followed by a 1 in the manner previously described.</p>
    <p>After a coded value is loaded into register 85, the sign bit from register 76 is enabled to be stored in register 85 by the enable gate 91 under control of the signal 94 from the control 81.</p>
    <p>Thereafter, the next value, V<sub>j</sub>, of the number, X(k), is loaded into register 76. Counter 82 is cleared and a new runlength of zeros is counted until comparator 77 detects a non-zero value by asserting either an equal-to-1 signal on line 79 or a signal on line 80 signifying a greater-than-1 value in register 76. If the runlength of zeros is followed by a value greater than 1, then line 80 is asserted and control 81 causes line 87 to be not asserted, thereby signifying an R'-type of operation. The runlength value from counter 82 on line 95 together with the non-asserted signal on line 87 causes the runlength table 84 to be addressed to obtain a R' value from table 84. Line 89 causes the output from table 84 to be gated to the code register 85.</p>
    <p>Because of a greater than 1 value in register 76, control 81 causes the line 88 to be next enabled to provide an output from the amplitude table 83. The amplitude table 83 is a random access memory or read only memroy loaded with amplitude values like those of TABLE 7. The value in register 76 addresses the amplitude table 83 to provide the appropriate amplitude value output on line 93 for storage in the code register 85. Thereafter, the control 81 causes line 94 to be enabled to cause the sign value from register 76 to be stored in the code register 85.</p>
    <p>The FIG. 3 coder continues to process code values in register 76 until an entire block of code values (all values for a digital number, X(k)) has been processed. Control 81 includes counters and other appropriate means for counting or otherwise determining all values comprising a digital number. When a full series of values for a digital number X(k) has been processed, control 81 enables the output line 93 to provide an end of block, EOB, signal on line 93 for storage in the control register 85. Control 81 provides the CLK<sub>1</sub> signal for clocking each new value into register 76, provides the CLK<sub>2</sub> signal for incrementing the zero counter 83 and CLK<sub>3</sub> signal for clocking values into register 44. In a conventional manner, control 81 is controlled by a master clock signal CLK, from the transmitter of FIG. 2.</p>
    <p>In FIG. 3, when the amplitude table 83 is addressed and produces the ESC code, the ESC detector 126 senses that no amplitude value is available in the table and signals control 81. The ESC value from table 83 is gated into the code register 85. Thereafter, control 81 enables gate 127 via line 181 to gate the value from register 76 into the code register 85. Alternatively, an additional table (not shown) can be provided for storing Huffman coded values of amplitudes not in the table 83. Such an additional Huffman table would provide compression of additional amplitude values.</p>
    <p>In FIG. 3, when the runlength table 84 provides the R ESC or the R' ESC code value, the ESC detector 126 senses the ESC value and signals the control 81 on line 130. The ESC code value is clocked into register 85, and on the next cycle, control 81 causes alternate processing to occur. In the example described, gage 129 is enabled to enter directly the value from counter 82 into the code register 85 so that runlengths not in the runlength table 84 are directly entered after the ESC code. Alternatively, an additional runlength table with Huffman coded runlength values can be employed to provide additional compressed runlengths not in the table 84.</p>
    <p>While FIG. 3 depicts one embodiment for implementing the coder 14 of FIG. 2, many other software and hardware implementations of the coder are, of course, possible.</p>
    <p>Decoder Detail--FIG. 4</p>
    <p>In FIG. 4, further details of the decoder 54 of FIG. 1 are shown. The serial-by-bit data is input on line 117 to the code register 101. The input data, as it is clocked into the register 101 by the CLK<sub>4</sub> signal, is continuously detected by the detector 102. Detector 102 senses the synchronization, header and other control information and signals the control 107 when coded data is to follow. The coded data is clocked into register 101 one bit at a time. A code value clocked into register 101 is presented in left-to-right order when viewing the CODE column of TABLE 6. With each new code value bit, the coded data from register 101 is input to the inverse runlength table 103 and to the inverse amplitude table 104. The runlength table 103 includes the data of TABLE 6 organized in an inverse order. The inverse order means that table 103 of FIG. 4 is addressed by the CODE column code values and provides as an output the type (R or R') from column T and the length from column L. The type information appears on output line 113. Line 113 is one binary value (for example 1) when the addressed value is of type R and is another binary value (for example 0) when the type is R'.</p>
    <p>The R/R' information on line 113 is connected to the control 107. The L information from table 103 is input on line 119 to the runlength counter 105. Typically, the L information is a binary count and runlength counter 105 is parallel loaded with the binary count under control of line 114 from control 107.</p>
    <p>If an R ESC or an R' ESC value is detected by detector 102, control 107 is signaled that no valid runlength will be derived from table 103. When control 107 senses that the ESC code has appeared in register 101, control 107 causes the content of the register 101 through gate 125 to be gated into the runlength counter 105. Thereafter, runlength counter 105 is decremented in the manner previously described.</p>
    <p>Line 116 output from the table 103 is a validity bit indicating that a valid entry has been found in table 103. As each new code value bit is clocked into register 101, table 103 is addressed to determine if a valid entry is found. Not all input codes from register 101 will find a valid entry in table 103. All valid entries in table 103 provide a validity bit output on line 116 for signalling the control 107. When control 107 receives a valid bit from line 116, the length value for the addressed entry is stored into the runlength counter 105. Thereafter, the runlength counter 105 is decremented by the CLK<sub>5</sub> signal thereby counting out the runlength of zeros. Control line 118 inhibits any output from the amplitude table 104 whenever counter 105 is being decremented thereby loading zeros into the CO register 109. When the counter 105 has been counted down and the entire runlength of zeros has been loaded into register 109, control 107 has sensed the R or R' signal from line 113 and thereafter provides the following sequencing.</p>
    <p>If line 113 indicated an R-type operation, then line 121 loads a 1 into the register 109 since R-type operations imply a 1 after a runlength of zeros. When line 121 writes a 1 into register 109, gate 108 is enabled by line 119 to load the sign bit, which will be the next bit in order clocked into register 101 into the register 109. Thereafter regiser 101 will be cleared and clocked to receive the next code bits.</p>
    <p>If line 113 indicates an R'-type operation, then line 121 is not enabled and line 118 is enabled to read out an amplitude from amplitude table 104. Amplitude table 104 contains the information of TABLE 7 in inverse order. The inverse order indicates that table 104 is addressed by the information in the CODE column and provides an output on line 120 from the A column. Typically, the output value from the A column is a binary number representing the amplitude.</p>
    <p>If an ESC value is called for, detector 102 signals control 107 to indicate that no valid amplitude will be obtained from table 104. When the A ESC code appears in the code register 101, the control 107 causes the next amplitude value in code register 101 to be gated directly via gate 108 to the CO register 109.</p>
    <p>After an amplitude value is loaded into register 109 from table 104 or register 101, control 107 then signals via line 119 the loading of the sign bit from register 101 into register 109. Register 101 is then cleared to receive the next code value on line 117 from the buffer 53 of FIG. 1.</p>
    <p>While FIG. 4 depicts one embodiment of a decoder in accordance with the present invention, many other software and hardware embodiments of the FIG. 5 decoder are possible.</p>
    <p>Rate Buffer</p>
    <p>The rate buffer 15 in FIG. 2 performs channel rate equalization. The buffer has a variable rate data input on lines 44 and a constant rate data output on lines 44. The differentials are monitored from frame to frame, and the status is converted into a scaling factor that is fed to the normalizer on lines 25. The buffer always forces the coder to adjust to the local coding variations, while ensuring global performance at a desired level.</p>
    <p>Let B(n) represent the number of bits into the rate buffer for the nth frame and let S(n) represent the buffer status (difference between the read and write pointers of the FIFO) at the end of the nth frame. Then, B(n) and S(n) can be written as follows: ##EQU5##</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">S(n)=S(n-1)+[B(n)-N<sup>2</sup> R]                               Eq. (13)</pre>
    
    <p>where</p>
    <p>N<sub>1</sub> =number of blocks in replenishment mode</p>
    <p>N<sub>2</sub> =number of blocks in motion compensated replenishment mode</p>
    <p>N<sub>3</sub> =number of blocks in DPCM mode</p>
    <p>N<sub>4</sub> =number of blocks in motion compensated DPCM mode</p>
    <p>N<sub>5</sub> =number of blocks in intraframe mode</p>
    <p>[I(u,v)]<sub>i</sub> =normalized and quantized coefficient differences in ith block</p>
    <p>H(.)}="One's Redundancy" coding function R=average coding rate</p>
    <p>N=transform block size</p>
    <p>K=sync, header, and NF</p>
    <p>i.sub.ε N<sub>3</sub> =i belongs to N<sub>3</sub> DPCM block</p>
    <p>i.sub.ε N<sub>4</sub> =i belongs to N<sub>4</sub> DPCM block</p>
    <p>i.sub.ε N<sub>5</sub> =i belongs to N<sub>5</sub> DPCM block</p>
    <p>The buffer status S(n) is used to select an instantaneous scaling factor D* (n) according to an empirically determined "scaling factor versus status" curve. This relationship is described by</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">D*(n)=Φ{S(n)}                                          Eq. (14)</pre>
    
    <p>In order to smooth out this instantaneous scaling factor such that the desired scaling factor does not fluctuate too much, a recursive filtering process is applied as follows:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">D(n)=(1=c)D(n-1)+cD*(n)                                    Eq. (15)</pre>
    
    <p>where c is a constant with value less than unity. The rate buffer can be guaranteed not to overflow by introducing a frame repetition mechanism. It can also be prevented from underflow by introducing fill bits.</p>
    <p>Frame Repetition</p>
    <p>The requirement of a frame repetition in the Motion Compensated Combined Interframe and Intraframe Coding System of FIG. 2 is well justified. Due to the usage of only one normalization factor per frame, an excessive amount of data can flow into the buffer during a scene cut or fast zooming operations. Only instantaneous shutting off of the input data like the frame repetition will prevent the rate buffer from overflowing. Also, in order to prevent the scaling factor from getting too large to introduce blocking artifacts, a frame repetition is desired.</p>
    <p>To establish frame repetition in the rate buffer, a threshold in the rate buffer is first established. During the encoding process, if the data within the buffer exceeds this threshold at the end of the frame, frame repetition is initiated to stop the input data. The repetition process is stopped when the data within the buffer is reduced to a level lower than the threshold.</p>
    <p>While the invention has been particularly shown and described with reference to preferred embodiments thereof, it will be understood by those skilled in the art that the foregoing and other changes in form and details may be made therein without departing from the spirit and scope of the invention.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4302775">US4302775</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 15, 1978</td><td class="patent-data-table-td patent-date-value">Nov 24, 1981</td><td class="patent-data-table-td ">Compression Labs, Inc.</td><td class="patent-data-table-td ">Digital video compression system and methods utilizing scene adaptive coding with rate buffer feedback</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4476495">US4476495</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 1, 1982</td><td class="patent-data-table-td patent-date-value">Oct 9, 1984</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Multilevel signal compression method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4520490">US4520490</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 5, 1983</td><td class="patent-data-table-td patent-date-value">May 28, 1985</td><td class="patent-data-table-td ">At&amp;T Information Systems Inc.</td><td class="patent-data-table-td ">Differentially nonlinear convolutional channel coding with expanded set of signalling alphabets</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4558370">US4558370</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 21, 1983</td><td class="patent-data-table-td patent-date-value">Dec 10, 1985</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Image processing method for graphics images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4633325">US4633325</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 4, 1984</td><td class="patent-data-table-td patent-date-value">Dec 30, 1986</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Adaptive predictive encoding and/or decoding apparatus</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4802232">US4802232</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 13, 1987</td><td class="patent-data-table-td patent-date-value">Jan 31, 1989</td><td class="patent-data-table-td ">Ant Nachrichtentechnik Gmbh</td><td class="patent-data-table-td ">Method for reducing the quantity of data in image coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4816906">US4816906</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 31, 1987</td><td class="patent-data-table-td patent-date-value">Mar 28, 1989</td><td class="patent-data-table-td ">Aeg Aktiengesellschaft</td><td class="patent-data-table-td ">Method for motion-compensated frame-to-frame prediction coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4849812">US4849812</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 24, 1988</td><td class="patent-data-table-td patent-date-value">Jul 18, 1989</td><td class="patent-data-table-td ">U.S. Philips Corporation</td><td class="patent-data-table-td ">Television system in which digitized picture signals subjected to a transform coding are transmitted from an encoding station to a decoding station</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4855825">US4855825</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 5, 1985</td><td class="patent-data-table-td patent-date-value">Aug 8, 1989</td><td class="patent-data-table-td ">Valtion Teknillinen Tutkimuskeskus</td><td class="patent-data-table-td ">Method and apparatus for detecting the most powerfully changed picture areas in a live video signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4897717">US4897717</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 30, 1988</td><td class="patent-data-table-td patent-date-value">Jan 30, 1990</td><td class="patent-data-table-td ">Starsignal, Inc.</td><td class="patent-data-table-td ">Computer-based video compression system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4901075">US4901075</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 11, 1987</td><td class="patent-data-table-td patent-date-value">Feb 13, 1990</td><td class="patent-data-table-td ">U. S. Philips Corporation</td><td class="patent-data-table-td ">Method and apparatus for bit rate reduction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4920426">US4920426</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 9, 1987</td><td class="patent-data-table-td patent-date-value">Apr 24, 1990</td><td class="patent-data-table-td ">Kokusai Denshin Denwa Co., Ltd.</td><td class="patent-data-table-td ">Image coding system coding digital image signals by forming a histogram of a coefficient signal sequence to estimate an amount of information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4941053">US4941053</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 5, 1989</td><td class="patent-data-table-td patent-date-value">Jul 10, 1990</td><td class="patent-data-table-td ">U.S. Philips Corp.</td><td class="patent-data-table-td ">Predictive encoder for still pictures</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5001418">US5001418</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 6, 1989</td><td class="patent-data-table-td patent-date-value">Mar 19, 1991</td><td class="patent-data-table-td ">Posse Kenneth E</td><td class="patent-data-table-td ">Method for compressing data-vectors for a circuit board testing machine</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5028995">US5028995</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 18, 1988</td><td class="patent-data-table-td patent-date-value">Jul 2, 1991</td><td class="patent-data-table-td ">Hitachi, Ltd.</td><td class="patent-data-table-td ">Picture signal processor, picture signal coder and picture signal interpolator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5113262">US5113262</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 17, 1990</td><td class="patent-data-table-td patent-date-value">May 12, 1992</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Video signal recording system enabling limited bandwidth recording and playback</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5151791">US5151791</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 24, 1990</td><td class="patent-data-table-td patent-date-value">Sep 29, 1992</td><td class="patent-data-table-td ">Pioneer Electronic Corporation</td><td class="patent-data-table-td ">Efficient encoding of picture signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5164831">US5164831</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 15, 1990</td><td class="patent-data-table-td patent-date-value">Nov 17, 1992</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Electronic still camera providing multi-format storage of full and reduced resolution images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5265180">US5265180</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 8, 1993</td><td class="patent-data-table-td patent-date-value">Nov 23, 1993</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method of encoding a sequence of images of a digital motion video signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5351046">US5351046</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 28, 1993</td><td class="patent-data-table-td patent-date-value">Sep 27, 1994</td><td class="patent-data-table-td ">Adcox Thomas A</td><td class="patent-data-table-td ">Method and system for compacting binary coded decimal data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5367629">US5367629</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 18, 1992</td><td class="patent-data-table-td patent-date-value">Nov 22, 1994</td><td class="patent-data-table-td ">Sharevision Technology, Inc.</td><td class="patent-data-table-td ">Digital video compression system utilizing vector adaptive transform</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5414779">US5414779</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 14, 1993</td><td class="patent-data-table-td patent-date-value">May 9, 1995</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Image frame detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5650829">US5650829</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 20, 1995</td><td class="patent-data-table-td patent-date-value">Jul 22, 1997</td><td class="patent-data-table-td ">Sanyo Electric Co., Ltd.</td><td class="patent-data-table-td ">Motion video coding systems with motion vector detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5663763">US5663763</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 18, 1993</td><td class="patent-data-table-td patent-date-value">Sep 2, 1997</td><td class="patent-data-table-td ">Sony Corp.</td><td class="patent-data-table-td ">Picture signal encoding method and apparatus and picture signal decoding method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5808700">US5808700</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 28, 1997</td><td class="patent-data-table-td patent-date-value">Sep 15, 1998</td><td class="patent-data-table-td ">Sanyo Electric Co., Ltd.</td><td class="patent-data-table-td ">Motion video coding systems with motion vector detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5815217">US5815217</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 22, 1997</td><td class="patent-data-table-td patent-date-value">Sep 29, 1998</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Scene-change detector for a moving image composed of a plurality of frames</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5825426">US5825426</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 19, 1996</td><td class="patent-data-table-td patent-date-value">Oct 20, 1998</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method for encoding video data in a video system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6147703">US6147703</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 19, 1996</td><td class="patent-data-table-td patent-date-value">Nov 14, 2000</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Electronic camera with image review</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6285796">US6285796</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 3, 1997</td><td class="patent-data-table-td patent-date-value">Sep 4, 2001</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Pseudo-fixed length image compression scheme</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6408029">US6408029</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 1999</td><td class="patent-data-table-td patent-date-value">Jun 18, 2002</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and apparatus for simplifying real-time data encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6574278">US6574278</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 1999</td><td class="patent-data-table-td patent-date-value">Jun 3, 2003</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and apparatus for performing real-time data encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6803931">US6803931</a></td><td class="patent-data-table-td patent-date-value">Nov 4, 1999</td><td class="patent-data-table-td patent-date-value">Oct 12, 2004</td><td class="patent-data-table-td ">Kendyl A. Roman</td><td class="patent-data-table-td ">Graphical user interface including zoom control box representing image and magnification of displayed image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6904174">US6904174</a></td><td class="patent-data-table-td patent-date-value">Dec 11, 1998</td><td class="patent-data-table-td patent-date-value">Jun 7, 2005</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Simplified predictive video encoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6952448">US6952448</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 9, 1998</td><td class="patent-data-table-td patent-date-value">Oct 4, 2005</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image coding apparatus and method of the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7016417">US7016417</a></td><td class="patent-data-table-td patent-date-value">Dec 22, 1999</td><td class="patent-data-table-td patent-date-value">Mar 21, 2006</td><td class="patent-data-table-td ">Kendyl A. Roman</td><td class="patent-data-table-td ">General purpose compression for video images (RHN)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7016547">US7016547</a></td><td class="patent-data-table-td patent-date-value">Jun 28, 2002</td><td class="patent-data-table-td patent-date-value">Mar 21, 2006</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive entropy encoding/decoding for screen capture content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7046734">US7046734</a></td><td class="patent-data-table-td patent-date-value">Jan 8, 2003</td><td class="patent-data-table-td patent-date-value">May 16, 2006</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and apparatus for performing real-time data encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7191462">US7191462</a></td><td class="patent-data-table-td patent-date-value">Nov 8, 1999</td><td class="patent-data-table-td patent-date-value">Mar 13, 2007</td><td class="patent-data-table-td ">Kendyl A. Román</td><td class="patent-data-table-td ">System for transmitting video images over a computer network to a remote receiver</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7194137">US7194137</a></td><td class="patent-data-table-td patent-date-value">May 16, 2003</td><td class="patent-data-table-td patent-date-value">Mar 20, 2007</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Variable length coding method and apparatus for video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7203372">US7203372</a></td><td class="patent-data-table-td patent-date-value">May 19, 2003</td><td class="patent-data-table-td patent-date-value">Apr 10, 2007</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Extension of two-dimensional variable length coding for image compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7212681">US7212681</a></td><td class="patent-data-table-td patent-date-value">Jan 15, 2003</td><td class="patent-data-table-td patent-date-value">May 1, 2007</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Extension of two-dimensional variable length coding for image compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7215384">US7215384</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 1999</td><td class="patent-data-table-td patent-date-value">May 8, 2007</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and apparatus for simplifying field prediction motion estimation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7218790">US7218790</a></td><td class="patent-data-table-td patent-date-value">Dec 29, 2005</td><td class="patent-data-table-td patent-date-value">May 15, 2007</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive entropy encoding/decoding for screen capture content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7231091">US7231091</a></td><td class="patent-data-table-td patent-date-value">May 16, 2005</td><td class="patent-data-table-td patent-date-value">Jun 12, 2007</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Simplified predictive video encoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7233619">US7233619</a></td><td class="patent-data-table-td patent-date-value">Dec 20, 1999</td><td class="patent-data-table-td patent-date-value">Jun 19, 2007</td><td class="patent-data-table-td ">Roman Kendyl A</td><td class="patent-data-table-td ">Variable general purpose compression for video images (ZLN)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7242328">US7242328</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 2006</td><td class="patent-data-table-td patent-date-value">Jul 10, 2007</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Variable length coding for sparse coefficients</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7257158">US7257158</a></td><td class="patent-data-table-td patent-date-value">May 17, 1999</td><td class="patent-data-table-td patent-date-value">Aug 14, 2007</td><td class="patent-data-table-td ">Kendyl A. Román</td><td class="patent-data-table-td ">System for transmitting video images over a computer network to a remote receiver</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7263127">US7263127</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 1999</td><td class="patent-data-table-td patent-date-value">Aug 28, 2007</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and apparatus for simplifying frame-based motion estimation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7305233">US7305233</a></td><td class="patent-data-table-td patent-date-value">May 27, 2005</td><td class="patent-data-table-td patent-date-value">Dec 4, 2007</td><td class="patent-data-table-td ">Exclaim, Inc.</td><td class="patent-data-table-td ">Method and apparatus for image distribution using a cellular phone</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7324699">US7324699</a></td><td class="patent-data-table-td patent-date-value">Feb 15, 2007</td><td class="patent-data-table-td patent-date-value">Jan 29, 2008</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Extension of two-dimensional variable length coding for image compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7340103">US7340103</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2007</td><td class="patent-data-table-td patent-date-value">Mar 4, 2008</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive entropy encoding/decoding for screen capture content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7369611">US7369611</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 27, 2005</td><td class="patent-data-table-td patent-date-value">May 6, 2008</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Image coding apparatus and method of the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7394942">US7394942</a></td><td class="patent-data-table-td patent-date-value">Jan 5, 2007</td><td class="patent-data-table-td patent-date-value">Jul 1, 2008</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Variable length coding method and apparatus for video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7403561">US7403561</a></td><td class="patent-data-table-td patent-date-value">Apr 2, 2004</td><td class="patent-data-table-td patent-date-value">Jul 22, 2008</td><td class="patent-data-table-td ">Avid Technology, Inc.</td><td class="patent-data-table-td ">Fixed bit rate, intraframe compression and decompression of video</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7433824">US7433824</a></td><td class="patent-data-table-td patent-date-value">Aug 25, 2003</td><td class="patent-data-table-td patent-date-value">Oct 7, 2008</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Entropy coding by adapting coding between level and run-length/level modes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7454073">US7454073</a></td><td class="patent-data-table-td patent-date-value">Aug 3, 2004</td><td class="patent-data-table-td patent-date-value">Nov 18, 2008</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Video compression using multiple variable length coding processes for multiple classes of transform coefficient blocks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7454076">US7454076</a></td><td class="patent-data-table-td patent-date-value">Jun 15, 2004</td><td class="patent-data-table-td patent-date-value">Nov 18, 2008</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Hybrid variable length coding method for low bit rate video coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7469011">US7469011</a></td><td class="patent-data-table-td patent-date-value">Sep 2, 2004</td><td class="patent-data-table-td patent-date-value">Dec 23, 2008</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Escape mode code resizing for fields and slices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7471840">US7471840</a></td><td class="patent-data-table-td patent-date-value">Aug 18, 2004</td><td class="patent-data-table-td patent-date-value">Dec 30, 2008</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Two-dimensional variable length coding of runs of zero and non-zero transform coefficients for image compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7471841">US7471841</a></td><td class="patent-data-table-td patent-date-value">Feb 28, 2005</td><td class="patent-data-table-td patent-date-value">Dec 30, 2008</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Adaptive breakpoint for hybrid variable length coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7480418">US7480418</a></td><td class="patent-data-table-td patent-date-value">Nov 17, 2004</td><td class="patent-data-table-td patent-date-value">Jan 20, 2009</td><td class="patent-data-table-td ">Scalado Ab</td><td class="patent-data-table-td ">Method for processing a digital image and image representation format</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7483584">US7483584</a></td><td class="patent-data-table-td patent-date-value">Jul 22, 2004</td><td class="patent-data-table-td patent-date-value">Jan 27, 2009</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Extended hybrid variable length coding of transform coefficients for video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7486212">US7486212</a></td><td class="patent-data-table-td patent-date-value">Jun 11, 2007</td><td class="patent-data-table-td patent-date-value">Feb 3, 2009</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Variable length coding for sparse coefficients</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7492956">US7492956</a></td><td class="patent-data-table-td patent-date-value">Aug 18, 2004</td><td class="patent-data-table-td patent-date-value">Feb 17, 2009</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Video coding using multi-dimensional amplitude coding and 2-D non-zero/zero cluster position coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7499595">US7499595</a></td><td class="patent-data-table-td patent-date-value">Feb 28, 2005</td><td class="patent-data-table-td patent-date-value">Mar 3, 2009</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Joint amplitude and position coding for photographic image and video coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7499596">US7499596</a></td><td class="patent-data-table-td patent-date-value">Feb 28, 2005</td><td class="patent-data-table-td patent-date-value">Mar 3, 2009</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Amplitude coding for clustered transform coefficients</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7564874">US7564874</a></td><td class="patent-data-table-td patent-date-value">Aug 10, 2005</td><td class="patent-data-table-td patent-date-value">Jul 21, 2009</td><td class="patent-data-table-td ">Uni-Pixel Displays, Inc.</td><td class="patent-data-table-td ">Enhanced bandwidth data encoding method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7565018">US7565018</a></td><td class="patent-data-table-td patent-date-value">Aug 12, 2005</td><td class="patent-data-table-td patent-date-value">Jul 21, 2009</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive coding and decoding of wide-range coefficients</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7599840">US7599840</a></td><td class="patent-data-table-td patent-date-value">Jul 15, 2005</td><td class="patent-data-table-td patent-date-value">Oct 6, 2009</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Selectively using multiple entropy models in adaptive coding and decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7606314">US7606314</a></td><td class="patent-data-table-td patent-date-value">Jul 22, 2004</td><td class="patent-data-table-td patent-date-value">Oct 20, 2009</td><td class="patent-data-table-td ">Raritan America, Inc.</td><td class="patent-data-table-td ">Method and apparatus for caching, compressing and transmitting video signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7620258">US7620258</a></td><td class="patent-data-table-td patent-date-value">Nov 9, 2005</td><td class="patent-data-table-td patent-date-value">Nov 17, 2009</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Extended amplitude coding for clustered transform coefficients</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7671864">US7671864</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2001</td><td class="patent-data-table-td patent-date-value">Mar 2, 2010</td><td class="patent-data-table-td ">Roman Kendyl A</td><td class="patent-data-table-td ">Faster image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7680349">US7680349</a></td><td class="patent-data-table-td patent-date-value">Mar 20, 2006</td><td class="patent-data-table-td patent-date-value">Mar 16, 2010</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Variable length coding for clustered transform coefficients in video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7684483">US7684483</a></td><td class="patent-data-table-td patent-date-value">Aug 29, 2002</td><td class="patent-data-table-td patent-date-value">Mar 23, 2010</td><td class="patent-data-table-td ">Raritan Americas, Inc.</td><td class="patent-data-table-td ">Method and apparatus for digitizing and compressing remote video signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7684981">US7684981</a></td><td class="patent-data-table-td patent-date-value">Jul 15, 2005</td><td class="patent-data-table-td patent-date-value">Mar 23, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Prediction of spectral coefficients in waveform coding and decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7688894">US7688894</a></td><td class="patent-data-table-td patent-date-value">Nov 15, 2004</td><td class="patent-data-table-td patent-date-value">Mar 30, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Scan patterns for interlaced video content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7693709">US7693709</a></td><td class="patent-data-table-td patent-date-value">Jul 15, 2005</td><td class="patent-data-table-td patent-date-value">Apr 6, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Reordering coefficients for waveform coding or decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7698653">US7698653</a></td><td class="patent-data-table-td patent-date-value">Jul 13, 2004</td><td class="patent-data-table-td patent-date-value">Apr 13, 2010</td><td class="patent-data-table-td ">Roman Kendyl A</td><td class="patent-data-table-td ">Graphical user interface including zoom control box representing image and magnification of displayed image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7702015">US7702015</a></td><td class="patent-data-table-td patent-date-value">Mar 19, 2004</td><td class="patent-data-table-td patent-date-value">Apr 20, 2010</td><td class="patent-data-table-td ">Ge Security, Inc.</td><td class="patent-data-table-td ">Systems and methods for multi-resolution image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7711195">US7711195</a></td><td class="patent-data-table-td patent-date-value">Dec 15, 2008</td><td class="patent-data-table-td patent-date-value">May 4, 2010</td><td class="patent-data-table-td ">Scalado Ab</td><td class="patent-data-table-td ">Method for processing a digital image and image representation format</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7711205">US7711205</a></td><td class="patent-data-table-td patent-date-value">Dec 15, 2008</td><td class="patent-data-table-td patent-date-value">May 4, 2010</td><td class="patent-data-table-td ">Scalado Ab</td><td class="patent-data-table-td ">Method for processing a digital image and image representation format</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7720298">US7720298</a></td><td class="patent-data-table-td patent-date-value">Dec 15, 2008</td><td class="patent-data-table-td patent-date-value">May 18, 2010</td><td class="patent-data-table-td ">Scalado Ab</td><td class="patent-data-table-td ">Method for processing a digital image and image representation format</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7724827">US7724827</a></td><td class="patent-data-table-td patent-date-value">Apr 15, 2004</td><td class="patent-data-table-td patent-date-value">May 25, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Multi-layer run level encoding and decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7729423">US7729423</a></td><td class="patent-data-table-td patent-date-value">Jun 26, 2008</td><td class="patent-data-table-td patent-date-value">Jun 1, 2010</td><td class="patent-data-table-td ">Avid Technology, Inc.</td><td class="patent-data-table-td ">Fixed bit rate, intraframe compression and decompression of video</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7742518">US7742518</a></td><td class="patent-data-table-td patent-date-value">Nov 28, 2005</td><td class="patent-data-table-td patent-date-value">Jun 22, 2010</td><td class="patent-data-table-td ">Honeywell International Inc.</td><td class="patent-data-table-td ">Discriminator function for GPS code alignment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7774205">US7774205</a></td><td class="patent-data-table-td patent-date-value">Jun 15, 2007</td><td class="patent-data-table-td patent-date-value">Aug 10, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Coding of sparse digital media spectral data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7782954">US7782954</a></td><td class="patent-data-table-td patent-date-value">Nov 15, 2004</td><td class="patent-data-table-td patent-date-value">Aug 24, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Scan patterns for progressive video content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7796825">US7796825</a></td><td class="patent-data-table-td patent-date-value">Feb 16, 2007</td><td class="patent-data-table-td patent-date-value">Sep 14, 2010</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Losslessly improving compression of compressed image data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7822601">US7822601</a></td><td class="patent-data-table-td patent-date-value">May 16, 2008</td><td class="patent-data-table-td patent-date-value">Oct 26, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive vector Huffman coding and decoding based on a sum of values of audio data symbols</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7831101">US7831101</a></td><td class="patent-data-table-td patent-date-value">Dec 15, 2008</td><td class="patent-data-table-td patent-date-value">Nov 9, 2010</td><td class="patent-data-table-td ">Scalado Ab</td><td class="patent-data-table-td ">Method for processing a digital image and image representation format</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7840403">US7840403</a></td><td class="patent-data-table-td patent-date-value">May 27, 2008</td><td class="patent-data-table-td patent-date-value">Nov 23, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Entropy coding using escape codes to switch between plural code tables</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7853090">US7853090</a></td><td class="patent-data-table-td patent-date-value">Dec 15, 2008</td><td class="patent-data-table-td patent-date-value">Dec 14, 2010</td><td class="patent-data-table-td ">Scalado Ab</td><td class="patent-data-table-td ">Method for processing a digital image and image representation format</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7853663">US7853663</a></td><td class="patent-data-table-td patent-date-value">Apr 4, 2005</td><td class="patent-data-table-td patent-date-value">Dec 14, 2010</td><td class="patent-data-table-td ">Riip, Inc.</td><td class="patent-data-table-td ">Wireless management system for control of remote devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7912306">US7912306</a></td><td class="patent-data-table-td patent-date-value">Nov 25, 2009</td><td class="patent-data-table-td patent-date-value">Mar 22, 2011</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Variable length coding for clustered transform coefficients in video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7916363">US7916363</a></td><td class="patent-data-table-td patent-date-value">Oct 3, 2008</td><td class="patent-data-table-td patent-date-value">Mar 29, 2011</td><td class="patent-data-table-td ">Avid Technology, Inc.</td><td class="patent-data-table-td ">Bitstream format for compressed image data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7933337">US7933337</a></td><td class="patent-data-table-td patent-date-value">Aug 12, 2005</td><td class="patent-data-table-td patent-date-value">Apr 26, 2011</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Prediction of transform coefficients for image compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7949195">US7949195</a></td><td class="patent-data-table-td patent-date-value">Mar 15, 2007</td><td class="patent-data-table-td patent-date-value">May 24, 2011</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Per block breakpoint determining for hybrid variable length coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7965897">US7965897</a></td><td class="patent-data-table-td patent-date-value">Jan 7, 2010</td><td class="patent-data-table-td patent-date-value">Jun 21, 2011</td><td class="patent-data-table-td ">Scalado Ab</td><td class="patent-data-table-td ">Method for processing a digital image and image representation format</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7991052">US7991052</a></td><td class="patent-data-table-td patent-date-value">Dec 13, 2006</td><td class="patent-data-table-td patent-date-value">Aug 2, 2011</td><td class="patent-data-table-td ">Zin Stai Pte. In, Llc</td><td class="patent-data-table-td ">Variable general purpose compression for video images (ZLN)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7995652">US7995652</a></td><td class="patent-data-table-td patent-date-value">Mar 19, 2004</td><td class="patent-data-table-td patent-date-value">Aug 9, 2011</td><td class="patent-data-table-td ">Utc Fire &amp; Security Americas Corporation, Inc.</td><td class="patent-data-table-td ">Systems and methods for multi-stream image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8004572">US8004572</a></td><td class="patent-data-table-td patent-date-value">Dec 4, 2006</td><td class="patent-data-table-td patent-date-value">Aug 23, 2011</td><td class="patent-data-table-td ">Zin Stai Pte. In, Llc</td><td class="patent-data-table-td ">System for transmitting a video stream over a computer network to a remote receiver</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8031777">US8031777</a></td><td class="patent-data-table-td patent-date-value">Mar 21, 2006</td><td class="patent-data-table-td patent-date-value">Oct 4, 2011</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Multipass video encoding and rate control using subsampling of frames</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8068544">US8068544</a></td><td class="patent-data-table-td patent-date-value">Dec 21, 2007</td><td class="patent-data-table-td patent-date-value">Nov 29, 2011</td><td class="patent-data-table-td ">Zin Stai Pte. In, Llc</td><td class="patent-data-table-td ">Compression with doppler enhancement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8068546">US8068546</a></td><td class="patent-data-table-td patent-date-value">Sep 19, 2003</td><td class="patent-data-table-td patent-date-value">Nov 29, 2011</td><td class="patent-data-table-td ">Riip, Inc.</td><td class="patent-data-table-td ">Method and apparatus for transmitting video signals</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8090574">US8090574</a></td><td class="patent-data-table-td patent-date-value">Oct 19, 2010</td><td class="patent-data-table-td patent-date-value">Jan 3, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Entropy encoding and decoding using direct level and run-length/level context-adaptive arithmetic coding/decoding modes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8111934">US8111934</a></td><td class="patent-data-table-td patent-date-value">Mar 21, 2007</td><td class="patent-data-table-td patent-date-value">Feb 7, 2012</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Extension of two-dimensional variable length coding for image compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8121427">US8121427</a></td><td class="patent-data-table-td patent-date-value">Dec 20, 2007</td><td class="patent-data-table-td patent-date-value">Feb 21, 2012</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Breakpoint determining for hybrid variable length coding and encoding the determined breakpoint</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8126062">US8126062</a></td><td class="patent-data-table-td patent-date-value">Mar 15, 2007</td><td class="patent-data-table-td patent-date-value">Feb 28, 2012</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Per multi-block partition breakpoint determining for hybrid variable length coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8131096">US8131096</a></td><td class="patent-data-table-td patent-date-value">Mar 5, 2011</td><td class="patent-data-table-td patent-date-value">Mar 6, 2012</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Variable length coding for clustered transform coefficients in video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8135071">US8135071</a></td><td class="patent-data-table-td patent-date-value">Mar 15, 2007</td><td class="patent-data-table-td patent-date-value">Mar 13, 2012</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Breakpoint determining for hybrid variable length coding using relationship to neighboring blocks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8154776">US8154776</a></td><td class="patent-data-table-td patent-date-value">Mar 21, 2011</td><td class="patent-data-table-td patent-date-value">Apr 10, 2012</td><td class="patent-data-table-td ">Avid Technology, Inc.</td><td class="patent-data-table-td ">Bitstream format for compressed image data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8170095">US8170095</a></td><td class="patent-data-table-td patent-date-value">Dec 14, 2007</td><td class="patent-data-table-td patent-date-value">May 1, 2012</td><td class="patent-data-table-td ">Zin Stai Pte. In, Llc</td><td class="patent-data-table-td ">Faster image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8179974">US8179974</a></td><td class="patent-data-table-td patent-date-value">May 2, 2008</td><td class="patent-data-table-td patent-date-value">May 15, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Multi-level representation of reordered transform coefficients</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8184710">US8184710</a></td><td class="patent-data-table-td patent-date-value">Jun 29, 2007</td><td class="patent-data-table-td patent-date-value">May 22, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive truncation of transform coefficient data in a transform-based digital media codec</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8233535">US8233535</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 2006</td><td class="patent-data-table-td patent-date-value">Jul 31, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Region-based processing of predicted pixels</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8238431">US8238431</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 5, 2009</td><td class="patent-data-table-td patent-date-value">Aug 7, 2012</td><td class="patent-data-table-td ">Arris Solutions, Inc.</td><td class="patent-data-table-td ">Method and system for rate reduction of video streams</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8275209">US8275209</a></td><td class="patent-data-table-td patent-date-value">Sep 30, 2009</td><td class="patent-data-table-td patent-date-value">Sep 25, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Reduced DC gain mismatch and DC leakage in overlap transform processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8281040">US8281040</a></td><td class="patent-data-table-td patent-date-value">Sep 14, 2010</td><td class="patent-data-table-td patent-date-value">Oct 2, 2012</td><td class="patent-data-table-td ">RIP, Inc.</td><td class="patent-data-table-td ">Wireless management of remote devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8285068">US8285068</a></td><td class="patent-data-table-td patent-date-value">Jun 25, 2008</td><td class="patent-data-table-td patent-date-value">Oct 9, 2012</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Combined deblocking and denoising filter</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8290034">US8290034</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 2005</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">Zin Stai Pte. In, Llc</td><td class="patent-data-table-td ">Video transmission and display including bit-wise sub-sampling video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8295343">US8295343</a></td><td class="patent-data-table-td patent-date-value">Jun 23, 2006</td><td class="patent-data-table-td patent-date-value">Oct 23, 2012</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Video bit rate control method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8345776">US8345776</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 24, 2008</td><td class="patent-data-table-td patent-date-value">Jan 1, 2013</td><td class="patent-data-table-td ">Huawei Technologies Co., Ltd.</td><td class="patent-data-table-td ">System and method of error control for video coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8352853">US8352853</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2005</td><td class="patent-data-table-td patent-date-value">Jan 8, 2013</td><td class="patent-data-table-td ">Motorola Mobility Llc</td><td class="patent-data-table-td ">Composer circuit and method for encoding device independent multi-modal content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8358380">US8358380</a></td><td class="patent-data-table-td patent-date-value">Jun 5, 2009</td><td class="patent-data-table-td patent-date-value">Jan 22, 2013</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Efficient spatial and temporal transform-based video preprocessing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8369638">US8369638</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2008</td><td class="patent-data-table-td patent-date-value">Feb 5, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Reducing DC leakage in HD photo transform</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8396306">US8396306</a></td><td class="patent-data-table-td patent-date-value">Apr 13, 2011</td><td class="patent-data-table-td patent-date-value">Mar 12, 2013</td><td class="patent-data-table-td ">Mobile Imaging In Sweden Ab</td><td class="patent-data-table-td ">Method for processing a digital image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8406307">US8406307</a></td><td class="patent-data-table-td patent-date-value">Aug 22, 2008</td><td class="patent-data-table-td patent-date-value">Mar 26, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Entropy coding/decoding of hierarchically organized data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8416847">US8416847</a></td><td class="patent-data-table-td patent-date-value">Jun 18, 2007</td><td class="patent-data-table-td patent-date-value">Apr 9, 2013</td><td class="patent-data-table-td ">Zin Stai Pte. In, Llc</td><td class="patent-data-table-td ">Separate plane compression using plurality of compression methods including ZLN and ZLD methods</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8447591">US8447591</a></td><td class="patent-data-table-td patent-date-value">May 30, 2008</td><td class="patent-data-table-td patent-date-value">May 21, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Factorization of overlapping tranforms into two block transforms</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8472725">US8472725</a></td><td class="patent-data-table-td patent-date-value">Jun 2, 2010</td><td class="patent-data-table-td patent-date-value">Jun 25, 2013</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Scene change detection and handling for preprocessing video with overlapped 3D transforms</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8478884">US8478884</a></td><td class="patent-data-table-td patent-date-value">Sep 30, 2005</td><td class="patent-data-table-td patent-date-value">Jul 2, 2013</td><td class="patent-data-table-td ">Riip, Inc.</td><td class="patent-data-table-td ">Wireless remote device management utilizing mesh topology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8494295">US8494295</a></td><td class="patent-data-table-td patent-date-value">Feb 16, 2012</td><td class="patent-data-table-td patent-date-value">Jul 23, 2013</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Variable length coding for clustered transform coefficients in video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8537898">US8537898</a></td><td class="patent-data-table-td patent-date-value">Oct 11, 2011</td><td class="patent-data-table-td patent-date-value">Sep 17, 2013</td><td class="patent-data-table-td ">Zin Stai Pte. In, Llc</td><td class="patent-data-table-td ">Compression with doppler enhancement</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8558795">US8558795</a></td><td class="patent-data-table-td patent-date-value">Mar 12, 2004</td><td class="patent-data-table-td patent-date-value">Oct 15, 2013</td><td class="patent-data-table-td ">Riip, Inc.</td><td class="patent-data-table-td ">Switchless KVM network with wireless technology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8571117">US8571117</a></td><td class="patent-data-table-td patent-date-value">Jun 5, 2009</td><td class="patent-data-table-td patent-date-value">Oct 29, 2013</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Out of loop frame matching in 3D-based video denoising</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8599925">US8599925</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 12, 2005</td><td class="patent-data-table-td patent-date-value">Dec 3, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Efficient coding and decoding of transform blocks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8615044">US8615044</a></td><td class="patent-data-table-td patent-date-value">Jun 5, 2009</td><td class="patent-data-table-td patent-date-value">Dec 24, 2013</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Adaptive thresholding of 3D transform coefficients for video denoising</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8619881">US8619881</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 5, 2009</td><td class="patent-data-table-td patent-date-value">Dec 31, 2013</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Estimation of temporal depth of 3D overlapped transforms in video denoising</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8638395">US8638395</a></td><td class="patent-data-table-td patent-date-value">Jun 5, 2009</td><td class="patent-data-table-td patent-date-value">Jan 28, 2014</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Consolidating prior temporally-matched frames in 3D-based video denoising</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8681859">US8681859</a></td><td class="patent-data-table-td patent-date-value">Jul 18, 2011</td><td class="patent-data-table-td patent-date-value">Mar 25, 2014</td><td class="patent-data-table-td ">Utc Fire &amp; Security Americas Corporation, Inc.</td><td class="patent-data-table-td ">Systems and methods for multi-stream image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8712783">US8712783</a></td><td class="patent-data-table-td patent-date-value">Nov 29, 2011</td><td class="patent-data-table-td patent-date-value">Apr 29, 2014</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Entropy encoding and decoding using direct level and run-length/level context-adaptive arithmetic coding/decoding modes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8724916">US8724916</a></td><td class="patent-data-table-td patent-date-value">Feb 4, 2013</td><td class="patent-data-table-td patent-date-value">May 13, 2014</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Reducing DC leakage in HD photo transform</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8780997">US8780997</a></td><td class="patent-data-table-td patent-date-value">Aug 4, 2006</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Regulation of decode-side processing based on perceptual masking</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8781244">US8781244</a></td><td class="patent-data-table-td patent-date-value">Oct 8, 2012</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Combined deblocking and denoising filter</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20070036223">US20070036223</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 12, 2005</td><td class="patent-data-table-td patent-date-value">Feb 15, 2007</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Efficient coding and decoding of transform blocks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090074082">US20090074082</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 24, 2008</td><td class="patent-data-table-td patent-date-value">Mar 19, 2009</td><td class="patent-data-table-td ">Huawei Technologies Co., Ltd.</td><td class="patent-data-table-td ">System And Method Of Error Control For Video Coding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090225853">US20090225853</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 5, 2009</td><td class="patent-data-table-td patent-date-value">Sep 10, 2009</td><td class="patent-data-table-td ">Ran Oz</td><td class="patent-data-table-td ">Method and system for rate reduction of video streams</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100309990">US20100309990</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 5, 2009</td><td class="patent-data-table-td patent-date-value">Dec 9, 2010</td><td class="patent-data-table-td ">Schoenblum Joel W</td><td class="patent-data-table-td ">Estimation of temporal depth of 3d overlapped transforms in video denoising</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120243798">US20120243798</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 28, 2011</td><td class="patent-data-table-td patent-date-value">Sep 27, 2012</td><td class="patent-data-table-td ">Fuji Xerox Co., Ltd.</td><td class="patent-data-table-td ">Image processing apparatus, image processing method, and non-transitory computer readable medium storing image processing program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130027400">US20130027400</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 20, 2011</td><td class="patent-data-table-td patent-date-value">Jan 31, 2013</td><td class="patent-data-table-td ">Bo-Ram Kim</td><td class="patent-data-table-td ">Display device and method of driving the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0260748A2?cl=en">EP0260748A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 10, 1987</td><td class="patent-data-table-td patent-date-value">Mar 23, 1988</td><td class="patent-data-table-td ">Philips Patentverwaltung GmbH</td><td class="patent-data-table-td ">Bitrate reduction method and circuitry</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0345608A2?cl=en">EP0345608A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 30, 1989</td><td class="patent-data-table-td patent-date-value">Dec 13, 1989</td><td class="patent-data-table-td ">Digital Recording Research Limited Partnership</td><td class="patent-data-table-td ">Data compression system and method with buffer control</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0411264A2?cl=en">EP0411264A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 28, 1990</td><td class="patent-data-table-td patent-date-value">Feb 6, 1991</td><td class="patent-data-table-td ">ALCATEL ITALIA Società per Azioni</td><td class="patent-data-table-td ">Compression method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0414074A2?cl=en">EP0414074A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 11, 1990</td><td class="patent-data-table-td patent-date-value">Feb 27, 1991</td><td class="patent-data-table-td ">Mitsubishi Denki Kabushiki Kaisha</td><td class="patent-data-table-td ">Transform coding apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0418952A1?cl=en">EP0418952A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 10, 1990</td><td class="patent-data-table-td patent-date-value">Mar 27, 1991</td><td class="patent-data-table-td ">Laboratoires D&#39;electronique Philips S.A.S.</td><td class="patent-data-table-td ">Coding device for bidimensional informations, and decoding device therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0482864A2?cl=en">EP0482864A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 21, 1991</td><td class="patent-data-table-td patent-date-value">Apr 29, 1992</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">An image data processing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0487295A2?cl=en">EP0487295A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 19, 1991</td><td class="patent-data-table-td patent-date-value">May 27, 1992</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Variable length code encoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0517273A2?cl=en">EP0517273A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 5, 1992</td><td class="patent-data-table-td patent-date-value">Dec 9, 1992</td><td class="patent-data-table-td ">Alcatel Espacio S.A.</td><td class="patent-data-table-td ">Method and device to regulate the output bit rate in variable bit rate video coders</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1992022986A1?cl=en">WO1992022986A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 1, 1992</td><td class="patent-data-table-td patent-date-value">Dec 23, 1992</td><td class="patent-data-table-td ">Intel Corp</td><td class="patent-data-table-td ">Method for encoding a sequence of images of a digital motion video signal</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375S240120">375/240.12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07234">375/E07.234</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07214">375/E07.214</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07144">375/E07.144</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07232">375/E07.232</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07245">375/E07.245</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375S246000">375/246</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc358/defs358.htm&usg=AFQjCNEC_AaMeiygGFdxZMppKKYmAkpQlw#C358S001900">358/1.9</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07244">375/E07.244</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07226">375/E07.226</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07163">375/E07.163</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07159">375/E07.159</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07211">375/E07.211</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07231">375/E07.231</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07176">375/E07.176</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07140">375/E07.14</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07216">375/E07.216</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07148">375/E07.148</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07263">375/E07.263</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0009000000">G06T9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007360000">H04N7/36</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H03M0007420000">H03M7/42</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007320000">H04N7/32</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007500000">H04N7/50</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007260000">H04N7/26</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0005000000">G06F5/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007300000">H04N7/30</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00121">H04N19/00121</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00951">H04N19/00951</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00781">H04N19/00781</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00169">H04N19/00169</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00775">H04N19/00775</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/0003">H04N19/0003</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00193">H04N19/00193</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00096">H04N19/00096</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00145">H04N19/00145</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00278">H04N19/00278</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00575">H04N19/00575</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00569">H04N19/00569</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H03M7/42">H03M7/42</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=FaImBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/0009">H04N19/0009</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N7/50E5B</span>, <span class="nested-value">H04N7/30</span>, <span class="nested-value">H04N7/26A4Q2</span>, <span class="nested-value">H04N7/32E</span>, <span class="nested-value">H04N7/50</span>, <span class="nested-value">H04N7/30E5B</span>, <span class="nested-value">H04N7/36D</span>, <span class="nested-value">H03M7/42</span>, <span class="nested-value">H04N7/32B</span>, <span class="nested-value">H04N7/50E4</span>, <span class="nested-value">H04N7/30E4</span>, <span class="nested-value">H04N7/30E2</span>, <span class="nested-value">H04N7/26A4V</span>, <span class="nested-value">H04N7/26A6C4</span>, <span class="nested-value">H04N7/26A8B</span>, <span class="nested-value">H04N7/26A4C2</span>, <span class="nested-value">H04N7/26A6E6</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Apr 15, 2008</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 2, 4, 5, 7, 9, 10, 14, 16-24, 26, 28, 29, 31, 33, 34, 37, 40, 43, 45 AND 46 IS CONFIRMED. CLAIMS 1, 3, 6, 8, 11-13, 15, 25, 27, 30, 32, 35, 36, 38, 39, 41, 42 AND 44 ARE CANCELLED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 4, 2006</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20051121</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 18, 2004</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">COMPRESSION LABS, INC., TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:GENERAL INSTRUMENT CORPORATION;REEL/FRAME:015886/0203</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20041006</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">COMPRESSION LABS, INC. 108 WILD BASIN ROADAUSTIN,</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:GENERAL INSTRUMENT CORPORATION /AR;REEL/FRAME:015886/0203</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 5, 1999</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 12, 1996</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">MAGNITUDE COMPRESSION SYSTEMS, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CHANGE OF NAME;ASSIGNOR:CHARGER INDUSTRIES, INC.;REEL/FRAME:008031/0928</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19960625</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 10, 1996</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">CHARGER INDUSTRIES, INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ONE-HALF INTEREST;ASSIGNOR:COMPRESSION LABS, INCORPORATED;REEL/FRAME:008022/0833</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19960624</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 4, 1995</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 16, 1994</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">BANK OF AMERICA NT&amp;SA, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY INTEREST;ASSIGNOR:COMPRESSION LABS, INCORPORATED;REEL/FRAME:007097/0913</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19940630</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 5, 1994</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">BANK OF AMERICA NT&amp;SA, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">SECURITY INTEREST;ASSIGNOR:COMPRESSION LABS, INCORPORATED;REEL/FRAME:007038/0811</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19940630</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 19, 1991</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 27, 1986</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">COMPRESSION LABS, INC., 2305 BERING DRIVE, SAN JOS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST.;ASSIGNORS:CHEN, WEN-HSIUNG;KLENKE, DANIEL J.;REEL/FRAME:004644/0670</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19861023</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">COMPRESSION LABS, INC., A CORP OF CA, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:CHEN, WEN-HSIUNG;KLENKE, DANIEL J.;REEL/FRAME:004644/0670</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U1n-AA8ISufMwRZ619u4vTIolp9Kw\u0026id=FaImBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U36P8M729ckDVJrpzkQEVoTIb702w\u0026id=FaImBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1nx6v0XqafwYxh1lK6cfCXqQTdsw","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Coding_system_for_reducing_redundancy.pdf?id=FaImBAABERAJ\u0026output=pdf\u0026sig=ACfU3U1fHpeYsxN7QbE-QXwmqlF5g4Rmyw"},"sample_url":"http://www.google.com/patents/reader?id=FaImBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>