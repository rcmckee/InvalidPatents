<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5974254 - Method for detecting differences between graphical programs - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method for detecting differences between graphical programs"><meta name="DC.contributor" content="Ray Hsu" scheme="inventor"><meta name="DC.contributor" content="National Instruments Corporation" scheme="assignee"><meta name="DC.date" content="1997-6-6" scheme="dateSubmitted"><meta name="DC.description" content="A method for detecting differences between two graphical programs is disclosed. The graphical programs include objects, preferably arranged as a user interface panel, including controls and indicators, and a block diagram, including graphical code function blocks connected together as a data flow program. Directed graph data structures are created to represent the graphical programs, wherein the vertices of the graphs are the objects of the graphical programs and the edges of the graphs are data flow signals of the block diagram and/or hierarchical relationships of the user interface panel objects. The objects of the two graphical programs are heuristically matched together using a scoring approach. The scores are stored in a match matrix and indicate a degree of similarity between an object in the first graphical program and an object in the second graphical program according to one or more criteria. The matching criteria include object type, object connectivity and object attributes. The match matrix is resolved to generate a 1:1 or 1:0 correspondence between the objects in the first and second graphical programs based on the match scores. The matching information is used to determine differences in the two graphical programs. First, using the matching information and a compare engine, the objects are grouped into exact matching subgraphs and then into non-exact matching subgraphs. Non-exact matching subgraphs are matched and merged where possible using transitivity. Objects in the non-exact matching subgraphs are compared using the compare engine to detect additional differences. All detected differences are stored and displayed for the user. The differences may be displayed in various manners such as drawing a circle around the differences, highlighting the differences by color, and/or displaying a textual description of the differences."><meta name="DC.date" content="1999-10-26" scheme="issued"><meta name="DC.relation" content="US:4860204" scheme="references"><meta name="DC.relation" content="US:4901221" scheme="references"><meta name="DC.relation" content="US:5005119" scheme="references"><meta name="DC.relation" content="US:5423027" scheme="references"><meta name="DC.relation" content="US:5428788" scheme="references"><meta name="DC.relation" content="US:5440742" scheme="references"><meta name="DC.relation" content="US:5493682" scheme="references"><meta name="DC.relation" content="US:5557730" scheme="references"><meta name="DC.relation" content="US:5619638" scheme="references"><meta name="DC.relation" content="US:5630025" scheme="references"><meta name="DC.relation" content="US:5659735" scheme="references"><meta name="DC.relation" content="US:5729744" scheme="references"><meta name="DC.relation" content="US:5778378" scheme="references"><meta name="DC.relation" content="US:5805889" scheme="references"><meta name="citation_reference" content="&quot;Of Interest&quot;, Dr. Dobb&#39;s Journal, Jun. 1995."><meta name="citation_reference" content="Al Stevens, &quot;C Programming&quot;, Dr. Dobb&#39;s Journal, May 1991."><meta name="citation_reference" content="Al Stevens, C Programming , Dr. Dobb s Journal, May 1991."><meta name="citation_reference" content="Dan Allen, &quot;The Macintosh Programmer&#39;s Workshop&quot;, Dr. Dobb&#39;s Journal, Sep. 1998."><meta name="citation_reference" content="Dan Allen, The Macintosh Programmer s Workshop , Dr. Dobb s Journal, Sep. 1998."><meta name="citation_reference" content="Edward Allburn, &quot;Letters&quot;, Dr. Dobb&#39;s Journal, May 1991."><meta name="citation_reference" content="Edward Allburn, Letters , Dr. Dobb s Journal, May 1991."><meta name="citation_reference" content="Kishi, N., &quot;SimUI: graphical user interface evaluation using playback,&quot; Proc., 16th Ann. Int. COMPASAC &#39;92, pp. 121-127, Sep. 25, 1992."><meta name="citation_reference" content="Kishi, N., SimUI: graphical user interface evaluation using playback, Proc., 16th Ann. Int. COMPASAC 92, pp. 121 127, Sep. 25, 1992."><meta name="citation_reference" content="Kris Coppieters, &quot;A Cross-Platform Binary Diff&quot;, Dr. Dobb&#39;s Journal, May 1995."><meta name="citation_reference" content="Kris Coppieters, A Cross Platform Binary Diff , Dr. Dobb s Journal, May 1995."><meta name="citation_reference" content="Of Interest , Dr. Dobb s Journal, Jun. 1995."><meta name="citation_reference" content="Tsuda College and Nobuko Kishi, &quot;Development of a Tool for Comparing User Operation Records in X Window (sic)&quot;, 53-6 Society of Inform. Proc. Human Interface Research Center Report 44-46, 1994."><meta name="citation_reference" content="Tsuda College and Nobuko Kishi, Development of a Tool for Comparing User Operation Records in X Window (sic) , 53 6 Society of Inform. Proc. Human Interface Research Center Report 44 46, 1994."><meta name="citation_patent_number" content="US:5974254"><meta name="citation_patent_application_number" content="US:08/870,262"><link rel="canonical" href="http://www.google.com/patents/US5974254"/><meta property="og:url" content="http://www.google.com/patents/US5974254"/><meta name="title" content="Patent US5974254 - Method for detecting differences between graphical programs"/><meta name="description" content="A method for detecting differences between two graphical programs is disclosed. The graphical programs include objects, preferably arranged as a user interface panel, including controls and indicators, and a block diagram, including graphical code function blocks connected together as a data flow program. Directed graph data structures are created to represent the graphical programs, wherein the vertices of the graphs are the objects of the graphical programs and the edges of the graphs are data flow signals of the block diagram and/or hierarchical relationships of the user interface panel objects. The objects of the two graphical programs are heuristically matched together using a scoring approach. The scores are stored in a match matrix and indicate a degree of similarity between an object in the first graphical program and an object in the second graphical program according to one or more criteria. The matching criteria include object type, object connectivity and object attributes. The match matrix is resolved to generate a 1:1 or 1:0 correspondence between the objects in the first and second graphical programs based on the match scores. The matching information is used to determine differences in the two graphical programs. First, using the matching information and a compare engine, the objects are grouped into exact matching subgraphs and then into non-exact matching subgraphs. Non-exact matching subgraphs are matched and merged where possible using transitivity. Objects in the non-exact matching subgraphs are compared using the compare engine to detect additional differences. All detected differences are stored and displayed for the user. The differences may be displayed in various manners such as drawing a circle around the differences, highlighting the differences by color, and/or displaying a textual description of the differences."/><meta property="og:title" content="Patent US5974254 - Method for detecting differences between graphical programs"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("fpXtU6bgOamzsATWgYGoCg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("ITA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("fpXtU6bgOamzsATWgYGoCg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("ITA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5974254?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5974254"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=9opMBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5974254&amp;usg=AFQjCNFINwud2gKES4dJYqoXAURqJhX5VQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5974254.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5974254.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5974254" style="display:none"><span itemprop="description">A method for detecting differences between two graphical programs is disclosed. The graphical programs include objects, preferably arranged as a user interface panel, including controls and indicators, and a block diagram, including graphical code function blocks connected together as a data flow program....</span><span itemprop="url">http://www.google.com/patents/US5974254?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5974254 - Method for detecting differences between graphical programs</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5974254 - Method for detecting differences between graphical programs" title="Patent US5974254 - Method for detecting differences between graphical programs"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5974254 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/870,262</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Oct 26, 1999</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jun 6, 1997</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jun 6, 1997</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US6138270">US6138270</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08870262, </span><span class="patent-bibdata-value">870262, </span><span class="patent-bibdata-value">US 5974254 A, </span><span class="patent-bibdata-value">US 5974254A, </span><span class="patent-bibdata-value">US-A-5974254, </span><span class="patent-bibdata-value">US5974254 A, </span><span class="patent-bibdata-value">US5974254A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Ray+Hsu%22">Ray Hsu</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22National+Instruments+Corporation%22">National Instruments Corporation</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5974254.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5974254.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5974254.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (14),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (14),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (73),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (9),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (9)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5974254&usg=AFQjCNFdOn8l_HxXepCedVNU0yNVf49Hig">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5974254&usg=AFQjCNG4A3aPvfXcgbAtwdAvrIQIcmGPRQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5974254A%26KC%3DA%26FT%3DD&usg=AFQjCNFiuE_-lf-RoGhXb4Kk8Uz_psdl2A">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54497812" lang="EN" load-source="patent-office">Method for detecting differences between graphical programs</invention-title></span><br><span class="patent-number">US 5974254 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37978354" lang="EN" load-source="patent-office"> <div class="abstract">A method for detecting differences between two graphical programs is disclosed. The graphical programs include objects, preferably arranged as a user interface panel, including controls and indicators, and a block diagram, including graphical code function blocks connected together as a data flow program. Directed graph data structures are created to represent the graphical programs, wherein the vertices of the graphs are the objects of the graphical programs and the edges of the graphs are data flow signals of the block diagram and/or hierarchical relationships of the user interface panel objects. The objects of the two graphical programs are heuristically matched together using a scoring approach. The scores are stored in a match matrix and indicate a degree of similarity between an object in the first graphical program and an object in the second graphical program according to one or more criteria. The matching criteria include object type, object connectivity and object attributes. The match matrix is resolved to generate a 1:1 or 1:0 correspondence between the objects in the first and second graphical programs based on the match scores. The matching information is used to determine differences in the two graphical programs. First, using the matching information and a compare engine, the objects are grouped into exact matching subgraphs and then into non-exact matching subgraphs. Non-exact matching subgraphs are matched and merged where possible using transitivity. Objects in the non-exact matching subgraphs are compared using the compare engine to detect additional differences. All detected differences are stored and displayed for the user. The differences may be displayed in various manners such as drawing a circle around the differences, highlighting the differences by color, and/or displaying a textual description of the differences.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(11)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-7.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-7.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-8.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-8.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-9.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-9.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-10.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-10.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-11.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-11.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5974254-12.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5974254-12.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(67)</span></span></div><div class="patent-text"><div mxw-id="PCLM5463875" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>I claim:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A computer-implemented method for detecting differences between first and second graphical programs, wherein the method executes on a computer including a display screen and an input device, wherein the first and second graphical programs comprise graphical code, wherein the first graphical program comprises a first plurality of objects and wherein the second graphical program comprises a second plurality of objects, the method comprising:<div class="claim-text">creating data structures to represent said first and second graphical programs;</div> <div class="claim-text">matching said first plurality of objects of said first graphical program with said second plurality of objects of said second graphical program;</div> <div class="claim-text">determining differences between said first graphical program and said second graphical program in response to said matching; and</div> <div class="claim-text">displaying an indication of said differences on the display screen.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The method of claim 1, wherein said matching includes determining matches between one or more of said first plurality of objects of said first graphical program with one or more of said second plurality of objects of said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The method of claim 2, wherein said matching comprises determining objects of said first graphical program which have a same type as objects of said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The method of claim 3, wherein said matching further comprises determining if an object of said first graphical program which has the same type as an object of said second graphical program has the same type as another object in said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The method of claim 1, wherein said determining differences includes determining objects present in said first graphical program which have no matching object in said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The method of claim 1, wherein said determining differences includes comparing matching objects in said first graphical program and said second graphical program to determine differences in said matching objects.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The method of claim 6, wherein each of said first plurality of objects and said second plurality of objects comprises a set of attributes and methods, wherein said comparing matching objects includes comparing attributes of said matching objects in said first graphical program and said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The method of claim 1, wherein said determining differences between said first and second graphical programs comprises finding functional differences between said first graphical program and said second graphical program, wherein a functional difference indicates a potential difference in execution of said first and second graphical programs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The method of claim 8, wherein said determining differences between said first and second graphical programs comprises finding cosmetic differences between said first and second graphical programs, wherein a cosmetic difference is a non-functional difference.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The method of claim 1, wherein said first plurality of objects and said second plurality of objects include function block icons.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The method of claim 1, wherein said first plurality of objects and said second plurality of objects include controls and indicators.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The method of claim 1, wherein said first plurality of objects and said second plurality of objects include function block icons;<div class="claim-text">wherein said first plurality of objects and said second plurality of objects further include data flow paths coupled between said function block icons.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The method of claim 1, wherein said displaying said differences includes displaying a textual description of each of said differences.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The method of claim 1, wherein said displaying said differences comprises displaying said first and second graphical programs, wherein said displaying said differences further comprises highlighting each of said differences between said first and second graphical programs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. The method of claim 1, wherein said first and second graphical programs each comprise a block diagram comprising the graphical code, a user interface panel for displaying one or more of data output from the block diagram and data input to the block diagram, and graphical program attributes;<div class="claim-text">wherein said determining differences between said first graphical program and said second graphical program comprises:<div class="claim-text">determining differences between said block diagrams of said first and second graphical programs;</div> <div class="claim-text">determining differences between said user interface panels of said first and second graphical programs;</div> <div class="claim-text">determining differences between said graphical program attributes of said first and second graphical programs.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The method of claim 1, wherein said creating data structures includes:<div class="claim-text">creating one or more data structures which includes information regarding said first plurality of objects in said first graphical program and said second plurality of objects in said second graphical program.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The method of claim 16, wherein said one or more data structures each comprise directed acyclic graphs comprising a plurality of vertices connected by edges, wherein each of said vertices represents one of said first plurality of objects or said second plurality of objects in one of said graphical programs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. The method of claim 16, wherein said one or more data structures each comprise directed graphs comprising a plurality of vertices connected by edges, wherein each of said vertices represents one of said first plurality of objects or said second plurality of objects in one of said graphical programs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The method of claim 18, wherein said first and second graphical programs each comprise a block diagram comprising the graphical code and a user interface panel for displaying one or more of data output from the block diagram and data input to the block diagram;<div class="claim-text">wherein, for each graphical program, said one or more data structures comprise:<div class="claim-text">a block diagram data structure comprising a directed graph, wherein the edges of said graph between said first or second plurality of objects represent directed flow of data and/or hierarchical relationship between said first or second plurality of objects in said block diagram;</div> <div class="claim-text">a user interface panel data structure comprising a directed graph, wherein the edges of said graph between said first or second plurality of objects represent a hierarchical relationship between said first or second plurality of objects in said user interface panel.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The method of claim 1, wherein said first graphical program includes a first data structure stored in a memory of the computer system which comprises information regarding said first graphical program, and wherein said second graphical program includes a second data structure stored in the memory of the computer system which comprises information regarding said second graphical program, wherein said creating data structures includes:<div class="claim-text">creating a third data structure which includes information regarding said first plurality of objects in said first graphical program, wherein said third data structure is created in response to said first data structure;</div> <div class="claim-text">creating a fourth data structure which includes information regarding said second plurality of objects in said second graphical program, wherein said fourth data structure is created in response to said second data structure.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. The method of claim 1, wherein said creating data structures includes:<div class="claim-text">creating a first data stucture which includes information regarding said first plurality of objects in said first graphical program;</div> <div class="claim-text">creating a second data structure which includes information regarding said second plurality of objects in said second graphical program;</div> <div class="claim-text">wherein, for each respective object in said first graphical program, said matching comprises:<div class="claim-text">comparing the respective object in said first graphical program with one or more objects in said second graphical program;</div> <div class="claim-text">determining a score value for a plurality of object pairs in response to said comparing, wherein each of said plurality of object pairs comprises two object elements, said two object elements comprising said respective object in said first graphical program and an object of said one or more objects in said second graphical program, wherein said score value indicates a degree of matching between said object elements comprising said object pair.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22. The method of claim 21, wherein said determining said score value for one of said plurality of object pairs includes examining connectivity of object elements comprising said object pair.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. The method of claim 21, wherein said determining said score value for one of said plurality of object pairs includes examining attributes of object elements comprising said object pair.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" class="claim">
      <div class="claim-text">24. The method of claim 21, wherein said score value is a weighted score value, wherein said determining said score value for one of said plurality of object pairs includes examining connectivity of object elements comprising said object pair and examining attributes of object elements comprising said object pair;<div class="claim-text">wherein said connectivity of object elements has greater weight than said attributes of said object elements.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25. The method of claim 24, wherein said attributes comprise functional attributes and cosmetic attributes;<div class="claim-text">wherein said functional attributes have greater weight than said cosmetic attributes.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" class="claim">
      <div class="claim-text">26. The method of claim 21, wherein said matching further comprises:<div class="claim-text">storing said score values in a match matrix, wherein said match matrix comprises rows which correspond to said first plurality of objects in said first graphical program, and wherein said match matrix comprises columns which correspond to said second plurality of objects in said second graphical program;</div> <div class="claim-text">wherein for an ith row and a jth column, the matrix element (i,j) includes the score value for the object pair comprising object i and object j.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27. The method of claim 26, wherein said matching further comprises:<div class="claim-text">resolving said match matrix using said match matrix score values, wherein said resolving produces a 1:1 or 1:0 relationship between objects in said first graphical program and objects in said second graphical program depending upon whether or not an object in said first graphical program has a matching object in said second graphical program.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" class="claim">
      <div class="claim-text">28. The method of claim 26, wherein said matching further comprises:<div class="claim-text">resolving said match matrix using said match matrix score values, wherein, for each of at least a subset of said rows corresponding to said first plurality of objects, said resolving produces a column from said second plurality of objects in said second graphical program, wherein said produced column has a match matrix element with a highest score value for the respective row.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" class="claim">
      <div class="claim-text">29. The method of claim 1,<div class="claim-text">wherein said creating data structures includes:<div class="claim-text">creating a first data structure which includes information regarding said first plurality of objects in said first graphical program;</div> <div class="claim-text">creating a second data structure which includes information regarding said second plurality of objects in said second graphical program;</div> </div> <div class="claim-text">wherein said matching produces a resolved match matrix, wherein said resolved match matrix comprises matching information regarding matches between said first plurality of objects in said first graphical program and said second plurality of objects in said second graphical program;</div> <div class="claim-text">wherein said determining differences between said first graphical program and said second graphical program comprises:<div class="claim-text">grouping objects which have exact matches with connectivity matches into exact matching connected components using said matching information;</div> <div class="claim-text">grouping remaining objects to produce non-exact matching connected components wherein said grouping remaining objects produces a first list of non-exact-matching connected components for said first data structure and produces a second list of non-matching connected components for said second data structure;</div> <div class="claim-text">matching said first and second lists of non-exact matching connected components, wherein said matching said first and second lists of non-exact matching connected components includes finding common objects in said first and second lists of non-exact matching connected components, wherein said matching said first and second lists of non-exact matching connected components produces second matching information;</div> <div class="claim-text">merging said first and second lists of non-exact matching connected components using said second matching information, wherein said merging produces a composite non-exact matching connected component list;</div> <div class="claim-text">storing corresponding non-exact matching connected components in a result data structure;</div> <div class="claim-text">comparing matching objects in corresponding non-exact matching connected components to determine additional object differences;</div> <div class="claim-text">storing said additional object differences in said result data structure.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" class="claim">
      <div class="claim-text">30. The method of claim 29, wherein said grouping objects which have exact matches with connectivity matches comprises grouping objects which have exact matches with connectivity matches using said first and second data structures and said matching information to produce a first list of exact matching connected components for said first data structure and to produce a second list of exact matching connected components for said second data structure, wherein said grouping objects includes comparing objects according to one or more criteria to determine exact matches between objects, wherein an exact match comprises a match in the match matrix and match in said comparing.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" class="claim">
      <div class="claim-text">31. The method of claim 1,<div class="claim-text">wherein said first graphical program comprise a first user interface panel including a subset of said first plurality of objects for displaying one or more of outputs from the block diagram or inputs to the block diagram;</div> <div class="claim-text">wherein said second graphical program comprise a second user interface panel including a subset of said second plurality of objects for displaying one or more of outputs from the block diagram or inputs to the block diagram;</div> <div class="claim-text">wherein said matching produces a user interface panel match matrix comprising matching information;</div> <div class="claim-text">wherein said determining differences includes determining differences between said first user interface panel and said second user interface panel which comprises:<div class="claim-text">comparing matching top-level objects of said first and second user interface panels to determine differences between said top-level objects using said matching infounation;</div> <div class="claim-text">comparing low-level objects of said top-level objects to determine differences between said low-level objects using said matching information;</div> <div class="claim-text">storing said differences in response to said steps of comparing.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="32" class="claim">
      <div class="claim-text">32. The method of claim 1, wherein said determining differences between said first graphical program and said second graphical program includes comparing differences between attributes of said first graphical program and attributes of said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" class="claim">
      <div class="claim-text">33. The method of claim 1, wherein each of said first and second graphical programs comprises a user interface panel and a block diagram, wherein said first graphical program comprises a first user interface panel and a first block diagram, and wherein said second graphical program comprises a second user interface panel and a second block diagram;<div class="claim-text">wherein said creating data structures comprises creating a data structure for objects in said first block diagram and said first user interface panel and creating a data structure for objects in said second block diagram and said second user interface panel;</div> <div class="claim-text">wherein said matching comprises matching one or more objects in said first block diagram with one or more objects in said second block diagram, and wherein said matching further includes matching one or more objects in said first user interface panel with one or more objects in said second user interface panel;</div> <div class="claim-text">wherein said determining differences between said first graphical program and said second graphical program comprises determining differences between said first block diagram and said second block diagram and determining differences between said first user interface panel and said second user interface panel.</div> </div>
    </div>
    </div> <div class="claim"> <div num="34" class="claim">
      <div class="claim-text">34. A computer system for detecting differences between first and second graphical programs, comprising:<div class="claim-text">a central processing unit (CPU);</div> <div class="claim-text">a display screen operably coupled to the CPU;</div> <div class="claim-text">an input device operably coupled to the CPU; and</div> <div class="claim-text">a memory for storing said first and second graphical programs and for storing a difference program for detecting differences between said first and second graphical programs, wherein the fast and second graphical programs comprise graphical code, wherein the first graphical program comprises a first plurality of objects and wherein the second graphical program comprises a second plurality of objects;</div> <div class="claim-text">wherein said CPU is operable to fetch program instructions of said difference program from said memory and to execute said program instructions to:<div class="claim-text">create data structures to represent said first and second graphical programs;</div> <div class="claim-text">match said first plurality of objects of said first graphical program with said second plurality of objects of said second graphical program;</div> <div class="claim-text">determine differences between said first graphical program and said second graphical program in response to the matching; and</div> <div class="claim-text">display an indication of said differences on the display screen.</div> </div> </div>
    </div>
    </div> <div class="claim"> <div num="35" class="claim">
      <div class="claim-text">35. A computer-readable storage medium comprising program instructions for detecting differences between first and second graphical programs, wherein the program instructions execute on a computer including a display screen and an input device, wherein said program instructions are executable to implement:<div class="claim-text">creating data structures to represent first and second graphical programs, wherein the first and second graphical programs comprise graphical code, wherein the first graphical program comprises a first plurality of objects and wherein the second graphical program comprises a second plurality of objects;</div> <div class="claim-text">matching said first plurality of objects of said first graphical program with said second plurality of objects of said second graphical program;</div> <div class="claim-text">determining differences between said first graphical program and said second graphical program in response to said matching; and</div> <div class="claim-text">displaying an indication of said differences on the display screen.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="36" class="claim">
      <div class="claim-text">36. The medium of claim 35, wherein said matching includes determining matches between one or more of said first plurality of objects of said first graphical program with one or more of said second plurality of objects of said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="37" class="claim">
      <div class="claim-text">37. The medium of claim 36, wherein said matching comprises determining objects of said first graphical program which have a same type as objects of said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="38" class="claim">
      <div class="claim-text">38. The medium of claim 37, wherein said matching further comprises determining if an object of said first graphical program which has the same type as an object of said second graphical program has the same type as another object in said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="39" class="claim">
      <div class="claim-text">39. The medium of claim 35, wherein said determining differences includes determining objects present in said first graphical program which have no matching object in said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="40" class="claim">
      <div class="claim-text">40. The medium of claim 35, wherein said determining differences includes comparing matching objects in said first graphical program and said second graphical program to determine differences in said matching objects.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="41" class="claim">
      <div class="claim-text">41. The medium of claim 40, wherein each of said first plurality of objects and said second plurality of objects comprises a set of attributes and methods, wherein said comparing matching objects includes comparing attributes of said matching objects in said first graphical program and said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="42" class="claim">
      <div class="claim-text">42. The medium of claim 35, wherein said determining differences between said first and second graphical programs comprises finding functional differences between said first graphical program and said second graphical program, wherein a functional difference indicates a potential difference in execution of said first and second graphical programs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="43" class="claim">
      <div class="claim-text">43. The medium of claim 42, wherein said determining differences between said first and second graphical programs comprises finding cosmetic differences between said first and second graphical programs, wherein a cosmetic difference is a non-functional difference.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="44" class="claim">
      <div class="claim-text">44. The medium of claim 35, wherein said first plurality of objects and said second plurality of objects include function block icons.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="45" class="claim">
      <div class="claim-text">45. The medium of claim 35, wherein said first plurality of objects and said second plurality of objects include controls and indicators.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="46" class="claim">
      <div class="claim-text">46. The medium of claim 35, wherein said first plurality of objects and said second plurality of objects include function block icons;<div class="claim-text">wherein said first plurality of objects and said second plurality of objects further include data flow paths coupled between said function block icons.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="47" class="claim">
      <div class="claim-text">47. The medium of claim 35, wherein said displaying said differences includes displaying a textual description of each of said differences.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="48" class="claim">
      <div class="claim-text">48. The medium of claim 35, wherein said displaying said differences comprises displaying said first and second graphical programs, wherein said displaying said differences further comprises highlighting each of said differences between said first and second graphical programs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="49" class="claim">
      <div class="claim-text">49. The medium of claim 35, wherein said first and second graphical programs each comprise a block diagram comprising graphical code, a user interface panel for displaying data input/output to/from the block diagram, and graphical program attributes;<div class="claim-text">wherein said determining differences between said first graphical program and said second graphical program comprises:<div class="claim-text">determining differences between said block diagrams of said first and second graphical programs;</div> <div class="claim-text">determining differences between said user interface panels of said first and second graphical programs;</div> <div class="claim-text">determining differences between said graphical program attributes of said first and second graphical programs.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="50" class="claim">
      <div class="claim-text">50. The medium of claim 35, wherein said creating data structures includes:<div class="claim-text">creating one or more data structures which includes information regarding said first plurality of objects in said first graphical program and said second plurality of objects in said second graphical program.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="51" class="claim">
      <div class="claim-text">51. The medium of claim 50, wherein said one or more data structures each comprise directed acyclic graphs comprising a plurality of vertices connected by edges, wherein each of said vertices represents one of said first plurality of objects or said second plurality of objects in one of said graphical programs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="52" class="claim">
      <div class="claim-text">52. The medium of claim 50, wherein said one or more data structures each comprise directed graphs comprising a plurality of vertices connected by edges, wherein each of said vertices represents one of said first plurality of objects or said second plurality of objects in a respective one of said graphical programs.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="53" class="claim">
      <div class="claim-text">53. The medium of claim 52, wherein said first and second graphical programs each comprise a block diagram comprising the graphical code and a user interface panel for displaying one or more of data input to the block diagram and data output to the block diagram;<div class="claim-text">wherein, for each graphical program, said one or more data structures comprise:<div class="claim-text">a block diagram data structure comprising a directed graph, wherein the edges of said graph between said first or second plurality of objects represent directed flow of data and/or hierarchical relationship between said first or second plurality of objects in said block diagram;</div> <div class="claim-text">a user interface panel data structure comprising a directed graph, wherein the edges of said graph between said first or second plurality of objects represent a hierarchical relationship between said first or second plurality of objects in said user interface panel.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="54" class="claim">
      <div class="claim-text">54. The medium of claim 35, wherein said first graphical program includes a first data structure stored in a memory of the computer system which comprises information regarding said first graphical program, and wherein said second graphical program includes a second data structure stored in the memory of the computer system which comprises information regarding said second graphical program, wherein said creating data structures includes:<div class="claim-text">creating a third data structure which includes information regarding said first plurality of objects in said first graphical program, wherein said third data structure is created in response to said first data structure;</div> <div class="claim-text">creating a fourth data structure which includes information regarding said second plurality of objects in said second graphical program, wherein said fourth data structure is created in response to said second data structure.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="55" class="claim">
      <div class="claim-text">55. The medium of claim 35, wherein said creating data structures includes:<div class="claim-text">creating a first data structure which includes information regarding said first plurality of objects in said first graphical program;</div> <div class="claim-text">creating a second data structure which includes information regarding said second plurality of objects in said second graphical program;</div> <div class="claim-text">wherein, for each respective object in said first graphical program, said matching comprises:<div class="claim-text">comparing the respective object in said first graphical program with one or more objects in said second graphical program;</div> <div class="claim-text">determining a score value for a plurality of object pairs in response to said comparing, wherein each of said plurality of object pairs comprises two object elements, said two object elements comprising said respective object in said first graphical program and an object of said one or more objects in said second graphical program, wherein said score value indicates a degree of matching between said object elements comprising said object pair.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="56" class="claim">
      <div class="claim-text">56. The medium of claim 55, wherein said determining said score value for one of said plurality of object pairs includes examining connectivity of object elements comprising said object pair.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="57" class="claim">
      <div class="claim-text">57. The medium of claim 55, wherein said determining said score value for one of said plurality of object pairs includes examining attributes of object elements comprising said object pair.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="58" class="claim">
      <div class="claim-text">58. The medium of claim 55, wherein said score value is a weighted score value, wherein said determining said score value for one of said plurality of object pairs includes examining connectivity of object elements comprising said object pair and examining attributes of object elements comprising said object pair;<div class="claim-text">wherein said connectivity of object elements has greater weight than said attributes of said object elements.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="59" class="claim">
      <div class="claim-text">59. The medium of claim 58, wherein said attributes comprise functional attributes and cosmetic attributes;<div class="claim-text">wherein said functional attributes have greater weight than said cosmetic attributes.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="60" class="claim">
      <div class="claim-text">60. The medium of claim 55, wherein said matching further comprises:<div class="claim-text">storing said score values in a match matrix, wherein said match matrix comprises rows which correspond to said first plurality of objects in said first graphical program, and wherein said match matrix comprises columns which correspond to said second plurality of objects in said second graphical program;</div> <div class="claim-text">wherein for an ith row and a jth column, the matrix element (i,j) includes the score value for the object pair comprising object i and object j.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="61" class="claim">
      <div class="claim-text">61. The medium of claim 60, wherein said matching flurther comprises:<div class="claim-text">resolving said match matrix using said match matrix score values, wherein said resolving produces a 1:1 or 1:0 relationship between objects in said first graphical program and objects in said second graphical program depending upon whether or not an object in said first graphical program has a matching object in said second graphical program.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="62" class="claim">
      <div class="claim-text">62. The medium of claim 60, wherein said matching further comprises:<div class="claim-text">resolving said match matrix using said match matrix score values, wherein, for each of at least a subset of said rows corresponding to said first plurality of objects, said resolving produces a column from said second plurality of objects in said second graphical program, wherein said produced column has a match matrix element with a highest score value for the respective row.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="63" class="claim">
      <div class="claim-text">63. The medium of claim 35,<div class="claim-text">wherein said creating data structures includes:<div class="claim-text">creating a first data structure which includes information regarding said first plurality of objects in said first graphical program;</div> <div class="claim-text">creating a second data structure which includes information regarding said second plurality of objects in said second graphical program;</div> </div> <div class="claim-text">wherein said matching produces a resolved match matrix, wherein said resolved match matrix comprises matching information regarding matches between said first plurality of objects in said first graphical program and said second plurality of objects in said second graphical program;</div> <div class="claim-text">wherein said determining differences between said first graphical program and said second graphical program comprises:<div class="claim-text">grouping objects which have exact matches with connectivity matches into exact matching connected components using said matching information;</div> <div class="claim-text">grouping remaining objects to produce non-exact matching connected components wherein said grouping remaining objects produces a first list of non-exact-matching connected components for said first data structure and produces a second list of non-matching connected components for said second data structure;</div> <div class="claim-text">matching said first and second lists of non-exact matching connected components, wherein said matching said first and second lists of non-exact matching connected components includes finding common objects in said first and second lists of non-exact matching connected components, wherein said matching said first and second lists of non-exact matching connected components produces second matching information;</div> <div class="claim-text">merging said first and second lists of non-exact matching connected components using said second matching information, wherein said merging produces a composite non-exact matching connected component list;</div> <div class="claim-text">storing corresponding non-exact matching connected components in a result data structure;</div> <div class="claim-text">comparing matching objects in corresponding non-exact matching connected components to determine additional object differences;</div> <div class="claim-text">storing said additional object differences in said result data structure.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="64" class="claim">
      <div class="claim-text">64. The medium of claim 63, wherein said step of grouping objects which have exact matches with connectivity matches comprises grouping objects which have exact matches with connectvity matches using said first and second data structures and said matching information to produce a first list of exact matching connected components for said first data structure and to produce a second list of exact matching connected components for said second data structure, wherein said grouping objects includes comparing objects according to one or more criteria to determine exact matches between objects, wherein an exact match comprises a match in the match matrix and match in said comparing.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="65" class="claim">
      <div class="claim-text">65. The medium of claim 35,<div class="claim-text">wherein said first graphical program comprise a first user interface panel including a subset of said first plurality of objects for displaying one or more of outputs from the block diagram or inputs to the block diagram;</div> <div class="claim-text">wherein said second graphical program comprise a second user interface panel including a subset of said second plurality of objects for displaying one or more of outputs from the block diagram or inputs to the block diagram;</div> <div class="claim-text">wherein said matching produces a user interface panel match matrix comprising matching information;</div> <div class="claim-text">wherein said determining differences includes determining differences between said first user interface panel and said second user interface panel which comprises:<div class="claim-text">comparing matching top-level objects of said first and second user interface panels to determine differences between said top-level objects using said matching information;</div> <div class="claim-text">comparing low-level objects of said top-level objects to determine diferences between said low-level objects using said matching information;</div> <div class="claim-text">storing said differences in response to said steps of comparing matching top-level objects of said first and second user interface panels and comparing low-level objects of said top-level objects.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="66" class="claim">
      <div class="claim-text">66. The medium of claim 35, wherein said determining differences between said first graphical program and said second graphical program includes comparing differences between attributes of said first graphical program and attributes of said second graphical program.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="67" class="claim">
      <div class="claim-text">67. The medium of claim 35, wherein each of said first and second graphical programs comprises a user interface panel and a block diagram, wherein said first graphical program comprises a first user interface panel and a first block diagram, and wherein said second graphical program comprises a second user interface panel and a second block diagram;<div class="claim-text">wherein said creating data structures comprises creating a data structure for objects in said first block diagram and said first user interface panel and creating a data structure for objects in said second block diagram and said second user interface panel;</div> <div class="claim-text">wherein said matching comprises matching one or more objects in said first block diagram with one or more objects in said second block diagram, and wherein said matching further includes matching one or more objects in said first user interface panel with one or more objects in said second user interface panel;</div> <div class="claim-text">wherein said determining differences between said first graphical program and said second graphical program comprises determining differences between said first block diagram and said second block diagram and determining differences between said first user interface panel and said second user interface panel.</div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67355836" lang="EN" load-source="patent-office" class="description">
    <heading>MICROFICHE APPENDIX</heading> <p>The present application includes a microfiche source code appendix comprising a portion of a C language source code listing of one embodiment of the software of the present invention. The appendix comprises 3 microfiche and a total of 201 frames.</p>
    <heading>FIELD OF THE INVENTION</heading> <p>The present invention relates to graphical programming, and in particular to detecting differences between graphical programs.</p>
    <heading>DESCRIPTION OF THE RELATED ART</heading> <p>Traditionally, high level text-based programming languages have typically been used by programmers in writing applications programs. Many different high level programming languages exist, including BASIC, C, FORTRAN, Pascal, COBOL, ADA, APL, etc. Programs written in these high level languages are translated to the machine language level by translators known as compilers. The high level text-based programming languages in this level, as well as the assembly language level, are referred to in this disclosure as text-based programming environments.</p>
    <p>Increasingly computers are required to be used and programmed by those who are not highly trained in computer programming techniques. When traditional text-based programming environments are used, the user's programming skills and ability to interact with the computer system often become a limiting factor in the achievement of optimal utilization of the computer system.</p>
    <p>There are numerous subtle complexities which a user must master before he can efficiently program a computer system in a text-based environment. In addition, the task of programming a computer system to model a process often is further complicated by the fact that a sequence of mathematical formulas, mathematical steps or other procedures customarily used to conceptually model a process often does not closely correspond to the traditional text-based programming techniques used to program a computer system to model such a process. For example, a computer programmer typically develops a conceptual model for a physical system which can be partitioned into functional blocks, each of which corresponds to actual systems or subsystems. Computer systems, however, ordinarily do not actually compute in accordance with such conceptualized functional blocks. Instead, they often utilize calls to various subroutines and the retrieval of data from different memory storage locations to implement a procedure which could be conceptualized by a user in terms of a functional block. In other words, the requirement that a user program in a text-based programming environment places a level of abstraction between the user's conceptualization of the solution and the implementation of a method that accomplishes this solution in a computer program. Thus, a user often must substantially master different skills in order to both conceptually model a system and then to program a computer to model that system. Since a user often is not fully proficient in techniques for programming a computer system in a text-based environment to implement his model, the efficiency with which the computer system can be utilized to perform such modeling often is reduced.</p>
    <p>An example of a field in which computer systems are employed to model physical systems is the field of instrumentation. An instrument is a device which collects information from an environment and displays this information to a user. Examples of various types of instruments include oscilloscopes, digital multimeters, pressure sensors, etc. Types of information which might be collected by respective instruments include: voltage, resistance, distance, velocity, pressure, frequency of oscillation, humidity or temperature, among others. An instrumentation system ordinarily controls its constituent instruments from which it acquires data which it analyzes, stores and presents to a user of the system.</p>
    <p>Computer control of instrumentation has become increasingly desirable in view of the increasing complexity and variety of instruments available for use. However, when first introduced, computer-controlled instrumentation systems had significant drawbacks. For example, due to the wide variety of possible testing situations and environments, and also the wide array of instruments available, it was often necessary for a user to develop a program to control the new instrumentation system desired. As discussed above, computer programs used to control such improved instrumentation systems had to be written in conventional text-based programming languages such as, for example, assembly language, C, FORTRAN, BASIC, or Pascal. Traditional users of instrumentation systems, however, often were not highly trained in programming techniques and, in addition, traditional text-based programming languages were not sufficiently intuitive to allow users to use these languages without training. Therefore, implementation of such systems frequently required the involvement of a programmer to write software for control and analysis of instrumentation data. Thus, development and maintenance of the software elements in these instrumentation systems often proved to be difficult.</p>
    <p>U.S. Pat. No. 4,901,221 to Kodosky et al discloses a graphical system and method for modeling a process, i.e. a graphical programming environment which enables a user to easily and intuitively model a process. The graphical programming environment disclosed in Kodosky et al can be considered the highest and most intuitive way in which to interact with a computer. A graphically based programming environment can be represented at level above text-based high level programming languages such as C, Pascal, etc. The method disclosed in Kodosky et al allows a user to construct a diagram using a block diagram editor such that the diagram created graphically displays a procedure or method for accomplishing a certain result, such as manipulating one or more input variables to produce one or more output variables. As the user constructs the data flow diagram using the block diagram editor, machine language instructions are automatically constructed which characterize an execution procedure which corresponds to the displayed procedure. Therefore, a user can create a text-based computer program solely by using a graphically based programming environment. This graphically based programming environment may be used for creating virtual instrumentation systems and modeling processes as well as for any type of general programming.</p>
    <p>Therefore, Kodosky et al teaches a graphical programming environment wherein a user manipulates icons in a block diagram using a block diagram editor to create a data flow "program." A graphical program for controlling instruments or implementing instrumentation functions is referred to as a virtual instrument (VI). In creating a virtual instrument, a user preferably first creates a front panel including various controls or indicators that represent the respective input and output that will be used by the VI. When the controls and indicators are created in the front panel, corresponding icons or terminals are automatically created in the block diagram by the block diagram editor. Alternatively, the user may first place data input/output icons in the block diagram, which may optionally cause control and indicator icons to be placed in a front panel. The user then chooses various functions that accomplish his desired result, connecting the corresponding function icons between the terminals of the respective controls and indicators. In other words, the user creates a data flow and/or control flow program, referred to as a block diagram, representing the graphical data flow which accomplishes his desired function. This is done by wiring up the various function icons between the control icons and indicator icons. The manipulation and organization of icons in turn produces machine language that accomplishes the desired method or process as shown in the block diagram.</p>
    <p>A user inputs data to a virtual instrument using front panel controls. This input data propagates through the data flow block diagram or graphical program and appears as changes on the output indicators. The data that flows from the controls to the indicators in this manner is referred to as control data. In an instrumentation application, the front panel can be analogized to the front panel of an instrument. The user adjusts the controls on the front panel to affect the input and views the output on the respective indicators.</p>
    <p>Thus, graphical programming has become a powerful tool available to programmers. Graphical programming environments such as the National Instruments LabVIEW product have become very popular. Tools such as LabVIEW have greatly increased the productivity of programmers and more and more programmers are using graphical programming environments to develop their software applications. In particular, graphical programming tools are being used more frequently for large projects. However, large projects in which multiple software developers are working together often introduces many problems.</p>
    <p>One of the problems often encountered when working on large software development projects is keeping track of changes to software programs. With one or two developers working on a project, disciplined efforts to document the changes to the programs may suffice. However, with more developers making changes to the same set of programs, project management becomes exceedingly difficult. In addition, an individual developer may desire to detect changes which he or she has made between two different versions of a program, such as to determine why a bug was introduced or to examine changes made to a template version of the program.</p>
    <p>This problem has been solved somewhat satisfactorily for software programs developed in text-based languages. As previously described, text-based software programs are software programs which are written in traditional, i.e., non-graphical, textual-based programming languages such as FORTRAN, Pascal and the C language. In particular, one characteristic of text-based programs is that they are written as text files. That is, typically, the source code of the text-based software program is comprised within a text file, such as an ASCII character set text file. Thus, the constructs such as blocks, functions, statements, operations, etc. of text-based software programs are represented as words or numbers or combinations thereof.</p>
    <p>Software utilities have been written to detect changes between two different versions of a text-based software program. The utilities typically take as input two source code text files, each containing a different version of the program, and parse through the characters of the text files comparing each character to detect the differences in the characters between the two text files. The differences in characters are then displayed so that the user can readily discern the difference between the characters of the two programs. An example of such a utility for text-based programs is the "diff" utility commonly found in various versions of the UNIX® operating system.</p>
    <p>While a utility such as "diff" may require skill to develop, the basic concept of parsing through the characters of text files and comparing their differences is relatively straightforward. However, the problem of keeping track of changes in graphical programs is a much more difficult problem since graphical programs comprise graphical representations of programming constructs. As previously mentioned, graphical programs typically comprise functional blocks graphically represented as icons, not as text. A graphical program also may include control/indicator icons for providing and/or displaying data input to and output from the graphical program. Thus far, no solutions to this problem have been provided with respect to graphical programs. Therefore, a system and method for detecting differences between different versions of a graphical program are desired.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention provides a method for detecting differences between two graphical programs. Preferably, the method is executed on a computer system including a display screen and an input device. In one embodiment, the graphical programs are used to control instruments or other devices coupled to the computer system. The first graphical program comprises a first plurality of objects and the second graphical program comprises a second plurality of objects. The objects include attributes and methods and have a specific object type. Preferably, the objects are represented visually as icons in a user interface panel and/or block diagram. The user interface panel is used to provide input to and receive output from the graphical program. The block diagram comprises graphical code including user interface panel terminals and function blocks connected by data flow paths, or signals, to perform the desired function of the graphical program. The block diagram receives input for the graphical code from the user interface panel and provides output of the graphical code to the user interface panel. The graphical prograrns also include attributes themselves.</p>
    <p>The method comprises first creating data structures to represent the first and second graphical programs. Preferably, the data structures include a directed graph for each of the block diagrams and user interface panels of each of the graphical programs. The vertices of the graphs correspond to the objects of the block diagram or user interface panel. The edges of the block diagram graph correspond to the data flow paths. The edges of the user interface panel graph indicate the hierarchical relationships of the user interface panel objects, such as parent/child relationships in data aggregation clusters.</p>
    <p>The method further comprises a step of matching the first plurality of objects of the first graphical program with the second plurality of objects of the second graphical program. The method attempts to match objects of the graphical programs to determine similarities between the two programs, and hence to aid in finding differences between them. Preferably, the matching is performed according to a matching heuristic which calculates scores indicating a degree of similarity between an object in the first graphical program and an object in the second graphical program according to one or more criteria. These scores, or matching information, are stored in a match matrix data structure. The rows of the match matrix correspond to the objects of the first graphical program and the columns of the match matrix correspond to the objects of the second graphical program. The matching is performed for both the block diagram graphs and the user interface panel graphs.</p>
    <p>Pairs of objects (i.e., one from each of the graphical programs) are scored which match according to object type and which have no conflicts with other objects according to object type. Using these matching objects as starting points, the graphs are traversed looking for matching edges. The score of the source and destination objects of matching edges are updated accordingly. The matrix is then resolved by selecting the highest score in a given row or column. That is, in a given row, for example, the object corresponding to the column element in the match matrix with the highest score is selected to match the object corresponding to the given row. The other elements in the row are then zeroed out to indicate the resolved match. If a tie in scores exists at this point, the tie is not resolved, but postponed until a later step. Thus, when the match matrix is eventually resolved with all ties broken, a 1:1 or 1:0 relationship exists between objects in the first graphical program and objects in the second graphical program, the relationship depending upon whether or not an object in the first graphical program has a matching object in the second graphical program.</p>
    <p>After the matrix is resolved as described above, yet unmatched objects are scored according to object type only, and the match matrix is resolved again where possible. Next, any remaining conflicts are scored by examining the immediately neighboring objects of the graphs and the match matrix is resolved again where possible. Next, any remaining conflicts are scored by object attributes using a compare engine which includes specific knowledge of the attributes of each of the object types and the match matrix is resolved. Finally, the remaining conflicts are scored by the positions and sizes of the objects. After this step, the matrix is resolved and tie scores are resolved.</p>
    <p>The method then determines differences between the first graphical program and the second graphical program in response to the matching step. First, objects which match exactly are grouped into lists of matching subgraphs. Objects match exactly if they are of the same object type, their attributes match, and they have matching edges. The remaining objects which do not match exactly are then grouped into lists of non-exact matching subgraphs. The lists of non-exact matching subgraphs are matched using a subgraph match matrix in a similar manner to which the objects themselves were matched using a match matrix. The non-exact matching subgraphs in the subgraph match matrix are scored based upon matching nodes in the original match matrix. The rows and columns of the subgraph match matrix correspond to the subgraphs in the non-exact matching subgraph lists. Considering direct and transitive connections, the non-exact matching subgraphs are merged into composite non-exact matching subgraph lists. The compare engine is then used to compare the individual objects in the non-exact matching subgraphs to determine additional differences. Furthermore, non-exact matching subgraphs, which may be single objects, which have no match in the match matrix are stored as differences. For the user interface panels, top-level objects are compared using the compare engine and then the low-level objects, e.g., the data elements of any clusters, are compared using the compare engine to determine differences. All of the differences determined are stored in a results data structure.</p>
    <p>The method further comprises displaying an indication of the stored differences on the display screen of the computer system. In one embodiment, the differences are highlighted by greying out the portions of the block diagram which are not part of the difference and a geometric symbol, such as an ellipse or circle, is drawn around the difference. In one embodiment, the differences are displayed in a distinguishing color. In one embodiment, the differences are surrounded with "marching ants". In one embodiment, displaying the differences includes displaying a text description describing the differences.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>A better understanding of the present invention can be obtained when the following detailed description of the preferred embodiment is considered in conjunction with the following drawings, in which:</p>
    <p>FIG. 1 is an illustration of an instrumentation control system;</p>
    <p>FIG. 2 is a screen shot of an example of a virtual instrument or graphical software program for controlling an instrumentation control system such as in FIG. 1;</p>
    <p>FIG. 3 is a flowchart illustrating the method of detecting differences between graphical programs, such as the graphical program of FIG. 2, according to the present invention;</p>
    <p>FIG. 4 is a screen shot of the method of the present invention displaying differences between two graphical programs;</p>
    <p>FIG. 5 is a screen shot of a dialog which allows a user to select various options for detecting differences between two graphical programs;</p>
    <p>FIG. 6 is a block diagram illustrating a graph data structure according to a preferred embodiment of the present invention;</p>
    <p>FIG. 7 is a matrix list according to a preferred embodiment for storing an n row by m column matrix;</p>
    <p>FIG. 8 is a flowchart illustrating in more detail the step of matching objects of two graphical programs from FIG. 3;</p>
    <p>FIG. 9 is a block diagram illustrating a match matrix according to a preferred embodiment of the present invention;</p>
    <p>FIG. 10 is a flowchart illustrating in more detail the step of determining differences between block diagrams of two graphical programs of FIG. 3;</p>
    <p>FIG. 11 is a flowchart illustrating in more detail the step of determining differences between the user interface panels of two graphical programs of FIG. 3.</p>
    <p>While the invention is susceptible to various modifications and alternative forms specific embodiments are shown by way of example in the drawings and will herein be described in detail. It should be understood however, that drawings and detailed description thereto are not intended to limit the invention to the particular form disclosed. But on the contrary the invention is to cover all modifications, equivalents and alternative following within the spirit and scope of the present invention as defined by the appended claims.</p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading> <p>The present invention provides a method for detecting differences between two different graphical programs. Although in one embodiment described below the graphical programs control instrumentation hardware, it is noted that graphical programs may be used for a plethora of software applications and are not limited to instrumentation applications. Likewise, the method of the present invention is operable for use in detecting differences in graphical programs written for any application.</p>
    <p>FIG. 1--Computer System</p>
    <p>Referring now to FIG. 1, an instrumentation control system 10 is shown. The system 10 comprises a computer 12, which connects to one or more instruments. The computer comprises a CPU, a display screen, and one or more input devices such as a mouse or keyboard as shown.</p>
    <p>The one or more instruments may include a GPIB instrument 14, a VXI instrument 16, a serial instrument 18 and/or a data acquisition board 20. The GPIB instrument 14 is coupled to the computer 12 via a GPIB interface provided by the computer 12. The VXI instrument 16 is coupled to the computer 12 via a VXI bus or MXI bus provided by the computer. The serial instrument 18 is coupled to the computer 12 through a serial port, such as an RS-232 port, provided by the computer 12. Finally, the data acquisition board 20 is coupled to the computer 12, typically by being plugged in to an I/O slot in the computer such as a PCI bus slot, an ISA bus slot, an EISA bus slot, or a MicroChannel bus slot provided by the computer 12. In typical instrumentation control systems an instrument will not be present of each interface type and in fact many systems may only have one or more instruments of a single interface type, such as only GPIB instruments.</p>
    <p>The instruments are coupled to a unit under test (UUT) 23, process or are coupled to receive field signals, typically generated by transducers. The system 10 may be used in a data acquisition and control application, or may instead be used in a test and measurement application. If the system 10 is used in a data acquisition application, the system 10 may also include signal conditioning circuitry 21 coupled between the data acquisition board 20 and transducers.</p>
    <p>The instruments are controlled by graphical software programs which are stored in memory of the computer and which execute on the computer 12. The graphical software programs which perform instrumentation control are also referred to as virtual instruments. FIG. 2 illustrates an example of a virtual instrument or graphical software program. In the embodiment described herein, the graphical programs used herein were created using the LabVIEW graphical programming system.</p>
    <p>Referring again to FIG. 1, the system 10 preferably includes a memory media, such as a non-volatile memory, e.g., magnetic media, a system memory, CD-ROM, or floppy disks 22, on which computer programs according to the present invention are stored. The present invention comprises a software program stored on a memory and/or hard drive of the computer 12 and executed by a CPU of the computer. The CPU executing code and data from the memory thus comprises a means for detecting differences in graphical programs according to the steps described below.</p>
    <p>FIG. 3--High-level Diff Flowchart</p>
    <p>Referring now to FIG. 3, a flowchart illustrating the method of detecting differences between graphical programs according to the present invention is shown. Preferably, the method of the present invention is embodied as a software program which executes on a computer system such as computer system 12 of FIG. 1. The software program of the present invention for detecting differences between graphical programs will subsequently be referred to as "diff" for brevity. Appendix A includes a portion of a C language source code listing of one embodiment of diff.</p>
    <p>In the preferred embodiment, the graphical programs use graphical data flow programming, such as the LabVIEW graphical programming environment. However, other graphical programming systems may employ the method described herein to detect differences between graphical programs. Examples of systems which may employ the method are Visual Designer from Intelligent Instrumentation, Hewlett-Packard's VEE (Visual Engineering Environment), Snap-Master by HEM Data Corporation, DASYLab by DasyTec, and GFS DiaDem, among others. Programming environments which include graphical programming elements can also use the graphical diff method of the present invention.</p>
    <p>Diff receives as input two graphical programs, such as the graphical program of FIG. 2, in step 100. Each of the graphical programs includes a plurality of objects. An object may be defined as having attributes, or properties, and methods according to the notion of objects in the art of object oriented programming. Preferably, an object has an associated icon which visually represents the object, as shown in FIG. 2. Preferably, the graphical program comprises a block diagram portion and a user interface panel portion, and the objects are arranged in these two portions: the block diagram portion and the user interface panel portion. Alternatively, the objects are comprised solely in a block diagram or graphical program portion. In this embodiment, user interface objects, if present, may be comprised in the block diagram portion. A user interface panel is shown in the window in the upper right hand portion of FIG. 2 and a block diagram is shown in the window in the lower left hand portion of FIG. 2. In the case of instrumentation control applications, the user interface panel is typically referred to as an instrument front panel, or front panel. The objects in the user interface panel include controls and indicators. Controls are used to receive input, typically from a user, and to provide the input data to the block diagram. Indicators are used to receive output data from the block diagram and display the output data to the user. Examples of indicators are graphs, thermometers, meters and gauges. Examples of controls are slides, knobs, switches, buttons and dials. In one embodiment, the controls and indicators include clusters of controls and indicators arranged in a hierarchical manner.</p>
    <p>Preferably, the user interface panel comprises a directed acyclic graph of objects. In particular, the user interface panel comprises a hierarchical tree structure wherein the nodes of the tree are the user interface panel objects. A graph may be defined as a finite non-empty set of vertices and a set of edges such that every edge connects exactly two vertices. Preferably, any two vertices may be connected by zero or more edges. In the user interface panel, the vertices are the control and indicator objects and the edges are the hierarchical relationship between the objects. The direction of the edges are determined by the level in the hierarchy. That is, the direction is from higher level objects to lower level objects. The connectivity of an object is related to the other objects to which it is connected, i.e., its neighboring objects, and the edges by which it is connected to its neighboring objects.</p>
    <p>The block diagram is the portion of the graphical program which includes the graphical code to perform the calculations and operations of the graphical program application. The objects in the block diagram include terminals associated with the front panel controls and indicators. The front panel terminals are used to input and output data between the front panel controls/indicators and the function blocks of the block diagram. The block diagram objects also include function nodes, such as mathematical operators; code execution structures such as for loops, while loops, case statements, and variable references; string functions; file I/O nodes; communication nodes; instrument I/O nodes; and data acquisition nodes, for example. Preferably, the block diagram nodes are connected by data paths, or signals, which determine the flow of data through the block diagram.</p>
    <p>In the preferred embodiment, the block diagram comprises a data flow diagram arranged as a directed acyclic graph. The vertices of the graph are the terminals and nodes of the block diagram. The edges of the graph are data path signals which connect the nodes and terminals. The nodes themselves comprise one or more terminals which are connected to the edges. The direction of the edges of the graph is determined by the nodes themselves. For example, if a signal is connected between an output terminal of a first node and an input terminal of a second node, then the direction of data flow on that edge is from the output terminal to the input terminal.</p>
    <p>In response to receiving the two graphical programs, diff creates a data structure representing the first block diagram, a data structure representing the second block diagram, a data structure representing the first user interface panel, and a data structure representing the second user interface panel, in step 102. Preferably, the data structures comprise directed graphs, and more particularly, directed acyclic graphs. The graphs are used by diff to determine differences between the block diagrams and user interface panels of the two graphical programs. Step 102 and the graph structure will be discussed in more detail with regard to FIG. 6.</p>
    <p>Diff then matches objects in the first graphical program with objects in the second graphical program, in step 104. Objects are matched according to one or more criteria, such as object type, connectivity, attributes and position. Preferably, the matching is performed by calculating a weighted score which indicates a degree of matching or similarity between an object in the first graphical program and an object in the second graphical program according to the one or more criteria to produce matching information. The matching information is used to group the objects into matching subgroups, or sub-graphs, and non-matching sub-graphs for the purpose of determining differences between the two graphical programs. The matching of objects performed in step 104 will be described in more detail with regard to FIG. 8.</p>
    <p>Diff then determines differences between the first graphical program and the second graphical program, in steps 106, 108 and 110. Differences are determined for the block diagrams, the user interface panels and the attributes of the first and second graphical programs. The determining of differences includes comparing objects found to match in step 104 to determine any differences between the matching objects. The determining of differences also includes determining objects in the first graphical program which have no match, i.e., which do not exist in the second graphical program. The differences may be functional differences or cosmetic differences. A functional difference is one which may potentially affect the execution of the graphical program. Cosmetic differences are differences which do not affect execution of the graphical program. If the same set of inputs to a graphical program produce the same set of outputs even though a change has been made, that difference is a cosmetic difference rather than a functional difference. The determining of differences in the block diagrams and user interface panels performed in steps 106 and 108, respectively, will be described in more detail below.</p>
    <p>Preferably, the graphical program also includes attributes. Examples of graphical program attributes include an icon and connector representing the virtual instrument; attributes related to execution of the graphical program, such as execution priority and whether or not to run the graphical program upon being loaded; attributes related to the visual presentation of the graphical program, such as whether or not to display toolbars and window scroll bars; documentation-related attributes; attributes relating the history of the graphical program; and selection of a run-time menu. Diff detects differences between the attributes of the two graphical programs, in step 110.</p>
    <p>Once diff determines the differences between the two graphical programs, diff displays on the display screen of the computer system 12, an indication of the differences, in step 112. In one embodiment, diff highlights differences by drawing a geometric symbol, such as an ellipse or circle, around the differences, as shown in FIG. 4. FIG. 4 shows two versions of a virtual instrument named "Calculate Num Iterations" and "Calculate Num Iterations2". The block diagrams of the two graphical programs are displayed side by side in FIG. 4. One of the differences between the two graphical programs is shown in FIG. 4. The difference is related to a constant node which is connected as an input to a Select node. The block diagram on the left has a constant node with a value attribute of 10, whereas, the block diagram on the right has a constant node with a value attribute of 1. FIG. 4 shows the constant node in each block diagram with an ellipse drawn around them to highlight the difference. It is noted that the portions of the block diagram which are not part of the currently selected difference are "greyed out" so that the difference may be visually highlighted for the user.</p>
    <p>In operation of one embodiment, diff also displays the differences in a distinguishing color. For example, a black rectangular background is displayed behind the constant node in the first block diagram for a first period of time (such as two seconds), and then a black rectangular background is displayed behind the constant node in the second block diagram for a similar period of time. This highlights the difference for the user so that the user can visually distinguish the difference.</p>
    <p>In operation of another embodiment, diff surrounds the differences with "marching ants". Marching ants refers to the visual movement of alternating colors, such as black and white, around a differing object in each of the graphical programs. This operation may be partially seen in FIG. 4 by virtue of the fact that the constant node and the Select node are circumscribed with an alternating black and white portion thick line. Likewise, the wire connecting the two nodes is highlighted in a similar manner. In operation, the alternating black and white portions "move" visually around the nodes and along the wire to highlight the difference.</p>
    <p>Displaying the differences may also include displaying a text description of the differences. FIG. 4 shows a "Differences" window 300 at the bottom portion of the screen. The left portion 302 of the Differences window lists five differences between the two block diagrams shown. The right portion 304 of the Differences window provides a more detailed textual description of the difference highlighted in the left portion and which is currently displayed in the block diagrams, namely, a numeric constant data value. In FIG. 4, the text description reads "Numeric Constant: data value" to indicate that there is a difference between the value of 10 and the value of 1 in the two constant nodes highlighted.</p>
    <p>Preferably, differences may be determined in the block diagram, front panel and/or graphical program attributes individually or in any combination thereof, rather than determining the differences in all three. FIG. 5 illustrates a screen shot of a dialog which allows the user to select various diff options.</p>
    <p>FIGS. 6 and 7--Data Structures</p>
    <p>Referring now to FIG. 6, a block diagram illustrating a graph data structure according to a preferred embodiment is shown. As described above, a graph data structure is created in step 102 to represent each of the block diagram and front panel of each of the two graphical programs. Preferably, a graph structure is a data structure which represents a directed graph. In the case of the block diagram, the vertices of the graph are the user interface panel terminals and the node terminals of the block diagram. The edges of the graph are data path signals which connect the terminals. That is, each edge in the graph includes a source terminal and a destination terminal. The direction of data flow is from the source terminal to the destination terminal.</p>
    <p>In the case of the user interface panel, the vertices of the graph are the user interface panel objects, i.e., the controls and indicators. The direction of the edges are determined by the level in the hierarchy. That is, the direction is from higher level objects to lower level objects. The hierarchy of objects in the user interface panel with relation to array and cluster controls and indicators will be described in more detail below with reference to FIG. 11.</p>
    <p>The vertices of the graph are stored as a vertex list 324, or object list, as shown. The number of elements in the object list is equal to the number of objects in the graph. Each object list element includes an object ID field and a flags field.</p>
    <p>In the preferred embodiment, the graph data structure is represented as an adjacency matrix 322, as shown in FIG. 6. The rows of the matrix correspond to the objects of the graph, i.e., the block diagram or user interface panel. One row exists for each object in the graph. Likewise, the columns of the matrix represent the objects of the graph, one for each object. Thus, a matrix element exists for each ordered pair defined by a row and column (i,j). If an edge exists between the two objects in the ordered pair, then a non-empty edge list exists in the matrix. If no edges exist between the two objects in the ordered pair, then the edge list is empty.</p>
    <p>FIG. 6 also illustrates a typical edge list 326. An element exists in the edge list for each edge between the two objects of the respective row and column. Each element in the edge list comprises a source terminal identifier field, a destination terminal identifier field and a flags field. Data flows along the edge from the source terminal to the destination terminal. The flags are used in the steps of matching objects and determining differences. The source terminal and destination terminal fields are used to reference the objects in the object list.</p>
    <p>The adjacency matrix representation of the graph structure is typically a sparse matrix. That is, typically, a given object is connected to a relatively small number of other objects in the graph. Thus, in a given row, for example, the edge list will be empty for most of the columns. In one embodiment the adjacency matrix is stored as a matrix list. A matrix list embodiment advantageously makes more efficient use of memory storage for relatively sparse, non-trivial graphs than a full matrix representation.</p>
    <p>Referring now to FIG. 7, a matrix list according to a preferred embodiment is shown for storing an n×m matrix, i.e., a matrix with n rows and m columns. A matrix list may be used to store a matrix of any dimensions. That is, the matrix list is not limited to representing an n×n matrix, but rather may be used to represent an n×m matrix. The matrix list comprises a rowList, a colList and an eltList, as shown. The eltList, or element list, is a list of the elements of an adjacency matrix. With regard to the graph of FIG. 6, the eltList elements would be the edges in all of the edge lists. The eltList may include a maximum of n×m elements.</p>
    <p>The rowList, or row list, comprises an array of list pointers indexed by row number. Each row list element includes a column number and eltIndex, or element index. The column number in the row list element is combined with the row number used to index the row list array to produce an ordered pair corresponding to the (i,j) element in the graph adjacency matrix. The eltIndex is used to index into the eltList array to select the desired matrix element, as shown, such as an edge of the graph of FIG. 6.</p>
    <p>Similarly, the colList, or column list, comprises an array of list pointers indexed by column number. Each column list element includes a row number and eltIndex. The row number in the column list element is combined with the column number used to index the column list array to produce an ordered pair corresponding to the (i,j) element in the graph adjacency matrix.</p>
    <p>FIG. 8--Matching Objects Flowchart</p>
    <p>Referring now to FIG. 8, a flowchart illustrating in more detail step 104 from FIG. 3 of matching objects of the two graphical programs is shown. Preferably, step 104, i.e., steps 120 through 132 are performed once for the block diagrams and once for the user interface panels. For brevity, the steps of FIG. 8 will be described with reference to the block diagram. First, diff creates a match matrix to match elements between the first block diagram and the second block diagram, in step 120. The match matrix is used to determine similarities between the two block diagrams so that differences may subsequently be determined. A match matrix is also created to match elements between the first and second user interface panels in step 120. As mentioned, for brevity, the steps of FIG. 8 will be understood to also be performed for the user interface panels as well as the block diagrams, although the steps are described with reference to the block diagrams.</p>
    <p>Referring now to FIG. 9, a block diagram illustrating a match matrix according to a preferred embodiment of the present invention is shown. The match matrix comprises a matrix of match information elements. The rows of the match matrix correspond to the objects of the first graphical program and the columns of the match matrix correspond to the objects of the second graphical program. FIG. 9 illustrates a match matrix wherein the first graphical program includes n objects and the second graphical program includes m objects. That is, the match matrix is an n row by m column matrix. Thus, a given match matrix element (i,j) includes matching information regarding an object pair, wherein the objects of the pair are the ith object of the first graphical program and the jth object of the second graphical program.</p>
    <p>The match information includes a score field and a flags field. The score field indicates a degree of matching between the two objects of the object pair. The object pairs are scored using a matching heuristic. Objects may match according to various criteria, such as object type and associated conflict in object type, connectivity, neighboring objects, object attributes, position and size. Each of these matching criteria are given a different weight according to the matching heuristic. Scoring of the object pairs will be described in more detail below. The flags field is used in the process of matching objects and determining differences. In the preferred embodiment, the match matrix is embodied as a matrix list as shown in FIG. 7, wherein the elements in the element list are match information elements.</p>
    <p>Referring again to FIG. 8, diff calculates scores for object pairs wherein the object type, or object id, of an object in the first graphical program matches the object type of an object in the second graphical program and wherein there are no other objects in the two graphical programs with the same object type, in step 122. For example, if there is only one add node in each of the two graphical programs, then the add nodes match according to object type and are without conflicts. When two objects match according to object type and are without conflicts, diff assigns a relatively large initial score, or weight, to the object pair, thereby effecting a high probability that when the match matrix is resolved, the two objects will be matched.</p>
    <p>Using the matching object pairs produced by step 122, diff traverses the graphs of the graphical programs searching for matching edges and increases the score of the source and destination object connected to each matching edge found, in step 124. That is, diff scores the objects by examining the connectivity of the objects. A matching edge is an edge in which both the source and destination objects are elements of matching object pairs according to step 122. According to one embodiment of the matching heuristic, the weight given to objects attached to a matching edge is relatively large.</p>
    <p>After scoring the match matrix elements, diff resolves the match matrix where possible. Resolving the match matrix includes recursively traversing the rows of the match matrix, i.e., the objects of the first graphical program, and selecting the element in a given row with the highest score and then setting the score of the other elements in the given row to zero. Thereby, a 1:1 correspondence is produced between the objects in the first and second graphical programs based on the match scores. That is, every object in the first graphical program can contain at most one match with an object in the second graphical program, or alternatively, a row can contain at most one matching column.</p>
    <p>A row with all zeroes indicates that the object of the first graphical program corresponding to the row has no matching object in the second graphical program. That is, for some objects a 1:0 correspondence is produced between the objects in the first and second graphical programs based on the match scores. The same process is performed for the columns of the match matrix, i.e., for the second graphical program. At this step in the matching process, if two scores in a given row (or column) are equal, diff does not resolve the row (or column). Instead, the row scores are left intact in hopes that they will be resolved according to a different criteria in a subsequent step. That is, diff does not perform any tie breaks at this point in the matching process.</p>
    <p>Next, diff scores unmatched objects according to object type only, in step 126. That is, diff assigns scores to objects which have the same object type. However, in this step 126 the requirement that objects match without conflict is not imposed as in step 122. Preferably, according to step 126, object pairs are assigned a score which is relatively smaller than the score assigned for matches according to step 122 or step 124. That is, the weight attributed to a match based on connectivity and/or non-conflicting object type matches is greater than the weight attributed to a match based solely on object type. After scoring unmatched objects according to object type, diff resolves the match matrix without using tie breaks, in step 126.</p>
    <p>Next, diff scores remaining conflicts, i.e., objects which match according to type but which still have conflicts after resolving the matrix according to step 126, by examining immediately neighboring objects of the graph, in step 128. That is, the match score is updated by inspecting each terminal of the objects for matching upstream objects, matching downstream objects, and matching non-connections, i.e., terminals with no signals connected. After scoring remaining conflicts by examining immediate neighbors, diff resolves the match matrix without using tie breaks, in step 128.</p>
    <p>Next, diff scores remaining conflicts by object attributes, in step 130. That is, diff invokes a compare engine to compare various attributes of the objects to determines similarities between the objects. The compare engine includes a compare method which has knowledge of each object type in order to distinctly compare the attributes of the objects according to their object types. The compare engine calculates and returns a score indicating the degree of matching or similarity between the two objects being compared. The attributes are grouped, according to the matching heuristic, into functional attributes and cosmetic attributes. Examples of functional object attributes are terminal data types and constant data values. Examples of cosmetic attributes are the position, size, color, visibility, name, etc. of objects. A functional attribute is one which may potentially affect the execution of the graphical program. Cosmetic attributes are attributes which do not affect execution of the graphical program. If the same set of inputs to a graphical program produce the same set of outputs even though an attribute has been changed, that attribute is a cosmetic attribute rather than a functional attribute. Preferably, functional attributes have greater weight than cosmetic attributes. Furthermore, match scores based on examination of attributes have less weight than matches based on connectivity or matches by object type without conflicts. After scoring by object attributes, diff resolves the match matrix without using tie breaks, in step 130.</p>
    <p>Next, diff scores remaining conflicts by object position and size, in step 132. That is, diff compares the position and size of the objects to determines similarities between the objects. The more similar the position and/or size of two objects the greater the match score assigned to them. After scoring by object position and size, diff resolves the match matrix using tie breaks, in step 132. That is, in step 132 diff resolves all conflicts. Preferably, tie breaks in match scores are resolved on a "first-come-first serve" basis, i.e., as the match matrix is traversed, the first score encountered among equal scores wins the tie.</p>
    <p>FIG. 10--Determining Differences in Block Diagrams Flowchart</p>
    <p>Referring now to FIG. 10, a flowchart illustrating in more detail step 106 of determining differences between the block diagrams of two graphical programs is shown. In step 140, diff groups exact matching objects into a list of exact matching subgraphs using the match information of the match matrix created according to step 104 and employing the compare engine. In an exact match the two objects: 1) have the same object type and their attributes compare exactly according to the compare engine; and, 2) have connectivity matches. The compare engine includes a compare method which has knowledge of each object type in order to distinctly compare the attributes of the objects according to their object types. The compare engine returns a predetermined value if the two objects being compared compare exactly. In a connectivity match all connections, or edges, of the objects match. That is, all objects to which the prospective exact matching objects are connected are also matching objects. The exact matching subgraphs comprise exact matching objects which are connected together. The exact matching subgraphs are also referred to as exact matching connected components.</p>
    <p>Diff simultaneously traverses both graphs representing the block diagrams to produce the list of exact matching subgraphs. While traversing the graphs to find exact matching subgraphs, each edge belonging to a matched object is marked in the flags field of the corresponding element in the adjacency matrix data structure to denote that the edge belongs to a matched object. Matching objects which have all of their edges marked in the corresponding adjacency matrix element in both graphs are marked in the flags field of the object list (shown in FIG. 6) element corresponding to the matching object.</p>
    <p>Next, diff groups the remaining objects, i.e., the objects which were not grouped into the exact matching subgraphs, into a list of non-exact matching subgraphs, one for each block diagram, using the match matrix and list of exact matching subgraphs, in step 142. These two lists of non-exact matching subgraphs are then matched together in a match matrix, in step 144. This match matrix is a different match matrix from the one produced in step 104, and will be referred to herein as the subgraph match matrix. The subgraph match matrix is similar to the match matrix shown in FIG. 9 except that the rows correspond to the subgraphs in the list of non-exact matching subgraphs of the first block diagram and the columns correspond to the subgraphs in the list of non-exact matching subgraphs of the second block diagram. The scores of the subgraph match matrix indicate a degree of matching or similarity between a subgraph in the first block diagram and a subgraph in the second block diagram. Objects in the non-exact matching subgraphs which match according to the match matrix of step 104, are referred to as anchor nodes. The anchor nodes are used to calculate the match scores in the subgraph match matrix.</p>
    <p>Using the matching information in the subgraph match matrix, diff merges the two lists of non-exact matching subgraphs into a composite non-exact matching subgraph, in step 146. The merging is performed such that transitive connections, i.e., non-direct connections, are taken into account when creating the composite non-exact matching subgraph. The non-exact matching subgraphs are then stored in a results data structure in step 148 so that the non-exact matching subgraph differences may be subsequently displayed to the user in step 112. Remaining non-exact matching subgraphs are paired with empty graphs and are considered as new subgraphs that have been added to or removed from the second block diagram. The remaining non-exact matching subgraphs paired with empty graphs are also stored in the results data structure so that they may be subsequently displayed to the user in step 112.</p>
    <p>Once the exact matching and non-exact matching subgraphs have been created, diff compares matching objects in the non-exact matching subgraphs to determine additional differences in the objects of the non-exact matching subgraphs, in step 150. The additional differences are stored in the results data structure, in step 152. The compare engine is employed to compare the matching objects. The compare engine includes a compare method which has knowledge of each object type in order to distinctly compare each attribute of the object. The compare engine produces a textual description of the differences between two objects. This textual description is displayed for the user in step 112, as described above.</p>
    <p>The differences found by the compare engine may be functional differences or cosmetic differences. A functional difference is one which may potentially affect the execution of the graphical program. Cosmetic differences are differences which do not affect execution of the graphical program. If the same set of inputs to a graphical program produce the same set of outputs even though a change has been made, that difference is a cosmetic difference rather than a functional difference.</p>
    <p>FIG. 11--Determining Differences in User Interface Panels Flowchart</p>
    <p>Referring now to FIG. 11, a flowchart illustrating in more detail step 108 of determining differences between the user interface panels of the two graphical programs is shown. In one embodiment, user interface panel controls and indicators may include arrays and/or clusters. In one embodiment, an array is a variable-sized collection of data elements of the same type. In one embodiment, a cluster is a fixed-sized collection of data elements of mixed types. The clusters are aggregations and/or child-parent relationships of data elements, similar to a record or structure in high-level programming languages. Clusters may include a hierarchy of objects, which include other clusters, controls, and/or indicators. Thus, a cluster may include top-level objects and low-level objects in the hierarchy of objects. As described above, in step 102, diff creates a graph for each user interface panel wherein the objects of the user interface panel are the vertices or nodes in the graph and the edges of the graph represent the hierarchical relationship between the user interface panel elements, and in particular arrays and clusters.</p>
    <p>As described above, in step 104 a match matrix including matching information is created which is resolved to produce a 1:1 or 1:0 matching relationship between objects of the first and second graphical programs. A resolved match matrix is produced for the block diagrams and a resolved match matrix is produced for the user interface panels according to steps 120 through 132.</p>
    <p>For top-level user interface panel objects which match in the match matrix, diff invokes the compare engine to compare the matching objects in order to determine differences between the top-level objects, in step 160.</p>
    <p>Next, diff provides matching information to the compare engine to compare the low-level objects (e.g., individual cluster elements) of the top-level objects in order to determine differences between the low-level objects of the user interface panels, in step 162.</p>
    <p>Then, diff determines which objects of the user interface panels have no match, in step 164. This occurs when the user has added or deleted an object between the first user interface panel and the second user interface panel. Objects which have no match are identified as those which have a 1:0 relationship in the user interface panel match matrix. The differences found in steps 160 through 164 are stored, in step 166, so that the differences may be displayed in step 112.</p>
    <p>Although the system and method of the present invention has been described in connection with the preferred embodiment, it is not intended to be limited to the specific form set forth herein, but on the contrary, it is intended to cover such alternatives, modifications, and equivalents, as can be reasonably included within the spirit and scope of the invention as defined by the appended claims.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4860204">US4860204</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 5, 1987</td><td class="patent-data-table-td patent-date-value">Aug 22, 1989</td><td class="patent-data-table-td ">Softron, Inc.</td><td class="patent-data-table-td ">Computer based workstation for development of graphic representation of computer programs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4901221">US4901221</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 14, 1986</td><td class="patent-data-table-td patent-date-value">Feb 13, 1990</td><td class="patent-data-table-td ">National Instruments, Inc.</td><td class="patent-data-table-td ">Graphical system for modelling a process and associated method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5005119">US5005119</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 29, 1989</td><td class="patent-data-table-td patent-date-value">Apr 2, 1991</td><td class="patent-data-table-td ">General Electric Company</td><td class="patent-data-table-td ">User interactive control of computer programs and corresponding versions of input/output data flow</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5423027">US5423027</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 27, 1991</td><td class="patent-data-table-td patent-date-value">Jun 6, 1995</td><td class="patent-data-table-td ">Massachusetts Institute Of Technology</td><td class="patent-data-table-td ">Tool for error detection in software using aspect specification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5428788">US5428788</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 4, 1993</td><td class="patent-data-table-td patent-date-value">Jun 27, 1995</td><td class="patent-data-table-td ">Siemens Corporate Research, Inc.</td><td class="patent-data-table-td ">Feature ratio method for computing software similarity</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5440742">US5440742</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 6, 1994</td><td class="patent-data-table-td patent-date-value">Aug 8, 1995</td><td class="patent-data-table-td ">Siemens Corporate Research, Inc.</td><td class="patent-data-table-td ">Two-neighborhood method for computing similarity between two groups of objects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5493682">US5493682</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 26, 1994</td><td class="patent-data-table-td patent-date-value">Feb 20, 1996</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Information processing system for managing message passing between objects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5557730">US5557730</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 6, 1995</td><td class="patent-data-table-td patent-date-value">Sep 17, 1996</td><td class="patent-data-table-td ">Borland International, Inc.</td><td class="patent-data-table-td ">Symbol browsing and filter switches in an object-oriented development system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5619638">US5619638</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 28, 1994</td><td class="patent-data-table-td patent-date-value">Apr 8, 1997</td><td class="patent-data-table-td ">Hewlett-Packard Company</td><td class="patent-data-table-td ">Object based computer system having representation objects for providing interpretative views onto a data object</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5630025">US5630025</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 13, 1994</td><td class="patent-data-table-td patent-date-value">May 13, 1997</td><td class="patent-data-table-td ">Unisys Corporation</td><td class="patent-data-table-td ">Generalized configurator using a declaratively constructed two-level bi-partite graph as a knowledge representation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5659735">US5659735</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 9, 1994</td><td class="patent-data-table-td patent-date-value">Aug 19, 1997</td><td class="patent-data-table-td ">Object Technology Licensing Corp.</td><td class="patent-data-table-td ">Object-oriented system for program version and history database management system for various program components</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5729744">US5729744</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 10, 1996</td><td class="patent-data-table-td patent-date-value">Mar 17, 1998</td><td class="patent-data-table-td ">International Business Machine Corp.</td><td class="patent-data-table-td ">Method and system of enhanced versioning control of objects in a data processing system using change control information which includes reasons for changes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5778378">US5778378</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 30, 1996</td><td class="patent-data-table-td patent-date-value">Jul 7, 1998</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Computer system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5805889">US5805889</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 20, 1995</td><td class="patent-data-table-td patent-date-value">Sep 8, 1998</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">System and method for integrating editing and versioning in data repositories</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Of+Interest"'>Of Interest</a>", Dr. Dobb's Journal, Jun. 1995.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Al Stevens, "<a href='http://scholar.google.com/scholar?q="C+Programming"'>C Programming</a>", Dr. Dobb's Journal, May 1991.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Al Stevens, C Programming , Dr. Dobb s Journal, May 1991.</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Dan Allen, "<a href='http://scholar.google.com/scholar?q="The+Macintosh+Programmer%27s+Workshop"'>The Macintosh Programmer's Workshop</a>", Dr. Dobb's Journal, Sep. 1998.</td></tr><tr><td class="patent-data-table-td ">5</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Dan Allen, The Macintosh Programmer s Workshop , Dr. Dobb s Journal, Sep. 1998.</td></tr><tr><td class="patent-data-table-td ">6</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Edward Allburn, "<a href='http://scholar.google.com/scholar?q="Letters"'>Letters</a>", Dr. Dobb's Journal, May 1991.</td></tr><tr><td class="patent-data-table-td ">7</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Edward Allburn, Letters , Dr. Dobb s Journal, May 1991.</td></tr><tr><td class="patent-data-table-td ">8</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Kishi, N., "<a href='http://scholar.google.com/scholar?q="SimUI%3A+graphical+user+interface+evaluation+using+playback%2C"'>SimUI: graphical user interface evaluation using playback,</a>" Proc., 16th Ann. Int. COMPASAC '92, pp. 121-127, Sep. 25, 1992.</td></tr><tr><td class="patent-data-table-td ">9</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Kishi, N., SimUI: graphical user interface evaluation using playback, Proc., 16th Ann. Int. COMPASAC 92, pp. 121 127, Sep. 25, 1992.</td></tr><tr><td class="patent-data-table-td ">10</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Kris Coppieters, "<a href='http://scholar.google.com/scholar?q="A+Cross-Platform+Binary+Diff"'>A Cross-Platform Binary Diff</a>", Dr. Dobb's Journal, May 1995.</td></tr><tr><td class="patent-data-table-td ">11</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Kris Coppieters, A Cross Platform Binary Diff , Dr. Dobb s Journal, May 1995.</td></tr><tr><td class="patent-data-table-td ">12</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Of Interest , Dr. Dobb s Journal, Jun. 1995.</td></tr><tr><td class="patent-data-table-td ">13</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Tsuda College and Nobuko Kishi, "<a href='http://scholar.google.com/scholar?q="Development+of+a+Tool+for+Comparing+User+Operation+Records+in+X+Window+%28sic%29"'>Development of a Tool for Comparing User Operation Records in X Window (sic)</a>", 53-6 Society of Inform. Proc. Human Interface Research Center Report 44-46, 1994.</td></tr><tr><td class="patent-data-table-td ">14</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Tsuda College and Nobuko Kishi, Development of a Tool for Comparing User Operation Records in X Window (sic) , 53 6 Society of Inform. Proc. Human Interface Research Center Report 44 46, 1994.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6223306">US6223306</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 27, 1998</td><td class="patent-data-table-td patent-date-value">Apr 24, 2001</td><td class="patent-data-table-td ">Hewlett-Packard Company</td><td class="patent-data-table-td ">Method and apparatus for testing X servers</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6243856">US6243856</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 1998</td><td class="patent-data-table-td patent-date-value">Jun 5, 2001</td><td class="patent-data-table-td ">Amazing Media, Inc.</td><td class="patent-data-table-td ">System and method for encoding a scene graph</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6263496">US6263496</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 1998</td><td class="patent-data-table-td patent-date-value">Jul 17, 2001</td><td class="patent-data-table-td ">Amazing Media, Inc.</td><td class="patent-data-table-td ">Self modifying scene graph</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6272650">US6272650</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 3, 1998</td><td class="patent-data-table-td patent-date-value">Aug 7, 2001</td><td class="patent-data-table-td ">Amazing Media, Inc.</td><td class="patent-data-table-td ">System and method for disambiguating scene graph loads</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6278452">US6278452</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 18, 1998</td><td class="patent-data-table-td patent-date-value">Aug 21, 2001</td><td class="patent-data-table-td ">Oracle Corporation</td><td class="patent-data-table-td ">Concise dynamic user interface for comparing hierarchically structured collections of objects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6490696">US6490696</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 15, 1999</td><td class="patent-data-table-td patent-date-value">Dec 3, 2002</td><td class="patent-data-table-td ">Electronics For Imaging, Inc.</td><td class="patent-data-table-td ">System and method for printer output regression testing using display lists</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6826715">US6826715</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 28, 1999</td><td class="patent-data-table-td patent-date-value">Nov 30, 2004</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">Automatic capture and comparison of computer configuration data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6898764">US6898764</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 29, 2002</td><td class="patent-data-table-td patent-date-value">May 24, 2005</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method, system and program product for determining differences between an existing graphical user interface (GUI) mapping file and a current GUI</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7058941">US7058941</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 14, 2000</td><td class="patent-data-table-td patent-date-value">Jun 6, 2006</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Minimum delta generator for program binaries</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7139687">US7139687</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 31, 2001</td><td class="patent-data-table-td patent-date-value">Nov 21, 2006</td><td class="patent-data-table-td ">The Mathworks, Inc.</td><td class="patent-data-table-td ">Adaptive lookup table: a graphical simulation component for recursively updating numeric data stored in table form</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7263531">US7263531</a></td><td class="patent-data-table-td patent-date-value">Jun 7, 2004</td><td class="patent-data-table-td patent-date-value">Aug 28, 2007</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Minimum delta generator for program binaries</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7277836">US7277836</a></td><td class="patent-data-table-td patent-date-value">Dec 6, 2001</td><td class="patent-data-table-td patent-date-value">Oct 2, 2007</td><td class="patent-data-table-td ">Exxonmobil Upstream Research Company</td><td class="patent-data-table-td ">Computer system and method having a facility network architecture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7296184">US7296184</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 28, 2004</td><td class="patent-data-table-td patent-date-value">Nov 13, 2007</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method and system for masking dynamic regions in a user interface to enable testing of user interface consistency</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7296261">US7296261</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 4, 2004</td><td class="patent-data-table-td patent-date-value">Nov 13, 2007</td><td class="patent-data-table-td ">Veritas Operating Corporation</td><td class="patent-data-table-td ">Method for determining the degree to which changed code has been exercised</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7313761">US7313761</a></td><td class="patent-data-table-td patent-date-value">Mar 13, 2001</td><td class="patent-data-table-td patent-date-value">Dec 25, 2007</td><td class="patent-data-table-td ">Cognex Technology And Investment Corporation</td><td class="patent-data-table-td ">Tree-style hierarchical control with graphical depiction of non-hierarchical interrelationships</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7367015">US7367015</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 25, 2004</td><td class="patent-data-table-td patent-date-value">Apr 29, 2008</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Method and system for software program editing in common language runtime environment (CLRE)</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7373613">US7373613</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 10, 2004</td><td class="patent-data-table-td patent-date-value">May 13, 2008</td><td class="patent-data-table-td ">Siemens Ag</td><td class="patent-data-table-td ">Visualization of a comparison result of at least two data structures organized in directory trees</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7420573">US7420573</a></td><td class="patent-data-table-td patent-date-value">Nov 9, 2001</td><td class="patent-data-table-td patent-date-value">Sep 2, 2008</td><td class="patent-data-table-td ">The Mathworks, Inc.</td><td class="patent-data-table-td ">System and method for merging electronic diagrams</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7493595">US7493595</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 19, 2003</td><td class="patent-data-table-td patent-date-value">Feb 17, 2009</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Navy</td><td class="patent-data-table-td ">Multiple-user graphical programming and analysis environment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7500222">US7500222</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 23, 2003</td><td class="patent-data-table-td patent-date-value">Mar 3, 2009</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Tracking and maintaining related and derivative code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7627860">US7627860</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 1, 2002</td><td class="patent-data-table-td patent-date-value">Dec 1, 2009</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Graphically deployment of a program with automatic conversion of program type</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7681190">US7681190</a></td><td class="patent-data-table-td patent-date-value">Mar 15, 2006</td><td class="patent-data-table-td patent-date-value">Mar 16, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Minimum delta generator for program binaries</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7685590">US7685590</a></td><td class="patent-data-table-td patent-date-value">Mar 15, 2006</td><td class="patent-data-table-td patent-date-value">Mar 23, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Minimum delta generator for program binaries</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7703027">US7703027</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 12, 2006</td><td class="patent-data-table-td patent-date-value">Apr 20, 2010</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Merging graphical programs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7742432">US7742432</a></td><td class="patent-data-table-td patent-date-value">Jan 5, 2006</td><td class="patent-data-table-td patent-date-value">Jun 22, 2010</td><td class="patent-data-table-td ">International Busniness Machines Corporation</td><td class="patent-data-table-td ">Topology comparison</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7761270">US7761270</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 6, 2001</td><td class="patent-data-table-td patent-date-value">Jul 20, 2010</td><td class="patent-data-table-td ">Exxonmobil Upstream Research Co.</td><td class="patent-data-table-td ">Computer system and method having a facility management logic architecture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7761794">US7761794</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 22, 2004</td><td class="patent-data-table-td patent-date-value">Jul 20, 2010</td><td class="patent-data-table-td ">Cisco Technology, Inc.</td><td class="patent-data-table-td ">Integrated audit and configuration techniques</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7802236">US7802236</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 9, 2003</td><td class="patent-data-table-td patent-date-value">Sep 21, 2010</td><td class="patent-data-table-td ">The Regents Of The University Of California</td><td class="patent-data-table-td ">Method and apparatus for identifying similar regions of a program&#39;s execution</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7814073">US7814073</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 22, 2003</td><td class="patent-data-table-td patent-date-value">Oct 12, 2010</td><td class="patent-data-table-td ">Jp Morgan Chase Bank</td><td class="patent-data-table-td ">Utility for identifying differences between two Java objects</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7930153">US7930153</a></td><td class="patent-data-table-td patent-date-value">Oct 18, 2006</td><td class="patent-data-table-td patent-date-value">Apr 19, 2011</td><td class="patent-data-table-td ">The Mathworks, Inc.</td><td class="patent-data-table-td ">Adaptive look up table: a graphical simulation component for recursively updating numeric data storage in table form</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7966291">US7966291</a></td><td class="patent-data-table-td patent-date-value">Jun 26, 2007</td><td class="patent-data-table-td patent-date-value">Jun 21, 2011</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Fact-based object merging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7970766">US7970766</a></td><td class="patent-data-table-td patent-date-value">Jul 23, 2007</td><td class="patent-data-table-td patent-date-value">Jun 28, 2011</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Entity type assignment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7987444">US7987444</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td patent-date-value">Jul 26, 2011</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Determining and merging differences between configuration diagrams</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7987445">US7987445</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td patent-date-value">Jul 26, 2011</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Comparing a configuration diagram to an actual system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7991797">US7991797</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 17, 2006</td><td class="patent-data-table-td patent-date-value">Aug 2, 2011</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">ID persistence through normalization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8024164">US8024164</a></td><td class="patent-data-table-td patent-date-value">Aug 20, 2007</td><td class="patent-data-table-td patent-date-value">Sep 20, 2011</td><td class="patent-data-table-td ">The Math Works, Inc.</td><td class="patent-data-table-td ">Adaptive lookup table: a graphical simulation component for recursively updating numeric data storage in table form</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8051148">US8051148</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td patent-date-value">Nov 1, 2011</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Determining differences between configuration diagrams</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8108315">US8108315</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 19, 2006</td><td class="patent-data-table-td patent-date-value">Jan 31, 2012</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">Discovering software code subject to licenses</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8122026">US8122026</a></td><td class="patent-data-table-td patent-date-value">Oct 20, 2006</td><td class="patent-data-table-td patent-date-value">Feb 21, 2012</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Finding and disambiguating references to entities on web pages</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8151218">US8151218</a></td><td class="patent-data-table-td patent-date-value">Jul 29, 2009</td><td class="patent-data-table-td patent-date-value">Apr 3, 2012</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Evaluation of graphical program nodes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8151244">US8151244</a></td><td class="patent-data-table-td patent-date-value">Jul 27, 2007</td><td class="patent-data-table-td patent-date-value">Apr 3, 2012</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Merging graphical programs based on an ancestor graphical program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8156147">US8156147</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 25, 2008</td><td class="patent-data-table-td patent-date-value">Apr 10, 2012</td><td class="patent-data-table-td ">The Mathworks, Inc.</td><td class="patent-data-table-td ">Sharing of instructions across model boundaries</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8161469">US8161469</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 13, 2005</td><td class="patent-data-table-td patent-date-value">Apr 17, 2012</td><td class="patent-data-table-td ">Altera Corporation</td><td class="patent-data-table-td ">Method and apparatus for comparing programmable logic device configurations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8239350">US8239350</a></td><td class="patent-data-table-td patent-date-value">May 8, 2007</td><td class="patent-data-table-td patent-date-value">Aug 7, 2012</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Date ambiguity resolution</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8244689">US8244689</a></td><td class="patent-data-table-td patent-date-value">Feb 17, 2006</td><td class="patent-data-table-td patent-date-value">Aug 14, 2012</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Attribute entropy as a signal in object normalization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8260785">US8260785</a></td><td class="patent-data-table-td patent-date-value">Feb 17, 2006</td><td class="patent-data-table-td patent-date-value">Sep 4, 2012</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Automatic object reference identification and linking in a browseable fact repository</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8291329">US8291329</a></td><td class="patent-data-table-td patent-date-value">Mar 26, 2010</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Automatically merging graphical programs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8347202">US8347202</a></td><td class="patent-data-table-td patent-date-value">Mar 14, 2007</td><td class="patent-data-table-td patent-date-value">Jan 1, 2013</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Determining geographic locations for place names in a fact repository</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8438558">US8438558</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 2009</td><td class="patent-data-table-td patent-date-value">May 7, 2013</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">System and method of updating programs and data</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8468163">US8468163</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 30, 2007</td><td class="patent-data-table-td patent-date-value">Jun 18, 2013</td><td class="patent-data-table-td ">Oracle International Corporation</td><td class="patent-data-table-td ">Ontology system providing enhanced search capability with ranking of results</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8578332">US8578332</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 30, 2007</td><td class="patent-data-table-td patent-date-value">Nov 5, 2013</td><td class="patent-data-table-td ">Mark Murray</td><td class="patent-data-table-td ">Universal microcode image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8583659">US8583659</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 9, 2012</td><td class="patent-data-table-td patent-date-value">Nov 12, 2013</td><td class="patent-data-table-td ">Facebook, Inc.</td><td class="patent-data-table-td ">Labeling samples in a similarity graph</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8584088">US8584088</a></td><td class="patent-data-table-td patent-date-value">Nov 5, 2009</td><td class="patent-data-table-td patent-date-value">Nov 12, 2013</td><td class="patent-data-table-td ">The Mathworks, Inc.</td><td class="patent-data-table-td ">Identification of patterns in modeling environments</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8595201">US8595201</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 2011</td><td class="patent-data-table-td patent-date-value">Nov 26, 2013</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Version visualization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8612490">US8612490</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 6, 2012</td><td class="patent-data-table-td patent-date-value">Dec 17, 2013</td><td class="patent-data-table-td ">The Mathworks, Inc.</td><td class="patent-data-table-td ">Sharing of instructions across model boundaries</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8650175">US8650175</a></td><td class="patent-data-table-td patent-date-value">Jul 13, 2012</td><td class="patent-data-table-td patent-date-value">Feb 11, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">User interface for facts query engine with snippets from information sources that include query terms and answer terms</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8682891">US8682891</a></td><td class="patent-data-table-td patent-date-value">Sep 4, 2012</td><td class="patent-data-table-td patent-date-value">Mar 25, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Automatic object reference identification and linking in a browseable fact repository</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8682913">US8682913</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 2005</td><td class="patent-data-table-td patent-date-value">Mar 25, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Corroborating facts extracted from multiple sources</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8700568">US8700568</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 2006</td><td class="patent-data-table-td patent-date-value">Apr 15, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Entity normalization via name normalization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8726232">US8726232</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 2, 2005</td><td class="patent-data-table-td patent-date-value">May 13, 2014</td><td class="patent-data-table-td ">The Math Works, Inc.</td><td class="patent-data-table-td ">Identification of patterns in modeling environments</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8738643">US8738643</a></td><td class="patent-data-table-td patent-date-value">Aug 2, 2007</td><td class="patent-data-table-td patent-date-value">May 27, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Learning synonymous object names from anchor texts</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8751498">US8751498</a></td><td class="patent-data-table-td patent-date-value">Feb 1, 2012</td><td class="patent-data-table-td patent-date-value">Jun 10, 2014</td><td class="patent-data-table-td ">Google Inc.</td><td class="patent-data-table-td ">Finding and disambiguating references to entities on web pages</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8762958">US8762958</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 9, 2008</td><td class="patent-data-table-td patent-date-value">Jun 24, 2014</td><td class="patent-data-table-td ">Identify Software, Ltd.</td><td class="patent-data-table-td ">System and method for troubleshooting software configuration problems using application tracing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20080270778">US20080270778</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 30, 2007</td><td class="patent-data-table-td patent-date-value">Oct 30, 2008</td><td class="patent-data-table-td ">Mark Murray</td><td class="patent-data-table-td ">Universal microcode image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090049034">US20090049034</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 30, 2007</td><td class="patent-data-table-td patent-date-value">Feb 19, 2009</td><td class="patent-data-table-td ">Oracle International Corporation</td><td class="patent-data-table-td ">Ontology system providing enhanced search capability</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100235816">US20100235816</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 16, 2009</td><td class="patent-data-table-td patent-date-value">Sep 16, 2010</td><td class="patent-data-table-td ">Ibm Corporation</td><td class="patent-data-table-td ">Data-driven testing without data configuration</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110161874">US20110161874</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 29, 2009</td><td class="patent-data-table-td patent-date-value">Jun 30, 2011</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Analyzing objects from a graphical interface for standards verification</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120198331">US20120198331</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 1, 2011</td><td class="patent-data-table-td patent-date-value">Aug 2, 2012</td><td class="patent-data-table-td ">Brian Hartmann</td><td class="patent-data-table-td ">Method for aligning a modified document and an original document for comparison and difference highlighting</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20140006922">US20140006922</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 11, 2008</td><td class="patent-data-table-td patent-date-value">Jan 2, 2014</td><td class="patent-data-table-td ">Alex Smith</td><td class="patent-data-table-td ">Comparison output of electronic documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN101520731B?cl=en">CN101520731B</a></td><td class="patent-data-table-td patent-date-value">Feb 26, 2009</td><td class="patent-data-table-td patent-date-value">Dec 5, 2012</td><td class="patent-data-table-td ">埃森哲环球服务有限公司</td><td class="patent-data-table-td ">图形用户接口应用比较器</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1872206A2?cl=en">EP1872206A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 13, 2006</td><td class="patent-data-table-td patent-date-value">Jan 2, 2008</td><td class="patent-data-table-td ">National Instruments Corporation</td><td class="patent-data-table-td ">Merging graphical programs</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2096536A2?cl=en">EP2096536A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 27, 2009</td><td class="patent-data-table-td patent-date-value">Sep 2, 2009</td><td class="patent-data-table-td ">Accenture Global Services GmbH</td><td class="patent-data-table-td ">Graphical user interface application comparator</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2455855A1?cl=en">EP2455855A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 22, 2010</td><td class="patent-data-table-td patent-date-value">May 23, 2012</td><td class="patent-data-table-td ">Siemens AG</td><td class="patent-data-table-td ">Graphical comparison display of software</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc717/defs717.htm&usg=AFQjCNHuT_DCk9A1B78-Dfs6s108xa-OtQ#C717S109000">717/109</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc717/defs717.htm&usg=AFQjCNHuT_DCk9A1B78-Dfs6s108xa-OtQ#C717S122000">717/122</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc714/defs714.htm&usg=AFQjCNF69HBVWbRkdZeFUtAyhUaqKU35WQ#C714S037000">714/37</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc714/defs714.htm&usg=AFQjCNF69HBVWbRkdZeFUtAyhUaqKU35WQ#C714S038100">714/38.1</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0009440000">G06F9/44</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F8/71">G06F8/71</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=9opMBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F8/34">G06F8/34</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06F8/71</span>, <span class="nested-value">G06F8/34</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jul 10, 2012</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 12, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 7, 2010</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 21, 2010</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1, 21 AND 34-35 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 2-19, 22-28, 32, 36-53, 55-62 AND 66, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. NEW CLAIMS 68-252 ARE ADDED AND DETERMINED TO BE PATENTABLE. CLAIMS 20, 29-31, 33, 54, 63-65 AND 67 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 6, 2007</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20070918</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 7, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 30, 2002</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 3, 2001</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 6, 1997</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">NATIONAL INSTRUMENTS CORPORATION, TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:HSU, RAY;REEL/FRAME:008617/0288</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19970605</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U3Vx8R5btRPJf86LxgwgqdxMAzxGg\u0026id=9opMBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U14ZPQjJa5ZsMUSl6Gy4XTbTXmxzg\u0026id=9opMBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1FSaDN7lIYk9i4pkNThZe9AT3G1w","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_for_detecting_differences_between.pdf?id=9opMBAABERAJ\u0026output=pdf\u0026sig=ACfU3U3f6Js8yLIIZ1XxOAPlocDCKQ4OaA"},"sample_url":"http://www.google.com/patents/reader?id=9opMBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>