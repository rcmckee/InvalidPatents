<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5191525 - System and method for extraction of data from documents for subsequent ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="System and method for extraction of data from documents for subsequent processing"><meta name="DC.contributor" content="Thomas Q. LeBrun" scheme="inventor"><meta name="DC.contributor" content="Kerry Cage" scheme="inventor"><meta name="DC.contributor" content="Dennis D. Arnold" scheme="inventor"><meta name="DC.contributor" content="Digital Image Systems, Corporation" scheme="assignee"><meta name="DC.date" content="1990-1-16" scheme="dateSubmitted"><meta name="DC.description" content="The present invention comprises an image based document processing and information management system and apparatus. It provides a more efficient method and apparatus for handling large volumes of form based business transactions using a digital image-based system for the capture, identification and processing of images, statistics and business data. The system converts documents, such as forms and supporting pages, into digital data which can be used to update computer records and to manage and support the adjudicative processing of business transactions by human operators at computer terminals."><meta name="DC.date" content="1993-3-2" scheme="issued"><meta name="DC.relation" content="US:3460673" scheme="references"><meta name="DC.relation" content="US:3815102" scheme="references"><meta name="DC.relation" content="US:4027142" scheme="references"><meta name="DC.relation" content="US:4205780" scheme="references"><meta name="DC.relation" content="US:4404649" scheme="references"><meta name="DC.relation" content="US:4510619" scheme="references"><meta name="citation_reference" content="&quot;ORBIT Search Service Japio: User Manual&quot;, First Edition, Nov. 1985, TM-8219/000/000, pp. 1-8."><meta name="citation_reference" content="ORBIT Search Service Japio: User Manual , First Edition, Nov. 1985, TM 8219/000/000, pp. 1 8."><meta name="citation_patent_number" content="US:5191525"><meta name="citation_patent_application_number" content="US:07/465,411"><link rel="canonical" href="http://www.google.com/patents/US5191525"/><meta property="og:url" content="http://www.google.com/patents/US5191525"/><meta name="title" content="Patent US5191525 - System and method for extraction of data from documents for subsequent processing"/><meta name="description" content="The present invention comprises an image based document processing and information management system and apparatus. It provides a more efficient method and apparatus for handling large volumes of form based business transactions using a digital image-based system for the capture, identification and processing of images, statistics and business data. The system converts documents, such as forms and supporting pages, into digital data which can be used to update computer records and to manage and support the adjudicative processing of business transactions by human operators at computer terminals."/><meta property="og:title" content="Patent US5191525 - System and method for extraction of data from documents for subsequent processing"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("w5btU7CWNcqqsQT_94DIDA"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("ITA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("w5btU7CWNcqqsQT_94DIDA"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("ITA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5191525?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5191525"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=N4A1BAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5191525&amp;usg=AFQjCNEjwAzRV3pPjay7ZBmHwyQBxq0Z5Q" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5191525.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5191525.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5191525" style="display:none"><span itemprop="description">The present invention comprises an image based document processing and information management system and apparatus. It provides a more efficient method and apparatus for handling large volumes of form based business transactions using a digital image-based system for the capture, identification and processing...</span><span itemprop="url">http://www.google.com/patents/US5191525?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5191525 - System and method for extraction of data from documents for subsequent processing</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5191525 - System and method for extraction of data from documents for subsequent processing" title="Patent US5191525 - System and method for extraction of data from documents for subsequent processing"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5191525 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 07/465,411</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Mar 2, 1993</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jan 16, 1990</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jan 16, 1990</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2071899A1">CA2071899A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0511309A1">EP0511309A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/EP0511309A4">EP0511309A4</a>, </span><span class="patent-bibdata-value"><a href="/patents/US6043819">US6043819</a>, </span><span class="patent-bibdata-value"><a href="/patents/WO1991010969A1">WO1991010969A1</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">07465411, </span><span class="patent-bibdata-value">465411, </span><span class="patent-bibdata-value">US 5191525 A, </span><span class="patent-bibdata-value">US 5191525A, </span><span class="patent-bibdata-value">US-A-5191525, </span><span class="patent-bibdata-value">US5191525 A, </span><span class="patent-bibdata-value">US5191525A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Thomas+Q.+LeBrun%22">Thomas Q. LeBrun</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Kerry+Cage%22">Kerry Cage</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Dennis+D.+Arnold%22">Dennis D. Arnold</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Digital+Image+Systems,+Corporation%22">Digital Image Systems, Corporation</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5191525.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5191525.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5191525.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (6),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (2),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (263),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (37),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (17)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5191525&usg=AFQjCNFBy3x72tyULiFhI9mZUYWeGmKqMg">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5191525&usg=AFQjCNHLHP-541n6SNItFDD7vMU9N9zYWg">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5191525A%26KC%3DA%26FT%3DD&usg=AFQjCNH5SeeZWkE8Qh3j_YY6G1dQskBSmA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT53741493" lang="EN" load-source="patent-office">System and method for extraction of data from documents for subsequent processing</invention-title></span><br><span class="patent-number">US 5191525 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37201865" lang="EN" load-source="patent-office"> <div class="abstract">The present invention comprises an image based document processing and information management system and apparatus. It provides a more efficient method and apparatus for handling large volumes of form based business transactions using a digital image-based system for the capture, identification and processing of images, statistics and business data. The system converts documents, such as forms and supporting pages, into digital data which can be used to update computer records and to manage and support the adjudicative processing of business transactions by human operators at computer terminals.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(10)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-7.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-7.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-8.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-8.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-9.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-9.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5191525-10.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5191525-10.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(92)</span></span></div><div class="patent-text"><div mxw-id="PCLM4605672" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A method of electronically processing data from one or more documents to facilitate user interaction with the data, comprising:<div class="claim-text">a) generating a plurality of first output signals representing electronic images of said documents, said output signals being generated by feeding a series of documents associated together as a transaction sequentially through an optical scanning device whereby transaction integrity is maintained;</div> <div class="claim-text">b) generating an electric signal at the beginning and end of the transaction for separating the images of one transaction from those of another;</div> <div class="claim-text">c) identifying at least one of the documents by reference to identification areas or identification words found on the documents, the identification occurring by reference to geographical location or pel pattern techniques;</div> <div class="claim-text">d) extracting data fields from at least one of the documents by generating a plurality of second output signals representing said data fields;</div> <div class="claim-text">e) storing said first and second output signals for subsequent processing; and</div> <div class="claim-text">f) managing the processing of transactions to support adjudication processes and customer inquiries.</div> </div>
    </div>
    </div> <div class="claim"> <div num="2" class="claim">
      <div class="claim-text">2. A method of electronically processing data to facilitate user interaction with the data, comprising:<div class="claim-text">(a) feeding documents through an optical scanning device;</div> <div class="claim-text">(b) recording electronic images of documents;</div> <div class="claim-text">(c) identifying document formats and transaction boundaries using identification areas or identification words;</div> <div class="claim-text">(d) extracting data fields from identified document images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(e) recording electronic data; and</div> <div class="claim-text">(f) transmitting recorded images and data to digital storage for subsequent processing.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The method of claim 2 further comprising the identification of document formats by automatic recognition techniques.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The method of claim 2 further comprising the identification of document formats by pel pattern techniques.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The method of claim 2 further comprising feeding documents of varying size through said optical scanning device.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The method of claim 2 further comprising feeding intermixed documents of varying format through said optical scanning device.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The method of claim 2 further comprising feeding documents through said optical scanning device in either a properly justified or inverted orientation.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The method of claim 2 further comprising the step of printing item sequence numbers upon said documents as said documents pass through said optical scanning device.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The method of claim 2 further comprising the step of correcting for document skew resulting from document misalignment during scanning.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The method of claim 2 further comprising extracting data fields from document images using a predictor field to determine whether machine printed or pen printed data resides in the data field.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The method of claim 2 further comprising the step of circulating data in a logical error reduction sequence to reduce keying errors.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The method of claim 2 further comprising the recording of statistical summaries of data key operator errors for evaluation of operator performance.</div>
    </div>
    </div> <div class="claim"> <div num="13" class="claim">
      <div class="claim-text">13. A method of electronically processing data from documents to electronic images to facilitate user interaction with the data, comprising:<div class="claim-text">(a) feeding documents through an optical scanning device, said documents proceeding through said optical scanning device in either a properly justified or inverted orientation, said documents being of varying size and different formats;</div> <div class="claim-text">(b) printing item sequence numbers upon said documents as said documents pass through said optical scanning device;</div> <div class="claim-text">(c) recording electronic images of documents;</div> <div class="claim-text">(d) identifying document formats using identification areas or identification words, the identification of document formats occurring by reference to geographic location;</div> <div class="claim-text">(e) extracting data fields from identified document images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(f) correcting for document skew resulting from document misalignment during scanning,</div> <div class="claim-text">(g) recording electronic data; and</div> <div class="claim-text">(h) transmitting recorded images and data to digital storage for subsequent processing.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The method of claim 13 further comprising extracting data fields from document images using a predictor field to determine whether machine or pen printed data resides in the data field.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="15" class="claim">
      <div class="claim-text">15. The method of claim 13 further comprising the step of circulating data in a logical error reduction sequence to reduce keying errors.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The method of claim 13 further comprising the recording of statistical summaries of data key operator errors for evaluation of operator performance.</div>
    </div>
    </div> <div class="claim"> <div num="17" class="claim">
      <div class="claim-text">17. An optical disc-based transaction processing system for performing business transactions by user interaction with electronically stored data comprising:<div class="claim-text">(a) a local area network for managing interaction of separate components of said transaction processing system;</div> <div class="claim-text">(b) an image acquisition subsystem operatively connected to said local area network, said image acquisition subsystem providing digital image data input to said local area network, said image acquisition subsystem coordinating the capture and transfer of electronic images;</div> <div class="claim-text">(c) a capture management subsystem operatively connected to said local area network, said capture management subsystem functioning to carve data fields from digital document images;</div> <div class="claim-text">(d) an application subsystem operatively connected to said local area network, said security and control subsystem operating to direct transaction processing events in sequence;</div> <div class="claim-text">(e) application support workstation for user interaction with said local area network; and</div> <div class="claim-text">(f) a storage management subsystem for storing electronic digital data, said stored data being available for user interaction.</div> </div>
    </div>
    </div> <div class="claim"> <div num="18" class="claim">
      <div class="claim-text">18. A system for optically capturing, storing, and retrieving data used electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning intermixed documents of various size and different formats;</div> <div class="claim-text">(b) means to separate checks from other pages;</div> <div class="claim-text">(c) means for recording electronic images of documents to facilitate document identification using identification areas or identification words, said means for identification of document formats occurring by automatic recognition techniques;</div> <div class="claim-text">(d) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction to record electronic data;</div> <div class="claim-text">(e) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(f) means for transmitting said recorded electronic data to a host computer;</div> <div class="claim-text">(g) means for selectively retrieving data as necessary in performing business transactions; and</div> <div class="claim-text">(h) means for indexing and cross-referencing stored data and electronic images.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The apparatus of claim 18 wherein the means for optically scanning documents includes means for feeding documents through said optical scanning means in either properly justified or inverted orientation.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The apparatus of claim 18 wherein the means for optically scanning documents further includes means for printing item sequence numbers upon said documents as said documents pass through said optical scanning means.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. The apparatus of claim 18 wherein the means for optically scanning documents further includes means for correcting document skew resulting from document misalignment during scanning.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22. The apparatus of claim 18 wherein the means from extracting data fields further includes means for circulating or re-routing data in a logical error reduction sequence to reduce keying errors.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. The apparatus of claim 18 wherein the means for optically scanning documents includes a wand and related switch mechanism associated with the document feeder to permit the definition of a transaction boundary.</div>
    </div>
    </div> <div class="claim"> <div num="24" class="claim">
      <div class="claim-text">24. A combination for optically capturing, storing and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning intermixed documents of various size and different formats to maintain transaction integrity in the processing of business transactions;</div> <div class="claim-text">(b) means to separate checks from other pages;</div> <div class="claim-text">(c) means for printing item sequence numbers upon said documents at or near the time when said documents pass through said optical scanning device;</div> <div class="claim-text">(d) recording electronic images of documents;</div> <div class="claim-text">(e) identifying document formats using identification areas or identification words, the identification of document formats occurring by automatic recognition techniques;</div> <div class="claim-text">(f) extracting data fields from identified document images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(g) correcting for document skew resulting from document misalignment during scanning;</div> <div class="claim-text">(h) recording electronic data; and</div> <div class="claim-text">(i) transmitting recorded images and data to digital storage for subsequent processing.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25. The combination of claim 24, where there is further included means for sensing the edge of a document, said means for sensing being connected to said means for printing item sequence numbers for causing said means for printing to print the sequence number in the margin of the documents.</div>
    </div>
    </div> <div class="claim"> <div num="26" class="claim">
      <div class="claim-text">26. A method of converting graphics to character data, comprising the steps of:<div class="claim-text">producing a graphics image of a document;</div> <div class="claim-text">identifying the graphics image by comparing portions of the image against a series of identifiers for a match;</div> <div class="claim-text">extracting at least one graphical data area from a selected portion of the graphics image a vector distance from the matched portion;</div> <div class="claim-text">converting the graphical data area to a character string by processing individual graphical portions of the data area and converting each portion to a character positioned in the string at a location associated with the location of the graphical portion from which it is derived;</div> <div class="claim-text">displaying the graphical data area along with the character string; and</div> <div class="claim-text">displaying an unconverted portion of the graphical data area as a universal character intermixed in the character string and located within the character string at a position associated with its location in the graphical data area.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27. The method of claim 26 wherein there is further included the step of keying in a character representative of the unconverted portion of the graphical data and positioning the character within the character string at a position associated with the location of the universal character to replace the universal character.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" class="claim">
      <div class="claim-text">28. The method of claim 27, wherein there is further included the step of displaying the character string with the keyed character in place of the character string and the intermixed universal character.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" class="claim">
      <div class="claim-text">29. The method of claim 26, wherein the step of converting each portion of the graphical data area leaves the original graphics image unaltered.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="30" class="claim">
      <div class="claim-text">30. The method of claim 26, wherein each character is an ASCII character.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="31" class="claim">
      <div class="claim-text">31. The method of claim 26, wherein the universal character is an asterisk.</div>
    </div>
    </div> <div class="claim"> <div num="32" class="claim">
      <div class="claim-text">32. A combination, comprising:<div class="claim-text">means for sequentially scanning a series of documents associated together as a transaction and producing a sequential series of graphical images of the documents, said means for scanning and producing for supplying a graphical image of each document;</div> <div class="claim-text">means for generating a signal to identify the end of the transaction; and</div> <div class="claim-text">means for producing a unique data key responsive to the reception of the signal for locating each sequential series of graphical images representing a transaction.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="33" class="claim">
      <div class="claim-text">33. The combination of claim 32, wherein said means for generating a signal is a wand located between each series of documents.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="34" class="claim">
      <div class="claim-text">34. The combination of claim 32, wherein said means for generating a signal is a unique document placed first in the series of documents associated as a transaction.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="35" class="claim">
      <div class="claim-text">35. The combination of claim 34, wherein said combination includes means for identifying an identification area in the graphical image of the unique document.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="36" class="claim">
      <div class="claim-text">36. The combination of claim 35, wherein said means for identifying, generating a signal to signify that the preceding document was the end of the transaction.</div>
    </div>
    </div> <div class="claim"> <div num="37" class="claim">
      <div class="claim-text">37. A method of improving the efficiency of entry of data from pages included in a plurality of transactions into a data processing system, the paper having intermixed document types, the method wherein a transaction comprises one or more pages reducing the amount of labor involved with handing of the documents, the method comprising steps of:<div class="claim-text">acquiring on a transaction by transaction basis an electronic image of a page in each transaction without pre-sorting pages according to page type; and</div> <div class="claim-text">automatically comparing with a computer each electronic image to predefined document types for identifying the page type for facilitating subsequent data extraction form the image of the page.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="38" class="claim">
      <div class="claim-text">38. The method of claim 37 further comprising the step of maintaining automatically a connection between an image of a page and the transaction of which it is apart.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="39" class="claim">
      <div class="claim-text">39. The method of claim 38 further comprising the steps of storing the electronic images and retrieving the electronic images during an image-based work flow management process.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="40" class="claim">
      <div class="claim-text">40. The method of claim 37 further comprising the step of deskewing an acquired electronic image to facilitate the step of automatically comparing.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="41" class="claim">
      <div class="claim-text">41. The method of claim 37 further comprising the step of extracting automatically data from the images based on identification of its page type.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="42" class="claim">
      <div class="claim-text">42. The method of claim 41 further comprising the step of electronically sorting identified electronic images according to type.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="43" class="claim">
      <div class="claim-text">43. The method of claim 41 wherein the step of extracting includes the step of extracting from at least a portion of an electronic image data using an automatic character recognition process.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="44" class="claim">
      <div class="claim-text">44. The method of claim 41 wherein the step of extracting includes the step manual key entry of data from the image.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="45" class="claim">
      <div class="claim-text">45. The method of claim 37 wherein the step of acquiring includes the step of receiving with a facsimile receiving device images of documents related to a single transaction having data to be extracted.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="46" class="claim">
      <div class="claim-text">46. The method of claim 37 wherein the step of acquiring includes the step of transporting across a scanner paper documents that have intermixed formats one transaction at a time.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="47" class="claim">
      <div class="claim-text">47. The method of claim 46 wherein the step of comparing includes the steps of identifying a preselected page type during the step of capturing, the pages so identified being diverted during transport into a pocket for special processing.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="48" class="claim">
      <div class="claim-text">48. The method of claim 37 wherein the step of comparing of the electronic image for identification of document type includes comparing the size of each electronic image for identification.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="49" class="claim">
      <div class="claim-text">49. The method of claim 37 wherein the step of comparing includes the step of identifying the page type by automated recognition of a preselected identifying reference area on the document.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="50" class="claim">
      <div class="claim-text">50. The method of claim 37 wherein the step of comparing includes the step of identifying the page type using a Pel pattern technique.</div>
    </div>
    </div> <div class="claim"> <div num="51" class="claim">
      <div class="claim-text">51. A method of data extraction from images of pages having multiple numbers of different types of data fields comprising the steps of:<div class="claim-text">identifying an electronic image of a page as having a known format;</div> <div class="claim-text">electronically carving form the electronic image a portion thereof based on the identified known format of the page, the image portion being a graphical representation of a data field on the document from which data is to be extracted; and</div> <div class="claim-text">distributing electronically the carved image portion to means for extracting data from the graphical representation of the data field.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="52" class="claim">
      <div class="claim-text">52. The method of claim 51 wherein the means for extracting includes an automated character reader for reading data from the image portion.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="53" class="claim">
      <div class="claim-text">53. The method of claim 52 wherein the step of distributing the carved portions includes the step of distributing carved image portions having characters in the graphical data field not capable of being read by the automated character reader to a operator correction means for display to and correction by an operator.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="54" class="claim">
      <div class="claim-text">54. The method of claim 51 wherein the means for extracting includes operator key entry means.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="55" class="claim">
      <div class="claim-text">55. The method of claim 51 wherein:<div class="claim-text">the step of electronically carving includes carving from a plurality of electronic images of pages portions thereof, each portion including a graphical representation of a data field from which data is to be extracted;</div> <div class="claim-text">the step of distributing includes distributing each of the plurality of carved image portions to one of a plurality of means for extracting data.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="56" class="claim">
      <div class="claim-text">56. The method of claim 55 wherein the step of distributing includes distributing each of a plurality of carved image portions to one of a plurality of means for extracting data based on the graphical data field's type.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="57" class="claim">
      <div class="claim-text">57. The method of claim 51 wherein the step of carving includes the step of carving from an electronic image of a document multiple portions thereof, each portion containing graphical representation of a data field from which data is to be extracted.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="58" class="claim">
      <div class="claim-text">58. The method of claim 57 wherein the step of distributing includes the step of distributing image portions to a plurality of means for extracting data depending on the graphical data field's type.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="59" class="claim">
      <div class="claim-text">59. The method of claim 57 wherein the means for extracting includes an automated reader adapted for reading a particular type of graphical data field, and wherein the step of distributing includes the step of distributing graphical data fields of the particular type to the automated reader.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="60" class="claim">
      <div class="claim-text">60. The method of claim 59 wherein the means for extracting further includes an operator entry device for extracting data from an electronic image that is not readable by the automated character reader.</div>
    </div>
    </div> <div class="claim"> <div num="61" class="claim">
      <div class="claim-text">61. A method of automated entry of data relating to a transaction into a data processing system from pages having intermixed page types while maintaining transaction integrity and reducing the amount of labor involved with handing of the documents, the method comprising the steps of:<div class="claim-text">capturing electronic images of pages having intermixed page types on a transaction by transaction basis;</div> <div class="claim-text">identifying automatically with a computer a page type of at least one of the electronic images of the pages;</div> <div class="claim-text">carving a portion of the identified electronic image containing a graphical data field based on a known format of the page type; and</div> <div class="claim-text">distributing carved image portion to means for reading data from the graphical data field.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="62" class="claim">
      <div class="claim-text">62. The method of claim 61 wherein the step of distributing includes distributing an image portion to automated character recognition means and to manual entry means depending on the graphical data field being distributed.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="63" class="claim">
      <div class="claim-text">63. The method of claim 61 further including the step of distributing an identified electronic image of a page to means for reading data from the electronic image of the entire page.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="64" class="claim">
      <div class="claim-text">64. The method of claim 61 wherein the means for reading includes an automated character recognition means and wherein the method further includes the step of distributing a graphical data field containing at least one character not readable by the automated character recognition means to means for correcting data.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="65" class="claim">
      <div class="claim-text">65. The method of claim 61 wherein the means for reading includes an automated character recognition means and wherein the method further includes the step of distributing a portion of graphical data field containing at least one character nor readable by the automated character recognition means to means for manually correcting the at least one character, the means for manually correcting displaying a plurality of unrelated image portions in a manner to facilitate a rate of entry of unreadable characters.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="66" class="claim">
      <div class="claim-text">66. The method of claim 65 further including the steps of storing the images and of performing image based work flow processing using the stored images.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="67" class="claim">
      <div class="claim-text">67. The method of claim 61 further including a step of collecting data read from each page in each transaction for storage in data storage.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="68" class="claim">
      <div class="claim-text">68. The method of claim 67 wherein the means for reading includes a plurality of readers; and wherein the step of distributing includes distributing each of a plurality of graphical data fields to means for reading without regard for the page from which the graphical data fields.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="69" class="claim">
      <div class="claim-text">69. The method of claim 67 further including the step performing work flow processing using the collected read data that is retrieved from data storage.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="70" class="claim">
      <div class="claim-text">70. The method of claim 61 wherein:<div class="claim-text">the step of carving includes a step of carving graphical data fields of certain of the electronic images based on predefined formats associated with the page type that locate fields within the image from which data is desired to be extracted; and</div> <div class="claim-text">the step of distributing includes a step of distributing each carved graphical data fields to one of a plurality of readers based on a field type.</div> </div>
    </div>
    </div> <div class="claim"> <div num="71" class="claim">
      <div class="claim-text">71. A method of manually correcting unreadable characters from an automated character recognition device comprising the steps of:<div class="claim-text">concurrently displaying a plurality of image portions from at least one electronic page image, each portion having at least one graphical character that cannot be read by the automated character recognition process and that is presented in a predetermined relationship to the other portions, the display and relationship of the plurality of image portions tending to make more efficient the rate of correction of unreadable characters with a manual key entry means; and</div> <div class="claim-text">providing operator entry means associated with the electronic display for entering characters that are not readable.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="72" class="claim">
      <div class="claim-text">72. The method of claim 71 wherein the concurrently displayed image portions are from a plurality of electronic page images.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="73" class="claim">
      <div class="claim-text">73. The method of claim 71 further comprising the step of displaying on the display near the image portions any data characters read by the automated character recognition process within the displayed image portion with an indication of any characters in the image portion that were not read.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="74" class="claim">
      <div class="claim-text">74. The method of claim 71 further comprising the steps of carving from an electronic page image of a document page portion having a graphical data field containing data to be extracted and presenting the carved graphical data field to an automated character recognition process as a portion of the electronic page image to be read; and displaying on the manual entry means a predetermined portions of the graphical data field, at least one of which is not readable by the automated character recognition process.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="75" class="claim">
      <div class="claim-text">75. The method of claim 71 further comprising a steps of:<div class="claim-text">carving from an electronic page image a graphical data field containing data to be extracted;</div> <div class="claim-text">distributing the graphical data field to an automated character recognition process and reading the graphical data field; and</div> <div class="claim-text">displaying the entire graphical data field for correction with the manual key entry means by keying in the entire data field if at least one of the characters in the graphical data field is not readably the automated character recognition process.</div> </div>
    </div>
    </div> <div class="claim"> <div num="76" class="claim">
      <div class="claim-text">76. An image capture and data extraction system comprising:<div class="claim-text">an image acquisition system for electronically capturing page images of intermixed types on a transaction by transaction basis while maintaining transaction integrity;</div> <div class="claim-text">data processing system for identifying a page image as having a known format, carving from an identified page image a portion of the image containing a data field based on its identified format, extracting character data from the carved image of the data field, and assembling extracted data into a data record for the transaction for storage.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="77" class="claim">
      <div class="claim-text">77. The image capture and data extraction system of claim 76 wherein the data processing system includes a plurality of computers linked together in a network and includes a capture management subsystem for extracting data from electronic images, storage management subsystem for storing electronic images and an application management subsystem for controlling the flow of electronic images and data between the image acquisition system, the capture management subsystem and the storage management subsystem.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="78" class="claim">
      <div class="claim-text">78. The image capture and data extraction system of claim 77 wherein the data processing system further includes data correction and entry work stations.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="79" class="claim">
      <div class="claim-text">79. The image capture and data extraction system of claim 77 further including at least one image-based work flow management work station coupled to the storage management subsystem, the image-based work flow management work station retrieving from the storage management subsystem data and images.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="80" class="claim">
      <div class="claim-text">80. The image capture and data extraction system of claim 76 further comprising an image-based work flow management system operating on the stored data record.</div>
    </div>
    </div> <div class="claim"> <div num="81" class="claim">
      <div class="claim-text">81. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer; and</div> <div class="claim-text">(f) mean for selectively retrieving data as necessary in performing business transactions;<div class="claim-text">wherein the means for optically scanning documents includes means to separate checks from other pages.</div> </div> </div>
    </div>
    </div> <div class="claim"> <div num="82" class="claim">
      <div class="claim-text">82. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer;</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions; and</div> <div class="claim-text">(g) means for indexing and cross-referencing stored data and electronic images.</div> </div>
    </div>
    </div> <div class="claim"> <div num="83" class="claim">
      <div class="claim-text">83. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer; and</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions;<div class="claim-text">wherein the means for recording electronic images of documents includes means for identifying document formats by pel pattern techniques.</div> </div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="84" class="claim">
      <div class="claim-text">84. The apparatus of claim 83 further including a scanner sensor means to detect document edge alignment while printing item sequence numbers.</div>
    </div>
    </div> <div class="claim"> <div num="85" class="claim">
      <div class="claim-text">85. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer; and</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions;<div class="claim-text">wherein the means for optically scanning documents further includes means for printing item sequence members upon said documents as said documents pass through said optical scanning means to permit a contiguous document filling and retrieval system.</div> </div> </div>
    </div>
    </div> <div class="claim"> <div num="86" class="claim">
      <div class="claim-text">86. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a hostcomputer; and</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions;<div class="claim-text">wherein the means for optically scanning documents includes means for correcting document skew resulting from document misalignment during scanning.</div> </div> </div>
    </div>
    </div> <div class="claim"> <div num="87" class="claim">
      <div class="claim-text">87. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer; and</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions;<div class="claim-text">wherein the means for extracting data fields further includes means for producing whether machine printed or pen printed data resides in said data field.</div> </div> </div>
    </div>
    </div> <div class="claim"> <div num="88" class="claim">
      <div class="claim-text">88. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer; and</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions;<div class="claim-text">wherein the means for extracting data fields further includes means for circulating or re-routing data in a logical error reduction sequence to reduce keying errors.</div> </div> </div>
    </div>
    </div> <div class="claim"> <div num="89" class="claim">
      <div class="claim-text">89. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer;</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions; and</div> <div class="claim-text">(g) means for recording statistical summaries of data key operator errors for evaluation of operator performance.</div> </div>
    </div>
    </div> <div class="claim"> <div num="90" class="claim">
      <div class="claim-text">90. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer; and</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions;<div class="claim-text">wherein the means for optically scanning documents includes a wand and a related switch mechanism associated with the document feeder to permit the definition of a transaction boundary.</div> </div> </div>
    </div>
    </div> <div class="claim"> <div num="91" class="claim">
      <div class="claim-text">91. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer; and</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions;<div class="claim-text">wherein the means for optically scanning documents further includes means for separating checks from other documents.</div> </div> </div>
    </div>
    </div> <div class="claim"> <div num="92" class="claim">
      <div class="claim-text">92. A system for optically capturing, storing, and retrieving data using electronic images, which system comprises:<div class="claim-text">(a) means for optically scanning documents;</div> <div class="claim-text">(b) means for recording electronic images of documents to facilitate document identification using identification areas or identification words;</div> <div class="claim-text">(c) means for extracting data fields from said electronic images using automatic character recognition techniques and key correction;</div> <div class="claim-text">(d) means to record electronic data extracted from said data fields;</div> <div class="claim-text">(e) means for transmitting said recorded electronic data to a host computer; and</div> <div class="claim-text">(f) means for selectively retrieving data as necessary in performing business transactions;<div class="claim-text">wherein the means for optically scanning documents further includes means for maintaining transaction integrity in the processing of said business transactions.</div> </div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES66279014" lang="EN" load-source="patent-office" class="description">
    <heading>BACKGROUND OF THE INVENTION</heading> <p>This invention relates to an image based document processing system and apparatus for converting paper documents into electronic data and electronic images and managing the transactions initiated by those documents using both the images and data extracted from the images. The system manages document entry and flow within a business or other organization by allowing user interaction with the electronically captured document.</p>
    <p>In the processing of transaction documents by a large business or governmental agency, there is generally a need to accomplish at least three basic objectives. The first objective relates to the capture of data so that it can be electronically stored, for example, by transmittal to a host computer system. This data may be pertinent to accounts payable, insurance policy-holder records, mail order records, taxpayer records or other business information. Secondly, there is a need to index and record the images of the documents from which the stored data was extracted for future retrieval and usage. Third, there is a need to manage the transactions requiring human judgement initiated by the documents and supply the captured data and image for use in the processing of a transaction, such as adjudicating an insurance claim or underwriting a loan application in the usual course of business. Until the present invention, there has not been a satisfactory method or apparatus for automatically capturing, identifying, indexing, and recording data and images from an incoming stream of documents of intermixed sizes and formats for future interactive use.</p>
    <p>Many companies employ manual sorting of documents, generally beginning with the receipt of the documents in a mailroom. The disadvantages inherent in such systems of document sorting are numerous. For example, sorting documents in the mailroom is labor intensive and costly. Manual sorting results in far greater error and document misidentification than electronic classification accomplished pursuant to the present invention.</p>
    <p>Manual sorting of the contents of an envelope is presently accomplished in several ways. Documents may be sorted by size, so that all documents with the same physical dimensions and format, such as 1040 Tax Forms, are manually segregated and grouped. This grouping is necessary because prior automatic document processing devices cannot accommodate documents of varying format. This pre-selection is necessary, using prior systems, to enable the software system to identify the data fields as they are geographically located on the document page. Pre-selection is also generally required in prior systems to accommodate paper feeding devices which will not tolerate varying sizes and weights of input documents.</p>
    <p>With the introduction of optical readers, some flexibility was introduced into the system by first labeling each document with a unique identification which identifies the format of the document and allows the system to accommodate different forms without being separated into individual pre-sized groups. However, this system requires that the document format be preserialized, and many forms and documents exist without a serialized identification. Thus, many documents are not readable by this pre-serialized type of system. Accordingly, the capability of processing many of the different sized and format documents did not exist before the present invention.</p>
    <p>Thus, even with pre-serialized systems, there has been a need in the industry for a document processing system which accomplishes electronic identification, delivery, storage, and retrieval of documents of various sizes and types, without the need for a special ID code or other serially printed mark to ascertain the identity of the document under observation. Also needed is a system which may be adapted for existing tax forms and other documents without the necessity of changing these standardized tax forms or other documents to include pre-printed marks or numbers.</p>
    <p>U.S. Pat. No. 4,205,780 (the "'780 patent") relates to a document processing system with a video camera and television monitor. The typical document transport as described in the '780 patent has the capability of reading magnetic ink character recognition (MICR) data or OCR data encoded on the documents being processed, recording the data, and sorting the documents in a predetermined manner, but requires that the documents be sorted by bank employees before they are loaded into the document scanner and that all the document formats conform. "Header" and "trailer" cards function to separate each batch of documents. Header cards contain MICR data that identify the account being processed.</p>
    <p>The present invention differs from the '780 patent disclosure. For instance, the '780 patent describes the use of MICR and OCR machine readable characters in processing check transactions. Stylized characters and special fonts are used, pursuant to the '780 patent, to allow machine recognition of forms and remittance documents which are pre-printed and manufactured, thus avoiding the automatic identification of other forms which are not specially pre-printed. However, the present invention uses the ability to automatically identify documents that are not pre-printed to keep envelope contents separate, processing the contents of the envelopes as a transaction.</p>
    <p>The '780 patent requires that human operators routinely enter data by hand keying the data on a keyboard. The present invention, however, allows for data capture without operator keying in many applications. This results because the present system will locate and extract data from existing forms after identifying the forms. In cases where data is machine readable, no operator keying is necessary for most data with the present invention.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>In contrast to the prior data capture systems described, the document imaging system of the present invention can capture an optical image of numerous intermixed documents of different sizes and formats, taken directly from opened mail, serially number them before or after image capture, automatically separate the checks, identify the form or document under observation, and manipulate the image data in an advantageous and required manner. After identification of the document, the present system can electronically carve and read specific data fields automatically. Human operators key correct the data for automatic auditing in a manner that is much more efficient than previous data entry systems. The invention permits less skilled operators to specialize, thereby requiring less training of these relatively unskilled operators.</p>
    <p>One advantage of the present system over previously known data capture systems is that known systems generally require that documents received in a mailroom or other data collection center be sorted into homogenous groups. For example, a clerk in a company mailroom using previously existing systems is required to sort, batch, and count various business forms and paper materials prior to sending these materials to an optical scanning device or data entry department.</p>
    <p>Accordingly, the present invention provides a novel method and apparatus that overcomes the limitations and disadvantages of the prior art. The present invention also speeds up the process of document processing so that a higher volume of transactions can be processed by allowing multiple transports and terminals to operate in parallel on the same communications network. Further, the present invention reduces the number of errors which were heretofore considered to be inherent in a document processing operation.</p>
    <p>A significant advantage of the present system for document retrieval and storage is that the data keying operator or adjudicator need not be directly involved with aspects such as the time of receipt or the location of a particular document or data field. In the preferred embodiment, incoming mail is extracted from envelopes in a mailroom and the pieces of mail are immediately scanned on an optical scanner serially, with no particular vertical orientation, i.e., with their wording right side up or upside down. The documents are sequentially numbered with a numbering device as they pass through the optical scanner, and are separated on a stacker separator to separate selected pages or checks from document forms and other pages. The same sequence number is electronically assigned to the captured image of the document, and to the data extracted from the document. This allows for subsequent hard copy retrieval for rescanning in cases in which an image is illegible, or for other evidentiary reasons. In these cases it is possible for an operator to retrieve the original hard copy based upon the partial image and the item sequence number. Thus, the adjudicator may return to the original hard copy if necessary.</p>
    <p>As a document page proceeds through the scanner, a digital picture of the page is taken. This image is captured at a resolution ranging from 150 to 400 pels.</p>
    <p>The next step relates to the identification of the document which now resides in the system as a unique captured electronic image or graphics screen. The software in the present system carves a previously ascertained identification area from the document. In order that this may be accomplished, a number of identification areas are chosen in advance by a designer from the existing printed forms using an interactive computer display. The co-ordinates of identification areas are stored in the computer and accessed for carving the identification area from the documents, thus identifying the document. Forms need not be redesigned to enable automatic identification.</p>
    <p>After document identification is complete, graphical data areas are carved for recognition and correction if necessary. The electronic image of the document, compressed if desired, is sent over a local area network and stored on magnetic disk for ready access to other portions of the system. The extracted and audited data is sent to a host computer for processing.</p>
    <p>The present invention may be advantageously adapted to existing tax forms and other documents because a designer may choose an existing identification area or word for identifying the document. This advantage is not available with previously known systems.</p>
    <p>The chosen identification area presently existing on the document is used as a geographical reference point for the entire spatial image of the document. All other graphical data areas on the document are carved in reference to the identification area located by the processing system.</p>
    <p>In choosing the identification area, the designer preselects a word or an area already existing on the form. The geographic location of the area and the spelling of a word, or the electronic signature of the pel pattern of the area are used as identifying criteria when appropriate. The intelligent character reader (ICR) in the system may examine the pre-chosen identification areas to interpret a word on the document, and identify the document. For instance, on a 1040 tax form, the word identifier might be the word "exemptions" as in FIG. 6.</p>
    <p>An additional advantage of the present optical scanning system invention is that a document may be inserted into the scanner either inverted or properly justified. The software accommodates and automatically inverts upside down identification fields and their related document images to properly read data in either position. When a dual sided scanner is used, documents may be inserted either face up or face down.</p>
    <p>The identified carved portion of the graphics screen image of the document is used to spatially reference graphical data areas of the graphics screen for conversion to usable character data. The first graphical data area carved from the image is known as the "predictor field." The predictor field has special significance. The predictor field is used to determine whether the image residing within a graphical data area was originally printed manually or by a machine. Because recognition techniques differ for these two different types of images, the initial determination of whether original data appearing as an image in the graphical data area was machine printed or manually written is used throughout to determine which type of processing each graphical data area will receive. If the desired data to be captured from the document is machine printed, the system will determine the pitch of the letters. This information is used in all subsequent carving and interpretation of the remaining graphical data areas on the document.</p>
    <p>An additional advantage of the image processing subsystem of the present system is that it can logically deduce the amount of skew in the document image. Perfect alignment is seldom possible, therefore, document skew is normally present in the data fields due to variations in the exact spatial coordinates of documents which are mechanically inserted and fed into the optical scanning device. Once the amount of skew is determined, the program can deduce the proper adjustment for carving and extracting data from the data fields.</p>
    <p>A further significant advantage of the present invention is its adjudicative ability. The efficiency of data correction/entry clerks is greatly increased by the present system. The present system reduces the adjudicative or decision making functions required of data entry personnel because they key only what they see and then only from a discriminate graphical data area.</p>
    <p>High productivity rates are thus possible with the present system. For instance, data corrector/entry operators may increase their keystroke rate productivity to levels as high as 20,000 keystrokes per hour. Unlike previously known systems, it is not necessary that personnel be aware of the type of document under observation or the relationship among specific fields from which data is extracted. It is only necessary that data corrector/entry personnel key information as it is rapidly and continuously placed in front of them. These operators may specialize in certain fields such as, for instance, only numerical fields, such as social security number fields, or only alphanumeric fields such as name and address fields. This specialization advantageously reduces error and costs associated with operator training. This allows, for example, an operator with only a numerical key pad to process only numerical fields, allowing for high input rate and decreased cost.</p>
    <p>The present invention obviates the need to manually deliver documents to various departments or groups within an organization. This results because the documents are converted to electronic data and images, and are automatically available to host computers and to data/document manipulation personnel through interface work stations.</p>
    <p>The present invention, in its preferred embodiment, uses a wand mechanism to separate different transactions. The contents of each envelope is termed a "transaction". Separator cards are not required with the present invention to separate each transaction. This is a significant advantage because separator cards waste valuable computer memory and time that might otherwise be available for data manipulation or storage. More significantly, the use of a wand allows for the contents of an envelope to be processed sequentially together, thus allowing for transaction integrity. Wands may also be used to separate batches of transactions.</p>
    <p>The present invention allows for automatic character recognition of machine printed characters, such as typewritten, upon existing forms, such as 1040 tax forms. These forms are "read" for a determination of the data residing thereon without changing the forms to accommodate the system. Special stylized characters and special pre-printed fonts are advantageously not required with the present invention.</p>
    <p>Another significant advantage of the present invention is that data keying errors may be reduced by re-routing or circulating the data in a logical error reduction sequence. For example, an audit in the system tests data for accuracy once it has been read and keyed by an operator. The auditing system uses a second operator who keys the same data keyed by a first operator. The system then compares the two data fields to determine whether or not they are identical. When the data fields are not identical and the keyed data has failed the audit, the system uses a third operator. In that case, one of the data fields previously keyed will be routed to the third adjudicative operator for keying. This third data field, when matched with one of the first two data fields, proves, with almost complete accuracy, which of the original two data fields was keyed incorrectly. The adjudicative subroutine then chooses the "matched" data in preference to the incorrect data. Operators are usually unaware whether they are keying the first, second or third iteration. Thus, keystroke errors may be essentially eliminated with the present invention.</p>
    <p>The present invention also provides a method of evaluating the accuracy of data key operators. A statistical summary of operator errors and operator performance may be retained in memory for future use in evaluating data operators.</p>
    <p>One step in the process of the present system is the recording of the image of each document in a digital medium as a graphics image. This recording of the image may be on magnetic or optical disks, microfilm, 8 millimeter magnetic or optical tape, or some other suitable digital data recordation and storage means. In many applications, such as the insurance industry, data must be stored, and yet available, for extended periods of time. An ongoing file may require that the data be retrieved and operated on many times before a file is closed.</p>
    <p>Once data is recorded and properly indexed by keys and addresses, for example within the data base, the system or an optional host computer manages work flow and directs the routing of transactions and associated document images to specific operators. In this manner, an unlimited number of adjudicators and employees may access, correct, or view the data simultaneously in an interactive mode. This system of document availability to a number of operators greatly increases the efficiency of a business organization.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>The advantages and technical advances of the preferred embodiment of the present invention can be discerned by reference to the following drawings and schematic diagrams:</p>
    <p>FIG. 1 depicts a typical block diagram of the configuration of the preferred embodiment of the document capture, processing, storage, and retrieval system of the present invention;</p>
    <p>FIG. 1(a) represents a more detailed block diagram of the image acquisition subsystem shown in FIG. 1 which shows the paper path and digital image production;</p>
    <p>FIG. 1(b) is an alternative block diagram of the preferred embodiment whereby separate "nodes" cooperate within the local area network;</p>
    <p>FIG. 1(c) depicts the block diagram of the application subsystem system responsible for managing data and image flow as individual graphics into and out of storage;</p>
    <p>FIG. 2 is a perspective view of the hardware configuration for the typical image acquisition subsystem shown in block diagram in FIG. 1(a) constituting document feeding, printing, scanning, separating, and stacking devices;</p>
    <p>FIG. 3 is a block diagram depicting the sequence of steps in the preferred embodiment of the present invention;</p>
    <p>FIG. 4 represents, as an illustration, the application of this invention to a typical hand written social security number field which has been electronically carved from a document as it appears on a terminal, displayed as a graphical data area;</p>
    <p>FIG. 5 depicts a hand written alpha-numeric field in the form of a name and address field as it appears, displayed on a terminal screen as a graphical data area;</p>
    <p>FIG. 6 shows an operator selecting the word identifier "exemption" on a typical federal tax form in another application of the preferred embodiment of this invention;</p>
    <p>FIG. 7(a) depicts a single character reject as it appears displayed on a correction terminal screen as a graphical data area and a character string with a universal character in the form of an "*" replacing the rejected character;</p>
    <p>FIG. 7(b) depicts multiple separate character rejects as they appear displayed on a correction terminal screen as graphical data areas and corresponding character strings, each having a universal character in the form of an "*" replacing the rejected character;</p>
    <p>FIG. 8 is a side view of the preferred automatic feeder apparatus of the document capture system according to the present invention; and</p>
    <p>FIG. 9 is a top view of the preferred feeder shown in FIG. 8.</p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENT</heading> <p>One embodiment of the present invention is illustrated as a block diagram in FIG. 1 as incorporated into a document processing system organized around a local area network (LAN) which may be Novell. The local area network, indicated as block 36, forms the central component of the document processing and information management system 38. All subsystems including the image acquisition subsystem, indicated as block 24, communicate with the local area network 36. The image acquisition subsystem 24 conveys the captured image from an input device to the local area network 36. The input of documents may occur through a microfilm or microfiche scanner 30, paper scanner 32, or facsimile device 28.</p>
    <p>Each subsystem contains modules of software which can function in a single dedicated computer, or which can be shared with other computer subsystems. The image acquisition subsystem 24, the capture management subsystem indicated as block 10, the application subsystem indicated as block 12, the data correction/entry workstation 14, the application support workstation 16, the storage management subsystem indicated as block 20 and the intelligent character reader (ICR) indicated by block 34 can all share a single computer environment in a very low volume use of the invention.</p>
    <p>FIG. 1(b) shows an alternate arrangement for the document processing system for high volume applications of the present invention. A control computer 180, 184, 188, 194, 198, 204, 210 is provided to each subsystem for data processing. Image transformer 186 receives digital data via telecommunications from a facsimile or other remote source, indicated as block 187 by suitable means such as a serial port. Image transformer 186 converts the digital data to provide a graphics image of each document received from the remote location to the LAN network via control computer 184. A second image transformer 190 receives digital data by suitable means such as a serial port from an optical scanner 192, and provides a graphics image of each document that is compressed or uncompressed to the local area network via control computer 188. An image character reader 182 provides ASCII data to the local area network 36. Storage 196 in the form of hard or optical discs receives and stores graphics images and character data from the LAN 36. An optional host computer 202, which may be an IBM, manages batches of transactions in conjunction with batch communication control 200. Interactive communication, e.g. IBM 3278, between control computer 204 and host computer 202 provides graphics output from a third image transformer 206 directly to host computer 202. Terminal 212 receives a graphics screen image and, when necessary for correction purposes, character string data. Terminal 212 provides operator input to LAN 36 through control computer 210.</p>
    <heading>The Image Acquisition Subsystem</heading> <p>The image acquisition subsystem 24 is responsible for the transfer of an image compressed or uncompressed, in the form of a raster graphics image of each document, suitable for entry onto the local area network 36. In order that the graphics image may be produced, a signal is first received from a scanner or a facsimile device as illustrated by block 129 in FIG. 1(a).</p>
    <p>Referring to FIG. 1, scanner 129 may be a microfilm or microfiche scanner as indicated by block 30, a document scanner as indicated by block 32, and a facsimile device as indicated by block 28. The facsimile device 28 may be a Gamafax® facsimile emulation device for use with an IBM PC AT compatible, with a modem, functioning at 9600 band rate. The microfilm or microfiche scanner 30 may be a Mekel® M400 available from Mekel Engineering in Walnut, Calif. The scanner 129, however, may not constitute all of these devices, or may constitute other suitable input devices.</p>
    <p>The scanner 129 is connected via suitable means such as a serial port to an image transfer system 138 in the form of a Kofax Image Products Series 8200 board, preferably an 8204, located in an expansion slot of a control computer 140 that processes the signal from the scanner 28, 30, 32. Preferably, the control computer 140 is an IBM AT compatible computer with an 80386 mother board, a hard disk drive, two megabytes of expanded memory, a floppy disk and a Proteon LAN interface card mounted in one of its other slots. Additionally, an optional keyboard and display, with associated graphic support, may be connected to control computer 140 for user interaction with a captured image.</p>
    <p>Where a document scanning device, as indicated by block 32, is used, the preferred device is a Fujitsu America scanner model 3090E(a) optical scanner for one-sided forms. A TDC scanner may be used for two-sided forms, although other suitable devices can also be substituted. An optical scanner 60 is shown in FIG. 2. A Digital Image Systems Company (or "DI") model 401 document separator 62 (see FIG. 2) receives documents from the document scanner 60.</p>
    <p>Regardless of what type of scanner 129 is used, which may even constitute a signal from a conventional group 3 or group 4 facsimile device over local or remote telephone lines, the signal is in the form of a serial digital bit stream. In applications requiring more voluminous documents processing, a separate control computer may be provided for each subsystem as seen in FIG. 1(b), each computer communicating with local area network 36.</p>
    <p>The image transformer 138, FIG. 1a, receives the signal, processes the signal into usable data and compresses the data into a first output image in the form of a unique graphics image of each of the documents processed by the scanner 129. The output from the image transformer 138 is passed to the local area network 36. Alternatively, an optional magnetic disk storage or other type of mass storage medium may receive graphics screen image data from control computer 140.</p>
    <p>The left half of FIG. 1(a) depicts the paper path 130 in those cases in which the document received is paper. In order for each document to be converted into a usable signal that is receivable by the image transformer 138, each document must be fed one at a time to the document scanner, illustrated in Figure 1 as block 32 and shown in FIG. 2 at 60. In order that this may be best accomplished, the present invention provides an auto feeder 1000, as shown in FIGS. 8 and 9, and described in detail below.</p>
    <p>Generally, envelopes received in the mailroom contain multiple sheets of paper and sometimes a check. In the past, the contents of the envelopes were sorted by size by a clerk so all documents of the same size were manually counted, segregated and grouped. The contents of the envelopes could even be sorted into stacks in which each stack contains documents of the same format, such as 1040 tax forms. In addition, each document in a stack was required to be oriented in the same direction. But, such sorting is extremely time-consuming and costly.</p>
    <p>However, the present invention is able to process documents of intermixed sizes and format without the necessity of each document format being identified by a unique identification stamped on each document. In order to process documents of intermixed sizes and format, the present invention provides an automatic feeder 1000 usable with different sized sheets of paper and checks, commonly termed documents hereafter, which are stacked together. The contents of each envelope are now kept together as a transaction and fed consecutively through the system first, for scanning, and afterwards, for archival serialization without being separated.</p>
    <p>In the past, documents of the same format had to be processed together, thus forming a type of batch, identified by the common format of each document. Each batch was separated by "header" and "trailer" cards. Commonly, these cards contained magnetic ink character recognition data (MICR) that identified the common format of the documents of each batch. These cards flowed along through the system with the documents, taking up processing time and were scanned, serialized, and stored along with the images of the documents by the system, wasting valuable computer time and memory. More importantly, transaction integrity was broken because different document types from the same transaction were placed in different batches. Accordingly, expensive error prone procedures were required to maintain the relationship of the separated documents during processing and subsequent retrieval.</p>
    <p>However, because the present invention processes documents which are of a different size and format, a transaction may constitute the contents of each unique envelope. This ability to handle documents of intermixed sizes is the strength of the system. Thus, not only may those documents which have a common format be processed together as a transaction, the present invention allows the contents of an envelope, which may constitute different size and format sheets of paper and a check, to be processed together. Even "white mail" which may contain address changes, complaints, instructions, etc., may now be processed in the same transaction and associated with an individual or account by virtue of being included in the same transaction. Because this new capability exists, transaction integrity can be maintained. The individual documents associated with each transaction can be kept associated, without allowing the images and data from one individual or account to be mixed with that of another.</p>
    <p>In order to maintain this integrity, these transactions also require separation, but "header" and "trailer" cards are not required with the present invention. Instead, the present invention implements two different means of virtual separation, as described hereafter, which do not physically accompany the documents being processed by the system, but which determines the end of each transaction, allowing the present invention to electronically maintain the integrity of each transaction. This is a significant advantage because clerical labor and errors are avoided, and valuable computer time and memory are now freed, allowing the computer to process more transactions during a comparable time frame.</p>
    <p>One preferred way to accomplish virtual separation is by a wand mechanism as described hereafter. Another preferred way to accomplish virtual separation is by placing a unique document, recognizable by the system, first in each transaction. With the second preferred way of accomplishing virtual separation, the operator places the unique document, i.e. a 1040 form of a tax return, first on the feeder. When the system encounters a second unique document, the beginning of another transaction is signaled, and the documents between the previous unique document and the second unique document, including the previous unique documents but not including the second unique document, are identified as belonging to the first transaction. When the control computer 140 receives the signal, logical separation is established by suitable methods such as a unique data key to locate the database addresses of the graphics images of each of the documents, and subsequent character data interpreted from graphical data areas of each graphics image. When a unique document is not present, the operator uses the wand mechanism as described hereafter to establish virtual separation.</p>
    <p>FIG. 8 represents an expanded detailed view of the feeder mechanism of the present invention encompassing the wand mechanism, as shown generally in the upper right portion of FIG. 2 (See document feeder 64 in FIG. 2). Referring to FIG. 8, the preferred feeder 1000 usable for feeding a stack of documents 1002 of intermixed size and format, and usable for detecting the boundary of each transaction included in the stack of documents 1002 is shown. The feeder 1000 includes a base 1004 on which the stack 1002 is located, and means associated with base 1004 for feeding a single document 1006 from the stack of documents 1002 while leaving the remaining documents stacked on base 1004. The base 1004 has an elongated, wedge shape, and includes a planar face 1008 over which the stack of documents 1002 is located that is oriented at an angle to the horizontal with its front end positioned at its nadir or lower-most point. Each document is fed forward, but downwardly across planar face 1008 of base 1004 to an optical scanning device 60 shown in phantom and also shown in the document feeder 64 in FIG. 2, as indicated by arrow 1009 that receives the document passing each document between roller 1011.</p>
    <p>A pair of vertically extending retainers 1013 may be provided to keep the documents in the processing path, thus preventing the documents from moving sideways and off the feeder 1000. Accordingly, planar face 1008 is provided with slots 1001 in which the retainers 1013 are located. The retainers 1013 can be adjusted apart as necessary via slots 1001 and tightened into position by thumbscrews 1003.</p>
    <p>The means for feeding a single document includes a pick drive means in the form of a pair of spaced, longitudinal pick rollers 1010 located in front of the base 1004 that drive the lowermost document of the stack 1002 forward from the stack 1002 and feed the document while aligning the next document of the stack 1002 to be fed. The pick rollers 1010 are positioned laterally across the front end of planar face 1008, which is located at the front end of base 1004, with their axes lying along a plane parallel to the planar face 1008 of base 1004. The pick rollers 1010 lie laterally across the forward path of the documents, and turn counterclockwise as indicated in the figure at 1012 in a direction suitable for driving the lowermost document of the stack forward, as indicated by arrow 1014. Preferably, but not shown in the figures, each pick roller 1010 includes an elongated rod 1015, shown partially in FIG. 9, and a number of narrow roller members spaced along the length of the rod that are attached thereto for rotation therewith. In order to rotate each pick roller 1010 and its roller members, each rod includes means such as sprockets or drive belts attached thereto for rotation thereof such that both pick rollers 1010 rotate counterclockwise at the same time.</p>
    <p>Located above pick rollers 1010 is a weighted bar 1019. Weighted bar 1019 includes a series of narrow rollers 1021 positioned above rollers 1017. Weighted bar 1019 is slidably located in a slot 1023 in rachet 1025 to move freely in a vertical direction and, when present, aids in the initial flattening of documents prior to being fed and processed.</p>
    <p>The means for feeding a single document also includes a means in the form of a longitudinal back scrubber roller 1016 adjacent the pick rollers 1010 for allowing only one document to leave the stack 1002 at a time. Back scrubber roller 1016 lies positioned parallel and above the forwardmost pick roller 1018 distal the front end of base 1004. Back scrubber roller 1016 lies longitudinally along the backside of pick roller 1018, biased against its backside. Back scrubber roller 1016 has a diameter less than the diameter of pick rollers 1010, and rotates counterclockwise as indicated at 1020. Referring to FIG. 9, back scrubber roller 1016 includes an elongated rod 1022, shown in phantom, and a number of narrow roller members 1024, shown in phantom, spaced along the length of rod 1022 that are attached thereto for rotation therewith. In order to rotate back scrubber roller 1016, the rod 1022 includes means such as sprockets or drive belts attached thereto for rotation thereof. Located above back scrubber roller 1016 is a cover 1027, pivotally attached to base 1004 for access to roller 1016.</p>
    <p>Referring to FIG. 8, both pick rollers 1010 are rotatively mounted on a connecting web 1026 that is mounted to pivot about an eccentric roller 1028, mounted adjacent to the bottom of base 1004. Eccentric roller 1028 provides a biasing means for urging pick roller 1018 against back scrubber roller 1016 that is adjustable by rotating eccentric roller 1028. A tension spring 1030 attached to the rear portion of web 1026 extends downwardly to attach to the bottom 1032 of base 1004. Tension spring 1030 provides a second biasing means for biasing pick roller 1018 against back scrubber roller 1016, as more pressure is needed for thicker paper. The diameter of back scrubber roller 1016, the rate at which roller 1016 counter-rotates relative to roller 1018 while pivoting about eccentric roller 1016 and the tensile force of spring 1030 are such that pick roller 1018 is urged against back scrubber roller 1016 with a suitable force so that only one document at a time may leave the stack 1002 and pass between rollers 1016 and 1018.</p>
    <p>The means for feeding a single document also includes a continuous drive means in the form of a pair of elongated belt drives 1034 located along base 1004 for urging the stack 1002 adjacent the pick rollers 1010. The belt drives 1034 are positioned parallel, but spaced along the base 1004 below the stack of documents 1002 with their longitudinal portions parallel to planar face 1008 of base 1004. The upper longitudinal portion of the belt drives 1034 engage the bottom of the stack of documents 1002, and the belt drives 1034 turn in a counterclockwise direction as indicated by arrow 1036, suitable for urging the stack 1002 forward over the pick rollers 1010 to a position in which all, or the lower portion of the stack 1002 contacts along the backside 1038 of the back scrubber roller 1016.</p>
    <p>Each belt drive 1034 includes a continuous belt 1040 which is located around a pair of drive wheels 1042 and rotates therewith. Each pair of drive wheels 1042 is connected to a suitable drive means so that all drive wheels 1042 rotate simultaneously.</p>
    <p>The means for feeding a single document includes a detection means adjacent the pick rollers 1010 that is engaged by the movement of the lower portion of the stack 1002 adjacent the pick rollers 1010 for activating the pick rollers 1010. Referring to FIG. 8, the detection means is in the form of a longitudinal detector web 1044 that is biased against the front side of the forwardmost pick roller 1018, and extends outwardly and forwardly from the front side of the forwardmost pick roller 1018 below its apex. Detector web 1044 includes laterally intersecting elongated portions. Extending downwardly from web 1044 is a switch portion 1046 engageable with a complementary switch portion 1048 located below on base 1004 by the downward motion of web 1044 responsive to the forward flow of a document over web 1044, which indicates the presence of a document flowing forward between rollers 1016 and 1018. The engagement of switch portions 1046, 1048 providing a signal that activates the pick rollers 1010.</p>
    <p>Extending downward from the rear of web 1044 is a bridge 1047 which intersects with an arm 1049. Arm 1049 is pivotally attached at its free end 1050 to the bottom of base 1004. Extending upwardly from the bottom of base 1004 adjacent the pivotal attachment of arm 1049 and base 1004 is an elongated support 1052. A suitable tension spring 1054 attached to arm 1049 between its free end 1050 and bridge 1047 is attached to support 1052 near its upper end and acts to bias arm 1049 upward, thus urging longitudinal web 1044 upwards.</p>
    <p>Two preferred ways are employed by the present invention to establish virtual separation. One preferred way to accomplish virtual separation is by the use of a unique document in each transaction as discussed above. Another preferred way to accomplish virtual separation is by the wand mechanism. In order to accomplish virtual separation in this way, an isolating means in the form of an elongated wand 1056 is located in the stack of documents to isolate the documents of a transaction below the wand from the documents and transactions above the wand. Referring to FIG. 8, the stack of documents 1002 constitutes four sets of transactions 1058a, 1058b, 1058c, 1058d, each transaction being separated from its overlying transaction by an elongated wand 1056a, 1056b, 1056c.</p>
    <p>A guide means in the form of a pair of parallel, but spaced elongated guides 1060 extends laterally upward adjacent the rear of the base 1004. Guides 1060 include laterally extending, spaced, adjustable longitudinal support rods 1062 that are carried in unseen slots in base 1004. Support rods 1062 are adapted for longitudinal motion within the unseen slots paralleling planar face 1008, and may be adjusted for moving guides 1060 forwards or backwards to accommodate different size paper. Accordingly, different lengths of wand 1056 may be provided for use in the guides as described in the following to best intermix different sizes of documents.</p>
    <p>Referring to FIG. 9, an elongated slot 1064 extends inwardly along the longitudinal length of each inner, opposing face of elongated guides 1060. Each slot 1064 opposes the other to form a larger guide slot 1066 which extends longitudinally between the upper and lower ends of guides 1060.</p>
    <p>Referring to FIG. 8, each wand 1056 is provided with a cylindrical bushing 1068 which surrounds one of its ends and which is slidable longitudinally within guide slot 1066 in a downwards direction as indicated by arrow 1070. Base 1004 includes an elongated slot 1072 which extends forwardly from the rear of base 1004 and connects with guide slot 1066. Slot 1072 is somewhat wider than the width of each wand 1056 so that each wand can pass easily therethrough. The elongated horizontal length of slot 1072 is long enough so that each wand 1056 when located with its bushing 1068 in guide slot 1066 can pass easily therethrough. A V-shaped neck 72, shown in FIG. 2 aids in quick entry of the brushings 1068 into slot 1066.</p>
    <p>Again referring to FIG. 8, three wands 1056a, 1056b, 1056c are shown. Each wand 1056a, 1056b, 1056c is positioned with its bushing 1068 lengthwise in the guide slot 1066, and located with its free end within the stack of documents 1002 isolating transactions 1058a, 1058b, 1058c and 1058d from each other. Each wand 1056a, 1056b, 1056c extends over slot 1064 and each wand moves downward as the documents are fed forward one at a time, each wand falling consecutively through slot 1064 when the last document of the transaction located below that wand has been fed forward.</p>
    <p>A means for detecting the separation or falling of each wand 1056 in order to determine the end of that transaction is included in the form of a sensor 1074, preferably photoelectric, attached to base 1004 adjacent slot 1064 and connected to the control computer 140 via a serial port or other means for communication therewith. An arm of 1075, the sensor 1074 is triggered by the falling of a wand 1056 through the slot 1072, and the sensor 1074, when triggered, communicates with the control computer 140 and signals the end of that transaction.</p>
    <p>The signal received by the control computer 140 from sensor 1074 allows the control computer to establish virtual separation and isolate the documents of each transaction from the documents of another transaction, maintaining the integrity of the transaction. Thus, for example as wand 1056a falls when the last document of transaction 1058a is passed forward, sensor 1074 signals the end of transaction 1058a, which indicates the beginning of transaction 1058b. Likewise, as wand 1056b falls when the last document of transaction 1058b is passed forward, sensor 1074 signals the end of transaction 1058b, which indicates the beginning of transaction 1058c. Likewise, as wand 1056c falls when the last document of transaction 1058c is passed forward, sensor 1074 signals the end of transaction 1058c, which indicates the beginning of transaction 1058d. At the end of transaction 1058d, an additional wand 1056 may be included, or the operator may manually trip sensor 1074, signaling the end of that transaction.</p>
    <p>Consequently, a rearwand extending narrow vertical slot 1071 connecting with slot 1066 through which the rear portion 1073 of each wand passes, has a land 1075 at its bottom against which rear portion 1073 engages before falling. Land 1075 advantageously prevents the rear portion of the wands 1056 from prematurely falling and activating the sensor 1074 before the transaction has ended. The falling of the front portion of the wand at the end of the transaction, causing the wand to tilt within slot 1066, thus allowing the rear portion 1073 of the wand to bypass land 1075 and fall. Accordingly, the horizontal length of slot 1066 is sufficiently long for bushing 1068 to tilt.</p>
    <p>The falling of a wand 1056 as it leaves the stack of documents and separates from the continued processing flow of the documents, gives rise to a signal being generated from sensor 1074 to the control computer 140. This signal, generated by the falling of a wand 1056, gives the system new capabilities, allowing the control computer 140 to establish virtual separation without using control cards or when no unique document is present, and maintain the integrity of each transaction.</p>
    <p>This provides the system with at least two important new capabilities. First, by merely drawing up one of the documents of the transaction, such as a billing statement, any accompanying "white mail" may be quickly referenced as a graphics screen by referencing the transaction identifier generated in the control computer 140 on its reception of the virtual separation signal. This transaction identifier may, for example, constitute a unique serialized number that serves as a data key to locate the database addresses of the graphics screen for each document of the transaction. This allows quick access to "white mail" and other documents included in the transaction that otherwise might become lost in the mail room or other processing area and disassociated from the account or individual.</p>
    <p>Second, the system is allowed to establish virtual separation without requiring batch intensive labor, overhead computational time and storage space as required in prior systems where control cards are processed, scanned, and stored along with individual documents. Of course, where all the documents being processed constitute a single batch, instead of using a wand 1056 to signal an end of the batch, the end may be manually triggered by the operator using, switch 1077 on the outside of the base 1004. Operation of the switch 1077 signals an end to the batch. Further, there may be other types of transactions for which manual triggering to signal the of the transaction is preferable, and this is within the scope of the present invention also.</p>
    <p>After each document is scanned, each document (as seen in paper path route 130 in Figure la) proceeds to the sequence number printer 132. A Hewlett Packard model 402 audit trail printer, for printing identification numbers on documents before or after scanning, is a preferred device for printing identification numbers on documents. More preferably, a Hewlett Packard Think-Jet printer may be employed for printing identification numbers on documents. The Think-Jet has a movable printhead, and receives information from a sensor identifying the edge of each document. The information from the sensor is processed and passed to the printer to position the printhead so that the identification is printed in the margin of the document. Preferably, the identification is printed in the left margin, and the position for the printhead is determined from an analysis of the scanned image to assure that the printed number is always in the left margin.</p>
    <p>After a sequence number is printed on the paper copy of the document, the paper proceeds to a paper stacker selector 134. The paper stacker selector 134 selectively separates checks from other documents and feeds the checks into the paper stacker assembly 136. Checks may be identified by the presence of ferrous based ink, or because they are less than four inches high. In this way, checks are advantageously separated and made available for deposit at a bank. The document separator 62 (depicted in FIG. 2) comprises the sequence number printer 132, the paper stacker selecter 134, and the paper stacker assembly 36, as depicted in FIG. 1(a).</p>
    <heading>The Capture Management Subsystem</heading> <p>FIG. 1(b) shows a more detailed diagram of the capture management subsystem 10 and its intelligent character reader (ICR) 34. The ICR 34 (FIG. 1), in the preferred embodiment, is an IRIS image recognition integrated systems character reader, available from Image Recognition Integrated Systems Company in Belgium.</p>
    <p>Referring to FIG. 1, the output signals representing an electronic raster graphics image of each document, uncompressed or compressed by conventional CCITT Group IV run length algorithms or the like to save space, are provided to the local area network by the image acquisition subsystem 24. The electronic images are provided from the local area network to the capture management subsystem 10. It is within the capture management subsystem that the output signals are used to identify the documents from which those output signals have emanated. The intelligent character reader 34 performs this function by reference to an identification area or an identification word found on the document itself.</p>
    <p>The capture management subsystem 10 is assembled on a VME backplane. The capture management subsystem 10 includes, in the preferred embodiment, one or more Force® model 80386 computers which may be obtained from Force Computers, Inc. in Campbell, Calif., one or more Iris® brand image character readers, one or more separate Ciprico® Rimfire 3400 brand disc controllers available from Ciprico Company and a Hitachi hard disk drive. Of course, similar equipment could be substituted in practicing the present invention.</p>
    <heading>The Storage Management System</heading> <p>The storage management subsystem 20 receives and stores signals representing both the electronic images and signals representing data fields within a document. These electronic images and data fields are provided to the control computer 158 from the local area network 36 (see FIG. 1(c)). The control computer has an interface to an optical disk storage, not shown in the Figures.</p>
    <p>Preferably, storage management subsystem 20 is assembled from a PC/AT compatible computer using an 80386 board, Novell Network software two megabytes of expanded memory, and a Western Digital Fasst® 7000 model disc controller with two 300 megabyte model DK514E38 hard magnetic disc storage devices.</p>
    <p>Preferably, the optical disk storage includes a Sony optical disc controller, two Sony® 450 megabyte worm optical disc drives and a Cygnet® model 5000 jukebox with 19 slots for optical disc media. A jukebox is a robotic device that selects optical media from an array of slots and inserts optical media into an optical drive. As another option, Sony® model SMO-S501 erasable optical discs with 325 megabytes per side may be used. However, other comparable components could be substituted.</p>
    <heading>The Data Correction and Application Support Workstations</heading> <p>There may be several data correction and entry workstations indicated as block 14 in FIG. 1. Each of these are preferably an IBM compatible 80286 or 80386 computer, but other comparable equipment should be substituted. Each of these computers are equipped with a Hercules® 720×348, VGA 640×480, EVGA 800×600 compatible, for example, or other high resolution display such as a Sigma L-Vue.</p>
    <p>Preferably, each workstation 14 is provided with a MicroSoft Windows or equivalent graphical operating system for controlling the display output. The workstation 14 receives the full raster binary image from the LAN system, and when the image is received by the workstation 14, the graphics image is given to the Windows operating system for display.</p>
    <p>Each workstation 14 also contains a Proteon LAN interface card, and interfaces with the local area network 36. Accordingly, each workstation 14 communicates with other control computers on the LAN.</p>
    <p>Preferably, the application support workstation indicated in FIG. 1 as block 16 is an IBM compatible 80386 AT equipped with a hard disk drive, a high resolution Sigma L-Vue display, decompression hardware or software, and a Fujistu floppy disk drive. The application support workstation 16 connects the local area network 36 to an optional host computer 46. The link to a host computer 46 provides the capability through which human operators may access graphics images resident on the host computer, and change the processed data. Data flows in or out of the local area network 36 from the application support workstation 16.</p>
    <heading>The Publication Subsystem</heading> <p>The publication subsystem 18 provides an outlet from the local area network 36 for producing hard copies 44, micrographics 42, or facsimile output of stored information or images.</p>
    <p>Publication subsystem 18 is preferably assembled from IBM compatible PC AT model 286 computer equipped with a Proteon LAN interface board. Kofax® compression/decompression boards and output devices suitable to the application are included. If a hard copy output 44 is desired, a Hewlett Packard Laser Jet Series II laser printer may be used. If micrographics 42 are desired as an output from the publication subsystem 18, a model IBase® film recorder may be used. A facsimile device may provide data transmission with a Gamafax® modem 40 at a 9600 baud rate to a direct dial phone line.</p>
    <p>The subsystems portrayed in FIG. 1 are typical of the preferred embodiment of the present invention. Of course, alternative devices or subsystems functionally equivalent to those depicted in FIG. 1 could be substituted. Additionally, functionally equivalent hardware can be substituted for the specific hardware components recited in the present specification.</p>
    <heading>Application Subsystem</heading> <p>The local area network 36 communicates with an application subsystem indicated as block 12 in FIG. 1, also known as an application processor. The application subsystem 12 preferably consists of an IBM Compatible Personal Computer, which is available from Systex in Carrollton, Tex. In the preferred embodiment, application subsystem 12 also includes an 80386 board, a Proteon model no. P1303 LAN interface card, a Western Digital® brand hard disc controller, a 300 megabyte hard disk and two megabytes of extended memory. An IBM compatible 3370 data communications link may connect the application subsystem 12 to a host computer.</p>
    <p>Referring to FIG. 1, the application subsystem 12, which may exist in a separate computer, or may share a computer with other subsystems, controls image and data traffic from the storage management subsystem 20 to the application support workstation 16 as the adjudication process ensues after data capture. The application subsystem 12 supervises the extraction of data and transmission of data to the host computer 48.</p>
    <heading>Processing a Transaction</heading> <p>FIG. 3 portrays the typical flow of a transaction in the preferred embodiment of the invention. In step 80 intermixed sizes of sheets and paper and checks, commonly termed documents, are processed as previously described in reference to the image acquisition subsystem in FIG. 1(a). The auto feeder 1000 feeds each document sequentially, one at a time from the bottom of the stack 1002, and introduces it to the optical scanner 60 for data capture.</p>
    <p>In step 82 the scanning device captures an image of the paper. Depending on the type of scanner used, such captured image may be at a variety of resolutions from 150 pels per linear inch to 400 pels per linear inch, or even more. The scanner produces a digital bit stream representation of the image that is transmitted to image transformer 138 via a serial port in computer 140.</p>
    <p>The raster graphics image produced by the transformer 138 of each document are saved in their uncompressed form for the subsequent identification process and for later other usage. The graphics image of each document is also compressed using the standard CCITT algorithms. Each graphics image is passed to LAN 36 and received therefrom by the capture management subsystem 10. Both the graphics images and the carved graphical data areas are sent to the storage subsystem for storage on magnetic disc. Within the capture management subsystem 10, the image character reader 34 processes each graphics image against pre-selected identification areas for a match. Using the matched identification area for that graphics image, graphical data areas of each graphics image are spatially referenced from the matching graphical representation of the matched identification area and carved therefrom.</p>
    <p>Step 84, together with steps 80, 88 and 90 permit the automatic processing of intermixed forms, checks, and documents. The integrity of each separate transaction must be maintained. That is, all the documents relating to a single transaction must be logically "held together" by the system. Referring to FIG. 2, the document feeder 64 provides a wand 68 as previously described which is usable for this purpose. The wand and related switch 70, as previously described and which is attached to the automatic feeder 1000, permit the definition of virtual transaction boundaries without consuming scanner throughout time. The falling of the wand causing switch 70 to generate a signal that is received by control computer 140. Upon the reception of the signal, computer 140 associates, for example, a unique data key with the preceding documents of the transaction. The data key serves to locate addresses of the graphics screen of each document of the transaction for subsequent retrieval from storage. Thus, transaction integrity is obtained, allowing for easy electronic retrieval of all documents of the transaction, including "white mail". Transaction integrity must be maintained; that is, one must, for example, keep the images and data from policyholder A's claim (doctor's report, drug store receipt, etc.) logically associated with A's claim, and not intermixed with policyholder B's claim.</p>
    <p>The preferred way to stack each transaction is to load the primary or principal transaction document first. For example, in a tax form processing transaction, the Form 1040 would be loaded first. A specially designed separator document may be used to indicate separation within a transaction. This manual separation may be necessary when a tax return, for example, arrives without a Form 1040 as part of the transaction.</p>
    <p>Preferential placement of a unique document as previously disclosed, manual use of the wand switch 70, or insertion of a unique formatted separator document, may also be used to effect transaction integrity.</p>
    <p>In step 86, a unique serialized number is printed on all the documents. Each unique number may include batch identification, transaction identification, transport identification, operator identification, date, time, or other identifying variables. That unique number may also be assigned to the image, stored on magnetic disc, and will be assigned to the data to be subsequently extracted from the image. The unique number serves as the primary key or locator number for the original document.</p>
    <p>In step 88, identification and separation of checks from other documents occurs. The preferred embodiment of the invention identifies checks by measuring the dimensions of the image of the check or sensing the presence of the ferrous-based ink printed in the line of characters on the bottom of the check. One or both of these two check-identifying criteria is used to physically separate the check from the other transaction documents by sending the check to a separate output pocket so that checks may later be deposited at a bank.</p>
    <p>Steps 80 through 88 are performed within the image acquisition subsystem 24 as shown in FIG. 1. In step 90, forms and pages are automatically identified by the image character reader 34 when the system has been instructed or programmed to anticipate them. That is, when the location and characteristics of the identification area for each page have been defined. This is accomplished by sequentially comparing each of the pre-chosen identification areas in the capture management subsystem 10 to selected, spatially referenced geographic areas of the graphics screen image of the document.</p>
    <p>Step 90 permits intermixing different forms, and even permits the intermixing of forms in the properly justified or inverted orientations. Graphics screen images of documents that are not identified automatically by the image character reader 34, are queued for manual identification by human operators looking sequentially at a screen or queue of images and keying in the identification. "White mail" (items included in customer transaction envelopes that are not expected or required for a particular business transaction) will appear in this queue, and be bypassed by the operator for subsequent data manipulation while being retained as a graphics screen image for other subsequent usage.</p>
    <p>There are two different ways which may be used to automatically identify forms in step 90. One of the ways is to use the image recognition system 34 to recognize a graphical representation of the identifying word of the form. Each form has a specific geographic identification area containing a specific identification word or words. In order to accomplish this, a pre-chosen series of identifiers is processed against portions of the graphics image. If a match is found, its location within the graphics image is identified as the geographic identification area. Once the geographic identification area is found and identified, other graphical data areas can be located a vector distance measured in binary bits from the identification area.</p>
    <p>One of the pre-chosen identifier may be the word "exemptions" as it appears in the upper right margin of the IRS Form 1040. Another may be the word "averagable" as it appears in Schedule G of the IRS Form tax return in the upper middle of the form.</p>
    <p>However, and referring to FIG. 6, in the event a graphics screen image is undecipherable due, for example, to extraneous matter on the original from such as accidental ink marks, spilt coffee, etc., the unidentified image is queued for an operator(s) who interprets the image and identifies the image to the system as a 1040 Tax Form. All or part of a digital image of 1040 Form 126 may be queued and available for operator review in this event. This process is indicated in FIG. 3 by block 92. Step 92 further relates to manual identification of obsolete forms. In this case, the graphics screen will be available for interpretation, but carved graphical data areas will not be.</p>
    <p>An alternative means to automatically identify forms pursuant to step 90 is by using the ICR to analyze the same geographic template area of each form and evaluating the distribution of black pel's on the white field. The so-called "signature" of this area is unique to each form. Histograms and intersection counts are two criteria used in the present system. Such counts and transformations hereof are accumulated by the ICR for each horizontal and/or vertical line of pel's within the template area. An advantage of this technique is that only one geographic template area need be developed from each form.</p>
    <p>Once a particular form is identified, the relative location of the identification word, or "signature" within the carved identification area, is used to adjust the carving of the data fields to be accomplished in step 94. This process adjusts for misregistration and skew that is introduced as part of the form printing process or the scanning process, whether it be from film, paper or facsimile.</p>
    <p>The automatic carving in step 94 can be used to exploit existing widely used forms without burdening the automatic identification feature to identify forms that occur very infrequently. In less advanced systems without an intelligent recognition subsystem 34 to accomplish step 90, step 92 may be accomplished concurrently with step 96 relating to key correction and entry if the entire page image is displayed to an operator.</p>
    <p>Step 94 relates to the carving of graphical data areas as described in the preceding, once the form has been identified. In step 90, the location and identity of the identification area was identified. Once the location and identity of the identification area has been established, other graphical data areas can be located vector distances, measured in binary bits, from the identification area. The identified graphical data areas are now carved or extracted from the graphic image. These carved graphical data areas are sent to the recognition sub-system 34. Step 94 is optional in the sense that systems may exist and function without it. However, without step 94, all data must be keyed.</p>
    <p>Only the area immediately surrounding each graphical images of data to be captured are carved and sent to the recognition subsystem 34. The first such carved graphical data area read is designated the "predictor field," and it is used to distinguish between hand print and machine print data since different character recognition techniques may be used for each. The predictor field can also be used to determine pitch for machine printed characters.</p>
    <p>With or without step 94, step 96 is essential because character readers are imperfect and sometimes the output of the character reader must be corrected. If the system does not include one or more character readers, then all data must be keyed after carving.</p>
    <p>In the event that the predictor field indicates the carved graphical data areas are undecipherable as may occur when the entries of a document were handwritten, each of the carved graphical data areas, such as shown in FIGS. 4 and 5 may be sent to a different clerk for interpretation and keying. This permits individual clerks to specialize. For example, one group of clerks may specialize in keying only numeric fields, which need only a numeric keypad, and another group may specialize in keying alpha numeric fields which require the use of the full keyboard at the data correction/entry workstation 14. Such specialization improves operator productivity by permitting them to build a rhythm. FIG. 4 shows a typical handwritten numeric social security field 120. FIG. 5 shows a typical handwritten alpha-numeric name and address field 122.</p>
    <p>Specialization may even extend to a specific field. For example, the social security number for tax return processing as seen in FIG. 4 is a fixed-length numeric field and does not require the stroking of the enter key at the workstation 14 to indicate that the keying of the field is complete.</p>
    <p>Operators may specialize in correcting individual characters which have not been recognized. In processing each carved graphical data area, the graphical data area is converted by the image character reader 34 to a representative ASCII character string by processing individual graphical portions of the data area and converting each individual graphical portion to an ASCII character which is positioned in the string at a location associated with the location of the graphical portion from which it was derived. But, the image character reader 34 may not be able to convert all portions of the graphical data areas to an ASCII character. This may happen for several reasons, including imperfectly formed numbers or letter on the original document or accidental marks such as ink stains that partially or totally obliterate numbers or characters on the original document character, which may be an "*" or other suitable character such as a "?", in the character string. The universal character is intermixed in the character string and located within the character string at a position associated with the location of the unconvertable portions in the graphical data area.</p>
    <p>The system recognizes that the conversion was partially imperfect. Consequently, both the graphical data area and its representative character string are routed to a correction terminal 14 where both the graphical data area and the representative character string are displayed. The display in FIG. 7a shows one such graphical data area 216 and its representative character string 217 containing a universal character. FIG. 7b illustrates a display which has a number of graphical data areas 218, 219, 220, 221, each graphical data area having a representative character string 218a, 219a, 220a, 221a containing a universal character associated with it.</p>
    <p>Referring to FIG. 7a for clarity, the operator examines the graphical data area 216 and interprets the portion of the graphical data area associated with location of the universal character in character string 217. The operator then keys in a character using the keyboard which is representative of the unconverted portion of the graphical data. In FIG. 7a, this is an "8". The input is read by the computer, manipulated and positioned within the character string at the position associated with the universal character, thus replacing the universal character.</p>
    <p>The corrected character string may now be displayed, replacing the original character string containing the universal character. The corrected character string is now data keyed, or addressed by the control computer 140 and stored for subsequent use. A number of graphical data areas and their associative character string may be displayed simultaneously as shown in FIG. 7b to reduce the number of required keystrokes and increase the speed of data entry. A prompt, which may be the position of the cursor on the screen alerts the operator to which graphical data area is being examined and interpreted. Of course, the original graphics image from which the graphical data areas were carved need not be altered, leaving the original graphics image for subsequent retrieval.</p>
    <p>Step 98 relates to using a computer program to audit data that has been either read by the character reader or keyed to determine its accuracy. An example of such auditing includes the use of check digit routines and testing for ranges. Audits are done automatically and failures are automatically recycled through step 96 using the pertinent queues. When differences in keying occur between operator A and operator B at different data correction/entry substations 14, or in the recognition subsystem 34, then fields or windows can be cycled a third time through step 96 to break the tie. As such, activity by a skilled operator at step 100 may be eliminated, resulting in substantial increases in efficiency and decreases in operating costs.</p>
    <p>Step 100 is the first step requiring a skilled human operator. Prior to step 100, all roles for clerical activities may be accomplished by very low-skilled clerks requiring little training. The low-skilled clerks simply key what they see or perform simple manual operations.</p>
    <p>During step 100, clerks solve problems. For instance, if a zip code does not match a city, clerks determine which of the two is correct, and subsequently change the wrong element. Clerks may delete incomplete transactions or create two or three separate transactions from one piece of paper. In any event, human judgment is exercised in step 100.</p>
    <p>Step 102 relates to the storing of the image. The graphics image, all carved graphical data areas and interpretive character data that has been extracted from the graphics image and all the operator and machine statistics generated in the process are written into storage in the storage management subsystem 20. For example, the identity of the operator who ran the document scanner 32 and the identity of the operator who keyed the social security numeric field 120 may be written into the storage management subsystem 20. This type of instructive information is coded in the data stored on the mass storage media.</p>
    <p>Step 104 relates to the "address" or location of the image in storage. A variety of data elements are cross-referenced, one to another, and assembled in a database. A database can be as simple as a "flat file," random or can be constructed upon some relational database model.</p>
    <p>Step 106 relates to extracting data from the database and sending it to a host computer system 48. The data sent may be taxpayer records, policyholder records or some other business records. The data is sent using any one of a variety of traditional software protocols. Data is sent to the host computer system 48 via the application subsystem 12 (see FIGS. 1 and 3).</p>
    <p>Step 108 relates to computer-based rules applied to data to classify the transaction or to automatically process the transaction. For example, it may be most efficient to pay a simple insurance claim if it is within a model of an acceptable claim, rather than take the time for a human professional to spend time judging the merits of the claim. Additionally, it may be useful to classify insurance claims so that adjudicators can specialize, negating the requirement that human adjudicators be trained to understand all nuances of each type of claim. For example, an insurance adjudicator may specialize in thoracic injuries. By applying such rules relating to a specific type of claim, transactions may be categorized and queued for suitable adjudicators with like skills and with more intensive specific training in one particular area.</p>
    <p>Step 110 relates to organization of queues which may have been established during step 108, or in the absence of step 108, by a human supervisor. In any event, work is scheduled from one professional task to another. Tasks are monitored by the system so that they are continually queued for the next workstation 14. The system automatically follows up when work is not passed to the next step in a workflow process before a particular pre-set deadline. Hard copy or facsimile output is selectively permitted at output step 111.</p>
    <p>Step 112 relates to the support of customer inquiries received by mail or phone. In processing customer inquiries, graphics images are retrieved and presented to a clerk who services those inquiries upon demand. The retrieval may be based on the item sequence number printed and assigned in step 86, if that number has been transmitted to the host computer. On the other hand, retrieval may be based upon any one of the indices or keys selected during step 104 or other conventional methods common to database application.</p>
    <p>Although the best modes contemplated for carrying out the present invention have been herein shown and described, it will be apparent that modification and variation may be made without departing from what is regarded to be the subject matter of the invention. For example, although digital apparatus is disclosed, appropriate analog equivalents may also be employed to form an analog combination suitable for practicing the present invention. It will be apparent to one skilled in the art that relatively simple software instruction may be devised to carry out the exact sequence of steps described in the present specification.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3460673">US3460673</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 19, 1967</td><td class="patent-data-table-td patent-date-value">Aug 12, 1969</td><td class="patent-data-table-td ">Recognition Equipment Inc</td><td class="patent-data-table-td ">Document sorting apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US3815102">US3815102</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 1, 1972</td><td class="patent-data-table-td patent-date-value">Jun 4, 1974</td><td class="patent-data-table-td ">Recognition Equipment Inc</td><td class="patent-data-table-td ">Method and apparatus for item tracking</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4027142">US4027142</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 18, 1975</td><td class="patent-data-table-td patent-date-value">May 31, 1977</td><td class="patent-data-table-td ">Recognition Equipment Incorporated</td><td class="patent-data-table-td ">Automated processing of financial documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4205780">US4205780</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 3, 1978</td><td class="patent-data-table-td patent-date-value">Jun 3, 1980</td><td class="patent-data-table-td ">Teknekron, Inc.</td><td class="patent-data-table-td ">Document processing system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4404649">US4404649</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 3, 1980</td><td class="patent-data-table-td patent-date-value">Sep 13, 1983</td><td class="patent-data-table-td ">Recognition Equipment Incorporated</td><td class="patent-data-table-td ">Document processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4510619">US4510619</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 1, 1981</td><td class="patent-data-table-td patent-date-value">Apr 9, 1985</td><td class="patent-data-table-td ">Banctec, Incorporated</td><td class="patent-data-table-td ">Document processing system</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="ORBIT+Search+Service+Japio%3A+User+Manual"'>ORBIT Search Service Japio: User Manual</a>", First Edition, Nov. 1985, TM-8219/000/000, pp. 1-8.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">ORBIT Search Service Japio: User Manual , First Edition, Nov. 1985, TM 8219/000/000, pp. 1 8.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5444794">US5444794</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 25, 1993</td><td class="patent-data-table-td patent-date-value">Aug 22, 1995</td><td class="patent-data-table-td ">Sqn</td><td class="patent-data-table-td ">Check image capture system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5530907">US5530907</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 23, 1993</td><td class="patent-data-table-td patent-date-value">Jun 25, 1996</td><td class="patent-data-table-td ">Tcsi Corporation</td><td class="patent-data-table-td ">Modular networked image processing system and method therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5557515">US5557515</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 17, 1995</td><td class="patent-data-table-td patent-date-value">Sep 17, 1996</td><td class="patent-data-table-td ">Hartford Fire Insurance Company, Inc.</td><td class="patent-data-table-td ">Computerized system and method for work management</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5623662">US5623662</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 9, 1996</td><td class="patent-data-table-td patent-date-value">Apr 22, 1997</td><td class="patent-data-table-td ">Supercomm, Inc.</td><td class="patent-data-table-td ">Revenue sharing system with data filtering using history, periodic, and exclusion databases</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5627973">US5627973</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 14, 1994</td><td class="patent-data-table-td patent-date-value">May 6, 1997</td><td class="patent-data-table-td ">Moore Business Forms, Inc.</td><td class="patent-data-table-td ">Method and apparatus for facilitating evaluation of business opportunities for supplying goods and/or services to potential customers</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5631984">US5631984</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 7, 1995</td><td class="patent-data-table-td patent-date-value">May 20, 1997</td><td class="patent-data-table-td ">Ncr Corporation</td><td class="patent-data-table-td ">Method and apparatus for separating static and dynamic portions of document images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5666490">US5666490</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 16, 1994</td><td class="patent-data-table-td patent-date-value">Sep 9, 1997</td><td class="patent-data-table-td ">Gillings; Dennis</td><td class="patent-data-table-td ">Computer network system and method for managing documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5684965">US5684965</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 7, 1995</td><td class="patent-data-table-td patent-date-value">Nov 4, 1997</td><td class="patent-data-table-td ">American Express Travel Related Services, Inc.</td><td class="patent-data-table-td ">Automated billing consolidation system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5790260">US5790260</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 8, 1995</td><td class="patent-data-table-td patent-date-value">Aug 4, 1998</td><td class="patent-data-table-td ">Financial Ware, Inc.</td><td class="patent-data-table-td ">Offline digitizing of items for subsequent image processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5793498">US5793498</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 10, 1995</td><td class="patent-data-table-td patent-date-value">Aug 11, 1998</td><td class="patent-data-table-td ">Telogy Networks, Inc.</td><td class="patent-data-table-td ">System for transferring facsimile data without dedicated G3 hardware</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5815209">US5815209</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 12, 1997</td><td class="patent-data-table-td patent-date-value">Sep 29, 1998</td><td class="patent-data-table-td ">Matsushita Electric Industrial Co., Ltd.</td><td class="patent-data-table-td ">Encoding method, an encoding apparatus, a decoding method and a decoding apparatus for a moving picture</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5815595">US5815595</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 29, 1995</td><td class="patent-data-table-td patent-date-value">Sep 29, 1998</td><td class="patent-data-table-td ">Seiko Epson Corporation</td><td class="patent-data-table-td ">Method and apparatus for identifying text fields and checkboxes in digitized images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5819040">US5819040</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 6, 1996</td><td class="patent-data-table-td patent-date-value">Oct 6, 1998</td><td class="patent-data-table-td ">Kabushiki Kaisha Toshiba</td><td class="patent-data-table-td ">Image processing system for transferring electronic document and paper document as single mail</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5848184">US5848184</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 30, 1995</td><td class="patent-data-table-td patent-date-value">Dec 8, 1998</td><td class="patent-data-table-td ">Unisys Corporation</td><td class="patent-data-table-td ">Document page analyzer and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5870319">US5870319</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 4, 1996</td><td class="patent-data-table-td patent-date-value">Feb 9, 1999</td><td class="patent-data-table-td ">Texas Instruments Incorporated</td><td class="patent-data-table-td ">Device and method for collecting data from graphed images</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5870725">US5870725</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 11, 1995</td><td class="patent-data-table-td patent-date-value">Feb 9, 1999</td><td class="patent-data-table-td ">Wachovia Corporation</td><td class="patent-data-table-td ">High volume financial image media creation and display system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5889896">US5889896</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 27, 1994</td><td class="patent-data-table-td patent-date-value">Mar 30, 1999</td><td class="patent-data-table-td ">Meshinsky; John</td><td class="patent-data-table-td ">System for performing multiple processes on images of scanned documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5895473">US5895473</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 11, 1995</td><td class="patent-data-table-td patent-date-value">Apr 20, 1999</td><td class="patent-data-table-td ">Integrated Industrial Information, Inc.</td><td class="patent-data-table-td ">System for extracting text from CAD files</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5940804">US5940804</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 18, 1996</td><td class="patent-data-table-td patent-date-value">Aug 17, 1999</td><td class="patent-data-table-td ">Turley; William N.</td><td class="patent-data-table-td ">Computer executable workflow resource management system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5999910">US5999910</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 6, 1997</td><td class="patent-data-table-td patent-date-value">Dec 7, 1999</td><td class="patent-data-table-td ">Fmr Corp.</td><td class="patent-data-table-td ">Processing a workflow item</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6006193">US6006193</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 18, 1996</td><td class="patent-data-table-td patent-date-value">Dec 21, 1999</td><td class="patent-data-table-td ">Gibson; Kenneth U.</td><td class="patent-data-table-td ">Computer executable workflow control system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6055327">US6055327</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 17, 1997</td><td class="patent-data-table-td patent-date-value">Apr 25, 2000</td><td class="patent-data-table-td ">Aragon; David Bradburn</td><td class="patent-data-table-td ">Method of detecting data entry errors by sorting amounts and verifying amount order</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6092088">US6092088</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 18, 1997</td><td class="patent-data-table-td patent-date-value">Jul 18, 2000</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Method for controlling document processing apparatus connected to network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6119132">US6119132</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 2, 1998</td><td class="patent-data-table-td patent-date-value">Sep 12, 2000</td><td class="patent-data-table-td ">Matsushita Electrical Industrial Co., Ltd.</td><td class="patent-data-table-td ">Electronic image filing system for assigning an identifier to an electronic representation, Wherein the identifier comprises an image identifier corresponding to the image and a predetermined apparatus identifier corresponding to the filing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6189009">US6189009</a></td><td class="patent-data-table-td patent-date-value">Aug 27, 1999</td><td class="patent-data-table-td patent-date-value">Feb 13, 2001</td><td class="patent-data-table-td ">The Voice.Com, Inc.</td><td class="patent-data-table-td ">System and method for integrating paper-based business documents with computer-readable data entered via a computer network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6196458">US6196458</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 1, 1997</td><td class="patent-data-table-td patent-date-value">Mar 6, 2001</td><td class="patent-data-table-td ">Walker Digital, Llc</td><td class="patent-data-table-td ">Method and apparatus for printing a billing statement to provide supplementary product sales</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6219647">US6219647</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 4, 1997</td><td class="patent-data-table-td patent-date-value">Apr 17, 2001</td><td class="patent-data-table-td ">Hadewe, B.V.</td><td class="patent-data-table-td ">Method and an apparatus for preprocessing logging of received postal items</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6349320">US6349320</a></td><td class="patent-data-table-td patent-date-value">Jun 3, 1997</td><td class="patent-data-table-td patent-date-value">Feb 19, 2002</td><td class="patent-data-table-td ">Fmr Corp.</td><td class="patent-data-table-td ">Computer executable workflow management and control system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6351566">US6351566</a></td><td class="patent-data-table-td patent-date-value">Mar 2, 2000</td><td class="patent-data-table-td patent-date-value">Feb 26, 2002</td><td class="patent-data-table-td ">International Business Machines</td><td class="patent-data-table-td ">Method for image binarization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6377986">US6377986</a></td><td class="patent-data-table-td patent-date-value">Feb 1, 2000</td><td class="patent-data-table-td patent-date-value">Apr 23, 2002</td><td class="patent-data-table-td ">Digital Convergence Corporation</td><td class="patent-data-table-td ">Routing string indicative of a location of a database on a web associated with a product in commerce</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6384744">US6384744</a></td><td class="patent-data-table-td patent-date-value">Jun 13, 2000</td><td class="patent-data-table-td patent-date-value">May 7, 2002</td><td class="patent-data-table-td ">Digital:Convergence Corp.</td><td class="patent-data-table-td ">Method and system for data transmission from an optical reader</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6397209">US6397209</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 29, 1997</td><td class="patent-data-table-td patent-date-value">May 28, 2002</td><td class="patent-data-table-td ">Telexis Corporation</td><td class="patent-data-table-td ">Real time structured summary search engine</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6421691">US6421691</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 5, 1999</td><td class="patent-data-table-td patent-date-value">Jul 16, 2002</td><td class="patent-data-table-td ">Mitani Sangyo Co., Ltd.</td><td class="patent-data-table-td ">Document management apparatus and method, a recording medium storing a document management program, and a recording medium storing a decision-making program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6507671">US6507671</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 9, 1999</td><td class="patent-data-table-td patent-date-value">Jan 14, 2003</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Method and system for dropping template from a filled in image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6526449">US6526449</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1999</td><td class="patent-data-table-td patent-date-value">Feb 25, 2003</td><td class="patent-data-table-td ">Digital Convergence Corporation</td><td class="patent-data-table-td ">Method and apparatus for controlling a computer from a remote location</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6594705">US6594705</a></td><td class="patent-data-table-td patent-date-value">Jan 20, 2000</td><td class="patent-data-table-td patent-date-value">Jul 15, 2003</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for utilizing an audibly coded signal to conduct commerce over the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6608696">US6608696</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 6, 2000</td><td class="patent-data-table-td patent-date-value">Aug 19, 2003</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Facsimile system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6614916">US6614916</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 4, 2001</td><td class="patent-data-table-td patent-date-value">Sep 2, 2003</td><td class="patent-data-table-td ">Bell &amp; Howell Mail And Messaging Technologies Company</td><td class="patent-data-table-td ">Machine vision system and triggering method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6615268">US6615268</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1999</td><td class="patent-data-table-td patent-date-value">Sep 2, 2003</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method for controlling a computer using an embedded unique code in the content of dat media</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6622165">US6622165</a></td><td class="patent-data-table-td patent-date-value">Feb 3, 2000</td><td class="patent-data-table-td patent-date-value">Sep 16, 2003</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for allowing a remote site to interact with an intermediate database to facilitate access to the remote site</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6629133">US6629133</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1999</td><td class="patent-data-table-td patent-date-value">Sep 30, 2003</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Interactive doll</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6631404">US6631404</a></td><td class="patent-data-table-td patent-date-value">May 11, 2000</td><td class="patent-data-table-td patent-date-value">Oct 7, 2003</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and system for conducting a contest using a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6636892">US6636892</a></td><td class="patent-data-table-td patent-date-value">Jun 15, 2000</td><td class="patent-data-table-td patent-date-value">Oct 21, 2003</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method for conducting a contest using a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6636896">US6636896</a></td><td class="patent-data-table-td patent-date-value">Jan 20, 2000</td><td class="patent-data-table-td patent-date-value">Oct 21, 2003</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for utilizing an audibly coded signal to conduct commerce over the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6640009">US6640009</a></td><td class="patent-data-table-td patent-date-value">Feb 6, 2001</td><td class="patent-data-table-td patent-date-value">Oct 28, 2003</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Identification, separation and compression of multiple forms with mutants</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6643692">US6643692</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1999</td><td class="patent-data-table-td patent-date-value">Nov 4, 2003</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method for controlling a computer using an embedded unique code in the content of video tape media</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6658166">US6658166</a></td><td class="patent-data-table-td patent-date-value">Mar 8, 2000</td><td class="patent-data-table-td patent-date-value">Dec 2, 2003</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Correction of distortions in form processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6672507">US6672507</a></td><td class="patent-data-table-td patent-date-value">Nov 14, 2000</td><td class="patent-data-table-td patent-date-value">Jan 6, 2004</td><td class="patent-data-table-td ">Walker Digital, Llc</td><td class="patent-data-table-td ">Method and apparatus for printing a billing statement to provide supplementary product sales</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6683697">US6683697</a></td><td class="patent-data-table-td patent-date-value">Dec 9, 1999</td><td class="patent-data-table-td patent-date-value">Jan 27, 2004</td><td class="patent-data-table-td ">Millenium L.P.</td><td class="patent-data-table-td ">Information processing methodology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6688522">US6688522</a></td><td class="patent-data-table-td patent-date-value">May 30, 2000</td><td class="patent-data-table-td patent-date-value">Feb 10, 2004</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Unique bar code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6694300">US6694300</a></td><td class="patent-data-table-td patent-date-value">Dec 19, 1997</td><td class="patent-data-table-td patent-date-value">Feb 17, 2004</td><td class="patent-data-table-td ">Walker Digital, Llc</td><td class="patent-data-table-td ">Method and apparatus for providing supplementary product sales to a customer at a customer terminal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6694356">US6694356</a></td><td class="patent-data-table-td patent-date-value">Jul 6, 2000</td><td class="patent-data-table-td patent-date-value">Feb 17, 2004</td><td class="patent-data-table-td ">L.V. Partner, L.P.</td><td class="patent-data-table-td ">Remote control having an optical indicia reader</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6697949">US6697949</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Feb 24, 2004</td><td class="patent-data-table-td ">L.V. Partner, L.P.</td><td class="patent-data-table-td ">Method and apparatus for controlling a user&#39;s pc through an audio-visual broadcast to archive information in the users pc</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6701354">US6701354</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Mar 2, 2004</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Method for interconnecting two locations over a network in response to using a tool</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6701369">US6701369</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 2000</td><td class="patent-data-table-td patent-date-value">Mar 2, 2004</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for accessing a remote location by sensing a machine-resolvable code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6704864">US6704864</a></td><td class="patent-data-table-td patent-date-value">May 10, 2000</td><td class="patent-data-table-td patent-date-value">Mar 9, 2004</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Automatic configuration of equipment software</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6707434">US6707434</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 30, 1997</td><td class="patent-data-table-td patent-date-value">Mar 16, 2004</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Computer workstation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6708208">US6708208</a></td><td class="patent-data-table-td patent-date-value">Jan 26, 2000</td><td class="patent-data-table-td patent-date-value">Mar 16, 2004</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Unique bar code for indicating a link between a product and a remote location on a web network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6725220">US6725220</a></td><td class="patent-data-table-td patent-date-value">Nov 30, 2001</td><td class="patent-data-table-td patent-date-value">Apr 20, 2004</td><td class="patent-data-table-td ">Comfidex Corp.</td><td class="patent-data-table-td ">System and method for integrating paper-based business documents with computer-readable data entered via a computer network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6725260">US6725260</a></td><td class="patent-data-table-td patent-date-value">May 10, 2000</td><td class="patent-data-table-td patent-date-value">Apr 20, 2004</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for configuring configurable equipment with configuration information received from a remote location</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6745234">US6745234</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1999</td><td class="patent-data-table-td patent-date-value">Jun 1, 2004</td><td class="patent-data-table-td ">Digital:Convergence Corporation</td><td class="patent-data-table-td ">Method and apparatus for accessing a remote location by scanning an optical code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6754698">US6754698</a></td><td class="patent-data-table-td patent-date-value">Jun 23, 2000</td><td class="patent-data-table-td patent-date-value">Jun 22, 2004</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for accessing a remote location with an optical reader having a dedicated memory system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6758398">US6758398</a></td><td class="patent-data-table-td patent-date-value">Jun 21, 2000</td><td class="patent-data-table-td patent-date-value">Jul 6, 2004</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Optical reader with ultraviolet wavelength capability</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6778703">US6778703</a></td><td class="patent-data-table-td patent-date-value">Apr 19, 2000</td><td class="patent-data-table-td patent-date-value">Aug 17, 2004</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Form recognition using reference areas</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6788407">US6788407</a></td><td class="patent-data-table-td patent-date-value">Mar 18, 2002</td><td class="patent-data-table-td patent-date-value">Sep 7, 2004</td><td class="patent-data-table-td ">Itt Manufacturing Enterprises, Inc.</td><td class="patent-data-table-td ">Laser interrogation of surface agents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6791585">US6791585</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 21, 2000</td><td class="patent-data-table-td patent-date-value">Sep 14, 2004</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Computer method and system for reconciling disparate data archival mediums</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6791588">US6791588</a></td><td class="patent-data-table-td patent-date-value">Jun 15, 2000</td><td class="patent-data-table-td patent-date-value">Sep 14, 2004</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Method for conducting a contest using a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6792452">US6792452</a></td><td class="patent-data-table-td patent-date-value">May 10, 2000</td><td class="patent-data-table-td patent-date-value">Sep 14, 2004</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Method for configuring a piece of equipment with the use of an associated machine resolvable code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6810136">US6810136</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 18, 2002</td><td class="patent-data-table-td patent-date-value">Oct 26, 2004</td><td class="patent-data-table-td ">Olive Software Inc.</td><td class="patent-data-table-td ">System and method for automatic preparation of data repositories from microfilm-type materials</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6816894">US6816894</a></td><td class="patent-data-table-td patent-date-value">Feb 1, 2000</td><td class="patent-data-table-td patent-date-value">Nov 9, 2004</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Method for interfacing scanned product information with a source for the product over a global network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6823388">US6823388</a></td><td class="patent-data-table-td patent-date-value">Jun 30, 2000</td><td class="patent-data-table-td patent-date-value">Nov 23, 2004</td><td class="patent-data-table-td ">L.V. Parners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for accessing a remote location with an optical reader having a programmable memory system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6826592">US6826592</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Nov 30, 2004</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Digital ID for selecting web browser and use preferences of a user during use of a web application</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6829650">US6829650</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Dec 7, 2004</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for opening and launching a web browser in response to an audible signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6836799">US6836799</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Dec 28, 2004</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for tracking user profile and habits on a global network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6843417">US6843417</a></td><td class="patent-data-table-td patent-date-value">May 30, 2000</td><td class="patent-data-table-td patent-date-value">Jan 18, 2005</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Aiming indicia for a bar code and method of use</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6845366">US6845366</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 22, 1999</td><td class="patent-data-table-td patent-date-value">Jan 18, 2005</td><td class="patent-data-table-td ">Ncr Corporation</td><td class="patent-data-table-td ">Method of processing a check and an apparatus therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6845388">US6845388</a></td><td class="patent-data-table-td patent-date-value">Feb 2, 2000</td><td class="patent-data-table-td patent-date-value">Jan 18, 2005</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Web site access manual of a character string into a software interface</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6860424">US6860424</a></td><td class="patent-data-table-td patent-date-value">May 30, 2000</td><td class="patent-data-table-td patent-date-value">Mar 1, 2005</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Optical reader and use</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6868433">US6868433</a></td><td class="patent-data-table-td patent-date-value">Jan 24, 2000</td><td class="patent-data-table-td patent-date-value">Mar 15, 2005</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Input device having positional and scanning capabilities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6877032">US6877032</a></td><td class="patent-data-table-td patent-date-value">Jun 21, 2000</td><td class="patent-data-table-td patent-date-value">Apr 5, 2005</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Launching a web site using a portable scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6886136">US6886136</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 5, 2000</td><td class="patent-data-table-td patent-date-value">Apr 26, 2005</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Automatic template and field definition in form processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6928413">US6928413</a></td><td class="patent-data-table-td patent-date-value">Jan 14, 2000</td><td class="patent-data-table-td patent-date-value">Aug 9, 2005</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Method of product promotion</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6961555">US6961555</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2000</td><td class="patent-data-table-td patent-date-value">Nov 1, 2005</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">System and apparatus for connecting a wireless device to a remote location on a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6968317">US6968317</a></td><td class="patent-data-table-td patent-date-value">Aug 21, 2000</td><td class="patent-data-table-td patent-date-value">Nov 22, 2005</td><td class="patent-data-table-td ">Charles Schwab &amp; Co., Inc.</td><td class="patent-data-table-td ">Method and apparatus for new accounts program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6970914">US6970914</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1999</td><td class="patent-data-table-td patent-date-value">Nov 29, 2005</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for embedding routing information to a remote web site in an audio/video track</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6970916">US6970916</a></td><td class="patent-data-table-td patent-date-value">Jun 15, 2000</td><td class="patent-data-table-td patent-date-value">Nov 29, 2005</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Method for conducting a contest using a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6973438">US6973438</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 2000</td><td class="patent-data-table-td patent-date-value">Dec 6, 2005</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for delivering information from a remote site on a network based on statistical information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6981059">US6981059</a></td><td class="patent-data-table-td patent-date-value">Feb 1, 2000</td><td class="patent-data-table-td patent-date-value">Dec 27, 2005</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Audible designation for a node on a communication network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6985954">US6985954</a></td><td class="patent-data-table-td patent-date-value">Jan 26, 2000</td><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Input device for allowing input of a unique digital code to a user&#39;s computer to control access thereof to a web site</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6985962">US6985962</a></td><td class="patent-data-table-td patent-date-value">Sep 16, 2003</td><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for allowing a remote site to interact with an intermediate database to facilitate access to the remote site</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7010577">US7010577</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1999</td><td class="patent-data-table-td patent-date-value">Mar 7, 2006</td><td class="patent-data-table-td ">L. V. Partners, L.P.</td><td class="patent-data-table-td ">Method of controlling a computer using an embedded unique code in the content of DVD media</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7016951">US7016951</a></td><td class="patent-data-table-td patent-date-value">Apr 20, 2000</td><td class="patent-data-table-td patent-date-value">Mar 21, 2006</td><td class="patent-data-table-td ">Mantech Ctx Corporation</td><td class="patent-data-table-td ">System and method for network security</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7043536">US7043536</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 1999</td><td class="patent-data-table-td patent-date-value">May 9, 2006</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method for controlling a computer using an embedded unique code in the content of CD media</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7069582">US7069582</a></td><td class="patent-data-table-td patent-date-value">Feb 24, 2004</td><td class="patent-data-table-td patent-date-value">Jun 27, 2006</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for controlling a user&#39;s PC through an audio-visual broadcast to archive information in the user&#39;s PC</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7075673">US7075673</a></td><td class="patent-data-table-td patent-date-value">Nov 6, 2003</td><td class="patent-data-table-td patent-date-value">Jul 11, 2006</td><td class="patent-data-table-td ">Eon-Net L.P.</td><td class="patent-data-table-td ">Information processing methodology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7089291">US7089291</a></td><td class="patent-data-table-td patent-date-value">Jul 27, 2000</td><td class="patent-data-table-td patent-date-value">Aug 8, 2006</td><td class="patent-data-table-td ">L.V. Partners, L.P.</td><td class="patent-data-table-td ">Battery pack having integral optical reader for wireless communication device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7110134">US7110134</a></td><td class="patent-data-table-td patent-date-value">May 2, 2003</td><td class="patent-data-table-td patent-date-value">Sep 19, 2006</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Facsimile system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7117240">US7117240</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Oct 3, 2006</td><td class="patent-data-table-td ">Lv Partners, Lp</td><td class="patent-data-table-td ">Method and apparatus for launching a web site with non-standard control input device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7159037">US7159037</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Jan 2, 2007</td><td class="patent-data-table-td ">Lv Partners, Lp</td><td class="patent-data-table-td ">Method and apparatus for utilizing an existing product code to issue a match to a predetermined location on a global network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7184162">US7184162</a></td><td class="patent-data-table-td patent-date-value">Apr 15, 2005</td><td class="patent-data-table-td patent-date-value">Feb 27, 2007</td><td class="patent-data-table-td ">Eon-Net L.P.</td><td class="patent-data-table-td ">Information processing methodology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7197543">US7197543</a></td><td class="patent-data-table-td patent-date-value">Jun 22, 2004</td><td class="patent-data-table-td patent-date-value">Mar 27, 2007</td><td class="patent-data-table-td ">Lv Partners, Lp</td><td class="patent-data-table-td ">Method and apparatus for accessing a remote location with an optical reader having a dedicated memory system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7228282">US7228282</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Jun 5, 2007</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for directing an existing product code to a remote location</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7237104">US7237104</a></td><td class="patent-data-table-td patent-date-value">Mar 9, 2004</td><td class="patent-data-table-td patent-date-value">Jun 26, 2007</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Automatic configuration of equipment software</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7257614">US7257614</a></td><td class="patent-data-table-td patent-date-value">Nov 30, 2004</td><td class="patent-data-table-td patent-date-value">Aug 14, 2007</td><td class="patent-data-table-td ">Lv Partners, Lp</td><td class="patent-data-table-td ">Digital ID for selecting web browser and use preferences of a user during use of a web application</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7257619">US7257619</a></td><td class="patent-data-table-td patent-date-value">Jun 29, 2004</td><td class="patent-data-table-td patent-date-value">Aug 14, 2007</td><td class="patent-data-table-td ">Lv Partners, Lp</td><td class="patent-data-table-td ">Bar code scanner and software interface interlock for performing encrypted handshaking and for disabling the scanner or input device in case of handshaking operation failure</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7259887">US7259887</a></td><td class="patent-data-table-td patent-date-value">Apr 10, 2006</td><td class="patent-data-table-td patent-date-value">Aug 21, 2007</td><td class="patent-data-table-td ">Eon-Net L.P.</td><td class="patent-data-table-td ">Information processing methodology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7271924">US7271924</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 16, 2000</td><td class="patent-data-table-td patent-date-value">Sep 18, 2007</td><td class="patent-data-table-td ">Seiko Epson Corporation</td><td class="patent-data-table-td ">Printer, control method for the same, and control device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7284066">US7284066</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Oct 16, 2007</td><td class="patent-data-table-td ">Lv Partners, Lp</td><td class="patent-data-table-td ">Method and apparatus for matching a user&#39;s use profile in commerce with a broadcast</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7287091">US7287091</a></td><td class="patent-data-table-td patent-date-value">Dec 7, 2004</td><td class="patent-data-table-td patent-date-value">Oct 23, 2007</td><td class="patent-data-table-td ">L.V. Partners, Lp.</td><td class="patent-data-table-td ">Method and apparatus for opening and launching a web browser in response to an audible signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7305612">US7305612</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 31, 2003</td><td class="patent-data-table-td patent-date-value">Dec 4, 2007</td><td class="patent-data-table-td ">Siemens Corporate Research, Inc.</td><td class="patent-data-table-td ">Systems and methods for automatic form segmentation for raster-based passive electronic documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7308483">US7308483</a></td><td class="patent-data-table-td patent-date-value">Apr 20, 2004</td><td class="patent-data-table-td patent-date-value">Dec 11, 2007</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for automatic configuration of equipment</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7314173">US7314173</a></td><td class="patent-data-table-td patent-date-value">Jul 2, 2004</td><td class="patent-data-table-td patent-date-value">Jan 1, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Optical reader with ultraviolet wavelength capability</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7318106">US7318106</a></td><td class="patent-data-table-td patent-date-value">Jul 15, 2003</td><td class="patent-data-table-td patent-date-value">Jan 8, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for utilizing an audibly coded signal to conduct commerce over the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7321941">US7321941</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Jan 22, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Network routing utilizing a product code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7336813">US7336813</a></td><td class="patent-data-table-td patent-date-value">Apr 26, 2004</td><td class="patent-data-table-td patent-date-value">Feb 26, 2008</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method of determining image skew using connected components</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7346214">US7346214</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 25, 2003</td><td class="patent-data-table-td patent-date-value">Mar 18, 2008</td><td class="patent-data-table-td ">Mathias Wettstein</td><td class="patent-data-table-td ">Method for capturing a complete data set of forms provided with graphic characters</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7370114">US7370114</a></td><td class="patent-data-table-td patent-date-value">Oct 13, 1999</td><td class="patent-data-table-td patent-date-value">May 6, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Software downloading using a television broadcast channel</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7379901">US7379901</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 2000</td><td class="patent-data-table-td patent-date-value">May 27, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Accessing a vendor web site using personal account information retrieved from a credit card company web site</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7383333">US7383333</a></td><td class="patent-data-table-td patent-date-value">Dec 28, 2004</td><td class="patent-data-table-td patent-date-value">Jun 3, 2008</td><td class="patent-data-table-td ">L.V. Partners, Lp</td><td class="patent-data-table-td ">Method and apparatus for tracking user profile and habits on a global network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7386600">US7386600</a></td><td class="patent-data-table-td patent-date-value">Sep 12, 2000</td><td class="patent-data-table-td patent-date-value">Jun 10, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Launching a web site using a personal device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7392285">US7392285</a></td><td class="patent-data-table-td patent-date-value">Oct 21, 2003</td><td class="patent-data-table-td patent-date-value">Jun 24, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method for conducting a contest using a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7392312">US7392312</a></td><td class="patent-data-table-td patent-date-value">Nov 2, 2000</td><td class="patent-data-table-td patent-date-value">Jun 24, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method for utilizing visual cue in conjunction with web access</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7392945">US7392945</a></td><td class="patent-data-table-td patent-date-value">Jun 20, 2000</td><td class="patent-data-table-td patent-date-value">Jul 1, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Portable scanner for enabling automatic commerce transactions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7412666">US7412666</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 14, 2004</td><td class="patent-data-table-td patent-date-value">Aug 12, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method for conducting a contest using a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7415511">US7415511</a></td><td class="patent-data-table-td patent-date-value">Nov 9, 2004</td><td class="patent-data-table-td patent-date-value">Aug 19, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method for interfacing scanned product information with a source for the product over a global network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7422150">US7422150</a></td><td class="patent-data-table-td patent-date-value">Nov 1, 2001</td><td class="patent-data-table-td patent-date-value">Sep 9, 2008</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Electronic voting apparatus, system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7424521">US7424521</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Sep 9, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method using database for facilitating computer based access to a location on a network after scanning a barcode disposed on a product</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7431209">US7431209</a></td><td class="patent-data-table-td patent-date-value">Sep 26, 2002</td><td class="patent-data-table-td patent-date-value">Oct 7, 2008</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Electronic voting apparatus, system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7437475">US7437475</a></td><td class="patent-data-table-td patent-date-value">Oct 21, 2003</td><td class="patent-data-table-td patent-date-value">Oct 14, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for utilizing an audibly coded signal to conduct commerce over the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7440993">US7440993</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Oct 21, 2008</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for launching a web browser in response to scanning of product information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7444302">US7444302</a></td><td class="patent-data-table-td patent-date-value">Jun 14, 2002</td><td class="patent-data-table-td patent-date-value">Oct 28, 2008</td><td class="patent-data-table-td ">Ellie Mae, Inc.</td><td class="patent-data-table-td ">Online system for fulfilling loan applications from loan originators</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7461787">US7461787</a></td><td class="patent-data-table-td patent-date-value">Mar 20, 2006</td><td class="patent-data-table-td patent-date-value">Dec 9, 2008</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Electronic voting apparatus, system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7467745">US7467745</a></td><td class="patent-data-table-td patent-date-value">Jun 9, 2006</td><td class="patent-data-table-td patent-date-value">Dec 23, 2008</td><td class="patent-data-table-td ">Walker Digital, Llc</td><td class="patent-data-table-td ">Billing statement customer acquisition system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7472089">US7472089</a></td><td class="patent-data-table-td patent-date-value">Aug 15, 2002</td><td class="patent-data-table-td patent-date-value">Dec 30, 2008</td><td class="patent-data-table-td ">Ellie Mae, Inc.</td><td class="patent-data-table-td ">Loan origination system interface for online loan application processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7474434">US7474434</a></td><td class="patent-data-table-td patent-date-value">Mar 16, 2007</td><td class="patent-data-table-td patent-date-value">Jan 6, 2009</td><td class="patent-data-table-td ">Millennium L.P.</td><td class="patent-data-table-td ">Information processing methodology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7493283">US7493283</a></td><td class="patent-data-table-td patent-date-value">Sep 11, 2000</td><td class="patent-data-table-td patent-date-value">Feb 17, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Performing an e-commerce transaction from credit card account information retrieved from a credit card company web site</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7493384">US7493384</a></td><td class="patent-data-table-td patent-date-value">Jun 23, 2000</td><td class="patent-data-table-td patent-date-value">Feb 17, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Controlling a PC using a tone from a cellular telephone</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7496638">US7496638</a></td><td class="patent-data-table-td patent-date-value">Mar 29, 2005</td><td class="patent-data-table-td patent-date-value">Feb 24, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Launching a web site using a portable scanner</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7505922">US7505922</a></td><td class="patent-data-table-td patent-date-value">May 9, 2000</td><td class="patent-data-table-td patent-date-value">Mar 17, 2009</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Method and apparatus for utilizing a unique transaction code to update a magazine subscription over the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7515286">US7515286</a></td><td class="patent-data-table-td patent-date-value">Aug 15, 2007</td><td class="patent-data-table-td patent-date-value">Apr 7, 2009</td><td class="patent-data-table-td ">Seiko Epson Corporation</td><td class="patent-data-table-td ">Printer, control method for the same, and control device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7519214">US7519214</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Apr 14, 2009</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method of determining image skew using connected components</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7523161">US7523161</a></td><td class="patent-data-table-td patent-date-value">Jan 18, 2005</td><td class="patent-data-table-td patent-date-value">Apr 21, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Control of software interface with information input to access window</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7533177">US7533177</a></td><td class="patent-data-table-td patent-date-value">Nov 23, 2004</td><td class="patent-data-table-td patent-date-value">May 12, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method and apparatus for accessing a remote location with an optical reader having a programmable memory system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7536478">US7536478</a></td><td class="patent-data-table-td patent-date-value">Oct 22, 2007</td><td class="patent-data-table-td patent-date-value">May 19, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method and apparatus for opening and launching a web browser in response to an audible signal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7548988">US7548988</a></td><td class="patent-data-table-td patent-date-value">May 6, 2008</td><td class="patent-data-table-td patent-date-value">Jun 16, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Software downloading using a television broadcast channel</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7558838">US7558838</a></td><td class="patent-data-table-td patent-date-value">Sep 14, 2004</td><td class="patent-data-table-td patent-date-value">Jul 7, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method for configuring a piece of equipment with the use of an associated machine resolvable code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7570383">US7570383</a></td><td class="patent-data-table-td patent-date-value">Mar 16, 2007</td><td class="patent-data-table-td patent-date-value">Aug 4, 2009</td><td class="patent-data-table-td ">Glory Licensing Llc</td><td class="patent-data-table-td ">Information processing methodology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7596786">US7596786</a></td><td class="patent-data-table-td patent-date-value">Jan 2, 2007</td><td class="patent-data-table-td patent-date-value">Sep 29, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method and apparatus for utilizing an existing product code to issue a match to a predetermined location on a global network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7599543">US7599543</a></td><td class="patent-data-table-td patent-date-value">Aug 8, 2005</td><td class="patent-data-table-td patent-date-value">Oct 6, 2009</td><td class="patent-data-table-td ">Cummins-Allison Corp.</td><td class="patent-data-table-td ">Document processing system using full image scanning</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7602956">US7602956</a></td><td class="patent-data-table-td patent-date-value">Aug 1, 2005</td><td class="patent-data-table-td patent-date-value">Oct 13, 2009</td><td class="patent-data-table-td ">Cummins-Allison Corp.</td><td class="patent-data-table-td ">Document processing system using full image scanning</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7614553">US7614553</a></td><td class="patent-data-table-td patent-date-value">Jul 17, 2006</td><td class="patent-data-table-td patent-date-value">Nov 10, 2009</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Method for reading an optically readable sheet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7619768">US7619768</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Nov 17, 2009</td><td class="patent-data-table-td ">Glory Licensing Llc</td><td class="patent-data-table-td ">Information processing methodology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7620231">US7620231</a></td><td class="patent-data-table-td patent-date-value">Aug 5, 2005</td><td class="patent-data-table-td patent-date-value">Nov 17, 2009</td><td class="patent-data-table-td ">Cummins-Allison Corp.</td><td class="patent-data-table-td ">Document processing system using full image scanning</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7634557">US7634557</a></td><td class="patent-data-table-td patent-date-value">Apr 29, 2002</td><td class="patent-data-table-td patent-date-value">Dec 15, 2009</td><td class="patent-data-table-td ">Netwitness Corporation</td><td class="patent-data-table-td ">Apparatus and method for network analysis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7635087">US7635087</a></td><td class="patent-data-table-td patent-date-value">Feb 28, 2005</td><td class="patent-data-table-td patent-date-value">Dec 22, 2009</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Method for processing a machine readable ballot and ballot therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7635088">US7635088</a></td><td class="patent-data-table-td patent-date-value">Feb 22, 2007</td><td class="patent-data-table-td patent-date-value">Dec 22, 2009</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Electronic voting method and system employing a printed machine readable ballot</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7636788">US7636788</a></td><td class="patent-data-table-td patent-date-value">Oct 15, 2007</td><td class="patent-data-table-td patent-date-value">Dec 22, 2009</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method and apparatus for matching a user&#39;s use profile in commerce with a broadcast</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7672007">US7672007</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Mar 2, 2010</td><td class="patent-data-table-td ">Glory Licensing Llc</td><td class="patent-data-table-td ">Information processing methodology</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7672940">US7672940</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 29, 2004</td><td class="patent-data-table-td patent-date-value">Mar 2, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Processing an electronic document for information extraction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7684646">US7684646</a></td><td class="patent-data-table-td patent-date-value">Oct 22, 2008</td><td class="patent-data-table-td patent-date-value">Mar 23, 2010</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">System and method of determining image skew using connected components</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7739353">US7739353</a></td><td class="patent-data-table-td patent-date-value">Jun 10, 2008</td><td class="patent-data-table-td patent-date-value">Jun 15, 2010</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Launching a web site using a personal device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7778902">US7778902</a></td><td class="patent-data-table-td patent-date-value">Jul 1, 2005</td><td class="patent-data-table-td patent-date-value">Aug 17, 2010</td><td class="patent-data-table-td ">Charles Schwab &amp; Co., Inc.</td><td class="patent-data-table-td ">Method and apparatus for a new accounts program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7792696">US7792696</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Sep 7, 2010</td><td class="patent-data-table-td ">RPX-LV Acquisition, LLC</td><td class="patent-data-table-td ">Method and apparatus for allowing a broadcast to remotely control a computer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7797742">US7797742</a></td><td class="patent-data-table-td patent-date-value">Feb 26, 2007</td><td class="patent-data-table-td patent-date-value">Sep 14, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">File blocking mitigation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7797743">US7797743</a></td><td class="patent-data-table-td patent-date-value">Feb 26, 2007</td><td class="patent-data-table-td patent-date-value">Sep 14, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">File conversion in restricted process</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7818423">US7818423</a></td><td class="patent-data-table-td patent-date-value">Aug 21, 2000</td><td class="patent-data-table-td patent-date-value">Oct 19, 2010</td><td class="patent-data-table-td ">RPX-LV Acquisition, LLC</td><td class="patent-data-table-td ">Retrieving personal account information from a web site by reading a credit card</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7819316">US7819316</a></td><td class="patent-data-table-td patent-date-value">Oct 8, 2007</td><td class="patent-data-table-td patent-date-value">Oct 26, 2010</td><td class="patent-data-table-td ">Lv Partners, L.P.</td><td class="patent-data-table-td ">Portable scanner for enabling automatic commerce transactions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7822829">US7822829</a></td><td class="patent-data-table-td patent-date-value">Aug 11, 2008</td><td class="patent-data-table-td patent-date-value">Oct 26, 2010</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method for interfacing scanned product information with a source for the product over a global network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7828215">US7828215</a></td><td class="patent-data-table-td patent-date-value">May 12, 2006</td><td class="patent-data-table-td patent-date-value">Nov 9, 2010</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Reader for an optically readable ballot</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7856379">US7856379</a></td><td class="patent-data-table-td patent-date-value">Oct 13, 2006</td><td class="patent-data-table-td patent-date-value">Dec 21, 2010</td><td class="patent-data-table-td ">Walker Digital, Llc</td><td class="patent-data-table-td ">Pre-sale data broadcast system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7870189">US7870189</a></td><td class="patent-data-table-td patent-date-value">Mar 15, 2005</td><td class="patent-data-table-td patent-date-value">Jan 11, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Input device having positional and scanning capabilities</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7873200">US7873200</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2006</td><td class="patent-data-table-td patent-date-value">Jan 18, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for remote deposit of checks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7873576">US7873576</a></td><td class="patent-data-table-td patent-date-value">Sep 24, 2003</td><td class="patent-data-table-td patent-date-value">Jan 18, 2011</td><td class="patent-data-table-td ">Cummins-Allison Corp.</td><td class="patent-data-table-td ">Financial document processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7876949">US7876949</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2006</td><td class="patent-data-table-td patent-date-value">Jan 25, 2011</td><td class="patent-data-table-td ">United Services Automobile Association</td><td class="patent-data-table-td ">Systems and methods for remote deposit of checks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7881561">US7881561</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 26, 2003</td><td class="patent-data-table-td patent-date-value">Feb 1, 2011</td><td class="patent-data-table-td ">Abbyy Software Ltd.</td><td class="patent-data-table-td ">Method of pre-analysis of a machine-readable form image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7885451">US7885451</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2006</td><td class="patent-data-table-td patent-date-value">Feb 8, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for displaying negotiable instruments derived from various sources</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7885880">US7885880</a></td><td class="patent-data-table-td patent-date-value">Sep 30, 2008</td><td class="patent-data-table-td patent-date-value">Feb 8, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Atomic deposit transaction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7886017">US7886017</a></td><td class="patent-data-table-td patent-date-value">May 28, 2004</td><td class="patent-data-table-td patent-date-value">Feb 8, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method and apparatus for accessing a remote location by receiving a product code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7896232">US7896232</a></td><td class="patent-data-table-td patent-date-value">Nov 6, 2007</td><td class="patent-data-table-td patent-date-value">Mar 1, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems, methods, and apparatus for receiving images of one or more checks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7900224">US7900224</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Mar 1, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method and apparatus for utilizing an audible signal to induce a user to select an E-commerce function</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7900822">US7900822</a></td><td class="patent-data-table-td patent-date-value">Nov 6, 2007</td><td class="patent-data-table-td patent-date-value">Mar 8, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems, methods, and apparatus for receiving images of one or more checks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7904344">US7904344</a></td><td class="patent-data-table-td patent-date-value">Jan 29, 2008</td><td class="patent-data-table-td patent-date-value">Mar 8, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Accessing a vendor web site using personal account information retrieved from a credit card company web site</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7908430">US7908430</a></td><td class="patent-data-table-td patent-date-value">Aug 14, 2008</td><td class="patent-data-table-td patent-date-value">Mar 15, 2011</td><td class="patent-data-table-td ">Bdgb Enterprise Software S.A.R.L.</td><td class="patent-data-table-td ">Associative memory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7908467">US7908467</a></td><td class="patent-data-table-td patent-date-value">Jun 26, 2007</td><td class="patent-data-table-td patent-date-value">Mar 15, 2011</td><td class="patent-data-table-td ">RPX-LV Acquistion LLC</td><td class="patent-data-table-td ">Automatic configuration of equipment software</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7912760">US7912760</a></td><td class="patent-data-table-td patent-date-value">Mar 17, 2009</td><td class="patent-data-table-td patent-date-value">Mar 22, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method and apparatus for utilizing a unique transaction code to update a magazine subscription over the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7912961">US7912961</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td patent-date-value">Mar 22, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Input device for allowing input of unique digital code to a user&#39;s computer to control access thereof to a web site</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7916892">US7916892</a></td><td class="patent-data-table-td patent-date-value">Aug 31, 2004</td><td class="patent-data-table-td patent-date-value">Mar 29, 2011</td><td class="patent-data-table-td ">Opex Corporation</td><td class="patent-data-table-td ">Method and apparatus for processing mail to obtain image data of contents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7917844">US7917844</a></td><td class="patent-data-table-td patent-date-value">Jul 14, 2000</td><td class="patent-data-table-td patent-date-value">Mar 29, 2011</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Directory service for form processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7925780">US7925780</a></td><td class="patent-data-table-td patent-date-value">Mar 13, 2007</td><td class="patent-data-table-td patent-date-value">Apr 12, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method for connecting a wireless device to a remote location on a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7930213">US7930213</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Apr 19, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method and apparatus for completing, securing and conducting an E-commerce transaction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7949587">US7949587</a></td><td class="patent-data-table-td patent-date-value">Oct 24, 2008</td><td class="patent-data-table-td patent-date-value">May 24, 2011</td><td class="patent-data-table-td ">United States Automobile Association (USAA)</td><td class="patent-data-table-td ">Systems and methods for financial deposits by electronic message</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7962411">US7962411</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 30, 2008</td><td class="patent-data-table-td patent-date-value">Jun 14, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Atomic deposit transaction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7970677">US7970677</a></td><td class="patent-data-table-td patent-date-value">Oct 24, 2008</td><td class="patent-data-table-td patent-date-value">Jun 28, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for financial deposits by electronic message</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7974899">US7974899</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 30, 2008</td><td class="patent-data-table-td patent-date-value">Jul 5, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Atomic deposit transaction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7975022">US7975022</a></td><td class="patent-data-table-td patent-date-value">Oct 23, 2007</td><td class="patent-data-table-td patent-date-value">Jul 5, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Launching a web site using a passive transponder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7975920">US7975920</a></td><td class="patent-data-table-td patent-date-value">Sep 8, 2008</td><td class="patent-data-table-td patent-date-value">Jul 12, 2011</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Electronic voting method and system employing a machine readable ballot envelope</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7979576">US7979576</a></td><td class="patent-data-table-td patent-date-value">Oct 21, 2008</td><td class="patent-data-table-td patent-date-value">Jul 12, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Method and apparatus for connecting a user location to one of a plurality of destination locations on a network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7988047">US7988047</a></td><td class="patent-data-table-td patent-date-value">Jan 21, 2010</td><td class="patent-data-table-td patent-date-value">Aug 2, 2011</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Method for decoding an optically readable sheet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7992853">US7992853</a></td><td class="patent-data-table-td patent-date-value">Jan 10, 2007</td><td class="patent-data-table-td patent-date-value">Aug 9, 2011</td><td class="patent-data-table-td ">Opex Corporation</td><td class="patent-data-table-td ">Method and apparatus for processing mail to obtain image data of contents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7996314">US7996314</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Aug 9, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods to modify a negotiable instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7996315">US7996315</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Aug 9, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods to modify a negotiable instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7996316">US7996316</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Aug 9, 2011</td><td class="patent-data-table-td ">United Services Automobile Association</td><td class="patent-data-table-td ">Systems and methods to modify a negotiable instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8001051">US8001051</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Aug 16, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods to modify a negotiable instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8005985">US8005985</a></td><td class="patent-data-table-td patent-date-value">Oct 14, 2008</td><td class="patent-data-table-td patent-date-value">Aug 23, 2011</td><td class="patent-data-table-td ">RPX—LV Acquisition LLC</td><td class="patent-data-table-td ">Method and apparatus for utilizing an audibly coded signal to conduct commerce over the internet</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8015198">US8015198</a></td><td class="patent-data-table-td patent-date-value">Apr 21, 2008</td><td class="patent-data-table-td patent-date-value">Sep 6, 2011</td><td class="patent-data-table-td ">Bdgb Enterprise Software S.A.R.L.</td><td class="patent-data-table-td ">Method for automatically indexing documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8027537">US8027537</a></td><td class="patent-data-table-td patent-date-value">May 18, 2007</td><td class="patent-data-table-td patent-date-value">Sep 27, 2011</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Air Force</td><td class="patent-data-table-td ">Visual object identification by computational majority voting</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8028036">US8028036</a></td><td class="patent-data-table-td patent-date-value">Jul 11, 2000</td><td class="patent-data-table-td patent-date-value">Sep 27, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Launching a web site using a passive transponder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8046301">US8046301</a></td><td class="patent-data-table-td patent-date-value">Oct 30, 2007</td><td class="patent-data-table-td patent-date-value">Oct 25, 2011</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods to modify a negotiable instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8066184">US8066184</a></td><td class="patent-data-table-td patent-date-value">Sep 9, 2008</td><td class="patent-data-table-td patent-date-value">Nov 29, 2011</td><td class="patent-data-table-td ">Avante International Technology, Inc.</td><td class="patent-data-table-td ">Optically readable marking sheet and reading apparatus and method therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8069098">US8069098</a></td><td class="patent-data-table-td patent-date-value">Sep 22, 2008</td><td class="patent-data-table-td patent-date-value">Nov 29, 2011</td><td class="patent-data-table-td ">Rpx-Lv Acquisition Llc</td><td class="patent-data-table-td ">Input device for allowing interface to a web site in association with a unique input code</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8112359">US8112359</a></td><td class="patent-data-table-td patent-date-value">Dec 21, 2010</td><td class="patent-data-table-td patent-date-value">Feb 7, 2012</td><td class="patent-data-table-td ">Walker Digital, Llc</td><td class="patent-data-table-td ">Pre-sale data broadcast system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8117117">US8117117</a></td><td class="patent-data-table-td patent-date-value">Nov 18, 2008</td><td class="patent-data-table-td patent-date-value">Feb 14, 2012</td><td class="patent-data-table-td ">Ellie Mae, Inc.</td><td class="patent-data-table-td ">Loan origination system interface for online loan application processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8121950">US8121950</a></td><td class="patent-data-table-td patent-date-value">Nov 2, 2004</td><td class="patent-data-table-td patent-date-value">Feb 21, 2012</td><td class="patent-data-table-td ">Ncr Corporation</td><td class="patent-data-table-td ">Method of processing a check and an apparatus therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8125624">US8125624</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 1, 2005</td><td class="patent-data-table-td patent-date-value">Feb 28, 2012</td><td class="patent-data-table-td ">Cummins-Allison Corp.</td><td class="patent-data-table-td ">Automated document processing system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8126920">US8126920</a></td><td class="patent-data-table-td patent-date-value">Nov 18, 2004</td><td class="patent-data-table-td patent-date-value">Feb 28, 2012</td><td class="patent-data-table-td ">Ellie Mae, Inc.</td><td class="patent-data-table-td ">Enterprise security management system using hierarchical organization and multiple ownership structure</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8157254">US8157254</a></td><td class="patent-data-table-td patent-date-value">Sep 16, 2009</td><td class="patent-data-table-td patent-date-value">Apr 17, 2012</td><td class="patent-data-table-td ">Opex Corporation</td><td class="patent-data-table-td ">Method and apparatus for processing mail to obtain image data of contents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8170371">US8170371</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 26, 2003</td><td class="patent-data-table-td patent-date-value">May 1, 2012</td><td class="patent-data-table-td ">Abbyy Software, Ltd</td><td class="patent-data-table-td ">Method of image pre-analyzing of a machine-readable form of non-fixed layout</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8209481">US8209481</a></td><td class="patent-data-table-td patent-date-value">Feb 9, 2011</td><td class="patent-data-table-td patent-date-value">Jun 26, 2012</td><td class="patent-data-table-td ">Bdgb Enterprise Software S.A.R.L</td><td class="patent-data-table-td ">Associative memory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8261985">US8261985</a></td><td class="patent-data-table-td patent-date-value">Apr 1, 2010</td><td class="patent-data-table-td patent-date-value">Sep 11, 2012</td><td class="patent-data-table-td ">Avante Corporation Limited</td><td class="patent-data-table-td ">Manual recount process using digitally imaged ballots</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8261986">US8261986</a></td><td class="patent-data-table-td patent-date-value">Oct 15, 2010</td><td class="patent-data-table-td patent-date-value">Sep 11, 2012</td><td class="patent-data-table-td ">Kevin Kwong-Tai Chung</td><td class="patent-data-table-td ">System and method for decoding an optically readable markable sheet and markable sheet therefor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8276067">US8276067</a></td><td class="patent-data-table-td patent-date-value">Sep 10, 2008</td><td class="patent-data-table-td patent-date-value">Sep 25, 2012</td><td class="patent-data-table-td ">Bdgb Enterprise Software S.A.R.L.</td><td class="patent-data-table-td ">Classification method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8290237">US8290237</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods to use a digital camera to remotely deposit a negotiable instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8296440">US8296440</a></td><td class="patent-data-table-td patent-date-value">May 12, 2009</td><td class="patent-data-table-td patent-date-value">Oct 23, 2012</td><td class="patent-data-table-td ">Rpx Corporation</td><td class="patent-data-table-td ">Method and apparatus for accessing a remote location with an optical reader having a programmable memory system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8320657">US8320657</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2007</td><td class="patent-data-table-td patent-date-value">Nov 27, 2012</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods to use a digital camera to remotely deposit a negotiable instrument</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8321357">US8321357</a></td><td class="patent-data-table-td patent-date-value">Sep 30, 2009</td><td class="patent-data-table-td patent-date-value">Nov 27, 2012</td><td class="patent-data-table-td ">Lapir Gennady</td><td class="patent-data-table-td ">Method and system for extraction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8351677">US8351677</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2006</td><td class="patent-data-table-td patent-date-value">Jan 8, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for remote deposit of checks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8351678">US8351678</a></td><td class="patent-data-table-td patent-date-value">Jun 11, 2008</td><td class="patent-data-table-td patent-date-value">Jan 8, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Duplicate check detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8358826">US8358826</a></td><td class="patent-data-table-td patent-date-value">Oct 23, 2007</td><td class="patent-data-table-td patent-date-value">Jan 22, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for receiving and orienting an image of one or more checks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8364579">US8364579</a></td><td class="patent-data-table-td patent-date-value">Oct 27, 2008</td><td class="patent-data-table-td patent-date-value">Jan 29, 2013</td><td class="patent-data-table-td ">Ellie Mae, Inc.</td><td class="patent-data-table-td ">Online system for fulfilling loan applications from loan originators</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8391599">US8391599</a></td><td class="patent-data-table-td patent-date-value">Oct 17, 2008</td><td class="patent-data-table-td patent-date-value">Mar 5, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for adaptive binarization of an image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8392332">US8392332</a></td><td class="patent-data-table-td patent-date-value">Dec 8, 2010</td><td class="patent-data-table-td patent-date-value">Mar 5, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for remote deposit of checks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8401268">US8401268</a></td><td class="patent-data-table-td patent-date-value">Sep 3, 2009</td><td class="patent-data-table-td patent-date-value">Mar 19, 2013</td><td class="patent-data-table-td ">Cummins-Allison Corp.</td><td class="patent-data-table-td ">Optical imaging sensor for a document processing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8422758">US8422758</a></td><td class="patent-data-table-td patent-date-value">Sep 2, 2008</td><td class="patent-data-table-td patent-date-value">Apr 16, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods of check re-presentment deterrent</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8433127">US8433127</a></td><td class="patent-data-table-td patent-date-value">May 10, 2007</td><td class="patent-data-table-td patent-date-value">Apr 30, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for real-time validation of check image quality</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8438077">US8438077</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2003</td><td class="patent-data-table-td patent-date-value">May 7, 2013</td><td class="patent-data-table-td ">Ebay, Inc.</td><td class="patent-data-table-td ">Method and apparatus for providing supplementary product sales to a customer at a customer terminal</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8452689">US8452689</a></td><td class="patent-data-table-td patent-date-value">Feb 18, 2009</td><td class="patent-data-table-td patent-date-value">May 28, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods of check detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8459632">US8459632</a></td><td class="patent-data-table-td patent-date-value">Apr 16, 2012</td><td class="patent-data-table-td patent-date-value">Jun 11, 2013</td><td class="patent-data-table-td ">Opex Corporation</td><td class="patent-data-table-td ">Method and apparatus for processing mail to obtain image data of contents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8464933">US8464933</a></td><td class="patent-data-table-td patent-date-value">Jan 31, 2011</td><td class="patent-data-table-td patent-date-value">Jun 18, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems, methods and apparatus for receiving images of one or more checks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8488173">US8488173</a></td><td class="patent-data-table-td patent-date-value">Jul 14, 2011</td><td class="patent-data-table-td patent-date-value">Jul 16, 2013</td><td class="patent-data-table-td ">Mphj Technology Investments, Llc</td><td class="patent-data-table-td ">Distributed computer architecture and process for document management</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8538124">US8538124</a></td><td class="patent-data-table-td patent-date-value">May 10, 2007</td><td class="patent-data-table-td patent-date-value">Sep 17, 2013</td><td class="patent-data-table-td ">United Services Auto Association (USAA)</td><td class="patent-data-table-td ">Systems and methods for real-time validation of check image quality</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8542921">US8542921</a></td><td class="patent-data-table-td patent-date-value">Jul 27, 2009</td><td class="patent-data-table-td patent-date-value">Sep 24, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for remote deposit of negotiable instrument using brightness correction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8543510">US8543510</a></td><td class="patent-data-table-td patent-date-value">Feb 6, 2012</td><td class="patent-data-table-td patent-date-value">Sep 24, 2013</td><td class="patent-data-table-td ">Walker Digital, Llc</td><td class="patent-data-table-td ">Pre-sale data broadcast system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8600173">US8600173</a></td><td class="patent-data-table-td patent-date-value">Aug 19, 2010</td><td class="patent-data-table-td patent-date-value">Dec 3, 2013</td><td class="patent-data-table-td ">Dst Technologies, Inc.</td><td class="patent-data-table-td ">Contextualization of machine indeterminable information based on machine determinable information</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8600798">US8600798</a></td><td class="patent-data-table-td patent-date-value">Sep 21, 2007</td><td class="patent-data-table-td patent-date-value">Dec 3, 2013</td><td class="patent-data-table-td ">Ellie Mae, Inc.</td><td class="patent-data-table-td ">Loan screening</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8611635">US8611635</a></td><td class="patent-data-table-td patent-date-value">Dec 20, 2012</td><td class="patent-data-table-td patent-date-value">Dec 17, 2013</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Duplicate check detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8675220">US8675220</a></td><td class="patent-data-table-td patent-date-value">Oct 22, 2008</td><td class="patent-data-table-td patent-date-value">Mar 18, 2014</td><td class="patent-data-table-td ">J2 Global Communications, Inc.</td><td class="patent-data-table-td ">Internet fax message searching and fax content delivery using keyword detection</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8688579">US8688579</a></td><td class="patent-data-table-td patent-date-value">Jun 8, 2011</td><td class="patent-data-table-td patent-date-value">Apr 1, 2014</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Automatic remote deposit image preparation apparatuses, methods and systems</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8699779">US8699779</a></td><td class="patent-data-table-td patent-date-value">Aug 28, 2009</td><td class="patent-data-table-td patent-date-value">Apr 15, 2014</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for alignment of check during mobile deposit</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8708227">US8708227</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 2006</td><td class="patent-data-table-td patent-date-value">Apr 29, 2014</td><td class="patent-data-table-td ">United Services Automobile Association (Usaa)</td><td class="patent-data-table-td ">Systems and methods for remote deposit of checks</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8712835">US8712835</a></td><td class="patent-data-table-td patent-date-value">Aug 24, 1999</td><td class="patent-data-table-td patent-date-value">Apr 29, 2014</td><td class="patent-data-table-td ">Rpx Corporation</td><td class="patent-data-table-td ">Method and apparatus for linking a web browser link to a promotional offer</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8762357">US8762357</a></td><td class="patent-data-table-td patent-date-value">Feb 27, 2012</td><td class="patent-data-table-td patent-date-value">Jun 24, 2014</td><td class="patent-data-table-td ">Ellie Mae. Inc.</td><td class="patent-data-table-td ">Enterprise security management system using hierarchical organization and multiple ownership structure</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8781206">US8781206</a></td><td class="patent-data-table-td patent-date-value">Feb 15, 2013</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Cummins-Allison Corp.</td><td class="patent-data-table-td ">Optical imaging sensor for a document processing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090265385">US20090265385</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 18, 2008</td><td class="patent-data-table-td patent-date-value">Oct 22, 2009</td><td class="patent-data-table-td ">Beland Paula M</td><td class="patent-data-table-td ">Insurance document imaging and processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20100027062">US20100027062</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 24, 2009</td><td class="patent-data-table-td patent-date-value">Feb 4, 2010</td><td class="patent-data-table-td ">Canon Kabushiki Kaisha</td><td class="patent-data-table-td ">Information processing apparatus, job processing method, and storage medium</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20110091109">US20110091109</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 22, 2010</td><td class="patent-data-table-td patent-date-value">Apr 21, 2011</td><td class="patent-data-table-td ">Abbyy Software Ltd</td><td class="patent-data-table-td ">Method of pre-analysis of a machine-readable form image</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20130202185">US20130202185</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 3, 2012</td><td class="patent-data-table-td patent-date-value">Aug 8, 2013</td><td class="patent-data-table-td ">Scientific Games International, Inc.</td><td class="patent-data-table-td ">Method for optically decoding a debit or credit card</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/CN100483442C?cl=en">CN100483442C</a></td><td class="patent-data-table-td patent-date-value">Aug 16, 2001</td><td class="patent-data-table-td patent-date-value">Apr 29, 2009</td><td class="patent-data-table-td ">国际商业机器公司</td><td class="patent-data-table-td ">Identification separation and compression of multiple forms with mutants</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1128278A1?cl=en">EP1128278A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 23, 2000</td><td class="patent-data-table-td patent-date-value">Aug 29, 2001</td><td class="patent-data-table-td ">SER Systeme AG Produkte und Anwendungen der Datenverarbeitung</td><td class="patent-data-table-td ">Method and apparatus for processing electronic documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1636671A2?cl=en">EP1636671A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 5, 2004</td><td class="patent-data-table-td patent-date-value">Mar 22, 2006</td><td class="patent-data-table-td ">Opex Corporation</td><td class="patent-data-table-td ">Method and apparatus for processing mail to obtain image data of contents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO1995032456A2?cl=en">WO1995032456A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 12, 1995</td><td class="patent-data-table-td patent-date-value">Nov 30, 1995</td><td class="patent-data-table-td ">Quintiles Transnational Corp</td><td class="patent-data-table-td ">Electronic document management system with document imaging</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000068811A1?cl=en">WO2000068811A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 27, 2000</td><td class="patent-data-table-td patent-date-value">Nov 16, 2000</td><td class="patent-data-table-td ">Network Forensics Inc</td><td class="patent-data-table-td ">System and method for capturing network data and identifying network events therefrom</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2001063467A1?cl=en">WO2001063467A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 2, 2001</td><td class="patent-data-table-td patent-date-value">Aug 30, 2001</td><td class="patent-data-table-td ">Alexander Goerke</td><td class="patent-data-table-td ">Method and apparatus for processing electronic documents</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2002063546A1?cl=en">WO2002063546A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 16, 2001</td><td class="patent-data-table-td patent-date-value">Aug 15, 2002</td><td class="patent-data-table-td ">Ibm</td><td class="patent-data-table-td ">Identification , separation and compression of multiple forms with mutants</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc715/defs715.htm&usg=AFQjCNEsvPOacMHcG92b6Esmd6a_S2NVkg#C715S229000">715/229</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc715/defs715.htm&usg=AFQjCNEsvPOacMHcG92b6Esmd6a_S2NVkg#C715S273000">715/273</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc707/defs707.htm&usg=AFQjCNE7Q7Bg2eD2wcE_fXEcdOe7Yesevw#C707SE17009">707/E17.009</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009000000">G06K9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=B07C0003000000">B07C3/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009030000">G06K9/03</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0001000000">H04N1/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0009200000">G06K9/20</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0001320000">H04N1/32</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0017300000">G06F17/30</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=B07C3/00">B07C3/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/32101">H04N1/32101</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/0082">H04N2201/0082</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/32561">H04N1/32561</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00">G06K9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/033">G06K9/033</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/0081">H04N2201/0081</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/0086">H04N2201/0086</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F17/30017">G06F17/30017</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/0087">H04N2201/0087</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3204">H04N2201/3204</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/32512">H04N1/32512</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3212">H04N2201/3212</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/32529">H04N1/32529</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K9/00442">G06K9/00442</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3274">H04N2201/3274</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2201/3205">H04N2201/3205</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=N4A1BAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N1/00204">H04N1/00204</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06K9/00L</span>, <span class="nested-value">H04N1/32J3B</span>, <span class="nested-value">H04N1/32J4B</span>, <span class="nested-value">H04N1/32C</span>, <span class="nested-value">G06K9/03A</span>, <span class="nested-value">G06K9/00</span>, <span class="nested-value">H04N1/32K</span>, <span class="nested-value">G06F17/30E</span>, <span class="nested-value">B07C3/00</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Jul 24, 2012</td><td class="patent-data-table-td ">B3</td><td class="patent-data-table-td ">Reexamination certificate third or further reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-16, 24-25, 32-41, 43-50, 61-70, 76-80 AND 92 IS CONFIRMED. CLAIMS 17-23, 26-31, 42, 51-60, 71-75 AND 81-91 WERE NOT REEXAMINED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 6, 2012</td><td class="patent-data-table-td ">B2</td><td class="patent-data-table-td ">Reexamination certificate second reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-16, 24-50, 61-70, 76-80 AND 92 IS CONFIRMED. CLAIMS 18-22, 51-60, 71-75, 81-88 AND 91 WERE PREVIOUSLY CANCELLED. CLAIMS 17, 23, 89 AND 90 ARE CANCELLED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 14, 2012</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120106</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 7, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100916</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Nov 2, 2010</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 1-17, 23-50, 61-70, 76-80, 89, 90 AND 92 IS CONFIRMED. CLAIMS 18-22, 51-60, 71-75, 81-88 AND 91 ARE CANCELLED.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Aug 24, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100604</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 13, 2010</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20100429</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 13, 2009</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20090717</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 19, 2008</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20071031</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 25, 2004</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 25, 2004</td><td class="patent-data-table-td ">SULP</td><td class="patent-data-table-td ">Surcharge for late payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">11</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 15, 2004</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">May 24, 2000</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 3, 1997</td><td class="patent-data-table-td ">SULP</td><td class="patent-data-table-td ">Surcharge for late payment</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 3, 1997</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 8, 1996</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 2, 1990</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">DIGITAL IMAGE SYSTEMS, CORPORATION, 3033 KELLWAY,</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST.;ASSIGNORS:LE BRUN, THOMAS Q.;CAGE, KERRY;ARNOLD, DENNIS D.;REEL/FRAME:005264/0876</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19900103</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:LE BRUN, THOMAS Q.;CAGE, KERRY;ARNOLD, DENNIS D.;REEL/FRAME:005264/0876</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">DIGITAL IMAGE SYSTEMS, CORPORATION, A CORP. OF TX,</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U38n0OE4aN3KuRdDlXsUTAdZSOk7A\u0026id=N4A1BAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U2k49in0zbVEyklCC56MegrbzRdfQ\u0026id=N4A1BAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2D2jcKUulNLRCMhrLfJNZyXzeQ3g","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/System_and_method_for_extraction_of_data.pdf?id=N4A1BAABERAJ\u0026output=pdf\u0026sig=ACfU3U3WD9vxQZNn7y9qTd9B8FhAJAi-wA"},"sample_url":"http://www.google.com/patents/reader?id=N4A1BAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>