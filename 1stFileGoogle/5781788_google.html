<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5781788 - Full duplex single clip video codec - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Full duplex single clip video codec"><meta name="DC.contributor" content="Beng-Yu Woo" scheme="inventor"><meta name="DC.contributor" content="Xiaoming Li" scheme="inventor"><meta name="DC.contributor" content="Vivian Hsiun" scheme="inventor"><meta name="DC.contributor" content="Avc Technology, Inc." scheme="assignee"><meta name="DC.date" content="1997-9-29" scheme="dateSubmitted"><meta name="DC.description" content="A single-chip video compression/decompression (video codec) chip is connected to receive a video input from a NTSC-compatible or PAL-compatible camera and a transmit channel. Video information from the camera or other video input source is compressed by the video codec and transmitted out in compressed form on a transmit channel. Concurrently, compressed video information is input to the video codec from a receive channel, decompressed and output to the monitor or other video output device, e.g., a television set. Only a separate single module of dynamic random access memory (DRAM) is needed to provide storage for incoming and outgoing video data, compressed bit streams and reconstructed pictures for both compression and decompression procedures. The compression of video information is by spatial decorrelation of the intraframe information, and temporal decorrelation of the interframe information. The communication channel bit rate is further reduced by quantization and variable length coding. Intraframe coding uses the redundancy of information within a single frame. The processing is done on blocks of eight-by-eight pixels. Both the luminance and chrominance pixel blocks are transform coded by a discrete cosine transform that changes the pixels from spatial domain to frequency domain."><meta name="DC.date" content="1998-7-14" scheme="issued"><meta name="DC.relation" content="US:5367629" scheme="references"><meta name="DC.relation" content="US:5379351" scheme="references"><meta name="DC.relation" content="US:5457780" scheme="references"><meta name="DC.relation" content="US:5541640" scheme="references"><meta name="DC.relation" content="US:5543939" scheme="references"><meta name="citation_patent_number" content="US:5781788"><meta name="citation_patent_application_number" content="US:08/939,997"><link rel="canonical" href="http://www.google.com/patents/US5781788"/><meta property="og:url" content="http://www.google.com/patents/US5781788"/><meta name="title" content="Patent US5781788 - Full duplex single clip video codec"/><meta name="description" content="A single-chip video compression/decompression (video codec) chip is connected to receive a video input from a NTSC-compatible or PAL-compatible camera and a transmit channel. Video information from the camera or other video input source is compressed by the video codec and transmitted out in compressed form on a transmit channel. Concurrently, compressed video information is input to the video codec from a receive channel, decompressed and output to the monitor or other video output device, e.g., a television set. Only a separate single module of dynamic random access memory (DRAM) is needed to provide storage for incoming and outgoing video data, compressed bit streams and reconstructed pictures for both compression and decompression procedures. The compression of video information is by spatial decorrelation of the intraframe information, and temporal decorrelation of the interframe information. The communication channel bit rate is further reduced by quantization and variable length coding. Intraframe coding uses the redundancy of information within a single frame. The processing is done on blocks of eight-by-eight pixels. Both the luminance and chrominance pixel blocks are transform coded by a discrete cosine transform that changes the pixels from spatial domain to frequency domain."/><meta property="og:title" content="Patent US5781788 - Full duplex single clip video codec"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("nKvtU_eTI_aosAS13YHwAg"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("PAN"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("nKvtU_eTI_aosAS13YHwAg"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("PAN"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5781788?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5781788"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=KDpHBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5781788&amp;usg=AFQjCNEIVZ5B0ccVmz_93oTxYxS7ca8_wg" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5781788.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5781788.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5781788" style="display:none"><span itemprop="description">A single-chip video compression/decompression (video codec) chip is connected to receive a video input from a NTSC-compatible or PAL-compatible camera and a transmit channel. Video information from the camera or other video input source is compressed by the video codec and transmitted out in compressed...</span><span itemprop="url">http://www.google.com/patents/US5781788?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5781788 - Full duplex single clip video codec</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5781788 - Full duplex single clip video codec" title="Patent US5781788 - Full duplex single clip video codec"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5781788 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/939,997</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Jul 14, 1998</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Sep 29, 1997</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">May 8, 1995</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08939997, </span><span class="patent-bibdata-value">939997, </span><span class="patent-bibdata-value">US 5781788 A, </span><span class="patent-bibdata-value">US 5781788A, </span><span class="patent-bibdata-value">US-A-5781788, </span><span class="patent-bibdata-value">US5781788 A, </span><span class="patent-bibdata-value">US5781788A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Beng-Yu+Woo%22">Beng-Yu Woo</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Xiaoming+Li%22">Xiaoming Li</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Vivian+Hsiun%22">Vivian Hsiun</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Avc+Technology,+Inc.%22">Avc Technology, Inc.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5781788.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5781788.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5781788.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (5),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (61),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (16),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (12)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5781788&usg=AFQjCNENyLMmRPnGkm1nn5w5HqIYxWk3rw">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5781788&usg=AFQjCNHJPD6oXP5cb-uVKPnYsSt5XwRfgQ">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5781788A%26KC%3DA%26FT%3DD&usg=AFQjCNEaEKMXWufKHkYaACEBmGDVcAm-hg">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT70360049" lang="EN" load-source="patent-office">Full duplex single clip video codec</invention-title></span><br><span class="patent-number">US 5781788 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37789339" lang="EN" load-source="patent-office"> <div class="abstract">A single-chip video compression/decompression (video codec) chip is connected to receive a video input from a NTSC-compatible or PAL-compatible camera and a transmit channel. Video information from the camera or other video input source is compressed by the video codec and transmitted out in compressed form on a transmit channel. Concurrently, compressed video information is input to the video codec from a receive channel, decompressed and output to the monitor or other video output device, e.g., a television set. Only a separate single module of dynamic random access memory (DRAM) is needed to provide storage for incoming and outgoing video data, compressed bit streams and reconstructed pictures for both compression and decompression procedures. The compression of video information is by spatial decorrelation of the intraframe information, and temporal decorrelation of the interframe information. The communication channel bit rate is further reduced by quantization and variable length coding. Intraframe coding uses the redundancy of information within a single frame. The processing is done on blocks of eight-by-eight pixels. Both the luminance and chrominance pixel blocks are transform coded by a discrete cosine transform that changes the pixels from spatial domain to frequency domain.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(8)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5781788-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5781788-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5781788-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5781788-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5781788-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5781788-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5781788-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5781788-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5781788-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5781788-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5781788-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5781788-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5781788-7.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5781788-7.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5781788-8.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5781788-8.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(12)</span></span></div><div class="patent-text"><div mxw-id="PCLM5255299" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A video codec, comprising:<div class="claim-text">a single semiconductor chip providing for a video input connection from a camera and a video output connection to a monitor of decompressed data, and a transmit channel and a receive channel of compressed data;</div> <div class="claim-text">an interface connected to the chip for external connection to a separate frame memory dynamic random access memory (DRAM) and that provides for interim storage of incoming and outgoing video data; and</div> <div class="claim-text">a video compressor/decompressor disposed fully within the chip and connected to compress video information received from said video input connection for output on said transmit channel, and connected to decompress video information received from said receive channel for output on said video output connection;</div> <div class="claim-text">wherein, said compression of video information is by spatial de-correlation of intraframe information and temporal decorrelation of interframe information, and said transmit and receive channels have communication channel bit rates reduced by quantization and variable length coding.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The video codec of claim 1, wherein:<div class="claim-text">the video compressor/decompressor includes intraframe coding based on single frame information redundancy, with processing done on blocks of eight-by-eight pixels, and both the luminance and chrominance pixel blocks are transform coded by a discrete cosine transform that changes the pixels from spatial domain to frequency domain.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The video codec of claim 2, wherein:<div class="claim-text">the video compressor/decompressor includes processors for transform coefficients that are arranged in the order of increasing frequency to prepare for run-length coding, a quantizer with adjustable threshold used to increase the zero run to enhance the coding efficiency;</div> <div class="claim-text">wherein said threshold is determined by a stepsize which can only be changed every n-number of macroblocks; and</div> <div class="claim-text">wherein, each of a series of frames is reconstructed using an inverse quantization, inverse zigzag operation, inverse discrete cosine transform.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The video codec of claim 3, wherein:<div class="claim-text">the video compressor/decompressor includes an interframe compression process that exploits the high correlations of temporally adjacent frames, and motion estimation of two sequential frames with motion vectors that are then included in an encoded bit stream of said transmit and receive channels.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The video codec of claim 1, wherein:<div class="claim-text">the video compressor/decompressor includes a process for comparing the macroblocks for the current frame at a time "t" with the macroblocks of a previous frame "t-1", and a displacement vector within a defined search window that provides a minimum cost function, which can be as simple as an absolute difference, is the motion vector and is encoded by variable length coding;</div> <div class="claim-text">wherein, motion estimation is provided for luminance data only, and motion vectors for chrominance data is about one-half of that for luminance data, for a particular macroblock of four luminance blocks and two chrominance blocks, such that a frame at "t-1" is motion-compensated using newly-computed motion vectors for both luminance and chrominance, and a motion-compensated frame "t-1" passed through an optional loop filter, is compared with a current frame "t";</div> <div class="claim-text">wherein, the difference between a current frame "t" and a reconstructed frame "t-1" is discrete-cosine-transform encoded, processed for zigzag and quantizer, and decoded with the inverse functions, and the decoded differences are added to motion-compensation to form a reconstructed current frame that is used for a motion estimation of the next frame "t+1".</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The video codec of claim 1, wherein:<div class="claim-text">the video compressor/decompressor includes decoding that is the opposite of encoding;</div> <div class="claim-text">wherein a bit stream received on said receive channel is variable-length coded, and the length of each code-word is determined, segmented and decoded;</div> <div class="claim-text">wherein, a frame start, a group-of-block start and a macroblock start are used for triggers wherein, intra-type macroblocks are decoded using inverse zigzag, inverse quantizer and inverse discrete cosine transform and sent out and stored in said frame memory DRAM;</div> <div class="claim-text">wherein, inter-type macroblocks include a decoded motion vector used for motion-compensation of a macroblock in a previous frame "t-1", and simultaneously the differences between "t" and "t-1" are decoded using inverse quantizer, zigzag and discrete cosine transform; and</div> <div class="claim-text">wherein, said decoded differences are added to a motion-compensated macroblock, to reconstruct a macroblock for a current frame "t" and stored in said frame memory DRAM for reconstructing a next frame "t+1".</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The video codec of claim 1, further comprising:<div class="claim-text">a framing processor connected between the video compressor/decompressor and each of said transmit channel and receive channel;</div> <div class="claim-text">wherein the framing processor includes an encoder to generate a forward-error-correction code within an outgoing error-correction-framing pattern in a transmitted bit stream directed to said transmit channel, and further includes a decoder to relock timing when timing lock is lost for an incoming error-correction-framing pattern in a received bit stream from said receive channel.</div> </div>
    </div>
    </div> <div class="claim"> <div num="8" class="claim">
      <div class="claim-text">8. A single-chip video codec for full-duplex communication of thirty frame per second video, comprising:<div class="claim-text">a single semiconductor integrated circuit (IC) with external connections provided for a dynamic random access memory (DRAM), a video source input, a video output, a transmit communications channel, a receive communications channel and a host buss for initialization and chip status communication;</div> <div class="claim-text">a memory controller fully disposed on the IC and having a connection to control an external memory module;</div> <div class="claim-text">resource sharing means fully disposed on the IC and connected to both an encoding bit stream and a decoding bit stream that flow through said external memory module for simultaneous video compression and decompression;</div> <div class="claim-text">said external memory module provides for segment storage of video compression and decompression frames, a transmit buffer and a receive buffer, and the memory controller includes means for user-programmable segment-storage sizes in said external memory module;</div> <div class="claim-text">a pipelined discrete cosine transform and quantization (DCTQ) means fully disposed on the IC and for producing one coefficient every two clock cycles in said video bitstreams and including matrix decomposition means for reducing a required number of multiplications and additions, wherein said DCTQ means performs both forward and inverse discrete cosine transform;</div> <div class="claim-text">motion-prediction means fully disposed on the IC and connected to said bitstreams and having an array of parallel-processing elements and multiport memories providing for full search of motion vectors, and means for accepting user-programmable weights input for motion estimation smoothing, wherein motion-compensated prediction is provided for both compression and decompression, for a type-inter or a type-intra compression decision, and for whether a loop filter should be on, and storage for a user-programmable bias;</div> <div class="claim-text">an on-chip microcomputer (CPU) fully disposed on the IC and for concurrent processing of said compression and decompression bitstreams with on-chip parameter busses for both address and data which allow addressing and parameter passing;</div> <div class="claim-text">direct communication channel connection means fully disposed on the IC and connected to said bitstreams and means for assigning different bit rates to said channels wherein spatial and temporal resolutions are automatically adjusted;</div> <div class="claim-text">host-programmable means in the DCTQ means for adaptive quantization and rate buffer control providing for the optimization of a variety of applications with individual environments, wherein problematic portions of each frame are favored with a disproportionate share of said compressed bitstreams to reduce compression artifact generation;</div> <div class="claim-text">an on-chip register file fully disposed on the IC and providing for real-time monitoring and control of the compression and decompression of said bitstreams; and</div> <div class="claim-text">video input and output means for pipelined encoding and decoding of macroblocks of video information providing for a minimization of throughput delays.</div> </div>
    </div>
    </div> <div class="claim"> <div num="9" class="claim">
      <div class="claim-text">9. A video codec, comprising:<div class="claim-text">a single semiconductor chip providing for a video input connection from a camera and a video output connection to a monitor of decompressed data, and a transmit channel and a receive channel of compressed data;</div> <div class="claim-text">an interface connected to the chip for external connection to a separate frame memory dynamic random access memory (DRAM) and provides for interim storage of incoming and outgoing video data;</div> <div class="claim-text">a video compressor/decompressor disposed fully within the chip and connected to compress video information received from said video input connection to be output on said transmit channel, and connected to decompress video information received from said receive channel to be output on said video output connection;</div> <div class="claim-text">wherein, said compression of video information is by spatial de-correlation of intraframe information, and temporal decorrelation of interframe information, and said transmit and receive channels have communication channel bit rates reduced by quantization and variable length coding;</div> <div class="claim-text">wherein, the video compressor/decompressor includes intraframe coding that uses the redundancy of information within a single frame, the processing is done on blocks of eight-by-eight pixels, and both the luminance and chrominance pixel blocks are transform coded by a discrete cosine transform that changes the pixels from spatial domain to frequency domain;</div> <div class="claim-text">wherein, the video compressor/decompressor includes transform coefficients that are arranged in the order of increasing frequency to prepare for run-length coding, a quantizer with adjustable threshold used to increase the zero run to enhance the coding efficiency;</div> <div class="claim-text">wherein, said threshold is determined by a stepsize which can only be changed every n-number of macroblocks; and</div> <div class="claim-text">wherein, each of a series of frames is reconstructed using an inverse quantization, an inverse zigzag operation, and an inverse discrete cosine transform.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The video codec of claim 9, wherein:<div class="claim-text">the video compressor/decompressor includes interframe compression that exploits the high correlations of temporally adjacent frames, and motion estimation of two sequential frames with motion vectors that are then included in an encoded bit stream of said transmit and receive channels.</div> </div>
    </div>
    </div> <div class="claim"> <div num="11" class="claim">
      <div class="claim-text">11. A video codec, comprising:<div class="claim-text">a single semiconductor chip providing for a video input connection from a camera and a video output connection to a monitor of decompressed data, and a transmit channel and a receive channel of compressed data;</div> <div class="claim-text">an interface connected to the chip for external connection to a separate frame memory dynamic random access memory (DRAM) and provides for interim storage of incoming and outgoing video data;</div> <div class="claim-text">a video compressor/decompressor disposed fully within the chip and connected to compress video information received from said video input connection to be output on said transmit channel, and connected to decompress video information received from said receive channel to be output on said video output connection;</div> <div class="claim-text">wherein, said compression of video information is by spatial de-correlation of intraframe information, and temporal decorrelation of interframe information, and said transmit and receive channels have communication channel bit rates reduced by quantization and variable length coding;</div> <div class="claim-text">wherein, the video compressor/decompressor compares the macroblocks for the current frame at a time "t" with the macroblocks of a previous frame "t-1", and a displacement vector within a defined search window that provides a minimum cost function, which can be as simple as an absolute difference, is the motion vector and is encoded by variable length coding;</div> <div class="claim-text">wherein, motion estimation is provided for luminance data only, and motion vectors for chrominance data is about one-half of that for luminance data, for a particular macroblock of four luminance blocks and two chrominance blocks, such that a frame at "t-1" is motion-compensated using newly-computed motion vectors for both luminance and chrominance, and a motion-compensated frame "t-1" passed through an optional loop filter, is compared with a current frame "t"; and</div> <div class="claim-text">wherein, the difference between a current frame "t" and a reconstructed frame "t-1" is discrete-cosine-transform encoded, processed for zigzag and quantizer, and decoded with the inverse functions, and the decoded differences are added to motion-compensation to form a reconstructed current frame that is used for a motion estimation of the next frame "t+1".</div> </div>
    </div>
    </div> <div class="claim"> <div num="12" class="claim">
      <div class="claim-text">12. A video codec, comprising:<div class="claim-text">a single semiconductor chip providing for a video input connection from a camera and a video output connection to a monitor of decompressed data, and a transmit channel and a receive channel of compressed data;</div> <div class="claim-text">an interface connected to the chip for external connection to a separate frame memory dynamic random access memory (DRAM) and provides for interim storage of incoming and outgoing video data;</div> <div class="claim-text">a video compressor/decompressor disposed fully within the chip and connected to compress video information received from said video input connection to be output on said transmit channel, and connected to decompress video information received from said receive channel to be output on said video output connection;</div> <div class="claim-text">wherein, said compression of video information is by spatial de-correlation of intraframe information, and temporal decorrelation of interframe information, and said transmit and receive channels have communication channel bit rates reduced by quantization and variable length coding;</div> <div class="claim-text">wherein, the video compressor/decompressor includes decoding that is the opposite of encoding;</div> <div class="claim-text">wherein a bit stream received on said receive channel is variable-length coded, and the length of each code-word is determined, segmented and decoded;</div> <div class="claim-text">wherein, a frame start, a group-of-block start and a macroblock start are used for triggers;</div> <div class="claim-text">wherein, intra-type macroblocks are decoded using inverse zigzag, inverse quantizer and inverse discrete cosine transform and sent out and stored in said frame memory DRAM;</div> <div class="claim-text">wherein, inter-type macroblocks include a decoded motion vector used for motion-compensation of a macroblock in a previous frame "t-1", and simultaneously the differences between "t" and "t-1" are decoded using inverse quantizer, zigzag and discrete cosine transform; and</div> <div class="claim-text">wherein, said decoded differences are added to a motion-compensated macroblock, to reconstruct a macroblock for a current frame "t" and stored in said frame memory DRAM for reconstructing a next frame "t+1".</div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67147231" lang="EN" load-source="patent-office" class="description">
    <p>This application is a continuation of application Ser. No. 08/437,276 filed on May 8, 1995 now abandoned.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>The invention relates generally to semiconductor devices and video circuitry and more specifically to single-chip video compression/decompression processors (video codecs) with digital data compression capabilities sufficient to sustain video conferencing over long distance telephone connections. Further applications include interactive multimedia, audio-visual conferencing system, video telephone and remote video data-base retrieval. The international telephone union (ITU) has defined a group of standards for visual telephone applications which are collectively known to artisans as "Px64". Such standards promise type-inter-operability among different videophone manufacturers' commercial products.</p>
    <p>2. Description of the Prior Art</p>
    <p>Television comprises video signals that describe the hue, color saturation and luminance of every picture element (pixel) in a frame at a basic frame rate of thirty frames per second (fps). Each frame can have close to one thousand raster lines each with one thousand individual pixels (720 active pixels per line). Therefore every frame can comprise close to one million pixels. Since thirty fps are typically scanned, close to thirty million pixels per second would ordinarily need to be transmitted from a video camera to a monitor.</p>
    <p>Digital compression and motion prediction techniques can drastically reduce the required video channel bandwidth. Motion prediction techniques encode motion vectors and compare the last frame sent, motion-compensated, to the current frame and take the difference. Then only the motion vectors and the difference are transmitted. Obviously for picture subjects that do not move much, such as "talking heads" in video conferencing, the difference information can fall to near zero and an ordinary telephone line could be used to handle the resulting signal bandwidth.</p>
    <p>Although video industry standards specify data formats, frame structures, procedures for establishing connections and recovery from fault conditions, they do not specify how to pre-filter and post-filter pictures, mode criteria for skip frames etc., motion estimation for search window, method, cost function, and step-size determination for quantization. The International Telephone Union (ITU) has produced a so-called industry standard, "Px64", within which there is an item "H.261", comprising a recommendation for a video codec. The exchange data format is specified such that audiovisual teleservices vendors can follow this format to decode compressed information.</p>
    <p>Fandrianto, et al., describe in U.S. Pat. No. 5,379,351, issued Jan. 3, 1995, video compression and decompression (codec) processing and processors. Such patent is incorporated herein by reference. A vision processor is described that has both motion estimation and discrete cosine transform functions, e.g., in a chip set. The motion estimation part includes an image memory and a search memory with each memory having a write port and two read ports. For motion vector searching, an arithmetic logic unit (ALU) does averaging and difference operations on pixels in the frame and search memories.</p>
    <heading>SUMMARY OF THE PRESENT INVENTION</heading> <p>It is therefore an object of the present invention to provide a single-chip video codec for simultaneous encoding/decoding up to full Px64 resolution at thirty frames per second of completely asynchronous full-duplex transmit and receive channels.</p>
    <p>It is another object of the present invention to provide a single-chip video codec with on-chip clock generator which generates operating frequencies as high as 27 MHz, 40.5 MHz, 54 MHz, 67.5 MHz and 81 MHz.</p>
    <p>It is an object of the present invention to provide a single-chip video codec for thirty frames per second common intermediate format (CIF), with 288 lines with 352 pixels per line, and quarter CIF (QCIF), with 144 lines with 176 pixels per line, coding and decoding.</p>
    <p>It is another object of the present invention to provide a single-chip video codec with on-chip error handling capability, programmable buffer control, and a flexible user interface with on-chip programmable registers that are both readable and writable, allowing spatial and temporal resolution selection and channel-rate selection.</p>
    <p>It is a still further object of the present invention to provide a single-chip video codec with a dynamic random access memory (DRAM) on-chip controller and interface that allows the use of low cost memory system of external DRAMs.</p>
    <p>It is another object of the present invention to provide a single-chip video codec with a video interface, host interface and interfaces to time-division-multiplexed channels.</p>
    <p>It is an object of the present invention to provide a single-chip video codec with an on-chip processor to execute both parallel and pipelined operations.</p>
    <p>Briefly, a video codec embodiment of the present invention comprises video compression and decompression processors, and single-chip architectures for intra-frame coding/decoding, discrete cosine transform, inter-frame coding and decoding, motion estimation, motion-compensated prediction, quantization, variable length coding and decoding and error detection and correction, and frame synchronization. Full-duplex video data bitstreams are simultaneously encoded and decoded with shared resources.</p>
    <p>An advantage of the present invention is that a single-chip video codec is provided for simultaneous encoding/decoding of completely asynchronous full-duplex transmit and receive channels.</p>
    <p>Another advantage of the present invention is that a single-chip video codec with on-chip clock generator which generates operating frequencies as high as 27 MHz, 40.5 MHz, 54 MHz, 67.5 MHz and 81 MHz.</p>
    <p>A further advantage of the present invention is that a single-chip video codec is provided for thirty frame per second CIF and QCIF coding and decoding.</p>
    <p>An advantage of the present invention is that a single-chip video codec is provided with on-chip error handling capability, buffer control, and a flexible user interface with on-chip programmable registers that are both readable and writable.</p>
    <p>Another advantage of the present invention is that a single-chip video codec is provided with a DRAM interface that allows the use of low cost memory system of external DRAMs.</p>
    <p>It is another advantage of the present invention that a single-chip video codec is provided with a video interface, host interface and interfaces to time-division-multiplexed channels.</p>
    <p>It is an advantage of the present invention that a single-chip video codec is provided with an on-chip processor to execute both parallel and pipelined operations.</p>
    <p>These and other objects and advantages of the present invention will no doubt become obvious to those of ordinary skill in the art after having read the following detailed description of the preferred embodiment which is illustrated in the drawing figures.</p>
    <heading>IN THE DRAWINGS</heading> <p>FIG. 1 is a block diagram of a single-chip video codec of the present invention shown in a system with DRAM, video input, video output, host and communication channel connections;</p>
    <p>FIG. 2 is a block diagram of the codec of FIG. 1 showing the internal functional parts that are implemented with a combination of hardware and firmware;</p>
    <p>FIG. 3 is a more detailed block diagram of the single-chip video codec of FIG. 2;</p>
    <p>FIG. 4A is a block diagram of the CPU included in the video codec of FIGS. 2 and 3;</p>
    <p>FIG. 4B is a diagram of the five-stage pipelining operation of the CPU of FIG. 4A;</p>
    <p>FIG. 5 is a flowchart of a rate buffer control method of the present invention included in the codec of FIGS. 2 and 3;</p>
    <p>FIG. 6 is a prior flow diagram representing the functional connections of the "H.261" encoding process standard, which is implemented by a transmitting part of the video codec of FIG. 2; and</p>
    <p>FIG. 7 is a prior flow diagram representing the functional connections of the "H.261" standard decoding process, which is implemented by a receiving part of the video codec of FIG. 2.</p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading> <p>FIG. 1 illustrates a video system embodiment of the present invention, referred to by the general reference numeral 10. A single-chip video compression/decompression (video codec) chip 12 is connected to receive a video input from a NTSC-compatible or PAL-compatible camera 14 and a monitor 16. ("NTSC" and "PAL" are respective television-broadcast standards used in the United States and Europe.) A separate dynamic random access memory (DRAM) 18 provides storage for incoming and outgoing video data. Video information from the camera 14 or other video input source is compressed by the video codec 12 and transmitted out in compressed form on a transmit channel 20. Conversely, compressed video information is input to the video codec 12 from a receive channel 22, decompressed and output to the monitor 16 or other video output device, e.g., a television set.</p>
    <p>The compression of video information is by spatial de-correlation of the intraframe information, and temporal decorrelation of the interframe information. The communication channel bit rate is further reduced by quantization and variable length coding.</p>
    <p>Intraframe coding uses the redundancy of information within a single frame. The processing is done on blocks of eight-by-eight pixels. Both the luminance and chrominance pixel blocks are transform coded by a discrete cosine transform that changes the pixels from spatial domain to frequency domain.</p>
    <p>The transform coefficients are then arranged in the order of increasing frequency, e.g., in zigzag fashion, to prepare for run-length coding. A quantizer with adjustable threshold is used to increase the zero run to enhance the coding efficiency. This threshold is determined by the stepsize, which can only be changed every eleven macroblocks. The policy of changing stepsize is not specified in the important industry standards. However, it can be related to how full the transmit buffer is. In order to emulate the behavior of the decoder, the frame is reconstructed using the inverse quantization, inverse zigzag operation, inverse discrete cosine transform. Intraframe compression can achieve a compression ratio of about 20:1. In order to have a higher compression ratio, interframe compression is done taking advantage of the fact that adjacent frames are highly correlated temporally. Motion estimation uses two sequential frames, and motion vectors are then included in the encoded bit stream.</p>
    <p>For interframe pictures, the macroblocks for the current frame at time "t" are compared with the macroblocks of the previous frame "t-1". The displacement vector within a defined search window (a maximum of 46<sup>2</sup> in H.261) that provides a minimum cost function which can be as simple as an absolute difference is the motion vector. This motion vector is encoded by variable length coding. Motion estimation is provided for luminance data only. Motion vectors for the chrominance data is one-half of that for luminance data, for a particular macroblock of four luminance blocks and two chrominance blocks. The frame at "t-1" is motion-compensated using newly-computed motion vectors for both luminance and chrominance. A motion-compensated frame "t-1" passed through an optional loop filter, is compared with a current frame "t". The difference between a current frame "t" and a reconstructed frame "t-1" is discrete-cosine-transform encoded, processed for zigzag and quantizer, and decoded with the inverse functions. The decoded differences are added to motion-compensation to form a reconstructed current frame that is used for a motion estimation of the next frame "t+1".</p>
    <p>As to be expected, decoding is the opposite of encoding. The bit stream is error detected and corrected, when error control is enabled. Since the data is variable-length coded, the length of each code-word is determined, segmented and decoded. From the decoded data, the frame start, group-of-block start and macroblock start are used to trigger various parts of the video codec 12. Within a macroblock, if it is type-intra, it is decoded using inverse zigzag, inverse quantizer and inverse discrete cosine transform and is sent out and stored in the frame memory in DRAM 18. If it is type-inter, the decoded motion vector is used to motion-compensate the macroblock in a previous frame "t-1". At the same time, the differences between "t" and "t-1" are decoded using inverse quantizer, zigzag and discrete cosine transform. These decoded differences, are added to a motion-compensated macroblock, to reconstruct macroblock for the current frame "t". The re-constructed macroblock is the output of the decoder and is stored in the frame memory in DRAM 18 for reconstructing the next frame "t+1".</p>
    <p>As shown in FIG. 2, the video codec 12 processor comprises a video input/output buffer 30, a motion prediction processor 32, a discrete cosine transform and quantization block 34, a variable-length coder and decoder 36, a framing processor 38, a register file 40, a DRAM controller and scheduler 42, a host interface 44, and a microcomputer (CPU) 46.</p>
    <p>The video input/output buffer (VP) 30 is such that the incoming pixels are buffered and stored in the external DRAM 18 for raster-scan-to-block conversion. Macroblocks of such pixel data are fetched and used for discrete cosine transform in intra-frame compression and for motion-estimation in inter-frame compression in the motion prediction processor (MP) 32.</p>
    <p>The discrete cosine transform and quantization (DCTQ) block 34 provides for discrete cosine transform, zigzag conversion and quantization, both forward and inverse. For discrete cosine transforms, dedicated logic is used to do row and column transformations. Bits in the intermediate result are preserved for output coefficient precision that exceeds the ITU and IEEE standard requirements. Quantization logic makes the trade-off between spatial and temporal resolutions. Saturation logic is included to prevent overflow.</p>
    <p>The quantized discrete cosine transform coefficients are sent to the variable length coder and decoder (VLC/VLD) 36. Run-length and variable-length Huffman coding are done. The inverse is provided for the decoder. Picture headers and macro-block headers are added to the video data and errors are attended.</p>
    <p>In the framing processor (FP) 38, a BCH (511, 493) forward error correction code is generated for inclusion in the transmitted bit stream. The encoder includes an error correction framing pattern. In the decoder, relock timing for the error corrector framing is re-established when lock is lost.</p>
    <p>The register file 40 allows users to control the operations of the video codec 12, to adjust its parameters for specific applications, and to interrogate the status of operations and to monitor the behavior of the internal coding/decoding processes.</p>
    <p>The DRAM controller 42 manages access to the frame buffer and the transmit/receive buffer. It schedules memory cycles for the encoder and decoder. In addition, users can set the sizes of encoding and decoding frame buffers, as well as the transmit and receive buffers.</p>
    <p>The host interface 44 controls access to and from the host bus 24. The CPU 46 coordinates multiple pipelined and concurrent operations within the video codec 12, making sure that important resources are ready during the timing slot opportunities for a particular data stream and routing of the data.</p>
    <p>Within the video codec 12, there are several busses for transferring data, address and control/parameters, an internal memory data (IMD 31:0!) bus 48, an internal parameter address (IPA 4:0!) bus 50, and an internal parameter data (IPD 4:0!) bus 52.</p>
    <p>FIG. 3 shows the video codec 12 in more detail than FIG. 2. A set of encoder and decoder general registers 60 are interfaced to the host interface bus 24. A set of encoder and decoder parameter registers 62 are connected to the internal parameter address and data buses 50 and 52. A coding, control and sequencer 64 provides overall management of the resources of the video codec 12. For example, the coding, control and sequencer 64 coordinates the bitstream compression and decompression process.</p>
    <p>The motion processor 32 comprises a current macroblock buffer 66 that receives video input from a local source. A motion processor parameter register 68 accepts control information, e.g., from the host via the host interface 24 and parameter buses 50 and 52. An array of sixteen processors 70 selects a best match macroblock 72 and has an output connection to an adder subtractor 74. A search window 76 contains several macroblocks that are operated on by the processor array 70. The parameters provide programmable weights in calculating the cost function of motion estimation so that the motion vectors selection and inter/intra decisions can be influenced by users. A video output, e.g., to the monitor 16, is provided from a reconstructed macroblock 78.</p>
    <p>When encoding, the motion predictor 32 computes the difference between two sequentially-adjacent video frames and supplies a frame-difference data, instead of the frame itself, to the DCTQ 34. Any temporal redundancy, where two time-sequential frame elements are repeated, is thus removed from the video frame, and a lower bit rate results. Reconstructed frames are used for predicting a next frame, e.g., from the frame prediction plus the transmitted frame difference.</p>
    <p>When decoding, the motion predictor 32 reconstructs each video frame by adding a received-frame difference to a frame prediction based on previous reconstructed frames. The motion predictor 32 processes the main bitstreams between the video input/output ports and the forward/inverse discrete cosine transform transformers. The encoding process is activated by a video input macroblock start signal. The decoding process is activated by a signal from the DCTQ 34.</p>
    <p>For full-duplex thirty frame-per-second CIF video streams and assuming a clock frequency of fifty-four MHz, the motion predictor 32 must process a macroblock for the encoding channel and a macroblock for the decoding channel in 54*10<sup>6</sup> /(30*396)=4545 clock cycles (T)=one macroblock cycle (MT). The encoding operations consist of motion estimation, type-intra/type-inter decision, loop filtering, motion-compensated prediction, and feedback reconstruction, while the decoding operations consist only of the reconstruction with optional loop filtering. The number of computations required for the motion estimation for one macro-block is 16<sup>4</sup> =65,536 subtract-magnitude-accumulates for a full search.</p>
    <p>The motion predictor 32 uses a two-stage pipelined approach. In a given macroblock cycle, while encoding frame prediction and decoding reconstructions are being done for a current set of macroblocks (both encoding and decoding), the motion estimation is done for a next macroblock (encoding only). The motion estimation depends on processor array 70 for a full search. This dedicated processor array breaks down a macroblock motion estimation theoretically to 4096 T, assuming each processor computes a subtract-magnitude-accumulate in a single clock cycle "T". In encoding the macroblock, prediction and reconstruction are simultaneous, so the adder/subtractor 74 includes independent subtractor and adder functions. The adder part of adder/subtractor 74 is shared in decoding reconstruction. The workload of the adder part of adder/subtractor 74 is estimated by 64*6*2=768 T, and the workload of the adder is about 1536 T, since they both process each pixel in every two clock cycles. Loop filtering follows loading of the matched previous macroblock into its buffer and is shared between encoding and decoding, e.g., for 64*6*2=768 T.</p>
    <p>Various data rates can be interfaced to the video input/output ports. The discrete cosine transform transformers use two cycle-per-byte bursts. Supporting memory buffers are used for the current encoding macroblock, the current reconstructed macroblock, and the matched previous macroblock. This requires a minimum memory burst bandwidth of one byte every two clock cycles for the 32-bit DRAM controller 42. To be able to use a whole macroblock cycle for estimating a macroblock, both the current frame macroblock and the previous frame search window are double buffered. A motion estimation is done for one macroblock in its search window. The next macroblock and its search window are fetched from DRAM 18 into the buffers 76 for next macroblock estimation. Because the search windows of two adjacent macroblocks overlap by sixteen pixels, the left half of the search window is obtained by shifting from the right half. Only the right half of a search window needs be fetched from DRAM 18. Ping-pong switching provides for the double buffering and window shifting. The memory traffic requirement in a macroblock cycle comprises 256*2=512 byte reads for the next motion estimation, 64*2=128 byte reads for encoding prediction, 384 byte writes for encoding reconstruction, 384 byte reads for decoding prediction, and 384 byte writes for decoding reconstruction. The total memory traffic is 1024 byte memory reads and 768 byte memory writes through the internal memory data IMD 31:0! bus 48 in each macroblock cycle.</p>
    <p>The motion predictor 32 communicates with the CPU 46 through the IPA 4:0! bus 50 and the IPD 7:0! bus 52 and uses separate registers in register files 60 and 62 for encoding and decoding. When writing, a first register specifies guidance information of the next macroblock processing. When writing, the first register specifies the status information of the previous just processed macroblock. Other registers specify the location information of the next (previous) macroblock.</p>
    <p>As shown in FIG. 3, the DCTQ 34 includes a first dimension (row) processor 80, a row/column RAM (RCRAM) 81, and a second dimensional (column) processor 82. A DCTQ parameter register 83 is connected to the parameter address and data buses 50 and 52. A state machine 84 drives the processors 80 and 82. A zigzag (ZZ) unit 84 and a quantizer (Q) 86 complete the DCTQ 34. The DCTQ 34 is host-programmable by virtue of the parameter register 83, which allows for adaptive quantization and rate buffer control. This provides for the optimization of a variety of applications in different environments. In essence, problematic portions of each frame susceptible to compression artifacts are favored with a disproportionate share of the compressed bitstreams, thereby reducing compression-artifact generation. DCTQ 34 includes high-speed algorithm specific processors that compute both the two-dimensional forward and inverse discrete cosine transform over eight-by-eight data blocks.</p>
    <p>In a forward discrete cosine transform mode, the DCTQ processor 34 accepts each image data block in row-major format at two clock cycles per pixel. In an inverse discrete cosine transform mode, the DCTQ processor 34 accepts column-major format and return row-major data at two clocks cycles per pixel. In both modes, the processor 34 operates on continuous data at high rates.</p>
    <p>Zigzag and quantization processing is placed down-stream of forward discrete cosine transforms, and up-stream of inverse discrete cosine transforms. In forward (encoding) mode, the coefficients are re-ordered into a one-dimensional array by reading out the entries of the two-dimensional array along a zigzag route. Following such zigzag, the processing provides for variable threshold and quantization. In inverse mode, the coefficients are reconstructed and passed to the inverse discrete cosine transform process.</p>
    <p>Each processor 80 and 82 includes arithmetic elements connected to the row-column memory 81. Each such arithmetic element includes a multiplier and two adders for computing an eight-point one-dimensional discrete cosine transform in sixteen clock cycles. The row-column memory 81 is preferably implemented as a two-port, sixty-four word RAM for re-arranging the data format, e.g., from an incoming eight-by-eight block to an output eight-by-eight block. In coding, the first arithmetic element 80 computes the discrete cosine transform of each consecutive row of eight pixels. The results are written into the RCRAM 81. After one dimensional transforms are computed, the second arithmetic element 82 computes the discrete cosine transform of each consecutive column, while the first arithmetic element 80 computes the discrete cosine transforms of the rows of the next block of data.</p>
    <p>The zigzag memory 84 is a dual-port, sixty-four word RAM for reformatting data into a zigzag format for later run-length encoding. Zigzag scanning of the coefficients provides a string of coefficients from low to high frequency. After such a zigzag reordering, the data is processed by three functions through the quantizer 86. A variable threshold is created that helps set coefficients to zero and increase the "run" length. A quantization of the coefficients after threshold is processed. And the quantized coefficients are either clipped for an eight-bit range, or the de-quantized coefficients are clipped to a twelve-bit coefficient, depending on whether coding or decoding.</p>
    <p>The VLC/VLD 36 includes a four luminance (Y) block and two chrominance (U and V) block buffer 88. Run length patterns are matched with a pattern detector 90. A run length coder (RLC) 92 is connected to a multiplexer (MUX) 94. Variable length coding parameters are stored in a register 96 for the control of a variable length coder (VLC) 98. A fist-in-first-out (FIFO) 100 communicates the coded macroblocks to the DRAM 18 via the data bus 48. A four luminance (Y) block and two chrominance block buffer 102 is connected to a run-length decoder (RLD) 104 on the receive side. Variable length decoding parameters are stored in a register 106 for the control of a variable length decoder (VLD) 108. A first-in-first-out (FIFO) 110 communicates the coded macroblocks to the DRAM 18 via the data bus 48.</p>
    <p>The VLC/VLD 36 uses on-chip buffer 88 for storing a current macroblock of four luminance blocks and two chrominance blocks, the run-length coder (RLC) and the variable length coder (VLC). Such a macroblock buffer is necessary because the coded block pattern and type cannot be determined until a whole macroblock has been scanned.</p>
    <p>Transform coefficients are input to VLC/VLD 36 from the DCTQ 34 at a rate of one coefficient every two clock cycles, first the four luminance and then the two chrominance blocks. These coefficients are stored in the buffer, and zero-crossings are counted.</p>
    <p>Local memory and the DRAM controller 42 provide data transfer supports to the pipelined video codec operations on a macroblock cycle basis. The DRAM 18 is partitioned by the video codec 12 into four sections, (1) an encoder frame buffer (EFB), (2) a decoder frame buffer (DFB), (3) a transmission channel buffer (TCB), and (4) a reception channel buffer (RCB). The section start address and the section size in words or double-words are programmable, and the section start addresses must be at word and double-word boundaries respectively. All of the memory sections operate in a wrap-around fashion, wherein the read/write pointer automatically jumps back to the starting address after hitting the section's ending boundary. The order of data storage in each section is sequentially consistent with the H.261 standard and thus DRAM 18 is preferably a page-mode type to allow faster memory accesses.</p>
    <p>The DRAM controller 42 responds with two sixteen block memory access requests in each macroblock cycle. The order is consistent with the parallel micro operations of the macroblocks. During each memory service, DRAM controller 42 fetches the starting address offsets, if needed, and the required number of memory transfers from the unit to be serviced. It then does memory address incrementing, and transfers a given number of words or double words between the local memory and the serviced unit. The DRAM controller 42 also provides all the ordinary housekeeping and interfacing conventionally necessary for commercially-available 64K, 128K, and 256K dynamic/static RAMs of either sixteen bit words or thirty-two-bit double words.</p>
    <p>The framing processor (FP) 38 receives such macroblocks from the DRAM. A FP parameter register 112 controls the operation of a BCH coder 114. A pair of serializers/deserializers 116 and 117 provide format changes for the BCH coder 114 and a BCH decoder 118 that are connected to the transmit channel 20 and receive channel 22, respectively. The VLC/VLD 36 is not directly connected to the FP 38, data between them passes through the DRAM 18 first.</p>
    <p>The DRAM controller and scheduler 42 is comprised of a set of DRAM control registers connected to the host interface 44 and a memory arbiter 122.</p>
    <p>In operation, an encoder read access is initiated by an input to the motion predictor 32 and an encoder read acknowledge is issued. At the start of service, the motion predictor 32 transfers macroblock location offsets and count information to the DRAM controller 42 through the IMD 31:0! bus 48. Then DRAM controller 42 sets up the block starting local memory address and transfers the given number of words or double words to the external DRAM 18.</p>
    <p>The first encoder read access {er1} fetches 16×32 luminance pixels to form a right half of a search window, e.g., in search window 76. The frame boundary conditions are handled by the motion predictor 32. These 16×32 luminance pixels come across as six macroblocks stored in the frame buffer. The DRAM controller 42 accesses these six areas separately.</p>
    <p>In pseudocode this can be implemented as follows,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________initialize at second picture start ERA = encoder frame buffer startingaddress{efa}:At ERRQ1 do {issue ERAK1;repeat (4) {for (i=0to7) do {fetch from TMP=ERA-11H*384/4-16*8/4+16*i/4;fetch from TMP=ERA-11H*384/4+16*i/4;}repeat (8) {for (i = 0 to 7) do {fetch from TMP = ERA - 16 * 8/4 + 16 * i/4;fetch from TMP = ERA + 16 * i/4;}}repeat (4) {for (i = 0 to 7) do {fetch from TMP=ERA+11H*384/4-16 *8/4+16*i/4;fetch from TMP=ERA+11H*384/4+16*i/4;}}}______________________________________</pre>
    
    <p>where, H=2 for CIF, and H=1 for QCIF, and H is the relative sub-sampling frequency.</p>
    <p>A second encoder read access {er2} fetches the best matching two chrominance blocks after motion vectors are estimated to the best matching on-chip buffer. The motion predictor 32 guarantees that the two chrominance blocks are within the picture boundaries, and within the group of blocks in out implementation, and a smaller search window. To be consistent with the decoder read request design, this read request supports crossing group boundaries request and the standard 31 by 31 search window.</p>
    <p>In pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________At ERRQ2 do {issue ERAK2;for (-my to 1) {for (j= mx/4! to 1) do {fetch from TMP=ERA-(11H+1) * 384/4 +256+8* i/4+ j/4!;for (j=0 to   (8+mx)/4!) do {fetch from TMP=ERA-(11H+1) * 384/4 +256+8* i/4+ j/4!;}for (j=0 to  (8+mx)/4!) do {fetch from TMP=ERA-(11H+1) * 384/4 +256+8* i/4+ j/4!;}}for (i=0 to my+8) {for (j= mx/4! to 0) do {fetch from TMP=ERA-(+1) * 384/4 +256+8* i/4+ j/4!;}for (j=0 to   (8+mx)/4!) do {fetch from TMP=ERA-(0) * 384/4 +256+8* i/4+ j/4!;}for (j=0 to   (8+mx)/4!) do {fetch from TMP=ERA-(-1) * 384/4 +256+8* i/4+ j/4!;}}for (i=0 to my+8) {for (j= mx/4! to 0) do {fetch from TMP=ERA+(11H-1) * 384/4 +256+8* i/4+ j/4!;}for (j=0 to   (8+mx)/4!) do {fetch from TMP=ERA+(11H) * 384/4 +256+8* i/4+ j/4!;}for (j=0 to   (8+mx)/4!) do {fetch from TMP=ERA+(11H+1) * 384/4+256+8* i/4+ j/4!;}}repeat all the above for V by adding TMP with 64;update ERA=ERA+384;}______________________________________</pre>
    
    <p>The encoder write {ew} is an access that stores one whole macroblock sequentially from the reconstruction adder into the encoder frame buffer.</p>
    <p>In pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Initialize at programming EWA = encoder frame buffer starting address{efa};At EWRQ do {issue EWAK;repeat (96) { store IMD 31:0! into mem EWA!; EWA++ };______________________________________</pre>
    
    <p>The decoder read {dr} is an access that fetches the best matching macroblock (both luminance and chrominances) to the on-chip best matching buffer. The pixels to-be-fetched flow across group boundaries. The search window size is 31×31. The chrominances are as specified in {er} with {dra} replacing {era}, while the luminance is fetched as follows in pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________At DRRQ do {issue DRAK;for (-my to 1) {for (j= mx/4! to 1) do {fetch from TMP=ERA-(11H+1) * 384/4 + 16 * i/4+ j/4!;for (j=0 to   (16+mx)/4!) do {fetch from TMP=ERA-(11H+1) * 384/4 + 16 * i/4+ j/4!;}for (j=0 to   (16+mx)/4!) do {fetch from TMP=ERA-(11H+1) * 384/4 + 16 * i/4+ j/4!;}}for (i=0 to my+16) {for (j= mx/4! to 0) do {fetch from TMP=ERA-(+1) * 384/4 +16 * i/4+ j/4!;}for (j=0 to   (16+mx/4!) do {fetch from TMP=ERA-(0) * 384/4 +16 * i/4+ j/4!;}for (j=0 to   (16+mx/4!) do {fetch from TMP=ERA-(-1) * 384/4 +16 * i/4+ j/4!;}}for (i=0 to my+16) {for (j= mx/4! to 0) do {fetch from TMP=ERA+(11H-1) * 384/4 +16 * i/4+ j/4!;}for (j=0 to   (16+mx)/4!) do {fetch from TMP=ERA+(11H) * 384/4 +16 * i/4+ j/4!;}for (j=0 to   (16+mx)/4!) do {fetch from TMP=ERA+(11H+1) * 384/4+16 * i/4+ j/4!;}}}______________________________________</pre>
    
    <p>The decoder write {dw} is an access that stores one whole macroblock sequentially from the reconstruction adder into the decoder frame buffer.</p>
    <p>In pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Initialize at programming DWA = decoder frame buffer starting address{dfa};At DWRQ do {issue DWAK;repeat (96) { store IMD 31:0! into mem DWA!; DWA++ };______________________________________</pre>
    
    <p>The transmission Read {tr} is an access that fetches 512 bits=16 double-words sequentially from transmission channel buffer to the transmission channel interface 20.</p>
    <p>In pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Initialize at programming TAR = transmission channel buffer startingaddress {tea};At TR. do {issue TRAK;repeat (16) { fetch from mem TAR! onto IMD 31:0!; TRA++ };______________________________________</pre>
    
    <p>The reception read {tw} is an access that fetches 512 bits=16 double-words sequentially from the variable length coder into the transmission channel buffer.</p>
    <p>In pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Initialize at programming TWA = transmission channel buffer startingaddress {tea};At TWRQ do {issue TWAK;repeat (16) { store IMD 31:0! into mem TWA!; TWA++ };______________________________________</pre>
    
    <p>The reception read {read} is an access that fetches 512 bits=16 double words sequentially from reception channel buffer to the variable length decoder.</p>
    <p>In pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Initialize at programming RRA = reception channel buffer startingaddress{rca};At RRRQ do {issue RRAK;repeat (16) { fetch from mem RRA! onto IMD 31:0!; RRA++ };______________________________________</pre>
    
    <p>The reception write {rw} is an access stores 512 bits=16 double words sequentially from the reception channel interface into the reception channel buffer.</p>
    <p>In pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Initialize at programming RWA = reception channel buffer startingaddress {rca};At RWRQ do {issue RWAK;repeat (16) { store IMD 31:0! into mem RWA!; RWA++ };______________________________________</pre>
    
    <p>The refresh access {rf} is two refresh modes (RAS-only, CAS-before-RAS) that are supported by the DRAM controller 42, while the number of fresh clock cycles in each macroblock is programmable in RFC (should be the row length). The starting row address in also programmable, row first address (RFA) with default 0.</p>
    <p>In pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Initialize RFA = 0 and program RFC;At every RFRQ do {repeat (RFC) { memory refresh read at RFA; RFA++ };______________________________________</pre>
    
    <p>The host memory access {ha} is provided for debugging uses. The memory controller assumes the read and write accesses do not happen at the same time.</p>
    <p>In pseudocode,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________Initialize at programming HMA and HMC;At HRRQ do {issue HRAK;repeat (HMC) { fetch mem HMA! onto IMD 31:0!; HMA++ };At HWRQ do {issue HWAK;repeat (HMC) { store IMD 31:0! into mem HMA}; HMA++ };}______________________________________</pre>
    
    <p>For a single-chip implementation of the video codec 12, external connection pins should preferably be provided for a clock, a hardware or software reset, an eighteen-bit memory address bus, a thirty-two bit memory data bus, a row select address for DRAM row address strobe that latches the memory address into DRAM's row address registers, a column select address for DRAM column address strobe that latches the memory address into DRAM's column address registers, a memory read enable to activate the memory's output buffer, and a memory write enable to latch memory data into the memory cells selected.</p>
    <p>Forward error correction by the decoder is recommended by H.261, but not required. The error correction code recommended is BCH (511, 493). Such code is capable of correcting any combination of two or fewer errors in a block of 511 bits, which include eighteen bits of correction parity bits. The generator polynomial of the galois field (GF) (2<sup>9</sup>) is:</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="equation">g(x)=(x<sup>9</sup> +x<sup>4</sup> +1) (x<sup>9</sup> +x<sup>6</sup> +x<sup>4</sup> +x<sup>3</sup> +1).</pre>
    
    <p>The video codec 12 includes a buffer control strategy for optimum picture quality which is determined by the number of bits in the buffer for the encoded picture, for a given channel rate and frame rate, where Rv is channel bit rate for video, f is frame rate (the user can assign the frame rate for the application), CIF is spatial resolution, whether CIF (352×288) or QCIF (176×144), LUT is look up table, and Tenc is encoder delay. For integrated services digital network (ISDN/BRI) the channel rate is 128K bits per second (bps), of which 96K bps of the bandwidth can be assigned to the video communication.</p>
    <p>Within standard H.261, a reconstruction rule is given, but the rule of quantization is left to the implementation. However, the quantizer has the most impact on picture quality. A proper implementation of quantization reduces the artifacts introduced by compression.</p>
    <p>The video codec 12 allows access by the user for the elimination of some undesirable artifacts such as quantizer overload. In the following pseudocode, "step" is the step-size for the quantizer, "QUANT" is a parameter generated by the encoder, "T" is the threshold which defines the dead zone,</p>
    <p>
      </p> <pre xml:space="preserve" listing-type="tabular">______________________________________step &gt;= 2*QUANT; orstep = 2 * a * QUANT  where a &gt; 1 and is a function of QUANT; andT = step + d  where d &gt; 0 (for example 0.5).If     x = input of quantizer, and  y = output of quantizer  thenfor x&gt;T  y = max trunc (x/step -d), 1!;for x&lt;-T y = min trunc (x/step + d), -1!; orelse     y = 0______________________________________</pre>
    
    <p>T, d can be normalized to step.</p>
    <p>FIG. 4A shows an exemplary implementation of the coding control and sequencer 64, which includes an instruction memory bank 130 and a data memory bank 132, e.g., each 256×16, are connected to a sixteen-bit arithmetic logic unit (ALU) 134 and sixteen registers 136. Sixteen-bit instructions, each with three or four fields, provide load/store, ALU, jump/branch operations and are five-stage pipelined, as represented in FIG. 4B. The coding control and sequencer 64 is roughly equivalent to the CPU 46 in FIG. 2.</p>
    <p>FIG. 5 illustrates the steps of a method 200 for rate buffer control. A step 202 begins at reset and inputs Rv, f and CIF. A step 204 loads default parameters, e.g., target number of bits per frame (Bf), buffer threshold to decide whether to drop next frame (Bufth) Buth=Rv*(1/f+Tenc)+Bmin, quantizer threshold (Qth) where frame drops if Quant&gt;Qth (initially Quant=Qth), number of bits per frame at which to set Quant=Qhi (Bhi), Qhi, or user can load a quantizer look-up table (Q-LUT). Buffer maximum (Bmax) is 256K bits for CIF and 64K bits for QCIF. Buffer minimum (Bmin) is 493 bits. A step 206 starts a new frame process. A step 208 tests for the end of a macroblock (MB). A step 210 tests the number of bits generated in the current frame up to the i-th MB. A step 212 tests for Bi&gt;Bhi. The buffer content at the i-th MB (Bufi) is tested in a step 214 with Bufi&lt;Bmin. The number of bits used in the last 12(3) GOBs is Bg. A step 216 tests for the end of GOB. A step 218 tests for the end of frame. A step 220 checks to see if the buffer content at the end of the frame (Buf) exceeds Bufth. A step 222 skips the next n frames. If the answer to step 210 is yes, a step 224 causes coding to stop until the next frame and returns control to step 206. If the answer in step 212 is yes, a step 226 sets Quant=Qhi and passes control ahead to step 218. If the answer in step 214 is yes, a step 228 does macroblock stuffing. If the answer in step 216 is yes, a step 230 calculates Bg and Qav and finds a new value for Quant from the look-up table. Control is then passed to step 218. If the answer in step 218 is no, a step 232 processes the next macroblock by passing control to step 208.</p>
    <p>FIG. 6 is a prior flow diagram representing the functional connections of the "H.261" encoding process standard, which is implemented by the video codec (FIG. 2) while in encoder mode. An encoder process 300 includes a differencer 302 that accepts eight-by-eight blocks of current video and reconstructed video. A summer 304 feeds a discrete cosine transform (DCT) process 306. A zigzag and quantizer (ZZQ) processor 308 includes a zigzag RAM memory (ZZ) 310 and a quantizer (Q) 312. The ZZQ processor 308 drives an inverse zigzag processor 314, an inverse quantizer 316 and an inverse DCT 318. These, in turn feed a mixer 320 from a summer 322 to supply a frame memory 324 (e.g., in DRAM 18). The motion processor (MP) 32 implements both a motion compensation processor 326 that accepts input from the frame memory 324 and a motion estimator 328. A two-dimensional loop filter 330 supplies a delayed signal to the summer 322 and differencer 302. The array of processors 70 is used to concurrently find any motion vectors between current macro-blocks and previous macroblocks.</p>
    <p>FIG. 7 is a prior flow diagram representing the functional connections of the "H.261" standard decoding process, which is implemented by the video codec (FIG. 2) while in decoder mode. A decoder process 400 accepts the encoded data into an error controller 402. A buffer 404 supplies incoming data to an inverse variable length controller (VLC) 406, an inverse zigzag memory (ZZMEM) 408, an inverse quantizer 410, and an inverse DCT processor 412. A mixer 414 produces a decoded output which is copied to a frame memory 416, e.g., in DRAM 48. A motion compensator 418 receives a motion vector from the inverse VLC 406 and a decoded frame from the frame memory 416. A loop filter 420, receives the motion compensated frames and drives a summer 422 that receives intra/inter frame control.</p>
    <p>Although the present invention has been described in terms of the presently preferred embodiment, it is to be understood that the disclosure is not to be interpreted as limiting. Various alterations and modifications will no doubt become apparent to those skilled in the art after having read the above disclosure. Accordingly, it is intended that the appended claims be interpreted as covering all alterations and modifications as fall within the true spirit and scope of the invention.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5367629">US5367629</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 18, 1992</td><td class="patent-data-table-td patent-date-value">Nov 22, 1994</td><td class="patent-data-table-td ">Sharevision Technology, Inc.</td><td class="patent-data-table-td ">Digital video compression system utilizing vector adaptive transform</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5379351">US5379351</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 19, 1992</td><td class="patent-data-table-td patent-date-value">Jan 3, 1995</td><td class="patent-data-table-td ">Integrated Information Technology, Inc.</td><td class="patent-data-table-td ">Video compression/decompression processing and processors</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5457780">US5457780</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 6, 1992</td><td class="patent-data-table-td patent-date-value">Oct 10, 1995</td><td class="patent-data-table-td ">Shaw; Venson M.</td><td class="patent-data-table-td ">System for producing a video-instruction set utilizing a real-time frame differential bit map and microblock subimages</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5541640">US5541640</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 19, 1995</td><td class="patent-data-table-td patent-date-value">Jul 30, 1996</td><td class="patent-data-table-td ">Larson; Craig R.</td><td class="patent-data-table-td ">Videophone for simultaneous audio and video communication via a standard telephone line</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5543939">US5543939</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 2, 1994</td><td class="patent-data-table-td patent-date-value">Aug 6, 1996</td><td class="patent-data-table-td ">Massachusetts Institute Of Technology</td><td class="patent-data-table-td ">Video telephone systems</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5995513">US5995513</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 8, 1995</td><td class="patent-data-table-td patent-date-value">Nov 30, 1999</td><td class="patent-data-table-td ">Sgs-Thomson Microelectronics S.A.</td><td class="patent-data-table-td ">Multitask processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6035349">US6035349</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 9, 1997</td><td class="patent-data-table-td patent-date-value">Mar 7, 2000</td><td class="patent-data-table-td ">Electrolnics And Telecommunications Research Institute</td><td class="patent-data-table-td ">Structure of portable multimedia data input/output processor and method for driving the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6040861">US6040861</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 10, 1997</td><td class="patent-data-table-td patent-date-value">Mar 21, 2000</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Adaptive real-time encoding of video sequence employing image statistics</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6072548">US6072548</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 28, 1997</td><td class="patent-data-table-td patent-date-value">Jun 6, 2000</td><td class="patent-data-table-td ">Lsi Logic Corporation</td><td class="patent-data-table-td ">Video decoder dynamic memory allocation system and method allowing variable decoded image size</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6097757">US6097757</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 16, 1998</td><td class="patent-data-table-td patent-date-value">Aug 1, 2000</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Real-time variable bit rate encoding of video sequence employing statistics</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6121998">US6121998</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 9, 1998</td><td class="patent-data-table-td patent-date-value">Sep 19, 2000</td><td class="patent-data-table-td ">8×8, Inc.</td><td class="patent-data-table-td ">Apparatus and method for videocommunicating having programmable architecture permitting data revisions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6456335">US6456335</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 6, 1998</td><td class="patent-data-table-td patent-date-value">Sep 24, 2002</td><td class="patent-data-table-td ">Fujitsu Limited</td><td class="patent-data-table-td ">Multiple picture composing method and multiple picture composing apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6539001">US6539001</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 16, 1998</td><td class="patent-data-table-td patent-date-value">Mar 25, 2003</td><td class="patent-data-table-td ">Nec Corporation</td><td class="patent-data-table-td ">Visual telephone apparatus and data compression multiplexing method therefor as well as recording medium on which data compression multiplexing control program is recorded</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6738424">US6738424</a></td><td class="patent-data-table-td patent-date-value">Jul 3, 2000</td><td class="patent-data-table-td patent-date-value">May 18, 2004</td><td class="patent-data-table-td ">Objectvideo, Inc.</td><td class="patent-data-table-td ">Scene model generation from video for use in video processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6914908">US6914908</a></td><td class="patent-data-table-td patent-date-value">Oct 19, 1999</td><td class="patent-data-table-td patent-date-value">Jul 5, 2005</td><td class="patent-data-table-td ">Sgs-Thomson Microelectronics S.A.</td><td class="patent-data-table-td ">Multitask processing system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7039817">US7039817</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 7, 2003</td><td class="patent-data-table-td patent-date-value">May 2, 2006</td><td class="patent-data-table-td ">Sun Microsystems, Inc.</td><td class="patent-data-table-td ">Method and apparatus for supplying power to a processor at a controlled voltage</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7154948">US7154948</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 30, 2001</td><td class="patent-data-table-td patent-date-value">Dec 26, 2006</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Video codec system, method for processing data between system and host system, and encoding/decoding control method in the system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7158571">US7158571</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 11, 2001</td><td class="patent-data-table-td patent-date-value">Jan 2, 2007</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">System and method for balancing video encoding tasks between multiple processors</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7376185">US7376185</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 22, 2003</td><td class="patent-data-table-td patent-date-value">May 20, 2008</td><td class="patent-data-table-td ">Leonid Yavits</td><td class="patent-data-table-td ">Video encoding and video/audio/data multiplexing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7376186">US7376186</a></td><td class="patent-data-table-td patent-date-value">Apr 9, 2003</td><td class="patent-data-table-td patent-date-value">May 20, 2008</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Motion estimation with weighting prediction</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7477691">US7477691</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 22, 1999</td><td class="patent-data-table-td patent-date-value">Jan 13, 2009</td><td class="patent-data-table-td ">Snell &amp; Wilcox Limited</td><td class="patent-data-table-td ">Video signal compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7606427">US7606427</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 21, 2004</td><td class="patent-data-table-td patent-date-value">Oct 20, 2009</td><td class="patent-data-table-td ">Qualcomm Incorporated</td><td class="patent-data-table-td ">Efficient rate control techniques for video encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7634148">US7634148</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 27, 2005</td><td class="patent-data-table-td patent-date-value">Dec 15, 2009</td><td class="patent-data-table-td ">Ntt Docomo, Inc.</td><td class="patent-data-table-td ">Image signal transforming and inverse-transforming method and computer program product with pre-encoding filtering features</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7672372">US7672372</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 24, 2003</td><td class="patent-data-table-td patent-date-value">Mar 2, 2010</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and system for data management in a video decoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7751480">US7751480</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 13, 2008</td><td class="patent-data-table-td patent-date-value">Jul 6, 2010</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Video encoding and video/audio/data multiplexing device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7769274">US7769274</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 6, 2005</td><td class="patent-data-table-td patent-date-value">Aug 3, 2010</td><td class="patent-data-table-td ">Mediatek, Inc.</td><td class="patent-data-table-td ">Video processing and optical recording using a shared memory</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7778476">US7778476</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 21, 2005</td><td class="patent-data-table-td patent-date-value">Aug 17, 2010</td><td class="patent-data-table-td ">Maxim Integrated Products, Inc.</td><td class="patent-data-table-td ">System and method for transform coding randomization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7801383">US7801383</a></td><td class="patent-data-table-td patent-date-value">May 15, 2004</td><td class="patent-data-table-td patent-date-value">Sep 21, 2010</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Embedded scalar quantizers with arbitrary dead-zone ratios</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7903742">US7903742</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 9, 2003</td><td class="patent-data-table-td patent-date-value">Mar 8, 2011</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7974340">US7974340</a></td><td class="patent-data-table-td patent-date-value">Apr 7, 2006</td><td class="patent-data-table-td patent-date-value">Jul 5, 2011</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive B-picture quantization control</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7995649">US7995649</a></td><td class="patent-data-table-td patent-date-value">Apr 7, 2006</td><td class="patent-data-table-td patent-date-value">Aug 9, 2011</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Quantization adjustment based on texture level</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8059721">US8059721</a></td><td class="patent-data-table-td patent-date-value">Apr 7, 2006</td><td class="patent-data-table-td patent-date-value">Nov 15, 2011</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Estimating sample-domain distortion in the transform domain with rounding compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8130828">US8130828</a></td><td class="patent-data-table-td patent-date-value">Apr 7, 2006</td><td class="patent-data-table-td patent-date-value">Mar 6, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adjusting quantization to preserve non-zero AC coefficients</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8144785">US8144785</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Mar 27, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8144786">US8144786</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Mar 27, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8144787">US8144787</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Mar 27, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8149924">US8149924</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Apr 3, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8155208">US8155208</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Apr 10, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video decoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8184694">US8184694</a></td><td class="patent-data-table-td patent-date-value">Feb 16, 2007</td><td class="patent-data-table-td patent-date-value">May 22, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Harmonic quantizer scale</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8189933">US8189933</a></td><td class="patent-data-table-td patent-date-value">Mar 31, 2008</td><td class="patent-data-table-td patent-date-value">May 29, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Classifying and controlling encoding quality for textured, dark smooth and smooth video content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8238424">US8238424</a></td><td class="patent-data-table-td patent-date-value">Feb 9, 2007</td><td class="patent-data-table-td patent-date-value">Aug 7, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Complexity-based adaptive preprocessing for multiple-pass video compression</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8243797">US8243797</a></td><td class="patent-data-table-td patent-date-value">Mar 30, 2007</td><td class="patent-data-table-td patent-date-value">Aug 14, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Regions of interest for quality adjustments</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8249145">US8249145</a></td><td class="patent-data-table-td patent-date-value">Sep 29, 2011</td><td class="patent-data-table-td patent-date-value">Aug 21, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Estimating sample-domain distortion in the transform domain with rounding compensation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8284836">US8284836</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 22, 2008</td><td class="patent-data-table-td patent-date-value">Oct 9, 2012</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Motion compensation method and apparatus to perform parallel processing on macroblocks in a video decoding system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8290050">US8290050</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8290051">US8290051</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8290052">US8290052</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8290053">US8290053</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Oct 16, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8295354">US8295354</a></td><td class="patent-data-table-td patent-date-value">Oct 1, 2010</td><td class="patent-data-table-td patent-date-value">Oct 23, 2012</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8311088">US8311088</a></td><td class="patent-data-table-td patent-date-value">Feb 7, 2005</td><td class="patent-data-table-td patent-date-value">Nov 13, 2012</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Method and system for image processing in a microprocessor for portable video communication devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8331438">US8331438</a></td><td class="patent-data-table-td patent-date-value">Jun 5, 2007</td><td class="patent-data-table-td patent-date-value">Dec 11, 2012</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive selection of picture-level quantization parameters for predicted video pictures</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8406301">US8406301</a></td><td class="patent-data-table-td patent-date-value">Apr 9, 2003</td><td class="patent-data-table-td patent-date-value">Mar 26, 2013</td><td class="patent-data-table-td ">Thomson Licensing</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video encoding</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8422546">US8422546</a></td><td class="patent-data-table-td patent-date-value">May 25, 2005</td><td class="patent-data-table-td patent-date-value">Apr 16, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive video encoding using a perceptual model</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8442337">US8442337</a></td><td class="patent-data-table-td patent-date-value">Apr 18, 2007</td><td class="patent-data-table-td patent-date-value">May 14, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Encoding adjustments for animation content</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8483290">US8483290</a></td><td class="patent-data-table-td patent-date-value">Jan 14, 2010</td><td class="patent-data-table-td patent-date-value">Jul 9, 2013</td><td class="patent-data-table-td ">Intel Corporation</td><td class="patent-data-table-td ">Method and system for data management in a video decoder</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8498335">US8498335</a></td><td class="patent-data-table-td patent-date-value">Mar 26, 2007</td><td class="patent-data-table-td patent-date-value">Jul 30, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Adaptive deadzone size adjustment in quantization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8503536">US8503536</a></td><td class="patent-data-table-td patent-date-value">Apr 7, 2006</td><td class="patent-data-table-td patent-date-value">Aug 6, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Quantization adjustments for DC shift artifacts</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8576908">US8576908</a></td><td class="patent-data-table-td patent-date-value">Jul 2, 2012</td><td class="patent-data-table-td patent-date-value">Nov 5, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Regions of interest for quality adjustments</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8588298">US8588298</a></td><td class="patent-data-table-td patent-date-value">May 10, 2012</td><td class="patent-data-table-td patent-date-value">Nov 19, 2013</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Harmonic quantizer scale</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8711925">US8711925</a></td><td class="patent-data-table-td patent-date-value">May 5, 2006</td><td class="patent-data-table-td patent-date-value">Apr 29, 2014</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Flexible quantization</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8767822">US8767822</a></td><td class="patent-data-table-td patent-date-value">Jun 29, 2011</td><td class="patent-data-table-td patent-date-value">Jul 1, 2014</td><td class="patent-data-table-td ">Microsoft Corporation</td><td class="patent-data-table-td ">Quantization adjustment based on texture level</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20090175345">US20090175345</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 22, 2008</td><td class="patent-data-table-td patent-date-value">Jul 9, 2009</td><td class="patent-data-table-td ">Samsung Electronics Co., Ltd.</td><td class="patent-data-table-td ">Motion compensation method and apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1478185A2?cl=en">EP1478185A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 20, 2004</td><td class="patent-data-table-td patent-date-value">Nov 17, 2004</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">A method of protecting image data in the frame buffer of video compression system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1677542A2?cl=en">EP1677542A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 15, 2005</td><td class="patent-data-table-td patent-date-value">Jul 5, 2006</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Method and system for video motion processing</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP1689186A1?cl=en">EP1689186A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 19, 2005</td><td class="patent-data-table-td patent-date-value">Aug 9, 2006</td><td class="patent-data-table-td ">Broadcom Corporation</td><td class="patent-data-table-td ">Image processing in portable video communication devices</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2004008762A1?cl=en">WO2004008762A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 14, 2003</td><td class="patent-data-table-td patent-date-value">Jan 22, 2004</td><td class="patent-data-table-td ">Thomson Licensing Sa</td><td class="patent-data-table-td ">Adaptive weighting of reference pictures in video decoding</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc712/defs712.htm&usg=AFQjCNFSlkDLYE-yriA4W3Ix_OZ4YREIEw#C712S001000">712/1</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07093">375/E07.093</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07094">375/E07.094</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc370/defs370.htm&usg=AFQjCNEr5EDctcusna2HU7Iww2g4dx3BIw#C370S276000">370/276</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc370/defs370.htm&usg=AFQjCNEr5EDctcusna2HU7Iww2g4dx3BIw#C370S278000">370/278</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc370/defs370.htm&usg=AFQjCNEr5EDctcusna2HU7Iww2g4dx3BIw#C370S282000">370/282</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc375/defs375.htm&usg=AFQjCNFcuagMfSu6xvEzMh0uBF37Cw37ZA#C375SE07211">375/E07.211</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007500000">H04N7/50</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06T0009000000">G06T9/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=H04N0007260000">H04N7/26</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00781">H04N19/00781</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00484">H04N19/00484</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=KDpHBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N19/00478">H04N19/00478</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">H04N7/26L</span>, <span class="nested-value">H04N7/26L2</span>, <span class="nested-value">H04N7/50</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Dec 17, 2009</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 8, 2008</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1, 2 AND 8-12 ARE CANCELLED. CLAIMS 3 AND 5-7 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIM 4, DEPENDENT ON AN AMENDED CLAIM, IS DETERMINED TO BE PATENTABLE. NEW CLAIMS 13-26 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jan 10, 2006</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 14, 2004</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20040727</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 2, 2003</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">ADVANCED VIDEO TECHNOLOGIES LLC, NEW YORK</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:GROSS, J. NICHOLAS;REEL/FRAME:013699/0026</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20030430</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">EPOGY COMMUNICATIONS INC., CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AVC TECHNOLOGY INC.;REEL/FRAME:013758/0214</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20000717</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">GROSS, JOHN NICHOLAS, CALIFORNIA</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:EPOGY COMMUNICATIONS, INC.;REEL/FRAME:013699/0024</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20030115</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">ADVANCED VIDEO TECHNOLOGIES LLC 75 MONTEBELLO ROAD</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">EPOGY COMMUNICATIONS INC. 1271 OAKMEAD PARKWAYSUNN</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">GROSS, JOHN NICHOLAS 726 DUBOCE AVENUESAN FRANCISC</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 14, 2003</td><td class="patent-data-table-td ">PRDP</td><td class="patent-data-table-td ">Patent reinstated due to the acceptance of a late maintenance fee</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20030415</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 31, 2003</td><td class="patent-data-table-td ">SULP</td><td class="patent-data-table-td ">Surcharge for late payment</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 31, 2003</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 10, 2002</td><td class="patent-data-table-td ">FP</td><td class="patent-data-table-td ">Expired due to failure to pay maintenance fee</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20020714</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 15, 2002</td><td class="patent-data-table-td ">REIN</td><td class="patent-data-table-td ">Reinstatement after maintenance fee payment confirmed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Feb 6, 2002</td><td class="patent-data-table-td ">REMI</td><td class="patent-data-table-td ">Maintenance fee reminder mailed</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 29, 1998</td><td class="patent-data-table-td ">CC</td><td class="patent-data-table-td ">Certificate of correction</td><td class="patent-data-table-td "></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U175vGxbE8cL21_ekYQjCsjYhNVUw\u0026id=KDpHBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U0zeQ8whwSCeGqbOt7Dfe7UZ92dcQ\u0026id=KDpHBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U2I9UW7lt3ERJDmN5ee3NpblbogUg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Full_duplex_single_clip_video_codec.pdf?id=KDpHBAABERAJ\u0026output=pdf\u0026sig=ACfU3U022yTwNqskQpcqtESycHvITsNd-A"},"sample_url":"http://www.google.com/patents/reader?id=KDpHBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>