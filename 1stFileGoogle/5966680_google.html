<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US5966680 - Motion sickness/vertigo prevention device and method - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Motion sickness/vertigo prevention device and method"><meta name="DC.contributor" content="Hanan Butnaru" scheme="inventor"><meta name="DC.contributor" content="Butnaru; Hanan" scheme="assignee"><meta name="DC.date" content="1997-2-13" scheme="dateSubmitted"><meta name="DC.description" content="A device and method which operates as an artificial labyrinth to eliminate sensory mismatch between the natural labyrinth/vestibular system and the vision system of an individual. The present invention provides an alternative means for the user to determine the true orientation of his body with respect to the surrounding environment. The method can be effected by means of a device which senses true body orientation and displays corresponding visual orientation cues that the brain can use to confirm other visual position information. The display can be projected into space in front of the user, directly onto the user&#39;s retina, or effected by pictorial scene averaging. The device is particularly useful in the rehabilitation treatment of persons suffering from vestibular nervous system defect or damage, and in providing relief to those suffering from the symptoms of nausea and/or vertigo which are often experienced as a result of the aforementioned sensory mismatch."><meta name="DC.date" content="1999-10-12" scheme="issued"><meta name="DC.relation" content="US:5051735" scheme="references"><meta name="DC.relation" content="US:5138555" scheme="references"><meta name="DC.relation" content="US:5613022" scheme="references"><meta name="DC.relation" content="US:5717392" scheme="references"><meta name="DC.relation" content="US:5727098" scheme="references"><meta name="DC.relation" content="US:5729366" scheme="references"><meta name="DC.relation" content="US:5745054" scheme="references"><meta name="citation_reference" content="&quot;A Retinal Display for Virtual-Environment Applications&quot; by Joel S. Kollin, 1993 International Symposium, Digest of Technical Papers, vol. XXIV (p. 827)."><meta name="citation_reference" content="&quot;Performance and Well-Being Under Tilting Conditions: The Effects of Visual Reference and Artificial Horizon&quot; by A. Rolnick and W. Bles, Aviation Space Environmental Medicine, 60(8); 779-785, 1989 Aug."><meta name="citation_reference" content="A Retinal Display for Virtual Environment Applications by Joel S. Kollin, 1993 International Symposium, Digest of Technical Papers, vol. XXIV (p. 827)."><meta name="citation_reference" content="Performance and Well Being Under Tilting Conditions: The Effects of Visual Reference and Artificial Horizon by A. Rolnick and W. Bles, Aviation Space Environmental Medicine, 60(8); 779 785, 1989 Aug."><meta name="citation_patent_number" content="US:5966680"><meta name="citation_patent_application_number" content="US:08/800,266"><link rel="canonical" href="http://www.google.com/patents/US5966680"/><meta property="og:url" content="http://www.google.com/patents/US5966680"/><meta name="title" content="Patent US5966680 - Motion sickness/vertigo prevention device and method"/><meta name="description" content="A device and method which operates as an artificial labyrinth to eliminate sensory mismatch between the natural labyrinth/vestibular system and the vision system of an individual. The present invention provides an alternative means for the user to determine the true orientation of his body with respect to the surrounding environment. The method can be effected by means of a device which senses true body orientation and displays corresponding visual orientation cues that the brain can use to confirm other visual position information. The display can be projected into space in front of the user, directly onto the user&#39;s retina, or effected by pictorial scene averaging. The device is particularly useful in the rehabilitation treatment of persons suffering from vestibular nervous system defect or damage, and in providing relief to those suffering from the symptoms of nausea and/or vertigo which are often experienced as a result of the aforementioned sensory mismatch."/><meta property="og:title" content="Patent US5966680 - Motion sickness/vertigo prevention device and method"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("VpbtU-jZHevNsQSh2oLYDA"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("ITA"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("VpbtU-jZHevNsQSh2oLYDA"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("ITA"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us5966680?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US5966680"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=jqhMBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS5966680&amp;usg=AFQjCNGijtHzCidlhqZCLUeSny8K7s6CfQ" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US5966680.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US5966680.pdf"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US5966680" style="display:none"><span itemprop="description">A device and method which operates as an artificial labyrinth to eliminate sensory mismatch between the natural labyrinth/vestibular system and the vision system of an individual. The present invention provides an alternative means for the user to determine the true orientation of his body with respect...</span><span itemprop="url">http://www.google.com/patents/US5966680?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US5966680 - Motion sickness/vertigo prevention device and method</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US5966680 - Motion sickness/vertigo prevention device and method" title="Patent US5966680 - Motion sickness/vertigo prevention device and method"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US5966680 A</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 08/800,266</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Oct 12, 1999</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Feb 13, 1997</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Feb 15, 1996</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/CA2197588A1">CA2197588A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/CA2197588C">CA2197588C</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">08800266, </span><span class="patent-bibdata-value">800266, </span><span class="patent-bibdata-value">US 5966680 A, </span><span class="patent-bibdata-value">US 5966680A, </span><span class="patent-bibdata-value">US-A-5966680, </span><span class="patent-bibdata-value">US5966680 A, </span><span class="patent-bibdata-value">US5966680A</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Hanan+Butnaru%22">Hanan Butnaru</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Butnaru%3B+Hanan%22">Butnaru; Hanan</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US5966680.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5966680.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US5966680.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (7),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (4),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (34),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (12),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (11)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/5966680&usg=AFQjCNEkRDEBFAruTigFewbaN7qS5BW6CQ">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D5966680&usg=AFQjCNF5frMgUbf7b4PYKycfFcvrdUofzg">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D5966680A%26KC%3DA%26FT%3DD&usg=AFQjCNFPbBAursN_VWCVKV8UW-ttDOitWg">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT54505358" lang="EN" load-source="patent-office">Motion sickness/vertigo prevention device and method</invention-title></span><br><span class="patent-number">US 5966680 A</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA37972651" lang="EN" load-source="patent-office"> <div class="abstract">A device and method which operates as an artificial labyrinth to eliminate sensory mismatch between the natural labyrinth/vestibular system and the vision system of an individual. The present invention provides an alternative means for the user to determine the true orientation of his body with respect to the surrounding environment. The method can be effected by means of a device which senses true body orientation and displays corresponding visual orientation cues that the brain can use to confirm other visual position information. The display can be projected into space in front of the user, directly onto the user's retina, or effected by pictorial scene averaging. The device is particularly useful in the rehabilitation treatment of persons suffering from vestibular nervous system defect or damage, and in providing relief to those suffering from the symptoms of nausea and/or vertigo which are often experienced as a result of the aforementioned sensory mismatch.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(9)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5966680-1.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5966680-1.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5966680-2.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5966680-2.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5966680-3.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5966680-3.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5966680-4.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5966680-4.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5966680-5.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5966680-5.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5966680-6.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5966680-6.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5966680-7.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5966680-7.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5966680-8.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5966680-8.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/pages/US5966680-9.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/pages/US5966680-9.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(30)</span></span></div><div class="patent-text"><div mxw-id="PCLM5457483" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>I claim:</claim-statement> <div class="claim"> <div num="1" class="claim">
      <div class="claim-text">1. A system for providing visual orientation information to a user, comprising:<div class="claim-text">orientation sensing means for providing positional change information of said user with respect to a baseline position of said user;</div> <div class="claim-text">data acquisition means to acquire said positional change information of said user and said baseline position of said user from said orientation sensing means;</div> <div class="claim-text">data processing means for determination of a relative positional change of said user from said baseline position of said user, based upon said positional change information of said user and said baseline position of said user acquired by said data acquisition means; and</div> <div class="claim-text">display means for presenting to said user a set of visual cues indicative of said relative positional change of said user.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="2" class="claim">
      <div class="claim-text">2. The system of claim 1 wherein said orientation sensing means comprises an accelerometer.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="3" class="claim">
      <div class="claim-text">3. The system of claim 1 wherein said orientation sensing means comprises a magnetostrictive sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="4" class="claim">
      <div class="claim-text">4. The system of claim 1 wherein said orientation sensing means comprises a gyroscope.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="5" class="claim">
      <div class="claim-text">5. The system of claim 1 wherein said orientation sensing means is worn by said user on a band affixed to the head of said user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="6" class="claim">
      <div class="claim-text">6. The system of claim 1 wherein said display means is affixed to a pair of eye glasses.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="7" class="claim">
      <div class="claim-text">7. The system of claim 1 wherein said display means comprises a liquid crystal display.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="8" class="claim">
      <div class="claim-text">8. The system of claim 1 wherein said display means comprises a retinal scanner.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="9" class="claim">
      <div class="claim-text">9. The system of claim 1 wherein said display means comprises the projection of a series of averaged video images acquired by a camera.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="10" class="claim">
      <div class="claim-text">10. The system of claim 1 wherein said display means comprises a holographic projection.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="11" class="claim">
      <div class="claim-text">11. The system of claim 1 wherein said visual cues comprise relative pitch orientation information.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="12" class="claim">
      <div class="claim-text">12. The system of claim 1 wherein said visual cues comprises roll orientation information.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="13" class="claim">
      <div class="claim-text">13. The system of claim 1 wherein said visual cues comprise relative yaw orientation information.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="14" class="claim">
      <div class="claim-text">14. The system of claim 1 wherein said visual cues comprise relative elevation orientation information.</div>
    </div>
    </div> <div class="claim"> <div num="15" class="claim">
      <div class="claim-text">15. A method of providing physical orientation information to a user comprising the following steps:<div class="claim-text">a. first sensing a baseline position of said user;</div> <div class="claim-text">b. second sensing a positional change of sad user from said baseline position of said user;</div> <div class="claim-text">c. computing a relative amount of said positional change of said user from said baseline position of said user; and</div> <div class="claim-text">d. presenting said relative amount of said positional change of said user as a series of visual cues to said user.</div> </div>
    </div>
    </div> <div class="claim-dependent"> <div num="16" class="claim">
      <div class="claim-text">16. The system of claim 15 wherein said sensing steps comprise the use of an accelerometer.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="17" class="claim">
      <div class="claim-text">17. The method of claim 15 wherein said sensing steps comprise the use of a magnetostrictive sensor.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="18" class="claim">
      <div class="claim-text">18. The method of claim 15 wherein said sensing steps comprise the use of a gyroscope.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="19" class="claim">
      <div class="claim-text">19. The method of claim 15 wherein said presenting step comprises providing non-orientation information to said user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="20" class="claim">
      <div class="claim-text">20. The method of claim 15 wherein said second sensing step comprises sensing a change in said user's pitch.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="21" class="claim">
      <div class="claim-text">21. The method of claim 15 wherein said second sensing step comprises sensing a change in said user's roll.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="22" class="claim">
      <div class="claim-text">22. The method of claim 15 wherein said second sensing step comprises sensing a change in said user's yaw.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="23" class="claim">
      <div class="claim-text">23. The method of claim 15 wherein said second sensing step comprises sensing a change in said user's elevation.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="24" class="claim">
      <div class="claim-text">24. The system of claim 15 wherein said presenting step comprises provision of a holographic image to said user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="25" class="claim">
      <div class="claim-text">25. The method of claim 15 wherein said presenting step comprises provision of a retinal scanning image to said user.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="26" class="claim">
      <div class="claim-text">26. The method of claim 15 wherein said second sensing step is repeated a multiplicity of times, and wherein said computing step comprises the determination of an average of a set of positional change data acquired during the repetition of said second sensing steps.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="27" class="claim">
      <div class="claim-text">27. The method of claim 26 wherein said repetition of said second sensing step occurs at a rate of more than 10 times per second.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="28" class="claim">
      <div class="claim-text">28. The method of claim 15 wherein said presenting step occurs at a rate of more than 6 times per second.</div>
    </div>
    </div> <div class="claim-dependent"> <div num="29" class="claim">
      <div class="claim-text">29. The method of claim 15 further including the continuous repetition of steps b, c and d.</div>
    </div>
    </div> <div class="claim"> <div num="30" class="claim">
      <div class="claim-text">30. A system for providing visual orientation information to a user, comprising:<div class="claim-text">orientation sensing means for providing positional change information of an object moving with said user with respect to a baseline position of said user;</div> <div class="claim-text">data acquisition means to acquire said positional change information of said object moving with said user and said baseline position of said user from said orientation sensing means;</div> <div class="claim-text">data processing means for determination of a relative positional change of said object moving with said user from said baseline position of said user, based upon said positional change information of said object moving with said user and said baseline position of said user acquired by said data acquisition means; and</div> <div class="claim-text">display means for presenting to said user a set of visual cues indicative of said relative positional change of said object moving with user.</div> </div>
    </div>
  </div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES67349441" lang="EN" load-source="patent-office" class="description">
    <p>This application claims the benefit of U.S. Provisional Application Nos. 60/011,895, filed on Feb. 15, 1996, and 60/017,753, filed on May 15, 1996.</p>
    <heading>BACKGROUND OF THE INVENTION</heading> <p>1. Field of the Invention</p>
    <p>The present invention relates generally to a device for the relief of nausea, disorientation, and other disabling symptoms resulting from sensory mismatch and, more particularly, to an artificial labyrinth which provides the user an alternate means of determining his actual, physical orientation with respect to the surrounding environment.</p>
    <p>2. Background of the Invention</p>
    <p>Motion sickness does not discriminate. It can attack anyone, at any time. It is always disabling, to a greater or lesser degree, depending on the person. It is known from research that certain types of sensory mismatch are the leading cause of motion sickness. This mismatch occurs when the brain perceives that the body is in motion (through signals originating in the labyrinth and transmitted to the brain by the vestibular nerve system), but the motion sensed does not match what the eye can see and verify. The reverse is also true (i.e. sensory mismatch may also occur when the eye perceives motion, but the labyrinth does not provide confirming signals to the brain). There are many causes of this mismatch, including: time delay between the arrival of labyrinth motion signals and visual confirmation signals within the brain, or conflict between these signals when they do manage to arrive at the same time. In addition, the labyrinth's signals may be corrupted by various physical defects, conflict with each other within the labyrinth, or be missing entirely, as is the case when a person has the vestibular system disconnected (via operation, accident, or birth defect). All causes of this type of sensory mismatch are not precisely known, but it is well-established that such conditions can drastically affect an individual's quality of life and performance of everyday tasks.</p>
    <p>One example of sensory mismatch is vertigo, which is the sensation the brain encounters when it perceives that the body is in motion (when in fact there is no motion), and it attempts to correct bodily posture to counteract the perceived physical sensation. Another example of sensory mismatch occurs when the eye perceives motion, but no motion actually occurs. This can be described as a type of "virtual reality" sickness, which is normally experienced users of video games or flight simulators. The reverse situation, when the body feels motion but there are no visual cues, is a much more common occurrence. Examples include: passengers in an airplane with no access to a window, sailors in a submarine, and ship passengers that cannot see the horizon. Such persons sense actual changes in body position, but have nothing in the environment which allows their eye to confirm the motion they perceive.</p>
    <p>It is not clear why some persons can tolerate sensory mismatch better than others. However, at some point, almost everyone is affected when the mismatch is severe. This is especially true for those who, through accident or genetic deficiency, suffer from vestibular system disfunction. That is, even though the person is sitting or standing in a stationary fashion, they have the constant feeling of motion and, as a result, sickness. Simply bending over or slight movement of any kind may result in total disability in these cases. In the United States alone, over 30,000 vestibular section operations occur each year to help those suffering from Meniere's disease (i.e. vertigo induced by a distended labyrinth) get some relief, which drugs alone can't provide. However, rehabilitation after such an operation may require months of therapy.</p>
    <p>Several attempts have been made to alleviate the symptoms of motion sickness (e.g., drugs which numb the nervous system and give some relief from nausea), but no successful product exists to eliminate the cause of motion sickness. Even if the resulting nausea is somewhat lessened, the sensory mismatch still exists, and may cause the affected person to make improper or dangerous decisions when accomplishing everyday tasks, such as driving an automobile.</p>
    <p>Thus, there exists a long-felt and widespread need to provide alternative environmental orientation information (i.e. "visual cues") which can be used by the brain to replace erroneous or missing sensation signals normally provided by the natural labyrinth, and which can be readily confirmed by the natural vision system. The method and apparatus of the present invention, discussed in greater detail below, clearly satisfies this need.</p>
    <heading>SUMMARY OF THE INVENTION</heading> <p>The present invention provides an artificial labyrinth which augments or replaces the natural labyrinth. It functions by sending visual cue orientation information directly to the eye for transmission to the brain. After some training by the user, the brain will learn to compare the artificial labyrinth orientation cue information with the visual perception of the user, and to disregard misleading natural labyrinth signals.</p>
    <p>The artificial labyrinth can exist in the form of a wearable accessory usable by any number of people; it can be integrated into glasses already worn for vision correction, or can be used with an independently wearable frame or other apparatus which enables a portable system to be devised. It is specifically designed to take advantage of miniature gyroscope, accelerometer, magnetostrictive sensor, or other attitudinal sensing technology to produce a device and method which give the user constant visual cues as to his orientation with respect to the surrounding environment. Such cues, when substituted by the brain for erroneous signals sent by a dysfunctional labyrinth or vestibular system, serve to eliminate sensory mismatch and the resulting sensations of nausea or vertigo.</p>
    <p>Visual cues can be supplied in a number of ways, including: a series of lines projected into the space in front of the user by way of a display or projection mechanism such as the commercially-available "Private-Eyeâ„¢"; direct projection of visual cues onto the retina; laser holography; or some type of averaged video display which records the image in front of the user, and re-displays a series of averaged video frames to the user's eye in order to give the appearance of a stable platform--much like the technology some commercial movie cameras use to stabilize an image while the camera is being moved during operation.</p>
    <p>In the presently preferred embodiment, by way of example and not necessarily by way of limitation, the artificial labyrinth makes use of a triaxial accelerometerto produce visual cues indicating the user's actual pitch and roll motion. The accelerometer is mounted on the user's head and the resulting electrical output from each axis (which reflects movement) is sampled every 10 msec. After 12 sample cycles occur (120 msec), the accelerometer signal data is averaged for each axis, compared with the user's baseline position (i.e. at rest), and translated into visual cues for display. The visual display is updated several times a second (at least every 150 msec) so that reference orientation cues are timely delivered to the eye for transmission to the brain. It has been determined through experimentation that such feedback eliminates sensory mismatch between the labyrinth/vestibular system and the visual system, so as to give relief to many who suffer from vertigo or motion sickness.</p>
    <p>The basic system can also be enhanced by the inclusion of magnetic sensors, which allow the addition of visual cues to indicate the yaw of the user. Thus, users can receive visual verification of rotational changes which occur to the left or right about a vertical axis which extends from the head to the toes. Elevational changes can likewise be communicated to the user by way of visual cues, as well as other useful, but non-orientation related (e.g. mapping or message) information.</p>
    <p>The artificial labyrinth satisfies a long existing need for a system capable of quickly, accurately, and inexpensively eliminating the sensory mismatch which is induced by environmental conditions or labyrinth/vestibular system disfunction. The above and other advantages of this invention will become apparent from the following more detailed description, in conjunction with the accompanying drawings and illustrative embodiments.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p>FIG. 1 is a perspective view of the present invention as worn by a user.</p>
    <p>FIG. 2 is a stylized example of a visual cue display.</p>
    <p>FIGS. 3(a)-(d) are various representations of the visual cue display as it reflects the true position of the user with respect to his environment.</p>
    <p>FIGS. 4(a)-(h) are alternative representations of the visual cue display as it reflects the true position of the user with respect to his environment.</p>
    <p>FIG. 5 is a simplified block diagram of an alternative embodiment of the invention.</p>
    <p>FIG. 6 is a simplified block diagram of an alternative embodiment of the present invention.</p>
    <p>FIG. 7 is a block diagram of an alternative embodiment of the present invention, realized as an operational system.</p>
    <p>FIG. 8 is a summary flow chart illustration of the processing steps for implementing the method of the present invention.</p>
    <p>FIG. 9 is a block diagram of an alternative embodiment of the present invention.</p>
    <p>FIG. 10 is a stylized representation of the visual cue display with user messaging capability.</p>
    <p>FIG. 11 is a simplified block diagram of an alternative embodiment of the present invention.</p>
    <p>FIG. 12 is a perspective view of an alternative embodiment of the present invention indicating a user's perception of a projected visual cue image.</p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading> <p>FIG. 1 illustrates a perspective view of one embodiment of the present invention, as it may be worn by a user. Glasses frames (40) encompass lenses (90), which provide a display to the user having fixed orientation marks (200) and movable visual cue orientation marks (100).</p>
    <p>Turning now to FIG. 2, orientation markings (100 and 200) are shown as a stylized representation of one possible display perceived by the user of the instant invention. Moveable visual cue marks (100) are displayed in relation to a field of fixed orientation marks (200). Moveable visual cue marks (100) will change their position with respect to fixed orientation marks (200) whenever the position of frame (45) changes with respect to the true horizon. If orientation sensors (10) are mounted to a frame (45), which is in turn affixed to the user's head, the display presented to the user will correspond roughly to that shown in FIG. 2 when the user's head is positioned so as to be straight and level, Turning now to FIG. 3, it can be seen how the position of moveable visual cue marks (100) will change with respect to fixed orientation marks (200) as the user's head position changes. FIGS. 3(a)-(d) show how the display changes when the user's head moves up, down, left, and right, respectively. Such changes assume that all orientation sensors are affixed to the user's head (e.g., by using glasses frame (40)).</p>
    <p>The changing orientation display gives the user visual cues as to the difference between his head position and that of his environment. Thus, users experiencing nausea and/or vertigo because they lack knowledge as to their physical position within the environment now have access to a simple means of determining their true relative orientation.</p>
    <p>FIG. 4 illustrates several additional examples of visual cues which can occur in the present invention. It should be noted that such visual cues are by no means limited to those shown in the accompanying figures. That is, instead of various combinations of dashed or dotted lines, and the geometric shapes shown, other forms of visual cuing are contemplated. For example, the intensity or color of the display can be varied over its entire surface, or in specified areas, to indicate various conditions of orientation. Colors may be bright or muted, intensities may also be brightened or dimmed, and geometric figures or indicators can change shape, color, or intensity to indicate various orientations to a specific user. In addition, display visual cues can be tailored to each individual user, so that the user need only adapt to those visual cues he needs to properly navigate in his own environment and avoid the disabling affects of vertigo and motion sickness.</p>
    <p>FIG. 4(a) represents a display providing two additional elements contemplated by the present invention. Vertical yaw bars (500) are used to indicate rotational position changes about an axis which extends from the head to the toes of the user. Elevational bubble (510) is used to indicate changes in altitude of the user's body from an initial baseline position. As can be seen in FIG. 4(b), the user has rotated toward his left about the central axis of his body. In FIG. 4(c), the user has rotated toward his right. In FIG. 4(d), the user has been elevated to some distance above an initial baseline rest position, and in FIG. 4(e), the user has been moved to a lower elevation than he initially encountered at the baseline rest position.</p>
    <p>The present invention also anticipates a combination of visual cues from any number of orientation sensors, all operating at the same time. That is, a particular user may require roll (rotational movement about an axis which extends from the front to the back of the user), pitch (rotation about an axis which extends from the left to the right of the user), yaw (rotational movement which occurs about an axis which extends from the head to the toes of the user), and elevation (change in altitude above or below a baseline rest position) change information simultaneously. FIG. 4(f) illustrates such a combination of visual cues. In this case, the user has pitched backward and rolled to the left. Altitude and yaw remain unchanged. Note that elevation bubble (510) is now located at the side of the display. The present invention contemplates location of various visual cues at any place on the display which is convenient to the user, and most effective at transmission of orientation information to the brain for processing. FIG. 4(g) indicates that the user has pitched forward and rolled to the right. Elevation and yaw remain unchanged. Finally, FIG. 4(h) indicates that the user has rolled to the right, yawed to the right, and been elevated upwardly. Pitch has not changed. All orientation marks in FIG. 4(h) (both moving and stationary) have been relegated to the periphery (75) of the display (50). This allows use of the display for unobstructed views of objects in front of the user, while still providing needed visual orientation cues.</p>
    <p>Turning now to FIG. 5, a simplified block diagram of the preferred embodiment of the present invention can be seen. Frame (45) may consist of glasses frame (40), as shown in FIG. 1, or any other convenient means to mount the required components of the present invention, so as to make them easily transportable by the user. Orientation sensors (10) are preferably mounted to frame (45). Orientation sensors (10) can be any type among several commonly available, including gyroscopic, accelerometer, or magnetostrictive. Orientation sensors (10) are energized by power source (30), which can be batteries or some other portable mechanism (e.g., solar). Power source (30) also supplies power to microprocessor (20) and other elements, such as a display (50) or projector (60), which are also preferably mounted to frame (45). The output of orientation sensors (10) is sent to microprocessor (20) and translated by means of a program into display commands for display (50) or projector (60) mounted on frame (45). If display (50) is used, it must be transparent so as to interpose only the orientation markings (100 and 200) as shown on lenses (90) in FIG. I between the eyes of the user and his environment. The display (50) mechanism can be affixed to corrective lenses or incorporated into clear glass or other transparent material for use with frame (45).</p>
    <p>An alternative means of presenting orientation markings (100 and 200) for perception by the user is to make use of a projector (60) to replace the function of display (50). Projector (60) is preferably mounted onto frame (45) in such a way as to project out into space in front of the user, by laser beam holographic means or other means, a display similar to that shown in FIG. 1, to include orientation markings (100 and 200). Commands to projector (60) are derived from signals produced by microprocessor (20) in response to input provided by orientation sensors (10). The projected display should preferably appear to be located several feet in front of the user.</p>
    <p>An alternative embodiment of the invention is shown in FIG. 6. In this case, no visual cue marks are displayed. The means to give the user visual clues as to orientation is now effected by producing an averaged semi-real-time display of what normally would be viewed through the lenses (90) of glasses frame (40) (of FIG. 1). In this case, a microprocessor (20) is powered by power source (30) which also provides power to a camera (70) (or series of cameras) and a projector (60). Camera (70) and projector (60) are preferably both mounted on glasses frame (40). In this embodiment of the instant invention, camera (70) can be used to produce a recorded image of the scene in front of the user. The recorded image is sent to microprocessor (20) and averaged with other images produced by camera (70) so as to produce what is perceived by the user to be a slowly changing display of the visual environment. This changing display is projected onto lenses (90) for actual perception by the user via projector (60). Thus, the user does not perceive the actual scene as recorded by camera (70), but only the averaged image as displayed by projector (60) on the inner surface of lenses (90).</p>
    <p>Turning now to FIG. 7, an operational realization of the preferred embodiment using conventional components can be seen. Power source (30) is used to supply microprocessor (20) and, indirectly, display (50) and orientation sensors (10). Microprocessor (20) is composed of a personal computer central processor unit (300) or equivalent, connected to conventional random access memory(310), and non-volatile memory (320).</p>
    <p>Projection display (390) is directly connected to display controller (380), which in turn is interfaced to a serial port on the central processor (300). A program is resident in the non-volatile memory (320), and used to direct the display controller (380), so as to project a series of visual cues onto projection display (390). Random access memory (310) is used as a scratchpad memory to store sensor input information and make calculations to update the visual cues sent to projection display (390) via display controller (380). The combination of analog-to-digital converter (330), analog multiplexer (340), and sample-and-hold (350) are integrated into a single circuit card made by Crossbow (Part No. CXLDK RS232, digital interface card), or equivalent. Orientation sensors (10) may take the form of a triaxial accelerometer(360), also made by Crossbow (Part No. CXL04M3) and three magnetostrictive sensors (Honeywell Part No. HMC1001).</p>
    <p>Turning now to FIG. 8, a summary flow chart sequence of events necessary to effect the method of the present invention, given the specific implementation as shown in FIG. 7, can be seen. In step (400), the system is powered-up and microprocessor (300) is used to initialize display control (380) and scratch pad random access memory (310). In addition, the data acquisition sub-system consisting of analog-to-digital converter (330), analog multiplexer (340), and the sample-and-hold (350) are reset and prepared to accept data from accelerometer sensors (360) and magnetic sensors (370) in step (420).</p>
    <p>Accelerometer sensors (360) are responsive to the Earth's gravitational field, which is relatively constant in magnitude and direction. The amount of angular tilt or acceleration experienced by each of accelerometer sensors (360) is passed on to sample-and-hold (350) in the form of a voltage, which is proportional to the change between the baseline (i.e. rest) position, and any newly measured position. Likewise, magnetic sensors (370) are responsive to changes in the Earth's magnetic field. Given a constant current input, the resistance of magnetic sensors (370) will change in proportion to changes in magnetic field strength. Thus, magnetic sensors (370) also provide a voltage indicative of positional change (from a baseline) to sample-and-hold (350).</p>
    <p>To obtain a baseline (resting or initial reference)position measurement, accelerometer sensors (360) and magnetic sensors (370) are placed on a stable, non-moving surface, and the data acquisition sub-system consisting of analog-to-digital convertor (330), analog multiplexer (340), and the sample-and-hold (350) are calibrated by subjecting the system to test voltage inputs over a specific range (e.g. 0.0 to 5.0 volts), and obtaining a range of expected conversion values (i.e. conversion slope) in step (430). In step (440), the system is programmed to take about 100 samples from each sensor. These samples are averaged for each sensor, and recorded as the initial baseline (i.e. "at rest") position in step (450).</p>
    <p>Now the microprocessor (300) enters a program loop which begins at step (460) and requires taking orientation sensors (10) data every 10 msec to produce a data set consisting of 12 samples of each sensor (e.g., 4 sensorsÃ—12 samples=48 samples in the set, if orientation sensors (10) consist of a triaxial accelerometer and a single magnetostrictive sensor), every 120 msec. In step (470), microprocessor (300) calculates the average position derived from the sample data for each sensor.</p>
    <p>Finally, in step (480), the average measured position for each sensor is compared to the baseline position and the new, updated position sensed by the orientation sensors (10) is presented to the user via projection display (390) after the appropriate commands have been sent to display controller (380).</p>
    <p>In this particular implementation of the preferred embodiment, the microprocessor (300) will look to see if any key on the computer keyboard (not shown) has been pressed in step (490). If it has, then the microprocessor (300) will exit from the data acquisition and positional update loop if the key pressed was an "ESCAPE" in step (500). If the key pressed was not an "ESCAPE", then microprocessor (300) will loop to step (460) and begin to acquire a new multi-sample data set based on any changes in orientation as sensed by accelerometer sensors (360) and magnetostrictive sensors (370).</p>
    <p>If the microprocessor (300) has sensed an "ESCAPE" key input in step (500), then projection display (390) is cleared of all visual cues and the system is prevented from acquiring any more position-dependent data or displaying changes in that data in step (520), and the program is halted.</p>
    <p>The spirit of the present invention anticipates the partition of the data acquisition, data processing, and visual cue display functions of the system into separate units, or combined into a single monolithic unit. Implementation as separate units can be seen in FIG. 7, although other methods of partition are possible. For example, the data acquisition and display functions can be combined into a single head-mounted unit, and the data processing system can be remotely located to reduce weight and/or power requirements. In FIG. 9, the data acquisition function of the present invention is implemented by using a power source (30) to supply the data acquisition sub-system (consisting of analog-to-digital convertor (330), analog multiplexer (340), and the sample-and-hold (350)), data transmitter (600), and various orientation sensors (10), consisting of accelerometer sensors (360) and magnetostrictive sensors (370). In this system, positional input data is provided by the orientation sensors (10), acquired by the data acquisition sub-system, and provided to the data transmitter (600) for transmission to the data processing sub-system.</p>
    <p>The data processing sub-system consists of a data transceiver (620) which sends the acquired data from orientation sensors (10) to a finite state machine (630) for processing. A power source (30) is also required at this juncture to energize data transceiver (620) and finite state machine (630). After processing of the positional sample data is completed, finite state machine (630) sends the resulting display controller information, along with any other data which may be desired (e.g., GPS, altitude, etc.), to the data transceiver (620). At this point, all data is received by data receiver (610) and passed on to display controller (380) for presentation to the user at projection display (390). Again, a power source (30) is used to supply the requirements of the data receiver (610), display controller (380), and projection display (390). It should be noted that all data communications which occur between data transmitter (600), data receiver (610), and data transceiver (620) can be effected by either radio frequency means, infrared means, or other wireless methods of communication.</p>
    <p>Many other possible implementations will suggest themselves to those skilled in the art. For example, this invention may be used in either civilian or military applications. Referring now to FIGS. 10, 11, and 12, an enhanced version of the invention can be seen. In this case, orientation information is projected out into space, several feet in front of the wearer, and provided at the periphery of the wearer's vision area (75). A miniaturized radio data receiver (e.g., cellular phone with modem, or similar device) (190) can be added to the basic system shown in FIG. 2, so that microprocessor (20) may also receive data which is unrelated to the user's position within his environment (See FIG. 10). Circuitry similar to that used in modern cordless or cellular phones, or digital messaging pagers, can also be used to directly interface with the microprocessor for wireless data transfer (20). In a military application, such information as target speed (80) and altitude (90) can be displayed at the top of the wearer's vision area display, and real-time messages which give an indication to the wearer of target proximity could be displayed in a "movie marquee" fashion at the bottom of the display (100). The center of the display (110) can be left open, as shown in FIG. 10, for display of any type of information which can be received over the radio/data link. The use of such display messaging in the military version of this invention obviates the need for verbal communications in many circumstances. This can be a real advantage in the battlefield or other situations where verbal or sonic communication is undesirable. The visual cue orientation display may also be superimposed onto a virtual reality display field (e.g. video games, flight simulators, etc.) or presented in conjunction with night-vision display applications. In naval or marine applications, the entire system worn by the user may have to be constructed in a water resistant or waterproof fashion. In this case, the central display area (110) might be used to display fleet position information (mapping) to the wearer.</p>
    <p>It is not necessary in all circumstances to provide visual cue information to each eye of the wearer. In low cost civilian applications, for example, only a single display element may be required. See FIG. 12. Various methods of mounting the display are possible. For example, a band (120) can be used to mount the unit on the head of the wearer with a simple extendable arm (130) to place the display (50) in front of the wearer's eye (e.g., similar to the inspection mirror worn by doctors, or some jeweler's loupes). Physically, display (50) is preferably about one square inch in size. However, the user will actually perceive a display image (140) which is much larger, and projected out into the space in front of him. The invention for civilian use should be very light weight, inexpensive and rugged. If a radio data receiver is used with the visual cue display, such information as news, weather updates, or other information of interest can be displayed in an updated fashion on the peripheral edges of the display.</p>
    <p>Turning now to FIGS. 11 and 12, it can be seen that other embodiments of the invention may include a three-axis accelerometer (150) in place of the orientation sensors (10) shown in FIG. 2. Of course, three separate single-axis accelerometers can also be used to replace orientation sensors (10). The use of accelerometers in place of a gyroscope will allow cost savings in some instances, and increase the ruggedness of the device.</p>
    <p>In more sophisticated versions of this device, the display can be adjusted by the wearer to compensate for vision deficiency (i.e., diopter adjustment, similar to that used in binoculars) so that the projected information display appears to be in perfect focus at a distance from the user. This adjustment can be programmed into the microprocessor (20) by sensing a user-controlled input (160), or mechanically adjusted by moving the display (50) closer to or farther away from the user's eye.</p>
    <p>Display (50) can be manufactured so that it is capable of displaying different elements in color. This will allow the wearer to immediately differentiate background information from priority or emergency information (e.g., emergency information can be displayed in red, while all other information is displayed in black and/or yellow). Display (50) can also be manufactured with a filter component to protect the eye of the wearer from damage by intense sources of electromagnetic energy. This may include simple polarizing filters or some type of material whose optical transmission properties can be adjusted to protect the eyesight of the wearer, depending on the optical sensing properties of the display material, or of an additional electromagnetic sensor (170) connected to microprocessor (20). Finally, retinal scanning, such as that described in "A Retinal Display for Virtual Environment Applications" (Proceedings of Society for Information display, 1993 International Symposium, Digest of Technical Papers, Vol. XXIV, pg. 827) or holographic projection, can be used to present appropriate visual cues to the user, with additional communications or message data if desired. Such technology would obviate the need for fixed display means for providing visual cues to the user.</p>
    <p>An alternative embodiment of the present invention may also include GPS (global positioning satellite) information processing capability. That is, messaging display (50) can present location information to the user, or a map display which is automatically updated as the user moves along terrain. GPS information processing capability is also useful to underwater divers. In this case, the diver's underwater position updates could be displayed in real-time as GPS receiver (180) obtains locational updates from satellites overhead and ports the resulting data to microprocessor (20).</p>
    <p>In order for the implementation of the present invention to be effective, it is important that the visual cue display information be processed and analyzed in a timely manner. This means that the display update for orientation visual cues (i.e. "physical sensation" information) should not lead or lag visual verification by a time period of greater than 150 msec, which means that orientation sensors (10) must normally be mounted on the head of the user. Head mounting of orientation sensors (10) will speed up the acquisition of any movement sensation resulting from changes in user physical position. If the orientation sensors (10) are mounted at some other location, it may be more convenient for the user, but may not be as effective at elimination of sensory mismatch as would direct mounting to the user's head. However, there may be instances in which the user desires to monitor the motion of an object moving with his own body, in which case the orientation sensors (10) must be mounted directly to that object, such as a car or airplane in which the user travels. In the described implementation of the embodiment depicted by FIG. 7, it was determined that a sensor sampling period of 120 msec, coupled with calculation of position change and display update commands of less than 30 msec, was sufficient to eliminate sensory mismatch (i.e. the display was continuously updated with new positional change information every 150 msec, or less). By supplying the user's brain with true conditions of motion within the required time period, sensory mismatch is eliminated and the user is relieved of vertigo and/or nausea that may result. This invention is also useful to those who have undergone the procedure of vestibular nerve section. Usually it takes months of rehabilitation to overcome the effects of such a procedure, but with the use of the present invention it is believed that rehabilitation can occur much more rapidly and successfully. Use of the artificial labyrinth will also lead to reductions in rehabilitation cost, since patients can get back to work more quickly, and drugs used to relieve the symptoms of sensory mismatch are avoided.</p>
    <p>Although the invention has been described with reference to a specific embodiment, this description is not meant to be construed in a limiting sense. On the contrary, even though only specific devices have been shown to be mounted to the glasses frames, all elements of the instant invention can be mounted on these frames, given sufficient miniaturization. Also, various alternative stylized displays can be used, other than that shown in FIG. 3. As long as the user is given visual orientation cues which reflect motion such as pitch, roll, yaw, or elevation of his body with respect to the environment, the spirit of this invention is effected. This includes the use of mechanical orientation sensing devices placed within the user's normal viewing field to give appropriate visual cues. Other various modifications of the enclosed embodiments will become apparent to those skilled in the art upon reference to the description of the invention. It is, therefore, contemplated that the following claims will cover such modifications, alternatives, and equivalents that fall within the true spirit of the scope of the invention.</p>
    </div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5051735">US5051735</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Sep 23, 1988</td><td class="patent-data-table-td patent-date-value">Sep 24, 1991</td><td class="patent-data-table-td ">Honda Giken Kogyo Kabushiki Kaisha</td><td class="patent-data-table-td ">Heads-up display system for a road vehicle</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5138555">US5138555</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jun 28, 1990</td><td class="patent-data-table-td patent-date-value">Aug 11, 1992</td><td class="patent-data-table-td ">Albrecht Robert E</td><td class="patent-data-table-td ">Helmet mounted display adaptive predictive tracking</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5613022">US5613022</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jul 12, 1994</td><td class="patent-data-table-td patent-date-value">Mar 18, 1997</td><td class="patent-data-table-td ">Luckoff Display Corporation</td><td class="patent-data-table-td ">Diffractive display and method utilizing reflective or transmissive light yielding single pixel full color capability</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5717392">US5717392</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 13, 1996</td><td class="patent-data-table-td patent-date-value">Feb 10, 1998</td><td class="patent-data-table-td ">Eldridge; Marty</td><td class="patent-data-table-td ">Position-responsive, hierarchically-selectable information presentation system and control program</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5727098">US5727098</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 6, 1995</td><td class="patent-data-table-td patent-date-value">Mar 10, 1998</td><td class="patent-data-table-td ">Jacobson; Joseph M.</td><td class="patent-data-table-td ">Oscillating fiber optic display and imager</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5729366">US5729366</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 24, 1996</td><td class="patent-data-table-td patent-date-value">Mar 17, 1998</td><td class="patent-data-table-td ">Hyundas Electronics Industries Co., Ltd.</td><td class="patent-data-table-td ">Heads-up display for vehicle using holographic optical elements</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5745054">US5745054</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 18, 1996</td><td class="patent-data-table-td patent-date-value">Apr 28, 1998</td><td class="patent-data-table-td ">Honeywell Inc.</td><td class="patent-data-table-td ">Method and apparatus for conformal runway alignment on a head up display</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="A+Retinal+Display+for+Virtual-Environment+Applications"'>A Retinal Display for Virtual-Environment Applications</a>" by Joel S. Kollin, 1993 International Symposium, Digest of Technical Papers, vol. XXIV (p. 827).</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">"<a href='http://scholar.google.com/scholar?q="Performance+and+Well-Being+Under+Tilting+Conditions%3A+The+Effects+of+Visual+Reference+and+Artificial+Horizon"'>Performance and Well-Being Under Tilting Conditions: The Effects of Visual Reference and Artificial Horizon</a>" by A. Rolnick and W. Bles, Aviation Space Environmental Medicine, 60(8); 779-785, 1989 Aug.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">A Retinal Display for Virtual Environment Applications by Joel S. Kollin, 1993 International Symposium, Digest of Technical Papers, vol. XXIV (p. 827).</td></tr><tr><td class="patent-data-table-td ">4</td><td class="patent-data-table-td "><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td ">Performance and Well Being Under Tilting Conditions: The Effects of Visual Reference and Artificial Horizon by A. Rolnick and W. Bles, Aviation Space Environmental Medicine, 60(8); 779 785, 1989 Aug.</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6228021">US6228021</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Mar 5, 1999</td><td class="patent-data-table-td patent-date-value">May 8, 2001</td><td class="patent-data-table-td ">Fountainhead</td><td class="patent-data-table-td ">Apparatus and method for relieving motion sickness</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6354011">US6354011</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 1, 2000</td><td class="patent-data-table-td patent-date-value">Mar 12, 2002</td><td class="patent-data-table-td ">Pruftechnik Dieter Busch Ag</td><td class="patent-data-table-td ">Orientation measuring device</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6361508">US6361508</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 20, 2000</td><td class="patent-data-table-td patent-date-value">Mar 26, 2002</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Army</td><td class="patent-data-table-td ">Personal event monitor with linear omnidirectional response</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6443913">US6443913</a></td><td class="patent-data-table-td patent-date-value">Mar 7, 2000</td><td class="patent-data-table-td patent-date-value">Sep 3, 2002</td><td class="patent-data-table-td ">Bruce Kania</td><td class="patent-data-table-td ">Apparatus and method for relieving motion sickness</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6497649">US6497649</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 21, 2001</td><td class="patent-data-table-td patent-date-value">Dec 24, 2002</td><td class="patent-data-table-td ">University Of Washington</td><td class="patent-data-table-td ">Alleviating motion, simulator, and virtual environmental sickness by presenting visual scene components matched to inner ear vestibular sensations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6692428">US6692428</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Dec 10, 1999</td><td class="patent-data-table-td patent-date-value">Feb 17, 2004</td><td class="patent-data-table-td ">Bruce Kania</td><td class="patent-data-table-td ">Apparatus and method for relieving motion sickness</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6748275">US6748275</a></td><td class="patent-data-table-td patent-date-value">Nov 2, 2001</td><td class="patent-data-table-td patent-date-value">Jun 8, 2004</td><td class="patent-data-table-td ">Respironics, Inc.</td><td class="patent-data-table-td ">Vestibular stimulation system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6925410">US6925410</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Nov 8, 2001</td><td class="patent-data-table-td patent-date-value">Aug 2, 2005</td><td class="patent-data-table-td ">International Business Machines Corporation</td><td class="patent-data-table-td ">Selecting a target device in a device network</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6932090">US6932090</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 6, 2003</td><td class="patent-data-table-td patent-date-value">Aug 23, 2005</td><td class="patent-data-table-td ">The United States Of America As Represented By The United States National Aeronautics And Space Administration</td><td class="patent-data-table-td ">Motion sickness treatment apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7469162">US7469162</a></td><td class="patent-data-table-td patent-date-value">May 14, 2004</td><td class="patent-data-table-td patent-date-value">Dec 23, 2008</td><td class="patent-data-table-td ">Ric Investments, Llc</td><td class="patent-data-table-td ">Vestibular stimulation system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7490611">US7490611</a></td><td class="patent-data-table-td patent-date-value">Apr 12, 2007</td><td class="patent-data-table-td patent-date-value">Feb 17, 2009</td><td class="patent-data-table-td ">Matthew Alexander Bromwich</td><td class="patent-data-table-td ">Device for the treatment of vertigo</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7717841">US7717841</a></td><td class="patent-data-table-td patent-date-value">Sep 19, 2006</td><td class="patent-data-table-td patent-date-value">May 18, 2010</td><td class="patent-data-table-td ">Artis Llc</td><td class="patent-data-table-td ">Motion-coupled visual environment for prevention or reduction of motion sickness and simulator/virtual environment sickness</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7722526">US7722526</a></td><td class="patent-data-table-td patent-date-value">Jun 24, 2005</td><td class="patent-data-table-td patent-date-value">May 25, 2010</td><td class="patent-data-table-td ">Samuel Kim</td><td class="patent-data-table-td ">System, method and apparatus for preventing motion sickness</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7856274">US7856274</a></td><td class="patent-data-table-td patent-date-value">Oct 24, 2007</td><td class="patent-data-table-td patent-date-value">Dec 21, 2010</td><td class="patent-data-table-td ">Ric Investments, Llc</td><td class="patent-data-table-td ">Vestibular stimulation system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7908041">US7908041</a></td><td class="patent-data-table-td patent-date-value">Apr 29, 2005</td><td class="patent-data-table-td patent-date-value">Mar 15, 2011</td><td class="patent-data-table-td ">Munro &amp; Associates, Inc.</td><td class="patent-data-table-td ">Self-leveling laser horizon for navigation guidance</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7918781">US7918781</a></td><td class="patent-data-table-td patent-date-value">Mar 22, 2006</td><td class="patent-data-table-td patent-date-value">Apr 5, 2011</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Army</td><td class="patent-data-table-td ">Systems and methods for suppressing motion sickness</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7981097">US7981097</a></td><td class="patent-data-table-td patent-date-value">Mar 27, 2008</td><td class="patent-data-table-td patent-date-value">Jul 19, 2011</td><td class="patent-data-table-td ">Paoli Jr Alexander Delli</td><td class="patent-data-table-td ">Medical device for the treatment and prevention of eye and respiratory tract conditions</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7983694">US7983694</a></td><td class="patent-data-table-td patent-date-value">Mar 21, 2008</td><td class="patent-data-table-td patent-date-value">Jul 19, 2011</td><td class="patent-data-table-td ">Nav-Track, Inc.</td><td class="patent-data-table-td ">Target and base station for a navigation system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8010133">US8010133</a></td><td class="patent-data-table-td patent-date-value">Jan 3, 2008</td><td class="patent-data-table-td patent-date-value">Aug 30, 2011</td><td class="patent-data-table-td ">Nav-Track, Inc.</td><td class="patent-data-table-td ">Navigation system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8214147">US8214147</a></td><td class="patent-data-table-td patent-date-value">Mar 21, 2008</td><td class="patent-data-table-td patent-date-value">Jul 3, 2012</td><td class="patent-data-table-td ">Nav-Track, Inc.</td><td class="patent-data-table-td ">Navigation unit and base station</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8355788">US8355788</a></td><td class="patent-data-table-td patent-date-value">Oct 24, 2007</td><td class="patent-data-table-td patent-date-value">Jan 15, 2013</td><td class="patent-data-table-td ">Ric Investments, Llc</td><td class="patent-data-table-td ">Vestibular stimulation system and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8690750">US8690750</a></td><td class="patent-data-table-td patent-date-value">May 16, 2011</td><td class="patent-data-table-td patent-date-value">Apr 8, 2014</td><td class="patent-data-table-td ">Wesley W. O. Krueger</td><td class="patent-data-table-td ">System and method for measuring and minimizing the effects of vertigo, motion sickness, motion intolerance, and/or spatial disorientation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8692845">US8692845</a></td><td class="patent-data-table-td patent-date-value">Oct 28, 2010</td><td class="patent-data-table-td patent-date-value">Apr 8, 2014</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Head-mounted display control with image-content analysis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8708884">US8708884</a></td><td class="patent-data-table-td patent-date-value">Mar 11, 2013</td><td class="patent-data-table-td patent-date-value">Apr 29, 2014</td><td class="patent-data-table-td ">The United States Of America As Represented By The Secretary Of The Army</td><td class="patent-data-table-td ">Systems and methods for adaptive mitigation of motion sickness</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US8780014">US8780014</a></td><td class="patent-data-table-td patent-date-value">Aug 25, 2010</td><td class="patent-data-table-td patent-date-value">Jul 15, 2014</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Switchable head-mounted display</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120182206">US20120182206</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 17, 2011</td><td class="patent-data-table-td patent-date-value">Jul 19, 2012</td><td class="patent-data-table-td ">Ronald Steven Cok</td><td class="patent-data-table-td ">Head-mounted display control with sensory stimulation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US20120289767">US20120289767</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 13, 2011</td><td class="patent-data-table-td patent-date-value">Nov 15, 2012</td><td class="patent-data-table-td ">Mobitv, Inc.</td><td class="patent-data-table-td ">Methods and apparatus for device based prevention of kinetosis</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/USRE44855">USRE44855</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 8, 1998</td><td class="patent-data-table-td patent-date-value">Apr 22, 2014</td><td class="patent-data-table-td ">Apple Inc.</td><td class="patent-data-table-td ">Multi-functional cellular telephone</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2071558A1?cl=en">EP2071558A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 17, 2007</td><td class="patent-data-table-td patent-date-value">Jun 17, 2009</td><td class="patent-data-table-td ">Sony Corporation</td><td class="patent-data-table-td ">Display apparatus and display method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP2431011A1?cl=en">EP2431011A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">May 13, 2010</td><td class="patent-data-table-td patent-date-value">Mar 21, 2012</td><td class="patent-data-table-td ">Ono &amp; Co., Ltd.</td><td class="patent-data-table-td ">Instrument for treating patient with semicircular canal injury and method for producing same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000051673A1?cl=en">WO2000051673A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Feb 22, 2000</td><td class="patent-data-table-td patent-date-value">Sep 8, 2000</td><td class="patent-data-table-td ">Kania Bruce</td><td class="patent-data-table-td ">An apparatus and method for relieving motion sickness</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2002056792A2?cl=en">WO2002056792A2</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Jan 4, 2002</td><td class="patent-data-table-td patent-date-value">Jul 25, 2002</td><td class="patent-data-table-td ">Univ Washington</td><td class="patent-data-table-td ">Alleviating motion, simulator, and virtual environmental sickness by presenting visual scene components matched to inner ear vestibular sensations</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2011143655A1?cl=en">WO2011143655A1</a></td><td class="patent-data-table-td patent-date-value">May 16, 2011</td><td class="patent-data-table-td patent-date-value">Nov 17, 2011</td><td class="patent-data-table-td ">Advitech, Inc.</td><td class="patent-data-table-td ">System and method for prevention and control of the effects of spatial disorientation</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2012058175A1?cl=en">WO2012058175A1</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 25, 2011</td><td class="patent-data-table-td patent-date-value">May 3, 2012</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Method of operating a head-mounted display for prevention of motion sickness</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc702/defs702.htm&usg=AFQjCNEwDgPZO8lzVvNBu0VAYuT88y7k4g#C702S150000">702/150</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=A61F0009080000">A61F9/08</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=A61M0021000000">A61M21/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G02B0027010000">G02B27/01</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=A61M21/00">A61M21/00</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=A61M2021/005">A61M2021/005</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=A61M2021/0044">A61M2021/0044</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=A61M21/02">A61M21/02</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=jqhMBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G02B27/017">G02B27/017</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">A61M21/00</span>, <span class="nested-value">G02B27/01C</span>, <span class="nested-value">A61M21/02</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Oct 23, 2012</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:JEFFERSON BANK;REEL/FRAME:029340/0605</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120905</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">BCMC, L.L.C., TEXAS</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 18, 2012</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">WESLEY W.O. KRUEGER, TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:ADVITECH, INC;REEL/FRAME:028578/0104</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20111209</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 11, 2011</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">LIEN;ASSIGNORS:KRUEGER, WESLEY, M.D., DR.;ADVITECH, INC.;REEL/FRAME:026262/0564</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110205</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">JEFFERSON BANK, TEXAS</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 12, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">12</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Mar 15, 2011</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:BUTNARU, HANAN;BUTNARU, DRORA;REEL/FRAME:025955/0113</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20000301</span></div><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">ADVITECH, INC., TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:KRUEGER, WESLEY W.O.;KRUEGER, LAURA T.;REEL/FRAME:025955/0206</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Oct 19, 2010</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">CLAIMS 1, 15, 16, 24 AND 30 ARE DETERMINED TO BE PATENTABLE AS AMENDED. CLAIMS 2-14, 17-23 AND 25-29, DEPENDENT ON AN AMENDED CLAIM, ARE DETERMINED TO BE PATENTABLE. NEW CLAIMS 31-84 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 12, 2007</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">8</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 6, 2005</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20050907</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Sep 9, 2005</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">KRUEGER, WESLEY O., TEXAS</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:BUTNARU, HANAN;REEL/FRAME:016958/0247</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">19991012</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 6, 2003</td><td class="patent-data-table-td ">SULP</td><td class="patent-data-table-td ">Surcharge for late payment</td><td class="patent-data-table-td "></td></tr><tr><td class="patent-data-table-td patent-date-value">Jun 6, 2003</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0mleHv2AE3GkXYnC-SDWX61FpmKA\u0026id=jqhMBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U1iuBj5W1MeDbe6n9Q2vTMzikbeVA\u0026id=jqhMBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U3gbw0doeN4AX5VHVvjdYUVvSV7mg","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Motion_sickness_vertigo_prevention_devic.pdf?id=jqhMBAABERAJ\u0026output=pdf\u0026sig=ACfU3U1HI4Y6JCJ1lVA253Ln1GK64UV16w"},"sample_url":"http://www.google.com/patents/reader?id=jqhMBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>