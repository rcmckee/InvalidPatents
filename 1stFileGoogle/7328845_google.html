<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html><head><title>Patent US7328845 - Method for producing indicators and processing apparatus and system ... - Google Patents</title><script>(function(){(function(){function e(a){this.t={};this.tick=function(a,c,b){var d=void 0!=b?b:(new Date).getTime();this.t[a]=[d,c];if(void 0==b)try{window.console.timeStamp("CSI/"+a)}catch(e){}};this.tick("start",null,a)}var a;window.performance&&(a=window.performance.timing);var f=a?new e(a.responseStart):new e;window.jstiming={Timer:e,load:f};if(a){var c=a.navigationStart,d=a.responseStart;0<c&&d>=c&&(window.jstiming.srt=d-c)}if(a){var b=window.jstiming.load;0<c&&d>=c&&(b.tick("_wtsrt",void 0,c),b.tick("wtsrt_",
"_wtsrt",d),b.tick("tbsd_","wtsrt_"))}try{a=null,window.chrome&&window.chrome.csi&&(a=Math.floor(window.chrome.csi().pageT),b&&0<c&&(b.tick("_tbnd",void 0,window.chrome.csi().startE),b.tick("tbnd_","_tbnd",c))),null==a&&window.gtbExternal&&(a=window.gtbExternal.pageT()),null==a&&window.external&&(a=window.external.pageT,b&&0<c&&(b.tick("_tbnd",void 0,window.external.startE),b.tick("tbnd_","_tbnd",c))),a&&(window.jstiming.pt=a)}catch(g){}})();})();
</script><link rel="stylesheet" href="/patents/css/_8a2b04e7bf975d5171d8e4c0b6365c7a/kl_intl_patents_bundle.css" type="text/css" /><script src="/books/javascript/atb_8a2b04e7bf975d5171d8e4c0b6365c7a__en.js"></script><script>function googleTranslateElementInit() {new google.translate.TranslateElement({pageLanguage: "en",gaTrack: true,gaId: "UA-27188110-1",multilanguagePage: true});}</script><script src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script><meta name="DC.type" content="Patent"><meta name="DC.title" content="Method for producing indicators and processing apparatus and system utilizing the indicators"><meta name="DC.contributor" content="Yao-Hung Tsai" scheme="inventor"><meta name="DC.contributor" content="Sonix Technology Co., Ltd." scheme="assignee"><meta name="DC.date" content="2002-7-2" scheme="dateSubmitted"><meta name="DC.description" content="The present invention discloses a method for producing graphical indicators and interactive systems for utilizing the graphical indicators. On the surface of an object, visually negligible graphical indicators are provided. The graphical indicators and main information, i.e. text or pictures, co-exist on the surface of object. The graphical indicators do not interfere with the main information when the perception of human eyes are concerned. With the graphical indicators, further information other than the main information on the surface of object are carried. In addition to the main information on the surface of object, one is able to obtain additional information through an auxiliary electronic device or trigger an interactive operation."><meta name="DC.date" content="2008-2-12" scheme="issued"><meta name="DC.relation" content="EP:0626660:A2" scheme="references"><meta name="DC.relation" content="EP:0660261:A2" scheme="references"><meta name="DC.relation" content="EP:0764944:A2" scheme="references"><meta name="DC.relation" content="JP:2000022930" scheme="references"><meta name="DC.relation" content="JP:2001096889" scheme="references"><meta name="DC.relation" content="JP:2001346032" scheme="references"><meta name="DC.relation" content="JP:2001353955" scheme="references"><meta name="DC.relation" content="JP:H0931382" scheme="references"><meta name="DC.relation" content="JP:H10251570" scheme="references"><meta name="DC.relation" content="JP:H11112787" scheme="references"><meta name="DC.relation" content="US:4627819" scheme="references"><meta name="DC.relation" content="US:4869532" scheme="references"><meta name="DC.relation" content="US:5329108" scheme="references"><meta name="DC.relation" content="US:5416312" scheme="references"><meta name="DC.relation" content="US:5473536" scheme="references"><meta name="DC.relation" content="US:5852434" scheme="references"><meta name="DC.relation" content="US:5866895" scheme="references"><meta name="DC.relation" content="US:5945656" scheme="references"><meta name="DC.relation" content="US:5959285" scheme="references"><meta name="DC.relation" content="US:6229964" scheme="references"><meta name="DC.relation" content="US:6412695" scheme="references"><meta name="DC.relation" content="US:6441921" scheme="references"><meta name="DC.relation" content="US:6460766" scheme="references"><meta name="DC.relation" content="US:6473762" scheme="references"><meta name="DC.relation" content="WO:2000073981:A1" scheme="references"><meta name="citation_reference" content="Computer, IEEE Service Center, Los Alamitos, CA, USA, vol. 34, No. 3, pp. 47-51 and 54, XP 001053842, &quot;Printed Embedded Data Graphical User Interfaces.&quot;, 2001."><meta name="citation_reference" content="CT Magazin Fuer Computer Technik, Heise Zeitschiften Verlag, Hannover, DE, p. 22, XP 00963015, &quot;E-Commerce mit Stift Auf Papier.&quot;, 2000."><meta name="citation_reference" content="Elektronik, Weka Fachzeitschriftenverlag, Poing, DE, VIL 49, No. 16, pp. 74-76, XP 001107913, &quot;Handschrift Per Funk in Die Ganze Welt.&quot;, 2000."><meta name="citation_patent_number" content="US:7328845"><meta name="citation_patent_application_number" content="US:10/189,244"><link rel="canonical" href="http://www.google.com/patents/US7328845"/><meta property="og:url" content="http://www.google.com/patents/US7328845"/><meta name="title" content="Patent US7328845 - Method for producing indicators and processing apparatus and system utilizing the indicators"/><meta name="description" content="The present invention discloses a method for producing graphical indicators and interactive systems for utilizing the graphical indicators. On the surface of an object, visually negligible graphical indicators are provided. The graphical indicators and main information, i.e. text or pictures, co-exist on the surface of object. The graphical indicators do not interfere with the main information when the perception of human eyes are concerned. With the graphical indicators, further information other than the main information on the surface of object are carried. In addition to the main information on the surface of object, one is able to obtain additional information through an auxiliary electronic device or trigger an interactive operation."/><meta property="og:title" content="Patent US7328845 - Method for producing indicators and processing apparatus and system utilizing the indicators"/><meta property="og:type" content="book"/><meta property="og:site_name" content="Google Books"/><meta property="og:image" content="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><link rel="image_src" href="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"/><script>(function(){try{var aa=function(a,b,c,d){d=d||{};d._sn=["cfg",b,c].join(".");window.gbar.logger.ml(a,d)};var g=window.gbar=window.gbar||{},l=window.gbar.i=window.gbar.i||{},m={},n;function _tvn(a,b){var c=parseInt(a,10);return isNaN(c)?b:c}function _tvf(a,b){var c=parseFloat(a);return isNaN(c)?b:c}function _tvv(a){return!!a}function p(a,b,c){(c||g)[a]=b}g.bv={n:_tvn("2",0),r:"",f:".67.",e:"0",m:_tvn("0",1)};
function q(a,b,c){var d="on"+b;if(a.addEventListener)a.addEventListener(b,c,!1);else if(a.attachEvent)a.attachEvent(d,c);else{var f=a[d];a[d]=function(){var a=f.apply(this,arguments),b=c.apply(this,arguments);return void 0==a?b:void 0==b?a:b&&a}}}var s=function(a){return function(){return g.bv.m==a}},ba=s(1),ca=s(2);p("sb",ba);p("kn",ca);l.a=_tvv;l.b=_tvf;l.c=_tvn;l.i=aa;var da=window.gbar.i.i;var t,u,v,w;function ea(a){v=a}function fa(a){var b;if(b=v&&window.encodeURIComponent)b=a.href,b=!b.match(/^http[s]?:\/\/accounts\.google\.[^/]*\/ClearSID/i)&&!b.match(/^http[s]?:\/\/[^/]*\/accounts\/ClearSID/i);if(b=b&&encodeURIComponent(v()))a.href=a.href.replace(/([?&]continue=)[^&]*/,"$1"+b)}function ga(a){window.gApplication&&(a.href=window.gApplication.getTabUrl(a.href))}
function ha(a){var b=document.forms[0].q,c=window.encodeURIComponent&&b&&b.value,b=b&&b.placeholder;c&&c!=b&&(a.href=a.href.replace(/([?&])q=[^&]*|$/,function(a,b){return(b||"&")+"q="+encodeURIComponent(c)}))}n=l.a("")?ga:ha;
function x(a,b,c,d,f,e){var h=document.getElementById(a);if(h){var k=h.style;k.left=d?"auto":b+"px";k.right=d?b+"px":"auto";k.top=c+"px";k.visibility=u?"hidden":"visible";f&&e?(k.width=f+"px",k.height=e+"px"):(x(t,b,c,d,h.offsetWidth,h.offsetHeight),u=u?"":a)}}
var y=[],ia=function(a,b){y.push(b)},ja=function(a){a=a||window.event;var b=a.target||a.srcElement;a.cancelBubble=!0;null==t&&(a=document.createElement(Array.every||window.createPopup?"iframe":"div"),a.frameBorder="0",t=a.id="gbs",a.src="javascript:''",b.parentNode.appendChild(a),q(document,"click",z));var c=b,b=0;"gb3"!=c.className&&(c=c.parentNode);a=c.getAttribute("aria-owns")||"gbi";var d=c.offsetWidth,f=20<c.offsetTop?46:24;document.getElementById("tphdr")&&(f-=3);var e=!1;do b+=c.offsetLeft||
0;while(c=c.offsetParent);var c=(document.documentElement.clientWidth||document.body.clientWidth)-b-d,h,d=document.body,k=document.defaultView;k&&k.getComputedStyle?(d=k.getComputedStyle(d,""))&&(h=d.direction):h=d.currentStyle?d.currentStyle.direction:d.style.direction;h="rtl"==h;if("gbi"==a){for(d=0;k=y[d++];)k();A(null,window.navExtra);h&&(b=c,e=!0)}else h||(b=c,e=!0);u!=a&&z();x(a,b,f,e)},z=function(){u&&x(u,0,0)},A=function(a,b){var c,d=document.getElementById("gbi"),f=a;f||(f=d.firstChild);
for(;b&&(c=b.pop());){var e=d,h=c,k=f;w||(w="gb2");e.insertBefore(h,k).className=w}},ka=function(a,b,c){if((b=document.getElementById(b))&&a){a.className="gb4";var d=document.createElement("span");d.appendChild(a);d.appendChild(document.createTextNode(" | "));d.id=c;b.appendChild(d)}},la=function(){return document.getElementById("gb_70")},ma=function(){return!!u};p("qs",n);p("setContinueCb",ea);p("pc",fa);p("tg",ja);p("close",z);p("addLink",ka);p("almm",A);p("si",la);p("adh",ia);p("op",ma);var B=function(){},C=function(){},F=function(a){var b=new Image,c=D;b.onerror=b.onload=b.onabort=function(){try{delete E[c]}catch(a){}};E[c]=b;b.src=a;D=c+1},E=[],D=0;p("logger",{il:C,ml:B,log:F});var G=window.gbar.logger;var H={},na={},I=[],oa=l.b("0.1",.1),pa=l.a("1",!0),qa=function(a,b){I.push([a,b])},ra=function(a,b){H[a]=b},sa=function(a){return a in H},J={},K=function(a,b){J[a]||(J[a]=[]);J[a].push(b)},ta=function(a){K("m",a)},L=function(a,b){var c=document.createElement("script");c.src=a;c.async=pa;Math.random()<oa&&(c.onerror=function(){c.onerror=null;B(Error("Bundle load failed: name="+(b||"UNK")+" url="+a))});(document.getElementById("xjsc")||document.getElementsByTagName("body")[0]||
document.getElementsByTagName("head")[0]).appendChild(c)},N=function(a){for(var b=0,c;(c=I[b])&&c[0]!=a;++b);!c||c[1].l||c[1].s||(c[1].s=!0,M(2,a),c[1].url&&L(c[1].url,a),c[1].libs&&m.d&&m.d(c[1].libs))},O=function(a){K("gc",a)},P=null,ua=function(a){P=a},M=function(a,b,c){if(P){a={t:a,b:b};if(c)for(var d in c)a[d]=c[d];try{P(a)}catch(f){}}};p("mdc",H);p("mdi",na);p("bnc",I);p("qGC",O);p("qm",ta);p("qd",J);p("lb",N);p("mcf",ra);p("bcf",qa);p("aq",K);p("mdd","");p("has",sa);
p("trh",ua);p("tev",M);var Q=l.b("0.1",.001),R=0;
function _mlToken(a,b){try{if(1>R){R++;var c,d=a,f=b||{},e=encodeURIComponent,h=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&jexpid=",e("17483"),"&srcpg=",e("prop=22"),"&jsr=",Math.round(1/Q),"&ogev=",e("OIftU9CWAbKzsQSyloDoDw"),"&ogf=",g.bv.f,"&ogrp=",e("1"),"&ogv=",e("1407723702.0"),"&oggv="+e("es_plusone_gc_20140723.0_p0"),"&ogd=",e("com"),"&ogc=",e("GBR"),"&ogl=",e("en")];f._sn&&(f._sn="og."+
f._sn);for(var k in f)h.push("&"),h.push(e(k)),h.push("="),h.push(e(f[k]));h.push("&emsg=");h.push(e(d.name+":"+d.message));var r=h.join("");S(r)&&(r=r.substr(0,2E3));c=r;var Aa=window.gbar.logger._aem(a,c);F(Aa)}}catch(Na){}}var S=function(a){return 2E3<=a.length},va=function(a,b){return b};function T(a){B=a;p("_itl",S,G);p("_aem",va,G);p("ml",B,G);a={};H.er=a}l.a("")?T(function(a){throw a;}):l.a("1")&&Math.random()<Q&&T(_mlToken);I.push(["m",{url:"//ssl.gstatic.com/gb/js/scm_7385cc5883250b43a39405734c1bea59.js"}]);g.mcf("c",{});g.sg={c:""};if(l.a("1")){var wa=l.a("");I.push(["gc",{auto:wa,url:"//ssl.gstatic.com/gb/js/abc/gci_91f30755d6a6b787dcc2a4062e6e9824.js",libs:"googleapis.client:plusone:gapi.iframes"}]);var xa={version:"gci_91f30755d6a6b787dcc2a4062e6e9824.js",index:"",lang:"en"};H.gc=xa;var U=function(a){window.googleapis&&window.iframes?a&&a():(a&&O(a),N("gc"))};p("lGC",U);l.a("1")&&p("lPWF",U)};window.__PVT="";if(l.a("1")&&l.a("1")){var V=function(a){U(function(){K("pw",a);N("pw")})};p("lPW",V);I.push(["pw",{url:"//ssl.gstatic.com/gb/js/abc/pwm_45f73e4df07a0e388b0fa1f3d30e7280.js"}]);var W=[],ya=function(a){W[0]=a},za=function(a,b){var c=b||{};c._sn="pw";B(a,c)},Ba={signed:W,elog:za,base:"https://plusone.google.com/u/0",loadTime:(new Date).getTime()};H.pw=Ba;var X=function(a,b){for(var c=b.split("."),d=function(){var b=arguments;a(function(){for(var a=g,d=0,e=c.length-1;d<e;++d)a=a[c[d]];a[c[d]].apply(a,b)})},f=g,e=0,h=c.length-1;e<h;++e)f=
f[c[e]]=f[c[e]]||{};return f[c[e]]=d};X(V,"pw.clk");X(V,"pw.hvr");p("su",ya,g.pw)};function Ca(){function a(){for(var b;(b=e[h++])&&"m"!=b[0]&&!b[1].auto;);b&&(M(2,b[0]),b[1].url&&L(b[1].url,b[0]),b[1].libs&&m.d&&m.d(b[1].libs));h<e.length&&setTimeout(a,0)}function b(){0<f--?setTimeout(b,0):a()}var c=l.a("1"),d=l.a(""),f=3,e=I,h=0,k=window.gbarOnReady;if(k)try{k()}catch(r){da(r,"ml","or")}d?p("ldb",a):c?q(window,"load",b):b()}p("rdl",Ca);var Da={D:1,H:2,da:3,p:4,W:5,M:6,F:7,g:8,ha:9,U:10,L:11,T:12,S:13,N:14,Q:15,P:16,fa:17,w:18,O:19,ga:20,ea:21,u:22,G:23,ja:24,ka:25,ia:26,A:27,j:28,o:29,k:30,ca:31,Z:32,$:33,J:34,K:35,ba:36,aa:37,Y:38,B:39,R:40,v:41,X:42,V:43,h:48,C:49,I:500},Y=[1,2,3,4,5,6,9,10,11,13,14,28,29,30,34,35,37,38,39,40,41,42,43,48,49,500];var Z=l.b("0.001",1E-4),Ea=l.b("1",1),Fa=!1,Ga=!1;if(l.a("1")){var Ha=Math.random();Ha<=Z&&(Fa=!0);Ha<=Ea&&(Ga=!0)}var Ia=Da,$=null;function Ja(){var a=0,b=function(b,d){l.a(d)&&(a|=b)};b(1,"");b(2,"");b(4,"");b(8,"");return a}
function Ka(a,b){var c=Z,d=Fa,f;f=a;if(!$){$={};for(var e=0;e<Y.length;e++){var h=Y[e];$[h]=!0}}if(f=!!$[f])c=Ea,d=Ga;if(d){d=encodeURIComponent;g.rp?(f=g.rp(),f="-1"!=f?f:"1"):f="1";c=["//www.google.com/gen_204?atyp=i&zx=",(new Date).getTime(),"&oge=",a,"&ogex=",d("17483"),"&ogev=",d("OIftU9CWAbKzsQSyloDoDw"),"&ogf=",g.bv.f,"&ogp=",d("22"),"&ogrp=",d(f),"&ogsr=",Math.round(1/c),"&ogv=",d("1407723702.0"),"&oggv="+
d("es_plusone_gc_20140723.0_p0"),"&ogd=",d("com"),"&ogl=",d("en"),"&ogc=",d("GBR"),"&ogus=",Ja()];if(b){"ogw"in b&&(c.push("&ogw="+b.ogw),delete b.ogw);var k;f=b;e=[];for(k in f)0!=e.length&&e.push(","),e.push(La(k)),e.push("."),e.push(La(f[k]));k=e.join("");""!=k&&(c.push("&ogad="),c.push(d(k)))}F(c.join(""))}}function La(a){"number"==typeof a&&(a+="");return"string"==typeof a?a.replace(".","%2E").replace(",","%2C"):a}C=Ka;p("il",C,G);var Ma={};H.il=Ma;setTimeout(function(){C(Ia.g)},0);}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var b=window.gbar.i.i;var c=window.gbar;var f=function(d){try{var a=document.getElementById("gbom");a&&d.appendChild(a.cloneNode(!0))}catch(e){b(e,"omas","aomc")}};c.aomc=f;}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{var a=window.gbar;a.mcf("pm",{p:""});}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
(function(){try{window.gbar.rdl();}catch(e){window.gbar&&gbar.logger&&gbar.logger.ml(e,{"_sn":"cfg.init"});}})();
if (window['_OC_timingAction']) {window['_OC_timingAction']('patents_refpage');}</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{float:left;height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}#gbs,.gbm{background:#fff;left:0;position:absolute;text-align:left;visibility:hidden;z-index:1000}.gbm{border:1px solid;border-color:#c9d7f1 #36c #36c #a2bae7;z-index:1001}.gb1{margin-right:.5em}.gb1,.gb3{zoom:1}.gb2{display:block;padding:.2em .5em}.gb2,.gb3{text-decoration:none !important;border-bottom:none}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb2,a.gb3,a.gb4{color:#00c !important}.gbi .gb3,.gbi .gb2,.gbi .gb4{color:#dd8e27 !important}.gbf .gb3,.gbf .gb2,.gbf .gb4{color:#900 !important}a.gb2:hover{background:#36c;color:#fff !important}#gbar .gbz0l{color:#000 !important;cursor:default;font-weight:bold;text-decoration:none !important}
#gbar { padding:.3em .6em !important;}</style></head><body  topmargin="3" marginheight="3"><div id=gbar><nobr><a onclick=gbar.qs(this);gbar.logger.il(1,{t:1}); class=gb1 id=gb_1 href="https://www.google.com/search?sa=N&tab=tw">Search</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:2}); class=gb1 id=gb_2 href="http://www.google.com/search?hl=en&tbm=isch&source=og&sa=N&tab=ti">Images</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:8}); class=gb1 id=gb_8 href="http://maps.google.com/maps?hl=en&sa=N&tab=tl">Maps</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:78}); class=gb1 id=gb_78 href="https://play.google.com/?hl=en&sa=N&tab=t8">Play</a> <a onclick=gbar.qs(this);gbar.logger.il(1,{t:36}); class=gb1 id=gb_36 href="http://www.youtube.com/results?sa=N&tab=t1">YouTube</a> <a onclick=gbar.logger.il(1,{t:5}); class=gb1 id=gb_5 href="http://news.google.com/nwshp?hl=en&tab=tn">News</a> <a onclick=gbar.logger.il(1,{t:23}); class=gb1 id=gb_23 href="https://mail.google.com/mail/?tab=tm">Gmail</a> <a onclick=gbar.logger.il(1,{t:25}); class=gb1 id=gb_25 href="https://drive.google.com/?tab=to">Drive</a> <a class=gb3 href="http://www.google.com/intl/en/options/" onclick="this.blur();gbar.tg(event);return !1" aria-haspopup=true><u>More</u> <small>&#9660;</small></a><div class=gbm id=gbi><a onclick=gbar.logger.il(1,{t:24}); class=gb2 id=gb_24 href="https://www.google.com/calendar?tab=tc">Calendar</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:51}); class=gb2 id=gb_51 href="http://translate.google.com/?hl=en&sa=N&tab=tT">Translate</a><a onclick=gbar.logger.il(1,{t:17}); class=gb2 id=gb_17 href="http://www.google.com/mobile/?hl=en&tab=tD">Mobile</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:10}); class=gb2 id=gb_10 href="http://www.google.com/search?hl=en&tbo=u&tbm=bks&source=og&sa=N&tab=tp">Books</a><a onclick=gbar.logger.il(1,{t:212}); class=gb2 id=gb_212 href="https://wallet.google.com/manage/?tab=ta">Wallet</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:6}); class=gb2 id=gb_6 href="http://www.google.com/search?hl=en&tbo=u&tbm=shop&source=og&sa=N&tab=tf">Shopping</a><a onclick=gbar.logger.il(1,{t:30}); class=gb2 id=gb_30 href="http://www.blogger.com/?tab=tj">Blogger</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:27}); class=gb2 id=gb_27 href="http://www.google.com/finance?sa=N&tab=te">Finance</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:31}); class=gb2 id=gb_31 href="https://plus.google.com/photos?sa=N&tab=tq">Photos</a><a onclick=gbar.qs(this);gbar.logger.il(1,{t:12}); class=gb2 id=gb_12 href="http://www.google.com/search?hl=en&tbo=u&tbm=vid&source=og&sa=N&tab=tv">Videos</a><div class=gb2><div class=gbd></div></div><a onclick=gbar.logger.il(1,{t:66}); href="http://www.google.com/intl/en/options/" class=gb2>Even more &raquo;</a></div></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a target=_top id=gb_70 href="https://www.google.com/accounts/Login?service=&continue=http://www.google.com/patents%3Fhl%3Den&hl=en" class=gb4>Sign in</a><div style="display: none"><div class=gbm id=gbd5 aria-owner=gbg5><div class=gbmc><ol id=gbom class=gbmcc></ol></div></div></div></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div><div role="alert" style="position: absolute; left: 0; right: 0;"><a href="http://www.google.com/patents/us7328845?hl=en&amp;output=html_text" title="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."><img border="0" src="http://www.google.com/images/cleardot.gif"alt="Screen reader users: click this link for accessible mode. Accessible mode has the same essential features but works better with your reader."></a></div><div id="guser"><nobr></nobr></div><div style="clear:both;"></div><div id="gb-top-search-box" class="gb-top-search-box-small gb-reset"><table><tr><td class="logo"><a href="http://www.google.com/patents" class="logo-link"><img class="logo-img" src="/intl/en/images/logos/google_logo_41.png" alt="Go to Google Books Home" height="41"/></a></td><td><form action="http://www.google.com/search" name="f" id="vheadf" method="get"><span id="hf"></span><input type="hidden" name="tbm" value="pts"/><input type="hidden" name="tbo" value="1"/><input type="hidden" name="hl" value="en"/><table><tr><td><div class="inputs"><table><tr><td><div class="text-input"><input type="text" name="q" id="vheadq" class="text" maxlength="2048" size="31" value="" title="Search Patents" accesskey="s" autocomplete="off"/><script>window._OC_autoDir &&window._OC_autoDir('vheadq', 'tia-vheadq');</script></div></td><td><div class="submit-input"><input name="btnG" class="submit" type="submit" value=""/></div></td></tr></table></div></td><td class="col-ext-links"><div class="ext-links"><a href="http://www.google.com/advanced_patent_search">&lt;nobr&gt;Advanced Patent Search&lt;/nobr&gt;</a></div></td></tr></table></form></td></tr></table></div><div class="kd-appbar"><h2 class="kd-appname"><a href="/patents">Patents</a></h2><div class="kd-buttonbar left" id="left-toolbar-buttons"><a id="appbar-write-review-link" href=""></a><a id="appbar-view-print-sample-link" href=""></a><a id="appbar-view-ebook-sample-link" href=""></a><a id="appbar-patents-prior-art-finder-link" href="https://www.google.com/patents/related/US7328845"></a><a id="appbar-patents-discuss-this-link" href="http://www.google.com/url?id=Jn2BBAABERAJ&amp;q=http://patents.stackexchange.com/redirect/google-patents%3Fpatent%3DUS7328845&amp;usg=AFQjCNEWxposeZa96DX511fnSmu0zxvGFA" data-is-grant="true"></a><a id="appbar-read-patent-link" href="//docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US7328845.pdf"></a><a id="appbar-download-pdf-link" href="//patentimages.storage.googleapis.com/pdfs/US7328845.pdf"></a><a class="appbar-application-grant-link" data-label="Application" href="/patents/US20030133164"></a><a class="appbar-application-grant-link" data-selected="true" data-label="Grant" href="/patents/US7328845"></a></div><div class="kd-buttonbar right" id="right-toolbar-buttons"></div></div><div id="books-microdata" itemscope=""itemtype="http://schema.org/Book"itemid="http://www.google.com/patents/US7328845" style="display:none"><span itemprop="description">The present invention discloses a method for producing graphical indicators and interactive systems for utilizing the graphical indicators. On the surface of an object, visually negligible graphical indicators are provided. The graphical indicators and main information, i.e. text or pictures, co-exist...</span><span itemprop="url">http://www.google.com/patents/US7328845?utm_source=gb-gplus-share</span><span class="main-title" itemprop="name">Patent US7328845 - Method for producing indicators and processing apparatus and system utilizing the indicators</span><img itemprop="image" src="http://www.google.com/patents?id=&amp;printsec=frontcover&amp;img=1&amp;zoom=1"alt="Patent US7328845 - Method for producing indicators and processing apparatus and system utilizing the indicators" title="Patent US7328845 - Method for producing indicators and processing apparatus and system utilizing the indicators"></div><div style="display: none"><ol id="ofe-gear-menu-contents" class="gbmcc"><li class="gbe gbmtc"><a class="gbmt goog-menuitem-content" id="" href="http://www.google.com/advanced_patent_search">Advanced Patent Search</a></li></ol></div><table id="viewport_table" cellpadding="0" style="clear:both" cellspacing="0"><tr><td id="viewport_td"><div class=vertical_module_list_row><div id=intl_patents class=about_content><div id=intl_patents_v><table class="patent-bibdata"><tr><td class="patent-bibdata-heading">Publication number</td><td class="single-patent-bibdata">US7328845 B2</td></tr><tr><td class="patent-bibdata-heading">Publication type</td><td class="single-patent-bibdata">Grant</td></tr><tr><td class="patent-bibdata-heading">Application number</td><td class="single-patent-bibdata">US 10/189,244</td></tr><tr><td class="patent-bibdata-heading">Publication date</td><td class="single-patent-bibdata">Feb 12, 2008</td></tr><tr><td class="patent-bibdata-heading">Filing date</td><td class="single-patent-bibdata">Jul 2, 2002</td></tr><tr><td class="patent-bibdata-heading">Priority date<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed."></span></td><td class="single-patent-bibdata">Jan 11, 2002</td></tr><tr><td class="patent-bibdata-heading">Fee status<span class="patent-tooltip-anchor patent-question-icon"data-tooltip-text="The fee status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status or dates listed."></span></td><td class="single-patent-bibdata">Paid</td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Also published as</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/DE10255926A1">DE10255926A1</a>, </span><span class="patent-bibdata-value"><a href="/patents/DE10255926B4">DE10255926B4</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7669774">US7669774</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7726570">US7726570</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8002198">US8002198</a>, </span><span class="patent-bibdata-value"><a href="/patents/US8006913">US8006913</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20030133164">US20030133164</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20080128502">US20080128502</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20080128520">US20080128520</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20100072281">US20100072281</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20100072282">US20100072282</a>, </span><span class="patent-bibdata-value"><a href="/patents/US20100076766">US20100076766</a></span></span></td></tr><tr class="patent-bibdata-list-row alternate-patent-number"><td class="patent-bibdata-heading">Publication number</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value">10189244, </span><span class="patent-bibdata-value">189244, </span><span class="patent-bibdata-value">US 7328845 B2, </span><span class="patent-bibdata-value">US 7328845B2, </span><span class="patent-bibdata-value">US-B2-7328845, </span><span class="patent-bibdata-value">US7328845 B2, </span><span class="patent-bibdata-value">US7328845B2</span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Inventors</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=ininventor:%22Yao-Hung+Tsai%22">Yao-Hung Tsai</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Original Assignee</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="http://www.google.com/search?tbo=p&tbm=pts&hl=en&q=inassignee:%22Sonix+Technology+Co.,+Ltd.%22">Sonix Technology Co., Ltd.</a></span></span></td></tr><tr class="patent-bibdata-list-row "><td class="patent-bibdata-heading">Export Citation</td><td><span class="patent-bibdata-value-list"><span class="patent-bibdata-value"><a href="/patents/US7328845.bibtex">BiBTeX</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7328845.enw">EndNote</a>, </span><span class="patent-bibdata-value"><a href="/patents/US7328845.ris">RefMan</a></span></span></td></tr><tr class="patent-internal-links"><td colspan=2><span class="patent-bibdata-value"><a href="#backward-citations">Patent Citations</a> (25),</span> <span class="patent-bibdata-value"><a href="#npl-citations">Non-Patent Citations</a> (3),</span> <span class="patent-bibdata-value"><a href="#forward-citations">Referenced by</a> (1),</span> <span class="patent-bibdata-value"><a href="#classifications">Classifications</a> (27),</span> <span class="patent-bibdata-value"><a href="#legal-events">Legal Events</a> (5)</span> </td></tr><tr><td colspan=2 class="patent-bibdata-external-link-spacer-top"></td></tr><tr class="patent-bibdata-external-link-spacer-bottom"></tr><tr><td colspan=2><span class="patent-bibdata-heading">External Links:&nbsp;</span><span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://patft.uspto.gov/netacgi/nph-Parser%3FSect2%3DPTO1%26Sect2%3DHITOFF%26p%3D1%26u%3D/netahtml/PTO/search-bool.html%26r%3D1%26f%3DG%26l%3D50%26d%3DPALL%26RefSrch%3Dyes%26Query%3DPN/7328845&usg=AFQjCNEoHbSgEITZXQdrHM-unFcWQyym9g">USPTO</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://assignments.uspto.gov/assignments/q%3Fdb%3Dpat%26pat%3D7328845&usg=AFQjCNH3O0dvb2Gnq9se1UcivDe875qULA">USPTO Assignment</a>, </span><span class="patent-bibdata-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DUS%26NR%3D7328845B2%26KC%3DB2%26FT%3DD&usg=AFQjCNF-EGzcb-qPxf6sBciwbLwxvsI2eA">Espacenet</a></span></span></td></tr><tr class="patent-bibdata-group-spacer"></tr></table><div class="number-and-title"><span class="patent-title"><invention-title mxw-id="PT55858888" lang="EN" load-source="patent-office">Method for producing indicators and processing apparatus and system utilizing the indicators</invention-title></span><br><span class="patent-number">US 7328845 B2</span></div><div class="patent-section patent-abstract-section"><div class="patent-section-header"><span class="patent-section-title">Abstract</span></div><div class="patent-text"><abstract mxw-id="PA51264672" lang="EN" load-source="patent-office"> <div num="p-0001" class="abstract">The present invention discloses a method for producing graphical indicators and interactive systems for utilizing the graphical indicators. On the surface of an object, visually negligible graphical indicators are provided. The graphical indicators and main information, i.e. text or pictures, co-exist on the surface of object. The graphical indicators do not interfere with the main information when the perception of human eyes are concerned. With the graphical indicators, further information other than the main information on the surface of object are carried. In addition to the main information on the surface of object, one is able to obtain additional information through an auxiliary electronic device or trigger an interactive operation.</div>
  </abstract></div></div><div class="patent-section patent-drawings-section"><div class="patent-section-header"><span class="patent-section-title">Images<span class="patent-section-count">(17)</span></span></div><div class="patent-drawings-body"><div class="patent-drawings-carousel"><div class="drawings"><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00000.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00000.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00001.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00001.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00002.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00002.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00003.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00003.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00004.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00004.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00005.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00005.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00006.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00006.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00007.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00007.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00008.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00008.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00009.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00009.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00010.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00010.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00011.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00011.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00012.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00012.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00013.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00013.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00014.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00014.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00015.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00015.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div><div class="patent-image"><div class="patent-thumbnail"><a href="//patentimages.storage.googleapis.com/US7328845B2/US07328845-20080212-D00016.png"><img class="patent-thumbnail-image" alt="Patent Drawing"src="//patentimages.storage.googleapis.com/thumbnails/US7328845B2/US07328845-20080212-D00016.png" /></a></div><div class="patent-thumbnail-caption">&nbsp;</div></div></div></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img" alt="Previous page"src="/googlebooks/images/kennedy/page_left.png"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img" alt="Next page"src="/googlebooks/images/kennedy/page_right.png"width="21" height="21" /></div></div></div><div class="patent-post-drawings"></div><div class="patent-section patent-claims-section"><div class="patent-section-header"><span class="patent-section-title">Claims<span class="patent-section-count">(51)</span></span></div><div class="patent-text"><div mxw-id="PCLM9342306" lang="EN" load-source="patent-office" class="claims">
  <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
    <div class="claim-text">1. A processing system comprising:
<div class="claim-text">an optical device for capturing an image from a selected zone on a surface of an object by a user, wherein the image includes a graphical indicator that is visually negligible and is affixed on the surface of the object;</div>
<div class="claim-text">a processing device coupled to the optical device for receiving the image, the processing device retrieving the graphical indicator from the image and acquiring an additional information corresponding to the graphical indicator by processing and/or transforming the graphical indicators; and</div>
<div class="claim-text">an output device coupled to the processing device for outputting the additional information.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
    <div class="claim-text">2. The processing system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the graphical indicator comprises a plurality of graphical micro-units arranged in a layout, the layout corresponds to an indicator information, the processing device analyses the layout of the graphical micro-units to retrieve the indicator information and further to acquire the additional information from the indicator information by processing and/or transforming the graphical indicators.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
    <div class="claim-text">3. The processing system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein each graphical indicator occupies very small amount of area, and each graphical micro-unit occupies very small amount of area, and number of graphical micro-units of each graphical indicator is substantially equal to each other.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
    <div class="claim-text">4. The processing system of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the surface of the object comprises a main information that overlaps and co-exists with the graphical micro-units on the surface of the object, wherein the graphical micro-units are negligible when the user observes the main information.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
    <div class="claim-text">5. The processing system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the graphical indicator comprises a plurality of state zones for selectively respectively storing the graphical micro-units, wherein each of the state zones displays a state from at least two candidate states.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
    <div class="claim-text">6. The processing system of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the candidate states comprise a first state and a second state, as in the first state, the state zone includes one graphical micro-unit, and as in the second state, the state zone does not include the graphical micro-unit.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
    <div class="claim-text">7. The processing system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein each square centimeter of the selected zone includes more than 3000 state zones of which less than seventy percent are in the first state, and percentage of area occupied by the graphical micro-unit in the state zone is less than 80.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
    <div class="claim-text">8. The processing system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein each square centimeter of the selected zone includes more than 6000 state zones of which less than seventy percent are in the first state, and percentage of area occupied by the graphical micro-unit in the state zone is less than 80.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
    <div class="claim-text">9. The processing system of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the state zones are arranged in a two-dimensional matrix form and the graphical indicator comprises a header information and a content information, each header information within each graphical indicator is capable of distinguishing the corresponding graphical indicator from adjacent graphical indicators and indicating the orientation of the corresponding graphical indicator to the optical device.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
    <div class="claim-text">10. The processing system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein each graphical micro-unit is printed in an ink that substantially absorbs infrared ray, and the main information is printed in an ink that hardly absorbs infrared ray, and the optical device emits infrared ray onto the surface of the object and then receives a response image from the surface of the object as the image.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
    <div class="claim-text">11. The processing system of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the ink is a black oil ink, while the main information is printed in a Near-K ink that hardly absorb infrared ray.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
    <div class="claim-text">12. The processing system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein each graphical micro-unit is printed in a fluorescent ink, and the main information is printed in a typical oil ink, the optical device emitting ultraviolet ray or blue ray onto the surface of the object and then receiving a response image from the surface of the object as the image.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
    <div class="claim-text">13. The processing system of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the surface of the object comprises multiple index zones, each index zone corresponds to one index value, and multiple identical graphical indicators are arranged in each index zone.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
    <div class="claim-text">14. The processing system of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising a mapping unit indicating mapping relationship of the indicator information and the additional information, the processing device being coupled to the mapping unit to retrieve one additional information corresponding to the indicator information.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
    <div class="claim-text">15. The processing system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the additional information comprises a multi-media information, and the output device outputs the multi-media information to the user.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
    <div class="claim-text">16. The processing system of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the graphical indicator is recorded in a vehicle that is affixed onto the surface of the object.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
    <div class="claim-text">17. The processing system of <claim-ref idref="CLM-00001">claim 1</claim-ref> further comprising a mapping unit indicating mapping relationship of the indicator information and the additional information, the mapping unit retrieves one additional information corresponding to the indicator information.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00018" num="00018" class="claim">
    <div class="claim-text">18. A processing system comprising:
<div class="claim-text">a surface of an object including multiple index zones, multiple visually negligible graphical indicators are arranged in each index zone; and</div>
<div class="claim-text">an electronic system comprising an optical device for capturing a selected zone on the surface of the object by a user, the optical device capturing an image from the selected zone, the electronic system retrieving the graphical indicators from the image and producing an response by using an additional information corresponding to one graphic indicator.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
    <div class="claim-text">19. The processing system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein each graphical indicator comprises a plurality of graphical micro-units arranged in a layout, the layout corresponds to an indicator information, the processing device analyses the layout of the graphical micro-units to retrieve the indicator information and further to acquire the additional information from the indicator information by processing and/or transforming the indicator information.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
    <div class="claim-text">20. The processing system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the surface of the object comprises a main information that overlaps and co-exists with the graphical micro-units on the surface of the object, wherein the graphical micro-units are negligible when the user observes the main information.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
    <div class="claim-text">21. The processing system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein each graphical indicators comprises a plurality of state zones for selectively respectively storing the graphical micro-units, and each state zone displays a state from at least two candidate states.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
    <div class="claim-text">22. The processing system of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein each square centimeter of the selected zone includes more than 3000 state zones of which less than seventy percent are in the first state, and percentage of area occupied by the graphical micro-unit in the state zone is less than 80.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
    <div class="claim-text">23. The processing system of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein each square centimeter of the selected zone includes more than 6000 state zones of which less than seventy percent are in the first state, and percentage of area occupied by the graphical micro-unit in the state zone is less than 80.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00024" num="00024" class="claim">
    <div class="claim-text">24. The processing system of <claim-ref idref="CLM-00021">claim 21</claim-ref>, wherein the candidate states comprise a first state and a second state, as in the first state, the state zone includes one graphical micro-unit, and as in the second state, the state zone does not include the graphical micro-unit.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00025" num="00025" class="claim">
    <div class="claim-text">25. The processing system of <claim-ref idref="CLM-00024">claim 24</claim-ref>, wherein the state zones are arranged in a two-dimensional matrix form and the graphical indicator comprises a header information and a content information, each header information within each graphical indicator is capable of distinguishing the corresponding graphical indicator from adjacent graphical indicators and indicating the orientation of the corresponding graphical indicator to the optical device.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00026" num="00026" class="claim">
    <div class="claim-text">26. The processing system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein each graphical micro-unit is printed in an ink that substantially absorbs infrared ray, and the main information is printed in an ink that hardly absorbs infrared ray, and the optical device emits infrared ray onto the surface of the object and then receives a response image from the surface of the object as the image.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00027" num="00027" class="claim">
    <div class="claim-text">27. The processing system of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein the ink is a black oil ink, while the main information is printed in a Near-K ink that comprises an ink hardly absorbing infrared ray.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00028" num="00028" class="claim">
    <div class="claim-text">28. The processing system of <claim-ref idref="CLM-00020">claim 20</claim-ref>, wherein each graphical micro-unit is printed in a fluorescent ink, and the main information is printed in a typical oil ink, the optical device emitting ultraviolet ray or blue ray onto the surface of the object and then receiving a response image from the surface of the object as the image.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00029" num="00029" class="claim">
    <div class="claim-text">29. The processing system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein each graphical indicator occupies very small amount of area, and each graphical micro-unit occupies very small amount of area, and number of graphical micro-units of each graphical indicator is substantially equal to each other.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00030" num="00030" class="claim">
    <div class="claim-text">30. The processing system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the surface of the object comprises multiple index zones, each index zone corresponds to one index value, and multiple identical graphical indicators are arranged in each index zone.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00031" num="00031" class="claim">
    <div class="claim-text">31. The processing system of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the response comprises outputting the additional information to the user.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00032" num="00032" class="claim">
    <div class="claim-text">32. The processing system of <claim-ref idref="CLM-00018">claim 18</claim-ref> further comprising a response system for receiving the additional information to implement the response.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00033" num="00033" class="claim">
    <div class="claim-text">33. An electronic apparatus comprising:
<div class="claim-text">an optical-reading device for capturing an image from a selected zone on a surface of an object by a user, emitting infrared ray to the surface of the object, and then receiving a response image from the surface of the object as the image, the image comprising a graphical indicator that is visually negligible and is affixed onto the surface of the object, the graphical indicator comprising a plurality of state zones for selectively respectively storing a plurality of graphical micro-units, and each state zone displaying a state from at least two candidate states;</div>
<div class="claim-text">an image-processing circuit coupled to the optical-reading device and used to retrieve the image from the graphical indicator and acquire an additional information corresponding to the graphical indicator; and</div>
<div class="claim-text">an output circuit being coupled to the image-processing circuit and outputting the additional information;</div>
<div class="claim-text">wherein the surface of the object comprises multiple index zones, each index zone corresponds to one index value, and multiple identical graphical indicators are arranged</div>
<div class="claim-text">in each index zone, the surface of the object further comprises a main information that overlaps and co-exists with the graphical micro-units on the surface of the object, and the graphical micro-units are negligible when the user observes the main information, and each graphical micro-unit is printed in an ink that substantially absorbs infrared ray, and the main information is printed in an ink that hardly absorbs infrared ray.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00034" num="00034" class="claim">
    <div class="claim-text">34. The electronic apparatus of <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein the candidate states comprise a first state and a second state, as in the first state, the state zone includes one graphical micro-unit, and as in the second state, the state zone does not include the graphical micro-unit.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00035" num="00035" class="claim">
    <div class="claim-text">35. The electronic apparatus of <claim-ref idref="CLM-00034">claim 34</claim-ref>, wherein the state zones are arranged in a two-dimensional matrix form and the graphical indicator comprises a header information and a content information, each header information within each graphical indicator is capable of distinguishing the corresponding graphical indicator from adjacent graphical indicators and indicating the orientation of the corresponding graphical indicator to the optical device.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00036" num="00036" class="claim">
    <div class="claim-text">36. The electronic apparatus of <claim-ref idref="CLM-00035">claim 35</claim-ref>, wherein the ink is a black oil ink, while the main information is printed in a Near-K ink that comprises an ink hardly absorbing infrared ray.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00037" num="00037" class="claim">
    <div class="claim-text">37. The electronic apparatus of <claim-ref idref="CLM-00036">claim 36</claim-ref>, further comprising a mapping unit indicating mapping relationship of the indicator information and the additional information, the image-processing circuit being coupled to the mapping unit to retrieve one additional information corresponding to the indicator information.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00038" num="00038" class="claim">
    <div class="claim-text">38. The electronic apparatus of <claim-ref idref="CLM-00036">claim 36</claim-ref> further comprising a mapping unit indicating mapping relationship of the indicator information and the additional information, the mapping unit retrieves one additional information corresponding to the indicator information.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00039" num="00039" class="claim">
    <div class="claim-text">39. The electronic apparatus of <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein the additional information comprises a multi-media information and the output circuit outputs the multi-media to the user.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00040" num="00040" class="claim">
    <div class="claim-text">40. The electronic apparatus of <claim-ref idref="CLM-00033">claim 33</claim-ref>, wherein the graphical indicator is recorded in a vehicle that is affixed onto the surface of the object.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00041" num="00041" class="claim">
    <div class="claim-text">41. A memory vehicle comprising: an indicator information;
<div class="claim-text">an additional information; and</div>
<div class="claim-text">mapping relationship of the indicator information and the additional information;</div>
</div>
    <div class="claim-text">wherein the indicator information corresponds to a graphical indicator that comprises a plurality of state zones for selectively respectively storing a plurality of graphical micro-units, each state zone displays a state from at least two candidate states, a surface of an object comprises multiple index zones, each index zone corresponds to one index value, and multiple identical graphical indicators are arranged in each index zone, and the surface of the object further comprises main information that overlaps and coexists with the graphical micro-units that are negligible when a user observes the main information.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00042" num="00042" class="claim">
    <div class="claim-text">42. An image-processing circuit comprising:
<div class="claim-text">a digital-signal-processing chip coupled to a memory vehicle and used for capturing a graphical indicator from an image and retrieving additional information corresponding to the graphical indicator;</div>
<div class="claim-text">wherein the graphical indicator comprises a plurality of state zones for selectively respectively storing a plurality of graphical micro-units, and each the state zone displays a state from at least two candidate states, and the digital-signal-processing chip analyzes a layout of the graphical micro-units to retrieve the plurality of indicator information and further to acquire the additional information by processing and/or transforming the indicator information.</div>
</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00043" num="00043" class="claim">
    <div class="claim-text">43. A coordinate positioning system allowing a user to make positioning action over a surface of an object, said surface including a main information, comprising:
<div class="claim-text">a coordinate system, implemented over said surface, including multiple coordinate zones, each coordinate zone including at least a visually negligible graphical indicator, said graphical indicator including multiple graphical micro-units co-existing with the main information over the surface without interference with the main information, multiple graphical micro-units being arranged in a layout in the graphical indicator, the layout corresponding to an indicator information indicating a coordinate value of each coordinate zone; and</div>
<div class="claim-text">a device for capturing the layout from the graphical indicator, retrieving the coordinate value responsive to said layout, and providing a response in response to the coordinate value.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00044" num="00044" class="claim">
    <div class="claim-text">44. The coordinate positioning system of <claim-ref idref="CLM-00043">claim 43</claim-ref>, wherein the graphical indicator comprises a plurality of state zones for selectively respectively storing the graphical micro-units, wherein each of the state zones displays a state from at least two candidate states, combination of states in each graphical indicator is different from combination of states in one different graphical indicator.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00045" num="00045" class="claim">
    <div class="claim-text">45. The coordinate positioning system of <claim-ref idref="CLM-00044">claim 44</claim-ref>, wherein the candidate states comprise a first state and a second state, as in the first state, the state zone includes one graphical micro-unit, and as in the second state, the state zone does not include the graphical micro-unit.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00046" num="00046" class="claim">
    <div class="claim-text">46. The coordinate positioning system of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein the state zones are arranged in a two-dimensional matrix form and the graphical indicator comprises a header information and a content information, each header information within each graphical indicator is capable of distinguishing the corresponding graphical indicator from adjacent graphical indicators and indicating the orientation of the corresponding graphical indicator to the optical device.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00047" num="00047" class="claim">
    <div class="claim-text">47. The coordinate positioning system of <claim-ref idref="CLM-00046">claim 46</claim-ref>, wherein each graphical micro-unit is printed in an ink that substantially absorbs infrared ray, and the main information is printed in an ink that hardly absorbs infrared ray, and the optical device emits infrared ray onto the surface of the object and then receives a response image from the surface of the object as the image.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00048" num="00048" class="claim">
    <div class="claim-text">48. The coordinate positioning system of <claim-ref idref="CLM-00047">claim 47</claim-ref>, wherein the ink is a black oil ink, while the main information is printed in a Near-K ink that hardly absorb infrared ray.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00049" num="00049" class="claim">
    <div class="claim-text">49. The coordinate positioning system of <claim-ref idref="CLM-00047">claim 47</claim-ref> wherein each graphical micro-unit is printed in a fluorescent ink, and the main information is printed in a typical oil ink, the optical device emitting ultraviolet ray or blue ray onto the surface of the object and then receiving a response image from the surface of the object as the image.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00050" num="00050" class="claim">
    <div class="claim-text">50. The coordinate positioning of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein each square centimeter of the selected zone includes more than 3000 state zones of which less than seventy percent are in the first state, and percentage of area occupied by the graphical micro-unit in the state zone is less than 80.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00051" num="00051" class="claim">
    <div class="claim-text">51. The coordinate positioning of <claim-ref idref="CLM-00045">claim 45</claim-ref>, wherein each square centimeter of the selected zone includes more than 6000 state zones of which less than seventy percent are in the first state, and percentage of area occupied by the graphical micro-unit in the state zone is less than 80.</div>
  </div>
</div> </div></div></div><div class="patent-section patent-description-section"><div class="patent-section-header"><span class="patent-section-title">Description</span></div><div class="patent-text"><div mxw-id="PDES16364850" lang="EN" load-source="patent-office" class="description">
<heading>BACKGROUND OF THE INVENTION</heading> <p num="p-0002">1. Field of the Invention</p>
  <p num="p-0003">The present invention relates to a method for producing indicators and processing apparatus and system utilizing the indicators, and more particularly, to a method, an apparatus and a system for providing additional information from the indicators affixed onto the surface of an object.</p>
  <p num="p-0004">2. Description of the Prior Art</p>
  <p num="p-0005">Dating back to ancient time, people start delivering information by recording information on surfaces of various objects. For example, since the birth of paper, people acquire the information through characters and drawings affixed on papers. Furthermore, in recent years, with distinctive colors, characters, or pictures attached to different locations on surface of an object, people try to disclose the information with regard to each different position of the object.</p>
  <p num="p-0006">When people observe the surface of object, they generally capture the information visually. However, the amount or types of the information carried by the surface of object are generally limited under the restrictions of the area size, beautification of the surface.</p>
  <p num="p-0007">Nowadays, due to the advance of electronic technology, the visual information has been retrieved from its original carrier and stored as the digital information in an electronic apparatus. And people read them directly from the electronic apparatus. However, it is difficult for the digital information to totally replace the information printed in books or information attached to the surface of object.</p>
  <p num="p-0008">On the other hand, through hyper link approach of computer technology, the digital information can be displayed in multiple dimensions, while the information printed in book or attached to the object still are displayed in two dimensions. Thus, if multiple dimensions information can be recorded on the book or the object, people can acquire additional information through the electronic apparatus.</p>
  <heading>SUMMARY OF THE INVENTION</heading> <p num="p-0009">One aspect of the present invention is to provide a method for producing graphical indicators. Some visually negligible graphical indicators are affixed on the surface of an object. The graphical indicators co-exist with main information, such as a text or picture, on the surface of object, and do not interfere with the perception of human eyes to the main information. A user retrieves the graphical indicators through an electronic system that does not couple with the object and acquires additional information from the graphical indicators.</p>
  <p num="p-0010">Another aspect of the present invention provides an apparatus and a system utilizing the graphical indicators. The apparatus or the system includes an optical-reading device, a processing device, and an output device. The optical-reading device captures an image including the graphical indicators from the surface of object, the processing device, responsive to the graphical indicators, acquires the corresponding additional information by processing and/or transforming the graphical indicators, and the output device outputs the additional information.</p>
<description-of-drawings> <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading> <p num="p-0011"> <figref idrefs="DRAWINGS">FIG. 1(A)</figref> is a schematic diagram illustrating the graphical indicators on the surface of object in accordance with the present invention;</p>
    <p num="p-0012"> <figref idrefs="DRAWINGS">FIG. 1(B)</figref> is an enlarged diagram illustrating one of the graphical indicators in <figref idrefs="DRAWINGS">FIG. 1(A)</figref>;</p>
    <p num="p-0013"> <figref idrefs="DRAWINGS">FIG. 1(C)</figref> is a schematic diagram illustrating the combination of the graphical micro-units in <figref idrefs="DRAWINGS">FIG. 1(B)</figref> converting into the bit array;</p>
    <p num="p-0014"> <figref idrefs="DRAWINGS">FIG. 1(D)</figref> is a schematic diagram illustrating the two-dimensional matrix form in accordance with the present invention;</p>
    <p num="p-0015"> <figref idrefs="DRAWINGS">FIG. 1(E)</figref> is an enlarged diagram illustrating the index zones and the graphical indicators in accordance with the present invention;</p>
    <p num="p-0016"> <figref idrefs="DRAWINGS">FIG. 1(F)</figref> illustrates the image corresponding to the matrix form of the graphical indicators converted into a bit matrix form in accordance with the present invention;</p>
    <p num="p-0017"> <figref idrefs="DRAWINGS">FIGS. 2(A)-2(C)</figref> are the diagrams illustrating various embodiments in accordance with the present invention;</p>
    <p num="p-0018"> <figref idrefs="DRAWINGS">FIG. 2(D)</figref> is the diagram illustrating other embodiment for the arrangement of the graphical indicators in accordance with the present invention;</p>
    <p num="p-0019"> <figref idrefs="DRAWINGS">FIG. 2(E)</figref> is the diagram illustrating the different graphical indicators arranged in a index zone in accordance with the present invention;</p>
    <p num="p-0020"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a schematic diagram illustrating an electronic system in accordance with the present invention;</p>
    <p num="p-0021"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a schematic flowchart illustrating the operation of the electronic system in accordance with the present invention;</p>
    <p num="p-0022"> <figref idrefs="DRAWINGS">FIG. 5</figref> is an embodiment of the processing system in accordance with the present invention;</p>
    <p num="p-0023"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a schematic diagram illustrating the electronic apparatus in accordance with the present invention;</p>
    <p num="p-0024"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a schematic flow chart illustrating the operation of the electronic apparatus in accordance with the present invention;</p>
    <p num="p-0025"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a schematic diagram illustrating one practical application in accordance with the present invention;</p>
    <p num="p-0026"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a schematic diagram illustrating the additional information used for controlling a response device in accordance with the present invention;</p>
    <p num="p-0027"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a schematic diagram illustrating the application of the present invention to information appliances;</p>
    <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a schematic diagram illustrating the additional information used to control other devices;</p>
    <p num="p-0029"> <figref idrefs="DRAWINGS">FIG. 12(A)</figref> is a graph illustrating the conventional bar code in the prior art; and</p>
    <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 12(B)</figref> is a graph illustrating use of indicators of the present invention.</p>
  </description-of-drawings> <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading> <p num="p-0031">The present invention provides a method for producing graphical indicators and interactive systems for utilizing the graphical indicators. Some visually negligible graphical indicators are affixed on the surface of an object. The graphical indicators co-exist with a main information, such as a text or picture, on the surface of object, and do not interfere with the perception of human eyes to the main information. A user retrieves the graphical indicators through an electronic system and acquires additional information from the graphical indicators. The user can utilize the graphical indicators without a complicated platform providing coordinate system. Furthermore, the typical book or the surface of object can carry more information through the graphical indicators.</p>
  <p num="h-0005">Exemplary Design for the Graphical Indicators</p>
  <p num="p-0032">In the present invention, one aspect of the graphical indicators is that the graphical indicators are so visually negligible that do not interfere with the main information on the surface of object. Another aspect of the graphical indicators is that the graphical indicators are not interfered by the other information on the surface when the electronic system reads the graphical indicators.</p>
  <p num="p-0033">For the visually negligible feature of graphical indicator, each graphical indicator includes multiple graphical micro-units arranged in a layout. Shown in <figref idrefs="DRAWINGS">FIG. 1(A)</figref>, which has scale of 2.5:1, the combination <b>100</b> of the graphical micro-units in a background to APPLE is the matrix consisting of graphical micro-units. The micro-units can be reduced further such that the combination <b>100</b> of the graphical micro-units is visually negligible or is viewed as a background material by human eyes.</p>
  <p num="p-0034">In practical application, the shape of the graphical micro-units may be regular or irregular shape, such as a round spot. For best result, the graphical micro-unit must be so tiny that only a microscope apparatus can detect it.</p>
  <p num="p-0035">When the graphical micro-units are tiny and arranged loosely in the layout, the user easily neglects the combination <b>100</b> of graphical micro-units and pays attention to main information, like the word APPLE depicted in <figref idrefs="DRAWINGS">FIG. 1(A)</figref>. Next, we explain how to use the graphical indicator to carry information.</p>
  <p num="p-0036">The combination <b>100</b> of the graphical micro-units consists of multiple graphical indicators arranged in sequence. Each graphical indicator includes multiple state zones for selectively respectively storing the graphical micro-units, wherein each of the state zones displays a state from at least two candidate states.</p>
  <p num="p-0037">For example, shown in <figref idrefs="DRAWINGS">FIG. 1(B)</figref> is an enlarged diagram illustrating one of the graphical indicators in <figref idrefs="DRAWINGS">FIG. 1(A)</figref>. The graphical indicator <b>11</b> includes <b>36</b> units of state zones <b>113</b> in the form of 6 by 6 matrix. Each state zone <b>113</b> selectively includes one graphical micro-unit or does not include the graphical micro-unit to represent the first or second state.</p>
  <p num="p-0038">When the micro-units in state zone <b>113</b> of the first state are assigned value of one and those of the second state are assigned value of zero, a bit matrix form <b>114</b> shown in <figref idrefs="DRAWINGS">FIG. 1(C)</figref> is resulted. Thus, the bit matrix form <b>114</b> stores a variety of information as expected or desired. In other word, the user can store desired information based on the combination of different values of the state zones.</p>
  <p num="p-0039">Furthermore, the multiple graphical indicators, as well as the graphical micro-units, are arranged in two-dimension matrix forms. Such arrangements of the graphical indicators and the graphical micro-units look homogenous to human eyes. Next, the present invention provides a method for retrieving the individual graphical indicator from the matrix form of the graphical indicators.</p>
  <p num="p-0040">Shown in <figref idrefs="DRAWINGS">FIG. 1(B)</figref>, which has scale of 100: 1, the graphical indicator <b>11</b> includes a header information <b>111</b> and a content information <b>112</b> arranged in a layout that corresponds to different indicator information. In one embodiment, all header information <b>111</b> are identical among different graphical indicators <b>11</b>. However, for a more comprehensive design, more than one set of header information may be employed as long as each header information within each graphical indicator is capable of distinguishing the corresponding graphical indicator from adjacent graphical indicators and indicating the orientation of the corresponding graphical indicator to the optical device. On the other hand, different value of content information <b>112</b> represents different indicator information. Thus, one graphical indicator <b>11</b> is read through capturing one header information <b>111</b>, and the graphical indicator <b>11</b> does not interfere with each adjacent graphical indicator <b>11</b>. However, in another embodiment, the header information <b>111</b> in one graphical indicator <b>11</b> may be different from that of other graphical indicator <b>11</b> as long as the system can use the header information to retrieve the corresponding content information.</p>
  <p num="p-0041"> <figref idrefs="DRAWINGS">FIG. 1(D)</figref>, which has scale of 120:1, is a schematic diagram illustrating the two-dimensional matrix form in accordance with the present invention. The user first searches the header information <b>111</b> and further retrieves the graphical indicator <b>11</b> and the corresponding content information <b>112</b>.</p>
  <p num="p-0042">Furthermore, in order to rapidly retrieve the indicator information, the image corresponding to the matrix form of the graphical indicators is rotated and converted into bit matrix form, shown in <figref idrefs="DRAWINGS">FIG. 1(F)</figref> during the process.</p>
  <p num="p-0043">Furthermore, we divide the surface of object into multiple index zones. Each zone corresponds to an index value. The graphical indicator corresponding to identical indicator information is repeatedly arranged in each index zone. The graphical indicator corresponding to different indicator information is repeatedly arranged in different index zones. The system maker of the invention records the corresponding relationship of the indicator information to the index zone in an electronic apparatus. When the electronic apparatus captures an image from a index zone, it can acquire the index value of the zone using the corresponding relationship.</p>
  <p num="p-0044">For example, <figref idrefs="DRAWINGS">FIG. 1(E)</figref>, which has scale of 20:1, is an enlarged diagram illustrating the index zones and the graphical indicators in accordance with the present invention. The graphical indicators <b>11</b> corresponding to same indicator information are arranged in the index zone <b>12</b>. The graphical indicators corresponding to different indicator information are respectively arranged in the other index zones.</p>
  <p num="p-0045">Other embodiment for the graphical indicators is possible. For example, <figref idrefs="DRAWINGS">FIGS. 2(A)-2(C)</figref> are the diagrams illustrating other embodiments for the graphical indicators in accordance with the present invention. Shown in <figref idrefs="DRAWINGS">FIGS. 2(A)-2(C)</figref>, a vertical segment represents the first state, and a horizontal segment represents the second state.</p>
  <p num="p-0046">Furthermore, <figref idrefs="DRAWINGS">FIG. 2(D)</figref> is the diagram illustrating other embodiment for the arrangement of the graphical indicators in accordance with the present invention. Different from the matrix arrangement in <figref idrefs="DRAWINGS">FIGS. 1(A)-1(F)</figref>, a cellular arrangement is set forth in <figref idrefs="DRAWINGS">FIG. 2(D)</figref>.</p>
  <p num="p-0047">Alternately, different graphical indicators may also be arranged in one index zone as shown in <figref idrefs="DRAWINGS">FIG. 2(E)</figref>. The letters A, B, C, and D respectively represent four different graphical indicators corresponding to four different indicator information. These four different graphical indicators are repeatedly arranged in sequence within one index zone, shown in <figref idrefs="DRAWINGS">FIG. 2(E)</figref>.</p>
  <p num="p-0048">There are requirements for the graphical indicators being negligible to human eyes. First, each graphical indicator must be tiny and human eyes can not differentiate one graphical indicator from others. Second, according to the size of the graphical micro-unit, the pitch between micro-unit, and the desired visual effect, one should reduce the number of the graphical micro-units used. In this way, the graphical indicators have little influence on the brightness of the surface of object. Furthermore, number of graphical micro-units of each graphical indicator is substantially equal to each other, and therefore the graphical indicators look more homogenous to human eyes and become invisible to human eyes.</p>
  <p num="p-0049">In a first embodiment, each square centimeter of the selected zone includes more than 3000 state zones of which less than seventy percent are in the first state, and percentage of area occupied by the graphical micro-unit in the state zone is less than 80.</p>
  <p num="p-0050">In a second embodiment, each square centimeter of the selected zone includes more than 6000 state zones of which less than seventy percent are in the first state, and percentage of area occupied by the graphical micro-unit in the state zone is less than 80.</p>
  <p num="p-0051">The following provides the methods for capturing the graphical indicators by an electronic system without interference with main information on the surface of object.</p>
  <p num="h-0006">First, a method utilizing infrared ray and oil ink is illustrated below.</p>
  <p num="p-0052">While printing the information on conventional media, a desired color is obtained by combining primitive color inks: cyan (C), magenta (M), yellow (Y), and black (K). Generally, hue and saturation are obtained by adjusting combination of C, Y, and M, and brightness is obtained by adjusting K.</p>
  <p num="p-0053">It is noted that infrared ray has high transmittance for most of C, M, Y primitive color inks, but has low transmittance for most of K color inks. In other words, C, M, Y color inks hardly absorb the infrared ray, but black color ink substantially absorbs the infrared ray. Therefore, infrared ray transmits through most of C, M, Y color inks and displays high brightness after reflecting from a light-coloured object surface under C, M, Y color inks. On the contrary, the surface that is printed in black color ink displays low brightness because of the absorption of the infrared ray by most of black color ink. Thus, when a detector receives an image corresponding to graphical indicators printed in most of black color ink, the image does not interfere with main information printed in most of C, M, Y color inks.</p>
  <p num="p-0054">On the other hand, when the main information needs to be printed in black, one type of black color, in the specification we called it Near_K, which hardly absorbs infrared ray, is used to print the main information. Mixing C, M, Y colors under predetermined ratio makes Near_K that displays visual black, such as dark indigo or dark brown. The ratio for mixing C, M, Y colors to obtain Near_K color is well known to the people skilled in the art. Since Near_K is made by C, M, Y color inks, Near_K is transmittable by infrared ray. And, to cooperate with this arrangement, the graphical indicators are printed using K (black) color.</p>
  <p num="p-0055">In the above description, the black color is used for an example and, however, it is not a limitation. Other inks that can substantially absorb the infrared ray can be used to print graphical indicators. This approach has advantage of low cost. It is to be noted that any type of oil ink, no matter what color it shows, that could substantially absorb infrared ray, are suitable for the print of graphical indicator and are intended scope of protection of present application. Any types of oil ink, that are transmittable by infrared and are close to black visually, i.e. some oil ink of edibility-class without carbon element, can also be used as Near-K color. Near-K color may act as role of black color of four primitive colors (C,M,YK) while printing the main information over the surface.</p>
  <p num="p-0056">On the other end, it is known that most oil inks absorb ultra-violent or blue light. That is, they do not produce light in visible spectrum when irradiated by ultra-violent or blue light. However, special type ink, such as fluorescent ink, produces visual image under the irradiation of ultra-violet or blue light. Thus, under this approach, the graphical indicators are printed in fluorescent ink, and the main information is printed in a typical oil ink. To cope with the arrangement, ultra-violent or blue light is used to irradiate the surface of object while reading the image. Afterwards, the non-interference image can be obtained by implementing an optical filter for filtering out unwanted spectrum portion.</p>
  <p num="p-0057">Another method is to directly use visual light. Since there are many graphical indicators that are not overlapped with the main information, as long as the detector detects single graphical indicator, the indicator information can be obtained.</p>
  <p num="p-0058">There are more than one approach to generate (prepare) the indicator information. For example, the additional information is encoded into the indicator information by method of compressed encoding. When the electronic system retrieves the indicator information, it acquires the additional information by decoding the indicator information. When this approach is adopted, the processing device of the invention, responsive to the graphical indicators, acquires the corresponding additional information by processing (decoding) the graphical indicators.</p>
  <p num="p-0059">Another way to obtain the additional information from the indicator information is using a mapping unit stored in the electronic system. The embodiments of the mapping unit include a database or a lookup table, etc. Actual implementations for the mapping unit include a hard disk, a floppy disk, a compact disk, a read-only memory, or a memory card. The electronic system acquires the additional information corresponding to the indicator information through the mapping unit. When this approach is adopted, the processing device, responsive to the graphical indicators, acquires the corresponding additional information by transforming the graphical indicators. Furthermore, for a more complicated design, the processing device, responsive to the graphical indicators, acquires the corresponding additional information by processing and/or transforming the graphical indicators.</p>
  <p num="h-0007">Exemplary Electronic System Utilizing the Graphical Indicators</p>
  <p num="p-0060"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a schematic diagram illustrating an electronic system <b>31</b> in accordance with the present invention. The electronic system <b>31</b> includes an optical device <b>311</b>, i.e. an image acquiring device, a processing device <b>312</b>, i.e. an image-processing circuit, and an output device <b>313</b>, i.e. an output circuit. The processing device <b>312</b> is wired or wireless coupled to the optical device <b>311</b>. Similarly, the processing device <b>312</b> is wired or wireless coupled to the output device <b>313</b>.</p>
  <p num="p-0061"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a schematic flowchart illustrating the operation of the electronic system in accordance with the present invention. The optical device <b>311</b> captures an image from the surface of object (step <b>41</b>) that includes the graphical indicator. Next, the processing device <b>312</b> retrieves the graphical indicator from the image (step <b>42</b>) and acquires the additional information corresponding to the graphical indicator (step <b>43</b>). The output device <b>313</b> receives the additional information from the processing device <b>312</b> and outputs the additional information (step <b>44</b>).</p>
  <p num="p-0062"> <figref idrefs="DRAWINGS">FIG. 5</figref> is an embodiment of the processing system in accordance with the present invention. The main information is printed on the surface of an object <b>51</b>. The main information in the embodiment includes multiple icons <b>511</b> and corresponding illustrations <b>513</b>. Such main information is generally used in a typical language-learning book or children-teaching book. The object is made of plastic, paper, or any printable carriers.</p>
  <p num="p-0063">In addition, the surface of object <b>51</b> includes multiple index zones on which respective icons <b>511</b> and illustrations <b>513</b> are affixed. In particular, the index zone corresponding to the icon <b>511</b> is printed with multiple identical graphical indicators <b>512</b>. To illustrate clearly, the graphical indicator <b>512</b> is visible. But in actual practice, the graphical indicator <b>512</b> may be so tiny as to be non-visible to human naked eyes.</p>
  <p num="p-0064">In this embodiment, the icon <b>511</b> is directly captured by human eyes <b>52</b>. In addition, the electronic system <b>31</b> is used to acquire the additional information corresponding to the graphical indicator <b>512</b>.</p>
  <p num="p-0065">As the electronic system <b>31</b> is directed to a zone to that the graphical indicator <b>512</b> is affixed, the optical device <b>311</b> captures the image including the graphical indicator <b>512</b> and transfers the image to the processing device <b>312</b>. Then the processing device <b>312</b> retrieves the graphical indicator <b>512</b> from the image and acquires the additional information corresponding to the graphical indicator <b>512</b>. In the embodiment, the additional information includes audio information, such as pronunciations of horse in English or other visual information, such as illustration of horse. Then the output device <b>313</b> outputs the audio information with a speaker <b>3131</b> and the visual information with a display panel <b>3132</b>. In addition, other types of information sensible by human being, such as olfactory or tactual information, can also be outputted.</p>
  <p num="p-0066"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a schematic diagram illustrating details of the electronic apparatus in accordance with the present invention. In the embodiment, the electronic apparatus includes an optical-reading device <b>61</b>, an image-processing circuit <b>62</b>, and an output circuit <b>63</b>. The optical-reading device <b>61</b> includes one or more sensor units <b>611</b> and one or more active light source <b>612</b>. The exemplary sensor unit <b>611</b> includes sensor micro-units, such as charge couple devices (CCD) or CMOS sensor units. In the embodiment, the image-processing circuit <b>62</b> includes a digital signal processor <b>621</b> (DSP) and a read-only memory card (ROM card) <b>622</b>. The read-only memory card (ROM card) <b>622</b> functions as a mapping unit.</p>
  <p num="p-0067"> <figref idrefs="DRAWINGS">FIG. 6</figref> and <figref idrefs="DRAWINGS">FIG. 7</figref> together illustrate the operation of embodiment. <figref idrefs="DRAWINGS">FIG. 7</figref> is a schematic flow chart illustrating the operation of the electronic apparatus in <figref idrefs="DRAWINGS">FIG. 6</figref>. The active light source <b>612</b> of the optical-reading device <b>61</b> irradiates active light beam <b>613</b> onto the surface of object <b>64</b> (step <b>71</b>). The surface of object <b>64</b> absorbs the portion of the active light beam <b>613</b> and reflects or scatters the light. The sensor unit <b>611</b> captures the scattered light <b>614</b> through subsequent lens <b>615</b> and an optic filter <b>616</b> to form an image (step <b>72</b>) and converts the image into electronic information (step <b>73</b>).</p>
  <p num="p-0068">The sensor unit <b>611</b> transfers the electronic information to the image-processing circuit <b>62</b> for image processing purpose. The image-processing circuit <b>62</b> extracts the combination of the graphical micro-units from the electronic information (step <b>74</b>). The exemplary combination of the graphical micro-units is denoted as <b>100</b> in <figref idrefs="DRAWINGS">FIGS. 1(A) to 1(E)</figref>. Next, the image-processing circuit <b>62</b> converts the combination of the graphical micro-units into the numeral codes (step <b>75</b>). For example, the combination of the graphical micro-units in <figref idrefs="DRAWINGS">FIG. 1(B)</figref> converts into the bit array shown in <figref idrefs="DRAWINGS">FIG. 1(C)</figref>. Then the image-processing circuit <b>62</b> retrieves the indicator information according to the numeral codes (step <b>76</b>) and further acquires the additional information corresponding to the indicator information (step <b>77</b>). In the embodiment, the ROM card <b>622</b> stores the mapping relationship of the indicator information and the additional information. The digital signal processor <b>621</b> executes the image process above-mentioned.</p>
  <p num="p-0069">Next, the output circuit <b>63</b> outputs the additional information (step <b>78</b>). In the embodiment, the additional information is audio information. The output circuit <b>63</b> includes a speaker that outputs the audio information corresponding to the zone on the surface of object irradiated by the active light source <b>612</b>.</p>
  <p num="p-0070">Alternatively, the read-only memory card (ROM card) <b>622</b> per se includes a built-in digital signal processor. Under this arrangement, the mapping unit, i.e. read-only memory card (ROM card) <b>622</b>, retrieves additional information corresponding to the indicator information responsive to the command from digital signal processor <b>621</b>.</p>
  <p num="p-0071"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a schematic diagram illustrating one practical application in accordance with the present invention. In the embodiment, the optical device includes an input pen <b>81</b>. The processing device is embedded in a general-purpose computer <b>82</b> and is programmable. The output device includes a monitor <b>831</b> and a speaker <b>832</b>. The book <b>80</b> has the graphical indicators of the present invention at predetermined locations, and a disc <b>821</b> is accompanied with the book <b>80</b>. When the user directs the input pen <b>81</b> to the selected zone of the book <b>80</b>, such as zone at which BOOK is printed, the optical device of the input pen <b>81</b> captures the image of the selected zone and transfers it to the general-purpose computer <b>82</b> run by the program in the disc <b>821</b>. The general-purpose computer <b>82</b> processes the image and acquires the additional information under control of the disc <b>821</b>, and retrieves the additional information. The additional information includes the explanation of the graphical indicators retrieved and the audio information. Next, the monitor <b>831</b> coupled to the general-purpose computer <b>82</b> outputs an illustration <b>834</b>, as well as the speaker <b>832</b> outputs the audio information.</p>
  <p num="p-0072">Furthermore, the additional information may also include commands for controlling other interactive devices.</p>
  <p num="h-0008">Application for Input of Information</p>
  <p num="p-0073"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a schematic diagram illustrating the additional information used for controlling a responsive device in accordance with the present invention. The surface of object <b>90</b> includes multiple index zones, and each index zone has one main information <b>9011</b>, such as alphanumeric information on a conventional key cap. Furthermore, one desired graphical indicator <b>9012</b> is affixed to the same index zone.</p>
  <p num="p-0074">The optical device of an electronic system <b>91</b> captures the image including the graphical indicator <b>9012</b>. The processing device of the electronic system <b>91</b> retrieves the graphical indicator <b>9012</b> from the image and acquires the additional information corresponding to the graphical indicator <b>9012</b>. The additional information is a command corresponding to the main information <b>9011</b>. The electronic system <b>91</b> transfers the command to a response device <b>92</b>. For instance, the response device <b>92</b> may be an audio device capable of generating sound of corresponding piano key. Under the same concept while altering the patterns, the object <b>90</b> may easily become a computer keyboard or calculator keyboard. The response device <b>92</b> may include mobile phone, personal digital assistant, notebook, and other electronic devices.</p>
  <p num="p-0075"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a schematic diagram illustrating the application of the present invention to information appliances. An interactive television <b>101</b> is equipped with a set top box <b>1011</b> for receiving user-interactive commands. A brochure <b>103</b> provided by cable TV program supplier is designed to include the graphical indicator of the invention. When the user selects one program <b>104</b> with an input device within the remote selector <b>102</b>, the input device retrieves the graphical indicator from the image of the program <b>104</b> and acquires the additional information corresponding to the graphical indicator. In the embodiment, the additional information is a command to the set top box <b>1011</b>. The output device in the remote selector <b>102</b> is an infrared emitter for transferring the command to the set top box <b>1011</b>. Thus, the present invention provides an input solution for the interactive television <b>101</b>.</p>
  <p num="h-0009">Application for Control Function</p>
  <p num="p-0076">Besides visual, olfactory or vibrating effects, the additional information includes controlling commands. <figref idrefs="DRAWINGS">FIG. 11</figref> is a schematic diagram illustrating the additional information used to control other devices. As indicated, a response device <b>1001</b> includes puppets <b>10011</b>, <b>10012</b>, <b>10013</b>, word-line display panel <b>10014</b>, and display panel <b>10015</b>. A script book <b>10018</b> is provided to include the graphical indicators corresponding to the contents. The user selects the specific content with the electronic device <b>10016</b>. For example, if the user would like to have a sunny day displayed in the display panel <b>10015</b>, he or she captures the corresponding graphical indicator on the script book <b>10018</b> using the electronic device <b>10016</b>. The electronic device <b>10016</b> retrieves the graphical indicator and acquires the corresponding additional information. The additional information is the command <b>10017</b> transmitted for controlling the response device <b>1001</b>. The electronic device <b>10016</b> transfers the command <b>10017</b> to the response device <b>1001</b> through wireless or infrared transmission. The response device <b>1001</b> displays the sunny day on the display panel <b>10015</b> in response to the command <b>10017</b>.</p>
  <p num="p-0077">As the electronic device <b>10016</b> is denoted to a dialogue <b>10019</b>, the electronic device <b>10016</b> retrieves the graphical indicators corresponding to the dialogue <b>10019</b> and then acquires a command of additional information. The electronic device <b>10016</b> transfers the command to the response device <b>1001</b> and the puppet <b>10012</b>. The response device <b>1001</b> displays the dialogue <b>10019</b> on the word-line display panel <b>10014</b>, and the puppet <b>10012</b> speaks dialogue when making the action.</p>
  <p num="h-0010">Substitute for Bar Code</p>
  <p num="p-0078">The feature of the present invention is different from conventional bar code. <figref idrefs="DRAWINGS">FIG. 12(A)</figref> is a graph illustrating the conventional bar code <b>10001</b> in the prior art. <figref idrefs="DRAWINGS">FIG. 12(B)</figref> is a graph illustrating use of indicators <b>10002</b>, <b>10003</b> of the present invention. In one embodiment, the information implicitly stored in the conventional bar code <b>10001</b> is now stored in the graphical indicator <b>10002</b> provided by the invention, and the information of an editor or a writer is stored in the graphical indicator <b>10003</b> provided by the invention. The graphical indicators <b>10002</b>, <b>10003</b> do not interfere with other main information on the surface <b>10000</b>.</p>
  <p num="h-0011">Application for Coordinate Positioning System</p>
  <p num="p-0079">This invention may be implemented into a coordinate positioning system as index value mentioned above is a coordinate value when a coordinate system is predefined over the surface. Under this application, the coordinate positioning system allows a user to make positioning action over a surface of an object while the surface including a main information. The coordinate positioning system includes a coordinate system and a device.</p>
  <p num="p-0080">The coordinate system, implemented over the surface, includes multiple coordinate zones. Each coordinate zone includes at least a visually negligible graphical indicator, and the graphical indicator includes multiple graphical micro-units co-existing with the main information over the surface without interference with the main information. The multiple graphical micro-units are arranged in a layout in the graphical indicator, the layout corresponds to an indicator information indicating a coordinate value of each coordinate zone. The device is used for capturing the layout from the graphical indicator, retrieving the coordinate value responsive to the layout, and providing a response in response to the coordinate value.</p>
  <p num="p-0081">Those skilled in the art will readily observe that numerous modifications and alterations of the device may be made while retaining the teaching of the invention. Accordingly, the above disclosure should be construed as limited only by the metes and bounds of the appended claims.</p>
</div></div></div><div class="patent-section patent-tabular-section"><a id="backward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Cited Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4627819">US4627819</a></td><td class="patent-data-table-td patent-date-value">Oct 31, 1985</td><td class="patent-data-table-td patent-date-value">Dec 9, 1986</td><td class="patent-data-table-td ">Price/Stern/Sloan Publishers, Inc.</td><td class="patent-data-table-td ">Teaching or amusement apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US4869532">US4869532</a></td><td class="patent-data-table-td patent-date-value">Sep 29, 1987</td><td class="patent-data-table-td patent-date-value">Sep 26, 1989</td><td class="patent-data-table-td ">Dainichiseika Color &amp; Chemicals Mfg. Co., Ltd.</td><td class="patent-data-table-td ">Black inks, azo dyes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5329108">US5329108</a></td><td class="patent-data-table-td patent-date-value">Nov 20, 1992</td><td class="patent-data-table-td patent-date-value">Jul 12, 1994</td><td class="patent-data-table-td ">Cherloc</td><td class="patent-data-table-td ">Map with indexes for a geographical information system and system for applying same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5416312">US5416312</a></td><td class="patent-data-table-td patent-date-value">May 17, 1994</td><td class="patent-data-table-td patent-date-value">May 16, 1995</td><td class="patent-data-table-td ">Cherloc</td><td class="patent-data-table-td ">Document bearing an image or a text and provided with an indexing frame, and associated document analysis system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5473536">US5473536</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Apr 4, 1994</td><td class="patent-data-table-td patent-date-value">Dec 5, 1995</td><td class="patent-data-table-td ">Spacelabs Medical, Inc.</td><td class="patent-data-table-td ">Method and system for customizing the display of patient physiological parameters on a medical monitor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5852434">US5852434</a></td><td class="patent-data-table-td patent-date-value">Dec 18, 1995</td><td class="patent-data-table-td patent-date-value">Dec 22, 1998</td><td class="patent-data-table-td ">Sekendur; Oral F.</td><td class="patent-data-table-td ">Coordinate sensor</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5866895">US5866895</a></td><td class="patent-data-table-td patent-date-value">Dec 13, 1995</td><td class="patent-data-table-td patent-date-value">Feb 2, 1999</td><td class="patent-data-table-td ">Olympus Optical Co., Ltd.</td><td class="patent-data-table-td ">Information recording medium and information reproduction system</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5945656">US5945656</a></td><td class="patent-data-table-td patent-date-value">May 27, 1997</td><td class="patent-data-table-td patent-date-value">Aug 31, 1999</td><td class="patent-data-table-td ">Lemelson; Jerome H.</td><td class="patent-data-table-td ">Apparatus and method for stand-alone scanning and audio generation from printed material</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US5959285">US5959285</a></td><td class="patent-data-table-td patent-date-value">Oct 16, 1996</td><td class="patent-data-table-td patent-date-value">Sep 28, 1999</td><td class="patent-data-table-td ">Symbol Technologies, Inc.</td><td class="patent-data-table-td ">Two-dimensional bar code symbology using gray code encodation scheme</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6229964">US6229964</a></td><td class="patent-data-table-td patent-date-value">Feb 26, 1998</td><td class="patent-data-table-td patent-date-value">May 8, 2001</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">Image with sound playback apparatus</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6412695">US6412695</a></td><td class="patent-data-table-td patent-date-value">Apr 7, 2000</td><td class="patent-data-table-td patent-date-value">Jul 2, 2002</td><td class="patent-data-table-td ">Motorola, Inc.</td><td class="patent-data-table-td ">Optical code and delineator apparatus and method</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6441921">US6441921</a></td><td class="patent-data-table-td patent-date-value">Jun 18, 1998</td><td class="patent-data-table-td patent-date-value">Aug 27, 2002</td><td class="patent-data-table-td ">Eastman Kodak Company</td><td class="patent-data-table-td ">System and method for imprinting and reading a sound message on a greeting card</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6460766">US6460766</a></td><td class="patent-data-table-td patent-date-value">Mar 17, 2000</td><td class="patent-data-table-td patent-date-value">Oct 8, 2002</td><td class="patent-data-table-td ">Francis Olschafskie</td><td class="patent-data-table-td ">Graphic symbols and method and system for identification of same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US6473762">US6473762</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Oct 31, 2000</td><td class="patent-data-table-td patent-date-value">Oct 29, 2002</td><td class="patent-data-table-td ">Mci Communications Corporation</td><td class="patent-data-table-td ">System and method to automatic equipment placement at remote sites</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0626660A2?cl=en">EP0626660A2</a></td><td class="patent-data-table-td patent-date-value">May 20, 1994</td><td class="patent-data-table-td patent-date-value">Nov 30, 1994</td><td class="patent-data-table-td ">Pitney Bowes Inc.</td><td class="patent-data-table-td ">Document authentication system utilizing a transparent label</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0660261A2?cl=en">EP0660261A2</a></td><td class="patent-data-table-td patent-date-value">Dec 6, 1994</td><td class="patent-data-table-td patent-date-value">Jun 28, 1995</td><td class="patent-data-table-td ">Xerox Corporation</td><td class="patent-data-table-td ">Explicit synchronization for self-clocking glyph codes</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/EP0764944A2?cl=en">EP0764944A2</a></td><td class="patent-data-table-td patent-date-value">Aug 27, 1996</td><td class="patent-data-table-td patent-date-value">Mar 26, 1997</td><td class="patent-data-table-td ">Olympus Optical Co., Ltd.</td><td class="patent-data-table-td ">Information recording medium for recording multimedia information as optical readable code data thereon and information recording reproducing system using the same</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2000022930A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEBqF3G8T_5MieZwvaDOytOMEujNw">JP2000022930A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2001096889A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNE2a-i_myb1sagi8_WldR2RI_4Cyg">JP2001096889A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2001346032A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNFf0uwGB2-XTFq78NKhfZkyW6lgzw">JP2001346032A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3D2001353955A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNGZoon3hOHBaVOr7SfBi4EH0FtBfA">JP2001353955A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH0931382A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHpe_pOAMn9PJ82SvXpIvQeQOHh-g">JPH0931382A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH10251570A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNEwMtTOxJv3BQwQ8goq7z7eFNI4Vw">JPH10251570A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&amp;q=http://worldwide.espacenet.com/publicationDetails/biblio%3FCC%3DJP%26NR%3DH11112787A%26KC%3DA%26FT%3DD&amp;usg=AFQjCNHkkR4ErH1PjIDhAF8H51Jpv2MiOw">JPH11112787A</a></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td patent-date-value"></td><td class="patent-data-table-td "> </td><td class="patent-data-table-td citation-no-title">Title not available</td></tr><tr><td class="patent-data-table-td citation-patent"><a href="/patents/WO2000073981A1?cl=en">WO2000073981A1</a></td><td class="patent-data-table-td patent-date-value">May 26, 2000</td><td class="patent-data-table-td patent-date-value">Dec 7, 2000</td><td class="patent-data-table-td ">Anoto Ab</td><td class="patent-data-table-td ">Recording of information</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="npl-citations"></a><div class="patent-section-header"><span class="patent-section-title">Non-Patent Citations</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th colspan="3"class="patent-data-table-th">Reference</th></tr></thead><tr><td class="patent-data-table-td ">1</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Computer, IEEE Service Center, Los Alamitos, CA, USA, vol. 34, No. 3, pp. 47-51 and 54, XP 001053842, "<a href='http://scholar.google.com/scholar?q="Printed+Embedded+Data+Graphical+User+Interfaces."'>Printed Embedded Data Graphical User Interfaces.</a>", 2001.</td></tr><tr><td class="patent-data-table-td ">2</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">CT Magazin Fuer Computer Technik, Heise Zeitschiften Verlag, Hannover, DE, p. 22, XP 00963015, "<a href='http://scholar.google.com/scholar?q="E-Commerce+mit+Stift+Auf+Papier."'>E-Commerce mit Stift Auf Papier.</a>", 2000.</td></tr><tr><td class="patent-data-table-td ">3</td><td class="patent-data-table-td "></td><td class="patent-data-table-td ">Elektronik, Weka Fachzeitschriftenverlag, Poing, DE, VIL 49, No. 16, pp. 74-76, XP 001107913, "<a href='http://scholar.google.com/scholar?q="Handschrift+Per+Funk+in+Die+Ganze+Welt."'>Handschrift Per Funk in Die Ganze Welt.</a>", 2000.</td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="forward-citations"></a><div class="patent-section-header"><span class="patent-section-title">Referenced by</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Citing Patent</th><th class="patent-data-table-th">Filing date</th><th class="patent-data-table-th">Publication date</th><th class="patent-data-table-th">Applicant</th><th class="patent-data-table-th">Title</th></tr></thead><tr><td class="patent-data-table-td citation-patent"><a href="/patents/US7903281">US7903281</a><span class='patent-tooltip-anchor' data-tooltip-text="Cited by examiner"> *</span></td><td class="patent-data-table-td patent-date-value">Aug 27, 2004</td><td class="patent-data-table-td patent-date-value">Mar 8, 2011</td><td class="patent-data-table-td ">Hewlett-Packard Development Company, L.P.</td><td class="patent-data-table-td ">Methods, apparatus and software for printing location pattern and printed materials</td></tr></table><div class="patent-section-footer">* Cited by examiner</div></div><div class="patent-section patent-tabular-section"><a id="classifications"></a><div class="patent-section-header"><span class="patent-section-title">Classifications</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th"> </th><th class="patent-data-table-th"> </th></tr></thead><tr><td class="patent-data-table-td ">U.S. Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc235/defs235.htm&usg=AFQjCNE4qW8wy3R4_i_voHj55rF5UTzd0Q#C235S454000">235/454</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://www.uspto.gov/web/patents/classification/uspc235/defs235.htm&usg=AFQjCNE4qW8wy3R4_i_voHj55rF5UTzd0Q#C235S435000">235/435</a></span></td></tr><tr><td class="patent-data-table-td ">International Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0003033000">G06F3/033</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06F0003035400">G06F3/0354</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0019060000">G06K19/06</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0007120000">G06K7/12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0007100000">G06K7/10</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://web2.wipo.int/ipcpub/&usg=AFQjCNER44F5jlVoswCkvW3YEcB5lW4moA#refresh=page&notion=scheme&version=20130101&symbol=G06K0007140000">G06K7/14</a></span></td></tr><tr><td class="patent-data-table-td ">Cooperative Classification</td><td class="patent-data-table-td "><span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K7/1417">G06K7/1417</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K2019/06262">G06K2019/06262</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K7/1456">G06K7/1456</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/0317">G06F3/0317</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06F3/03545">G06F3/03545</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K19/06">G06K19/06</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=H04N2005/4428">H04N2005/4428</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K7/12">G06K7/12</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K19/06009">G06K19/06009</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K19/06037">G06K19/06037</a></span>, <span class="nested-value"><a href="http://www.google.com/url?id=Jn2BBAABERAJ&q=http://worldwide.espacenet.com/classification&usg=AFQjCNGs5WqSrPE3A4ZP63zGuM6PRNfEFA#!/CPC=G06K2019/06234">G06K2019/06234</a></span></td></tr><tr><td class="patent-data-table-td ">European Classification</td><td class="patent-data-table-td "><span class="nested-value">G06K7/14A4G</span>, <span class="nested-value">G06F3/0354N</span>, <span class="nested-value">G06K19/06C3</span>, <span class="nested-value">G06K7/14A2C</span>, <span class="nested-value">G06K7/12</span>, <span class="nested-value">G06K19/06C</span>, <span class="nested-value">G06K19/06</span>, <span class="nested-value">G06F3/03H3</span></td></tr></table><div class="patent-section-footer"></div></div><div class="patent-section patent-tabular-section"><a id="legal-events"></a><div class="patent-section-header"><span class="patent-section-title">Legal Events</span></div><table class="patent-data-table"><thead class="patent-data-table-thead"><tr class="patent-data-table"><th class="patent-data-table-th">Date</th><th class="patent-data-table-th">Code</th><th class="patent-data-table-th">Event</th><th class="patent-data-table-th">Description</th></tr></thead><tr><td class="patent-data-table-td patent-date-value">Mar 14, 2012</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20120126</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Dec 27, 2011</td><td class="patent-data-table-td ">B1</td><td class="patent-data-table-td ">Reexamination certificate first reexamination</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">THE PATENTABILITY OF CLAIMS 9, 15, 25, 35-39 AND 46-49 IS CONFIRMED. CLAIMS 1-8, 10-14, 16-24, 26-34, 40-45, 50, AND 51 ARE CANCELLED. NEW CLAIMS 52-90 ARE ADDED AND DETERMINED TO BE PATENTABLE.</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">May 18, 2011</td><td class="patent-data-table-td ">FPAY</td><td class="patent-data-table-td ">Fee payment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Year of fee payment: </span><span class="nested-value">4</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Apr 12, 2011</td><td class="patent-data-table-td ">RR</td><td class="patent-data-table-td ">Request for reexamination filed</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20110119</span></div></td></tr><tr><td class="patent-data-table-td patent-date-value">Jul 2, 2002</td><td class="patent-data-table-td ">AS</td><td class="patent-data-table-td ">Assignment</td><td class="patent-data-table-td "><div class="nested-key-value"><span class="nested-key">Owner name: </span><span class="nested-value">SONIX TECHNOLOGY CO., LTD., TAIWAN</span></div><div class="nested-key-value"><span class="nested-key">Free format text: </span><span class="nested-value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:TSAI, YAO-HUNG;REEL/FRAME:013099/0464</span></div><div class="nested-key-value"><span class="nested-key">Effective date: </span><span class="nested-value">20020613</span></div></td></tr></table><div class="patent-section-footer"></div></div><div class="modal-dialog" id="patent-images-lightbox"><div class="patent-lightbox-controls"><div class="patent-lightbox-rotate-controls"><div class="patent-lightbox-rotation-text">Rotate</div><div class="rotate-icon rotate-ccw-icon"></div><div class="rotate-icon rotate-cw-icon"></div></div><div class="patent-lightbox-index-counter"></div><a class="patent-lightbox-fullsize-link" target="_blank">Original Image</a><div class="patent-drawings-control patent-drawings-next"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_right.png" alt="Next page"width="21" height="21" /></div><div class="patent-drawings-control patent-drawings-prev"><img class="patent-drawings-button-img"src="/googlebooks/images/kennedy/page_left.png" alt="Previous page"width="21" height="21" /></div></div><div class="modal-dialog-content"><div class="patent-lightbox-image-holder"><div class="patent-lightbox-placeholder"></div></div></div></div><script>_OC_initPatentsAtb({image_not_available_html: " Image not available"});</script></div></div></div></td></tr></table><script>(function() {var href = window.location.href;if (href.indexOf('?') !== -1) {var parameters = href.split('?')[1].split('&');for (var i = 0; i < parameters.length; i++) {var param = parameters[i].split('=');if (param[0] == 'focus') {var elem = document.getElementById(param[1]);if (elem) {elem.focus();}}}}})();</script><script>_OC_addFlags({LockSrc:"/books/javascript/lock_8a2b04e7bf975d5171d8e4c0b6365c7a.js", Host:"http://www.google.com/", IsBooksRentalEnabled:1, IsWebstoreDisplayCaseEnabled:1, IsObfuscationEnabled:1, IsBrowsingHistoryEnabled:1, IsWebReaderSvgEnabled:0, IsGeoLayerEnabled:1, IsImageModeNotesEnabled:1, IsCopyMenuItemEnabled:1, IsGiftingEnabled:0, IsWebReaderUniversalPaginatorEnabled:0, IsOfflineBubbleEnabled:1, IsReaderEnabledForPlayRequests:1, IsFutureOnSaleVolumesEnabled:1, IsOfflineRestrictedCopyEnabled:1, IsBooksUnifiedLeftNavEnabled:1, IsRestrictedCopyEnabled:1, IsZipitFolderCollectionEnabled:1, IsEndOfSampleRecommendationsEnabled:1, IsRatingsOnBookcardsEnabled:1, IsAdsDisabled:0, IsIframePageDisplayEnabled:0, IsEmbeddedMediaEnabled:1, IsImageModeAnnotationsEnabled:1, IsMyLibraryGooglePlusEnabled:1, IsImagePageProviderEnabled:0, IsBookcardListPriceSmall:0, IsInternalUser:0, IsBooksShareButtonEnabled:0, IsPreOrdersEnabled:0, IsDisabledRandomBookshelves:0, WebstoreDisplayCasePosition:3});_OC_Run({"enable_p13n":false,"add_vol_to_collection_base_url":"http://www.google.com/patents?op=add\u0026sig=ACfU3U0DPTto9-pio-ViVpMHWcO5jMEzFg\u0026id=Jn2BBAABERAJ","remove_vol_from_collection_base_url":"http://www.google.com/patents?op=remove\u0026sig=ACfU3U1rd_0kU0g4XX7NQgstkugTKNO_fg\u0026id=Jn2BBAABERAJ","logged_in":false,"p13n_save_user_settings_url":"http://www.google.com/patents?op=edit_user_settings\u0026sig=ACfU3U1ITJUbzl3THfrDy3_-JR-glcbrxQ","is_cobrand":false,"sign_in_url":"https://www.google.com/accounts/Login?service=\u0026continue=http://www.google.com/patents%3Fhl%3Den\u0026hl=en","is_play_enabled":true}, {"volume_id":"","is_ebook":true,"volumeresult":{"has_flowing_text":false,"has_scanned_text":true,"can_download_pdf":false,"can_download_epub":false,"is_pdf_drm_enabled":false,"is_epub_drm_enabled":false,"download_pdf_url":"http://www.google.com/patents/download/Method_for_producing_indicators_and_proc.pdf?id=Jn2BBAABERAJ\u0026output=pdf\u0026sig=ACfU3U2xpfy9Ys6LCF3u_3cFjH5iek04aA"},"sample_url":"http://www.google.com/patents/reader?id=Jn2BBAABERAJ\u0026printsec=frontcover\u0026output=reader\u0026source=gbs_atb_hover","is_browsable":true,"is_public_domain":true}, {});</script><div id="footer_table" style="font-size:83%;text-align:center;position:relative;top:20px;height:4.5em;margin-top:2em"><div style="margin-bottom:8px"><a href=http://www.google.com/><nobr>Google&nbsp;Home</nobr></a> - <a href=//www.google.com/patents/sitemap/><nobr>Sitemap</nobr></a> - <a href=http://www.google.com/googlebooks/uspto.html><nobr>USPTO Bulk Downloads</nobr></a> - <a href=/intl/en/privacy/><nobr>Privacy Policy</nobr></a> - <a href=/intl/en/policies/terms/><nobr>Terms of Service</nobr></a> - <a href=https://support.google.com/faqs/answer/2539193?hl=en><nobr>About Google Patents</nobr></a> - <a href="http://www.google.com/tools/feedback/intl/en/error.html" onclick="try{_OC_startFeedback({productId: '72792',locale: 'en'});return false;}catch(e){}"><nobr>Send Feedback</nobr></a></div><span>Data provided by IFI CLAIMS Patent Services</span><br><span >&copy;2012 Google</span></div> <script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">var pageTracker = _gat._getTracker("UA-27188110-1");pageTracker._setCookiePath("/patents/");pageTracker._trackPageview();</script> </body></html>